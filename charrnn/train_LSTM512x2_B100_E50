using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 211, val: 12, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 3320385	
cloning rnn	
cloning criterion	
1/10550 (epoch 0.005), train_loss = 4.13896381, grad/param norm = 8.6446e-01, time/batch = 0.4034s	
2/10550 (epoch 0.009), train_loss = 4.48787235, grad/param norm = 1.9194e+00, time/batch = 0.1806s	
3/10550 (epoch 0.014), train_loss = 4.19546351, grad/param norm = 1.1178e+00, time/batch = 0.1794s	
4/10550 (epoch 0.019), train_loss = 3.73070820, grad/param norm = 1.0907e+00, time/batch = 0.1798s	
5/10550 (epoch 0.024), train_loss = 3.87038571, grad/param norm = 1.3254e+00, time/batch = 0.1814s	
6/10550 (epoch 0.028), train_loss = 3.74759889, grad/param norm = 7.6041e-01, time/batch = 0.1800s	
7/10550 (epoch 0.033), train_loss = 3.37679065, grad/param norm = 3.3369e-01, time/batch = 0.1796s	
8/10550 (epoch 0.038), train_loss = 3.32160297, grad/param norm = 3.0804e-01, time/batch = 0.1794s	
9/10550 (epoch 0.043), train_loss = 3.33610676, grad/param norm = 4.2910e-01, time/batch = 0.1799s	
10/10550 (epoch 0.047), train_loss = 3.36714391, grad/param norm = 6.6182e-01, time/batch = 0.1796s	
11/10550 (epoch 0.052), train_loss = 3.39105150, grad/param norm = 5.5158e-01, time/batch = 0.1808s	
12/10550 (epoch 0.057), train_loss = 3.28857440, grad/param norm = 1.4637e-01, time/batch = 0.1790s	
13/10550 (epoch 0.062), train_loss = 3.32466143, grad/param norm = 1.6231e-01, time/batch = 0.1798s	
14/10550 (epoch 0.066), train_loss = 3.30121188, grad/param norm = 1.5226e-01, time/batch = 0.1795s	
15/10550 (epoch 0.071), train_loss = 3.36069142, grad/param norm = 1.9021e-01, time/batch = 0.1793s	
16/10550 (epoch 0.076), train_loss = 3.32106225, grad/param norm = 2.3179e-01, time/batch = 0.1797s	
17/10550 (epoch 0.081), train_loss = 3.30823929, grad/param norm = 2.0512e-01, time/batch = 0.1792s	
18/10550 (epoch 0.085), train_loss = 3.28407504, grad/param norm = 1.8513e-01, time/batch = 0.1789s	
19/10550 (epoch 0.090), train_loss = 3.34960672, grad/param norm = 2.0479e-01, time/batch = 0.1792s	
20/10550 (epoch 0.095), train_loss = 3.29647307, grad/param norm = 2.0448e-01, time/batch = 0.1803s	
21/10550 (epoch 0.100), train_loss = 3.28617238, grad/param norm = 1.8009e-01, time/batch = 0.1814s	
22/10550 (epoch 0.104), train_loss = 3.31836859, grad/param norm = 1.9168e-01, time/batch = 0.1788s	
23/10550 (epoch 0.109), train_loss = 3.29174567, grad/param norm = 1.7291e-01, time/batch = 0.1790s	
24/10550 (epoch 0.114), train_loss = 3.29887054, grad/param norm = 1.8021e-01, time/batch = 0.1794s	
25/10550 (epoch 0.118), train_loss = 3.33595303, grad/param norm = 1.8130e-01, time/batch = 0.1792s	
26/10550 (epoch 0.123), train_loss = 3.32449574, grad/param norm = 1.8188e-01, time/batch = 0.1798s	
27/10550 (epoch 0.128), train_loss = 3.28297843, grad/param norm = 1.9832e-01, time/batch = 0.1788s	
28/10550 (epoch 0.133), train_loss = 3.32323297, grad/param norm = 2.5974e-01, time/batch = 0.1793s	
29/10550 (epoch 0.137), train_loss = 3.28977474, grad/param norm = 2.6108e-01, time/batch = 0.1798s	
30/10550 (epoch 0.142), train_loss = 3.27245575, grad/param norm = 2.2223e-01, time/batch = 0.1798s	
31/10550 (epoch 0.147), train_loss = 3.33367666, grad/param norm = 2.2121e-01, time/batch = 0.1809s	
32/10550 (epoch 0.152), train_loss = 3.33732894, grad/param norm = 3.1412e-01, time/batch = 0.1788s	
33/10550 (epoch 0.156), train_loss = 3.29071333, grad/param norm = 2.1324e-01, time/batch = 0.1793s	
34/10550 (epoch 0.161), train_loss = 3.31286582, grad/param norm = 1.6122e-01, time/batch = 0.1791s	
35/10550 (epoch 0.166), train_loss = 3.29525084, grad/param norm = 1.7049e-01, time/batch = 0.1792s	
36/10550 (epoch 0.171), train_loss = 3.28579793, grad/param norm = 2.1800e-01, time/batch = 0.1793s	
37/10550 (epoch 0.175), train_loss = 3.29446139, grad/param norm = 2.2004e-01, time/batch = 0.1790s	
38/10550 (epoch 0.180), train_loss = 3.27129303, grad/param norm = 2.3697e-01, time/batch = 0.1789s	
39/10550 (epoch 0.185), train_loss = 3.29298604, grad/param norm = 2.2325e-01, time/batch = 0.1799s	
40/10550 (epoch 0.190), train_loss = 3.29765000, grad/param norm = 2.1757e-01, time/batch = 0.1800s	
41/10550 (epoch 0.194), train_loss = 3.32191912, grad/param norm = 1.9953e-01, time/batch = 0.1815s	
42/10550 (epoch 0.199), train_loss = 3.25534346, grad/param norm = 1.9219e-01, time/batch = 0.1790s	
43/10550 (epoch 0.204), train_loss = 3.27504019, grad/param norm = 2.0521e-01, time/batch = 0.1792s	
44/10550 (epoch 0.209), train_loss = 3.22457110, grad/param norm = 1.7018e-01, time/batch = 0.1797s	
45/10550 (epoch 0.213), train_loss = 3.25475919, grad/param norm = 1.8338e-01, time/batch = 0.1794s	
46/10550 (epoch 0.218), train_loss = 3.34343595, grad/param norm = 7.1085e-01, time/batch = 0.1792s	
47/10550 (epoch 0.223), train_loss = 3.34432724, grad/param norm = 2.5448e-01, time/batch = 0.1797s	
48/10550 (epoch 0.227), train_loss = 3.32428993, grad/param norm = 2.4335e-01, time/batch = 0.1788s	
49/10550 (epoch 0.232), train_loss = 3.27712008, grad/param norm = 2.5140e-01, time/batch = 0.1798s	
50/10550 (epoch 0.237), train_loss = 3.28546172, grad/param norm = 3.0531e-01, time/batch = 0.1795s	
51/10550 (epoch 0.242), train_loss = 3.30302816, grad/param norm = 3.6021e-01, time/batch = 0.1815s	
52/10550 (epoch 0.246), train_loss = 3.23841211, grad/param norm = 1.4285e-01, time/batch = 0.1790s	
53/10550 (epoch 0.251), train_loss = 3.25110409, grad/param norm = 1.6269e-01, time/batch = 0.1793s	
54/10550 (epoch 0.256), train_loss = 3.26094918, grad/param norm = 2.2199e-01, time/batch = 0.1792s	
55/10550 (epoch 0.261), train_loss = 3.24626249, grad/param norm = 2.1378e-01, time/batch = 0.1789s	
56/10550 (epoch 0.265), train_loss = 3.24756571, grad/param norm = 1.9070e-01, time/batch = 0.1790s	
57/10550 (epoch 0.270), train_loss = 3.22355551, grad/param norm = 2.3505e-01, time/batch = 0.1796s	
58/10550 (epoch 0.275), train_loss = 3.22961138, grad/param norm = 2.3237e-01, time/batch = 0.1790s	
59/10550 (epoch 0.280), train_loss = 3.20939685, grad/param norm = 2.5633e-01, time/batch = 0.1800s	
60/10550 (epoch 0.284), train_loss = 3.20863247, grad/param norm = 2.8169e-01, time/batch = 0.1798s	
61/10550 (epoch 0.289), train_loss = 3.22567872, grad/param norm = 2.7234e-01, time/batch = 0.1814s	
62/10550 (epoch 0.294), train_loss = 3.20577894, grad/param norm = 2.6371e-01, time/batch = 0.1784s	
63/10550 (epoch 0.299), train_loss = 3.15537885, grad/param norm = 2.2554e-01, time/batch = 0.1791s	
64/10550 (epoch 0.303), train_loss = 3.14801132, grad/param norm = 1.9046e-01, time/batch = 0.1789s	
65/10550 (epoch 0.308), train_loss = 3.13626150, grad/param norm = 1.9235e-01, time/batch = 0.1793s	
66/10550 (epoch 0.313), train_loss = 3.13409030, grad/param norm = 2.0037e-01, time/batch = 0.1822s	
67/10550 (epoch 0.318), train_loss = 3.19016316, grad/param norm = 2.5049e-01, time/batch = 0.1795s	
68/10550 (epoch 0.322), train_loss = 3.20066463, grad/param norm = 3.7212e-01, time/batch = 0.1788s	
69/10550 (epoch 0.327), train_loss = 3.21090294, grad/param norm = 1.9105e-01, time/batch = 0.1796s	
70/10550 (epoch 0.332), train_loss = 3.12682590, grad/param norm = 1.3786e-01, time/batch = 0.1802s	
71/10550 (epoch 0.336), train_loss = 3.11957448, grad/param norm = 1.8401e-01, time/batch = 0.1817s	
72/10550 (epoch 0.341), train_loss = 3.13783619, grad/param norm = 3.2463e-01, time/batch = 0.1789s	
73/10550 (epoch 0.346), train_loss = 3.16468828, grad/param norm = 4.5532e-01, time/batch = 0.1791s	
74/10550 (epoch 0.351), train_loss = 3.15079474, grad/param norm = 4.2203e-01, time/batch = 0.1794s	
75/10550 (epoch 0.355), train_loss = 3.14927458, grad/param norm = 3.1264e-01, time/batch = 0.1794s	
76/10550 (epoch 0.360), train_loss = 3.06537579, grad/param norm = 1.8014e-01, time/batch = 0.1794s	
77/10550 (epoch 0.365), train_loss = 3.03490061, grad/param norm = 1.6840e-01, time/batch = 0.1787s	
78/10550 (epoch 0.370), train_loss = 3.02256182, grad/param norm = 1.5266e-01, time/batch = 0.1788s	
79/10550 (epoch 0.374), train_loss = 3.02719488, grad/param norm = 1.3350e-01, time/batch = 0.1794s	
80/10550 (epoch 0.379), train_loss = 2.99259556, grad/param norm = 3.3590e-01, time/batch = 0.1795s	
81/10550 (epoch 0.384), train_loss = 3.12982462, grad/param norm = 5.4110e-01, time/batch = 0.1815s	
82/10550 (epoch 0.389), train_loss = 3.07912615, grad/param norm = 3.6469e-01, time/batch = 0.1788s	
83/10550 (epoch 0.393), train_loss = 3.10474226, grad/param norm = 3.4972e-01, time/batch = 0.1789s	
84/10550 (epoch 0.398), train_loss = 3.09765841, grad/param norm = 5.1714e-01, time/batch = 0.1795s	
85/10550 (epoch 0.403), train_loss = 3.11745617, grad/param norm = 3.3538e-01, time/batch = 0.1798s	
86/10550 (epoch 0.408), train_loss = 3.02346879, grad/param norm = 2.2000e-01, time/batch = 0.1796s	
87/10550 (epoch 0.412), train_loss = 2.98193409, grad/param norm = 2.5637e-01, time/batch = 0.1797s	
88/10550 (epoch 0.417), train_loss = 2.94394232, grad/param norm = 2.3774e-01, time/batch = 0.1790s	
89/10550 (epoch 0.422), train_loss = 2.97918774, grad/param norm = 2.4880e-01, time/batch = 0.1794s	
90/10550 (epoch 0.427), train_loss = 2.90558738, grad/param norm = 2.7579e-01, time/batch = 0.1799s	
91/10550 (epoch 0.431), train_loss = 2.89000295, grad/param norm = 2.9494e-01, time/batch = 0.1813s	
92/10550 (epoch 0.436), train_loss = 2.89191930, grad/param norm = 3.2377e-01, time/batch = 0.1788s	
93/10550 (epoch 0.441), train_loss = 2.86012318, grad/param norm = 2.9991e-01, time/batch = 0.1794s	
94/10550 (epoch 0.445), train_loss = 2.85016182, grad/param norm = 2.8741e-01, time/batch = 0.1792s	
95/10550 (epoch 0.450), train_loss = 2.85218598, grad/param norm = 2.7807e-01, time/batch = 0.1794s	
96/10550 (epoch 0.455), train_loss = 2.82086672, grad/param norm = 2.7076e-01, time/batch = 0.1793s	
97/10550 (epoch 0.460), train_loss = 2.83682415, grad/param norm = 3.3163e-01, time/batch = 0.1792s	
98/10550 (epoch 0.464), train_loss = 2.97472908, grad/param norm = 8.3735e-01, time/batch = 0.1787s	
99/10550 (epoch 0.469), train_loss = 3.04587753, grad/param norm = 4.8119e-01, time/batch = 0.1792s	
100/10550 (epoch 0.474), train_loss = 2.87489602, grad/param norm = 1.9040e-01, time/batch = 0.1803s	
101/10550 (epoch 0.479), train_loss = 2.83392599, grad/param norm = 3.1835e-01, time/batch = 0.1814s	
102/10550 (epoch 0.483), train_loss = 2.82515940, grad/param norm = 2.7168e-01, time/batch = 0.1790s	
103/10550 (epoch 0.488), train_loss = 2.81807466, grad/param norm = 2.4471e-01, time/batch = 0.1788s	
104/10550 (epoch 0.493), train_loss = 2.71132879, grad/param norm = 2.3116e-01, time/batch = 0.1799s	
105/10550 (epoch 0.498), train_loss = 2.70634521, grad/param norm = 2.2358e-01, time/batch = 0.1796s	
106/10550 (epoch 0.502), train_loss = 2.71677030, grad/param norm = 2.8562e-01, time/batch = 0.1789s	
107/10550 (epoch 0.507), train_loss = 2.70343086, grad/param norm = 2.7112e-01, time/batch = 0.1793s	
108/10550 (epoch 0.512), train_loss = 2.69529633, grad/param norm = 2.2020e-01, time/batch = 0.1789s	
109/10550 (epoch 0.517), train_loss = 2.68793481, grad/param norm = 1.9728e-01, time/batch = 0.1794s	
110/10550 (epoch 0.521), train_loss = 2.64949730, grad/param norm = 1.7752e-01, time/batch = 0.1793s	
111/10550 (epoch 0.526), train_loss = 2.63478253, grad/param norm = 2.1494e-01, time/batch = 0.1820s	
112/10550 (epoch 0.531), train_loss = 2.67516104, grad/param norm = 2.8554e-01, time/batch = 0.1790s	
113/10550 (epoch 0.536), train_loss = 2.67979506, grad/param norm = 3.1237e-01, time/batch = 0.1793s	
114/10550 (epoch 0.540), train_loss = 2.64474738, grad/param norm = 3.2226e-01, time/batch = 0.1793s	
115/10550 (epoch 0.545), train_loss = 2.62636621, grad/param norm = 2.6277e-01, time/batch = 0.1789s	
116/10550 (epoch 0.550), train_loss = 2.62672278, grad/param norm = 2.4975e-01, time/batch = 0.1794s	
117/10550 (epoch 0.555), train_loss = 2.59997290, grad/param norm = 2.7912e-01, time/batch = 0.1791s	
118/10550 (epoch 0.559), train_loss = 2.61390091, grad/param norm = 2.8791e-01, time/batch = 0.1791s	
119/10550 (epoch 0.564), train_loss = 2.55184210, grad/param norm = 2.7597e-01, time/batch = 0.1795s	
120/10550 (epoch 0.569), train_loss = 2.57121274, grad/param norm = 2.7626e-01, time/batch = 0.1797s	
121/10550 (epoch 0.573), train_loss = 2.54267102, grad/param norm = 2.4415e-01, time/batch = 0.1811s	
122/10550 (epoch 0.578), train_loss = 2.51469618, grad/param norm = 2.2539e-01, time/batch = 0.1790s	
123/10550 (epoch 0.583), train_loss = 2.55260776, grad/param norm = 2.7456e-01, time/batch = 0.1794s	
124/10550 (epoch 0.588), train_loss = 2.60303215, grad/param norm = 2.6197e-01, time/batch = 0.1792s	
125/10550 (epoch 0.592), train_loss = 2.57340595, grad/param norm = 2.6647e-01, time/batch = 0.1788s	
126/10550 (epoch 0.597), train_loss = 2.57336630, grad/param norm = 2.9249e-01, time/batch = 0.1796s	
127/10550 (epoch 0.602), train_loss = 2.54825687, grad/param norm = 2.3513e-01, time/batch = 0.1793s	
128/10550 (epoch 0.607), train_loss = 2.53577184, grad/param norm = 3.0220e-01, time/batch = 0.1787s	
129/10550 (epoch 0.611), train_loss = 2.57612577, grad/param norm = 3.2676e-01, time/batch = 0.1797s	
130/10550 (epoch 0.616), train_loss = 2.50654758, grad/param norm = 2.8488e-01, time/batch = 0.1800s	
131/10550 (epoch 0.621), train_loss = 2.50435393, grad/param norm = 2.3517e-01, time/batch = 0.1812s	
132/10550 (epoch 0.626), train_loss = 2.45028408, grad/param norm = 1.3982e-01, time/batch = 0.1788s	
133/10550 (epoch 0.630), train_loss = 2.48616065, grad/param norm = 1.3029e-01, time/batch = 0.1795s	
134/10550 (epoch 0.635), train_loss = 2.43421771, grad/param norm = 1.4165e-01, time/batch = 0.1794s	
135/10550 (epoch 0.640), train_loss = 2.42589790, grad/param norm = 1.6571e-01, time/batch = 0.1793s	
136/10550 (epoch 0.645), train_loss = 2.44308890, grad/param norm = 2.1914e-01, time/batch = 0.1793s	
137/10550 (epoch 0.649), train_loss = 2.50149684, grad/param norm = 2.8776e-01, time/batch = 0.1790s	
138/10550 (epoch 0.654), train_loss = 2.51840087, grad/param norm = 2.5569e-01, time/batch = 0.1786s	
139/10550 (epoch 0.659), train_loss = 2.46155510, grad/param norm = 2.1356e-01, time/batch = 0.1795s	
140/10550 (epoch 0.664), train_loss = 2.47752016, grad/param norm = 2.0412e-01, time/batch = 0.1792s	
141/10550 (epoch 0.668), train_loss = 2.46632206, grad/param norm = 1.8304e-01, time/batch = 0.1813s	
142/10550 (epoch 0.673), train_loss = 2.44977556, grad/param norm = 1.8535e-01, time/batch = 0.1790s	
143/10550 (epoch 0.678), train_loss = 2.41848563, grad/param norm = 2.7742e-01, time/batch = 0.1792s	
144/10550 (epoch 0.682), train_loss = 2.48474816, grad/param norm = 4.0198e-01, time/batch = 0.1791s	
145/10550 (epoch 0.687), train_loss = 2.51734259, grad/param norm = 3.2726e-01, time/batch = 0.1794s	
146/10550 (epoch 0.692), train_loss = 2.46218748, grad/param norm = 3.0893e-01, time/batch = 0.1795s	
147/10550 (epoch 0.697), train_loss = 2.47729061, grad/param norm = 3.0070e-01, time/batch = 0.1794s	
148/10550 (epoch 0.701), train_loss = 2.43678652, grad/param norm = 1.7777e-01, time/batch = 0.1790s	
149/10550 (epoch 0.706), train_loss = 2.41312347, grad/param norm = 1.5366e-01, time/batch = 0.1798s	
150/10550 (epoch 0.711), train_loss = 2.40429432, grad/param norm = 1.5664e-01, time/batch = 0.1799s	
151/10550 (epoch 0.716), train_loss = 2.41986056, grad/param norm = 1.8942e-01, time/batch = 0.1814s	
152/10550 (epoch 0.720), train_loss = 2.39489412, grad/param norm = 1.9232e-01, time/batch = 0.1792s	
153/10550 (epoch 0.725), train_loss = 2.38545242, grad/param norm = 1.7134e-01, time/batch = 0.1794s	
154/10550 (epoch 0.730), train_loss = 2.39047010, grad/param norm = 1.7128e-01, time/batch = 0.1794s	
155/10550 (epoch 0.735), train_loss = 2.33925642, grad/param norm = 1.4829e-01, time/batch = 0.1795s	
156/10550 (epoch 0.739), train_loss = 2.34473729, grad/param norm = 1.2539e-01, time/batch = 0.1806s	
157/10550 (epoch 0.744), train_loss = 2.35318173, grad/param norm = 1.2531e-01, time/batch = 0.1804s	
158/10550 (epoch 0.749), train_loss = 2.35292973, grad/param norm = 1.5741e-01, time/batch = 0.1791s	
159/10550 (epoch 0.754), train_loss = 2.35552819, grad/param norm = 2.7240e-01, time/batch = 0.1799s	
160/10550 (epoch 0.758), train_loss = 2.40833771, grad/param norm = 3.0576e-01, time/batch = 0.1796s	
161/10550 (epoch 0.763), train_loss = 2.39507787, grad/param norm = 2.5601e-01, time/batch = 0.1815s	
162/10550 (epoch 0.768), train_loss = 2.39367838, grad/param norm = 2.6274e-01, time/batch = 0.1791s	
163/10550 (epoch 0.773), train_loss = 2.37109457, grad/param norm = 2.5352e-01, time/batch = 0.1795s	
164/10550 (epoch 0.777), train_loss = 2.40118895, grad/param norm = 3.2426e-01, time/batch = 0.1794s	
165/10550 (epoch 0.782), train_loss = 2.38128736, grad/param norm = 1.9392e-01, time/batch = 0.1796s	
166/10550 (epoch 0.787), train_loss = 2.36437588, grad/param norm = 1.4741e-01, time/batch = 0.1792s	
167/10550 (epoch 0.791), train_loss = 2.30783364, grad/param norm = 1.5716e-01, time/batch = 0.1789s	
168/10550 (epoch 0.796), train_loss = 2.27910673, grad/param norm = 1.5423e-01, time/batch = 0.1792s	
169/10550 (epoch 0.801), train_loss = 2.32616538, grad/param norm = 1.5543e-01, time/batch = 0.1797s	
170/10550 (epoch 0.806), train_loss = 2.34441054, grad/param norm = 1.8165e-01, time/batch = 0.1800s	
171/10550 (epoch 0.810), train_loss = 2.32704968, grad/param norm = 1.8456e-01, time/batch = 0.1816s	
172/10550 (epoch 0.815), train_loss = 2.30752258, grad/param norm = 1.9379e-01, time/batch = 0.1792s	
173/10550 (epoch 0.820), train_loss = 2.30061168, grad/param norm = 2.2921e-01, time/batch = 0.1786s	
174/10550 (epoch 0.825), train_loss = 2.31619906, grad/param norm = 2.6131e-01, time/batch = 0.1795s	
175/10550 (epoch 0.829), train_loss = 2.30566898, grad/param norm = 2.5908e-01, time/batch = 0.1799s	
176/10550 (epoch 0.834), train_loss = 2.36966355, grad/param norm = 2.3522e-01, time/batch = 0.1789s	
177/10550 (epoch 0.839), train_loss = 2.30415601, grad/param norm = 1.9192e-01, time/batch = 0.1797s	
178/10550 (epoch 0.844), train_loss = 2.30557122, grad/param norm = 1.7396e-01, time/batch = 0.1792s	
179/10550 (epoch 0.848), train_loss = 2.25700672, grad/param norm = 1.6705e-01, time/batch = 0.1798s	
180/10550 (epoch 0.853), train_loss = 2.24828891, grad/param norm = 1.7081e-01, time/batch = 0.1797s	
181/10550 (epoch 0.858), train_loss = 2.29379531, grad/param norm = 2.1185e-01, time/batch = 0.1811s	
182/10550 (epoch 0.863), train_loss = 2.34753317, grad/param norm = 2.3909e-01, time/batch = 0.1791s	
183/10550 (epoch 0.867), train_loss = 2.33631056, grad/param norm = 2.5794e-01, time/batch = 0.1791s	
184/10550 (epoch 0.872), train_loss = 2.32768647, grad/param norm = 2.4627e-01, time/batch = 0.1794s	
185/10550 (epoch 0.877), train_loss = 2.20723911, grad/param norm = 1.9085e-01, time/batch = 0.1790s	
186/10550 (epoch 0.882), train_loss = 2.25698574, grad/param norm = 1.7196e-01, time/batch = 0.1797s	
187/10550 (epoch 0.886), train_loss = 2.23177530, grad/param norm = 1.6861e-01, time/batch = 0.1793s	
188/10550 (epoch 0.891), train_loss = 2.26258333, grad/param norm = 1.6948e-01, time/batch = 0.1790s	
189/10550 (epoch 0.896), train_loss = 2.23327492, grad/param norm = 1.5025e-01, time/batch = 0.1800s	
190/10550 (epoch 0.900), train_loss = 2.20691987, grad/param norm = 1.4230e-01, time/batch = 0.1798s	
191/10550 (epoch 0.905), train_loss = 2.21692690, grad/param norm = 1.2366e-01, time/batch = 0.1811s	
192/10550 (epoch 0.910), train_loss = 2.16972825, grad/param norm = 1.3966e-01, time/batch = 0.1791s	
193/10550 (epoch 0.915), train_loss = 2.21100103, grad/param norm = 1.5775e-01, time/batch = 0.1793s	
194/10550 (epoch 0.919), train_loss = 2.19680890, grad/param norm = 2.1605e-01, time/batch = 0.1793s	
195/10550 (epoch 0.924), train_loss = 2.21451450, grad/param norm = 2.3233e-01, time/batch = 0.1794s	
196/10550 (epoch 0.929), train_loss = 2.21545275, grad/param norm = 3.0925e-01, time/batch = 0.1796s	
197/10550 (epoch 0.934), train_loss = 2.26327882, grad/param norm = 2.7535e-01, time/batch = 0.1795s	
198/10550 (epoch 0.938), train_loss = 2.25323126, grad/param norm = 2.0689e-01, time/batch = 0.1790s	
199/10550 (epoch 0.943), train_loss = 2.24331746, grad/param norm = 1.9159e-01, time/batch = 0.1796s	
200/10550 (epoch 0.948), train_loss = 2.23350626, grad/param norm = 1.6231e-01, time/batch = 0.1798s	
201/10550 (epoch 0.953), train_loss = 2.20367661, grad/param norm = 1.0951e-01, time/batch = 0.1819s	
202/10550 (epoch 0.957), train_loss = 2.16466318, grad/param norm = 9.7637e-02, time/batch = 0.1795s	
203/10550 (epoch 0.962), train_loss = 2.14588641, grad/param norm = 1.0587e-01, time/batch = 0.1792s	
204/10550 (epoch 0.967), train_loss = 2.16749347, grad/param norm = 1.2138e-01, time/batch = 0.1797s	
205/10550 (epoch 0.972), train_loss = 2.17141850, grad/param norm = 1.3186e-01, time/batch = 0.1795s	
206/10550 (epoch 0.976), train_loss = 2.20661520, grad/param norm = 1.5778e-01, time/batch = 0.1795s	
207/10550 (epoch 0.981), train_loss = 2.20349986, grad/param norm = 1.8403e-01, time/batch = 0.1791s	
208/10550 (epoch 0.986), train_loss = 2.22071874, grad/param norm = 2.4101e-01, time/batch = 0.1787s	
209/10550 (epoch 0.991), train_loss = 2.29015300, grad/param norm = 2.3167e-01, time/batch = 0.1800s	
210/10550 (epoch 0.995), train_loss = 2.24908837, grad/param norm = 3.2726e-01, time/batch = 0.1801s	
211/10550 (epoch 1.000), train_loss = 2.22787535, grad/param norm = 2.1660e-01, time/batch = 0.1814s	
212/10550 (epoch 1.005), train_loss = 2.23615622, grad/param norm = 1.9575e-01, time/batch = 0.1794s	
213/10550 (epoch 1.009), train_loss = 2.16834271, grad/param norm = 1.4432e-01, time/batch = 0.1793s	
214/10550 (epoch 1.014), train_loss = 2.11250401, grad/param norm = 1.2253e-01, time/batch = 0.1793s	
215/10550 (epoch 1.019), train_loss = 2.17053135, grad/param norm = 1.2222e-01, time/batch = 0.1798s	
216/10550 (epoch 1.024), train_loss = 2.13205847, grad/param norm = 1.6340e-01, time/batch = 0.1792s	
217/10550 (epoch 1.028), train_loss = 2.17320209, grad/param norm = 2.3597e-01, time/batch = 0.1791s	
218/10550 (epoch 1.033), train_loss = 2.19858017, grad/param norm = 2.6965e-01, time/batch = 0.1787s	
219/10550 (epoch 1.038), train_loss = 2.19356213, grad/param norm = 1.7198e-01, time/batch = 0.1797s	
220/10550 (epoch 1.043), train_loss = 2.14988612, grad/param norm = 2.1201e-01, time/batch = 0.1799s	
221/10550 (epoch 1.047), train_loss = 2.11046935, grad/param norm = 1.7682e-01, time/batch = 0.1811s	
222/10550 (epoch 1.052), train_loss = 2.15685183, grad/param norm = 1.4436e-01, time/batch = 0.1794s	
223/10550 (epoch 1.057), train_loss = 2.11181182, grad/param norm = 1.3527e-01, time/batch = 0.1796s	
224/10550 (epoch 1.062), train_loss = 2.11597137, grad/param norm = 1.3671e-01, time/batch = 0.1793s	
225/10550 (epoch 1.066), train_loss = 2.11416620, grad/param norm = 1.4250e-01, time/batch = 0.1794s	
226/10550 (epoch 1.071), train_loss = 2.10351889, grad/param norm = 2.1264e-01, time/batch = 0.1791s	
227/10550 (epoch 1.076), train_loss = 2.16291583, grad/param norm = 2.2041e-01, time/batch = 0.1791s	
228/10550 (epoch 1.081), train_loss = 2.23380742, grad/param norm = 4.4929e-01, time/batch = 0.1787s	
229/10550 (epoch 1.085), train_loss = 2.20979330, grad/param norm = 1.8838e-01, time/batch = 0.1792s	
230/10550 (epoch 1.090), train_loss = 2.09274823, grad/param norm = 1.2969e-01, time/batch = 0.1792s	
231/10550 (epoch 1.095), train_loss = 2.08015515, grad/param norm = 1.3373e-01, time/batch = 0.1817s	
232/10550 (epoch 1.100), train_loss = 2.08256181, grad/param norm = 1.6529e-01, time/batch = 0.1790s	
233/10550 (epoch 1.104), train_loss = 2.06714130, grad/param norm = 1.6389e-01, time/batch = 0.1796s	
234/10550 (epoch 1.109), train_loss = 2.05486941, grad/param norm = 1.4772e-01, time/batch = 0.1795s	
235/10550 (epoch 1.114), train_loss = 2.06165360, grad/param norm = 1.4274e-01, time/batch = 0.1794s	
236/10550 (epoch 1.118), train_loss = 2.03952281, grad/param norm = 1.4690e-01, time/batch = 0.1795s	
237/10550 (epoch 1.123), train_loss = 2.06442883, grad/param norm = 1.4141e-01, time/batch = 0.1793s	
238/10550 (epoch 1.128), train_loss = 2.01595385, grad/param norm = 1.5314e-01, time/batch = 0.1793s	
239/10550 (epoch 1.133), train_loss = 2.08145785, grad/param norm = 1.4796e-01, time/batch = 0.1802s	
240/10550 (epoch 1.137), train_loss = 2.01262659, grad/param norm = 1.1173e-01, time/batch = 0.1794s	
241/10550 (epoch 1.142), train_loss = 2.05830940, grad/param norm = 1.3538e-01, time/batch = 0.1815s	
242/10550 (epoch 1.147), train_loss = 2.05614821, grad/param norm = 1.7225e-01, time/batch = 0.1791s	
243/10550 (epoch 1.152), train_loss = 2.07990129, grad/param norm = 1.7851e-01, time/batch = 0.1790s	
244/10550 (epoch 1.156), train_loss = 2.02113829, grad/param norm = 1.8040e-01, time/batch = 0.1790s	
245/10550 (epoch 1.161), train_loss = 2.04391924, grad/param norm = 1.7503e-01, time/batch = 0.1795s	
246/10550 (epoch 1.166), train_loss = 2.03089604, grad/param norm = 1.4919e-01, time/batch = 0.1795s	
247/10550 (epoch 1.171), train_loss = 2.04098726, grad/param norm = 1.3341e-01, time/batch = 0.1823s	
248/10550 (epoch 1.175), train_loss = 2.08623644, grad/param norm = 1.2850e-01, time/batch = 0.1793s	
249/10550 (epoch 1.180), train_loss = 2.05484364, grad/param norm = 1.3755e-01, time/batch = 0.1798s	
250/10550 (epoch 1.185), train_loss = 2.00674946, grad/param norm = 1.3126e-01, time/batch = 0.1797s	
251/10550 (epoch 1.190), train_loss = 2.02328660, grad/param norm = 1.2491e-01, time/batch = 0.1816s	
252/10550 (epoch 1.194), train_loss = 2.02493862, grad/param norm = 1.1098e-01, time/batch = 0.1788s	
253/10550 (epoch 1.199), train_loss = 1.99927932, grad/param norm = 1.0214e-01, time/batch = 0.1794s	
254/10550 (epoch 1.204), train_loss = 2.00196582, grad/param norm = 1.0145e-01, time/batch = 0.1792s	
255/10550 (epoch 1.209), train_loss = 2.00195117, grad/param norm = 1.0940e-01, time/batch = 0.1788s	
256/10550 (epoch 1.213), train_loss = 2.00855629, grad/param norm = 1.3772e-01, time/batch = 0.1793s	
257/10550 (epoch 1.218), train_loss = 2.01348397, grad/param norm = 2.2231e-01, time/batch = 0.1792s	
258/10550 (epoch 1.223), train_loss = 2.02763255, grad/param norm = 2.4394e-01, time/batch = 0.1790s	
259/10550 (epoch 1.227), train_loss = 2.04115551, grad/param norm = 3.1422e-01, time/batch = 0.1799s	
260/10550 (epoch 1.232), train_loss = 2.07821345, grad/param norm = 1.9718e-01, time/batch = 0.1796s	
261/10550 (epoch 1.237), train_loss = 2.00055366, grad/param norm = 1.6395e-01, time/batch = 0.1815s	
262/10550 (epoch 1.242), train_loss = 2.02807587, grad/param norm = 1.4317e-01, time/batch = 0.1790s	
263/10550 (epoch 1.246), train_loss = 1.96170589, grad/param norm = 1.2756e-01, time/batch = 0.1797s	
264/10550 (epoch 1.251), train_loss = 1.97038520, grad/param norm = 1.3008e-01, time/batch = 0.1793s	
265/10550 (epoch 1.256), train_loss = 1.99975873, grad/param norm = 1.3491e-01, time/batch = 0.1797s	
266/10550 (epoch 1.261), train_loss = 1.99391100, grad/param norm = 1.2644e-01, time/batch = 0.1791s	
267/10550 (epoch 1.265), train_loss = 1.95309312, grad/param norm = 1.2380e-01, time/batch = 0.1796s	
268/10550 (epoch 1.270), train_loss = 1.97193121, grad/param norm = 1.3961e-01, time/batch = 0.1789s	
269/10550 (epoch 1.275), train_loss = 1.98125689, grad/param norm = 1.2982e-01, time/batch = 0.1796s	
270/10550 (epoch 1.280), train_loss = 1.98160011, grad/param norm = 1.1084e-01, time/batch = 0.1797s	
271/10550 (epoch 1.284), train_loss = 1.93966903, grad/param norm = 1.2681e-01, time/batch = 0.1809s	
272/10550 (epoch 1.289), train_loss = 1.98108192, grad/param norm = 1.2294e-01, time/batch = 0.1790s	
273/10550 (epoch 1.294), train_loss = 1.96408170, grad/param norm = 1.1585e-01, time/batch = 0.1791s	
274/10550 (epoch 1.299), train_loss = 1.94055197, grad/param norm = 1.1223e-01, time/batch = 0.1791s	
275/10550 (epoch 1.303), train_loss = 1.95966462, grad/param norm = 1.1320e-01, time/batch = 0.1795s	
276/10550 (epoch 1.308), train_loss = 1.94349180, grad/param norm = 1.2611e-01, time/batch = 0.1794s	
277/10550 (epoch 1.313), train_loss = 1.97464379, grad/param norm = 1.3752e-01, time/batch = 0.1790s	
278/10550 (epoch 1.318), train_loss = 1.94816970, grad/param norm = 1.5029e-01, time/batch = 0.1791s	
279/10550 (epoch 1.322), train_loss = 1.97918166, grad/param norm = 1.7182e-01, time/batch = 0.1793s	
280/10550 (epoch 1.327), train_loss = 2.01620215, grad/param norm = 1.8118e-01, time/batch = 0.1800s	
281/10550 (epoch 1.332), train_loss = 1.97862899, grad/param norm = 1.7154e-01, time/batch = 0.1813s	
282/10550 (epoch 1.336), train_loss = 1.94970263, grad/param norm = 1.1440e-01, time/batch = 0.1787s	
283/10550 (epoch 1.341), train_loss = 1.92232053, grad/param norm = 9.0979e-02, time/batch = 0.1792s	
284/10550 (epoch 1.346), train_loss = 1.93589313, grad/param norm = 1.1343e-01, time/batch = 0.1792s	
285/10550 (epoch 1.351), train_loss = 1.95814692, grad/param norm = 1.5695e-01, time/batch = 0.1793s	
286/10550 (epoch 1.355), train_loss = 1.93714697, grad/param norm = 1.8441e-01, time/batch = 0.1790s	
287/10550 (epoch 1.360), train_loss = 1.96321651, grad/param norm = 1.4989e-01, time/batch = 0.1791s	
288/10550 (epoch 1.365), train_loss = 1.86747857, grad/param norm = 1.0534e-01, time/batch = 0.1793s	
289/10550 (epoch 1.370), train_loss = 1.87279200, grad/param norm = 1.0955e-01, time/batch = 0.1791s	
290/10550 (epoch 1.374), train_loss = 1.92218897, grad/param norm = 1.5696e-01, time/batch = 0.1801s	
291/10550 (epoch 1.379), train_loss = 1.94204280, grad/param norm = 1.5087e-01, time/batch = 0.1815s	
292/10550 (epoch 1.384), train_loss = 1.89950878, grad/param norm = 1.3148e-01, time/batch = 0.1816s	
293/10550 (epoch 1.389), train_loss = 1.86784493, grad/param norm = 1.2368e-01, time/batch = 0.1796s	
294/10550 (epoch 1.393), train_loss = 1.90101098, grad/param norm = 9.9668e-02, time/batch = 0.1799s	
295/10550 (epoch 1.398), train_loss = 1.87034071, grad/param norm = 9.6277e-02, time/batch = 0.1798s	
296/10550 (epoch 1.403), train_loss = 1.90540415, grad/param norm = 1.0261e-01, time/batch = 0.1789s	
297/10550 (epoch 1.408), train_loss = 1.92473439, grad/param norm = 1.2694e-01, time/batch = 0.1795s	
298/10550 (epoch 1.412), train_loss = 1.89489847, grad/param norm = 1.2347e-01, time/batch = 0.1794s	
299/10550 (epoch 1.417), train_loss = 1.86129147, grad/param norm = 1.2128e-01, time/batch = 0.1799s	
300/10550 (epoch 1.422), train_loss = 1.96953172, grad/param norm = 1.5208e-01, time/batch = 0.1798s	
301/10550 (epoch 1.427), train_loss = 1.95583688, grad/param norm = 1.7372e-01, time/batch = 0.1813s	
302/10550 (epoch 1.431), train_loss = 1.95189456, grad/param norm = 1.7684e-01, time/batch = 0.1786s	
303/10550 (epoch 1.436), train_loss = 1.87075954, grad/param norm = 1.4119e-01, time/batch = 0.1793s	
304/10550 (epoch 1.441), train_loss = 1.89989590, grad/param norm = 1.1037e-01, time/batch = 0.1791s	
305/10550 (epoch 1.445), train_loss = 1.87424366, grad/param norm = 9.5650e-02, time/batch = 0.1792s	
306/10550 (epoch 1.450), train_loss = 1.86939584, grad/param norm = 8.9050e-02, time/batch = 0.1792s	
307/10550 (epoch 1.455), train_loss = 1.86697830, grad/param norm = 8.8540e-02, time/batch = 0.1795s	
308/10550 (epoch 1.460), train_loss = 1.84260091, grad/param norm = 9.0357e-02, time/batch = 0.1791s	
309/10550 (epoch 1.464), train_loss = 1.83920550, grad/param norm = 9.4238e-02, time/batch = 0.1791s	
310/10550 (epoch 1.469), train_loss = 1.81437694, grad/param norm = 9.6828e-02, time/batch = 0.1798s	
311/10550 (epoch 1.474), train_loss = 1.89360205, grad/param norm = 1.0997e-01, time/batch = 0.1807s	
312/10550 (epoch 1.479), train_loss = 1.83058842, grad/param norm = 1.1011e-01, time/batch = 0.1790s	
313/10550 (epoch 1.483), train_loss = 1.84568823, grad/param norm = 1.0804e-01, time/batch = 0.1795s	
314/10550 (epoch 1.488), train_loss = 1.85953479, grad/param norm = 1.2748e-01, time/batch = 0.1795s	
315/10550 (epoch 1.493), train_loss = 1.85013806, grad/param norm = 1.5300e-01, time/batch = 0.1794s	
316/10550 (epoch 1.498), train_loss = 1.85702263, grad/param norm = 1.5713e-01, time/batch = 0.1795s	
317/10550 (epoch 1.502), train_loss = 1.90625642, grad/param norm = 1.7606e-01, time/batch = 0.1795s	
318/10550 (epoch 1.507), train_loss = 1.84722537, grad/param norm = 1.6277e-01, time/batch = 0.1789s	
319/10550 (epoch 1.512), train_loss = 1.83687559, grad/param norm = 1.4631e-01, time/batch = 0.1794s	
320/10550 (epoch 1.517), train_loss = 1.89865837, grad/param norm = 1.3152e-01, time/batch = 0.1802s	
321/10550 (epoch 1.521), train_loss = 1.81225387, grad/param norm = 1.1635e-01, time/batch = 0.1816s	
322/10550 (epoch 1.526), train_loss = 1.75584095, grad/param norm = 9.2300e-02, time/batch = 0.1792s	
323/10550 (epoch 1.531), train_loss = 1.81157341, grad/param norm = 9.2543e-02, time/batch = 0.1789s	
324/10550 (epoch 1.536), train_loss = 1.82226220, grad/param norm = 8.6881e-02, time/batch = 0.1796s	
325/10550 (epoch 1.540), train_loss = 1.82724998, grad/param norm = 8.6956e-02, time/batch = 0.1795s	
326/10550 (epoch 1.545), train_loss = 1.82300584, grad/param norm = 8.6627e-02, time/batch = 0.1793s	
327/10550 (epoch 1.550), train_loss = 1.88199365, grad/param norm = 1.0307e-01, time/batch = 0.1799s	
328/10550 (epoch 1.555), train_loss = 1.80050297, grad/param norm = 1.1237e-01, time/batch = 0.1790s	
329/10550 (epoch 1.559), train_loss = 1.88498464, grad/param norm = 1.2453e-01, time/batch = 0.1795s	
330/10550 (epoch 1.564), train_loss = 1.80106954, grad/param norm = 1.1653e-01, time/batch = 0.1797s	
331/10550 (epoch 1.569), train_loss = 1.78906745, grad/param norm = 1.1077e-01, time/batch = 0.1812s	
332/10550 (epoch 1.573), train_loss = 1.82009136, grad/param norm = 1.3463e-01, time/batch = 0.1794s	
333/10550 (epoch 1.578), train_loss = 1.79930885, grad/param norm = 1.4630e-01, time/batch = 0.1791s	
334/10550 (epoch 1.583), train_loss = 1.81523812, grad/param norm = 1.3014e-01, time/batch = 0.1797s	
335/10550 (epoch 1.588), train_loss = 1.77051480, grad/param norm = 1.0324e-01, time/batch = 0.1795s	
336/10550 (epoch 1.592), train_loss = 1.81327673, grad/param norm = 8.9770e-02, time/batch = 0.1794s	
337/10550 (epoch 1.597), train_loss = 1.78781878, grad/param norm = 7.3916e-02, time/batch = 0.1824s	
338/10550 (epoch 1.602), train_loss = 1.80390102, grad/param norm = 7.6796e-02, time/batch = 0.1794s	
339/10550 (epoch 1.607), train_loss = 1.81018998, grad/param norm = 8.7728e-02, time/batch = 0.1795s	
340/10550 (epoch 1.611), train_loss = 1.84467945, grad/param norm = 9.8024e-02, time/batch = 0.1802s	
341/10550 (epoch 1.616), train_loss = 1.77091401, grad/param norm = 1.2203e-01, time/batch = 0.1814s	
342/10550 (epoch 1.621), train_loss = 1.76495498, grad/param norm = 1.2831e-01, time/batch = 0.1793s	
343/10550 (epoch 1.626), train_loss = 1.79600526, grad/param norm = 1.6772e-01, time/batch = 0.1791s	
344/10550 (epoch 1.630), train_loss = 1.86563254, grad/param norm = 1.3190e-01, time/batch = 0.1796s	
345/10550 (epoch 1.635), train_loss = 1.84830623, grad/param norm = 1.5471e-01, time/batch = 0.1793s	
346/10550 (epoch 1.640), train_loss = 1.83616554, grad/param norm = 1.6294e-01, time/batch = 0.1792s	
347/10550 (epoch 1.645), train_loss = 1.79026546, grad/param norm = 1.4534e-01, time/batch = 0.1791s	
348/10550 (epoch 1.649), train_loss = 1.81009400, grad/param norm = 1.2686e-01, time/batch = 0.1789s	
349/10550 (epoch 1.654), train_loss = 1.82731275, grad/param norm = 1.0468e-01, time/batch = 0.1793s	
350/10550 (epoch 1.659), train_loss = 1.76968418, grad/param norm = 8.3499e-02, time/batch = 0.1799s	
351/10550 (epoch 1.664), train_loss = 1.77661360, grad/param norm = 8.7184e-02, time/batch = 0.1810s	
352/10550 (epoch 1.668), train_loss = 1.79488982, grad/param norm = 9.1294e-02, time/batch = 0.1793s	
353/10550 (epoch 1.673), train_loss = 1.80096883, grad/param norm = 1.0135e-01, time/batch = 0.1798s	
354/10550 (epoch 1.678), train_loss = 1.76793267, grad/param norm = 1.0340e-01, time/batch = 0.1794s	
355/10550 (epoch 1.682), train_loss = 1.74000257, grad/param norm = 9.6372e-02, time/batch = 0.1795s	
356/10550 (epoch 1.687), train_loss = 1.74429401, grad/param norm = 9.3467e-02, time/batch = 0.1794s	
357/10550 (epoch 1.692), train_loss = 1.75781858, grad/param norm = 9.1171e-02, time/batch = 0.1792s	
358/10550 (epoch 1.697), train_loss = 1.75273743, grad/param norm = 9.7262e-02, time/batch = 0.1787s	
359/10550 (epoch 1.701), train_loss = 1.81768430, grad/param norm = 1.0902e-01, time/batch = 0.1796s	
360/10550 (epoch 1.706), train_loss = 1.76516921, grad/param norm = 1.2311e-01, time/batch = 0.1799s	
361/10550 (epoch 1.711), train_loss = 1.79640856, grad/param norm = 1.2269e-01, time/batch = 0.1814s	
362/10550 (epoch 1.716), train_loss = 1.74979968, grad/param norm = 1.1231e-01, time/batch = 0.1790s	
363/10550 (epoch 1.720), train_loss = 1.76515766, grad/param norm = 9.4742e-02, time/batch = 0.1791s	
364/10550 (epoch 1.725), train_loss = 1.74159589, grad/param norm = 8.6810e-02, time/batch = 0.1791s	
365/10550 (epoch 1.730), train_loss = 1.76017638, grad/param norm = 8.9225e-02, time/batch = 0.1793s	
366/10550 (epoch 1.735), train_loss = 1.74665700, grad/param norm = 9.8071e-02, time/batch = 0.1788s	
367/10550 (epoch 1.739), train_loss = 1.75751764, grad/param norm = 1.1301e-01, time/batch = 0.1790s	
368/10550 (epoch 1.744), train_loss = 1.74778607, grad/param norm = 1.0455e-01, time/batch = 0.1789s	
369/10550 (epoch 1.749), train_loss = 1.76469020, grad/param norm = 9.4246e-02, time/batch = 0.1795s	
370/10550 (epoch 1.754), train_loss = 1.75812287, grad/param norm = 1.0286e-01, time/batch = 0.1798s	
371/10550 (epoch 1.758), train_loss = 1.78927578, grad/param norm = 1.0666e-01, time/batch = 0.1816s	
372/10550 (epoch 1.763), train_loss = 1.75400900, grad/param norm = 1.0851e-01, time/batch = 0.1784s	
373/10550 (epoch 1.768), train_loss = 1.82314104, grad/param norm = 9.7805e-02, time/batch = 0.1791s	
374/10550 (epoch 1.773), train_loss = 1.78750817, grad/param norm = 8.7555e-02, time/batch = 0.1791s	
375/10550 (epoch 1.777), train_loss = 1.73449839, grad/param norm = 9.0471e-02, time/batch = 0.1796s	
376/10550 (epoch 1.782), train_loss = 1.77187026, grad/param norm = 1.0492e-01, time/batch = 0.1791s	
377/10550 (epoch 1.787), train_loss = 1.78996822, grad/param norm = 1.2432e-01, time/batch = 0.1791s	
378/10550 (epoch 1.791), train_loss = 1.73151471, grad/param norm = 1.2747e-01, time/batch = 0.1794s	
379/10550 (epoch 1.796), train_loss = 1.70991627, grad/param norm = 1.1579e-01, time/batch = 0.1795s	
380/10550 (epoch 1.801), train_loss = 1.75968966, grad/param norm = 1.0312e-01, time/batch = 0.1795s	
381/10550 (epoch 1.806), train_loss = 1.76250543, grad/param norm = 9.2365e-02, time/batch = 0.1824s	
382/10550 (epoch 1.810), train_loss = 1.76324263, grad/param norm = 7.9092e-02, time/batch = 0.1819s	
383/10550 (epoch 1.815), train_loss = 1.71514016, grad/param norm = 7.4477e-02, time/batch = 0.1795s	
384/10550 (epoch 1.820), train_loss = 1.73834717, grad/param norm = 7.7771e-02, time/batch = 0.1794s	
385/10550 (epoch 1.825), train_loss = 1.68220486, grad/param norm = 8.2207e-02, time/batch = 0.1792s	
386/10550 (epoch 1.829), train_loss = 1.68807811, grad/param norm = 8.0474e-02, time/batch = 0.1795s	
387/10550 (epoch 1.834), train_loss = 1.73153633, grad/param norm = 9.0454e-02, time/batch = 0.1798s	
388/10550 (epoch 1.839), train_loss = 1.71716186, grad/param norm = 1.0485e-01, time/batch = 0.1793s	
389/10550 (epoch 1.844), train_loss = 1.73393381, grad/param norm = 9.4696e-02, time/batch = 0.1796s	
390/10550 (epoch 1.848), train_loss = 1.69293449, grad/param norm = 8.4715e-02, time/batch = 0.1791s	
391/10550 (epoch 1.853), train_loss = 1.71487395, grad/param norm = 8.0620e-02, time/batch = 0.1815s	
392/10550 (epoch 1.858), train_loss = 1.71452601, grad/param norm = 9.1012e-02, time/batch = 0.1792s	
393/10550 (epoch 1.863), train_loss = 1.71495350, grad/param norm = 9.7388e-02, time/batch = 0.1792s	
394/10550 (epoch 1.867), train_loss = 1.73379423, grad/param norm = 1.0557e-01, time/batch = 0.1793s	
395/10550 (epoch 1.872), train_loss = 1.75409928, grad/param norm = 1.2288e-01, time/batch = 0.1793s	
396/10550 (epoch 1.877), train_loss = 1.68722514, grad/param norm = 1.3379e-01, time/batch = 0.1794s	
397/10550 (epoch 1.882), train_loss = 1.74290203, grad/param norm = 1.3896e-01, time/batch = 0.1793s	
398/10550 (epoch 1.886), train_loss = 1.73990086, grad/param norm = 1.3539e-01, time/batch = 0.1790s	
399/10550 (epoch 1.891), train_loss = 1.75806550, grad/param norm = 1.2117e-01, time/batch = 0.1796s	
400/10550 (epoch 1.896), train_loss = 1.72189610, grad/param norm = 1.3213e-01, time/batch = 0.1795s	
401/10550 (epoch 1.900), train_loss = 1.70485057, grad/param norm = 1.2397e-01, time/batch = 0.1813s	
402/10550 (epoch 1.905), train_loss = 1.70709095, grad/param norm = 1.1332e-01, time/batch = 0.1792s	
403/10550 (epoch 1.910), train_loss = 1.65624151, grad/param norm = 8.6660e-02, time/batch = 0.1794s	
404/10550 (epoch 1.915), train_loss = 1.67852904, grad/param norm = 7.4947e-02, time/batch = 0.1796s	
405/10550 (epoch 1.919), train_loss = 1.66369323, grad/param norm = 6.7304e-02, time/batch = 0.1793s	
406/10550 (epoch 1.924), train_loss = 1.65505667, grad/param norm = 6.7840e-02, time/batch = 0.1790s	
407/10550 (epoch 1.929), train_loss = 1.63970182, grad/param norm = 9.1182e-02, time/batch = 0.1794s	
408/10550 (epoch 1.934), train_loss = 1.68812740, grad/param norm = 9.5115e-02, time/batch = 0.1787s	
409/10550 (epoch 1.938), train_loss = 1.70224067, grad/param norm = 8.8521e-02, time/batch = 0.1798s	
410/10550 (epoch 1.943), train_loss = 1.70952682, grad/param norm = 8.6476e-02, time/batch = 0.1799s	
411/10550 (epoch 1.948), train_loss = 1.73190350, grad/param norm = 1.0014e-01, time/batch = 0.1813s	
412/10550 (epoch 1.953), train_loss = 1.73200556, grad/param norm = 1.1164e-01, time/batch = 0.1792s	
413/10550 (epoch 1.957), train_loss = 1.69868766, grad/param norm = 1.1447e-01, time/batch = 0.1796s	
414/10550 (epoch 1.962), train_loss = 1.69154751, grad/param norm = 1.0184e-01, time/batch = 0.1794s	
415/10550 (epoch 1.967), train_loss = 1.68929312, grad/param norm = 8.8806e-02, time/batch = 0.1795s	
416/10550 (epoch 1.972), train_loss = 1.67673163, grad/param norm = 8.1332e-02, time/batch = 0.1795s	
417/10550 (epoch 1.976), train_loss = 1.69015754, grad/param norm = 8.7567e-02, time/batch = 0.1797s	
418/10550 (epoch 1.981), train_loss = 1.71030044, grad/param norm = 8.6592e-02, time/batch = 0.1786s	
419/10550 (epoch 1.986), train_loss = 1.68580344, grad/param norm = 8.2093e-02, time/batch = 0.1792s	
420/10550 (epoch 1.991), train_loss = 1.76889891, grad/param norm = 9.0754e-02, time/batch = 0.1803s	
421/10550 (epoch 1.995), train_loss = 1.67219663, grad/param norm = 8.8962e-02, time/batch = 0.1815s	
422/10550 (epoch 2.000), train_loss = 1.67634645, grad/param norm = 7.1444e-02, time/batch = 0.1791s	
423/10550 (epoch 2.005), train_loss = 1.78894886, grad/param norm = 7.5373e-02, time/batch = 0.1795s	
424/10550 (epoch 2.009), train_loss = 1.63913174, grad/param norm = 7.5578e-02, time/batch = 0.1794s	
425/10550 (epoch 2.014), train_loss = 1.64028908, grad/param norm = 8.1693e-02, time/batch = 0.1793s	
426/10550 (epoch 2.019), train_loss = 1.70200516, grad/param norm = 9.3412e-02, time/batch = 0.1789s	
427/10550 (epoch 2.024), train_loss = 1.68249404, grad/param norm = 9.6958e-02, time/batch = 0.1826s	
428/10550 (epoch 2.028), train_loss = 1.67746905, grad/param norm = 1.0241e-01, time/batch = 0.1789s	
429/10550 (epoch 2.033), train_loss = 1.69118048, grad/param norm = 9.8236e-02, time/batch = 0.1797s	
430/10550 (epoch 2.038), train_loss = 1.69020432, grad/param norm = 7.5811e-02, time/batch = 0.1796s	
431/10550 (epoch 2.043), train_loss = 1.63886790, grad/param norm = 8.4466e-02, time/batch = 0.1813s	
432/10550 (epoch 2.047), train_loss = 1.62393670, grad/param norm = 8.4772e-02, time/batch = 0.1791s	
433/10550 (epoch 2.052), train_loss = 1.70787181, grad/param norm = 8.5171e-02, time/batch = 0.1793s	
434/10550 (epoch 2.057), train_loss = 1.65191580, grad/param norm = 9.9198e-02, time/batch = 0.1789s	
435/10550 (epoch 2.062), train_loss = 1.67187429, grad/param norm = 1.0283e-01, time/batch = 0.1794s	
436/10550 (epoch 2.066), train_loss = 1.64572409, grad/param norm = 9.2534e-02, time/batch = 0.1794s	
437/10550 (epoch 2.071), train_loss = 1.62280334, grad/param norm = 9.6980e-02, time/batch = 0.1796s	
438/10550 (epoch 2.076), train_loss = 1.64074635, grad/param norm = 9.7278e-02, time/batch = 0.1792s	
439/10550 (epoch 2.081), train_loss = 1.68808875, grad/param norm = 9.9686e-02, time/batch = 0.1790s	
440/10550 (epoch 2.085), train_loss = 1.64533553, grad/param norm = 8.2094e-02, time/batch = 0.1799s	
441/10550 (epoch 2.090), train_loss = 1.61195173, grad/param norm = 6.9039e-02, time/batch = 0.1817s	
442/10550 (epoch 2.095), train_loss = 1.61448365, grad/param norm = 6.4742e-02, time/batch = 0.1792s	
443/10550 (epoch 2.100), train_loss = 1.58808231, grad/param norm = 6.8734e-02, time/batch = 0.1793s	
444/10550 (epoch 2.104), train_loss = 1.59356680, grad/param norm = 7.2859e-02, time/batch = 0.1791s	
445/10550 (epoch 2.109), train_loss = 1.59219980, grad/param norm = 8.0982e-02, time/batch = 0.1797s	
446/10550 (epoch 2.114), train_loss = 1.62827700, grad/param norm = 8.9808e-02, time/batch = 0.1792s	
447/10550 (epoch 2.118), train_loss = 1.59526314, grad/param norm = 8.8200e-02, time/batch = 0.1795s	
448/10550 (epoch 2.123), train_loss = 1.64634233, grad/param norm = 9.3137e-02, time/batch = 0.1792s	
449/10550 (epoch 2.128), train_loss = 1.58733554, grad/param norm = 9.5702e-02, time/batch = 0.1796s	
450/10550 (epoch 2.133), train_loss = 1.62059482, grad/param norm = 8.9549e-02, time/batch = 0.1800s	
451/10550 (epoch 2.137), train_loss = 1.60226171, grad/param norm = 9.1438e-02, time/batch = 0.1815s	
452/10550 (epoch 2.142), train_loss = 1.64073518, grad/param norm = 7.9620e-02, time/batch = 0.1789s	
453/10550 (epoch 2.147), train_loss = 1.61235353, grad/param norm = 8.3358e-02, time/batch = 0.1794s	
454/10550 (epoch 2.152), train_loss = 1.63365577, grad/param norm = 7.6808e-02, time/batch = 0.1797s	
455/10550 (epoch 2.156), train_loss = 1.60939841, grad/param norm = 7.2479e-02, time/batch = 0.1795s	
456/10550 (epoch 2.161), train_loss = 1.59461701, grad/param norm = 8.4633e-02, time/batch = 0.1797s	
457/10550 (epoch 2.166), train_loss = 1.63819405, grad/param norm = 9.6924e-02, time/batch = 0.1795s	
458/10550 (epoch 2.171), train_loss = 1.61814729, grad/param norm = 9.5742e-02, time/batch = 0.1795s	
459/10550 (epoch 2.175), train_loss = 1.66552270, grad/param norm = 7.8290e-02, time/batch = 0.1797s	
460/10550 (epoch 2.180), train_loss = 1.62615760, grad/param norm = 7.5213e-02, time/batch = 0.1795s	
461/10550 (epoch 2.185), train_loss = 1.60098442, grad/param norm = 6.3188e-02, time/batch = 0.1812s	
462/10550 (epoch 2.190), train_loss = 1.59165029, grad/param norm = 6.4381e-02, time/batch = 0.1786s	
463/10550 (epoch 2.194), train_loss = 1.62684867, grad/param norm = 7.0954e-02, time/batch = 0.1788s	
464/10550 (epoch 2.199), train_loss = 1.60840352, grad/param norm = 7.8362e-02, time/batch = 0.1797s	
465/10550 (epoch 2.204), train_loss = 1.63023366, grad/param norm = 8.3950e-02, time/batch = 0.1798s	
466/10550 (epoch 2.209), train_loss = 1.61977679, grad/param norm = 8.8494e-02, time/batch = 0.1792s	
467/10550 (epoch 2.213), train_loss = 1.63266783, grad/param norm = 8.8478e-02, time/batch = 0.1799s	
468/10550 (epoch 2.218), train_loss = 1.60667304, grad/param norm = 9.9406e-02, time/batch = 0.1790s	
469/10550 (epoch 2.223), train_loss = 1.59178505, grad/param norm = 1.1189e-01, time/batch = 0.1797s	
470/10550 (epoch 2.227), train_loss = 1.59330603, grad/param norm = 9.9592e-02, time/batch = 0.1797s	
471/10550 (epoch 2.232), train_loss = 1.60835893, grad/param norm = 8.2205e-02, time/batch = 0.1817s	
472/10550 (epoch 2.237), train_loss = 1.54357204, grad/param norm = 7.2061e-02, time/batch = 0.1826s	
473/10550 (epoch 2.242), train_loss = 1.60049397, grad/param norm = 6.5084e-02, time/batch = 0.1795s	
474/10550 (epoch 2.246), train_loss = 1.56691987, grad/param norm = 6.9072e-02, time/batch = 0.1791s	
475/10550 (epoch 2.251), train_loss = 1.60321473, grad/param norm = 8.8195e-02, time/batch = 0.1797s	
476/10550 (epoch 2.256), train_loss = 1.62378060, grad/param norm = 8.1922e-02, time/batch = 0.1793s	
477/10550 (epoch 2.261), train_loss = 1.59313557, grad/param norm = 6.8502e-02, time/batch = 0.1794s	
478/10550 (epoch 2.265), train_loss = 1.56843802, grad/param norm = 6.1384e-02, time/batch = 0.1788s	
479/10550 (epoch 2.270), train_loss = 1.56529341, grad/param norm = 6.2080e-02, time/batch = 0.1792s	
480/10550 (epoch 2.275), train_loss = 1.59624618, grad/param norm = 7.7186e-02, time/batch = 0.1796s	
481/10550 (epoch 2.280), train_loss = 1.62725027, grad/param norm = 9.1342e-02, time/batch = 0.1811s	
482/10550 (epoch 2.284), train_loss = 1.59696990, grad/param norm = 1.0119e-01, time/batch = 0.1792s	
483/10550 (epoch 2.289), train_loss = 1.61862220, grad/param norm = 1.0438e-01, time/batch = 0.1794s	
484/10550 (epoch 2.294), train_loss = 1.61837914, grad/param norm = 1.0249e-01, time/batch = 0.1795s	
485/10550 (epoch 2.299), train_loss = 1.57480379, grad/param norm = 8.1626e-02, time/batch = 0.1790s	
486/10550 (epoch 2.303), train_loss = 1.59273158, grad/param norm = 6.7423e-02, time/batch = 0.1790s	
487/10550 (epoch 2.308), train_loss = 1.56768068, grad/param norm = 5.8756e-02, time/batch = 0.1791s	
488/10550 (epoch 2.313), train_loss = 1.58887758, grad/param norm = 5.4744e-02, time/batch = 0.1790s	
489/10550 (epoch 2.318), train_loss = 1.55416522, grad/param norm = 5.4227e-02, time/batch = 0.1794s	
490/10550 (epoch 2.322), train_loss = 1.58129885, grad/param norm = 6.2042e-02, time/batch = 0.1802s	
491/10550 (epoch 2.327), train_loss = 1.57953703, grad/param norm = 7.6748e-02, time/batch = 0.1815s	
492/10550 (epoch 2.332), train_loss = 1.59666129, grad/param norm = 8.9592e-02, time/batch = 0.1784s	
493/10550 (epoch 2.336), train_loss = 1.59956302, grad/param norm = 8.3152e-02, time/batch = 0.1790s	
494/10550 (epoch 2.341), train_loss = 1.55780450, grad/param norm = 8.0250e-02, time/batch = 0.1795s	
495/10550 (epoch 2.346), train_loss = 1.60309416, grad/param norm = 8.3340e-02, time/batch = 0.1798s	
496/10550 (epoch 2.351), train_loss = 1.58958450, grad/param norm = 8.4914e-02, time/batch = 0.1794s	
497/10550 (epoch 2.355), train_loss = 1.55557318, grad/param norm = 8.4979e-02, time/batch = 0.1792s	
498/10550 (epoch 2.360), train_loss = 1.61460660, grad/param norm = 7.9653e-02, time/batch = 0.1792s	
499/10550 (epoch 2.365), train_loss = 1.56330214, grad/param norm = 7.6020e-02, time/batch = 0.1796s	
500/10550 (epoch 2.370), train_loss = 1.55788208, grad/param norm = 6.8882e-02, time/batch = 0.1801s	
501/10550 (epoch 2.374), train_loss = 1.57478474, grad/param norm = 6.8052e-02, time/batch = 0.1811s	
502/10550 (epoch 2.379), train_loss = 1.55672896, grad/param norm = 6.7054e-02, time/batch = 0.1792s	
503/10550 (epoch 2.384), train_loss = 1.52694205, grad/param norm = 7.0223e-02, time/batch = 0.1796s	
504/10550 (epoch 2.389), train_loss = 1.52955025, grad/param norm = 7.6574e-02, time/batch = 0.1795s	
505/10550 (epoch 2.393), train_loss = 1.55630744, grad/param norm = 7.7691e-02, time/batch = 0.1794s	
506/10550 (epoch 2.398), train_loss = 1.53087149, grad/param norm = 7.6614e-02, time/batch = 0.1791s	
507/10550 (epoch 2.403), train_loss = 1.57590790, grad/param norm = 8.1858e-02, time/batch = 0.1795s	
508/10550 (epoch 2.408), train_loss = 1.61025949, grad/param norm = 9.5475e-02, time/batch = 0.1790s	
509/10550 (epoch 2.412), train_loss = 1.56286646, grad/param norm = 8.9779e-02, time/batch = 0.1795s	
510/10550 (epoch 2.417), train_loss = 1.52973266, grad/param norm = 8.0183e-02, time/batch = 0.1805s	
511/10550 (epoch 2.422), train_loss = 1.61882840, grad/param norm = 8.0901e-02, time/batch = 0.1812s	
512/10550 (epoch 2.427), train_loss = 1.57590608, grad/param norm = 7.3444e-02, time/batch = 0.1789s	
513/10550 (epoch 2.431), train_loss = 1.57027512, grad/param norm = 8.1628e-02, time/batch = 0.1790s	
514/10550 (epoch 2.436), train_loss = 1.52317479, grad/param norm = 7.9884e-02, time/batch = 0.1795s	
515/10550 (epoch 2.441), train_loss = 1.57086686, grad/param norm = 8.2167e-02, time/batch = 0.1796s	
516/10550 (epoch 2.445), train_loss = 1.55727304, grad/param norm = 9.1496e-02, time/batch = 0.1791s	
517/10550 (epoch 2.450), train_loss = 1.56716686, grad/param norm = 9.3922e-02, time/batch = 0.1806s	
518/10550 (epoch 2.455), train_loss = 1.57026773, grad/param norm = 8.8705e-02, time/batch = 0.1794s	
519/10550 (epoch 2.460), train_loss = 1.51422263, grad/param norm = 8.0452e-02, time/batch = 0.1801s	
520/10550 (epoch 2.464), train_loss = 1.52395592, grad/param norm = 8.0393e-02, time/batch = 0.1801s	
521/10550 (epoch 2.469), train_loss = 1.50239560, grad/param norm = 8.1189e-02, time/batch = 0.1813s	
522/10550 (epoch 2.474), train_loss = 1.55857319, grad/param norm = 8.3124e-02, time/batch = 0.1786s	
523/10550 (epoch 2.479), train_loss = 1.50001239, grad/param norm = 7.6068e-02, time/batch = 0.1793s	
524/10550 (epoch 2.483), train_loss = 1.51891107, grad/param norm = 7.1060e-02, time/batch = 0.1790s	
525/10550 (epoch 2.488), train_loss = 1.53041713, grad/param norm = 6.5984e-02, time/batch = 0.1795s	
526/10550 (epoch 2.493), train_loss = 1.51638847, grad/param norm = 7.0995e-02, time/batch = 0.1795s	
527/10550 (epoch 2.498), train_loss = 1.52585500, grad/param norm = 6.7429e-02, time/batch = 0.1794s	
528/10550 (epoch 2.502), train_loss = 1.54569227, grad/param norm = 6.5984e-02, time/batch = 0.1785s	
529/10550 (epoch 2.507), train_loss = 1.49260146, grad/param norm = 6.7777e-02, time/batch = 0.1797s	
530/10550 (epoch 2.512), train_loss = 1.49432012, grad/param norm = 6.3649e-02, time/batch = 0.1802s	
531/10550 (epoch 2.517), train_loss = 1.56173072, grad/param norm = 6.5290e-02, time/batch = 0.1815s	
532/10550 (epoch 2.521), train_loss = 1.48420579, grad/param norm = 7.1169e-02, time/batch = 0.1795s	
533/10550 (epoch 2.526), train_loss = 1.43823493, grad/param norm = 6.9216e-02, time/batch = 0.1798s	
534/10550 (epoch 2.531), train_loss = 1.50221587, grad/param norm = 6.5674e-02, time/batch = 0.1794s	
535/10550 (epoch 2.536), train_loss = 1.52689204, grad/param norm = 6.1210e-02, time/batch = 0.1793s	
536/10550 (epoch 2.540), train_loss = 1.53831204, grad/param norm = 6.4734e-02, time/batch = 0.1790s	
537/10550 (epoch 2.545), train_loss = 1.52701933, grad/param norm = 6.9061e-02, time/batch = 0.1795s	
538/10550 (epoch 2.550), train_loss = 1.59044616, grad/param norm = 7.6276e-02, time/batch = 0.1789s	
539/10550 (epoch 2.555), train_loss = 1.52521532, grad/param norm = 8.0702e-02, time/batch = 0.1799s	
540/10550 (epoch 2.559), train_loss = 1.59229384, grad/param norm = 8.6851e-02, time/batch = 0.1796s	
541/10550 (epoch 2.564), train_loss = 1.51140701, grad/param norm = 7.9375e-02, time/batch = 0.1817s	
542/10550 (epoch 2.569), train_loss = 1.51861808, grad/param norm = 8.0018e-02, time/batch = 0.1790s	
543/10550 (epoch 2.573), train_loss = 1.52874931, grad/param norm = 7.5818e-02, time/batch = 0.1793s	
544/10550 (epoch 2.578), train_loss = 1.50725568, grad/param norm = 6.7777e-02, time/batch = 0.1796s	
545/10550 (epoch 2.583), train_loss = 1.50097736, grad/param norm = 6.2665e-02, time/batch = 0.1798s	
546/10550 (epoch 2.588), train_loss = 1.48241912, grad/param norm = 6.9358e-02, time/batch = 0.1793s	
547/10550 (epoch 2.592), train_loss = 1.56550412, grad/param norm = 8.2292e-02, time/batch = 0.1798s	
548/10550 (epoch 2.597), train_loss = 1.54496439, grad/param norm = 8.7798e-02, time/batch = 0.1787s	
549/10550 (epoch 2.602), train_loss = 1.56235542, grad/param norm = 9.3887e-02, time/batch = 0.1794s	
550/10550 (epoch 2.607), train_loss = 1.54273131, grad/param norm = 8.1198e-02, time/batch = 0.1796s	
551/10550 (epoch 2.611), train_loss = 1.56382879, grad/param norm = 8.5178e-02, time/batch = 0.1818s	
552/10550 (epoch 2.616), train_loss = 1.49315682, grad/param norm = 8.3970e-02, time/batch = 0.1787s	
553/10550 (epoch 2.621), train_loss = 1.46694059, grad/param norm = 7.1988e-02, time/batch = 0.1792s	
554/10550 (epoch 2.626), train_loss = 1.49034547, grad/param norm = 5.8222e-02, time/batch = 0.1793s	
555/10550 (epoch 2.630), train_loss = 1.53333176, grad/param norm = 5.8024e-02, time/batch = 0.1793s	
556/10550 (epoch 2.635), train_loss = 1.52479797, grad/param norm = 6.2695e-02, time/batch = 0.1795s	
557/10550 (epoch 2.640), train_loss = 1.53670600, grad/param norm = 7.1074e-02, time/batch = 0.1795s	
558/10550 (epoch 2.645), train_loss = 1.51609272, grad/param norm = 6.5378e-02, time/batch = 0.1789s	
559/10550 (epoch 2.649), train_loss = 1.52456043, grad/param norm = 5.9969e-02, time/batch = 0.1796s	
560/10550 (epoch 2.654), train_loss = 1.55056314, grad/param norm = 7.1469e-02, time/batch = 0.1800s	
561/10550 (epoch 2.659), train_loss = 1.53695559, grad/param norm = 8.3685e-02, time/batch = 0.1815s	
562/10550 (epoch 2.664), train_loss = 1.52505891, grad/param norm = 7.9457e-02, time/batch = 0.1798s	
563/10550 (epoch 2.668), train_loss = 1.52864649, grad/param norm = 7.0713e-02, time/batch = 0.1798s	
564/10550 (epoch 2.673), train_loss = 1.54215050, grad/param norm = 6.2704e-02, time/batch = 0.1795s	
565/10550 (epoch 2.678), train_loss = 1.46734722, grad/param norm = 6.0962e-02, time/batch = 0.1795s	
566/10550 (epoch 2.682), train_loss = 1.45952002, grad/param norm = 6.4415e-02, time/batch = 0.1791s	
567/10550 (epoch 2.687), train_loss = 1.47145415, grad/param norm = 6.2093e-02, time/batch = 0.1796s	
568/10550 (epoch 2.692), train_loss = 1.50520332, grad/param norm = 6.0903e-02, time/batch = 0.1790s	
569/10550 (epoch 2.697), train_loss = 1.48406730, grad/param norm = 6.2150e-02, time/batch = 0.1797s	
570/10550 (epoch 2.701), train_loss = 1.53719659, grad/param norm = 6.4209e-02, time/batch = 0.1799s	
571/10550 (epoch 2.706), train_loss = 1.49687212, grad/param norm = 6.8286e-02, time/batch = 0.1814s	
572/10550 (epoch 2.711), train_loss = 1.51696358, grad/param norm = 6.5088e-02, time/batch = 0.1790s	
573/10550 (epoch 2.716), train_loss = 1.49893613, grad/param norm = 6.9627e-02, time/batch = 0.1789s	
574/10550 (epoch 2.720), train_loss = 1.51365045, grad/param norm = 7.5011e-02, time/batch = 0.1794s	
575/10550 (epoch 2.725), train_loss = 1.48769881, grad/param norm = 8.1047e-02, time/batch = 0.1797s	
576/10550 (epoch 2.730), train_loss = 1.52040120, grad/param norm = 7.7147e-02, time/batch = 0.1796s	
577/10550 (epoch 2.735), train_loss = 1.49377136, grad/param norm = 7.4320e-02, time/batch = 0.1792s	
578/10550 (epoch 2.739), train_loss = 1.49008121, grad/param norm = 6.8361e-02, time/batch = 0.1794s	
579/10550 (epoch 2.744), train_loss = 1.47332672, grad/param norm = 6.6563e-02, time/batch = 0.1797s	
580/10550 (epoch 2.749), train_loss = 1.51236249, grad/param norm = 6.0108e-02, time/batch = 0.1798s	
581/10550 (epoch 2.754), train_loss = 1.50359684, grad/param norm = 6.3240e-02, time/batch = 0.1813s	
582/10550 (epoch 2.758), train_loss = 1.51970250, grad/param norm = 6.9834e-02, time/batch = 0.1791s	
583/10550 (epoch 2.763), train_loss = 1.51048160, grad/param norm = 7.4393e-02, time/batch = 0.1793s	
584/10550 (epoch 2.768), train_loss = 1.55368545, grad/param norm = 7.1364e-02, time/batch = 0.1791s	
585/10550 (epoch 2.773), train_loss = 1.55880376, grad/param norm = 6.5608e-02, time/batch = 0.1796s	
586/10550 (epoch 2.777), train_loss = 1.51209288, grad/param norm = 6.5751e-02, time/batch = 0.1791s	
587/10550 (epoch 2.782), train_loss = 1.54229064, grad/param norm = 6.9230e-02, time/batch = 0.1794s	
588/10550 (epoch 2.787), train_loss = 1.51489188, grad/param norm = 6.8394e-02, time/batch = 0.1788s	
589/10550 (epoch 2.791), train_loss = 1.46028610, grad/param norm = 5.8181e-02, time/batch = 0.1793s	
590/10550 (epoch 2.796), train_loss = 1.45168269, grad/param norm = 5.6323e-02, time/batch = 0.1795s	
591/10550 (epoch 2.801), train_loss = 1.49515892, grad/param norm = 6.8441e-02, time/batch = 0.1816s	
592/10550 (epoch 2.806), train_loss = 1.52529011, grad/param norm = 7.3331e-02, time/batch = 0.1793s	
593/10550 (epoch 2.810), train_loss = 1.52730175, grad/param norm = 7.1049e-02, time/batch = 0.1794s	
594/10550 (epoch 2.815), train_loss = 1.47784477, grad/param norm = 5.9397e-02, time/batch = 0.1792s	
595/10550 (epoch 2.820), train_loss = 1.49998134, grad/param norm = 5.7305e-02, time/batch = 0.1791s	
596/10550 (epoch 2.825), train_loss = 1.45265035, grad/param norm = 6.1537e-02, time/batch = 0.1794s	
597/10550 (epoch 2.829), train_loss = 1.46245126, grad/param norm = 6.5306e-02, time/batch = 0.1791s	
598/10550 (epoch 2.834), train_loss = 1.51720640, grad/param norm = 7.5957e-02, time/batch = 0.1793s	
599/10550 (epoch 2.839), train_loss = 1.48198426, grad/param norm = 7.8456e-02, time/batch = 0.1797s	
600/10550 (epoch 2.844), train_loss = 1.50927844, grad/param norm = 7.9316e-02, time/batch = 0.1799s	
601/10550 (epoch 2.848), train_loss = 1.47431755, grad/param norm = 8.6892e-02, time/batch = 0.1815s	
602/10550 (epoch 2.853), train_loss = 1.48876947, grad/param norm = 7.0139e-02, time/batch = 0.1792s	
603/10550 (epoch 2.858), train_loss = 1.49533200, grad/param norm = 5.7682e-02, time/batch = 0.1788s	
604/10550 (epoch 2.863), train_loss = 1.46433313, grad/param norm = 6.3428e-02, time/batch = 0.1791s	
605/10550 (epoch 2.867), train_loss = 1.49873985, grad/param norm = 6.2606e-02, time/batch = 0.1798s	
606/10550 (epoch 2.872), train_loss = 1.49248350, grad/param norm = 6.1692e-02, time/batch = 0.1790s	
607/10550 (epoch 2.877), train_loss = 1.42867842, grad/param norm = 6.0704e-02, time/batch = 0.1795s	
608/10550 (epoch 2.882), train_loss = 1.47600954, grad/param norm = 5.9263e-02, time/batch = 0.1810s	
609/10550 (epoch 2.886), train_loss = 1.49080195, grad/param norm = 5.7878e-02, time/batch = 0.1799s	
610/10550 (epoch 2.891), train_loss = 1.49191286, grad/param norm = 5.5891e-02, time/batch = 0.1799s	
611/10550 (epoch 2.896), train_loss = 1.47033257, grad/param norm = 6.0429e-02, time/batch = 0.1822s	
612/10550 (epoch 2.900), train_loss = 1.44360060, grad/param norm = 5.9583e-02, time/batch = 0.1791s	
613/10550 (epoch 2.905), train_loss = 1.45141696, grad/param norm = 6.2433e-02, time/batch = 0.1792s	
614/10550 (epoch 2.910), train_loss = 1.41703287, grad/param norm = 6.0508e-02, time/batch = 0.1794s	
615/10550 (epoch 2.915), train_loss = 1.46290609, grad/param norm = 5.7858e-02, time/batch = 0.1793s	
616/10550 (epoch 2.919), train_loss = 1.46941488, grad/param norm = 5.4297e-02, time/batch = 0.1789s	
617/10550 (epoch 2.924), train_loss = 1.46005866, grad/param norm = 5.6118e-02, time/batch = 0.1795s	
618/10550 (epoch 2.929), train_loss = 1.43476113, grad/param norm = 7.1540e-02, time/batch = 0.1789s	
619/10550 (epoch 2.934), train_loss = 1.47898688, grad/param norm = 7.6368e-02, time/batch = 0.1794s	
620/10550 (epoch 2.938), train_loss = 1.48644827, grad/param norm = 8.0310e-02, time/batch = 0.1800s	
621/10550 (epoch 2.943), train_loss = 1.49858484, grad/param norm = 7.0978e-02, time/batch = 0.1816s	
622/10550 (epoch 2.948), train_loss = 1.50950268, grad/param norm = 6.2204e-02, time/batch = 0.1796s	
623/10550 (epoch 2.953), train_loss = 1.51250274, grad/param norm = 5.7016e-02, time/batch = 0.1793s	
624/10550 (epoch 2.957), train_loss = 1.47174831, grad/param norm = 6.2578e-02, time/batch = 0.1794s	
625/10550 (epoch 2.962), train_loss = 1.47389445, grad/param norm = 6.9346e-02, time/batch = 0.1793s	
626/10550 (epoch 2.967), train_loss = 1.46555420, grad/param norm = 6.8563e-02, time/batch = 0.1797s	
627/10550 (epoch 2.972), train_loss = 1.45037516, grad/param norm = 6.3880e-02, time/batch = 0.1796s	
628/10550 (epoch 2.976), train_loss = 1.47250362, grad/param norm = 5.8767e-02, time/batch = 0.1788s	
629/10550 (epoch 2.981), train_loss = 1.48885957, grad/param norm = 7.1064e-02, time/batch = 0.1795s	
630/10550 (epoch 2.986), train_loss = 1.46502099, grad/param norm = 6.5404e-02, time/batch = 0.1799s	
631/10550 (epoch 2.991), train_loss = 1.54396349, grad/param norm = 6.4171e-02, time/batch = 0.1814s	
632/10550 (epoch 2.995), train_loss = 1.45500392, grad/param norm = 5.9538e-02, time/batch = 0.1795s	
633/10550 (epoch 3.000), train_loss = 1.47190980, grad/param norm = 5.6011e-02, time/batch = 0.1791s	
634/10550 (epoch 3.005), train_loss = 1.62052799, grad/param norm = 6.0953e-02, time/batch = 0.1797s	
635/10550 (epoch 3.009), train_loss = 1.42745185, grad/param norm = 5.5721e-02, time/batch = 0.1794s	
636/10550 (epoch 3.014), train_loss = 1.44014507, grad/param norm = 5.1780e-02, time/batch = 0.1795s	
637/10550 (epoch 3.019), train_loss = 1.49113109, grad/param norm = 5.3772e-02, time/batch = 0.1798s	
638/10550 (epoch 3.024), train_loss = 1.47307735, grad/param norm = 5.0352e-02, time/batch = 0.1789s	
639/10550 (epoch 3.028), train_loss = 1.44865498, grad/param norm = 5.3434e-02, time/batch = 0.1797s	
640/10550 (epoch 3.033), train_loss = 1.48024071, grad/param norm = 5.4736e-02, time/batch = 0.1804s	
641/10550 (epoch 3.038), train_loss = 1.48296088, grad/param norm = 5.1582e-02, time/batch = 0.1816s	
642/10550 (epoch 3.043), train_loss = 1.42875946, grad/param norm = 4.6768e-02, time/batch = 0.1791s	
643/10550 (epoch 3.047), train_loss = 1.41198178, grad/param norm = 5.4117e-02, time/batch = 0.1795s	
644/10550 (epoch 3.052), train_loss = 1.50320548, grad/param norm = 6.3787e-02, time/batch = 0.1790s	
645/10550 (epoch 3.057), train_loss = 1.45081285, grad/param norm = 7.0965e-02, time/batch = 0.1794s	
646/10550 (epoch 3.062), train_loss = 1.47020144, grad/param norm = 7.1982e-02, time/batch = 0.1796s	
647/10550 (epoch 3.066), train_loss = 1.45026884, grad/param norm = 6.2427e-02, time/batch = 0.1795s	
648/10550 (epoch 3.071), train_loss = 1.42461247, grad/param norm = 6.6737e-02, time/batch = 0.1789s	
649/10550 (epoch 3.076), train_loss = 1.44640919, grad/param norm = 6.5304e-02, time/batch = 0.1799s	
650/10550 (epoch 3.081), train_loss = 1.47919801, grad/param norm = 6.8060e-02, time/batch = 0.1796s	
651/10550 (epoch 3.085), train_loss = 1.43290836, grad/param norm = 6.3969e-02, time/batch = 0.1816s	
652/10550 (epoch 3.090), train_loss = 1.43880540, grad/param norm = 6.5752e-02, time/batch = 0.1791s	
653/10550 (epoch 3.095), train_loss = 1.43477349, grad/param norm = 6.6571e-02, time/batch = 0.1808s	
654/10550 (epoch 3.100), train_loss = 1.42581238, grad/param norm = 7.3977e-02, time/batch = 0.1799s	
655/10550 (epoch 3.104), train_loss = 1.41931044, grad/param norm = 6.9599e-02, time/batch = 0.1795s	
656/10550 (epoch 3.109), train_loss = 1.41519835, grad/param norm = 6.2590e-02, time/batch = 0.1788s	
657/10550 (epoch 3.114), train_loss = 1.43534238, grad/param norm = 6.0673e-02, time/batch = 0.1797s	
658/10550 (epoch 3.118), train_loss = 1.38318714, grad/param norm = 5.3901e-02, time/batch = 0.1791s	
659/10550 (epoch 3.123), train_loss = 1.45181169, grad/param norm = 5.3484e-02, time/batch = 0.1800s	
660/10550 (epoch 3.128), train_loss = 1.39456374, grad/param norm = 5.7166e-02, time/batch = 0.1801s	
661/10550 (epoch 3.133), train_loss = 1.42343432, grad/param norm = 5.5520e-02, time/batch = 0.1809s	
662/10550 (epoch 3.137), train_loss = 1.41326957, grad/param norm = 5.4988e-02, time/batch = 0.1796s	
663/10550 (epoch 3.142), train_loss = 1.45848101, grad/param norm = 5.6297e-02, time/batch = 0.1795s	
664/10550 (epoch 3.147), train_loss = 1.42777123, grad/param norm = 5.5729e-02, time/batch = 0.1793s	
665/10550 (epoch 3.152), train_loss = 1.43611552, grad/param norm = 5.8641e-02, time/batch = 0.1793s	
666/10550 (epoch 3.156), train_loss = 1.44537555, grad/param norm = 7.1777e-02, time/batch = 0.1789s	
667/10550 (epoch 3.161), train_loss = 1.44232600, grad/param norm = 8.0609e-02, time/batch = 0.1798s	
668/10550 (epoch 3.166), train_loss = 1.48532513, grad/param norm = 7.4748e-02, time/batch = 0.1793s	
669/10550 (epoch 3.171), train_loss = 1.42858023, grad/param norm = 6.2326e-02, time/batch = 0.1799s	
670/10550 (epoch 3.175), train_loss = 1.48358287, grad/param norm = 5.5669e-02, time/batch = 0.1798s	
671/10550 (epoch 3.180), train_loss = 1.44512713, grad/param norm = 5.5487e-02, time/batch = 0.1813s	
672/10550 (epoch 3.185), train_loss = 1.44036680, grad/param norm = 5.7904e-02, time/batch = 0.1792s	
673/10550 (epoch 3.190), train_loss = 1.42688339, grad/param norm = 5.9858e-02, time/batch = 0.1792s	
674/10550 (epoch 3.194), train_loss = 1.46295542, grad/param norm = 5.7615e-02, time/batch = 0.1791s	
675/10550 (epoch 3.199), train_loss = 1.43892716, grad/param norm = 5.4720e-02, time/batch = 0.1793s	
676/10550 (epoch 3.204), train_loss = 1.44065478, grad/param norm = 5.7734e-02, time/batch = 0.1792s	
677/10550 (epoch 3.209), train_loss = 1.43955760, grad/param norm = 5.5621e-02, time/batch = 0.1792s	
678/10550 (epoch 3.213), train_loss = 1.44381436, grad/param norm = 4.9520e-02, time/batch = 0.1798s	
679/10550 (epoch 3.218), train_loss = 1.42186717, grad/param norm = 4.7233e-02, time/batch = 0.1796s	
680/10550 (epoch 3.223), train_loss = 1.38517968, grad/param norm = 4.6131e-02, time/batch = 0.1800s	
681/10550 (epoch 3.227), train_loss = 1.37922438, grad/param norm = 5.1977e-02, time/batch = 0.1811s	
682/10550 (epoch 3.232), train_loss = 1.41689442, grad/param norm = 6.1844e-02, time/batch = 0.1790s	
683/10550 (epoch 3.237), train_loss = 1.38017038, grad/param norm = 7.1750e-02, time/batch = 0.1794s	
684/10550 (epoch 3.242), train_loss = 1.46225880, grad/param norm = 7.9378e-02, time/batch = 0.1799s	
685/10550 (epoch 3.246), train_loss = 1.41507241, grad/param norm = 7.0905e-02, time/batch = 0.1792s	
686/10550 (epoch 3.251), train_loss = 1.42558849, grad/param norm = 6.1517e-02, time/batch = 0.1794s	
687/10550 (epoch 3.256), train_loss = 1.43728545, grad/param norm = 5.5396e-02, time/batch = 0.1797s	
688/10550 (epoch 3.261), train_loss = 1.40743316, grad/param norm = 5.2345e-02, time/batch = 0.1793s	
689/10550 (epoch 3.265), train_loss = 1.41670140, grad/param norm = 5.0722e-02, time/batch = 0.1798s	
690/10550 (epoch 3.270), train_loss = 1.39166527, grad/param norm = 5.3355e-02, time/batch = 0.1798s	
691/10550 (epoch 3.275), train_loss = 1.42146124, grad/param norm = 5.6224e-02, time/batch = 0.1819s	
692/10550 (epoch 3.280), train_loss = 1.43191757, grad/param norm = 5.7282e-02, time/batch = 0.1791s	
693/10550 (epoch 3.284), train_loss = 1.41030613, grad/param norm = 5.8427e-02, time/batch = 0.1791s	
694/10550 (epoch 3.289), train_loss = 1.42141618, grad/param norm = 5.5962e-02, time/batch = 0.1795s	
695/10550 (epoch 3.294), train_loss = 1.43655707, grad/param norm = 6.4961e-02, time/batch = 0.1797s	
696/10550 (epoch 3.299), train_loss = 1.41085913, grad/param norm = 6.7192e-02, time/batch = 0.1795s	
697/10550 (epoch 3.303), train_loss = 1.43950614, grad/param norm = 6.0640e-02, time/batch = 0.1800s	
698/10550 (epoch 3.308), train_loss = 1.40644694, grad/param norm = 5.5645e-02, time/batch = 0.1810s	
699/10550 (epoch 3.313), train_loss = 1.44479497, grad/param norm = 5.8055e-02, time/batch = 0.1799s	
700/10550 (epoch 3.318), train_loss = 1.41717692, grad/param norm = 6.0832e-02, time/batch = 0.1801s	
701/10550 (epoch 3.322), train_loss = 1.43247212, grad/param norm = 5.8557e-02, time/batch = 0.1816s	
702/10550 (epoch 3.327), train_loss = 1.42482262, grad/param norm = 5.3324e-02, time/batch = 0.1790s	
703/10550 (epoch 3.332), train_loss = 1.43118458, grad/param norm = 5.3097e-02, time/batch = 0.1789s	
704/10550 (epoch 3.336), train_loss = 1.42909582, grad/param norm = 5.5239e-02, time/batch = 0.1796s	
705/10550 (epoch 3.341), train_loss = 1.37376431, grad/param norm = 5.8313e-02, time/batch = 0.1790s	
706/10550 (epoch 3.346), train_loss = 1.44141545, grad/param norm = 6.0782e-02, time/batch = 0.1793s	
707/10550 (epoch 3.351), train_loss = 1.40506150, grad/param norm = 5.8946e-02, time/batch = 0.1797s	
708/10550 (epoch 3.355), train_loss = 1.38694260, grad/param norm = 5.6573e-02, time/batch = 0.1791s	
709/10550 (epoch 3.360), train_loss = 1.45683532, grad/param norm = 5.7876e-02, time/batch = 0.1802s	
710/10550 (epoch 3.365), train_loss = 1.40930034, grad/param norm = 6.2770e-02, time/batch = 0.1797s	
711/10550 (epoch 3.370), train_loss = 1.40444791, grad/param norm = 6.5611e-02, time/batch = 0.1816s	
712/10550 (epoch 3.374), train_loss = 1.42683933, grad/param norm = 6.1227e-02, time/batch = 0.1787s	
713/10550 (epoch 3.379), train_loss = 1.40865848, grad/param norm = 6.0292e-02, time/batch = 0.1795s	
714/10550 (epoch 3.384), train_loss = 1.37592700, grad/param norm = 5.6976e-02, time/batch = 0.1797s	
715/10550 (epoch 3.389), train_loss = 1.38943320, grad/param norm = 6.0545e-02, time/batch = 0.1793s	
716/10550 (epoch 3.393), train_loss = 1.38765697, grad/param norm = 5.6754e-02, time/batch = 0.1795s	
717/10550 (epoch 3.398), train_loss = 1.37648799, grad/param norm = 5.4377e-02, time/batch = 0.1797s	
718/10550 (epoch 3.403), train_loss = 1.41850840, grad/param norm = 5.1595e-02, time/batch = 0.1793s	
719/10550 (epoch 3.408), train_loss = 1.44189190, grad/param norm = 5.3197e-02, time/batch = 0.1797s	
720/10550 (epoch 3.412), train_loss = 1.39388167, grad/param norm = 5.2103e-02, time/batch = 0.1799s	
721/10550 (epoch 3.417), train_loss = 1.37670217, grad/param norm = 5.3775e-02, time/batch = 0.1815s	
722/10550 (epoch 3.422), train_loss = 1.45700381, grad/param norm = 5.7143e-02, time/batch = 0.1788s	
723/10550 (epoch 3.427), train_loss = 1.42345579, grad/param norm = 5.5546e-02, time/batch = 0.1796s	
724/10550 (epoch 3.431), train_loss = 1.42135280, grad/param norm = 6.0495e-02, time/batch = 0.1795s	
725/10550 (epoch 3.436), train_loss = 1.37829619, grad/param norm = 5.5729e-02, time/batch = 0.1790s	
726/10550 (epoch 3.441), train_loss = 1.41090628, grad/param norm = 5.2129e-02, time/batch = 0.1790s	
727/10550 (epoch 3.445), train_loss = 1.38970118, grad/param norm = 5.0850e-02, time/batch = 0.1797s	
728/10550 (epoch 3.450), train_loss = 1.39025663, grad/param norm = 5.2425e-02, time/batch = 0.1786s	
729/10550 (epoch 3.455), train_loss = 1.40497889, grad/param norm = 5.6498e-02, time/batch = 0.1793s	
730/10550 (epoch 3.460), train_loss = 1.36634375, grad/param norm = 6.2182e-02, time/batch = 0.1796s	
731/10550 (epoch 3.464), train_loss = 1.37750420, grad/param norm = 5.4038e-02, time/batch = 0.1814s	
732/10550 (epoch 3.469), train_loss = 1.35494576, grad/param norm = 4.9867e-02, time/batch = 0.1791s	
733/10550 (epoch 3.474), train_loss = 1.41233394, grad/param norm = 5.3732e-02, time/batch = 0.1797s	
734/10550 (epoch 3.479), train_loss = 1.35340373, grad/param norm = 5.4247e-02, time/batch = 0.1793s	
735/10550 (epoch 3.483), train_loss = 1.37170969, grad/param norm = 5.7778e-02, time/batch = 0.1797s	
736/10550 (epoch 3.488), train_loss = 1.39427859, grad/param norm = 5.9848e-02, time/batch = 0.1794s	
737/10550 (epoch 3.493), train_loss = 1.39394062, grad/param norm = 6.5959e-02, time/batch = 0.1797s	
738/10550 (epoch 3.498), train_loss = 1.38535282, grad/param norm = 6.4975e-02, time/batch = 0.1794s	
739/10550 (epoch 3.502), train_loss = 1.40050321, grad/param norm = 5.6450e-02, time/batch = 0.1793s	
740/10550 (epoch 3.507), train_loss = 1.35185376, grad/param norm = 5.5529e-02, time/batch = 0.1800s	
741/10550 (epoch 3.512), train_loss = 1.35318828, grad/param norm = 6.0985e-02, time/batch = 0.1813s	
742/10550 (epoch 3.517), train_loss = 1.42453972, grad/param norm = 6.8289e-02, time/batch = 0.1799s	
743/10550 (epoch 3.521), train_loss = 1.35716129, grad/param norm = 5.7780e-02, time/batch = 0.1815s	
744/10550 (epoch 3.526), train_loss = 1.28937548, grad/param norm = 4.5641e-02, time/batch = 0.1796s	
745/10550 (epoch 3.531), train_loss = 1.35261039, grad/param norm = 4.4926e-02, time/batch = 0.1798s	
746/10550 (epoch 3.536), train_loss = 1.37629034, grad/param norm = 4.3263e-02, time/batch = 0.1792s	
747/10550 (epoch 3.540), train_loss = 1.39584556, grad/param norm = 4.6553e-02, time/batch = 0.1795s	
748/10550 (epoch 3.545), train_loss = 1.37988990, grad/param norm = 4.8761e-02, time/batch = 0.1786s	
749/10550 (epoch 3.550), train_loss = 1.42833749, grad/param norm = 5.2867e-02, time/batch = 0.1797s	
750/10550 (epoch 3.555), train_loss = 1.38281763, grad/param norm = 5.6626e-02, time/batch = 0.1799s	
751/10550 (epoch 3.559), train_loss = 1.45206464, grad/param norm = 5.6507e-02, time/batch = 0.1817s	
752/10550 (epoch 3.564), train_loss = 1.37779876, grad/param norm = 5.9173e-02, time/batch = 0.1793s	
753/10550 (epoch 3.569), train_loss = 1.38048447, grad/param norm = 6.4122e-02, time/batch = 0.1794s	
754/10550 (epoch 3.573), train_loss = 1.40455153, grad/param norm = 6.2868e-02, time/batch = 0.1795s	
755/10550 (epoch 3.578), train_loss = 1.39007468, grad/param norm = 7.2726e-02, time/batch = 0.1799s	
756/10550 (epoch 3.583), train_loss = 1.38285950, grad/param norm = 7.4435e-02, time/batch = 0.1790s	
757/10550 (epoch 3.588), train_loss = 1.35190135, grad/param norm = 6.2122e-02, time/batch = 0.1796s	
758/10550 (epoch 3.592), train_loss = 1.42723088, grad/param norm = 6.1578e-02, time/batch = 0.1789s	
759/10550 (epoch 3.597), train_loss = 1.41295782, grad/param norm = 5.7387e-02, time/batch = 0.1797s	
760/10550 (epoch 3.602), train_loss = 1.40994177, grad/param norm = 5.7672e-02, time/batch = 0.1794s	
761/10550 (epoch 3.607), train_loss = 1.39466538, grad/param norm = 5.1358e-02, time/batch = 0.1808s	
762/10550 (epoch 3.611), train_loss = 1.41453620, grad/param norm = 5.1650e-02, time/batch = 0.1790s	
763/10550 (epoch 3.616), train_loss = 1.34237044, grad/param norm = 5.0926e-02, time/batch = 0.1794s	
764/10550 (epoch 3.621), train_loss = 1.33062918, grad/param norm = 5.4608e-02, time/batch = 0.1790s	
765/10550 (epoch 3.626), train_loss = 1.35993738, grad/param norm = 5.7183e-02, time/batch = 0.1794s	
766/10550 (epoch 3.630), train_loss = 1.40816820, grad/param norm = 5.4435e-02, time/batch = 0.1797s	
767/10550 (epoch 3.635), train_loss = 1.39583987, grad/param norm = 5.5420e-02, time/batch = 0.1796s	
768/10550 (epoch 3.640), train_loss = 1.39870482, grad/param norm = 5.4854e-02, time/batch = 0.1795s	
769/10550 (epoch 3.645), train_loss = 1.38838630, grad/param norm = 5.5560e-02, time/batch = 0.1799s	
770/10550 (epoch 3.649), train_loss = 1.40025486, grad/param norm = 5.4859e-02, time/batch = 0.1797s	
771/10550 (epoch 3.654), train_loss = 1.41734576, grad/param norm = 6.4371e-02, time/batch = 0.1813s	
772/10550 (epoch 3.659), train_loss = 1.40567688, grad/param norm = 6.5011e-02, time/batch = 0.1786s	
773/10550 (epoch 3.664), train_loss = 1.39289021, grad/param norm = 5.3560e-02, time/batch = 0.1795s	
774/10550 (epoch 3.668), train_loss = 1.38696962, grad/param norm = 5.4581e-02, time/batch = 0.1795s	
775/10550 (epoch 3.673), train_loss = 1.41142477, grad/param norm = 6.0708e-02, time/batch = 0.1790s	
776/10550 (epoch 3.678), train_loss = 1.33796486, grad/param norm = 6.1422e-02, time/batch = 0.1796s	
777/10550 (epoch 3.682), train_loss = 1.33685289, grad/param norm = 6.1476e-02, time/batch = 0.1797s	
778/10550 (epoch 3.687), train_loss = 1.34220259, grad/param norm = 5.3185e-02, time/batch = 0.1789s	
779/10550 (epoch 3.692), train_loss = 1.37885638, grad/param norm = 5.3888e-02, time/batch = 0.1798s	
780/10550 (epoch 3.697), train_loss = 1.36239023, grad/param norm = 5.3144e-02, time/batch = 0.1797s	
781/10550 (epoch 3.701), train_loss = 1.39608142, grad/param norm = 5.3729e-02, time/batch = 0.1810s	
782/10550 (epoch 3.706), train_loss = 1.37821674, grad/param norm = 5.7901e-02, time/batch = 0.1790s	
783/10550 (epoch 3.711), train_loss = 1.38773531, grad/param norm = 5.0217e-02, time/batch = 0.1793s	
784/10550 (epoch 3.716), train_loss = 1.37103687, grad/param norm = 5.3170e-02, time/batch = 0.1793s	
785/10550 (epoch 3.720), train_loss = 1.38438531, grad/param norm = 5.4756e-02, time/batch = 0.1797s	
786/10550 (epoch 3.725), train_loss = 1.34904334, grad/param norm = 5.8223e-02, time/batch = 0.1794s	
787/10550 (epoch 3.730), train_loss = 1.38368445, grad/param norm = 5.5361e-02, time/batch = 0.1799s	
788/10550 (epoch 3.735), train_loss = 1.35400423, grad/param norm = 5.2645e-02, time/batch = 0.1819s	
789/10550 (epoch 3.739), train_loss = 1.34692521, grad/param norm = 4.8532e-02, time/batch = 0.1800s	
790/10550 (epoch 3.744), train_loss = 1.34679866, grad/param norm = 5.1512e-02, time/batch = 0.1797s	
791/10550 (epoch 3.749), train_loss = 1.38148053, grad/param norm = 4.8971e-02, time/batch = 0.1819s	
792/10550 (epoch 3.754), train_loss = 1.38005209, grad/param norm = 5.0185e-02, time/batch = 0.1790s	
793/10550 (epoch 3.758), train_loss = 1.38797433, grad/param norm = 5.5664e-02, time/batch = 0.1797s	
794/10550 (epoch 3.763), train_loss = 1.37133046, grad/param norm = 6.1053e-02, time/batch = 0.1796s	
795/10550 (epoch 3.768), train_loss = 1.42994361, grad/param norm = 7.2029e-02, time/batch = 0.1794s	
796/10550 (epoch 3.773), train_loss = 1.43543974, grad/param norm = 6.7119e-02, time/batch = 0.1788s	
797/10550 (epoch 3.777), train_loss = 1.38486911, grad/param norm = 5.7284e-02, time/batch = 0.1795s	
798/10550 (epoch 3.782), train_loss = 1.41366618, grad/param norm = 5.5508e-02, time/batch = 0.1793s	
799/10550 (epoch 3.787), train_loss = 1.38043328, grad/param norm = 5.3643e-02, time/batch = 0.1797s	
800/10550 (epoch 3.791), train_loss = 1.33811672, grad/param norm = 4.8825e-02, time/batch = 0.1800s	
801/10550 (epoch 3.796), train_loss = 1.34061630, grad/param norm = 5.0097e-02, time/batch = 0.1815s	
802/10550 (epoch 3.801), train_loss = 1.36127736, grad/param norm = 5.3206e-02, time/batch = 0.1791s	
803/10550 (epoch 3.806), train_loss = 1.39731364, grad/param norm = 5.0980e-02, time/batch = 0.1795s	
804/10550 (epoch 3.810), train_loss = 1.40397070, grad/param norm = 4.8372e-02, time/batch = 0.1794s	
805/10550 (epoch 3.815), train_loss = 1.35194359, grad/param norm = 4.8124e-02, time/batch = 0.1794s	
806/10550 (epoch 3.820), train_loss = 1.38201689, grad/param norm = 5.3073e-02, time/batch = 0.1794s	
807/10550 (epoch 3.825), train_loss = 1.35009220, grad/param norm = 5.1757e-02, time/batch = 0.1792s	
808/10550 (epoch 3.829), train_loss = 1.34461770, grad/param norm = 5.2101e-02, time/batch = 0.1789s	
809/10550 (epoch 3.834), train_loss = 1.38871136, grad/param norm = 5.5299e-02, time/batch = 0.1798s	
810/10550 (epoch 3.839), train_loss = 1.34434798, grad/param norm = 5.3042e-02, time/batch = 0.1797s	
811/10550 (epoch 3.844), train_loss = 1.37566983, grad/param norm = 5.1876e-02, time/batch = 0.1817s	
812/10550 (epoch 3.848), train_loss = 1.34353214, grad/param norm = 4.8403e-02, time/batch = 0.1791s	
813/10550 (epoch 3.853), train_loss = 1.35791484, grad/param norm = 4.7683e-02, time/batch = 0.1794s	
814/10550 (epoch 3.858), train_loss = 1.38332894, grad/param norm = 5.0713e-02, time/batch = 0.1789s	
815/10550 (epoch 3.863), train_loss = 1.34114333, grad/param norm = 5.4881e-02, time/batch = 0.1795s	
816/10550 (epoch 3.867), train_loss = 1.38064744, grad/param norm = 5.0205e-02, time/batch = 0.1793s	
817/10550 (epoch 3.872), train_loss = 1.36554175, grad/param norm = 5.1143e-02, time/batch = 0.1795s	
818/10550 (epoch 3.877), train_loss = 1.31706372, grad/param norm = 5.6304e-02, time/batch = 0.1792s	
819/10550 (epoch 3.882), train_loss = 1.35628123, grad/param norm = 5.4902e-02, time/batch = 0.1798s	
820/10550 (epoch 3.886), train_loss = 1.37563456, grad/param norm = 5.0166e-02, time/batch = 0.1800s	
821/10550 (epoch 3.891), train_loss = 1.37942959, grad/param norm = 5.1479e-02, time/batch = 0.1814s	
822/10550 (epoch 3.896), train_loss = 1.35373936, grad/param norm = 5.0267e-02, time/batch = 0.1795s	
823/10550 (epoch 3.900), train_loss = 1.32527111, grad/param norm = 4.8874e-02, time/batch = 0.1789s	
824/10550 (epoch 3.905), train_loss = 1.33194848, grad/param norm = 4.8653e-02, time/batch = 0.1792s	
825/10550 (epoch 3.910), train_loss = 1.30612024, grad/param norm = 4.8008e-02, time/batch = 0.1793s	
826/10550 (epoch 3.915), train_loss = 1.35125949, grad/param norm = 5.2857e-02, time/batch = 0.1792s	
827/10550 (epoch 3.919), train_loss = 1.35907968, grad/param norm = 5.6794e-02, time/batch = 0.1797s	
828/10550 (epoch 3.924), train_loss = 1.36429195, grad/param norm = 6.1098e-02, time/batch = 0.1789s	
829/10550 (epoch 3.929), train_loss = 1.33100235, grad/param norm = 5.8121e-02, time/batch = 0.1796s	
830/10550 (epoch 3.934), train_loss = 1.35935126, grad/param norm = 5.0581e-02, time/batch = 0.1798s	
831/10550 (epoch 3.938), train_loss = 1.35742657, grad/param norm = 5.4681e-02, time/batch = 0.1811s	
832/10550 (epoch 3.943), train_loss = 1.36843793, grad/param norm = 5.4025e-02, time/batch = 0.1789s	
833/10550 (epoch 3.948), train_loss = 1.38957641, grad/param norm = 5.5957e-02, time/batch = 0.1814s	
834/10550 (epoch 3.953), train_loss = 1.40324232, grad/param norm = 5.2903e-02, time/batch = 0.1799s	
835/10550 (epoch 3.957), train_loss = 1.35863295, grad/param norm = 4.8946e-02, time/batch = 0.1792s	
836/10550 (epoch 3.962), train_loss = 1.34481514, grad/param norm = 5.2640e-02, time/batch = 0.1795s	
837/10550 (epoch 3.967), train_loss = 1.36234436, grad/param norm = 5.8092e-02, time/batch = 0.1797s	
838/10550 (epoch 3.972), train_loss = 1.33866783, grad/param norm = 5.4908e-02, time/batch = 0.1787s	
839/10550 (epoch 3.976), train_loss = 1.36315684, grad/param norm = 5.5342e-02, time/batch = 0.1802s	
840/10550 (epoch 3.981), train_loss = 1.36804864, grad/param norm = 5.7362e-02, time/batch = 0.1798s	
841/10550 (epoch 3.986), train_loss = 1.34411872, grad/param norm = 5.3006e-02, time/batch = 0.1818s	
842/10550 (epoch 3.991), train_loss = 1.42136866, grad/param norm = 5.8267e-02, time/batch = 0.1787s	
843/10550 (epoch 3.995), train_loss = 1.35069291, grad/param norm = 5.7865e-02, time/batch = 0.1787s	
844/10550 (epoch 4.000), train_loss = 1.36582055, grad/param norm = 5.2287e-02, time/batch = 0.1797s	
845/10550 (epoch 4.005), train_loss = 1.53730222, grad/param norm = 5.8558e-02, time/batch = 0.1793s	
846/10550 (epoch 4.009), train_loss = 1.32350741, grad/param norm = 5.5190e-02, time/batch = 0.1793s	
847/10550 (epoch 4.014), train_loss = 1.33909452, grad/param norm = 5.4745e-02, time/batch = 0.1795s	
848/10550 (epoch 4.019), train_loss = 1.38155475, grad/param norm = 5.5166e-02, time/batch = 0.1795s	
849/10550 (epoch 4.024), train_loss = 1.37392557, grad/param norm = 5.5466e-02, time/batch = 0.1796s	
850/10550 (epoch 4.028), train_loss = 1.34894487, grad/param norm = 5.2835e-02, time/batch = 0.1797s	
851/10550 (epoch 4.033), train_loss = 1.37110986, grad/param norm = 4.9334e-02, time/batch = 0.1810s	
852/10550 (epoch 4.038), train_loss = 1.38048839, grad/param norm = 4.7221e-02, time/batch = 0.1790s	
853/10550 (epoch 4.043), train_loss = 1.32822893, grad/param norm = 4.6259e-02, time/batch = 0.1797s	
854/10550 (epoch 4.047), train_loss = 1.30892842, grad/param norm = 4.9178e-02, time/batch = 0.1788s	
855/10550 (epoch 4.052), train_loss = 1.39210432, grad/param norm = 4.7904e-02, time/batch = 0.1790s	
856/10550 (epoch 4.057), train_loss = 1.33995862, grad/param norm = 4.7911e-02, time/batch = 0.1793s	
857/10550 (epoch 4.062), train_loss = 1.35988782, grad/param norm = 5.0224e-02, time/batch = 0.1789s	
858/10550 (epoch 4.066), train_loss = 1.34827354, grad/param norm = 5.0768e-02, time/batch = 0.1790s	
859/10550 (epoch 4.071), train_loss = 1.31389720, grad/param norm = 5.1080e-02, time/batch = 0.1798s	
860/10550 (epoch 4.076), train_loss = 1.33488641, grad/param norm = 4.7061e-02, time/batch = 0.1796s	
861/10550 (epoch 4.081), train_loss = 1.37479595, grad/param norm = 5.1048e-02, time/batch = 0.1812s	
862/10550 (epoch 4.085), train_loss = 1.32801961, grad/param norm = 4.6170e-02, time/batch = 0.1793s	
863/10550 (epoch 4.090), train_loss = 1.33329297, grad/param norm = 4.6776e-02, time/batch = 0.1791s	
864/10550 (epoch 4.095), train_loss = 1.33500424, grad/param norm = 5.1598e-02, time/batch = 0.1795s	
865/10550 (epoch 4.100), train_loss = 1.32125942, grad/param norm = 5.0940e-02, time/batch = 0.1791s	
866/10550 (epoch 4.104), train_loss = 1.31136256, grad/param norm = 4.9644e-02, time/batch = 0.1790s	
867/10550 (epoch 4.109), train_loss = 1.30556365, grad/param norm = 4.4615e-02, time/batch = 0.1795s	
868/10550 (epoch 4.114), train_loss = 1.32375327, grad/param norm = 4.4139e-02, time/batch = 0.1790s	
869/10550 (epoch 4.118), train_loss = 1.26805825, grad/param norm = 4.5363e-02, time/batch = 0.1793s	
870/10550 (epoch 4.123), train_loss = 1.35631358, grad/param norm = 4.9166e-02, time/batch = 0.1800s	
871/10550 (epoch 4.128), train_loss = 1.30002994, grad/param norm = 4.8915e-02, time/batch = 0.1815s	
872/10550 (epoch 4.133), train_loss = 1.31542197, grad/param norm = 5.2303e-02, time/batch = 0.1794s	
873/10550 (epoch 4.137), train_loss = 1.31136751, grad/param norm = 4.9785e-02, time/batch = 0.1787s	
874/10550 (epoch 4.142), train_loss = 1.35164390, grad/param norm = 5.1273e-02, time/batch = 0.1798s	
875/10550 (epoch 4.147), train_loss = 1.32538103, grad/param norm = 5.7986e-02, time/batch = 0.1791s	
876/10550 (epoch 4.152), train_loss = 1.33932402, grad/param norm = 6.5731e-02, time/batch = 0.1793s	
877/10550 (epoch 4.156), train_loss = 1.34516603, grad/param norm = 6.7708e-02, time/batch = 0.1794s	
878/10550 (epoch 4.161), train_loss = 1.33009405, grad/param norm = 6.1322e-02, time/batch = 0.1814s	
879/10550 (epoch 4.166), train_loss = 1.36189362, grad/param norm = 5.4425e-02, time/batch = 0.1804s	
880/10550 (epoch 4.171), train_loss = 1.31666909, grad/param norm = 4.6925e-02, time/batch = 0.1801s	
881/10550 (epoch 4.175), train_loss = 1.36835168, grad/param norm = 4.6648e-02, time/batch = 0.1816s	
882/10550 (epoch 4.180), train_loss = 1.34061030, grad/param norm = 4.8147e-02, time/batch = 0.1792s	
883/10550 (epoch 4.185), train_loss = 1.34423421, grad/param norm = 4.8180e-02, time/batch = 0.1797s	
884/10550 (epoch 4.190), train_loss = 1.32536469, grad/param norm = 4.9249e-02, time/batch = 0.1799s	
885/10550 (epoch 4.194), train_loss = 1.35873237, grad/param norm = 5.2228e-02, time/batch = 0.1796s	
886/10550 (epoch 4.199), train_loss = 1.35068824, grad/param norm = 5.1403e-02, time/batch = 0.1797s	
887/10550 (epoch 4.204), train_loss = 1.34557494, grad/param norm = 5.3534e-02, time/batch = 0.1795s	
888/10550 (epoch 4.209), train_loss = 1.35347623, grad/param norm = 5.1964e-02, time/batch = 0.1789s	
889/10550 (epoch 4.213), train_loss = 1.35562503, grad/param norm = 4.9522e-02, time/batch = 0.1795s	
890/10550 (epoch 4.218), train_loss = 1.33416235, grad/param norm = 4.9033e-02, time/batch = 0.1803s	
891/10550 (epoch 4.223), train_loss = 1.29169840, grad/param norm = 4.4883e-02, time/batch = 0.1814s	
892/10550 (epoch 4.227), train_loss = 1.28417487, grad/param norm = 4.8665e-02, time/batch = 0.1791s	
893/10550 (epoch 4.232), train_loss = 1.31746112, grad/param norm = 5.7005e-02, time/batch = 0.1796s	
894/10550 (epoch 4.237), train_loss = 1.28862737, grad/param norm = 6.0456e-02, time/batch = 0.1797s	
895/10550 (epoch 4.242), train_loss = 1.35291039, grad/param norm = 5.9848e-02, time/batch = 0.1793s	
896/10550 (epoch 4.246), train_loss = 1.30668987, grad/param norm = 5.4707e-02, time/batch = 0.1793s	
897/10550 (epoch 4.251), train_loss = 1.32111418, grad/param norm = 4.9439e-02, time/batch = 0.1792s	
898/10550 (epoch 4.256), train_loss = 1.34523678, grad/param norm = 4.7969e-02, time/batch = 0.1794s	
899/10550 (epoch 4.261), train_loss = 1.30493235, grad/param norm = 4.5961e-02, time/batch = 0.1796s	
900/10550 (epoch 4.265), train_loss = 1.31827318, grad/param norm = 4.7314e-02, time/batch = 0.1802s	
901/10550 (epoch 4.270), train_loss = 1.29688935, grad/param norm = 4.4510e-02, time/batch = 0.1816s	
902/10550 (epoch 4.275), train_loss = 1.31810554, grad/param norm = 4.4049e-02, time/batch = 0.1786s	
903/10550 (epoch 4.280), train_loss = 1.32962628, grad/param norm = 4.7985e-02, time/batch = 0.1792s	
904/10550 (epoch 4.284), train_loss = 1.31439335, grad/param norm = 5.2347e-02, time/batch = 0.1794s	
905/10550 (epoch 4.289), train_loss = 1.33034117, grad/param norm = 5.3729e-02, time/batch = 0.1789s	
906/10550 (epoch 4.294), train_loss = 1.33720745, grad/param norm = 5.7788e-02, time/batch = 0.1791s	
907/10550 (epoch 4.299), train_loss = 1.29797655, grad/param norm = 5.0921e-02, time/batch = 0.1796s	
908/10550 (epoch 4.303), train_loss = 1.33945007, grad/param norm = 4.9067e-02, time/batch = 0.1793s	
909/10550 (epoch 4.308), train_loss = 1.30963656, grad/param norm = 4.5689e-02, time/batch = 0.1794s	
910/10550 (epoch 4.313), train_loss = 1.34115606, grad/param norm = 4.7458e-02, time/batch = 0.1798s	
911/10550 (epoch 4.318), train_loss = 1.31171203, grad/param norm = 4.3251e-02, time/batch = 0.1818s	
912/10550 (epoch 4.322), train_loss = 1.33217215, grad/param norm = 5.1543e-02, time/batch = 0.1793s	
913/10550 (epoch 4.327), train_loss = 1.33595519, grad/param norm = 5.9559e-02, time/batch = 0.1797s	
914/10550 (epoch 4.332), train_loss = 1.34781536, grad/param norm = 6.0897e-02, time/batch = 0.1797s	
915/10550 (epoch 4.336), train_loss = 1.34292057, grad/param norm = 5.5080e-02, time/batch = 0.1792s	
916/10550 (epoch 4.341), train_loss = 1.28986125, grad/param norm = 5.3686e-02, time/batch = 0.1798s	
917/10550 (epoch 4.346), train_loss = 1.34662398, grad/param norm = 5.1386e-02, time/batch = 0.1798s	
918/10550 (epoch 4.351), train_loss = 1.31778485, grad/param norm = 5.8346e-02, time/batch = 0.1788s	
919/10550 (epoch 4.355), train_loss = 1.30492520, grad/param norm = 6.3735e-02, time/batch = 0.1795s	
920/10550 (epoch 4.360), train_loss = 1.38088077, grad/param norm = 6.8246e-02, time/batch = 0.1798s	
921/10550 (epoch 4.365), train_loss = 1.32739485, grad/param norm = 5.5774e-02, time/batch = 0.1811s	
922/10550 (epoch 4.370), train_loss = 1.31533053, grad/param norm = 5.1067e-02, time/batch = 0.1790s	
923/10550 (epoch 4.374), train_loss = 1.33158520, grad/param norm = 5.2806e-02, time/batch = 0.1819s	
924/10550 (epoch 4.379), train_loss = 1.32423459, grad/param norm = 5.3477e-02, time/batch = 0.1799s	
925/10550 (epoch 4.384), train_loss = 1.28750877, grad/param norm = 5.2985e-02, time/batch = 0.1794s	
926/10550 (epoch 4.389), train_loss = 1.30916782, grad/param norm = 5.8849e-02, time/batch = 0.1788s	
927/10550 (epoch 4.393), train_loss = 1.29946190, grad/param norm = 5.0543e-02, time/batch = 0.1796s	
928/10550 (epoch 4.398), train_loss = 1.29410608, grad/param norm = 4.7137e-02, time/batch = 0.1791s	
929/10550 (epoch 4.403), train_loss = 1.33097579, grad/param norm = 5.1453e-02, time/batch = 0.1795s	
930/10550 (epoch 4.408), train_loss = 1.35197115, grad/param norm = 5.0345e-02, time/batch = 0.1797s	
931/10550 (epoch 4.412), train_loss = 1.30054716, grad/param norm = 4.6038e-02, time/batch = 0.1816s	
932/10550 (epoch 4.417), train_loss = 1.28641335, grad/param norm = 4.8099e-02, time/batch = 0.1793s	
933/10550 (epoch 4.422), train_loss = 1.35841936, grad/param norm = 4.9422e-02, time/batch = 0.1794s	
934/10550 (epoch 4.427), train_loss = 1.32528670, grad/param norm = 4.8773e-02, time/batch = 0.1792s	
935/10550 (epoch 4.431), train_loss = 1.32275578, grad/param norm = 4.9452e-02, time/batch = 0.1798s	
936/10550 (epoch 4.436), train_loss = 1.28059380, grad/param norm = 4.5924e-02, time/batch = 0.1792s	
937/10550 (epoch 4.441), train_loss = 1.31668741, grad/param norm = 4.4527e-02, time/batch = 0.1796s	
938/10550 (epoch 4.445), train_loss = 1.30516999, grad/param norm = 5.1839e-02, time/batch = 0.1790s	
939/10550 (epoch 4.450), train_loss = 1.31817177, grad/param norm = 6.2320e-02, time/batch = 0.1799s	
940/10550 (epoch 4.455), train_loss = 1.32107548, grad/param norm = 5.5406e-02, time/batch = 0.1802s	
941/10550 (epoch 4.460), train_loss = 1.26435061, grad/param norm = 4.5399e-02, time/batch = 0.1816s	
942/10550 (epoch 4.464), train_loss = 1.28013896, grad/param norm = 4.5216e-02, time/batch = 0.1787s	
943/10550 (epoch 4.469), train_loss = 1.27004143, grad/param norm = 4.6048e-02, time/batch = 0.1792s	
944/10550 (epoch 4.474), train_loss = 1.31937947, grad/param norm = 4.6742e-02, time/batch = 0.1790s	
945/10550 (epoch 4.479), train_loss = 1.25970750, grad/param norm = 4.4910e-02, time/batch = 0.1795s	
946/10550 (epoch 4.483), train_loss = 1.28222528, grad/param norm = 5.1124e-02, time/batch = 0.1793s	
947/10550 (epoch 4.488), train_loss = 1.29929984, grad/param norm = 5.4368e-02, time/batch = 0.1795s	
948/10550 (epoch 4.493), train_loss = 1.30428028, grad/param norm = 5.8171e-02, time/batch = 0.1794s	
949/10550 (epoch 4.498), train_loss = 1.29916403, grad/param norm = 5.2694e-02, time/batch = 0.1799s	
950/10550 (epoch 4.502), train_loss = 1.31631582, grad/param norm = 5.1341e-02, time/batch = 0.1791s	
951/10550 (epoch 4.507), train_loss = 1.27755810, grad/param norm = 4.9563e-02, time/batch = 0.1816s	
952/10550 (epoch 4.512), train_loss = 1.27041759, grad/param norm = 5.6767e-02, time/batch = 0.1793s	
953/10550 (epoch 4.517), train_loss = 1.32751689, grad/param norm = 5.5898e-02, time/batch = 0.1794s	
954/10550 (epoch 4.521), train_loss = 1.27417192, grad/param norm = 4.8705e-02, time/batch = 0.1790s	
955/10550 (epoch 4.526), train_loss = 1.21047632, grad/param norm = 4.4530e-02, time/batch = 0.1795s	
956/10550 (epoch 4.531), train_loss = 1.27131952, grad/param norm = 4.9540e-02, time/batch = 0.1792s	
957/10550 (epoch 4.536), train_loss = 1.30147961, grad/param norm = 5.0455e-02, time/batch = 0.1793s	
958/10550 (epoch 4.540), train_loss = 1.31546697, grad/param norm = 5.2187e-02, time/batch = 0.1793s	
959/10550 (epoch 4.545), train_loss = 1.30326735, grad/param norm = 5.0358e-02, time/batch = 0.1794s	
960/10550 (epoch 4.550), train_loss = 1.33630202, grad/param norm = 4.9525e-02, time/batch = 0.1796s	
961/10550 (epoch 4.555), train_loss = 1.29572092, grad/param norm = 4.7752e-02, time/batch = 0.1815s	
962/10550 (epoch 4.559), train_loss = 1.34919556, grad/param norm = 4.6471e-02, time/batch = 0.1793s	
963/10550 (epoch 4.564), train_loss = 1.28270632, grad/param norm = 4.5165e-02, time/batch = 0.1792s	
964/10550 (epoch 4.569), train_loss = 1.28219106, grad/param norm = 5.1223e-02, time/batch = 0.1795s	
965/10550 (epoch 4.573), train_loss = 1.31752540, grad/param norm = 5.6223e-02, time/batch = 0.1793s	
966/10550 (epoch 4.578), train_loss = 1.30091856, grad/param norm = 5.6432e-02, time/batch = 0.1796s	
967/10550 (epoch 4.583), train_loss = 1.27682360, grad/param norm = 5.1133e-02, time/batch = 0.1795s	
968/10550 (epoch 4.588), train_loss = 1.25298533, grad/param norm = 4.4461e-02, time/batch = 0.1793s	
969/10550 (epoch 4.592), train_loss = 1.32532229, grad/param norm = 4.9283e-02, time/batch = 0.1817s	
970/10550 (epoch 4.597), train_loss = 1.31937223, grad/param norm = 4.9764e-02, time/batch = 0.1803s	
971/10550 (epoch 4.602), train_loss = 1.32069269, grad/param norm = 5.2389e-02, time/batch = 0.1818s	
972/10550 (epoch 4.607), train_loss = 1.31210064, grad/param norm = 5.6005e-02, time/batch = 0.1792s	
973/10550 (epoch 4.611), train_loss = 1.34154653, grad/param norm = 5.6794e-02, time/batch = 0.1792s	
974/10550 (epoch 4.616), train_loss = 1.28481919, grad/param norm = 5.3880e-02, time/batch = 0.1797s	
975/10550 (epoch 4.621), train_loss = 1.25907916, grad/param norm = 4.7980e-02, time/batch = 0.1794s	
976/10550 (epoch 4.626), train_loss = 1.26524075, grad/param norm = 4.4195e-02, time/batch = 0.1799s	
977/10550 (epoch 4.630), train_loss = 1.31079491, grad/param norm = 4.7214e-02, time/batch = 0.1796s	
978/10550 (epoch 4.635), train_loss = 1.30755527, grad/param norm = 5.1436e-02, time/batch = 0.1788s	
979/10550 (epoch 4.640), train_loss = 1.31061012, grad/param norm = 5.6628e-02, time/batch = 0.1795s	
980/10550 (epoch 4.645), train_loss = 1.31479796, grad/param norm = 5.8802e-02, time/batch = 0.1799s	
981/10550 (epoch 4.649), train_loss = 1.31780474, grad/param norm = 4.8183e-02, time/batch = 0.1811s	
982/10550 (epoch 4.654), train_loss = 1.31667569, grad/param norm = 4.4763e-02, time/batch = 0.1790s	
983/10550 (epoch 4.659), train_loss = 1.31198807, grad/param norm = 4.8672e-02, time/batch = 0.1792s	
984/10550 (epoch 4.664), train_loss = 1.30461358, grad/param norm = 4.8375e-02, time/batch = 0.1797s	
985/10550 (epoch 4.668), train_loss = 1.29539119, grad/param norm = 4.9804e-02, time/batch = 0.1794s	
986/10550 (epoch 4.673), train_loss = 1.31795878, grad/param norm = 5.1312e-02, time/batch = 0.1793s	
987/10550 (epoch 4.678), train_loss = 1.24906704, grad/param norm = 5.0366e-02, time/batch = 0.1789s	
988/10550 (epoch 4.682), train_loss = 1.24877766, grad/param norm = 4.7990e-02, time/batch = 0.1790s	
989/10550 (epoch 4.687), train_loss = 1.25184743, grad/param norm = 4.4321e-02, time/batch = 0.1797s	
990/10550 (epoch 4.692), train_loss = 1.28737453, grad/param norm = 4.4435e-02, time/batch = 0.1801s	
991/10550 (epoch 4.697), train_loss = 1.28058672, grad/param norm = 4.6880e-02, time/batch = 0.1813s	
992/10550 (epoch 4.701), train_loss = 1.31036366, grad/param norm = 4.8137e-02, time/batch = 0.1792s	
993/10550 (epoch 4.706), train_loss = 1.29780330, grad/param norm = 5.3705e-02, time/batch = 0.1796s	
994/10550 (epoch 4.711), train_loss = 1.30392368, grad/param norm = 4.9622e-02, time/batch = 0.1798s	
995/10550 (epoch 4.716), train_loss = 1.29012260, grad/param norm = 4.8812e-02, time/batch = 0.1795s	
996/10550 (epoch 4.720), train_loss = 1.30660992, grad/param norm = 4.7876e-02, time/batch = 0.1796s	
997/10550 (epoch 4.725), train_loss = 1.26538686, grad/param norm = 4.6812e-02, time/batch = 0.1794s	
998/10550 (epoch 4.730), train_loss = 1.29690070, grad/param norm = 4.7764e-02, time/batch = 0.1791s	
999/10550 (epoch 4.735), train_loss = 1.26929926, grad/param norm = 4.5117e-02, time/batch = 0.1798s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to cv/lm_lstm_epoch4.74_1.3848.t7	
1000/10550 (epoch 4.739), train_loss = 1.26633756, grad/param norm = 4.5739e-02, time/batch = 0.1796s	
1001/10550 (epoch 4.744), train_loss = 1.48926548, grad/param norm = 5.1652e-02, time/batch = 0.1836s	
1002/10550 (epoch 4.749), train_loss = 1.30286139, grad/param norm = 4.5365e-02, time/batch = 0.1800s	
1003/10550 (epoch 4.754), train_loss = 1.29556362, grad/param norm = 4.2672e-02, time/batch = 0.1799s	
1004/10550 (epoch 4.758), train_loss = 1.29900183, grad/param norm = 4.6045e-02, time/batch = 0.1802s	
1005/10550 (epoch 4.763), train_loss = 1.27667700, grad/param norm = 4.6595e-02, time/batch = 0.1805s	
1006/10550 (epoch 4.768), train_loss = 1.32443763, grad/param norm = 5.2573e-02, time/batch = 0.1801s	
1007/10550 (epoch 4.773), train_loss = 1.33941373, grad/param norm = 5.3958e-02, time/batch = 0.1802s	
1008/10550 (epoch 4.777), train_loss = 1.29236690, grad/param norm = 5.1035e-02, time/batch = 0.1838s	
1009/10550 (epoch 4.782), train_loss = 1.33458275, grad/param norm = 5.0677e-02, time/batch = 0.1803s	
1010/10550 (epoch 4.787), train_loss = 1.29381564, grad/param norm = 4.8089e-02, time/batch = 0.1800s	
1011/10550 (epoch 4.791), train_loss = 1.25795300, grad/param norm = 4.5132e-02, time/batch = 0.1802s	
1012/10550 (epoch 4.796), train_loss = 1.27648136, grad/param norm = 5.1485e-02, time/batch = 0.1797s	
1013/10550 (epoch 4.801), train_loss = 1.29103799, grad/param norm = 5.9399e-02, time/batch = 0.1800s	
1014/10550 (epoch 4.806), train_loss = 1.32951225, grad/param norm = 5.8294e-02, time/batch = 0.1794s	
1015/10550 (epoch 4.810), train_loss = 1.34447824, grad/param norm = 5.7299e-02, time/batch = 0.1799s	
1016/10550 (epoch 4.815), train_loss = 1.28386004, grad/param norm = 5.0959e-02, time/batch = 0.1802s	
1017/10550 (epoch 4.820), train_loss = 1.30250494, grad/param norm = 4.9573e-02, time/batch = 0.1803s	
1018/10550 (epoch 4.825), train_loss = 1.27572944, grad/param norm = 4.7851e-02, time/batch = 0.1792s	
1019/10550 (epoch 4.829), train_loss = 1.26690123, grad/param norm = 4.6453e-02, time/batch = 0.1801s	
1020/10550 (epoch 4.834), train_loss = 1.29859932, grad/param norm = 4.5757e-02, time/batch = 0.1801s	
1021/10550 (epoch 4.839), train_loss = 1.25931581, grad/param norm = 4.5636e-02, time/batch = 0.1808s	
1022/10550 (epoch 4.844), train_loss = 1.28760810, grad/param norm = 4.6127e-02, time/batch = 0.1793s	
1023/10550 (epoch 4.848), train_loss = 1.27617913, grad/param norm = 5.4467e-02, time/batch = 0.1796s	
1024/10550 (epoch 4.853), train_loss = 1.30238191, grad/param norm = 5.7222e-02, time/batch = 0.1797s	
1025/10550 (epoch 4.858), train_loss = 1.30720827, grad/param norm = 4.8259e-02, time/batch = 0.1802s	
1026/10550 (epoch 4.863), train_loss = 1.26655277, grad/param norm = 4.7203e-02, time/batch = 0.1796s	
1027/10550 (epoch 4.867), train_loss = 1.30115449, grad/param norm = 4.5765e-02, time/batch = 0.1800s	
1028/10550 (epoch 4.872), train_loss = 1.28814731, grad/param norm = 4.6880e-02, time/batch = 0.1792s	
1029/10550 (epoch 4.877), train_loss = 1.24325940, grad/param norm = 5.0069e-02, time/batch = 0.1806s	
1030/10550 (epoch 4.882), train_loss = 1.28369038, grad/param norm = 5.9249e-02, time/batch = 0.1801s	
1031/10550 (epoch 4.886), train_loss = 1.30826747, grad/param norm = 5.7673e-02, time/batch = 0.1806s	
1032/10550 (epoch 4.891), train_loss = 1.29718748, grad/param norm = 4.9388e-02, time/batch = 0.1796s	
1033/10550 (epoch 4.896), train_loss = 1.27761180, grad/param norm = 4.8853e-02, time/batch = 0.1800s	
1034/10550 (epoch 4.900), train_loss = 1.25232222, grad/param norm = 4.6317e-02, time/batch = 0.1803s	
1035/10550 (epoch 4.905), train_loss = 1.25897422, grad/param norm = 5.1869e-02, time/batch = 0.1802s	
1036/10550 (epoch 4.910), train_loss = 1.24167171, grad/param norm = 4.3145e-02, time/batch = 0.1801s	
1037/10550 (epoch 4.915), train_loss = 1.27173297, grad/param norm = 4.4540e-02, time/batch = 0.1798s	
1038/10550 (epoch 4.919), train_loss = 1.27901444, grad/param norm = 4.7565e-02, time/batch = 0.1795s	
1039/10550 (epoch 4.924), train_loss = 1.28236110, grad/param norm = 4.6352e-02, time/batch = 0.1799s	
1040/10550 (epoch 4.929), train_loss = 1.25581828, grad/param norm = 4.7637e-02, time/batch = 0.1801s	
1041/10550 (epoch 4.934), train_loss = 1.28130561, grad/param norm = 4.9070e-02, time/batch = 0.1807s	
1042/10550 (epoch 4.938), train_loss = 1.27827623, grad/param norm = 5.3760e-02, time/batch = 0.1792s	
1043/10550 (epoch 4.943), train_loss = 1.29084114, grad/param norm = 5.0950e-02, time/batch = 0.1803s	
1044/10550 (epoch 4.948), train_loss = 1.30285694, grad/param norm = 4.6748e-02, time/batch = 0.1799s	
1045/10550 (epoch 4.953), train_loss = 1.33307134, grad/param norm = 5.5026e-02, time/batch = 0.1803s	
1046/10550 (epoch 4.957), train_loss = 1.29425187, grad/param norm = 4.9127e-02, time/batch = 0.1796s	
1047/10550 (epoch 4.962), train_loss = 1.27242879, grad/param norm = 5.1233e-02, time/batch = 0.1800s	
1048/10550 (epoch 4.967), train_loss = 1.27732384, grad/param norm = 5.0055e-02, time/batch = 0.1804s	
1049/10550 (epoch 4.972), train_loss = 1.25494868, grad/param norm = 4.9054e-02, time/batch = 0.1803s	
1050/10550 (epoch 4.976), train_loss = 1.28065683, grad/param norm = 4.4648e-02, time/batch = 0.1808s	
1051/10550 (epoch 4.981), train_loss = 1.29032510, grad/param norm = 4.8174e-02, time/batch = 0.1809s	
1052/10550 (epoch 4.986), train_loss = 1.26393114, grad/param norm = 4.6120e-02, time/batch = 0.1800s	
1053/10550 (epoch 4.991), train_loss = 1.33154070, grad/param norm = 4.5726e-02, time/batch = 0.1803s	
1054/10550 (epoch 4.995), train_loss = 1.27478222, grad/param norm = 4.5863e-02, time/batch = 0.1800s	
1055/10550 (epoch 5.000), train_loss = 1.28743834, grad/param norm = 4.4895e-02, time/batch = 0.1799s	
1056/10550 (epoch 5.005), train_loss = 1.46608552, grad/param norm = 5.0094e-02, time/batch = 0.1803s	
1057/10550 (epoch 5.009), train_loss = 1.24748333, grad/param norm = 4.6352e-02, time/batch = 0.1801s	
1058/10550 (epoch 5.014), train_loss = 1.26098129, grad/param norm = 4.5656e-02, time/batch = 0.1800s	
1059/10550 (epoch 5.019), train_loss = 1.29994536, grad/param norm = 4.3352e-02, time/batch = 0.1799s	
1060/10550 (epoch 5.024), train_loss = 1.29352310, grad/param norm = 4.4308e-02, time/batch = 0.1799s	
1061/10550 (epoch 5.028), train_loss = 1.27686989, grad/param norm = 4.6364e-02, time/batch = 0.1813s	
1062/10550 (epoch 5.033), train_loss = 1.29638396, grad/param norm = 4.6029e-02, time/batch = 0.1797s	
1063/10550 (epoch 5.038), train_loss = 1.30925528, grad/param norm = 4.6929e-02, time/batch = 0.1801s	
1064/10550 (epoch 5.043), train_loss = 1.25934568, grad/param norm = 4.3601e-02, time/batch = 0.1805s	
1065/10550 (epoch 5.047), train_loss = 1.24198214, grad/param norm = 4.6345e-02, time/batch = 0.1799s	
1066/10550 (epoch 5.052), train_loss = 1.31754057, grad/param norm = 4.7602e-02, time/batch = 0.1804s	
1067/10550 (epoch 5.057), train_loss = 1.27287998, grad/param norm = 5.0071e-02, time/batch = 0.1800s	
1068/10550 (epoch 5.062), train_loss = 1.28392022, grad/param norm = 4.7595e-02, time/batch = 0.1797s	
1069/10550 (epoch 5.066), train_loss = 1.27187303, grad/param norm = 4.2645e-02, time/batch = 0.1806s	
1070/10550 (epoch 5.071), train_loss = 1.23418768, grad/param norm = 4.3643e-02, time/batch = 0.1806s	
1071/10550 (epoch 5.076), train_loss = 1.26116167, grad/param norm = 5.2039e-02, time/batch = 0.1814s	
1072/10550 (epoch 5.081), train_loss = 1.31200636, grad/param norm = 5.8689e-02, time/batch = 0.1798s	
1073/10550 (epoch 5.085), train_loss = 1.26739970, grad/param norm = 4.9796e-02, time/batch = 0.1795s	
1074/10550 (epoch 5.090), train_loss = 1.26541206, grad/param norm = 4.7839e-02, time/batch = 0.1800s	
1075/10550 (epoch 5.095), train_loss = 1.25943978, grad/param norm = 4.4665e-02, time/batch = 0.1802s	
1076/10550 (epoch 5.100), train_loss = 1.24944686, grad/param norm = 4.9268e-02, time/batch = 0.1804s	
1077/10550 (epoch 5.104), train_loss = 1.24972655, grad/param norm = 5.0632e-02, time/batch = 0.1798s	
1078/10550 (epoch 5.109), train_loss = 1.23898949, grad/param norm = 4.6546e-02, time/batch = 0.1795s	
1079/10550 (epoch 5.114), train_loss = 1.25986444, grad/param norm = 4.7407e-02, time/batch = 0.1803s	
1080/10550 (epoch 5.118), train_loss = 1.19476584, grad/param norm = 4.5802e-02, time/batch = 0.1799s	
1081/10550 (epoch 5.123), train_loss = 1.27551817, grad/param norm = 5.0175e-02, time/batch = 0.1812s	
1082/10550 (epoch 5.128), train_loss = 1.23257000, grad/param norm = 5.4381e-02, time/batch = 0.1798s	
1083/10550 (epoch 5.133), train_loss = 1.23332467, grad/param norm = 4.7768e-02, time/batch = 0.1800s	
1084/10550 (epoch 5.137), train_loss = 1.23713704, grad/param norm = 4.9212e-02, time/batch = 0.1798s	
1085/10550 (epoch 5.142), train_loss = 1.28133655, grad/param norm = 4.8017e-02, time/batch = 0.1800s	
1086/10550 (epoch 5.147), train_loss = 1.24551315, grad/param norm = 4.6082e-02, time/batch = 0.1798s	
1087/10550 (epoch 5.152), train_loss = 1.25370600, grad/param norm = 4.7298e-02, time/batch = 0.1802s	
1088/10550 (epoch 5.156), train_loss = 1.26479926, grad/param norm = 5.0106e-02, time/batch = 0.1798s	
1089/10550 (epoch 5.161), train_loss = 1.25204135, grad/param norm = 4.7357e-02, time/batch = 0.1804s	
1090/10550 (epoch 5.166), train_loss = 1.28708960, grad/param norm = 4.8865e-02, time/batch = 0.1805s	
1091/10550 (epoch 5.171), train_loss = 1.24861865, grad/param norm = 4.6806e-02, time/batch = 0.1809s	
1092/10550 (epoch 5.175), train_loss = 1.28902860, grad/param norm = 4.7926e-02, time/batch = 0.1798s	
1093/10550 (epoch 5.180), train_loss = 1.26777406, grad/param norm = 4.7011e-02, time/batch = 0.1802s	
1094/10550 (epoch 5.185), train_loss = 1.27136590, grad/param norm = 4.6330e-02, time/batch = 0.1800s	
1095/10550 (epoch 5.190), train_loss = 1.25013557, grad/param norm = 4.7349e-02, time/batch = 0.1800s	
1096/10550 (epoch 5.194), train_loss = 1.27822373, grad/param norm = 4.8130e-02, time/batch = 0.1800s	
1097/10550 (epoch 5.199), train_loss = 1.27936762, grad/param norm = 4.4365e-02, time/batch = 0.1804s	
1098/10550 (epoch 5.204), train_loss = 1.26880058, grad/param norm = 4.2531e-02, time/batch = 0.1797s	
1099/10550 (epoch 5.209), train_loss = 1.27194553, grad/param norm = 4.5436e-02, time/batch = 0.1803s	
1100/10550 (epoch 5.213), train_loss = 1.28489474, grad/param norm = 5.2813e-02, time/batch = 0.1804s	
1101/10550 (epoch 5.218), train_loss = 1.27116988, grad/param norm = 4.9718e-02, time/batch = 0.1815s	
1102/10550 (epoch 5.223), train_loss = 1.22897546, grad/param norm = 4.3340e-02, time/batch = 0.1797s	
1103/10550 (epoch 5.227), train_loss = 1.21424019, grad/param norm = 4.9982e-02, time/batch = 0.1801s	
1104/10550 (epoch 5.232), train_loss = 1.25139961, grad/param norm = 5.8202e-02, time/batch = 0.1805s	
1105/10550 (epoch 5.237), train_loss = 1.22013954, grad/param norm = 5.1793e-02, time/batch = 0.1800s	
1106/10550 (epoch 5.242), train_loss = 1.26432107, grad/param norm = 4.8017e-02, time/batch = 0.1801s	
1107/10550 (epoch 5.246), train_loss = 1.23003026, grad/param norm = 4.6493e-02, time/batch = 0.1795s	
1108/10550 (epoch 5.251), train_loss = 1.24633243, grad/param norm = 4.4665e-02, time/batch = 0.1797s	
1109/10550 (epoch 5.256), train_loss = 1.26759566, grad/param norm = 4.4114e-02, time/batch = 0.1798s	
1110/10550 (epoch 5.261), train_loss = 1.22274031, grad/param norm = 4.1800e-02, time/batch = 0.1803s	
1111/10550 (epoch 5.265), train_loss = 1.24629132, grad/param norm = 4.5945e-02, time/batch = 0.1810s	
1112/10550 (epoch 5.270), train_loss = 1.23143103, grad/param norm = 4.5333e-02, time/batch = 0.1799s	
1113/10550 (epoch 5.275), train_loss = 1.25005980, grad/param norm = 4.3588e-02, time/batch = 0.1803s	
1114/10550 (epoch 5.280), train_loss = 1.25252914, grad/param norm = 4.4867e-02, time/batch = 0.1799s	
1115/10550 (epoch 5.284), train_loss = 1.24658845, grad/param norm = 5.0966e-02, time/batch = 0.1800s	
1116/10550 (epoch 5.289), train_loss = 1.27077570, grad/param norm = 5.2630e-02, time/batch = 0.1799s	
1117/10550 (epoch 5.294), train_loss = 1.26329523, grad/param norm = 5.3239e-02, time/batch = 0.1797s	
1118/10550 (epoch 5.299), train_loss = 1.23030722, grad/param norm = 4.9343e-02, time/batch = 0.1798s	
1119/10550 (epoch 5.303), train_loss = 1.26853037, grad/param norm = 4.6726e-02, time/batch = 0.1804s	
1120/10550 (epoch 5.308), train_loss = 1.23744540, grad/param norm = 4.6544e-02, time/batch = 0.1801s	
1121/10550 (epoch 5.313), train_loss = 1.27261002, grad/param norm = 5.0973e-02, time/batch = 0.1815s	
1122/10550 (epoch 5.318), train_loss = 1.25366274, grad/param norm = 4.9057e-02, time/batch = 0.1795s	
1123/10550 (epoch 5.322), train_loss = 1.26965285, grad/param norm = 4.4070e-02, time/batch = 0.1806s	
1124/10550 (epoch 5.327), train_loss = 1.25242385, grad/param norm = 4.5774e-02, time/batch = 0.1794s	
1125/10550 (epoch 5.332), train_loss = 1.27768679, grad/param norm = 5.2330e-02, time/batch = 0.1802s	
1126/10550 (epoch 5.336), train_loss = 1.27152642, grad/param norm = 5.3841e-02, time/batch = 0.1806s	
1127/10550 (epoch 5.341), train_loss = 1.21998517, grad/param norm = 4.9207e-02, time/batch = 0.1796s	
1128/10550 (epoch 5.346), train_loss = 1.27753360, grad/param norm = 5.3582e-02, time/batch = 0.1808s	
1129/10550 (epoch 5.351), train_loss = 1.25304524, grad/param norm = 5.1889e-02, time/batch = 0.1803s	
1130/10550 (epoch 5.355), train_loss = 1.23230796, grad/param norm = 5.0451e-02, time/batch = 0.1802s	
1131/10550 (epoch 5.360), train_loss = 1.30090624, grad/param norm = 4.9483e-02, time/batch = 0.1813s	
1132/10550 (epoch 5.365), train_loss = 1.25233053, grad/param norm = 4.9255e-02, time/batch = 0.1795s	
1133/10550 (epoch 5.370), train_loss = 1.24973935, grad/param norm = 5.5474e-02, time/batch = 0.1806s	
1134/10550 (epoch 5.374), train_loss = 1.26159482, grad/param norm = 4.8091e-02, time/batch = 0.1794s	
1135/10550 (epoch 5.379), train_loss = 1.24817402, grad/param norm = 4.5238e-02, time/batch = 0.1802s	
1136/10550 (epoch 5.384), train_loss = 1.21644239, grad/param norm = 4.8428e-02, time/batch = 0.1805s	
1137/10550 (epoch 5.389), train_loss = 1.23719847, grad/param norm = 5.2656e-02, time/batch = 0.1804s	
1138/10550 (epoch 5.393), train_loss = 1.23551523, grad/param norm = 4.7122e-02, time/batch = 0.1795s	
1139/10550 (epoch 5.398), train_loss = 1.23271203, grad/param norm = 4.3838e-02, time/batch = 0.1804s	
1140/10550 (epoch 5.403), train_loss = 1.26400140, grad/param norm = 4.5169e-02, time/batch = 0.1802s	
1141/10550 (epoch 5.408), train_loss = 1.27525455, grad/param norm = 4.3725e-02, time/batch = 0.1813s	
1142/10550 (epoch 5.412), train_loss = 1.22707880, grad/param norm = 4.1084e-02, time/batch = 0.1793s	
1143/10550 (epoch 5.417), train_loss = 1.21399728, grad/param norm = 4.2600e-02, time/batch = 0.1800s	
1144/10550 (epoch 5.422), train_loss = 1.28098034, grad/param norm = 4.8086e-02, time/batch = 0.1801s	
1145/10550 (epoch 5.427), train_loss = 1.26087359, grad/param norm = 5.2210e-02, time/batch = 0.1803s	
1146/10550 (epoch 5.431), train_loss = 1.26663396, grad/param norm = 5.8138e-02, time/batch = 0.1804s	
1147/10550 (epoch 5.436), train_loss = 1.21841104, grad/param norm = 4.9348e-02, time/batch = 0.1802s	
1148/10550 (epoch 5.441), train_loss = 1.25436340, grad/param norm = 4.6908e-02, time/batch = 0.1797s	
1149/10550 (epoch 5.445), train_loss = 1.24463328, grad/param norm = 4.7314e-02, time/batch = 0.1802s	
1150/10550 (epoch 5.450), train_loss = 1.24553925, grad/param norm = 4.9164e-02, time/batch = 0.1803s	
1151/10550 (epoch 5.455), train_loss = 1.23952426, grad/param norm = 4.5374e-02, time/batch = 0.1812s	
1152/10550 (epoch 5.460), train_loss = 1.19057524, grad/param norm = 4.3632e-02, time/batch = 0.1797s	
1153/10550 (epoch 5.464), train_loss = 1.20774865, grad/param norm = 4.1858e-02, time/batch = 0.1800s	
1154/10550 (epoch 5.469), train_loss = 1.20188940, grad/param norm = 4.3247e-02, time/batch = 0.1801s	
1155/10550 (epoch 5.474), train_loss = 1.25153069, grad/param norm = 4.4192e-02, time/batch = 0.1805s	
1156/10550 (epoch 5.479), train_loss = 1.19364231, grad/param norm = 4.1617e-02, time/batch = 0.1798s	
1157/10550 (epoch 5.483), train_loss = 1.21359850, grad/param norm = 4.5007e-02, time/batch = 0.1799s	
1158/10550 (epoch 5.488), train_loss = 1.22414200, grad/param norm = 4.6473e-02, time/batch = 0.1793s	
1159/10550 (epoch 5.493), train_loss = 1.23086425, grad/param norm = 4.6900e-02, time/batch = 0.1801s	
1160/10550 (epoch 5.498), train_loss = 1.23094729, grad/param norm = 4.5473e-02, time/batch = 0.1801s	
1161/10550 (epoch 5.502), train_loss = 1.23788823, grad/param norm = 4.4430e-02, time/batch = 0.1812s	
1162/10550 (epoch 5.507), train_loss = 1.21073502, grad/param norm = 4.6552e-02, time/batch = 0.1802s	
1163/10550 (epoch 5.512), train_loss = 1.19802436, grad/param norm = 5.0302e-02, time/batch = 0.1796s	
1164/10550 (epoch 5.517), train_loss = 1.25243805, grad/param norm = 5.5393e-02, time/batch = 0.1804s	
1165/10550 (epoch 5.521), train_loss = 1.21728341, grad/param norm = 4.7362e-02, time/batch = 0.1801s	
1166/10550 (epoch 5.526), train_loss = 1.15011274, grad/param norm = 4.2488e-02, time/batch = 0.1797s	
1167/10550 (epoch 5.531), train_loss = 1.20607713, grad/param norm = 4.2926e-02, time/batch = 0.1798s	
1168/10550 (epoch 5.536), train_loss = 1.23384869, grad/param norm = 4.2184e-02, time/batch = 0.1793s	
1169/10550 (epoch 5.540), train_loss = 1.24167719, grad/param norm = 4.3745e-02, time/batch = 0.1805s	
1170/10550 (epoch 5.545), train_loss = 1.22851128, grad/param norm = 4.5275e-02, time/batch = 0.1800s	
1171/10550 (epoch 5.550), train_loss = 1.25918918, grad/param norm = 4.7856e-02, time/batch = 0.1813s	
1172/10550 (epoch 5.555), train_loss = 1.22759748, grad/param norm = 4.8123e-02, time/batch = 0.1798s	
1173/10550 (epoch 5.559), train_loss = 1.28348529, grad/param norm = 5.1041e-02, time/batch = 0.1800s	
1174/10550 (epoch 5.564), train_loss = 1.21849613, grad/param norm = 4.6299e-02, time/batch = 0.1801s	
1175/10550 (epoch 5.569), train_loss = 1.21670979, grad/param norm = 4.6528e-02, time/batch = 0.1800s	
1176/10550 (epoch 5.573), train_loss = 1.24376130, grad/param norm = 4.8813e-02, time/batch = 0.1802s	
1177/10550 (epoch 5.578), train_loss = 1.23798635, grad/param norm = 5.0189e-02, time/batch = 0.1802s	
1178/10550 (epoch 5.583), train_loss = 1.20997840, grad/param norm = 4.6910e-02, time/batch = 0.1794s	
1179/10550 (epoch 5.588), train_loss = 1.18918183, grad/param norm = 4.2022e-02, time/batch = 0.1805s	
1180/10550 (epoch 5.592), train_loss = 1.25517726, grad/param norm = 4.7482e-02, time/batch = 0.1798s	
1181/10550 (epoch 5.597), train_loss = 1.25064580, grad/param norm = 4.5661e-02, time/batch = 0.1810s	
1182/10550 (epoch 5.602), train_loss = 1.25507985, grad/param norm = 4.7644e-02, time/batch = 0.1798s	
1183/10550 (epoch 5.607), train_loss = 1.24546215, grad/param norm = 4.3855e-02, time/batch = 0.1800s	
1184/10550 (epoch 5.611), train_loss = 1.25916725, grad/param norm = 4.5267e-02, time/batch = 0.1797s	
1185/10550 (epoch 5.616), train_loss = 1.21039454, grad/param norm = 4.5561e-02, time/batch = 0.1799s	
1186/10550 (epoch 5.621), train_loss = 1.19833459, grad/param norm = 4.6050e-02, time/batch = 0.1804s	
1187/10550 (epoch 5.626), train_loss = 1.20772428, grad/param norm = 4.5557e-02, time/batch = 0.1803s	
1188/10550 (epoch 5.630), train_loss = 1.23825651, grad/param norm = 4.7662e-02, time/batch = 0.1802s	
1189/10550 (epoch 5.635), train_loss = 1.24080915, grad/param norm = 5.2666e-02, time/batch = 0.1800s	
1190/10550 (epoch 5.640), train_loss = 1.24974033, grad/param norm = 5.5681e-02, time/batch = 0.1800s	
1191/10550 (epoch 5.645), train_loss = 1.24262575, grad/param norm = 5.0294e-02, time/batch = 0.1814s	
1192/10550 (epoch 5.649), train_loss = 1.25214522, grad/param norm = 4.9380e-02, time/batch = 0.1796s	
1193/10550 (epoch 5.654), train_loss = 1.25115355, grad/param norm = 4.7453e-02, time/batch = 0.1801s	
1194/10550 (epoch 5.659), train_loss = 1.24760759, grad/param norm = 4.9846e-02, time/batch = 0.1803s	
1195/10550 (epoch 5.664), train_loss = 1.24393735, grad/param norm = 5.1912e-02, time/batch = 0.1799s	
1196/10550 (epoch 5.668), train_loss = 1.23884477, grad/param norm = 5.7636e-02, time/batch = 0.1800s	
1197/10550 (epoch 5.673), train_loss = 1.25690604, grad/param norm = 5.7572e-02, time/batch = 0.1798s	
1198/10550 (epoch 5.678), train_loss = 1.19011262, grad/param norm = 5.1205e-02, time/batch = 0.1799s	
1199/10550 (epoch 5.682), train_loss = 1.17995399, grad/param norm = 4.5084e-02, time/batch = 0.1801s	
1200/10550 (epoch 5.687), train_loss = 1.18238925, grad/param norm = 4.4886e-02, time/batch = 0.1802s	
1201/10550 (epoch 5.692), train_loss = 1.22664224, grad/param norm = 4.9933e-02, time/batch = 0.1812s	
1202/10550 (epoch 5.697), train_loss = 1.21890980, grad/param norm = 4.8617e-02, time/batch = 0.1801s	
1203/10550 (epoch 5.701), train_loss = 1.23741410, grad/param norm = 4.5117e-02, time/batch = 0.1794s	
1204/10550 (epoch 5.706), train_loss = 1.22259188, grad/param norm = 4.5865e-02, time/batch = 0.1803s	
1205/10550 (epoch 5.711), train_loss = 1.23441317, grad/param norm = 4.3114e-02, time/batch = 0.1801s	
1206/10550 (epoch 5.716), train_loss = 1.21958953, grad/param norm = 4.4609e-02, time/batch = 0.1800s	
1207/10550 (epoch 5.720), train_loss = 1.24058678, grad/param norm = 4.5870e-02, time/batch = 0.1800s	
1208/10550 (epoch 5.725), train_loss = 1.20163831, grad/param norm = 4.8073e-02, time/batch = 0.1797s	
1209/10550 (epoch 5.730), train_loss = 1.23507009, grad/param norm = 4.7883e-02, time/batch = 0.1803s	
1210/10550 (epoch 5.735), train_loss = 1.20762650, grad/param norm = 4.2877e-02, time/batch = 0.1801s	
1211/10550 (epoch 5.739), train_loss = 1.20116463, grad/param norm = 4.5003e-02, time/batch = 0.1810s	
1212/10550 (epoch 5.744), train_loss = 1.21334968, grad/param norm = 4.4728e-02, time/batch = 0.1799s	
1213/10550 (epoch 5.749), train_loss = 1.23032438, grad/param norm = 4.3681e-02, time/batch = 0.1802s	
1214/10550 (epoch 5.754), train_loss = 1.23531711, grad/param norm = 4.2644e-02, time/batch = 0.1799s	
1215/10550 (epoch 5.758), train_loss = 1.23403473, grad/param norm = 4.6238e-02, time/batch = 0.1803s	
1216/10550 (epoch 5.763), train_loss = 1.20547761, grad/param norm = 4.7492e-02, time/batch = 0.1800s	
1217/10550 (epoch 5.768), train_loss = 1.25395600, grad/param norm = 5.1090e-02, time/batch = 0.1801s	
1218/10550 (epoch 5.773), train_loss = 1.27615637, grad/param norm = 5.1634e-02, time/batch = 0.1799s	
1219/10550 (epoch 5.777), train_loss = 1.21652133, grad/param norm = 4.5322e-02, time/batch = 0.1803s	
1220/10550 (epoch 5.782), train_loss = 1.26490111, grad/param norm = 4.6457e-02, time/batch = 0.1799s	
1221/10550 (epoch 5.787), train_loss = 1.22784258, grad/param norm = 4.5037e-02, time/batch = 0.1810s	
1222/10550 (epoch 5.791), train_loss = 1.19758428, grad/param norm = 4.8295e-02, time/batch = 0.1800s	
1223/10550 (epoch 5.796), train_loss = 1.21751667, grad/param norm = 5.5923e-02, time/batch = 0.1799s	
1224/10550 (epoch 5.801), train_loss = 1.23376143, grad/param norm = 5.9237e-02, time/batch = 0.1802s	
1225/10550 (epoch 5.806), train_loss = 1.25755440, grad/param norm = 5.2424e-02, time/batch = 0.1801s	
1226/10550 (epoch 5.810), train_loss = 1.27914190, grad/param norm = 5.0377e-02, time/batch = 0.1795s	
1227/10550 (epoch 5.815), train_loss = 1.21810842, grad/param norm = 4.4612e-02, time/batch = 0.1801s	
1228/10550 (epoch 5.820), train_loss = 1.23001617, grad/param norm = 4.5554e-02, time/batch = 0.1802s	
1229/10550 (epoch 5.825), train_loss = 1.21352757, grad/param norm = 4.8352e-02, time/batch = 0.1799s	
1230/10550 (epoch 5.829), train_loss = 1.21100203, grad/param norm = 4.9805e-02, time/batch = 0.1797s	
1231/10550 (epoch 5.834), train_loss = 1.23217785, grad/param norm = 4.5219e-02, time/batch = 0.1811s	
1232/10550 (epoch 5.839), train_loss = 1.19648867, grad/param norm = 4.5016e-02, time/batch = 0.1796s	
1233/10550 (epoch 5.844), train_loss = 1.22275236, grad/param norm = 4.5954e-02, time/batch = 0.1829s	
1234/10550 (epoch 5.848), train_loss = 1.20398209, grad/param norm = 4.8664e-02, time/batch = 0.1799s	
1235/10550 (epoch 5.853), train_loss = 1.22445279, grad/param norm = 4.5557e-02, time/batch = 0.1803s	
1236/10550 (epoch 5.858), train_loss = 1.23332396, grad/param norm = 4.5925e-02, time/batch = 0.1799s	
1237/10550 (epoch 5.863), train_loss = 1.20775738, grad/param norm = 5.0582e-02, time/batch = 0.1803s	
1238/10550 (epoch 5.867), train_loss = 1.24296235, grad/param norm = 5.0852e-02, time/batch = 0.1797s	
1239/10550 (epoch 5.872), train_loss = 1.22597529, grad/param norm = 4.6982e-02, time/batch = 0.1800s	
1240/10550 (epoch 5.877), train_loss = 1.17835153, grad/param norm = 4.7996e-02, time/batch = 0.1797s	
1241/10550 (epoch 5.882), train_loss = 1.20836960, grad/param norm = 4.9640e-02, time/batch = 0.1815s	
1242/10550 (epoch 5.886), train_loss = 1.22797479, grad/param norm = 4.5572e-02, time/batch = 0.1801s	
1243/10550 (epoch 5.891), train_loss = 1.22732218, grad/param norm = 4.5394e-02, time/batch = 0.1797s	
1244/10550 (epoch 5.896), train_loss = 1.20617004, grad/param norm = 4.6949e-02, time/batch = 0.1797s	
1245/10550 (epoch 5.900), train_loss = 1.19369563, grad/param norm = 4.8511e-02, time/batch = 0.1796s	
1246/10550 (epoch 5.905), train_loss = 1.18698772, grad/param norm = 4.7034e-02, time/batch = 0.1792s	
1247/10550 (epoch 5.910), train_loss = 1.18353330, grad/param norm = 4.5315e-02, time/batch = 0.1798s	
1248/10550 (epoch 5.915), train_loss = 1.20684872, grad/param norm = 4.5262e-02, time/batch = 0.1794s	
1249/10550 (epoch 5.919), train_loss = 1.20778960, grad/param norm = 4.6114e-02, time/batch = 0.1805s	
1250/10550 (epoch 5.924), train_loss = 1.22924887, grad/param norm = 4.9139e-02, time/batch = 0.1801s	
1251/10550 (epoch 5.929), train_loss = 1.20335891, grad/param norm = 4.7749e-02, time/batch = 0.1811s	
1252/10550 (epoch 5.934), train_loss = 1.22060906, grad/param norm = 4.4073e-02, time/batch = 0.1794s	
1253/10550 (epoch 5.938), train_loss = 1.20764374, grad/param norm = 4.3321e-02, time/batch = 0.1797s	
1254/10550 (epoch 5.943), train_loss = 1.22173934, grad/param norm = 4.7837e-02, time/batch = 0.1796s	
1255/10550 (epoch 5.948), train_loss = 1.24159205, grad/param norm = 5.2087e-02, time/batch = 0.1802s	
1256/10550 (epoch 5.953), train_loss = 1.27175587, grad/param norm = 5.8654e-02, time/batch = 0.1801s	
1257/10550 (epoch 5.957), train_loss = 1.24378356, grad/param norm = 5.6088e-02, time/batch = 0.1798s	
1258/10550 (epoch 5.962), train_loss = 1.20717112, grad/param norm = 4.7320e-02, time/batch = 0.1797s	
1259/10550 (epoch 5.967), train_loss = 1.20744740, grad/param norm = 4.2907e-02, time/batch = 0.1801s	
1260/10550 (epoch 5.972), train_loss = 1.19038150, grad/param norm = 4.3323e-02, time/batch = 0.1799s	
1261/10550 (epoch 5.976), train_loss = 1.21503364, grad/param norm = 4.5290e-02, time/batch = 0.1813s	
1262/10550 (epoch 5.981), train_loss = 1.22065969, grad/param norm = 4.7018e-02, time/batch = 0.1799s	
1263/10550 (epoch 5.986), train_loss = 1.20038104, grad/param norm = 4.4183e-02, time/batch = 0.1801s	
1264/10550 (epoch 5.991), train_loss = 1.26521450, grad/param norm = 4.7783e-02, time/batch = 0.1802s	
1265/10550 (epoch 5.995), train_loss = 1.22253591, grad/param norm = 5.1700e-02, time/batch = 0.1800s	
1266/10550 (epoch 6.000), train_loss = 1.22770189, grad/param norm = 4.7219e-02, time/batch = 0.1800s	
1267/10550 (epoch 6.005), train_loss = 1.40918431, grad/param norm = 4.9889e-02, time/batch = 0.1799s	
1268/10550 (epoch 6.009), train_loss = 1.18947821, grad/param norm = 4.6526e-02, time/batch = 0.1800s	
1269/10550 (epoch 6.014), train_loss = 1.19759146, grad/param norm = 4.6412e-02, time/batch = 0.1804s	
1270/10550 (epoch 6.019), train_loss = 1.23817741, grad/param norm = 4.5139e-02, time/batch = 0.1801s	
1271/10550 (epoch 6.024), train_loss = 1.23164961, grad/param norm = 4.6798e-02, time/batch = 0.1812s	
1272/10550 (epoch 6.028), train_loss = 1.21595644, grad/param norm = 4.6157e-02, time/batch = 0.1796s	
1273/10550 (epoch 6.033), train_loss = 1.22830763, grad/param norm = 4.4675e-02, time/batch = 0.1801s	
1274/10550 (epoch 6.038), train_loss = 1.24275553, grad/param norm = 4.6380e-02, time/batch = 0.1797s	
1275/10550 (epoch 6.043), train_loss = 1.19142718, grad/param norm = 4.3075e-02, time/batch = 0.1803s	
1276/10550 (epoch 6.047), train_loss = 1.18074105, grad/param norm = 4.4819e-02, time/batch = 0.1798s	
1277/10550 (epoch 6.052), train_loss = 1.25143229, grad/param norm = 4.6733e-02, time/batch = 0.1798s	
1278/10550 (epoch 6.057), train_loss = 1.21251968, grad/param norm = 4.6979e-02, time/batch = 0.1798s	
1279/10550 (epoch 6.062), train_loss = 1.22375528, grad/param norm = 4.7309e-02, time/batch = 0.1796s	
1280/10550 (epoch 6.066), train_loss = 1.21766599, grad/param norm = 4.5119e-02, time/batch = 0.1797s	
1281/10550 (epoch 6.071), train_loss = 1.17560042, grad/param norm = 4.4789e-02, time/batch = 0.1815s	
1282/10550 (epoch 6.076), train_loss = 1.19610791, grad/param norm = 4.9783e-02, time/batch = 0.1796s	
1283/10550 (epoch 6.081), train_loss = 1.23737493, grad/param norm = 5.0785e-02, time/batch = 0.1795s	
1284/10550 (epoch 6.085), train_loss = 1.20439036, grad/param norm = 4.3504e-02, time/batch = 0.1800s	
1285/10550 (epoch 6.090), train_loss = 1.19677826, grad/param norm = 4.5379e-02, time/batch = 0.1801s	
1286/10550 (epoch 6.095), train_loss = 1.20273154, grad/param norm = 4.4710e-02, time/batch = 0.1798s	
1287/10550 (epoch 6.100), train_loss = 1.18652892, grad/param norm = 4.7760e-02, time/batch = 0.1798s	
1288/10550 (epoch 6.104), train_loss = 1.17832204, grad/param norm = 4.8376e-02, time/batch = 0.1796s	
1289/10550 (epoch 6.109), train_loss = 1.17413106, grad/param norm = 4.5954e-02, time/batch = 0.1805s	
1290/10550 (epoch 6.114), train_loss = 1.19611927, grad/param norm = 4.4232e-02, time/batch = 0.1800s	
1291/10550 (epoch 6.118), train_loss = 1.13547454, grad/param norm = 4.3348e-02, time/batch = 0.1812s	
1292/10550 (epoch 6.123), train_loss = 1.21653812, grad/param norm = 4.6339e-02, time/batch = 0.1797s	
1293/10550 (epoch 6.128), train_loss = 1.16968427, grad/param norm = 4.6986e-02, time/batch = 0.1799s	
1294/10550 (epoch 6.133), train_loss = 1.17060686, grad/param norm = 4.8245e-02, time/batch = 0.1800s	
1295/10550 (epoch 6.137), train_loss = 1.17624983, grad/param norm = 5.3142e-02, time/batch = 0.1797s	
1296/10550 (epoch 6.142), train_loss = 1.22407809, grad/param norm = 5.3981e-02, time/batch = 0.1801s	
1297/10550 (epoch 6.147), train_loss = 1.19073550, grad/param norm = 5.0222e-02, time/batch = 0.1805s	
1298/10550 (epoch 6.152), train_loss = 1.20000798, grad/param norm = 5.0551e-02, time/batch = 0.1795s	
1299/10550 (epoch 6.156), train_loss = 1.20091221, grad/param norm = 4.8540e-02, time/batch = 0.1795s	
1300/10550 (epoch 6.161), train_loss = 1.18887468, grad/param norm = 4.8181e-02, time/batch = 0.1802s	
1301/10550 (epoch 6.166), train_loss = 1.21961223, grad/param norm = 4.7035e-02, time/batch = 0.1808s	
1302/10550 (epoch 6.171), train_loss = 1.18599380, grad/param norm = 4.6036e-02, time/batch = 0.1797s	
1303/10550 (epoch 6.175), train_loss = 1.22627956, grad/param norm = 4.8114e-02, time/batch = 0.1794s	
1304/10550 (epoch 6.180), train_loss = 1.20216184, grad/param norm = 4.9662e-02, time/batch = 0.1801s	
1305/10550 (epoch 6.185), train_loss = 1.21107831, grad/param norm = 5.0088e-02, time/batch = 0.1799s	
1306/10550 (epoch 6.190), train_loss = 1.19112649, grad/param norm = 5.2877e-02, time/batch = 0.1802s	
1307/10550 (epoch 6.194), train_loss = 1.22005828, grad/param norm = 5.1817e-02, time/batch = 0.1799s	
1308/10550 (epoch 6.199), train_loss = 1.22052707, grad/param norm = 4.6794e-02, time/batch = 0.1793s	
1309/10550 (epoch 6.204), train_loss = 1.20219876, grad/param norm = 4.3942e-02, time/batch = 0.1798s	
1310/10550 (epoch 6.209), train_loss = 1.21274570, grad/param norm = 4.4628e-02, time/batch = 0.1800s	
1311/10550 (epoch 6.213), train_loss = 1.21228492, grad/param norm = 4.7967e-02, time/batch = 0.1813s	
1312/10550 (epoch 6.218), train_loss = 1.22021310, grad/param norm = 5.6315e-02, time/batch = 0.1800s	
1313/10550 (epoch 6.223), train_loss = 1.17634444, grad/param norm = 4.9204e-02, time/batch = 0.1794s	
1314/10550 (epoch 6.227), train_loss = 1.15379818, grad/param norm = 4.6294e-02, time/batch = 0.1797s	
1315/10550 (epoch 6.232), train_loss = 1.18271231, grad/param norm = 4.8302e-02, time/batch = 0.1796s	
1316/10550 (epoch 6.237), train_loss = 1.16698669, grad/param norm = 4.6389e-02, time/batch = 0.1800s	
1317/10550 (epoch 6.242), train_loss = 1.19774017, grad/param norm = 4.4839e-02, time/batch = 0.1803s	
1318/10550 (epoch 6.246), train_loss = 1.17081277, grad/param norm = 4.4854e-02, time/batch = 0.1801s	
1319/10550 (epoch 6.251), train_loss = 1.18799807, grad/param norm = 4.7291e-02, time/batch = 0.1799s	
1320/10550 (epoch 6.256), train_loss = 1.20545102, grad/param norm = 4.9085e-02, time/batch = 0.1798s	
1321/10550 (epoch 6.261), train_loss = 1.16371605, grad/param norm = 5.0146e-02, time/batch = 0.1812s	
1322/10550 (epoch 6.265), train_loss = 1.19587153, grad/param norm = 4.8824e-02, time/batch = 0.1794s	
1323/10550 (epoch 6.270), train_loss = 1.17570837, grad/param norm = 4.5135e-02, time/batch = 0.1809s	
1324/10550 (epoch 6.275), train_loss = 1.19114036, grad/param norm = 4.3931e-02, time/batch = 0.1801s	
1325/10550 (epoch 6.280), train_loss = 1.19242990, grad/param norm = 4.4388e-02, time/batch = 0.1800s	
1326/10550 (epoch 6.284), train_loss = 1.18548204, grad/param norm = 4.5842e-02, time/batch = 0.1799s	
1327/10550 (epoch 6.289), train_loss = 1.20465121, grad/param norm = 4.9559e-02, time/batch = 0.1795s	
1328/10550 (epoch 6.294), train_loss = 1.19120704, grad/param norm = 5.0249e-02, time/batch = 0.1798s	
1329/10550 (epoch 6.299), train_loss = 1.16185800, grad/param norm = 4.7320e-02, time/batch = 0.1801s	
1330/10550 (epoch 6.303), train_loss = 1.20907226, grad/param norm = 4.8261e-02, time/batch = 0.1797s	
1331/10550 (epoch 6.308), train_loss = 1.17853650, grad/param norm = 4.7842e-02, time/batch = 0.1810s	
1332/10550 (epoch 6.313), train_loss = 1.20929583, grad/param norm = 5.2520e-02, time/batch = 0.1797s	
1333/10550 (epoch 6.318), train_loss = 1.18234784, grad/param norm = 4.6612e-02, time/batch = 0.1796s	
1334/10550 (epoch 6.322), train_loss = 1.20627450, grad/param norm = 4.9238e-02, time/batch = 0.1799s	
1335/10550 (epoch 6.327), train_loss = 1.20200825, grad/param norm = 5.2238e-02, time/batch = 0.1808s	
1336/10550 (epoch 6.332), train_loss = 1.22127203, grad/param norm = 5.2042e-02, time/batch = 0.1795s	
1337/10550 (epoch 6.336), train_loss = 1.20091901, grad/param norm = 4.9194e-02, time/batch = 0.1797s	
1338/10550 (epoch 6.341), train_loss = 1.16003792, grad/param norm = 4.8661e-02, time/batch = 0.1796s	
1339/10550 (epoch 6.346), train_loss = 1.20734895, grad/param norm = 4.9539e-02, time/batch = 0.1803s	
1340/10550 (epoch 6.351), train_loss = 1.19120599, grad/param norm = 5.0575e-02, time/batch = 0.1799s	
1341/10550 (epoch 6.355), train_loss = 1.17104869, grad/param norm = 5.0711e-02, time/batch = 0.1814s	
1342/10550 (epoch 6.360), train_loss = 1.23192708, grad/param norm = 4.8106e-02, time/batch = 0.1795s	
1343/10550 (epoch 6.365), train_loss = 1.19380764, grad/param norm = 4.6477e-02, time/batch = 0.1802s	
1344/10550 (epoch 6.370), train_loss = 1.18491847, grad/param norm = 4.9355e-02, time/batch = 0.1802s	
1345/10550 (epoch 6.374), train_loss = 1.20325920, grad/param norm = 4.8903e-02, time/batch = 0.1799s	
1346/10550 (epoch 6.379), train_loss = 1.19502590, grad/param norm = 5.0680e-02, time/batch = 0.1802s	
1347/10550 (epoch 6.384), train_loss = 1.15870894, grad/param norm = 5.5021e-02, time/batch = 0.1796s	
1348/10550 (epoch 6.389), train_loss = 1.18096298, grad/param norm = 5.5153e-02, time/batch = 0.1800s	
1349/10550 (epoch 6.393), train_loss = 1.18221860, grad/param norm = 4.8403e-02, time/batch = 0.1803s	
1350/10550 (epoch 6.398), train_loss = 1.17222823, grad/param norm = 4.5395e-02, time/batch = 0.1799s	
1351/10550 (epoch 6.403), train_loss = 1.20513192, grad/param norm = 4.5338e-02, time/batch = 0.1814s	
1352/10550 (epoch 6.408), train_loss = 1.21483006, grad/param norm = 4.5721e-02, time/batch = 0.1794s	
1353/10550 (epoch 6.412), train_loss = 1.17101686, grad/param norm = 4.3101e-02, time/batch = 0.1792s	
1354/10550 (epoch 6.417), train_loss = 1.16290235, grad/param norm = 4.4570e-02, time/batch = 0.1801s	
1355/10550 (epoch 6.422), train_loss = 1.20855544, grad/param norm = 4.7788e-02, time/batch = 0.1799s	
1356/10550 (epoch 6.427), train_loss = 1.20074648, grad/param norm = 4.7966e-02, time/batch = 0.1802s	
1357/10550 (epoch 6.431), train_loss = 1.19550910, grad/param norm = 5.2038e-02, time/batch = 0.1801s	
1358/10550 (epoch 6.436), train_loss = 1.16614204, grad/param norm = 4.9313e-02, time/batch = 0.1795s	
1359/10550 (epoch 6.441), train_loss = 1.18930774, grad/param norm = 4.6742e-02, time/batch = 0.1804s	
1360/10550 (epoch 6.445), train_loss = 1.19799497, grad/param norm = 5.1475e-02, time/batch = 0.1800s	
1361/10550 (epoch 6.450), train_loss = 1.19083650, grad/param norm = 4.9866e-02, time/batch = 0.1809s	
1362/10550 (epoch 6.455), train_loss = 1.18394983, grad/param norm = 4.7525e-02, time/batch = 0.1798s	
1363/10550 (epoch 6.460), train_loss = 1.13162361, grad/param norm = 4.4490e-02, time/batch = 0.1803s	
1364/10550 (epoch 6.464), train_loss = 1.15244259, grad/param norm = 4.4630e-02, time/batch = 0.1796s	
1365/10550 (epoch 6.469), train_loss = 1.14993722, grad/param norm = 4.5814e-02, time/batch = 0.1804s	
1366/10550 (epoch 6.474), train_loss = 1.19095750, grad/param norm = 4.6981e-02, time/batch = 0.1797s	
1367/10550 (epoch 6.479), train_loss = 1.14096263, grad/param norm = 4.3943e-02, time/batch = 0.1799s	
1368/10550 (epoch 6.483), train_loss = 1.15443999, grad/param norm = 4.6186e-02, time/batch = 0.1798s	
1369/10550 (epoch 6.488), train_loss = 1.16463224, grad/param norm = 4.5868e-02, time/batch = 0.1801s	
1370/10550 (epoch 6.493), train_loss = 1.16720213, grad/param norm = 4.8151e-02, time/batch = 0.1801s	
1371/10550 (epoch 6.498), train_loss = 1.17362412, grad/param norm = 5.0673e-02, time/batch = 0.1816s	
1372/10550 (epoch 6.502), train_loss = 1.18362244, grad/param norm = 5.0716e-02, time/batch = 0.1796s	
1373/10550 (epoch 6.507), train_loss = 1.15580853, grad/param norm = 4.5784e-02, time/batch = 0.1798s	
1374/10550 (epoch 6.512), train_loss = 1.13195919, grad/param norm = 4.7394e-02, time/batch = 0.1802s	
1375/10550 (epoch 6.517), train_loss = 1.17803874, grad/param norm = 4.9679e-02, time/batch = 0.1801s	
1376/10550 (epoch 6.521), train_loss = 1.15878016, grad/param norm = 4.5259e-02, time/batch = 0.1794s	
1377/10550 (epoch 6.526), train_loss = 1.09519496, grad/param norm = 4.3886e-02, time/batch = 0.1800s	
1378/10550 (epoch 6.531), train_loss = 1.14597107, grad/param norm = 4.7008e-02, time/batch = 0.1795s	
1379/10550 (epoch 6.536), train_loss = 1.18050039, grad/param norm = 4.8606e-02, time/batch = 0.1799s	
1380/10550 (epoch 6.540), train_loss = 1.18027038, grad/param norm = 4.7069e-02, time/batch = 0.1801s	
1381/10550 (epoch 6.545), train_loss = 1.16995715, grad/param norm = 4.5320e-02, time/batch = 0.1798s	
1382/10550 (epoch 6.550), train_loss = 1.19133324, grad/param norm = 4.6753e-02, time/batch = 0.1799s	
1383/10550 (epoch 6.555), train_loss = 1.17144277, grad/param norm = 4.5844e-02, time/batch = 0.1800s	
1384/10550 (epoch 6.559), train_loss = 1.21783608, grad/param norm = 5.0100e-02, time/batch = 0.1798s	
1385/10550 (epoch 6.564), train_loss = 1.16200807, grad/param norm = 4.8850e-02, time/batch = 0.1799s	
1386/10550 (epoch 6.569), train_loss = 1.16146007, grad/param norm = 5.1396e-02, time/batch = 0.1798s	
1387/10550 (epoch 6.573), train_loss = 1.18694083, grad/param norm = 5.0726e-02, time/batch = 0.1807s	
1388/10550 (epoch 6.578), train_loss = 1.18140578, grad/param norm = 5.0572e-02, time/batch = 0.1782s	
1389/10550 (epoch 6.583), train_loss = 1.15339943, grad/param norm = 4.7210e-02, time/batch = 0.1802s	
1390/10550 (epoch 6.588), train_loss = 1.12799734, grad/param norm = 4.1394e-02, time/batch = 0.1797s	
1391/10550 (epoch 6.592), train_loss = 1.18642745, grad/param norm = 4.5218e-02, time/batch = 0.1813s	
1392/10550 (epoch 6.597), train_loss = 1.18095729, grad/param norm = 4.9021e-02, time/batch = 0.1798s	
1393/10550 (epoch 6.602), train_loss = 1.19487315, grad/param norm = 5.3932e-02, time/batch = 0.1799s	
1394/10550 (epoch 6.607), train_loss = 1.19014629, grad/param norm = 5.2999e-02, time/batch = 0.1801s	
1395/10550 (epoch 6.611), train_loss = 1.20819844, grad/param norm = 5.2188e-02, time/batch = 0.1803s	
1396/10550 (epoch 6.616), train_loss = 1.15577279, grad/param norm = 4.8400e-02, time/batch = 0.1796s	
1397/10550 (epoch 6.621), train_loss = 1.13773424, grad/param norm = 4.6955e-02, time/batch = 0.1801s	
1398/10550 (epoch 6.626), train_loss = 1.15600246, grad/param norm = 4.7146e-02, time/batch = 0.1797s	
1399/10550 (epoch 6.630), train_loss = 1.18072012, grad/param norm = 4.7755e-02, time/batch = 0.1803s	
1400/10550 (epoch 6.635), train_loss = 1.18162219, grad/param norm = 4.9273e-02, time/batch = 0.1802s	
1401/10550 (epoch 6.640), train_loss = 1.18071825, grad/param norm = 5.1847e-02, time/batch = 0.1811s	
1402/10550 (epoch 6.645), train_loss = 1.18372409, grad/param norm = 5.1278e-02, time/batch = 0.1798s	
1403/10550 (epoch 6.649), train_loss = 1.19740309, grad/param norm = 5.0291e-02, time/batch = 0.1799s	
1404/10550 (epoch 6.654), train_loss = 1.18853341, grad/param norm = 4.4826e-02, time/batch = 0.1804s	
1405/10550 (epoch 6.659), train_loss = 1.18462537, grad/param norm = 4.6455e-02, time/batch = 0.1807s	
1406/10550 (epoch 6.664), train_loss = 1.17527614, grad/param norm = 4.6405e-02, time/batch = 0.1798s	
1407/10550 (epoch 6.668), train_loss = 1.15954924, grad/param norm = 4.6570e-02, time/batch = 0.1800s	
1408/10550 (epoch 6.673), train_loss = 1.18704629, grad/param norm = 4.7503e-02, time/batch = 0.1796s	
1409/10550 (epoch 6.678), train_loss = 1.12388042, grad/param norm = 4.6762e-02, time/batch = 0.1803s	
1410/10550 (epoch 6.682), train_loss = 1.13414067, grad/param norm = 4.7649e-02, time/batch = 0.1798s	
1411/10550 (epoch 6.687), train_loss = 1.12719260, grad/param norm = 4.9952e-02, time/batch = 0.1812s	
1412/10550 (epoch 6.692), train_loss = 1.16745749, grad/param norm = 4.7753e-02, time/batch = 0.1798s	
1413/10550 (epoch 6.697), train_loss = 1.15895081, grad/param norm = 4.7150e-02, time/batch = 0.1797s	
1414/10550 (epoch 6.701), train_loss = 1.17565732, grad/param norm = 4.5695e-02, time/batch = 0.1799s	
1415/10550 (epoch 6.706), train_loss = 1.15861472, grad/param norm = 4.7686e-02, time/batch = 0.1804s	
1416/10550 (epoch 6.711), train_loss = 1.17529182, grad/param norm = 4.5722e-02, time/batch = 0.1797s	
1417/10550 (epoch 6.716), train_loss = 1.16468578, grad/param norm = 4.5160e-02, time/batch = 0.1801s	
1418/10550 (epoch 6.720), train_loss = 1.18165647, grad/param norm = 4.5657e-02, time/batch = 0.1794s	
1419/10550 (epoch 6.725), train_loss = 1.14455626, grad/param norm = 4.7940e-02, time/batch = 0.1802s	
1420/10550 (epoch 6.730), train_loss = 1.17561002, grad/param norm = 4.9111e-02, time/batch = 0.1796s	
1421/10550 (epoch 6.735), train_loss = 1.15325902, grad/param norm = 4.8453e-02, time/batch = 0.1810s	
1422/10550 (epoch 6.739), train_loss = 1.14727828, grad/param norm = 5.2490e-02, time/batch = 0.1797s	
1423/10550 (epoch 6.744), train_loss = 1.16052580, grad/param norm = 5.3265e-02, time/batch = 0.1802s	
1424/10550 (epoch 6.749), train_loss = 1.17179264, grad/param norm = 4.5867e-02, time/batch = 0.1801s	
1425/10550 (epoch 6.754), train_loss = 1.17779836, grad/param norm = 4.4148e-02, time/batch = 0.1804s	
1426/10550 (epoch 6.758), train_loss = 1.17601054, grad/param norm = 4.9622e-02, time/batch = 0.1804s	
1427/10550 (epoch 6.763), train_loss = 1.14093154, grad/param norm = 4.9852e-02, time/batch = 0.1800s	
1428/10550 (epoch 6.768), train_loss = 1.19220374, grad/param norm = 4.6296e-02, time/batch = 0.1798s	
1429/10550 (epoch 6.773), train_loss = 1.20384720, grad/param norm = 4.6579e-02, time/batch = 0.1802s	
1430/10550 (epoch 6.777), train_loss = 1.15987398, grad/param norm = 5.0984e-02, time/batch = 0.1802s	
1431/10550 (epoch 6.782), train_loss = 1.21431166, grad/param norm = 5.3594e-02, time/batch = 0.1815s	
1432/10550 (epoch 6.787), train_loss = 1.17513994, grad/param norm = 5.2390e-02, time/batch = 0.1797s	
1433/10550 (epoch 6.791), train_loss = 1.14650025, grad/param norm = 4.9506e-02, time/batch = 0.1795s	
1434/10550 (epoch 6.796), train_loss = 1.16010643, grad/param norm = 4.9772e-02, time/batch = 0.1801s	
1435/10550 (epoch 6.801), train_loss = 1.16382197, grad/param norm = 4.9986e-02, time/batch = 0.1799s	
1436/10550 (epoch 6.806), train_loss = 1.19692018, grad/param norm = 4.6801e-02, time/batch = 0.1797s	
1437/10550 (epoch 6.810), train_loss = 1.21715371, grad/param norm = 4.7209e-02, time/batch = 0.1800s	
1438/10550 (epoch 6.815), train_loss = 1.16112194, grad/param norm = 4.6690e-02, time/batch = 0.1794s	
1439/10550 (epoch 6.820), train_loss = 1.17367625, grad/param norm = 4.6045e-02, time/batch = 0.1804s	
1440/10550 (epoch 6.825), train_loss = 1.16057255, grad/param norm = 4.4779e-02, time/batch = 0.1798s	
1441/10550 (epoch 6.829), train_loss = 1.14212673, grad/param norm = 4.2618e-02, time/batch = 0.1809s	
1442/10550 (epoch 6.834), train_loss = 1.16490632, grad/param norm = 4.8325e-02, time/batch = 0.1795s	
1443/10550 (epoch 6.839), train_loss = 1.14933522, grad/param norm = 5.1445e-02, time/batch = 0.1801s	
1444/10550 (epoch 6.844), train_loss = 1.17256531, grad/param norm = 5.4856e-02, time/batch = 0.1802s	
1445/10550 (epoch 6.848), train_loss = 1.16349984, grad/param norm = 5.3783e-02, time/batch = 0.1802s	
1446/10550 (epoch 6.853), train_loss = 1.17364060, grad/param norm = 4.9107e-02, time/batch = 0.1798s	
1447/10550 (epoch 6.858), train_loss = 1.18461393, grad/param norm = 5.5052e-02, time/batch = 0.1802s	
1448/10550 (epoch 6.863), train_loss = 1.15801324, grad/param norm = 5.1174e-02, time/batch = 0.1797s	
1449/10550 (epoch 6.867), train_loss = 1.18395224, grad/param norm = 4.6997e-02, time/batch = 0.1797s	
1450/10550 (epoch 6.872), train_loss = 1.16644421, grad/param norm = 4.8944e-02, time/batch = 0.1799s	
1451/10550 (epoch 6.877), train_loss = 1.12335675, grad/param norm = 4.8236e-02, time/batch = 0.1817s	
1452/10550 (epoch 6.882), train_loss = 1.14913960, grad/param norm = 4.9446e-02, time/batch = 0.1796s	
1453/10550 (epoch 6.886), train_loss = 1.17913204, grad/param norm = 4.8477e-02, time/batch = 0.1793s	
1454/10550 (epoch 6.891), train_loss = 1.17089887, grad/param norm = 4.9411e-02, time/batch = 0.1799s	
1455/10550 (epoch 6.896), train_loss = 1.14131565, grad/param norm = 4.5772e-02, time/batch = 0.1804s	
1456/10550 (epoch 6.900), train_loss = 1.13238909, grad/param norm = 4.5552e-02, time/batch = 0.1793s	
1457/10550 (epoch 6.905), train_loss = 1.12569382, grad/param norm = 4.4723e-02, time/batch = 0.1798s	
1458/10550 (epoch 6.910), train_loss = 1.12938765, grad/param norm = 4.5950e-02, time/batch = 0.1794s	
1459/10550 (epoch 6.915), train_loss = 1.15124533, grad/param norm = 4.7720e-02, time/batch = 0.1796s	
1460/10550 (epoch 6.919), train_loss = 1.15293712, grad/param norm = 4.6957e-02, time/batch = 0.1800s	
1461/10550 (epoch 6.924), train_loss = 1.17736241, grad/param norm = 5.0965e-02, time/batch = 0.1810s	
1462/10550 (epoch 6.929), train_loss = 1.15303838, grad/param norm = 4.5946e-02, time/batch = 0.1798s	
1463/10550 (epoch 6.934), train_loss = 1.16777212, grad/param norm = 4.8791e-02, time/batch = 0.1797s	
1464/10550 (epoch 6.938), train_loss = 1.15551270, grad/param norm = 5.2721e-02, time/batch = 0.1798s	
1465/10550 (epoch 6.943), train_loss = 1.16065879, grad/param norm = 5.0428e-02, time/batch = 0.1800s	
1466/10550 (epoch 6.948), train_loss = 1.17774117, grad/param norm = 4.6928e-02, time/batch = 0.1798s	
1467/10550 (epoch 6.953), train_loss = 1.19427222, grad/param norm = 4.7963e-02, time/batch = 0.1805s	
1468/10550 (epoch 6.957), train_loss = 1.17074902, grad/param norm = 4.9480e-02, time/batch = 0.1792s	
1469/10550 (epoch 6.962), train_loss = 1.15494192, grad/param norm = 5.2720e-02, time/batch = 0.1801s	
1470/10550 (epoch 6.967), train_loss = 1.16400239, grad/param norm = 5.2099e-02, time/batch = 0.1804s	
1471/10550 (epoch 6.972), train_loss = 1.13866531, grad/param norm = 4.8783e-02, time/batch = 0.1816s	
1472/10550 (epoch 6.976), train_loss = 1.15194869, grad/param norm = 4.5931e-02, time/batch = 0.1795s	
1473/10550 (epoch 6.981), train_loss = 1.16378708, grad/param norm = 5.0038e-02, time/batch = 0.1794s	
1474/10550 (epoch 6.986), train_loss = 1.14812405, grad/param norm = 4.6099e-02, time/batch = 0.1802s	
1475/10550 (epoch 6.991), train_loss = 1.20371606, grad/param norm = 4.7045e-02, time/batch = 0.1801s	
1476/10550 (epoch 6.995), train_loss = 1.16117615, grad/param norm = 4.6129e-02, time/batch = 0.1799s	
1477/10550 (epoch 7.000), train_loss = 1.16470420, grad/param norm = 4.6453e-02, time/batch = 0.1796s	
1478/10550 (epoch 7.005), train_loss = 1.34641519, grad/param norm = 5.1005e-02, time/batch = 0.1795s	
1479/10550 (epoch 7.009), train_loss = 1.13267000, grad/param norm = 4.5950e-02, time/batch = 0.1799s	
1480/10550 (epoch 7.014), train_loss = 1.14283449, grad/param norm = 4.4818e-02, time/batch = 0.1801s	
1481/10550 (epoch 7.019), train_loss = 1.17252388, grad/param norm = 4.4360e-02, time/batch = 0.1815s	
1482/10550 (epoch 7.024), train_loss = 1.16372190, grad/param norm = 4.4145e-02, time/batch = 0.1797s	
1483/10550 (epoch 7.028), train_loss = 1.15308872, grad/param norm = 4.5919e-02, time/batch = 0.1803s	
1484/10550 (epoch 7.033), train_loss = 1.17465066, grad/param norm = 4.6533e-02, time/batch = 0.1801s	
1485/10550 (epoch 7.038), train_loss = 1.17876454, grad/param norm = 4.5768e-02, time/batch = 0.1799s	
1486/10550 (epoch 7.043), train_loss = 1.13464266, grad/param norm = 4.5113e-02, time/batch = 0.1802s	
1487/10550 (epoch 7.047), train_loss = 1.12451169, grad/param norm = 4.5935e-02, time/batch = 0.1798s	
1488/10550 (epoch 7.052), train_loss = 1.18356205, grad/param norm = 4.6471e-02, time/batch = 0.1792s	
1489/10550 (epoch 7.057), train_loss = 1.15774401, grad/param norm = 4.7260e-02, time/batch = 0.1801s	
1490/10550 (epoch 7.062), train_loss = 1.16422640, grad/param norm = 4.5780e-02, time/batch = 0.1801s	
1491/10550 (epoch 7.066), train_loss = 1.15561476, grad/param norm = 4.3019e-02, time/batch = 0.1809s	
1492/10550 (epoch 7.071), train_loss = 1.11363139, grad/param norm = 4.7029e-02, time/batch = 0.1798s	
1493/10550 (epoch 7.076), train_loss = 1.14157019, grad/param norm = 4.7701e-02, time/batch = 0.1800s	
1494/10550 (epoch 7.081), train_loss = 1.17405168, grad/param norm = 5.0319e-02, time/batch = 0.1798s	
1495/10550 (epoch 7.085), train_loss = 1.15147009, grad/param norm = 4.8324e-02, time/batch = 0.1804s	
1496/10550 (epoch 7.090), train_loss = 1.14213231, grad/param norm = 4.7833e-02, time/batch = 0.1798s	
1497/10550 (epoch 7.095), train_loss = 1.15198562, grad/param norm = 4.7229e-02, time/batch = 0.1801s	
1498/10550 (epoch 7.100), train_loss = 1.13105966, grad/param norm = 4.7571e-02, time/batch = 0.1791s	
1499/10550 (epoch 7.104), train_loss = 1.12993400, grad/param norm = 5.4304e-02, time/batch = 0.1800s	
1500/10550 (epoch 7.109), train_loss = 1.11963848, grad/param norm = 4.7436e-02, time/batch = 0.1800s	
1501/10550 (epoch 7.114), train_loss = 1.14247272, grad/param norm = 4.6655e-02, time/batch = 0.1809s	
1502/10550 (epoch 7.118), train_loss = 1.09315424, grad/param norm = 4.9948e-02, time/batch = 0.1793s	
1503/10550 (epoch 7.123), train_loss = 1.16103463, grad/param norm = 4.7437e-02, time/batch = 0.1801s	
1504/10550 (epoch 7.128), train_loss = 1.11442748, grad/param norm = 4.5124e-02, time/batch = 0.1798s	
1505/10550 (epoch 7.133), train_loss = 1.10837759, grad/param norm = 4.7396e-02, time/batch = 0.1801s	
1506/10550 (epoch 7.137), train_loss = 1.11709672, grad/param norm = 4.7862e-02, time/batch = 0.1802s	
1507/10550 (epoch 7.142), train_loss = 1.15106852, grad/param norm = 4.5513e-02, time/batch = 0.1803s	
1508/10550 (epoch 7.147), train_loss = 1.12784426, grad/param norm = 4.7660e-02, time/batch = 0.1792s	
1509/10550 (epoch 7.152), train_loss = 1.14446882, grad/param norm = 5.3617e-02, time/batch = 0.1801s	
1510/10550 (epoch 7.156), train_loss = 1.15710637, grad/param norm = 5.1789e-02, time/batch = 0.1805s	
1511/10550 (epoch 7.161), train_loss = 1.13561191, grad/param norm = 4.7527e-02, time/batch = 0.1808s	
1512/10550 (epoch 7.166), train_loss = 1.16116893, grad/param norm = 5.0151e-02, time/batch = 0.1794s	
1513/10550 (epoch 7.171), train_loss = 1.13355633, grad/param norm = 4.9460e-02, time/batch = 0.1793s	
1514/10550 (epoch 7.175), train_loss = 1.16791740, grad/param norm = 4.9150e-02, time/batch = 0.1801s	
1515/10550 (epoch 7.180), train_loss = 1.14342584, grad/param norm = 5.0782e-02, time/batch = 0.1804s	
1516/10550 (epoch 7.185), train_loss = 1.15615909, grad/param norm = 5.0729e-02, time/batch = 0.1793s	
1517/10550 (epoch 7.190), train_loss = 1.13344856, grad/param norm = 5.0060e-02, time/batch = 0.1797s	
1518/10550 (epoch 7.194), train_loss = 1.15229192, grad/param norm = 4.8741e-02, time/batch = 0.1799s	
1519/10550 (epoch 7.199), train_loss = 1.15939702, grad/param norm = 4.7265e-02, time/batch = 0.1802s	
1520/10550 (epoch 7.204), train_loss = 1.13890891, grad/param norm = 4.6345e-02, time/batch = 0.1800s	
1521/10550 (epoch 7.209), train_loss = 1.15825247, grad/param norm = 4.7130e-02, time/batch = 0.1809s	
1522/10550 (epoch 7.213), train_loss = 1.15498817, grad/param norm = 4.7208e-02, time/batch = 0.1795s	
1523/10550 (epoch 7.218), train_loss = 1.14404935, grad/param norm = 4.6189e-02, time/batch = 0.1784s	
1524/10550 (epoch 7.223), train_loss = 1.11428890, grad/param norm = 4.5723e-02, time/batch = 0.1795s	
1525/10550 (epoch 7.227), train_loss = 1.09680906, grad/param norm = 4.7423e-02, time/batch = 0.1798s	
1526/10550 (epoch 7.232), train_loss = 1.13269991, grad/param norm = 5.0607e-02, time/batch = 0.1796s	
1527/10550 (epoch 7.237), train_loss = 1.12148048, grad/param norm = 5.2637e-02, time/batch = 0.1801s	
1528/10550 (epoch 7.242), train_loss = 1.14281231, grad/param norm = 4.7977e-02, time/batch = 0.1795s	
1529/10550 (epoch 7.246), train_loss = 1.11105452, grad/param norm = 4.5590e-02, time/batch = 0.1796s	
1530/10550 (epoch 7.251), train_loss = 1.12800280, grad/param norm = 4.5826e-02, time/batch = 0.1802s	
1531/10550 (epoch 7.256), train_loss = 1.14241094, grad/param norm = 4.6034e-02, time/batch = 0.1807s	
1532/10550 (epoch 7.261), train_loss = 1.10656991, grad/param norm = 4.6569e-02, time/batch = 0.1798s	
1533/10550 (epoch 7.265), train_loss = 1.13719482, grad/param norm = 5.1247e-02, time/batch = 0.1805s	
1534/10550 (epoch 7.270), train_loss = 1.12084264, grad/param norm = 5.1096e-02, time/batch = 0.1796s	
1535/10550 (epoch 7.275), train_loss = 1.13594218, grad/param norm = 4.7947e-02, time/batch = 0.1803s	
1536/10550 (epoch 7.280), train_loss = 1.14195383, grad/param norm = 4.7287e-02, time/batch = 0.1800s	
1537/10550 (epoch 7.284), train_loss = 1.13432589, grad/param norm = 4.8190e-02, time/batch = 0.1802s	
1538/10550 (epoch 7.289), train_loss = 1.14222010, grad/param norm = 4.7244e-02, time/batch = 0.1796s	
1539/10550 (epoch 7.294), train_loss = 1.13348257, grad/param norm = 5.1169e-02, time/batch = 0.1803s	
1540/10550 (epoch 7.299), train_loss = 1.11024919, grad/param norm = 4.8940e-02, time/batch = 0.1798s	
1541/10550 (epoch 7.303), train_loss = 1.15229083, grad/param norm = 4.9676e-02, time/batch = 0.1805s	
1542/10550 (epoch 7.308), train_loss = 1.11728482, grad/param norm = 4.7683e-02, time/batch = 0.1795s	
1543/10550 (epoch 7.313), train_loss = 1.14213238, grad/param norm = 5.2350e-02, time/batch = 0.1797s	
1544/10550 (epoch 7.318), train_loss = 1.13429059, grad/param norm = 4.9848e-02, time/batch = 0.1801s	
1545/10550 (epoch 7.322), train_loss = 1.14935659, grad/param norm = 4.9294e-02, time/batch = 0.1806s	
1546/10550 (epoch 7.327), train_loss = 1.14132324, grad/param norm = 5.0449e-02, time/batch = 0.1803s	
1547/10550 (epoch 7.332), train_loss = 1.16638191, grad/param norm = 5.1638e-02, time/batch = 0.1799s	
1548/10550 (epoch 7.336), train_loss = 1.14338944, grad/param norm = 4.9171e-02, time/batch = 0.1795s	
1549/10550 (epoch 7.341), train_loss = 1.10169416, grad/param norm = 4.7423e-02, time/batch = 0.1800s	
1550/10550 (epoch 7.346), train_loss = 1.15131289, grad/param norm = 4.9315e-02, time/batch = 0.1798s	
1551/10550 (epoch 7.351), train_loss = 1.13049841, grad/param norm = 4.8649e-02, time/batch = 0.1812s	
1552/10550 (epoch 7.355), train_loss = 1.11881634, grad/param norm = 4.8983e-02, time/batch = 0.1793s	
1553/10550 (epoch 7.360), train_loss = 1.17570308, grad/param norm = 4.8551e-02, time/batch = 0.1797s	
1554/10550 (epoch 7.365), train_loss = 1.13686299, grad/param norm = 4.7904e-02, time/batch = 0.1797s	
1555/10550 (epoch 7.370), train_loss = 1.11975994, grad/param norm = 4.8093e-02, time/batch = 0.1799s	
1556/10550 (epoch 7.374), train_loss = 1.13998390, grad/param norm = 5.0023e-02, time/batch = 0.1797s	
1557/10550 (epoch 7.379), train_loss = 1.14300094, grad/param norm = 5.2378e-02, time/batch = 0.1802s	
1558/10550 (epoch 7.384), train_loss = 1.10285974, grad/param norm = 5.1188e-02, time/batch = 0.1790s	
1559/10550 (epoch 7.389), train_loss = 1.11289985, grad/param norm = 4.8649e-02, time/batch = 0.1801s	
1560/10550 (epoch 7.393), train_loss = 1.11949382, grad/param norm = 4.8298e-02, time/batch = 0.1797s	
1561/10550 (epoch 7.398), train_loss = 1.12458824, grad/param norm = 5.2236e-02, time/batch = 0.1812s	
1562/10550 (epoch 7.403), train_loss = 1.15046823, grad/param norm = 4.7708e-02, time/batch = 0.1799s	
1563/10550 (epoch 7.408), train_loss = 1.15228746, grad/param norm = 4.7259e-02, time/batch = 0.1796s	
1564/10550 (epoch 7.412), train_loss = 1.11985425, grad/param norm = 4.6645e-02, time/batch = 0.1802s	
1565/10550 (epoch 7.417), train_loss = 1.10581543, grad/param norm = 4.8858e-02, time/batch = 0.1801s	
1566/10550 (epoch 7.422), train_loss = 1.14912175, grad/param norm = 5.0957e-02, time/batch = 0.1795s	
1567/10550 (epoch 7.427), train_loss = 1.14884645, grad/param norm = 4.9313e-02, time/batch = 0.1801s	
1568/10550 (epoch 7.431), train_loss = 1.13065242, grad/param norm = 4.9901e-02, time/batch = 0.1793s	
1569/10550 (epoch 7.436), train_loss = 1.10742094, grad/param norm = 4.6746e-02, time/batch = 0.1801s	
1570/10550 (epoch 7.441), train_loss = 1.14111316, grad/param norm = 4.8270e-02, time/batch = 0.1799s	
1571/10550 (epoch 7.445), train_loss = 1.13848870, grad/param norm = 4.7624e-02, time/batch = 0.1811s	
1572/10550 (epoch 7.450), train_loss = 1.13190464, grad/param norm = 4.7894e-02, time/batch = 0.1797s	
1573/10550 (epoch 7.455), train_loss = 1.12771566, grad/param norm = 4.7573e-02, time/batch = 0.1795s	
1574/10550 (epoch 7.460), train_loss = 1.07514077, grad/param norm = 4.5743e-02, time/batch = 0.1800s	
1575/10550 (epoch 7.464), train_loss = 1.09761828, grad/param norm = 4.5544e-02, time/batch = 0.1803s	
1576/10550 (epoch 7.469), train_loss = 1.09902132, grad/param norm = 4.7568e-02, time/batch = 0.1800s	
1577/10550 (epoch 7.474), train_loss = 1.12925720, grad/param norm = 4.7459e-02, time/batch = 0.1801s	
1578/10550 (epoch 7.479), train_loss = 1.08935720, grad/param norm = 4.6527e-02, time/batch = 0.1790s	
1579/10550 (epoch 7.483), train_loss = 1.10345156, grad/param norm = 4.6954e-02, time/batch = 0.1803s	
1580/10550 (epoch 7.488), train_loss = 1.12245161, grad/param norm = 4.9975e-02, time/batch = 0.1802s	
1581/10550 (epoch 7.493), train_loss = 1.12261811, grad/param norm = 6.0814e-02, time/batch = 0.1812s	
1582/10550 (epoch 7.498), train_loss = 1.13371487, grad/param norm = 6.3903e-02, time/batch = 0.1795s	
1583/10550 (epoch 7.502), train_loss = 1.12641076, grad/param norm = 5.1850e-02, time/batch = 0.1800s	
1584/10550 (epoch 7.507), train_loss = 1.10722495, grad/param norm = 5.0003e-02, time/batch = 0.1804s	
1585/10550 (epoch 7.512), train_loss = 1.07883435, grad/param norm = 4.7700e-02, time/batch = 0.1798s	
1586/10550 (epoch 7.517), train_loss = 1.12501515, grad/param norm = 5.2180e-02, time/batch = 0.1800s	
1587/10550 (epoch 7.521), train_loss = 1.10356950, grad/param norm = 4.7401e-02, time/batch = 0.1799s	
1588/10550 (epoch 7.526), train_loss = 1.04288739, grad/param norm = 4.4118e-02, time/batch = 0.1799s	
1589/10550 (epoch 7.531), train_loss = 1.09207372, grad/param norm = 4.6910e-02, time/batch = 0.1805s	
1590/10550 (epoch 7.536), train_loss = 1.12254901, grad/param norm = 4.5060e-02, time/batch = 0.1798s	
1591/10550 (epoch 7.540), train_loss = 1.12518455, grad/param norm = 4.4742e-02, time/batch = 0.1811s	
1592/10550 (epoch 7.545), train_loss = 1.11021662, grad/param norm = 4.5430e-02, time/batch = 0.1802s	
1593/10550 (epoch 7.550), train_loss = 1.12942465, grad/param norm = 4.7499e-02, time/batch = 0.1802s	
1594/10550 (epoch 7.555), train_loss = 1.11355044, grad/param norm = 4.8444e-02, time/batch = 0.1802s	
1595/10550 (epoch 7.559), train_loss = 1.15374405, grad/param norm = 4.8653e-02, time/batch = 0.1799s	
1596/10550 (epoch 7.564), train_loss = 1.10656409, grad/param norm = 5.1758e-02, time/batch = 0.1804s	
1597/10550 (epoch 7.569), train_loss = 1.10622046, grad/param norm = 4.9888e-02, time/batch = 0.1803s	
1598/10550 (epoch 7.573), train_loss = 1.12845334, grad/param norm = 5.1938e-02, time/batch = 0.1795s	
1599/10550 (epoch 7.578), train_loss = 1.12413594, grad/param norm = 4.9428e-02, time/batch = 0.1799s	
1600/10550 (epoch 7.583), train_loss = 1.09044045, grad/param norm = 4.6540e-02, time/batch = 0.1797s	
1601/10550 (epoch 7.588), train_loss = 1.07686876, grad/param norm = 4.4924e-02, time/batch = 0.1814s	
1602/10550 (epoch 7.592), train_loss = 1.12797827, grad/param norm = 4.8747e-02, time/batch = 0.1801s	
1603/10550 (epoch 7.597), train_loss = 1.11209533, grad/param norm = 4.9932e-02, time/batch = 0.1794s	
1604/10550 (epoch 7.602), train_loss = 1.12901381, grad/param norm = 4.9135e-02, time/batch = 0.1799s	
1605/10550 (epoch 7.607), train_loss = 1.12118496, grad/param norm = 4.8690e-02, time/batch = 0.1801s	
1606/10550 (epoch 7.611), train_loss = 1.14095021, grad/param norm = 5.0486e-02, time/batch = 0.1798s	
1607/10550 (epoch 7.616), train_loss = 1.09077337, grad/param norm = 4.6163e-02, time/batch = 0.1802s	
1608/10550 (epoch 7.621), train_loss = 1.07766394, grad/param norm = 4.7897e-02, time/batch = 0.1795s	
1609/10550 (epoch 7.626), train_loss = 1.10083120, grad/param norm = 5.0071e-02, time/batch = 0.1804s	
1610/10550 (epoch 7.630), train_loss = 1.12847081, grad/param norm = 5.0727e-02, time/batch = 0.1799s	
1611/10550 (epoch 7.635), train_loss = 1.12781446, grad/param norm = 4.9083e-02, time/batch = 0.1812s	
1612/10550 (epoch 7.640), train_loss = 1.12444194, grad/param norm = 4.8464e-02, time/batch = 0.1798s	
1613/10550 (epoch 7.645), train_loss = 1.11585191, grad/param norm = 4.8975e-02, time/batch = 0.1800s	
1614/10550 (epoch 7.649), train_loss = 1.13812186, grad/param norm = 4.8331e-02, time/batch = 0.1802s	
1615/10550 (epoch 7.654), train_loss = 1.12977473, grad/param norm = 4.6196e-02, time/batch = 0.1802s	
1616/10550 (epoch 7.659), train_loss = 1.12923298, grad/param norm = 4.8272e-02, time/batch = 0.1805s	
1617/10550 (epoch 7.664), train_loss = 1.12066903, grad/param norm = 4.9464e-02, time/batch = 0.1795s	
1618/10550 (epoch 7.668), train_loss = 1.10832684, grad/param norm = 5.2684e-02, time/batch = 0.1788s	
1619/10550 (epoch 7.673), train_loss = 1.13634940, grad/param norm = 5.3695e-02, time/batch = 0.1805s	
1620/10550 (epoch 7.678), train_loss = 1.07376076, grad/param norm = 5.1031e-02, time/batch = 0.1800s	
1621/10550 (epoch 7.682), train_loss = 1.07983045, grad/param norm = 4.7478e-02, time/batch = 0.1808s	
1622/10550 (epoch 7.687), train_loss = 1.05926522, grad/param norm = 4.5444e-02, time/batch = 0.1795s	
1623/10550 (epoch 7.692), train_loss = 1.11704327, grad/param norm = 5.0122e-02, time/batch = 0.1797s	
1624/10550 (epoch 7.697), train_loss = 1.10592265, grad/param norm = 4.9431e-02, time/batch = 0.1799s	
1625/10550 (epoch 7.701), train_loss = 1.12201983, grad/param norm = 4.8621e-02, time/batch = 0.1803s	
1626/10550 (epoch 7.706), train_loss = 1.09854122, grad/param norm = 5.0913e-02, time/batch = 0.1803s	
1627/10550 (epoch 7.711), train_loss = 1.11846452, grad/param norm = 5.0997e-02, time/batch = 0.1803s	
1628/10550 (epoch 7.716), train_loss = 1.11711947, grad/param norm = 5.0420e-02, time/batch = 0.1797s	
1629/10550 (epoch 7.720), train_loss = 1.13348762, grad/param norm = 5.0506e-02, time/batch = 0.1800s	
1630/10550 (epoch 7.725), train_loss = 1.08784634, grad/param norm = 4.8825e-02, time/batch = 0.1800s	
1631/10550 (epoch 7.730), train_loss = 1.11114892, grad/param norm = 5.0283e-02, time/batch = 0.1810s	
1632/10550 (epoch 7.735), train_loss = 1.10352423, grad/param norm = 4.9636e-02, time/batch = 0.1795s	
1633/10550 (epoch 7.739), train_loss = 1.09044641, grad/param norm = 5.2944e-02, time/batch = 0.1795s	
1634/10550 (epoch 7.744), train_loss = 1.10081759, grad/param norm = 4.8279e-02, time/batch = 0.1792s	
1635/10550 (epoch 7.749), train_loss = 1.11195177, grad/param norm = 4.5891e-02, time/batch = 0.1806s	
1636/10550 (epoch 7.754), train_loss = 1.12079482, grad/param norm = 4.6274e-02, time/batch = 0.1802s	
1637/10550 (epoch 7.758), train_loss = 1.11155180, grad/param norm = 4.8591e-02, time/batch = 0.1801s	
1638/10550 (epoch 7.763), train_loss = 1.07655735, grad/param norm = 4.7388e-02, time/batch = 0.1799s	
1639/10550 (epoch 7.768), train_loss = 1.14268796, grad/param norm = 5.5408e-02, time/batch = 0.1801s	
1640/10550 (epoch 7.773), train_loss = 1.15407607, grad/param norm = 5.1829e-02, time/batch = 0.1801s	
1641/10550 (epoch 7.777), train_loss = 1.09635938, grad/param norm = 4.7829e-02, time/batch = 0.1813s	
1642/10550 (epoch 7.782), train_loss = 1.14897215, grad/param norm = 4.9773e-02, time/batch = 0.1801s	
1643/10550 (epoch 7.787), train_loss = 1.11607381, grad/param norm = 5.2677e-02, time/batch = 0.1802s	
1644/10550 (epoch 7.791), train_loss = 1.10351356, grad/param norm = 5.8332e-02, time/batch = 0.1799s	
1645/10550 (epoch 7.796), train_loss = 1.11540374, grad/param norm = 5.2673e-02, time/batch = 0.1802s	
1646/10550 (epoch 7.801), train_loss = 1.10948719, grad/param norm = 4.9020e-02, time/batch = 0.1800s	
1647/10550 (epoch 7.806), train_loss = 1.13356044, grad/param norm = 4.9217e-02, time/batch = 0.1801s	
1648/10550 (epoch 7.810), train_loss = 1.17053548, grad/param norm = 5.1651e-02, time/batch = 0.1800s	
1649/10550 (epoch 7.815), train_loss = 1.10728171, grad/param norm = 4.7337e-02, time/batch = 0.1801s	
1650/10550 (epoch 7.820), train_loss = 1.11988390, grad/param norm = 4.8364e-02, time/batch = 0.1799s	
1651/10550 (epoch 7.825), train_loss = 1.11156067, grad/param norm = 4.6387e-02, time/batch = 0.1808s	
1652/10550 (epoch 7.829), train_loss = 1.09376022, grad/param norm = 4.5931e-02, time/batch = 0.1799s	
1653/10550 (epoch 7.834), train_loss = 1.10836577, grad/param norm = 5.1345e-02, time/batch = 0.1798s	
1654/10550 (epoch 7.839), train_loss = 1.09002084, grad/param norm = 5.0118e-02, time/batch = 0.1799s	
1655/10550 (epoch 7.844), train_loss = 1.09956118, grad/param norm = 4.7556e-02, time/batch = 0.1802s	
1656/10550 (epoch 7.848), train_loss = 1.09589526, grad/param norm = 4.9408e-02, time/batch = 0.1800s	
1657/10550 (epoch 7.853), train_loss = 1.12256477, grad/param norm = 5.0608e-02, time/batch = 0.1800s	
1658/10550 (epoch 7.858), train_loss = 1.12442567, grad/param norm = 4.9683e-02, time/batch = 0.1795s	
1659/10550 (epoch 7.863), train_loss = 1.09261938, grad/param norm = 4.8001e-02, time/batch = 0.1801s	
1660/10550 (epoch 7.867), train_loss = 1.13041985, grad/param norm = 4.9622e-02, time/batch = 0.1794s	
1661/10550 (epoch 7.872), train_loss = 1.10836088, grad/param norm = 5.1868e-02, time/batch = 0.1808s	
1662/10550 (epoch 7.877), train_loss = 1.07663003, grad/param norm = 4.9936e-02, time/batch = 0.1795s	
1663/10550 (epoch 7.882), train_loss = 1.08484327, grad/param norm = 4.7774e-02, time/batch = 0.1800s	
1664/10550 (epoch 7.886), train_loss = 1.11528298, grad/param norm = 4.8345e-02, time/batch = 0.1799s	
1665/10550 (epoch 7.891), train_loss = 1.11400696, grad/param norm = 5.1784e-02, time/batch = 0.1793s	
1666/10550 (epoch 7.896), train_loss = 1.08807970, grad/param norm = 4.9647e-02, time/batch = 0.1801s	
1667/10550 (epoch 7.900), train_loss = 1.08416026, grad/param norm = 4.9302e-02, time/batch = 0.1796s	
1668/10550 (epoch 7.905), train_loss = 1.07353998, grad/param norm = 4.8053e-02, time/batch = 0.1795s	
1669/10550 (epoch 7.910), train_loss = 1.07875271, grad/param norm = 4.5404e-02, time/batch = 0.1802s	
1670/10550 (epoch 7.915), train_loss = 1.09041561, grad/param norm = 4.5605e-02, time/batch = 0.1800s	
1671/10550 (epoch 7.919), train_loss = 1.09947044, grad/param norm = 4.9711e-02, time/batch = 0.1813s	
1672/10550 (epoch 7.924), train_loss = 1.11634074, grad/param norm = 5.2824e-02, time/batch = 0.1794s	
1673/10550 (epoch 7.929), train_loss = 1.10652402, grad/param norm = 5.1234e-02, time/batch = 0.1802s	
1674/10550 (epoch 7.934), train_loss = 1.11314357, grad/param norm = 4.7288e-02, time/batch = 0.1800s	
1675/10550 (epoch 7.938), train_loss = 1.09389774, grad/param norm = 4.8197e-02, time/batch = 0.1798s	
1676/10550 (epoch 7.943), train_loss = 1.10617007, grad/param norm = 4.9329e-02, time/batch = 0.1799s	
1677/10550 (epoch 7.948), train_loss = 1.12506763, grad/param norm = 5.2102e-02, time/batch = 0.1802s	
1678/10550 (epoch 7.953), train_loss = 1.13791861, grad/param norm = 5.3832e-02, time/batch = 0.1792s	
1679/10550 (epoch 7.957), train_loss = 1.12311409, grad/param norm = 5.1571e-02, time/batch = 0.1798s	
1680/10550 (epoch 7.962), train_loss = 1.09352583, grad/param norm = 4.7932e-02, time/batch = 0.1799s	
1681/10550 (epoch 7.967), train_loss = 1.10537192, grad/param norm = 4.8390e-02, time/batch = 0.1810s	
1682/10550 (epoch 7.972), train_loss = 1.08930367, grad/param norm = 5.1413e-02, time/batch = 0.1799s	
1683/10550 (epoch 7.976), train_loss = 1.10445944, grad/param norm = 5.3224e-02, time/batch = 0.1799s	
1684/10550 (epoch 7.981), train_loss = 1.10338869, grad/param norm = 4.9096e-02, time/batch = 0.1800s	
1685/10550 (epoch 7.986), train_loss = 1.09294873, grad/param norm = 4.7326e-02, time/batch = 0.1799s	
1686/10550 (epoch 7.991), train_loss = 1.14881077, grad/param norm = 5.1729e-02, time/batch = 0.1800s	
1687/10550 (epoch 7.995), train_loss = 1.10927568, grad/param norm = 5.2272e-02, time/batch = 0.1802s	
1688/10550 (epoch 8.000), train_loss = 1.10980133, grad/param norm = 4.6432e-02, time/batch = 0.1797s	
1689/10550 (epoch 8.005), train_loss = 1.28780110, grad/param norm = 5.3962e-02, time/batch = 0.1800s	
1690/10550 (epoch 8.009), train_loss = 1.07574114, grad/param norm = 4.6336e-02, time/batch = 0.1802s	
1691/10550 (epoch 8.014), train_loss = 1.08716290, grad/param norm = 4.7586e-02, time/batch = 0.1812s	
1692/10550 (epoch 8.019), train_loss = 1.11801243, grad/param norm = 4.7962e-02, time/batch = 0.1795s	
1693/10550 (epoch 8.024), train_loss = 1.11508992, grad/param norm = 5.0667e-02, time/batch = 0.1800s	
1694/10550 (epoch 8.028), train_loss = 1.10206254, grad/param norm = 5.2098e-02, time/batch = 0.1796s	
1695/10550 (epoch 8.033), train_loss = 1.12236636, grad/param norm = 4.8574e-02, time/batch = 0.1804s	
1696/10550 (epoch 8.038), train_loss = 1.12016317, grad/param norm = 4.9000e-02, time/batch = 0.1803s	
1697/10550 (epoch 8.043), train_loss = 1.07593439, grad/param norm = 4.8183e-02, time/batch = 0.1805s	
1698/10550 (epoch 8.047), train_loss = 1.06965864, grad/param norm = 4.6635e-02, time/batch = 0.1792s	
1699/10550 (epoch 8.052), train_loss = 1.13042130, grad/param norm = 5.0368e-02, time/batch = 0.1801s	
1700/10550 (epoch 8.057), train_loss = 1.10517501, grad/param norm = 5.2255e-02, time/batch = 0.1800s	
1701/10550 (epoch 8.062), train_loss = 1.11697875, grad/param norm = 4.9630e-02, time/batch = 0.1808s	
1702/10550 (epoch 8.066), train_loss = 1.10357249, grad/param norm = 4.4971e-02, time/batch = 0.1798s	
1703/10550 (epoch 8.071), train_loss = 1.05693306, grad/param norm = 4.7789e-02, time/batch = 0.1801s	
1704/10550 (epoch 8.076), train_loss = 1.08864032, grad/param norm = 5.3857e-02, time/batch = 0.1797s	
1705/10550 (epoch 8.081), train_loss = 1.12358862, grad/param norm = 5.4278e-02, time/batch = 0.1800s	
1706/10550 (epoch 8.085), train_loss = 1.09999598, grad/param norm = 4.9819e-02, time/batch = 0.1799s	
1707/10550 (epoch 8.090), train_loss = 1.08545134, grad/param norm = 4.8827e-02, time/batch = 0.1801s	
1708/10550 (epoch 8.095), train_loss = 1.09255589, grad/param norm = 4.8581e-02, time/batch = 0.1795s	
1709/10550 (epoch 8.100), train_loss = 1.08600645, grad/param norm = 5.2229e-02, time/batch = 0.1801s	
1710/10550 (epoch 8.104), train_loss = 1.06906723, grad/param norm = 5.1205e-02, time/batch = 0.1797s	
1711/10550 (epoch 8.109), train_loss = 1.07851053, grad/param norm = 5.5337e-02, time/batch = 0.1810s	
1712/10550 (epoch 8.114), train_loss = 1.09772308, grad/param norm = 5.0591e-02, time/batch = 0.1790s	
1713/10550 (epoch 8.118), train_loss = 1.03260837, grad/param norm = 4.6238e-02, time/batch = 0.1799s	
1714/10550 (epoch 8.123), train_loss = 1.12139330, grad/param norm = 5.9371e-02, time/batch = 0.1798s	
1715/10550 (epoch 8.128), train_loss = 1.08312757, grad/param norm = 5.6112e-02, time/batch = 0.1796s	
1716/10550 (epoch 8.133), train_loss = 1.04818117, grad/param norm = 4.7881e-02, time/batch = 0.1798s	
1717/10550 (epoch 8.137), train_loss = 1.06315280, grad/param norm = 4.8516e-02, time/batch = 0.1799s	
1718/10550 (epoch 8.142), train_loss = 1.10014840, grad/param norm = 4.9913e-02, time/batch = 0.1791s	
1719/10550 (epoch 8.147), train_loss = 1.07703778, grad/param norm = 4.8507e-02, time/batch = 0.1803s	
1720/10550 (epoch 8.152), train_loss = 1.08396548, grad/param norm = 4.9747e-02, time/batch = 0.1796s	
1721/10550 (epoch 8.156), train_loss = 1.09193216, grad/param norm = 4.9593e-02, time/batch = 0.1810s	
1722/10550 (epoch 8.161), train_loss = 1.08783636, grad/param norm = 5.2177e-02, time/batch = 0.1798s	
1723/10550 (epoch 8.166), train_loss = 1.10608731, grad/param norm = 5.5365e-02, time/batch = 0.1800s	
1724/10550 (epoch 8.171), train_loss = 1.08717394, grad/param norm = 5.3635e-02, time/batch = 0.1803s	
1725/10550 (epoch 8.175), train_loss = 1.11035193, grad/param norm = 4.9828e-02, time/batch = 0.1797s	
1726/10550 (epoch 8.180), train_loss = 1.08284669, grad/param norm = 5.0700e-02, time/batch = 0.1802s	
1727/10550 (epoch 8.185), train_loss = 1.10126084, grad/param norm = 4.8937e-02, time/batch = 0.1802s	
1728/10550 (epoch 8.190), train_loss = 1.07528506, grad/param norm = 4.9882e-02, time/batch = 0.1803s	
1729/10550 (epoch 8.194), train_loss = 1.09706462, grad/param norm = 5.1442e-02, time/batch = 0.1798s	
1730/10550 (epoch 8.199), train_loss = 1.10575552, grad/param norm = 4.8600e-02, time/batch = 0.1800s	
1731/10550 (epoch 8.204), train_loss = 1.08157544, grad/param norm = 4.9434e-02, time/batch = 0.1813s	
1732/10550 (epoch 8.209), train_loss = 1.10600312, grad/param norm = 5.1708e-02, time/batch = 0.1801s	
1733/10550 (epoch 8.213), train_loss = 1.10543056, grad/param norm = 5.2410e-02, time/batch = 0.1800s	
1734/10550 (epoch 8.218), train_loss = 1.09371789, grad/param norm = 5.0247e-02, time/batch = 0.1795s	
1735/10550 (epoch 8.223), train_loss = 1.06136140, grad/param norm = 4.8165e-02, time/batch = 0.1805s	
1736/10550 (epoch 8.227), train_loss = 1.04647672, grad/param norm = 4.6770e-02, time/batch = 0.1810s	
1737/10550 (epoch 8.232), train_loss = 1.07477527, grad/param norm = 4.8326e-02, time/batch = 0.1801s	
1738/10550 (epoch 8.237), train_loss = 1.06545607, grad/param norm = 4.8501e-02, time/batch = 0.1792s	
1739/10550 (epoch 8.242), train_loss = 1.08441308, grad/param norm = 4.9370e-02, time/batch = 0.1800s	
1740/10550 (epoch 8.246), train_loss = 1.05495734, grad/param norm = 4.7003e-02, time/batch = 0.1801s	
1741/10550 (epoch 8.251), train_loss = 1.07990758, grad/param norm = 5.0389e-02, time/batch = 0.1816s	
1742/10550 (epoch 8.256), train_loss = 1.08015344, grad/param norm = 4.9756e-02, time/batch = 0.1796s	
1743/10550 (epoch 8.261), train_loss = 1.04624502, grad/param norm = 4.7831e-02, time/batch = 0.1800s	
1744/10550 (epoch 8.265), train_loss = 1.07708722, grad/param norm = 4.9536e-02, time/batch = 0.1796s	
1745/10550 (epoch 8.270), train_loss = 1.06114305, grad/param norm = 4.9526e-02, time/batch = 0.1797s	
1746/10550 (epoch 8.275), train_loss = 1.07958957, grad/param norm = 4.9388e-02, time/batch = 0.1799s	
1747/10550 (epoch 8.280), train_loss = 1.09730401, grad/param norm = 5.1747e-02, time/batch = 0.1798s	
1748/10550 (epoch 8.284), train_loss = 1.08278961, grad/param norm = 5.0341e-02, time/batch = 0.1797s	
1749/10550 (epoch 8.289), train_loss = 1.08975665, grad/param norm = 5.5892e-02, time/batch = 0.1802s	
1750/10550 (epoch 8.294), train_loss = 1.08260722, grad/param norm = 5.4155e-02, time/batch = 0.1799s	
1751/10550 (epoch 8.299), train_loss = 1.05740227, grad/param norm = 5.1205e-02, time/batch = 0.1810s	
1752/10550 (epoch 8.303), train_loss = 1.10121932, grad/param norm = 5.2253e-02, time/batch = 0.1797s	
1753/10550 (epoch 8.308), train_loss = 1.07372480, grad/param norm = 5.3885e-02, time/batch = 0.1796s	
1754/10550 (epoch 8.313), train_loss = 1.08602533, grad/param norm = 5.1242e-02, time/batch = 0.1802s	
1755/10550 (epoch 8.318), train_loss = 1.07254458, grad/param norm = 4.9756e-02, time/batch = 0.1798s	
1756/10550 (epoch 8.322), train_loss = 1.09434621, grad/param norm = 5.2354e-02, time/batch = 0.1800s	
1757/10550 (epoch 8.327), train_loss = 1.08477222, grad/param norm = 5.4703e-02, time/batch = 0.1800s	
1758/10550 (epoch 8.332), train_loss = 1.11430141, grad/param norm = 5.2216e-02, time/batch = 0.1797s	
1759/10550 (epoch 8.336), train_loss = 1.09347480, grad/param norm = 5.3942e-02, time/batch = 0.1801s	
1760/10550 (epoch 8.341), train_loss = 1.05271845, grad/param norm = 5.2526e-02, time/batch = 0.1802s	
1761/10550 (epoch 8.346), train_loss = 1.09382123, grad/param norm = 5.1415e-02, time/batch = 0.1814s	
1762/10550 (epoch 8.351), train_loss = 1.07025610, grad/param norm = 4.9977e-02, time/batch = 0.1793s	
1763/10550 (epoch 8.355), train_loss = 1.06683730, grad/param norm = 4.9644e-02, time/batch = 0.1802s	
1764/10550 (epoch 8.360), train_loss = 1.11849472, grad/param norm = 4.9814e-02, time/batch = 0.1801s	
1765/10550 (epoch 8.365), train_loss = 1.08437530, grad/param norm = 5.0407e-02, time/batch = 0.1797s	
1766/10550 (epoch 8.370), train_loss = 1.06774560, grad/param norm = 5.3049e-02, time/batch = 0.1796s	
1767/10550 (epoch 8.374), train_loss = 1.08162222, grad/param norm = 5.1539e-02, time/batch = 0.1803s	
1768/10550 (epoch 8.379), train_loss = 1.09059631, grad/param norm = 5.2377e-02, time/batch = 0.1799s	
1769/10550 (epoch 8.384), train_loss = 1.05463418, grad/param norm = 5.4443e-02, time/batch = 0.1802s	
1770/10550 (epoch 8.389), train_loss = 1.06048435, grad/param norm = 5.3621e-02, time/batch = 0.1794s	
1771/10550 (epoch 8.393), train_loss = 1.07227935, grad/param norm = 5.3077e-02, time/batch = 0.1813s	
1772/10550 (epoch 8.398), train_loss = 1.06575779, grad/param norm = 4.8469e-02, time/batch = 0.1800s	
1773/10550 (epoch 8.403), train_loss = 1.10127017, grad/param norm = 5.2742e-02, time/batch = 0.1806s	
1774/10550 (epoch 8.408), train_loss = 1.10036328, grad/param norm = 5.0347e-02, time/batch = 0.1796s	
1775/10550 (epoch 8.412), train_loss = 1.06627672, grad/param norm = 4.9474e-02, time/batch = 0.1797s	
1776/10550 (epoch 8.417), train_loss = 1.05570622, grad/param norm = 4.8696e-02, time/batch = 0.1797s	
1777/10550 (epoch 8.422), train_loss = 1.08236713, grad/param norm = 5.0524e-02, time/batch = 0.1802s	
1778/10550 (epoch 8.427), train_loss = 1.09146377, grad/param norm = 5.1130e-02, time/batch = 0.1797s	
1779/10550 (epoch 8.431), train_loss = 1.07702801, grad/param norm = 5.1325e-02, time/batch = 0.1801s	
1780/10550 (epoch 8.436), train_loss = 1.05417130, grad/param norm = 4.9439e-02, time/batch = 0.1799s	
1781/10550 (epoch 8.441), train_loss = 1.08420703, grad/param norm = 5.2697e-02, time/batch = 0.1810s	
1782/10550 (epoch 8.445), train_loss = 1.08808849, grad/param norm = 5.2523e-02, time/batch = 0.1793s	
1783/10550 (epoch 8.450), train_loss = 1.07927142, grad/param norm = 5.1971e-02, time/batch = 0.1795s	
1784/10550 (epoch 8.455), train_loss = 1.07783860, grad/param norm = 5.1326e-02, time/batch = 0.1802s	
1785/10550 (epoch 8.460), train_loss = 1.02652670, grad/param norm = 4.9580e-02, time/batch = 0.1798s	
1786/10550 (epoch 8.464), train_loss = 1.04870544, grad/param norm = 4.8101e-02, time/batch = 0.1799s	
1787/10550 (epoch 8.469), train_loss = 1.05067716, grad/param norm = 5.0516e-02, time/batch = 0.1800s	
1788/10550 (epoch 8.474), train_loss = 1.07901623, grad/param norm = 4.9735e-02, time/batch = 0.1801s	
1789/10550 (epoch 8.479), train_loss = 1.03983839, grad/param norm = 4.9209e-02, time/batch = 0.1800s	
1790/10550 (epoch 8.483), train_loss = 1.05424398, grad/param norm = 4.8792e-02, time/batch = 0.1799s	
1791/10550 (epoch 8.488), train_loss = 1.06636520, grad/param norm = 4.8647e-02, time/batch = 0.1807s	
1792/10550 (epoch 8.493), train_loss = 1.05760101, grad/param norm = 5.1705e-02, time/batch = 0.1797s	
1793/10550 (epoch 8.498), train_loss = 1.06421374, grad/param norm = 5.0299e-02, time/batch = 0.1799s	
1794/10550 (epoch 8.502), train_loss = 1.06631842, grad/param norm = 5.0007e-02, time/batch = 0.1795s	
1795/10550 (epoch 8.507), train_loss = 1.05469638, grad/param norm = 5.3144e-02, time/batch = 0.1799s	
1796/10550 (epoch 8.512), train_loss = 1.03448227, grad/param norm = 5.4144e-02, time/batch = 0.1800s	
1797/10550 (epoch 8.517), train_loss = 1.07057870, grad/param norm = 5.2399e-02, time/batch = 0.1799s	
1798/10550 (epoch 8.521), train_loss = 1.05533877, grad/param norm = 5.2170e-02, time/batch = 0.1797s	
1799/10550 (epoch 8.526), train_loss = 0.99699311, grad/param norm = 4.8762e-02, time/batch = 0.1804s	
1800/10550 (epoch 8.531), train_loss = 1.03744888, grad/param norm = 4.8685e-02, time/batch = 0.1797s	
1801/10550 (epoch 8.536), train_loss = 1.07882806, grad/param norm = 4.9605e-02, time/batch = 0.1814s	
1802/10550 (epoch 8.540), train_loss = 1.07293232, grad/param norm = 4.6855e-02, time/batch = 0.1793s	
1803/10550 (epoch 8.545), train_loss = 1.05301766, grad/param norm = 4.7489e-02, time/batch = 0.1798s	
1804/10550 (epoch 8.550), train_loss = 1.07134071, grad/param norm = 4.8592e-02, time/batch = 0.1804s	
1805/10550 (epoch 8.555), train_loss = 1.05420850, grad/param norm = 4.7968e-02, time/batch = 0.1800s	
1806/10550 (epoch 8.559), train_loss = 1.09762014, grad/param norm = 5.1512e-02, time/batch = 0.1800s	
1807/10550 (epoch 8.564), train_loss = 1.05404393, grad/param norm = 5.3783e-02, time/batch = 0.1802s	
1808/10550 (epoch 8.569), train_loss = 1.05604042, grad/param norm = 5.7087e-02, time/batch = 0.1799s	
1809/10550 (epoch 8.573), train_loss = 1.08777237, grad/param norm = 5.9256e-02, time/batch = 0.1803s	
1810/10550 (epoch 8.578), train_loss = 1.07617864, grad/param norm = 5.6191e-02, time/batch = 0.1800s	
1811/10550 (epoch 8.583), train_loss = 1.04786277, grad/param norm = 5.0497e-02, time/batch = 0.1808s	
1812/10550 (epoch 8.588), train_loss = 1.02587872, grad/param norm = 4.9784e-02, time/batch = 0.1795s	
1813/10550 (epoch 8.592), train_loss = 1.07163179, grad/param norm = 4.9755e-02, time/batch = 0.1802s	
1814/10550 (epoch 8.597), train_loss = 1.06025262, grad/param norm = 5.0235e-02, time/batch = 0.1793s	
1815/10550 (epoch 8.602), train_loss = 1.07540082, grad/param norm = 5.3485e-02, time/batch = 0.1797s	
1816/10550 (epoch 8.607), train_loss = 1.06244129, grad/param norm = 5.1799e-02, time/batch = 0.1806s	
1817/10550 (epoch 8.611), train_loss = 1.07652264, grad/param norm = 5.4456e-02, time/batch = 0.1800s	
1818/10550 (epoch 8.616), train_loss = 1.04892740, grad/param norm = 5.2580e-02, time/batch = 0.1802s	
1819/10550 (epoch 8.621), train_loss = 1.03027366, grad/param norm = 4.9538e-02, time/batch = 0.1804s	
1820/10550 (epoch 8.626), train_loss = 1.05004989, grad/param norm = 5.1360e-02, time/batch = 0.1797s	
1821/10550 (epoch 8.630), train_loss = 1.06834834, grad/param norm = 5.2181e-02, time/batch = 0.1815s	
1822/10550 (epoch 8.635), train_loss = 1.08093807, grad/param norm = 5.2323e-02, time/batch = 0.1794s	
1823/10550 (epoch 8.640), train_loss = 1.07096801, grad/param norm = 4.8257e-02, time/batch = 0.1798s	
1824/10550 (epoch 8.645), train_loss = 1.05962821, grad/param norm = 5.1891e-02, time/batch = 0.1804s	
1825/10550 (epoch 8.649), train_loss = 1.08904008, grad/param norm = 5.2392e-02, time/batch = 0.1800s	
1826/10550 (epoch 8.654), train_loss = 1.07882225, grad/param norm = 4.9411e-02, time/batch = 0.1799s	
1827/10550 (epoch 8.659), train_loss = 1.07781544, grad/param norm = 5.2197e-02, time/batch = 0.1797s	
1828/10550 (epoch 8.664), train_loss = 1.06205105, grad/param norm = 4.9591e-02, time/batch = 0.1797s	
1829/10550 (epoch 8.668), train_loss = 1.04422074, grad/param norm = 4.9634e-02, time/batch = 0.1800s	
1830/10550 (epoch 8.673), train_loss = 1.07665427, grad/param norm = 5.4106e-02, time/batch = 0.1804s	
1831/10550 (epoch 8.678), train_loss = 1.02503254, grad/param norm = 5.6294e-02, time/batch = 0.1810s	
1832/10550 (epoch 8.682), train_loss = 1.04231215, grad/param norm = 5.1410e-02, time/batch = 0.1797s	
1833/10550 (epoch 8.687), train_loss = 1.01479762, grad/param norm = 5.1463e-02, time/batch = 0.1802s	
1834/10550 (epoch 8.692), train_loss = 1.06368690, grad/param norm = 5.1467e-02, time/batch = 0.1799s	
1835/10550 (epoch 8.697), train_loss = 1.04610226, grad/param norm = 5.0984e-02, time/batch = 0.1801s	
1836/10550 (epoch 8.701), train_loss = 1.06634712, grad/param norm = 4.9694e-02, time/batch = 0.1803s	
1837/10550 (epoch 8.706), train_loss = 1.04570097, grad/param norm = 5.2100e-02, time/batch = 0.1803s	
1838/10550 (epoch 8.711), train_loss = 1.05986422, grad/param norm = 4.9518e-02, time/batch = 0.1793s	
1839/10550 (epoch 8.716), train_loss = 1.05809444, grad/param norm = 5.2136e-02, time/batch = 0.1798s	
1840/10550 (epoch 8.720), train_loss = 1.08536098, grad/param norm = 4.9838e-02, time/batch = 0.1799s	
1841/10550 (epoch 8.725), train_loss = 1.04151075, grad/param norm = 5.1718e-02, time/batch = 0.1816s	
1842/10550 (epoch 8.730), train_loss = 1.06274745, grad/param norm = 5.1959e-02, time/batch = 0.1796s	
1843/10550 (epoch 8.735), train_loss = 1.05572841, grad/param norm = 4.9059e-02, time/batch = 0.1798s	
1844/10550 (epoch 8.739), train_loss = 1.03408851, grad/param norm = 5.0003e-02, time/batch = 0.1800s	
1845/10550 (epoch 8.744), train_loss = 1.04875499, grad/param norm = 5.0130e-02, time/batch = 0.1803s	
1846/10550 (epoch 8.749), train_loss = 1.06787840, grad/param norm = 5.1137e-02, time/batch = 0.1800s	
1847/10550 (epoch 8.754), train_loss = 1.07527429, grad/param norm = 5.4266e-02, time/batch = 0.1797s	
1848/10550 (epoch 8.758), train_loss = 1.05754885, grad/param norm = 5.4627e-02, time/batch = 0.1795s	
1849/10550 (epoch 8.763), train_loss = 1.02485210, grad/param norm = 5.1183e-02, time/batch = 0.1801s	
1850/10550 (epoch 8.768), train_loss = 1.08584218, grad/param norm = 5.3007e-02, time/batch = 0.1800s	
1851/10550 (epoch 8.773), train_loss = 1.09432433, grad/param norm = 5.3555e-02, time/batch = 0.1808s	
1852/10550 (epoch 8.777), train_loss = 1.05518871, grad/param norm = 5.0861e-02, time/batch = 0.1795s	
1853/10550 (epoch 8.782), train_loss = 1.10247954, grad/param norm = 5.3549e-02, time/batch = 0.1800s	
1854/10550 (epoch 8.787), train_loss = 1.05145176, grad/param norm = 4.8913e-02, time/batch = 0.1801s	
1855/10550 (epoch 8.791), train_loss = 1.03595980, grad/param norm = 5.2886e-02, time/batch = 0.1801s	
1856/10550 (epoch 8.796), train_loss = 1.06430331, grad/param norm = 5.1787e-02, time/batch = 0.1799s	
1857/10550 (epoch 8.801), train_loss = 1.06071829, grad/param norm = 5.5384e-02, time/batch = 0.1798s	
1858/10550 (epoch 8.806), train_loss = 1.07390958, grad/param norm = 5.2550e-02, time/batch = 0.1796s	
1859/10550 (epoch 8.810), train_loss = 1.11625515, grad/param norm = 5.2541e-02, time/batch = 0.1802s	
1860/10550 (epoch 8.815), train_loss = 1.05839022, grad/param norm = 5.0434e-02, time/batch = 0.1799s	
1861/10550 (epoch 8.820), train_loss = 1.06261433, grad/param norm = 5.0121e-02, time/batch = 0.1814s	
1862/10550 (epoch 8.825), train_loss = 1.06279194, grad/param norm = 5.1291e-02, time/batch = 0.1795s	
1863/10550 (epoch 8.829), train_loss = 1.04788682, grad/param norm = 5.2594e-02, time/batch = 0.1800s	
1864/10550 (epoch 8.834), train_loss = 1.05221609, grad/param norm = 5.2658e-02, time/batch = 0.1798s	
1865/10550 (epoch 8.839), train_loss = 1.04205209, grad/param norm = 5.1723e-02, time/batch = 0.1798s	
1866/10550 (epoch 8.844), train_loss = 1.04752947, grad/param norm = 4.9357e-02, time/batch = 0.1802s	
1867/10550 (epoch 8.848), train_loss = 1.04418291, grad/param norm = 5.0400e-02, time/batch = 0.1802s	
1868/10550 (epoch 8.853), train_loss = 1.06553213, grad/param norm = 5.1297e-02, time/batch = 0.1801s	
1869/10550 (epoch 8.858), train_loss = 1.07627256, grad/param norm = 5.1725e-02, time/batch = 0.1798s	
1870/10550 (epoch 8.863), train_loss = 1.04198847, grad/param norm = 5.1723e-02, time/batch = 0.1797s	
1871/10550 (epoch 8.867), train_loss = 1.08505352, grad/param norm = 5.2540e-02, time/batch = 0.1808s	
1872/10550 (epoch 8.872), train_loss = 1.04971801, grad/param norm = 4.9228e-02, time/batch = 0.1800s	
1873/10550 (epoch 8.877), train_loss = 1.02301536, grad/param norm = 5.0876e-02, time/batch = 0.1803s	
1874/10550 (epoch 8.882), train_loss = 1.04240278, grad/param norm = 5.2878e-02, time/batch = 0.1794s	
1875/10550 (epoch 8.886), train_loss = 1.06987829, grad/param norm = 5.3768e-02, time/batch = 0.1804s	
1876/10550 (epoch 8.891), train_loss = 1.05283521, grad/param norm = 5.1176e-02, time/batch = 0.1797s	
1877/10550 (epoch 8.896), train_loss = 1.02950279, grad/param norm = 5.0169e-02, time/batch = 0.1798s	
1878/10550 (epoch 8.900), train_loss = 1.04230796, grad/param norm = 5.4391e-02, time/batch = 0.1794s	
1879/10550 (epoch 8.905), train_loss = 1.02335771, grad/param norm = 5.0589e-02, time/batch = 0.1800s	
1880/10550 (epoch 8.910), train_loss = 1.03591462, grad/param norm = 4.9802e-02, time/batch = 0.1799s	
1881/10550 (epoch 8.915), train_loss = 1.03894325, grad/param norm = 4.9914e-02, time/batch = 0.1810s	
1882/10550 (epoch 8.919), train_loss = 1.04679236, grad/param norm = 5.3190e-02, time/batch = 0.1794s	
1883/10550 (epoch 8.924), train_loss = 1.06009869, grad/param norm = 5.2400e-02, time/batch = 0.1801s	
1884/10550 (epoch 8.929), train_loss = 1.05422632, grad/param norm = 5.5225e-02, time/batch = 0.1799s	
1885/10550 (epoch 8.934), train_loss = 1.06726841, grad/param norm = 5.2746e-02, time/batch = 0.1796s	
1886/10550 (epoch 8.938), train_loss = 1.05762133, grad/param norm = 5.2938e-02, time/batch = 0.1797s	
1887/10550 (epoch 8.943), train_loss = 1.04380504, grad/param norm = 4.9401e-02, time/batch = 0.1804s	
1888/10550 (epoch 8.948), train_loss = 1.06228947, grad/param norm = 5.0950e-02, time/batch = 0.1795s	
1889/10550 (epoch 8.953), train_loss = 1.08020689, grad/param norm = 5.5074e-02, time/batch = 0.1801s	
1890/10550 (epoch 8.957), train_loss = 1.07438959, grad/param norm = 5.0961e-02, time/batch = 0.1801s	
1891/10550 (epoch 8.962), train_loss = 1.04645772, grad/param norm = 5.1685e-02, time/batch = 0.1808s	
1892/10550 (epoch 8.967), train_loss = 1.05410901, grad/param norm = 4.8004e-02, time/batch = 0.1800s	
1893/10550 (epoch 8.972), train_loss = 1.03123680, grad/param norm = 4.9569e-02, time/batch = 0.1801s	
1894/10550 (epoch 8.976), train_loss = 1.04516391, grad/param norm = 5.0759e-02, time/batch = 0.1801s	
1895/10550 (epoch 8.981), train_loss = 1.05857719, grad/param norm = 5.4266e-02, time/batch = 0.1805s	
1896/10550 (epoch 8.986), train_loss = 1.05415391, grad/param norm = 5.5723e-02, time/batch = 0.1799s	
1897/10550 (epoch 8.991), train_loss = 1.10464335, grad/param norm = 5.5556e-02, time/batch = 0.1802s	
1898/10550 (epoch 8.995), train_loss = 1.05624583, grad/param norm = 5.2029e-02, time/batch = 0.1797s	
1899/10550 (epoch 9.000), train_loss = 1.06699182, grad/param norm = 5.4756e-02, time/batch = 0.1800s	
1900/10550 (epoch 9.005), train_loss = 1.23695576, grad/param norm = 5.7220e-02, time/batch = 0.1804s	
1901/10550 (epoch 9.009), train_loss = 1.02911068, grad/param norm = 5.0705e-02, time/batch = 0.1813s	
1902/10550 (epoch 9.014), train_loss = 1.04354238, grad/param norm = 5.1168e-02, time/batch = 0.1796s	
1903/10550 (epoch 9.019), train_loss = 1.06126570, grad/param norm = 4.9907e-02, time/batch = 0.1796s	
1904/10550 (epoch 9.024), train_loss = 1.05834592, grad/param norm = 4.8752e-02, time/batch = 0.1802s	
1905/10550 (epoch 9.028), train_loss = 1.04738203, grad/param norm = 5.0399e-02, time/batch = 0.1800s	
1906/10550 (epoch 9.033), train_loss = 1.07309405, grad/param norm = 5.0800e-02, time/batch = 0.1797s	
1907/10550 (epoch 9.038), train_loss = 1.06060627, grad/param norm = 5.2068e-02, time/batch = 0.1797s	
1908/10550 (epoch 9.043), train_loss = 1.02591591, grad/param norm = 5.1509e-02, time/batch = 0.1805s	
1909/10550 (epoch 9.047), train_loss = 1.01999619, grad/param norm = 4.9013e-02, time/batch = 0.1805s	
1910/10550 (epoch 9.052), train_loss = 1.07261613, grad/param norm = 5.1785e-02, time/batch = 0.1797s	
1911/10550 (epoch 9.057), train_loss = 1.04363744, grad/param norm = 5.0895e-02, time/batch = 0.1808s	
1912/10550 (epoch 9.062), train_loss = 1.06753929, grad/param norm = 5.3279e-02, time/batch = 0.1797s	
1913/10550 (epoch 9.066), train_loss = 1.05229851, grad/param norm = 4.9130e-02, time/batch = 0.1799s	
1914/10550 (epoch 9.071), train_loss = 1.01829157, grad/param norm = 5.1747e-02, time/batch = 0.1796s	
1915/10550 (epoch 9.076), train_loss = 1.03267778, grad/param norm = 5.1031e-02, time/batch = 0.1797s	
1916/10550 (epoch 9.081), train_loss = 1.06322932, grad/param norm = 5.3211e-02, time/batch = 0.1799s	
1917/10550 (epoch 9.085), train_loss = 1.04312757, grad/param norm = 5.0528e-02, time/batch = 0.1801s	
1918/10550 (epoch 9.090), train_loss = 1.03373527, grad/param norm = 5.3336e-02, time/batch = 0.1794s	
1919/10550 (epoch 9.095), train_loss = 1.04613035, grad/param norm = 5.1174e-02, time/batch = 0.1802s	
1920/10550 (epoch 9.100), train_loss = 1.03194276, grad/param norm = 5.0848e-02, time/batch = 0.1802s	
1921/10550 (epoch 9.104), train_loss = 1.00899559, grad/param norm = 5.0578e-02, time/batch = 0.1808s	
1922/10550 (epoch 9.109), train_loss = 1.01272658, grad/param norm = 5.2652e-02, time/batch = 0.1798s	
1923/10550 (epoch 9.114), train_loss = 1.04062894, grad/param norm = 5.3592e-02, time/batch = 0.1796s	
1924/10550 (epoch 9.118), train_loss = 0.99006786, grad/param norm = 5.1813e-02, time/batch = 0.1800s	
1925/10550 (epoch 9.123), train_loss = 1.05662886, grad/param norm = 5.3030e-02, time/batch = 0.1804s	
1926/10550 (epoch 9.128), train_loss = 1.02584696, grad/param norm = 4.9852e-02, time/batch = 0.1801s	
1927/10550 (epoch 9.133), train_loss = 1.00762994, grad/param norm = 5.3207e-02, time/batch = 0.1799s	
1928/10550 (epoch 9.137), train_loss = 1.01412702, grad/param norm = 5.1774e-02, time/batch = 0.1795s	
1929/10550 (epoch 9.142), train_loss = 1.05090332, grad/param norm = 5.2898e-02, time/batch = 0.1801s	
1930/10550 (epoch 9.147), train_loss = 1.02896559, grad/param norm = 5.1202e-02, time/batch = 0.1800s	
1931/10550 (epoch 9.152), train_loss = 1.03841354, grad/param norm = 5.4657e-02, time/batch = 0.1809s	
1932/10550 (epoch 9.156), train_loss = 1.04109167, grad/param norm = 5.1020e-02, time/batch = 0.1800s	
1933/10550 (epoch 9.161), train_loss = 1.03205588, grad/param norm = 5.2917e-02, time/batch = 0.1798s	
1934/10550 (epoch 9.166), train_loss = 1.04934900, grad/param norm = 5.2690e-02, time/batch = 0.1795s	
1935/10550 (epoch 9.171), train_loss = 1.02768327, grad/param norm = 5.4590e-02, time/batch = 0.1804s	
1936/10550 (epoch 9.175), train_loss = 1.06578639, grad/param norm = 5.7998e-02, time/batch = 0.1799s	
1937/10550 (epoch 9.180), train_loss = 1.03514051, grad/param norm = 5.4223e-02, time/batch = 0.1799s	
1938/10550 (epoch 9.185), train_loss = 1.05705416, grad/param norm = 5.3423e-02, time/batch = 0.1800s	
1939/10550 (epoch 9.190), train_loss = 1.02476774, grad/param norm = 5.3528e-02, time/batch = 0.1804s	
1940/10550 (epoch 9.194), train_loss = 1.04104157, grad/param norm = 5.4419e-02, time/batch = 0.1802s	
1941/10550 (epoch 9.199), train_loss = 1.05471364, grad/param norm = 5.2793e-02, time/batch = 0.1814s	
1942/10550 (epoch 9.204), train_loss = 1.03596601, grad/param norm = 5.5417e-02, time/batch = 0.1799s	
1943/10550 (epoch 9.209), train_loss = 1.05500839, grad/param norm = 5.3249e-02, time/batch = 0.1801s	
1944/10550 (epoch 9.213), train_loss = 1.05073685, grad/param norm = 5.3094e-02, time/batch = 0.1802s	
1945/10550 (epoch 9.218), train_loss = 1.04116685, grad/param norm = 5.1284e-02, time/batch = 0.1798s	
1946/10550 (epoch 9.223), train_loss = 1.01427818, grad/param norm = 5.1663e-02, time/batch = 0.1800s	
1947/10550 (epoch 9.227), train_loss = 0.99809201, grad/param norm = 4.9187e-02, time/batch = 0.1802s	
1948/10550 (epoch 9.232), train_loss = 1.02671208, grad/param norm = 4.9853e-02, time/batch = 0.1793s	
1949/10550 (epoch 9.237), train_loss = 1.01520957, grad/param norm = 5.0898e-02, time/batch = 0.1800s	
1950/10550 (epoch 9.242), train_loss = 1.02934443, grad/param norm = 5.1903e-02, time/batch = 0.1799s	
1951/10550 (epoch 9.246), train_loss = 1.00924371, grad/param norm = 5.1856e-02, time/batch = 0.1809s	
1952/10550 (epoch 9.251), train_loss = 1.04044007, grad/param norm = 5.6987e-02, time/batch = 0.1800s	
1953/10550 (epoch 9.256), train_loss = 1.03961308, grad/param norm = 5.6535e-02, time/batch = 0.1802s	
1954/10550 (epoch 9.261), train_loss = 1.01053888, grad/param norm = 5.4356e-02, time/batch = 0.1795s	
1955/10550 (epoch 9.265), train_loss = 1.03617393, grad/param norm = 5.6771e-02, time/batch = 0.1798s	
1956/10550 (epoch 9.270), train_loss = 1.00928642, grad/param norm = 5.3837e-02, time/batch = 0.1801s	
1957/10550 (epoch 9.275), train_loss = 1.02395402, grad/param norm = 4.9355e-02, time/batch = 0.1797s	
1958/10550 (epoch 9.280), train_loss = 1.04622896, grad/param norm = 5.3180e-02, time/batch = 0.1789s	
1959/10550 (epoch 9.284), train_loss = 1.03461729, grad/param norm = 5.2673e-02, time/batch = 0.1798s	
1960/10550 (epoch 9.289), train_loss = 1.03709128, grad/param norm = 5.4535e-02, time/batch = 0.1802s	
1961/10550 (epoch 9.294), train_loss = 1.02927693, grad/param norm = 5.5381e-02, time/batch = 0.1813s	
1962/10550 (epoch 9.299), train_loss = 1.00984129, grad/param norm = 5.3871e-02, time/batch = 0.1796s	
1963/10550 (epoch 9.303), train_loss = 1.04746979, grad/param norm = 5.3675e-02, time/batch = 0.1795s	
1964/10550 (epoch 9.308), train_loss = 1.01461826, grad/param norm = 5.1959e-02, time/batch = 0.1798s	
1965/10550 (epoch 9.313), train_loss = 1.03421780, grad/param norm = 5.5284e-02, time/batch = 0.1800s	
1966/10550 (epoch 9.318), train_loss = 1.03913398, grad/param norm = 5.8432e-02, time/batch = 0.1803s	
1967/10550 (epoch 9.322), train_loss = 1.05048556, grad/param norm = 5.3052e-02, time/batch = 0.1799s	
1968/10550 (epoch 9.327), train_loss = 1.02362372, grad/param norm = 5.2348e-02, time/batch = 0.1793s	
1969/10550 (epoch 9.332), train_loss = 1.06712301, grad/param norm = 6.4113e-02, time/batch = 0.1803s	
1970/10550 (epoch 9.336), train_loss = 1.04497056, grad/param norm = 5.6334e-02, time/batch = 0.1800s	
1971/10550 (epoch 9.341), train_loss = 1.00023171, grad/param norm = 5.2442e-02, time/batch = 0.1807s	
1972/10550 (epoch 9.346), train_loss = 1.04383708, grad/param norm = 5.5300e-02, time/batch = 0.1790s	
1973/10550 (epoch 9.351), train_loss = 1.03486976, grad/param norm = 5.3948e-02, time/batch = 0.1792s	
1974/10550 (epoch 9.355), train_loss = 1.01664559, grad/param norm = 5.1742e-02, time/batch = 0.1799s	
1975/10550 (epoch 9.360), train_loss = 1.06977503, grad/param norm = 5.3344e-02, time/batch = 0.1801s	
1976/10550 (epoch 9.365), train_loss = 1.04210111, grad/param norm = 5.4482e-02, time/batch = 0.1800s	
1977/10550 (epoch 9.370), train_loss = 1.01418494, grad/param norm = 5.3704e-02, time/batch = 0.1805s	
1978/10550 (epoch 9.374), train_loss = 1.03305691, grad/param norm = 5.1776e-02, time/batch = 0.1796s	
1979/10550 (epoch 9.379), train_loss = 1.03387493, grad/param norm = 5.2036e-02, time/batch = 0.1797s	
1980/10550 (epoch 9.384), train_loss = 1.00107649, grad/param norm = 5.1584e-02, time/batch = 0.1801s	
1981/10550 (epoch 9.389), train_loss = 1.00681880, grad/param norm = 5.1158e-02, time/batch = 0.1808s	
1982/10550 (epoch 9.393), train_loss = 1.01647226, grad/param norm = 5.1975e-02, time/batch = 0.1796s	
1983/10550 (epoch 9.398), train_loss = 1.01443666, grad/param norm = 5.2314e-02, time/batch = 0.1800s	
1984/10550 (epoch 9.403), train_loss = 1.04108996, grad/param norm = 5.0571e-02, time/batch = 0.1802s	
1985/10550 (epoch 9.408), train_loss = 1.04267461, grad/param norm = 5.0710e-02, time/batch = 0.1804s	
1986/10550 (epoch 9.412), train_loss = 1.01335372, grad/param norm = 4.9986e-02, time/batch = 0.1801s	
1987/10550 (epoch 9.417), train_loss = 1.00893371, grad/param norm = 5.2829e-02, time/batch = 0.1797s	
1988/10550 (epoch 9.422), train_loss = 1.03915156, grad/param norm = 6.0250e-02, time/batch = 0.1794s	
1989/10550 (epoch 9.427), train_loss = 1.04450494, grad/param norm = 5.2463e-02, time/batch = 0.1803s	
1990/10550 (epoch 9.431), train_loss = 1.02790695, grad/param norm = 5.1355e-02, time/batch = 0.1803s	
1991/10550 (epoch 9.436), train_loss = 1.00237249, grad/param norm = 5.0080e-02, time/batch = 0.1810s	
1992/10550 (epoch 9.441), train_loss = 1.02651685, grad/param norm = 5.2453e-02, time/batch = 0.1791s	
1993/10550 (epoch 9.445), train_loss = 1.04832114, grad/param norm = 5.8072e-02, time/batch = 0.1801s	
1994/10550 (epoch 9.450), train_loss = 1.03588105, grad/param norm = 5.6812e-02, time/batch = 0.1800s	
1995/10550 (epoch 9.455), train_loss = 1.01835587, grad/param norm = 5.2077e-02, time/batch = 0.1798s	
1996/10550 (epoch 9.460), train_loss = 0.97862571, grad/param norm = 5.1824e-02, time/batch = 0.1799s	
1997/10550 (epoch 9.464), train_loss = 1.00192437, grad/param norm = 5.1833e-02, time/batch = 0.1802s	
1998/10550 (epoch 9.469), train_loss = 1.00470140, grad/param norm = 5.3372e-02, time/batch = 0.1802s	
1999/10550 (epoch 9.474), train_loss = 1.03557725, grad/param norm = 5.3549e-02, time/batch = 0.1799s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to cv/lm_lstm_epoch9.48_1.5324.t7	
2000/10550 (epoch 9.479), train_loss = 0.99213504, grad/param norm = 5.1750e-02, time/batch = 0.1798s	
2001/10550 (epoch 9.483), train_loss = 1.39391584, grad/param norm = 6.3868e-02, time/batch = 0.1829s	
2002/10550 (epoch 9.488), train_loss = 1.03188358, grad/param norm = 5.0327e-02, time/batch = 0.1801s	
2003/10550 (epoch 9.493), train_loss = 1.01124645, grad/param norm = 5.1130e-02, time/batch = 0.1797s	
2004/10550 (epoch 9.498), train_loss = 1.01299437, grad/param norm = 5.0786e-02, time/batch = 0.1801s	
2005/10550 (epoch 9.502), train_loss = 1.02041051, grad/param norm = 5.0000e-02, time/batch = 0.1804s	
2006/10550 (epoch 9.507), train_loss = 1.00307929, grad/param norm = 5.2856e-02, time/batch = 0.1801s	
2007/10550 (epoch 9.512), train_loss = 0.98610474, grad/param norm = 5.4822e-02, time/batch = 0.1800s	
2008/10550 (epoch 9.517), train_loss = 1.03257846, grad/param norm = 5.7951e-02, time/batch = 0.1799s	
2009/10550 (epoch 9.521), train_loss = 1.00741345, grad/param norm = 5.2975e-02, time/batch = 0.1796s	
2010/10550 (epoch 9.526), train_loss = 0.94797580, grad/param norm = 4.9105e-02, time/batch = 0.1803s	
2011/10550 (epoch 9.531), train_loss = 0.98795967, grad/param norm = 5.1783e-02, time/batch = 0.1802s	
2012/10550 (epoch 9.536), train_loss = 1.02911410, grad/param norm = 5.2046e-02, time/batch = 0.1799s	
2013/10550 (epoch 9.540), train_loss = 1.02911393, grad/param norm = 5.1047e-02, time/batch = 0.1799s	
2014/10550 (epoch 9.545), train_loss = 1.00111664, grad/param norm = 5.0542e-02, time/batch = 0.1798s	
2015/10550 (epoch 9.550), train_loss = 1.02696720, grad/param norm = 5.2672e-02, time/batch = 0.1800s	
2016/10550 (epoch 9.555), train_loss = 1.00565434, grad/param norm = 5.1841e-02, time/batch = 0.1798s	
2017/10550 (epoch 9.559), train_loss = 1.04723955, grad/param norm = 5.4348e-02, time/batch = 0.1802s	
2018/10550 (epoch 9.564), train_loss = 1.00104862, grad/param norm = 5.2628e-02, time/batch = 0.1792s	
2019/10550 (epoch 9.569), train_loss = 0.99891574, grad/param norm = 5.4360e-02, time/batch = 0.1801s	
2020/10550 (epoch 9.573), train_loss = 1.03620991, grad/param norm = 6.1671e-02, time/batch = 0.1800s	
2021/10550 (epoch 9.578), train_loss = 1.02308482, grad/param norm = 5.6356e-02, time/batch = 0.1808s	
2022/10550 (epoch 9.583), train_loss = 0.99945340, grad/param norm = 5.7327e-02, time/batch = 0.1791s	
2023/10550 (epoch 9.588), train_loss = 0.97783020, grad/param norm = 5.1699e-02, time/batch = 0.1801s	
2024/10550 (epoch 9.592), train_loss = 1.01589011, grad/param norm = 5.2226e-02, time/batch = 0.1795s	
2025/10550 (epoch 9.597), train_loss = 1.01195830, grad/param norm = 5.5141e-02, time/batch = 0.1801s	
2026/10550 (epoch 9.602), train_loss = 1.01608237, grad/param norm = 5.3360e-02, time/batch = 0.1802s	
2027/10550 (epoch 9.607), train_loss = 1.01020136, grad/param norm = 5.4192e-02, time/batch = 0.1806s	
2028/10550 (epoch 9.611), train_loss = 1.02986681, grad/param norm = 5.7661e-02, time/batch = 0.1791s	
2029/10550 (epoch 9.616), train_loss = 1.00041924, grad/param norm = 5.6655e-02, time/batch = 0.1799s	
2030/10550 (epoch 9.621), train_loss = 0.98058740, grad/param norm = 5.3926e-02, time/batch = 0.1797s	
2031/10550 (epoch 9.626), train_loss = 1.00106600, grad/param norm = 5.5781e-02, time/batch = 0.1804s	
2032/10550 (epoch 9.630), train_loss = 1.02603879, grad/param norm = 5.5646e-02, time/batch = 0.1794s	
2033/10550 (epoch 9.635), train_loss = 1.02460154, grad/param norm = 5.3681e-02, time/batch = 0.1800s	
2034/10550 (epoch 9.640), train_loss = 1.02560595, grad/param norm = 5.1171e-02, time/batch = 0.1798s	
2035/10550 (epoch 9.645), train_loss = 1.00833034, grad/param norm = 5.3755e-02, time/batch = 0.1799s	
2036/10550 (epoch 9.649), train_loss = 1.03662671, grad/param norm = 5.4781e-02, time/batch = 0.1800s	
2037/10550 (epoch 9.654), train_loss = 1.02124749, grad/param norm = 5.0648e-02, time/batch = 0.1799s	
2038/10550 (epoch 9.659), train_loss = 1.02466863, grad/param norm = 5.4413e-02, time/batch = 0.1796s	
2039/10550 (epoch 9.664), train_loss = 1.02313144, grad/param norm = 5.4172e-02, time/batch = 0.1800s	
2040/10550 (epoch 9.668), train_loss = 0.99678254, grad/param norm = 5.2801e-02, time/batch = 0.1802s	
2041/10550 (epoch 9.673), train_loss = 1.02041614, grad/param norm = 5.5333e-02, time/batch = 0.1816s	
2042/10550 (epoch 9.678), train_loss = 0.98729081, grad/param norm = 5.6787e-02, time/batch = 0.1799s	
2043/10550 (epoch 9.682), train_loss = 1.00651263, grad/param norm = 5.6299e-02, time/batch = 0.1797s	
2044/10550 (epoch 9.687), train_loss = 0.97809790, grad/param norm = 5.2932e-02, time/batch = 0.1801s	
2045/10550 (epoch 9.692), train_loss = 1.01661618, grad/param norm = 5.5899e-02, time/batch = 0.1804s	
2046/10550 (epoch 9.697), train_loss = 0.99638297, grad/param norm = 5.3050e-02, time/batch = 0.1796s	
2047/10550 (epoch 9.701), train_loss = 1.01163571, grad/param norm = 5.2595e-02, time/batch = 0.1804s	
2048/10550 (epoch 9.706), train_loss = 0.99676128, grad/param norm = 5.4502e-02, time/batch = 0.1800s	
2049/10550 (epoch 9.711), train_loss = 1.01533804, grad/param norm = 5.1571e-02, time/batch = 0.1801s	
2050/10550 (epoch 9.716), train_loss = 1.01292617, grad/param norm = 5.2876e-02, time/batch = 0.1798s	
2051/10550 (epoch 9.720), train_loss = 1.02103909, grad/param norm = 5.0154e-02, time/batch = 0.1804s	
2052/10550 (epoch 9.725), train_loss = 0.98765999, grad/param norm = 5.2040e-02, time/batch = 0.1795s	
2053/10550 (epoch 9.730), train_loss = 1.01321291, grad/param norm = 5.9534e-02, time/batch = 0.1793s	
2054/10550 (epoch 9.735), train_loss = 1.02057169, grad/param norm = 5.8170e-02, time/batch = 0.1803s	
2055/10550 (epoch 9.739), train_loss = 0.99203923, grad/param norm = 5.4260e-02, time/batch = 0.1802s	
2056/10550 (epoch 9.744), train_loss = 1.00138897, grad/param norm = 5.2849e-02, time/batch = 0.1802s	
2057/10550 (epoch 9.749), train_loss = 1.01890790, grad/param norm = 5.0664e-02, time/batch = 0.1801s	
2058/10550 (epoch 9.754), train_loss = 1.02196864, grad/param norm = 5.0590e-02, time/batch = 0.1793s	
2059/10550 (epoch 9.758), train_loss = 1.00241921, grad/param norm = 5.4845e-02, time/batch = 0.1802s	
2060/10550 (epoch 9.763), train_loss = 0.98108877, grad/param norm = 5.6462e-02, time/batch = 0.1798s	
2061/10550 (epoch 9.768), train_loss = 1.03107717, grad/param norm = 5.6631e-02, time/batch = 0.1813s	
2062/10550 (epoch 9.773), train_loss = 1.04484040, grad/param norm = 5.5633e-02, time/batch = 0.1797s	
2063/10550 (epoch 9.777), train_loss = 1.00796980, grad/param norm = 5.2857e-02, time/batch = 0.1794s	
2064/10550 (epoch 9.782), train_loss = 1.05743559, grad/param norm = 5.6556e-02, time/batch = 0.1803s	
2065/10550 (epoch 9.787), train_loss = 1.00573631, grad/param norm = 5.3891e-02, time/batch = 0.1796s	
2066/10550 (epoch 9.791), train_loss = 0.98393744, grad/param norm = 5.1939e-02, time/batch = 0.1805s	
2067/10550 (epoch 9.796), train_loss = 1.01350280, grad/param norm = 5.3986e-02, time/batch = 0.1801s	
2068/10550 (epoch 9.801), train_loss = 0.99968470, grad/param norm = 5.4499e-02, time/batch = 0.1795s	
2069/10550 (epoch 9.806), train_loss = 1.02395130, grad/param norm = 5.6224e-02, time/batch = 0.1800s	
2070/10550 (epoch 9.810), train_loss = 1.05749157, grad/param norm = 5.6319e-02, time/batch = 0.1803s	
2071/10550 (epoch 9.815), train_loss = 1.01330534, grad/param norm = 5.3227e-02, time/batch = 0.1810s	
2072/10550 (epoch 9.820), train_loss = 1.01521466, grad/param norm = 5.4154e-02, time/batch = 0.1781s	
2073/10550 (epoch 9.825), train_loss = 1.01573737, grad/param norm = 5.5259e-02, time/batch = 0.1798s	
2074/10550 (epoch 9.829), train_loss = 0.99356088, grad/param norm = 5.3389e-02, time/batch = 0.1800s	
2075/10550 (epoch 9.834), train_loss = 0.99982227, grad/param norm = 5.3392e-02, time/batch = 0.1803s	
2076/10550 (epoch 9.839), train_loss = 0.99516151, grad/param norm = 5.7897e-02, time/batch = 0.1795s	
2077/10550 (epoch 9.844), train_loss = 1.01023723, grad/param norm = 5.6978e-02, time/batch = 0.1801s	
2078/10550 (epoch 9.848), train_loss = 1.00559772, grad/param norm = 5.5130e-02, time/batch = 0.1792s	
2079/10550 (epoch 9.853), train_loss = 1.02103951, grad/param norm = 5.5404e-02, time/batch = 0.1798s	
2080/10550 (epoch 9.858), train_loss = 1.03138037, grad/param norm = 5.4700e-02, time/batch = 0.1802s	
2081/10550 (epoch 9.863), train_loss = 0.99298338, grad/param norm = 5.3924e-02, time/batch = 0.1807s	
2082/10550 (epoch 9.867), train_loss = 1.03780497, grad/param norm = 5.6319e-02, time/batch = 0.1795s	
2083/10550 (epoch 9.872), train_loss = 1.01466330, grad/param norm = 5.3928e-02, time/batch = 0.1798s	
2084/10550 (epoch 9.877), train_loss = 0.97167216, grad/param norm = 5.0646e-02, time/batch = 0.1795s	
2085/10550 (epoch 9.882), train_loss = 0.99377566, grad/param norm = 5.2832e-02, time/batch = 0.1798s	
2086/10550 (epoch 9.886), train_loss = 1.01852229, grad/param norm = 5.3050e-02, time/batch = 0.1799s	
2087/10550 (epoch 9.891), train_loss = 0.99524029, grad/param norm = 5.3247e-02, time/batch = 0.1799s	
2088/10550 (epoch 9.896), train_loss = 0.98721500, grad/param norm = 5.2278e-02, time/batch = 0.1792s	
2089/10550 (epoch 9.900), train_loss = 0.98967226, grad/param norm = 5.3874e-02, time/batch = 0.1802s	
2090/10550 (epoch 9.905), train_loss = 0.98294604, grad/param norm = 5.4733e-02, time/batch = 0.1802s	
2091/10550 (epoch 9.910), train_loss = 0.99272929, grad/param norm = 5.1623e-02, time/batch = 0.1811s	
2092/10550 (epoch 9.915), train_loss = 0.99146671, grad/param norm = 5.3039e-02, time/batch = 0.1795s	
2093/10550 (epoch 9.919), train_loss = 0.99617420, grad/param norm = 5.2885e-02, time/batch = 0.1798s	
2094/10550 (epoch 9.924), train_loss = 1.00648492, grad/param norm = 5.4421e-02, time/batch = 0.1799s	
2095/10550 (epoch 9.929), train_loss = 0.99973807, grad/param norm = 5.3328e-02, time/batch = 0.1805s	
2096/10550 (epoch 9.934), train_loss = 1.01613448, grad/param norm = 5.4747e-02, time/batch = 0.1801s	
2097/10550 (epoch 9.938), train_loss = 1.01749921, grad/param norm = 5.9580e-02, time/batch = 0.1802s	
2098/10550 (epoch 9.943), train_loss = 0.99340388, grad/param norm = 5.2592e-02, time/batch = 0.1793s	
2099/10550 (epoch 9.948), train_loss = 1.02187667, grad/param norm = 5.5433e-02, time/batch = 0.1802s	
2100/10550 (epoch 9.953), train_loss = 1.03674397, grad/param norm = 5.8096e-02, time/batch = 0.1805s	
2101/10550 (epoch 9.957), train_loss = 1.03849729, grad/param norm = 6.0215e-02, time/batch = 0.1810s	
2102/10550 (epoch 9.962), train_loss = 1.01623209, grad/param norm = 5.6400e-02, time/batch = 0.1793s	
2103/10550 (epoch 9.967), train_loss = 1.01960561, grad/param norm = 5.4895e-02, time/batch = 0.1798s	
2104/10550 (epoch 9.972), train_loss = 0.99280109, grad/param norm = 5.1795e-02, time/batch = 0.1799s	
2105/10550 (epoch 9.976), train_loss = 1.00205700, grad/param norm = 5.2778e-02, time/batch = 0.1796s	
2106/10550 (epoch 9.981), train_loss = 0.99805128, grad/param norm = 5.2553e-02, time/batch = 0.1798s	
2107/10550 (epoch 9.986), train_loss = 0.99389036, grad/param norm = 5.2479e-02, time/batch = 0.1797s	
2108/10550 (epoch 9.991), train_loss = 1.04994693, grad/param norm = 5.6248e-02, time/batch = 0.1799s	
2109/10550 (epoch 9.995), train_loss = 1.00820260, grad/param norm = 5.4218e-02, time/batch = 0.1799s	
decayed learning rate by a factor 0.97 to 0.00194	
2110/10550 (epoch 10.000), train_loss = 1.00913016, grad/param norm = 5.5670e-02, time/batch = 0.1799s	
2111/10550 (epoch 10.005), train_loss = 1.18978036, grad/param norm = 6.3313e-02, time/batch = 0.1814s	
2112/10550 (epoch 10.009), train_loss = 0.98825947, grad/param norm = 5.1847e-02, time/batch = 0.1798s	
2113/10550 (epoch 10.014), train_loss = 0.99339933, grad/param norm = 5.1756e-02, time/batch = 0.1797s	
2114/10550 (epoch 10.019), train_loss = 1.02941336, grad/param norm = 5.5023e-02, time/batch = 0.1801s	
2115/10550 (epoch 10.024), train_loss = 1.01425993, grad/param norm = 5.3922e-02, time/batch = 0.1803s	
2116/10550 (epoch 10.028), train_loss = 0.99713056, grad/param norm = 5.1459e-02, time/batch = 0.1800s	
2117/10550 (epoch 10.033), train_loss = 1.02436234, grad/param norm = 5.3473e-02, time/batch = 0.1800s	
2118/10550 (epoch 10.038), train_loss = 1.00944759, grad/param norm = 5.1973e-02, time/batch = 0.1800s	
2119/10550 (epoch 10.043), train_loss = 0.97444890, grad/param norm = 5.1036e-02, time/batch = 0.1802s	
2120/10550 (epoch 10.047), train_loss = 0.97569234, grad/param norm = 5.2743e-02, time/batch = 0.1801s	
2121/10550 (epoch 10.052), train_loss = 1.02956224, grad/param norm = 5.4928e-02, time/batch = 0.1813s	
2122/10550 (epoch 10.057), train_loss = 0.99846565, grad/param norm = 5.4641e-02, time/batch = 0.1793s	
2123/10550 (epoch 10.062), train_loss = 1.01456685, grad/param norm = 5.2644e-02, time/batch = 0.1801s	
2124/10550 (epoch 10.066), train_loss = 1.00087333, grad/param norm = 5.2258e-02, time/batch = 0.1797s	
2125/10550 (epoch 10.071), train_loss = 0.96424691, grad/param norm = 5.2057e-02, time/batch = 0.1802s	
2126/10550 (epoch 10.076), train_loss = 0.98719223, grad/param norm = 5.5153e-02, time/batch = 0.1797s	
2127/10550 (epoch 10.081), train_loss = 1.01268914, grad/param norm = 5.5050e-02, time/batch = 0.1799s	
2128/10550 (epoch 10.085), train_loss = 0.99259250, grad/param norm = 5.2201e-02, time/batch = 0.1792s	
2129/10550 (epoch 10.090), train_loss = 0.98002914, grad/param norm = 5.3737e-02, time/batch = 0.1805s	
2130/10550 (epoch 10.095), train_loss = 1.00062457, grad/param norm = 5.4760e-02, time/batch = 0.1803s	
2131/10550 (epoch 10.100), train_loss = 0.98855788, grad/param norm = 5.3541e-02, time/batch = 0.1810s	
2132/10550 (epoch 10.104), train_loss = 0.95824969, grad/param norm = 5.3432e-02, time/batch = 0.1793s	
2133/10550 (epoch 10.109), train_loss = 0.95957202, grad/param norm = 5.4097e-02, time/batch = 0.1801s	
2134/10550 (epoch 10.114), train_loss = 0.99362338, grad/param norm = 5.6611e-02, time/batch = 0.1794s	
2135/10550 (epoch 10.118), train_loss = 0.95416108, grad/param norm = 5.5007e-02, time/batch = 0.1806s	
2136/10550 (epoch 10.123), train_loss = 1.02006088, grad/param norm = 5.8811e-02, time/batch = 0.1808s	
2137/10550 (epoch 10.128), train_loss = 0.98241803, grad/param norm = 5.2977e-02, time/batch = 0.1798s	
2138/10550 (epoch 10.133), train_loss = 0.95929965, grad/param norm = 5.2560e-02, time/batch = 0.1797s	
2139/10550 (epoch 10.137), train_loss = 0.96845397, grad/param norm = 5.3584e-02, time/batch = 0.1793s	
2140/10550 (epoch 10.142), train_loss = 1.00186453, grad/param norm = 5.5756e-02, time/batch = 0.1802s	
2141/10550 (epoch 10.147), train_loss = 0.97959268, grad/param norm = 5.3867e-02, time/batch = 0.1811s	
2142/10550 (epoch 10.152), train_loss = 0.98707490, grad/param norm = 5.3060e-02, time/batch = 0.1794s	
2143/10550 (epoch 10.156), train_loss = 0.98091665, grad/param norm = 5.1547e-02, time/batch = 0.1793s	
2144/10550 (epoch 10.161), train_loss = 0.98757327, grad/param norm = 5.2190e-02, time/batch = 0.1800s	
2145/10550 (epoch 10.166), train_loss = 0.99684899, grad/param norm = 5.8384e-02, time/batch = 0.1799s	
2146/10550 (epoch 10.171), train_loss = 0.98096232, grad/param norm = 5.5682e-02, time/batch = 0.1798s	
2147/10550 (epoch 10.175), train_loss = 1.02180855, grad/param norm = 5.8820e-02, time/batch = 0.1802s	
2148/10550 (epoch 10.180), train_loss = 0.99421520, grad/param norm = 5.5145e-02, time/batch = 0.1794s	
2149/10550 (epoch 10.185), train_loss = 1.00077314, grad/param norm = 5.3407e-02, time/batch = 0.1795s	
2150/10550 (epoch 10.190), train_loss = 0.97246741, grad/param norm = 5.4248e-02, time/batch = 0.1805s	
2151/10550 (epoch 10.194), train_loss = 0.98431713, grad/param norm = 5.4271e-02, time/batch = 0.1812s	
2152/10550 (epoch 10.199), train_loss = 1.00819035, grad/param norm = 5.5996e-02, time/batch = 0.1793s	
2153/10550 (epoch 10.204), train_loss = 0.98844443, grad/param norm = 5.7316e-02, time/batch = 0.1800s	
2154/10550 (epoch 10.209), train_loss = 0.99813687, grad/param norm = 5.3778e-02, time/batch = 0.1795s	
2155/10550 (epoch 10.213), train_loss = 0.99472835, grad/param norm = 5.3365e-02, time/batch = 0.1797s	
2156/10550 (epoch 10.218), train_loss = 1.00639253, grad/param norm = 5.7631e-02, time/batch = 0.1796s	
2157/10550 (epoch 10.223), train_loss = 0.96479751, grad/param norm = 5.7491e-02, time/batch = 0.1803s	
2158/10550 (epoch 10.227), train_loss = 0.95091328, grad/param norm = 5.2268e-02, time/batch = 0.1796s	
2159/10550 (epoch 10.232), train_loss = 0.97901132, grad/param norm = 5.3358e-02, time/batch = 0.1803s	
2160/10550 (epoch 10.237), train_loss = 0.97112998, grad/param norm = 5.3671e-02, time/batch = 0.1795s	
2161/10550 (epoch 10.242), train_loss = 0.98021540, grad/param norm = 5.5403e-02, time/batch = 0.1811s	
2162/10550 (epoch 10.246), train_loss = 0.97235515, grad/param norm = 5.6260e-02, time/batch = 0.1796s	
2163/10550 (epoch 10.251), train_loss = 0.98721171, grad/param norm = 5.5458e-02, time/batch = 0.1799s	
2164/10550 (epoch 10.256), train_loss = 0.98709441, grad/param norm = 5.5108e-02, time/batch = 0.1799s	
2165/10550 (epoch 10.261), train_loss = 0.96527675, grad/param norm = 5.4466e-02, time/batch = 0.1799s	
2166/10550 (epoch 10.265), train_loss = 0.97514657, grad/param norm = 5.4095e-02, time/batch = 0.1799s	
2167/10550 (epoch 10.270), train_loss = 0.96465430, grad/param norm = 5.3669e-02, time/batch = 0.1799s	
2168/10550 (epoch 10.275), train_loss = 0.99229612, grad/param norm = 5.6346e-02, time/batch = 0.1795s	
2169/10550 (epoch 10.280), train_loss = 0.99703926, grad/param norm = 5.5727e-02, time/batch = 0.1799s	
2170/10550 (epoch 10.284), train_loss = 0.99212178, grad/param norm = 5.6169e-02, time/batch = 0.1802s	
2171/10550 (epoch 10.289), train_loss = 0.97329529, grad/param norm = 5.6320e-02, time/batch = 0.1812s	
2172/10550 (epoch 10.294), train_loss = 0.97986835, grad/param norm = 5.8453e-02, time/batch = 0.1797s	
2173/10550 (epoch 10.299), train_loss = 0.94873365, grad/param norm = 5.1909e-02, time/batch = 0.1798s	
2174/10550 (epoch 10.303), train_loss = 0.98744891, grad/param norm = 5.5400e-02, time/batch = 0.1798s	
2175/10550 (epoch 10.308), train_loss = 0.96286597, grad/param norm = 5.3273e-02, time/batch = 0.1799s	
2176/10550 (epoch 10.313), train_loss = 0.97767663, grad/param norm = 5.5052e-02, time/batch = 0.1799s	
2177/10550 (epoch 10.318), train_loss = 0.97806908, grad/param norm = 5.7141e-02, time/batch = 0.1803s	
2178/10550 (epoch 10.322), train_loss = 1.00084887, grad/param norm = 5.7687e-02, time/batch = 0.1797s	
2179/10550 (epoch 10.327), train_loss = 0.97646627, grad/param norm = 5.4776e-02, time/batch = 0.1798s	
2180/10550 (epoch 10.332), train_loss = 1.00250034, grad/param norm = 5.6781e-02, time/batch = 0.1798s	
2181/10550 (epoch 10.336), train_loss = 0.99081467, grad/param norm = 5.8328e-02, time/batch = 0.1813s	
2182/10550 (epoch 10.341), train_loss = 0.95665767, grad/param norm = 5.7145e-02, time/batch = 0.1792s	
2183/10550 (epoch 10.346), train_loss = 0.99283749, grad/param norm = 5.4792e-02, time/batch = 0.1801s	
2184/10550 (epoch 10.351), train_loss = 0.97196820, grad/param norm = 5.3582e-02, time/batch = 0.1797s	
2185/10550 (epoch 10.355), train_loss = 0.96790873, grad/param norm = 5.2551e-02, time/batch = 0.1801s	
2186/10550 (epoch 10.360), train_loss = 1.02620783, grad/param norm = 6.1895e-02, time/batch = 0.1801s	
2187/10550 (epoch 10.365), train_loss = 0.99587141, grad/param norm = 5.7564e-02, time/batch = 0.1799s	
2188/10550 (epoch 10.370), train_loss = 0.97354164, grad/param norm = 5.5218e-02, time/batch = 0.1800s	
2189/10550 (epoch 10.374), train_loss = 0.98648559, grad/param norm = 5.5181e-02, time/batch = 0.1804s	
2190/10550 (epoch 10.379), train_loss = 0.99105101, grad/param norm = 5.5348e-02, time/batch = 0.1804s	
2191/10550 (epoch 10.384), train_loss = 0.95836313, grad/param norm = 5.3322e-02, time/batch = 0.1808s	
2192/10550 (epoch 10.389), train_loss = 0.95267869, grad/param norm = 5.5577e-02, time/batch = 0.1791s	
2193/10550 (epoch 10.393), train_loss = 0.96945114, grad/param norm = 5.5767e-02, time/batch = 0.1794s	
2194/10550 (epoch 10.398), train_loss = 0.95602928, grad/param norm = 5.4385e-02, time/batch = 0.1798s	
2195/10550 (epoch 10.403), train_loss = 1.00318733, grad/param norm = 5.7555e-02, time/batch = 0.1798s	
2196/10550 (epoch 10.408), train_loss = 0.99038439, grad/param norm = 5.5604e-02, time/batch = 0.1799s	
2197/10550 (epoch 10.412), train_loss = 0.96297185, grad/param norm = 5.4119e-02, time/batch = 0.1799s	
2198/10550 (epoch 10.417), train_loss = 0.96277791, grad/param norm = 5.4221e-02, time/batch = 0.1802s	
2199/10550 (epoch 10.422), train_loss = 0.97571553, grad/param norm = 5.4907e-02, time/batch = 0.1801s	
2200/10550 (epoch 10.427), train_loss = 1.00260252, grad/param norm = 5.9190e-02, time/batch = 0.1800s	
2201/10550 (epoch 10.431), train_loss = 0.98698029, grad/param norm = 5.9438e-02, time/batch = 0.1810s	
2202/10550 (epoch 10.436), train_loss = 0.94643988, grad/param norm = 5.3271e-02, time/batch = 0.1794s	
2203/10550 (epoch 10.441), train_loss = 0.98290301, grad/param norm = 5.4531e-02, time/batch = 0.1796s	
2204/10550 (epoch 10.445), train_loss = 0.99087889, grad/param norm = 5.4335e-02, time/batch = 0.1798s	
2205/10550 (epoch 10.450), train_loss = 0.97973407, grad/param norm = 5.5980e-02, time/batch = 0.1799s	
2206/10550 (epoch 10.455), train_loss = 0.98221230, grad/param norm = 5.8198e-02, time/batch = 0.1799s	
2207/10550 (epoch 10.460), train_loss = 0.93961873, grad/param norm = 5.4371e-02, time/batch = 0.1803s	
2208/10550 (epoch 10.464), train_loss = 0.95683235, grad/param norm = 5.4114e-02, time/batch = 0.1794s	
2209/10550 (epoch 10.469), train_loss = 0.94890225, grad/param norm = 5.3168e-02, time/batch = 0.1804s	
2210/10550 (epoch 10.474), train_loss = 0.98552167, grad/param norm = 5.6068e-02, time/batch = 0.1794s	
2211/10550 (epoch 10.479), train_loss = 0.94059936, grad/param norm = 5.0281e-02, time/batch = 0.1815s	
2212/10550 (epoch 10.483), train_loss = 0.98417355, grad/param norm = 5.4342e-02, time/batch = 0.1797s	
2213/10550 (epoch 10.488), train_loss = 0.98062282, grad/param norm = 5.3650e-02, time/batch = 0.1803s	
2214/10550 (epoch 10.493), train_loss = 0.96170515, grad/param norm = 5.6376e-02, time/batch = 0.1800s	
2215/10550 (epoch 10.498), train_loss = 0.96529831, grad/param norm = 5.3772e-02, time/batch = 0.1799s	
2216/10550 (epoch 10.502), train_loss = 0.97773675, grad/param norm = 5.4425e-02, time/batch = 0.1799s	
2217/10550 (epoch 10.507), train_loss = 0.94453907, grad/param norm = 5.1993e-02, time/batch = 0.1798s	
2218/10550 (epoch 10.512), train_loss = 0.92526526, grad/param norm = 5.3667e-02, time/batch = 0.1797s	
2219/10550 (epoch 10.517), train_loss = 0.97165926, grad/param norm = 5.6355e-02, time/batch = 0.1798s	
2220/10550 (epoch 10.521), train_loss = 0.95476697, grad/param norm = 5.4224e-02, time/batch = 0.1800s	
2221/10550 (epoch 10.526), train_loss = 0.90680915, grad/param norm = 5.3034e-02, time/batch = 0.1808s	
2222/10550 (epoch 10.531), train_loss = 0.94173027, grad/param norm = 5.4112e-02, time/batch = 0.1791s	
2223/10550 (epoch 10.536), train_loss = 0.98030199, grad/param norm = 5.3222e-02, time/batch = 0.1799s	
2224/10550 (epoch 10.540), train_loss = 0.97770700, grad/param norm = 5.3699e-02, time/batch = 0.1799s	
2225/10550 (epoch 10.545), train_loss = 0.94789856, grad/param norm = 5.3806e-02, time/batch = 0.1803s	
2226/10550 (epoch 10.550), train_loss = 0.98055662, grad/param norm = 5.6025e-02, time/batch = 0.1801s	
2227/10550 (epoch 10.555), train_loss = 0.96107643, grad/param norm = 5.4660e-02, time/batch = 0.1796s	
2228/10550 (epoch 10.559), train_loss = 0.99820698, grad/param norm = 5.8814e-02, time/batch = 0.1801s	
2229/10550 (epoch 10.564), train_loss = 0.95217316, grad/param norm = 5.6008e-02, time/batch = 0.1803s	
2230/10550 (epoch 10.569), train_loss = 0.95217929, grad/param norm = 5.4845e-02, time/batch = 0.1806s	
2231/10550 (epoch 10.573), train_loss = 0.97190433, grad/param norm = 5.5925e-02, time/batch = 0.1811s	
2232/10550 (epoch 10.578), train_loss = 0.97821781, grad/param norm = 6.0709e-02, time/batch = 0.1794s	
2233/10550 (epoch 10.583), train_loss = 0.95175822, grad/param norm = 5.5343e-02, time/batch = 0.1793s	
2234/10550 (epoch 10.588), train_loss = 0.92773576, grad/param norm = 5.4897e-02, time/batch = 0.1793s	
2235/10550 (epoch 10.592), train_loss = 0.97128210, grad/param norm = 5.8061e-02, time/batch = 0.1801s	
2236/10550 (epoch 10.597), train_loss = 0.95322927, grad/param norm = 5.6111e-02, time/batch = 0.1795s	
2237/10550 (epoch 10.602), train_loss = 0.97775417, grad/param norm = 5.9329e-02, time/batch = 0.1800s	
2238/10550 (epoch 10.607), train_loss = 0.96919114, grad/param norm = 5.6852e-02, time/batch = 0.1795s	
2239/10550 (epoch 10.611), train_loss = 0.96605978, grad/param norm = 5.7511e-02, time/batch = 0.1805s	
2240/10550 (epoch 10.616), train_loss = 0.93616741, grad/param norm = 5.4041e-02, time/batch = 0.1796s	
2241/10550 (epoch 10.621), train_loss = 0.93986623, grad/param norm = 5.9306e-02, time/batch = 0.1814s	
2242/10550 (epoch 10.626), train_loss = 0.94449322, grad/param norm = 5.4042e-02, time/batch = 0.1792s	
2243/10550 (epoch 10.630), train_loss = 0.97303026, grad/param norm = 5.7855e-02, time/batch = 0.1796s	
2244/10550 (epoch 10.635), train_loss = 0.98496246, grad/param norm = 5.6602e-02, time/batch = 0.1796s	
2245/10550 (epoch 10.640), train_loss = 0.97906228, grad/param norm = 5.2874e-02, time/batch = 0.1802s	
2246/10550 (epoch 10.645), train_loss = 0.94771634, grad/param norm = 5.3295e-02, time/batch = 0.1797s	
2247/10550 (epoch 10.649), train_loss = 0.97695863, grad/param norm = 5.4962e-02, time/batch = 0.1798s	
2248/10550 (epoch 10.654), train_loss = 0.97582278, grad/param norm = 5.6289e-02, time/batch = 0.1797s	
2249/10550 (epoch 10.659), train_loss = 0.97672057, grad/param norm = 5.5948e-02, time/batch = 0.1794s	
2250/10550 (epoch 10.664), train_loss = 0.97502259, grad/param norm = 5.6137e-02, time/batch = 0.1799s	
2251/10550 (epoch 10.668), train_loss = 0.94969812, grad/param norm = 5.5736e-02, time/batch = 0.1808s	
2252/10550 (epoch 10.673), train_loss = 0.96877362, grad/param norm = 5.9260e-02, time/batch = 0.1799s	
2253/10550 (epoch 10.678), train_loss = 0.93203643, grad/param norm = 5.4783e-02, time/batch = 0.1794s	
2254/10550 (epoch 10.682), train_loss = 0.95682757, grad/param norm = 5.8762e-02, time/batch = 0.1799s	
2255/10550 (epoch 10.687), train_loss = 0.93565073, grad/param norm = 5.7275e-02, time/batch = 0.1801s	
2256/10550 (epoch 10.692), train_loss = 0.97239370, grad/param norm = 5.7569e-02, time/batch = 0.1800s	
2257/10550 (epoch 10.697), train_loss = 0.95042439, grad/param norm = 5.7036e-02, time/batch = 0.1798s	
2258/10550 (epoch 10.701), train_loss = 0.95859519, grad/param norm = 5.3723e-02, time/batch = 0.1795s	
2259/10550 (epoch 10.706), train_loss = 0.94094206, grad/param norm = 5.6397e-02, time/batch = 0.1801s	
2260/10550 (epoch 10.711), train_loss = 0.96604383, grad/param norm = 5.4667e-02, time/batch = 0.1799s	
2261/10550 (epoch 10.716), train_loss = 0.95449295, grad/param norm = 5.3383e-02, time/batch = 0.1809s	
2262/10550 (epoch 10.720), train_loss = 0.97358448, grad/param norm = 5.4773e-02, time/batch = 0.1794s	
2263/10550 (epoch 10.725), train_loss = 0.93636778, grad/param norm = 5.2967e-02, time/batch = 0.1800s	
2264/10550 (epoch 10.730), train_loss = 0.94832596, grad/param norm = 5.4304e-02, time/batch = 0.1802s	
2265/10550 (epoch 10.735), train_loss = 0.95565095, grad/param norm = 5.4513e-02, time/batch = 0.1797s	
2266/10550 (epoch 10.739), train_loss = 0.94060752, grad/param norm = 5.4194e-02, time/batch = 0.1796s	
2267/10550 (epoch 10.744), train_loss = 0.94826572, grad/param norm = 5.3980e-02, time/batch = 0.1804s	
2268/10550 (epoch 10.749), train_loss = 0.97160429, grad/param norm = 5.5774e-02, time/batch = 0.1795s	
2269/10550 (epoch 10.754), train_loss = 0.97234845, grad/param norm = 5.4605e-02, time/batch = 0.1802s	
2270/10550 (epoch 10.758), train_loss = 0.95208240, grad/param norm = 5.8582e-02, time/batch = 0.1801s	
2271/10550 (epoch 10.763), train_loss = 0.93394623, grad/param norm = 5.8232e-02, time/batch = 0.1809s	
2272/10550 (epoch 10.768), train_loss = 0.97769018, grad/param norm = 5.9372e-02, time/batch = 0.1799s	
2273/10550 (epoch 10.773), train_loss = 0.99135130, grad/param norm = 5.7497e-02, time/batch = 0.1794s	
2274/10550 (epoch 10.777), train_loss = 0.94680774, grad/param norm = 5.1760e-02, time/batch = 0.1797s	
2275/10550 (epoch 10.782), train_loss = 0.99974222, grad/param norm = 5.7616e-02, time/batch = 0.1798s	
2276/10550 (epoch 10.787), train_loss = 0.95290286, grad/param norm = 5.7195e-02, time/batch = 0.1798s	
2277/10550 (epoch 10.791), train_loss = 0.93907677, grad/param norm = 5.8531e-02, time/batch = 0.1803s	
2278/10550 (epoch 10.796), train_loss = 0.97130652, grad/param norm = 5.6486e-02, time/batch = 0.1797s	
2279/10550 (epoch 10.801), train_loss = 0.94657218, grad/param norm = 5.6324e-02, time/batch = 0.1796s	
2280/10550 (epoch 10.806), train_loss = 0.97047534, grad/param norm = 5.8280e-02, time/batch = 0.1798s	
2281/10550 (epoch 10.810), train_loss = 1.00825559, grad/param norm = 5.8753e-02, time/batch = 0.1816s	
2282/10550 (epoch 10.815), train_loss = 0.97008484, grad/param norm = 5.4623e-02, time/batch = 0.1799s	
2283/10550 (epoch 10.820), train_loss = 0.95764644, grad/param norm = 5.3554e-02, time/batch = 0.1798s	
2284/10550 (epoch 10.825), train_loss = 0.96255622, grad/param norm = 5.4446e-02, time/batch = 0.1798s	
2285/10550 (epoch 10.829), train_loss = 0.94143502, grad/param norm = 5.4387e-02, time/batch = 0.1801s	
2286/10550 (epoch 10.834), train_loss = 0.95822673, grad/param norm = 5.5874e-02, time/batch = 0.1800s	
2287/10550 (epoch 10.839), train_loss = 0.93499499, grad/param norm = 5.5574e-02, time/batch = 0.1802s	
2288/10550 (epoch 10.844), train_loss = 0.95376134, grad/param norm = 5.6653e-02, time/batch = 0.1797s	
2289/10550 (epoch 10.848), train_loss = 0.95013077, grad/param norm = 6.0011e-02, time/batch = 0.1800s	
2290/10550 (epoch 10.853), train_loss = 0.97504536, grad/param norm = 6.0283e-02, time/batch = 0.1802s	
2291/10550 (epoch 10.858), train_loss = 0.98716288, grad/param norm = 5.7750e-02, time/batch = 0.1810s	
2292/10550 (epoch 10.863), train_loss = 0.94942045, grad/param norm = 5.5284e-02, time/batch = 0.1800s	
2293/10550 (epoch 10.867), train_loss = 0.99097503, grad/param norm = 6.0518e-02, time/batch = 0.1802s	
2294/10550 (epoch 10.872), train_loss = 0.96473406, grad/param norm = 5.8428e-02, time/batch = 0.1802s	
2295/10550 (epoch 10.877), train_loss = 0.93137643, grad/param norm = 5.5440e-02, time/batch = 0.1799s	
2296/10550 (epoch 10.882), train_loss = 0.94663287, grad/param norm = 5.5300e-02, time/batch = 0.1802s	
2297/10550 (epoch 10.886), train_loss = 0.97360870, grad/param norm = 5.5440e-02, time/batch = 0.1799s	
2298/10550 (epoch 10.891), train_loss = 0.94723945, grad/param norm = 5.5685e-02, time/batch = 0.1794s	
2299/10550 (epoch 10.896), train_loss = 0.93722665, grad/param norm = 5.4734e-02, time/batch = 0.1801s	
2300/10550 (epoch 10.900), train_loss = 0.94031493, grad/param norm = 5.6377e-02, time/batch = 0.1799s	
2301/10550 (epoch 10.905), train_loss = 0.93218283, grad/param norm = 6.0437e-02, time/batch = 0.1812s	
2302/10550 (epoch 10.910), train_loss = 0.94642692, grad/param norm = 5.5093e-02, time/batch = 0.1797s	
2303/10550 (epoch 10.915), train_loss = 0.94839207, grad/param norm = 5.5843e-02, time/batch = 0.1801s	
2304/10550 (epoch 10.919), train_loss = 0.95189562, grad/param norm = 5.8271e-02, time/batch = 0.1798s	
2305/10550 (epoch 10.924), train_loss = 0.94979710, grad/param norm = 5.6363e-02, time/batch = 0.1802s	
2306/10550 (epoch 10.929), train_loss = 0.94886461, grad/param norm = 5.6384e-02, time/batch = 0.1804s	
2307/10550 (epoch 10.934), train_loss = 0.95768831, grad/param norm = 5.5131e-02, time/batch = 0.1800s	
2308/10550 (epoch 10.938), train_loss = 0.95900857, grad/param norm = 5.4233e-02, time/batch = 0.1800s	
2309/10550 (epoch 10.943), train_loss = 0.95190764, grad/param norm = 5.6205e-02, time/batch = 0.1797s	
2310/10550 (epoch 10.948), train_loss = 0.96261677, grad/param norm = 6.0067e-02, time/batch = 0.1800s	
2311/10550 (epoch 10.953), train_loss = 0.98117973, grad/param norm = 6.0700e-02, time/batch = 0.1810s	
2312/10550 (epoch 10.957), train_loss = 0.98681468, grad/param norm = 5.8089e-02, time/batch = 0.1798s	
2313/10550 (epoch 10.962), train_loss = 0.95870479, grad/param norm = 5.8230e-02, time/batch = 0.1793s	
2314/10550 (epoch 10.967), train_loss = 0.96205823, grad/param norm = 5.4328e-02, time/batch = 0.1800s	
2315/10550 (epoch 10.972), train_loss = 0.94456843, grad/param norm = 5.4561e-02, time/batch = 0.1801s	
2316/10550 (epoch 10.976), train_loss = 0.94566326, grad/param norm = 5.4326e-02, time/batch = 0.1799s	
2317/10550 (epoch 10.981), train_loss = 0.95616943, grad/param norm = 5.5004e-02, time/batch = 0.1796s	
2318/10550 (epoch 10.986), train_loss = 0.94093860, grad/param norm = 5.3188e-02, time/batch = 0.1793s	
2319/10550 (epoch 10.991), train_loss = 0.99628563, grad/param norm = 5.7599e-02, time/batch = 0.1797s	
2320/10550 (epoch 10.995), train_loss = 0.95264638, grad/param norm = 5.8568e-02, time/batch = 0.1800s	
decayed learning rate by a factor 0.97 to 0.0018818	
2321/10550 (epoch 11.000), train_loss = 0.96961197, grad/param norm = 5.9353e-02, time/batch = 0.1811s	
2322/10550 (epoch 11.005), train_loss = 1.14636063, grad/param norm = 6.1141e-02, time/batch = 0.1798s	
2323/10550 (epoch 11.009), train_loss = 0.94175371, grad/param norm = 5.5615e-02, time/batch = 0.1799s	
2324/10550 (epoch 11.014), train_loss = 0.95335293, grad/param norm = 5.7198e-02, time/batch = 0.1799s	
2325/10550 (epoch 11.019), train_loss = 0.98021120, grad/param norm = 5.7267e-02, time/batch = 0.1802s	
2326/10550 (epoch 11.024), train_loss = 0.97370100, grad/param norm = 5.7438e-02, time/batch = 0.1796s	
2327/10550 (epoch 11.028), train_loss = 0.95164804, grad/param norm = 5.5096e-02, time/batch = 0.1802s	
2328/10550 (epoch 11.033), train_loss = 0.98143284, grad/param norm = 5.7966e-02, time/batch = 0.1799s	
2329/10550 (epoch 11.038), train_loss = 0.96024647, grad/param norm = 5.6752e-02, time/batch = 0.1799s	
2330/10550 (epoch 11.043), train_loss = 0.92714211, grad/param norm = 5.3285e-02, time/batch = 0.1794s	
2331/10550 (epoch 11.047), train_loss = 0.92918351, grad/param norm = 5.4062e-02, time/batch = 0.1807s	
2332/10550 (epoch 11.052), train_loss = 0.97421964, grad/param norm = 5.6748e-02, time/batch = 0.1791s	
2333/10550 (epoch 11.057), train_loss = 0.94608041, grad/param norm = 5.7900e-02, time/batch = 0.1802s	
2334/10550 (epoch 11.062), train_loss = 0.97017241, grad/param norm = 5.7122e-02, time/batch = 0.1794s	
2335/10550 (epoch 11.066), train_loss = 0.94872179, grad/param norm = 5.4832e-02, time/batch = 0.1801s	
2336/10550 (epoch 11.071), train_loss = 0.92126202, grad/param norm = 5.5311e-02, time/batch = 0.1800s	
2337/10550 (epoch 11.076), train_loss = 0.94657849, grad/param norm = 5.7041e-02, time/batch = 0.1798s	
2338/10550 (epoch 11.081), train_loss = 0.96576242, grad/param norm = 5.7147e-02, time/batch = 0.1799s	
2339/10550 (epoch 11.085), train_loss = 0.95488765, grad/param norm = 5.5197e-02, time/batch = 0.1797s	
2340/10550 (epoch 11.090), train_loss = 0.92883862, grad/param norm = 5.5770e-02, time/batch = 0.1805s	
2341/10550 (epoch 11.095), train_loss = 0.94764969, grad/param norm = 5.3965e-02, time/batch = 0.1809s	
2342/10550 (epoch 11.100), train_loss = 0.94031489, grad/param norm = 5.5938e-02, time/batch = 0.1793s	
2343/10550 (epoch 11.104), train_loss = 0.92455471, grad/param norm = 5.6892e-02, time/batch = 0.1801s	
2344/10550 (epoch 11.109), train_loss = 0.91992818, grad/param norm = 5.7820e-02, time/batch = 0.1801s	
2345/10550 (epoch 11.114), train_loss = 0.94277887, grad/param norm = 5.7458e-02, time/batch = 0.1801s	
2346/10550 (epoch 11.118), train_loss = 0.90623496, grad/param norm = 5.6214e-02, time/batch = 0.1798s	
2347/10550 (epoch 11.123), train_loss = 0.96998265, grad/param norm = 5.8023e-02, time/batch = 0.1802s	
2348/10550 (epoch 11.128), train_loss = 0.93384817, grad/param norm = 5.9345e-02, time/batch = 0.1796s	
2349/10550 (epoch 11.133), train_loss = 0.92061081, grad/param norm = 6.0972e-02, time/batch = 0.1799s	
2350/10550 (epoch 11.137), train_loss = 0.92624424, grad/param norm = 5.6477e-02, time/batch = 0.1798s	
2351/10550 (epoch 11.142), train_loss = 0.95754438, grad/param norm = 6.0082e-02, time/batch = 0.1809s	
2352/10550 (epoch 11.147), train_loss = 0.93770878, grad/param norm = 5.6805e-02, time/batch = 0.1792s	
2353/10550 (epoch 11.152), train_loss = 0.93858422, grad/param norm = 5.3780e-02, time/batch = 0.1795s	
2354/10550 (epoch 11.156), train_loss = 0.94326761, grad/param norm = 5.5916e-02, time/batch = 0.1798s	
2355/10550 (epoch 11.161), train_loss = 0.93652647, grad/param norm = 5.6167e-02, time/batch = 0.1801s	
2356/10550 (epoch 11.166), train_loss = 0.93987935, grad/param norm = 5.5015e-02, time/batch = 0.1797s	
2357/10550 (epoch 11.171), train_loss = 0.93243393, grad/param norm = 5.5664e-02, time/batch = 0.1802s	
2358/10550 (epoch 11.175), train_loss = 0.95965464, grad/param norm = 5.6428e-02, time/batch = 0.1792s	
2359/10550 (epoch 11.180), train_loss = 0.93538158, grad/param norm = 5.6638e-02, time/batch = 0.1799s	
2360/10550 (epoch 11.185), train_loss = 0.96003988, grad/param norm = 5.9114e-02, time/batch = 0.1800s	
2361/10550 (epoch 11.190), train_loss = 0.92364595, grad/param norm = 5.9966e-02, time/batch = 0.1810s	
2362/10550 (epoch 11.194), train_loss = 0.93833099, grad/param norm = 5.9233e-02, time/batch = 0.1792s	
2363/10550 (epoch 11.199), train_loss = 0.95722350, grad/param norm = 5.9819e-02, time/batch = 0.1794s	
2364/10550 (epoch 11.204), train_loss = 0.93619141, grad/param norm = 5.8555e-02, time/batch = 0.1803s	
2365/10550 (epoch 11.209), train_loss = 0.94995669, grad/param norm = 5.6746e-02, time/batch = 0.1798s	
2366/10550 (epoch 11.213), train_loss = 0.95698591, grad/param norm = 5.8804e-02, time/batch = 0.1802s	
2367/10550 (epoch 11.218), train_loss = 0.95485178, grad/param norm = 5.8279e-02, time/batch = 0.1799s	
2368/10550 (epoch 11.223), train_loss = 0.90171214, grad/param norm = 5.5664e-02, time/batch = 0.1798s	
2369/10550 (epoch 11.227), train_loss = 0.89924750, grad/param norm = 5.4921e-02, time/batch = 0.1799s	
2370/10550 (epoch 11.232), train_loss = 0.93181444, grad/param norm = 5.7160e-02, time/batch = 0.1799s	
2371/10550 (epoch 11.237), train_loss = 0.93016680, grad/param norm = 5.5194e-02, time/batch = 0.1808s	
2372/10550 (epoch 11.242), train_loss = 0.92959686, grad/param norm = 5.6518e-02, time/batch = 0.1798s	
2373/10550 (epoch 11.246), train_loss = 0.91302633, grad/param norm = 5.3880e-02, time/batch = 0.1798s	
2374/10550 (epoch 11.251), train_loss = 0.93034838, grad/param norm = 5.5900e-02, time/batch = 0.1799s	
2375/10550 (epoch 11.256), train_loss = 0.94277268, grad/param norm = 5.9056e-02, time/batch = 0.1797s	
2376/10550 (epoch 11.261), train_loss = 0.91647698, grad/param norm = 5.6649e-02, time/batch = 0.1798s	
2377/10550 (epoch 11.265), train_loss = 0.92748847, grad/param norm = 5.7904e-02, time/batch = 0.1800s	
2378/10550 (epoch 11.270), train_loss = 0.92052069, grad/param norm = 5.8465e-02, time/batch = 0.1798s	
2379/10550 (epoch 11.275), train_loss = 0.93593012, grad/param norm = 5.6220e-02, time/batch = 0.1801s	
2380/10550 (epoch 11.280), train_loss = 0.94833618, grad/param norm = 5.8813e-02, time/batch = 0.1798s	
2381/10550 (epoch 11.284), train_loss = 0.93540769, grad/param norm = 5.8666e-02, time/batch = 0.1809s	
2382/10550 (epoch 11.289), train_loss = 0.92895061, grad/param norm = 5.9127e-02, time/batch = 0.1793s	
2383/10550 (epoch 11.294), train_loss = 0.93555327, grad/param norm = 6.0206e-02, time/batch = 0.1800s	
2384/10550 (epoch 11.299), train_loss = 0.91192395, grad/param norm = 5.6928e-02, time/batch = 0.1797s	
2385/10550 (epoch 11.303), train_loss = 0.93992969, grad/param norm = 5.6357e-02, time/batch = 0.1798s	
2386/10550 (epoch 11.308), train_loss = 0.92035128, grad/param norm = 5.9410e-02, time/batch = 0.1796s	
2387/10550 (epoch 11.313), train_loss = 0.92866200, grad/param norm = 5.6196e-02, time/batch = 0.1799s	
2388/10550 (epoch 11.318), train_loss = 0.92683772, grad/param norm = 5.7355e-02, time/batch = 0.1795s	
2389/10550 (epoch 11.322), train_loss = 0.95086642, grad/param norm = 5.9708e-02, time/batch = 0.1802s	
2390/10550 (epoch 11.327), train_loss = 0.93729645, grad/param norm = 6.1524e-02, time/batch = 0.1800s	
2391/10550 (epoch 11.332), train_loss = 0.94992586, grad/param norm = 5.9829e-02, time/batch = 0.1814s	
2392/10550 (epoch 11.336), train_loss = 0.93754173, grad/param norm = 5.8739e-02, time/batch = 0.1796s	
2393/10550 (epoch 11.341), train_loss = 0.90734702, grad/param norm = 5.8102e-02, time/batch = 0.1796s	
2394/10550 (epoch 11.346), train_loss = 0.95131709, grad/param norm = 5.9968e-02, time/batch = 0.1800s	
2395/10550 (epoch 11.351), train_loss = 0.93347938, grad/param norm = 5.9065e-02, time/batch = 0.1800s	
2396/10550 (epoch 11.355), train_loss = 0.92257824, grad/param norm = 5.4504e-02, time/batch = 0.1798s	
2397/10550 (epoch 11.360), train_loss = 0.96364791, grad/param norm = 5.6423e-02, time/batch = 0.1801s	
2398/10550 (epoch 11.365), train_loss = 0.93960835, grad/param norm = 5.8286e-02, time/batch = 0.1791s	
2399/10550 (epoch 11.370), train_loss = 0.92775804, grad/param norm = 5.9495e-02, time/batch = 0.1798s	
2400/10550 (epoch 11.374), train_loss = 0.92714699, grad/param norm = 5.6432e-02, time/batch = 0.1801s	
2401/10550 (epoch 11.379), train_loss = 0.94216100, grad/param norm = 5.7332e-02, time/batch = 0.1812s	
2402/10550 (epoch 11.384), train_loss = 0.92659372, grad/param norm = 5.9881e-02, time/batch = 0.1794s	
2403/10550 (epoch 11.389), train_loss = 0.91033161, grad/param norm = 6.1721e-02, time/batch = 0.1798s	
2404/10550 (epoch 11.393), train_loss = 0.91994398, grad/param norm = 5.8352e-02, time/batch = 0.1797s	
2405/10550 (epoch 11.398), train_loss = 0.92082498, grad/param norm = 6.1445e-02, time/batch = 0.1797s	
2406/10550 (epoch 11.403), train_loss = 0.96499586, grad/param norm = 6.1913e-02, time/batch = 0.1801s	
2407/10550 (epoch 11.408), train_loss = 0.94274397, grad/param norm = 5.6682e-02, time/batch = 0.1797s	
2408/10550 (epoch 11.412), train_loss = 0.91622906, grad/param norm = 5.5394e-02, time/batch = 0.1795s	
2409/10550 (epoch 11.417), train_loss = 0.92171349, grad/param norm = 5.6418e-02, time/batch = 0.1797s	
2410/10550 (epoch 11.422), train_loss = 0.93794257, grad/param norm = 5.9358e-02, time/batch = 0.1799s	
2411/10550 (epoch 11.427), train_loss = 0.94369102, grad/param norm = 5.8103e-02, time/batch = 0.1813s	
2412/10550 (epoch 11.431), train_loss = 0.93700602, grad/param norm = 5.9771e-02, time/batch = 0.1797s	
2413/10550 (epoch 11.436), train_loss = 0.90502728, grad/param norm = 5.6684e-02, time/batch = 0.1800s	
2414/10550 (epoch 11.441), train_loss = 0.93559035, grad/param norm = 5.8238e-02, time/batch = 0.1799s	
2415/10550 (epoch 11.445), train_loss = 0.94771477, grad/param norm = 5.8443e-02, time/batch = 0.1802s	
2416/10550 (epoch 11.450), train_loss = 0.93283290, grad/param norm = 5.9495e-02, time/batch = 0.1797s	
2417/10550 (epoch 11.455), train_loss = 0.92145379, grad/param norm = 5.7168e-02, time/batch = 0.1799s	
2418/10550 (epoch 11.460), train_loss = 0.90233355, grad/param norm = 5.6417e-02, time/batch = 0.1799s	
2419/10550 (epoch 11.464), train_loss = 0.90811855, grad/param norm = 5.6574e-02, time/batch = 0.1797s	
2420/10550 (epoch 11.469), train_loss = 0.91112597, grad/param norm = 5.5582e-02, time/batch = 0.1802s	
2421/10550 (epoch 11.474), train_loss = 0.93289667, grad/param norm = 5.8253e-02, time/batch = 0.1807s	
2422/10550 (epoch 11.479), train_loss = 0.88978548, grad/param norm = 5.2618e-02, time/batch = 0.1795s	
2423/10550 (epoch 11.483), train_loss = 0.93689878, grad/param norm = 5.7964e-02, time/batch = 0.1796s	
2424/10550 (epoch 11.488), train_loss = 0.92437345, grad/param norm = 5.7022e-02, time/batch = 0.1791s	
2425/10550 (epoch 11.493), train_loss = 0.91228959, grad/param norm = 5.3579e-02, time/batch = 0.1802s	
2426/10550 (epoch 11.498), train_loss = 0.91126837, grad/param norm = 5.6513e-02, time/batch = 0.1800s	
2427/10550 (epoch 11.502), train_loss = 0.91929136, grad/param norm = 5.5086e-02, time/batch = 0.1796s	
2428/10550 (epoch 11.507), train_loss = 0.90654529, grad/param norm = 5.8752e-02, time/batch = 0.1792s	
2429/10550 (epoch 11.512), train_loss = 0.88228036, grad/param norm = 5.9151e-02, time/batch = 0.1798s	
2430/10550 (epoch 11.517), train_loss = 0.91981524, grad/param norm = 5.8092e-02, time/batch = 0.1801s	
2431/10550 (epoch 11.521), train_loss = 0.90752804, grad/param norm = 5.6746e-02, time/batch = 0.1811s	
2432/10550 (epoch 11.526), train_loss = 0.86021873, grad/param norm = 5.6472e-02, time/batch = 0.1797s	
2433/10550 (epoch 11.531), train_loss = 0.89702586, grad/param norm = 5.6074e-02, time/batch = 0.1795s	
2434/10550 (epoch 11.536), train_loss = 0.93958720, grad/param norm = 5.6818e-02, time/batch = 0.1798s	
2435/10550 (epoch 11.540), train_loss = 0.92362396, grad/param norm = 5.6225e-02, time/batch = 0.1803s	
2436/10550 (epoch 11.545), train_loss = 0.89577815, grad/param norm = 5.5236e-02, time/batch = 0.1799s	
2437/10550 (epoch 11.550), train_loss = 0.92745449, grad/param norm = 5.5197e-02, time/batch = 0.1803s	
2438/10550 (epoch 11.555), train_loss = 0.91608441, grad/param norm = 5.8350e-02, time/batch = 0.1797s	
2439/10550 (epoch 11.559), train_loss = 0.94565282, grad/param norm = 5.8227e-02, time/batch = 0.1800s	
2440/10550 (epoch 11.564), train_loss = 0.90762578, grad/param norm = 5.9385e-02, time/batch = 0.1795s	
2441/10550 (epoch 11.569), train_loss = 0.90917103, grad/param norm = 6.1071e-02, time/batch = 0.1808s	
2442/10550 (epoch 11.573), train_loss = 0.92371958, grad/param norm = 5.7366e-02, time/batch = 0.1796s	
2443/10550 (epoch 11.578), train_loss = 0.92699710, grad/param norm = 5.9317e-02, time/batch = 0.1800s	
2444/10550 (epoch 11.583), train_loss = 0.90489910, grad/param norm = 5.8263e-02, time/batch = 0.1799s	
2445/10550 (epoch 11.588), train_loss = 0.88775811, grad/param norm = 5.7754e-02, time/batch = 0.1799s	
2446/10550 (epoch 11.592), train_loss = 0.92111415, grad/param norm = 5.9501e-02, time/batch = 0.1802s	
2447/10550 (epoch 11.597), train_loss = 0.90944424, grad/param norm = 5.6216e-02, time/batch = 0.1802s	
2448/10550 (epoch 11.602), train_loss = 0.93089438, grad/param norm = 6.1780e-02, time/batch = 0.1796s	
2449/10550 (epoch 11.607), train_loss = 0.90895332, grad/param norm = 5.6010e-02, time/batch = 0.1800s	
2450/10550 (epoch 11.611), train_loss = 0.91409984, grad/param norm = 5.9960e-02, time/batch = 0.1799s	
2451/10550 (epoch 11.616), train_loss = 0.89177303, grad/param norm = 5.7010e-02, time/batch = 0.1812s	
2452/10550 (epoch 11.621), train_loss = 0.88568478, grad/param norm = 5.6459e-02, time/batch = 0.1794s	
2453/10550 (epoch 11.626), train_loss = 0.89687778, grad/param norm = 5.9481e-02, time/batch = 0.1802s	
2454/10550 (epoch 11.630), train_loss = 0.92453569, grad/param norm = 6.2188e-02, time/batch = 0.1797s	
2455/10550 (epoch 11.635), train_loss = 0.93392741, grad/param norm = 5.9146e-02, time/batch = 0.1802s	
2456/10550 (epoch 11.640), train_loss = 0.93354655, grad/param norm = 5.5225e-02, time/batch = 0.1797s	
2457/10550 (epoch 11.645), train_loss = 0.90921604, grad/param norm = 5.9660e-02, time/batch = 0.1799s	
2458/10550 (epoch 11.649), train_loss = 0.94266799, grad/param norm = 6.0372e-02, time/batch = 0.1791s	
2459/10550 (epoch 11.654), train_loss = 0.91857832, grad/param norm = 5.6944e-02, time/batch = 0.1803s	
2460/10550 (epoch 11.659), train_loss = 0.92974251, grad/param norm = 5.8917e-02, time/batch = 0.1798s	
2461/10550 (epoch 11.664), train_loss = 0.92721375, grad/param norm = 5.8348e-02, time/batch = 0.1814s	
2462/10550 (epoch 11.668), train_loss = 0.89914349, grad/param norm = 5.9128e-02, time/batch = 0.1793s	
2463/10550 (epoch 11.673), train_loss = 0.92228970, grad/param norm = 6.0777e-02, time/batch = 0.1803s	
2464/10550 (epoch 11.678), train_loss = 0.88529466, grad/param norm = 5.6691e-02, time/batch = 0.1797s	
2465/10550 (epoch 11.682), train_loss = 0.90272568, grad/param norm = 5.6883e-02, time/batch = 0.1801s	
2466/10550 (epoch 11.687), train_loss = 0.88871281, grad/param norm = 5.9017e-02, time/batch = 0.1794s	
2467/10550 (epoch 11.692), train_loss = 0.93152217, grad/param norm = 6.1002e-02, time/batch = 0.1802s	
2468/10550 (epoch 11.697), train_loss = 0.90943056, grad/param norm = 6.3112e-02, time/batch = 0.1791s	
2469/10550 (epoch 11.701), train_loss = 0.93185868, grad/param norm = 6.0577e-02, time/batch = 0.1799s	
2470/10550 (epoch 11.706), train_loss = 0.89994496, grad/param norm = 5.9009e-02, time/batch = 0.1796s	
2471/10550 (epoch 11.711), train_loss = 0.92726681, grad/param norm = 5.7902e-02, time/batch = 0.1807s	
2472/10550 (epoch 11.716), train_loss = 0.90676269, grad/param norm = 5.6325e-02, time/batch = 0.1792s	
2473/10550 (epoch 11.720), train_loss = 0.92818558, grad/param norm = 5.8255e-02, time/batch = 0.1795s	
2474/10550 (epoch 11.725), train_loss = 0.89803189, grad/param norm = 5.7578e-02, time/batch = 0.1798s	
2475/10550 (epoch 11.730), train_loss = 0.90307272, grad/param norm = 5.8127e-02, time/batch = 0.1799s	
2476/10550 (epoch 11.735), train_loss = 0.90986621, grad/param norm = 5.5160e-02, time/batch = 0.1804s	
2477/10550 (epoch 11.739), train_loss = 0.89534360, grad/param norm = 5.5801e-02, time/batch = 0.1803s	
2478/10550 (epoch 11.744), train_loss = 0.89938831, grad/param norm = 5.5547e-02, time/batch = 0.1795s	
2479/10550 (epoch 11.749), train_loss = 0.92259427, grad/param norm = 5.7670e-02, time/batch = 0.1801s	
2480/10550 (epoch 11.754), train_loss = 0.92675909, grad/param norm = 5.6256e-02, time/batch = 0.1798s	
2481/10550 (epoch 11.758), train_loss = 0.89937091, grad/param norm = 5.8748e-02, time/batch = 0.1811s	
2482/10550 (epoch 11.763), train_loss = 0.88717781, grad/param norm = 5.9835e-02, time/batch = 0.1789s	
2483/10550 (epoch 11.768), train_loss = 0.93247134, grad/param norm = 6.2560e-02, time/batch = 0.1801s	
2484/10550 (epoch 11.773), train_loss = 0.95417316, grad/param norm = 6.3694e-02, time/batch = 0.1801s	
2485/10550 (epoch 11.777), train_loss = 0.90609269, grad/param norm = 5.8341e-02, time/batch = 0.1798s	
2486/10550 (epoch 11.782), train_loss = 0.95656824, grad/param norm = 6.1595e-02, time/batch = 0.1800s	
2487/10550 (epoch 11.787), train_loss = 0.89689658, grad/param norm = 5.7187e-02, time/batch = 0.1799s	
2488/10550 (epoch 11.791), train_loss = 0.89116255, grad/param norm = 5.9324e-02, time/batch = 0.1792s	
2489/10550 (epoch 11.796), train_loss = 0.92490629, grad/param norm = 5.8192e-02, time/batch = 0.1804s	
2490/10550 (epoch 11.801), train_loss = 0.90084022, grad/param norm = 6.0581e-02, time/batch = 0.1799s	
2491/10550 (epoch 11.806), train_loss = 0.92558806, grad/param norm = 6.0496e-02, time/batch = 0.1814s	
2492/10550 (epoch 11.810), train_loss = 0.95746317, grad/param norm = 6.1020e-02, time/batch = 0.1783s	
2493/10550 (epoch 11.815), train_loss = 0.92145162, grad/param norm = 5.5745e-02, time/batch = 0.1798s	
2494/10550 (epoch 11.820), train_loss = 0.91885927, grad/param norm = 5.7038e-02, time/batch = 0.1796s	
2495/10550 (epoch 11.825), train_loss = 0.91455596, grad/param norm = 5.5937e-02, time/batch = 0.1802s	
2496/10550 (epoch 11.829), train_loss = 0.89663212, grad/param norm = 5.8270e-02, time/batch = 0.1800s	
2497/10550 (epoch 11.834), train_loss = 0.90432801, grad/param norm = 5.7863e-02, time/batch = 0.1800s	
2498/10550 (epoch 11.839), train_loss = 0.89530294, grad/param norm = 5.7970e-02, time/batch = 0.1796s	
2499/10550 (epoch 11.844), train_loss = 0.90884060, grad/param norm = 6.0934e-02, time/batch = 0.1803s	
2500/10550 (epoch 11.848), train_loss = 0.90106503, grad/param norm = 5.8385e-02, time/batch = 0.1797s	
2501/10550 (epoch 11.853), train_loss = 0.92582590, grad/param norm = 5.9497e-02, time/batch = 0.1809s	
2502/10550 (epoch 11.858), train_loss = 0.93495748, grad/param norm = 6.5850e-02, time/batch = 0.1794s	
2503/10550 (epoch 11.863), train_loss = 0.90999722, grad/param norm = 6.1632e-02, time/batch = 0.1798s	
2504/10550 (epoch 11.867), train_loss = 0.92723090, grad/param norm = 5.7471e-02, time/batch = 0.1799s	
2505/10550 (epoch 11.872), train_loss = 0.91377234, grad/param norm = 5.8055e-02, time/batch = 0.1807s	
2506/10550 (epoch 11.877), train_loss = 0.87826569, grad/param norm = 5.5889e-02, time/batch = 0.1800s	
2507/10550 (epoch 11.882), train_loss = 0.89255243, grad/param norm = 5.7642e-02, time/batch = 0.1802s	
2508/10550 (epoch 11.886), train_loss = 0.92959488, grad/param norm = 5.9905e-02, time/batch = 0.1799s	
2509/10550 (epoch 11.891), train_loss = 0.90814273, grad/param norm = 5.8970e-02, time/batch = 0.1806s	
2510/10550 (epoch 11.896), train_loss = 0.89476253, grad/param norm = 5.7457e-02, time/batch = 0.1798s	
2511/10550 (epoch 11.900), train_loss = 0.89456470, grad/param norm = 5.7333e-02, time/batch = 0.1810s	
2512/10550 (epoch 11.905), train_loss = 0.87722336, grad/param norm = 5.8592e-02, time/batch = 0.1796s	
2513/10550 (epoch 11.910), train_loss = 0.89354413, grad/param norm = 5.7831e-02, time/batch = 0.1799s	
2514/10550 (epoch 11.915), train_loss = 0.89344993, grad/param norm = 5.6719e-02, time/batch = 0.1797s	
2515/10550 (epoch 11.919), train_loss = 0.90261388, grad/param norm = 5.7183e-02, time/batch = 0.1803s	
2516/10550 (epoch 11.924), train_loss = 0.91204496, grad/param norm = 6.0616e-02, time/batch = 0.1798s	
2517/10550 (epoch 11.929), train_loss = 0.90759778, grad/param norm = 5.9248e-02, time/batch = 0.1805s	
2518/10550 (epoch 11.934), train_loss = 0.91404277, grad/param norm = 6.1250e-02, time/batch = 0.1798s	
2519/10550 (epoch 11.938), train_loss = 0.92215777, grad/param norm = 6.0665e-02, time/batch = 0.1802s	
2520/10550 (epoch 11.943), train_loss = 0.90359035, grad/param norm = 5.6868e-02, time/batch = 0.1804s	
2521/10550 (epoch 11.948), train_loss = 0.91466375, grad/param norm = 6.0262e-02, time/batch = 0.1813s	
2522/10550 (epoch 11.953), train_loss = 0.93374732, grad/param norm = 6.4574e-02, time/batch = 0.1794s	
2523/10550 (epoch 11.957), train_loss = 0.93135661, grad/param norm = 5.7273e-02, time/batch = 0.1798s	
2524/10550 (epoch 11.962), train_loss = 0.90339064, grad/param norm = 5.6969e-02, time/batch = 0.1796s	
2525/10550 (epoch 11.967), train_loss = 0.91499012, grad/param norm = 5.6594e-02, time/batch = 0.1800s	
2526/10550 (epoch 11.972), train_loss = 0.90042025, grad/param norm = 5.7057e-02, time/batch = 0.1802s	
2527/10550 (epoch 11.976), train_loss = 0.90487429, grad/param norm = 5.9917e-02, time/batch = 0.1799s	
2528/10550 (epoch 11.981), train_loss = 0.91006185, grad/param norm = 6.0181e-02, time/batch = 0.1792s	
2529/10550 (epoch 11.986), train_loss = 0.90103177, grad/param norm = 5.9521e-02, time/batch = 0.1800s	
2530/10550 (epoch 11.991), train_loss = 0.94415080, grad/param norm = 6.0616e-02, time/batch = 0.1804s	
2531/10550 (epoch 11.995), train_loss = 0.89147298, grad/param norm = 5.5054e-02, time/batch = 0.1812s	
decayed learning rate by a factor 0.97 to 0.001825346	
2532/10550 (epoch 12.000), train_loss = 0.91817685, grad/param norm = 6.0242e-02, time/batch = 0.1794s	
2533/10550 (epoch 12.005), train_loss = 1.09922579, grad/param norm = 6.3554e-02, time/batch = 0.1800s	
2534/10550 (epoch 12.009), train_loss = 0.89202708, grad/param norm = 5.7420e-02, time/batch = 0.1801s	
2535/10550 (epoch 12.014), train_loss = 0.91368556, grad/param norm = 5.8684e-02, time/batch = 0.1803s	
2536/10550 (epoch 12.019), train_loss = 0.92110195, grad/param norm = 5.6204e-02, time/batch = 0.1802s	
2537/10550 (epoch 12.024), train_loss = 0.92535758, grad/param norm = 5.8081e-02, time/batch = 0.1802s	
2538/10550 (epoch 12.028), train_loss = 0.90846858, grad/param norm = 5.8023e-02, time/batch = 0.1800s	
2539/10550 (epoch 12.033), train_loss = 0.92562325, grad/param norm = 5.9646e-02, time/batch = 0.1798s	
2540/10550 (epoch 12.038), train_loss = 0.90923169, grad/param norm = 5.7737e-02, time/batch = 0.1806s	
2541/10550 (epoch 12.043), train_loss = 0.89009231, grad/param norm = 5.6441e-02, time/batch = 0.1807s	
2542/10550 (epoch 12.047), train_loss = 0.88479747, grad/param norm = 5.7104e-02, time/batch = 0.1789s	
2543/10550 (epoch 12.052), train_loss = 0.92835828, grad/param norm = 5.9069e-02, time/batch = 0.1798s	
2544/10550 (epoch 12.057), train_loss = 0.89774185, grad/param norm = 5.8098e-02, time/batch = 0.1798s	
2545/10550 (epoch 12.062), train_loss = 0.91989151, grad/param norm = 5.7392e-02, time/batch = 0.1803s	
2546/10550 (epoch 12.066), train_loss = 0.89820985, grad/param norm = 5.6518e-02, time/batch = 0.1796s	
2547/10550 (epoch 12.071), train_loss = 0.87351626, grad/param norm = 5.9024e-02, time/batch = 0.1800s	
2548/10550 (epoch 12.076), train_loss = 0.90816592, grad/param norm = 6.3457e-02, time/batch = 0.1798s	
2549/10550 (epoch 12.081), train_loss = 0.92923789, grad/param norm = 6.3563e-02, time/batch = 0.1801s	
2550/10550 (epoch 12.085), train_loss = 0.90263653, grad/param norm = 5.7702e-02, time/batch = 0.1800s	
2551/10550 (epoch 12.090), train_loss = 0.88772882, grad/param norm = 6.0315e-02, time/batch = 0.1808s	
2552/10550 (epoch 12.095), train_loss = 0.89463035, grad/param norm = 5.8220e-02, time/batch = 0.1795s	
2553/10550 (epoch 12.100), train_loss = 0.88809969, grad/param norm = 5.6799e-02, time/batch = 0.1794s	
2554/10550 (epoch 12.104), train_loss = 0.87455183, grad/param norm = 5.7268e-02, time/batch = 0.1799s	
2555/10550 (epoch 12.109), train_loss = 0.87799310, grad/param norm = 5.7433e-02, time/batch = 0.1805s	
2556/10550 (epoch 12.114), train_loss = 0.89782947, grad/param norm = 6.1041e-02, time/batch = 0.1803s	
2557/10550 (epoch 12.118), train_loss = 0.86280497, grad/param norm = 5.7960e-02, time/batch = 0.1796s	
2558/10550 (epoch 12.123), train_loss = 0.92380182, grad/param norm = 5.8922e-02, time/batch = 0.1796s	
2559/10550 (epoch 12.128), train_loss = 0.88996633, grad/param norm = 6.0517e-02, time/batch = 0.1799s	
2560/10550 (epoch 12.133), train_loss = 0.86879268, grad/param norm = 5.6985e-02, time/batch = 0.1800s	
2561/10550 (epoch 12.137), train_loss = 0.89238508, grad/param norm = 6.2632e-02, time/batch = 0.1810s	
2562/10550 (epoch 12.142), train_loss = 0.90904674, grad/param norm = 6.2354e-02, time/batch = 0.1791s	
2563/10550 (epoch 12.147), train_loss = 0.89839935, grad/param norm = 5.9811e-02, time/batch = 0.1795s	
2564/10550 (epoch 12.152), train_loss = 0.90457915, grad/param norm = 5.7492e-02, time/batch = 0.1801s	
2565/10550 (epoch 12.156), train_loss = 0.90296012, grad/param norm = 5.9762e-02, time/batch = 0.1795s	
2566/10550 (epoch 12.161), train_loss = 0.89049322, grad/param norm = 5.8730e-02, time/batch = 0.1805s	
2567/10550 (epoch 12.166), train_loss = 0.90054281, grad/param norm = 6.1106e-02, time/batch = 0.1799s	
2568/10550 (epoch 12.171), train_loss = 0.89079769, grad/param norm = 6.1667e-02, time/batch = 0.1792s	
2569/10550 (epoch 12.175), train_loss = 0.90122210, grad/param norm = 5.8442e-02, time/batch = 0.1798s	
2570/10550 (epoch 12.180), train_loss = 0.88461541, grad/param norm = 5.7687e-02, time/batch = 0.1799s	
2571/10550 (epoch 12.185), train_loss = 0.91140510, grad/param norm = 5.8625e-02, time/batch = 0.1812s	
2572/10550 (epoch 12.190), train_loss = 0.87914673, grad/param norm = 6.3539e-02, time/batch = 0.1798s	
2573/10550 (epoch 12.194), train_loss = 0.88588647, grad/param norm = 6.0149e-02, time/batch = 0.1799s	
2574/10550 (epoch 12.199), train_loss = 0.91277688, grad/param norm = 6.1263e-02, time/batch = 0.1791s	
2575/10550 (epoch 12.204), train_loss = 0.91248136, grad/param norm = 7.2741e-02, time/batch = 0.1804s	
2576/10550 (epoch 12.209), train_loss = 0.92592185, grad/param norm = 6.1030e-02, time/batch = 0.1805s	
2577/10550 (epoch 12.213), train_loss = 0.91561395, grad/param norm = 6.1467e-02, time/batch = 0.1801s	
2578/10550 (epoch 12.218), train_loss = 0.91680533, grad/param norm = 6.0113e-02, time/batch = 0.1797s	
2579/10550 (epoch 12.223), train_loss = 0.86977552, grad/param norm = 5.9593e-02, time/batch = 0.1794s	
2580/10550 (epoch 12.227), train_loss = 0.85409606, grad/param norm = 5.5736e-02, time/batch = 0.1797s	
2581/10550 (epoch 12.232), train_loss = 0.87222560, grad/param norm = 5.5198e-02, time/batch = 0.1810s	
2582/10550 (epoch 12.237), train_loss = 0.87611288, grad/param norm = 5.5389e-02, time/batch = 0.1795s	
2583/10550 (epoch 12.242), train_loss = 0.88809261, grad/param norm = 6.0848e-02, time/batch = 0.1795s	
2584/10550 (epoch 12.246), train_loss = 0.87811866, grad/param norm = 5.7726e-02, time/batch = 0.1798s	
2585/10550 (epoch 12.251), train_loss = 0.88725084, grad/param norm = 5.8042e-02, time/batch = 0.1800s	
2586/10550 (epoch 12.256), train_loss = 0.89834518, grad/param norm = 5.8920e-02, time/batch = 0.1798s	
2587/10550 (epoch 12.261), train_loss = 0.87429088, grad/param norm = 5.6891e-02, time/batch = 0.1801s	
2588/10550 (epoch 12.265), train_loss = 0.87817773, grad/param norm = 5.7464e-02, time/batch = 0.1799s	
2589/10550 (epoch 12.270), train_loss = 0.87732852, grad/param norm = 5.7327e-02, time/batch = 0.1797s	
2590/10550 (epoch 12.275), train_loss = 0.88842497, grad/param norm = 5.7275e-02, time/batch = 0.1800s	
2591/10550 (epoch 12.280), train_loss = 0.89928130, grad/param norm = 5.7961e-02, time/batch = 0.1810s	
2592/10550 (epoch 12.284), train_loss = 0.88508563, grad/param norm = 6.0454e-02, time/batch = 0.1794s	
2593/10550 (epoch 12.289), train_loss = 0.87922072, grad/param norm = 6.2645e-02, time/batch = 0.1800s	
2594/10550 (epoch 12.294), train_loss = 0.88384040, grad/param norm = 6.2235e-02, time/batch = 0.1800s	
2595/10550 (epoch 12.299), train_loss = 0.86155391, grad/param norm = 5.7888e-02, time/batch = 0.1803s	
2596/10550 (epoch 12.303), train_loss = 0.90487640, grad/param norm = 5.8654e-02, time/batch = 0.1802s	
2597/10550 (epoch 12.308), train_loss = 0.87023139, grad/param norm = 5.7241e-02, time/batch = 0.1798s	
2598/10550 (epoch 12.313), train_loss = 0.88726351, grad/param norm = 6.2643e-02, time/batch = 0.1797s	
2599/10550 (epoch 12.318), train_loss = 0.89324814, grad/param norm = 6.0307e-02, time/batch = 0.1801s	
2600/10550 (epoch 12.322), train_loss = 0.89263926, grad/param norm = 6.2027e-02, time/batch = 0.1799s	
2601/10550 (epoch 12.327), train_loss = 0.89918627, grad/param norm = 6.2274e-02, time/batch = 0.1810s	
2602/10550 (epoch 12.332), train_loss = 0.91066056, grad/param norm = 6.4903e-02, time/batch = 0.1791s	
2603/10550 (epoch 12.336), train_loss = 0.90910862, grad/param norm = 6.8533e-02, time/batch = 0.1799s	
2604/10550 (epoch 12.341), train_loss = 0.86977819, grad/param norm = 5.9168e-02, time/batch = 0.1799s	
2605/10550 (epoch 12.346), train_loss = 0.90086637, grad/param norm = 6.1438e-02, time/batch = 0.1802s	
2606/10550 (epoch 12.351), train_loss = 0.88456529, grad/param norm = 5.9667e-02, time/batch = 0.1799s	
2607/10550 (epoch 12.355), train_loss = 0.86816942, grad/param norm = 5.6478e-02, time/batch = 0.1798s	
2608/10550 (epoch 12.360), train_loss = 0.92114496, grad/param norm = 6.0583e-02, time/batch = 0.1793s	
2609/10550 (epoch 12.365), train_loss = 0.89744936, grad/param norm = 6.0681e-02, time/batch = 0.1802s	
2610/10550 (epoch 12.370), train_loss = 0.87215855, grad/param norm = 5.8434e-02, time/batch = 0.1803s	
2611/10550 (epoch 12.374), train_loss = 0.89200498, grad/param norm = 5.9185e-02, time/batch = 0.1809s	
2612/10550 (epoch 12.379), train_loss = 0.89537910, grad/param norm = 5.8956e-02, time/batch = 0.1794s	
2613/10550 (epoch 12.384), train_loss = 0.87244494, grad/param norm = 5.8014e-02, time/batch = 0.1796s	
2614/10550 (epoch 12.389), train_loss = 0.85758818, grad/param norm = 5.8522e-02, time/batch = 0.1798s	
2615/10550 (epoch 12.393), train_loss = 0.86946506, grad/param norm = 5.7808e-02, time/batch = 0.1798s	
2616/10550 (epoch 12.398), train_loss = 0.86480305, grad/param norm = 5.8805e-02, time/batch = 0.1800s	
2617/10550 (epoch 12.403), train_loss = 0.90755573, grad/param norm = 6.1453e-02, time/batch = 0.1798s	
2618/10550 (epoch 12.408), train_loss = 0.89820716, grad/param norm = 6.0442e-02, time/batch = 0.1797s	
2619/10550 (epoch 12.412), train_loss = 0.87363866, grad/param norm = 5.7665e-02, time/batch = 0.1792s	
2620/10550 (epoch 12.417), train_loss = 0.87308520, grad/param norm = 5.9470e-02, time/batch = 0.1797s	
2621/10550 (epoch 12.422), train_loss = 0.89754031, grad/param norm = 6.3671e-02, time/batch = 0.1814s	
2622/10550 (epoch 12.427), train_loss = 0.90109144, grad/param norm = 6.2812e-02, time/batch = 0.1790s	
2623/10550 (epoch 12.431), train_loss = 0.88455033, grad/param norm = 5.9839e-02, time/batch = 0.1791s	
2624/10550 (epoch 12.436), train_loss = 0.86740120, grad/param norm = 5.9190e-02, time/batch = 0.1797s	
2625/10550 (epoch 12.441), train_loss = 0.90797971, grad/param norm = 6.3326e-02, time/batch = 0.1800s	
2626/10550 (epoch 12.445), train_loss = 0.90576834, grad/param norm = 6.4348e-02, time/batch = 0.1800s	
2627/10550 (epoch 12.450), train_loss = 0.88618590, grad/param norm = 6.0784e-02, time/batch = 0.1783s	
2628/10550 (epoch 12.455), train_loss = 0.88693745, grad/param norm = 6.1678e-02, time/batch = 0.1794s	
2629/10550 (epoch 12.460), train_loss = 0.85992282, grad/param norm = 5.9161e-02, time/batch = 0.1798s	
2630/10550 (epoch 12.464), train_loss = 0.87343763, grad/param norm = 6.0868e-02, time/batch = 0.1802s	
2631/10550 (epoch 12.469), train_loss = 0.86679237, grad/param norm = 5.9888e-02, time/batch = 0.1812s	
2632/10550 (epoch 12.474), train_loss = 0.88840092, grad/param norm = 6.0257e-02, time/batch = 0.1793s	
2633/10550 (epoch 12.479), train_loss = 0.85979298, grad/param norm = 5.9203e-02, time/batch = 0.1794s	
2634/10550 (epoch 12.483), train_loss = 0.87892715, grad/param norm = 5.7842e-02, time/batch = 0.1797s	
2635/10550 (epoch 12.488), train_loss = 0.88240779, grad/param norm = 5.9128e-02, time/batch = 0.1799s	
2636/10550 (epoch 12.493), train_loss = 0.86858180, grad/param norm = 5.6742e-02, time/batch = 0.1800s	
2637/10550 (epoch 12.498), train_loss = 0.86168715, grad/param norm = 5.6602e-02, time/batch = 0.1796s	
2638/10550 (epoch 12.502), train_loss = 0.87505163, grad/param norm = 5.7335e-02, time/batch = 0.1795s	
2639/10550 (epoch 12.507), train_loss = 0.85911764, grad/param norm = 5.8686e-02, time/batch = 0.1798s	
2640/10550 (epoch 12.512), train_loss = 0.83815410, grad/param norm = 5.9148e-02, time/batch = 0.1801s	
2641/10550 (epoch 12.517), train_loss = 0.87949475, grad/param norm = 6.3806e-02, time/batch = 0.1815s	
2642/10550 (epoch 12.521), train_loss = 0.86389100, grad/param norm = 5.8598e-02, time/batch = 0.1794s	
2643/10550 (epoch 12.526), train_loss = 0.80909608, grad/param norm = 5.6996e-02, time/batch = 0.1799s	
2644/10550 (epoch 12.531), train_loss = 0.84796915, grad/param norm = 6.0450e-02, time/batch = 0.1795s	
2645/10550 (epoch 12.536), train_loss = 0.88782871, grad/param norm = 5.8901e-02, time/batch = 0.1802s	
2646/10550 (epoch 12.540), train_loss = 0.88487443, grad/param norm = 6.0054e-02, time/batch = 0.1801s	
2647/10550 (epoch 12.545), train_loss = 0.85846366, grad/param norm = 5.8515e-02, time/batch = 0.1799s	
2648/10550 (epoch 12.550), train_loss = 0.89216620, grad/param norm = 6.0857e-02, time/batch = 0.1801s	
2649/10550 (epoch 12.555), train_loss = 0.86719851, grad/param norm = 5.8002e-02, time/batch = 0.1803s	
2650/10550 (epoch 12.559), train_loss = 0.89120749, grad/param norm = 6.4447e-02, time/batch = 0.1799s	
2651/10550 (epoch 12.564), train_loss = 0.85854256, grad/param norm = 6.0627e-02, time/batch = 0.1818s	
2652/10550 (epoch 12.569), train_loss = 0.86513473, grad/param norm = 6.0857e-02, time/batch = 0.1791s	
2653/10550 (epoch 12.573), train_loss = 0.86778647, grad/param norm = 6.0045e-02, time/batch = 0.1797s	
2654/10550 (epoch 12.578), train_loss = 0.87679134, grad/param norm = 6.2544e-02, time/batch = 0.1799s	
2655/10550 (epoch 12.583), train_loss = 0.85837422, grad/param norm = 5.9175e-02, time/batch = 0.1797s	
2656/10550 (epoch 12.588), train_loss = 0.84163771, grad/param norm = 5.9459e-02, time/batch = 0.1799s	
2657/10550 (epoch 12.592), train_loss = 0.87370814, grad/param norm = 6.0048e-02, time/batch = 0.1799s	
2658/10550 (epoch 12.597), train_loss = 0.86466764, grad/param norm = 6.1583e-02, time/batch = 0.1800s	
2659/10550 (epoch 12.602), train_loss = 0.88205646, grad/param norm = 6.2989e-02, time/batch = 0.1803s	
2660/10550 (epoch 12.607), train_loss = 0.87053455, grad/param norm = 6.2300e-02, time/batch = 0.1802s	
2661/10550 (epoch 12.611), train_loss = 0.86556189, grad/param norm = 6.3165e-02, time/batch = 0.1809s	
2662/10550 (epoch 12.616), train_loss = 0.84240767, grad/param norm = 5.9375e-02, time/batch = 0.1795s	
2663/10550 (epoch 12.621), train_loss = 0.85420676, grad/param norm = 6.0060e-02, time/batch = 0.1800s	
2664/10550 (epoch 12.626), train_loss = 0.85344233, grad/param norm = 5.9429e-02, time/batch = 0.1800s	
2665/10550 (epoch 12.630), train_loss = 0.88169146, grad/param norm = 6.5746e-02, time/batch = 0.1799s	
2666/10550 (epoch 12.635), train_loss = 0.89080162, grad/param norm = 6.0833e-02, time/batch = 0.1801s	
2667/10550 (epoch 12.640), train_loss = 0.89760469, grad/param norm = 6.0374e-02, time/batch = 0.1798s	
2668/10550 (epoch 12.645), train_loss = 0.86901464, grad/param norm = 6.1876e-02, time/batch = 0.1797s	
2669/10550 (epoch 12.649), train_loss = 0.88302001, grad/param norm = 6.0646e-02, time/batch = 0.1804s	
2670/10550 (epoch 12.654), train_loss = 0.87719644, grad/param norm = 6.0828e-02, time/batch = 0.1803s	
2671/10550 (epoch 12.659), train_loss = 0.88549483, grad/param norm = 6.1698e-02, time/batch = 0.1807s	
2672/10550 (epoch 12.664), train_loss = 0.87004699, grad/param norm = 5.8963e-02, time/batch = 0.1798s	
2673/10550 (epoch 12.668), train_loss = 0.85221021, grad/param norm = 6.1004e-02, time/batch = 0.1802s	
2674/10550 (epoch 12.673), train_loss = 0.88135227, grad/param norm = 6.2652e-02, time/batch = 0.1795s	
2675/10550 (epoch 12.678), train_loss = 0.85445181, grad/param norm = 6.2602e-02, time/batch = 0.1801s	
2676/10550 (epoch 12.682), train_loss = 0.86915962, grad/param norm = 6.0302e-02, time/batch = 0.1798s	
2677/10550 (epoch 12.687), train_loss = 0.83982540, grad/param norm = 5.8762e-02, time/batch = 0.1803s	
2678/10550 (epoch 12.692), train_loss = 0.87369652, grad/param norm = 6.1355e-02, time/batch = 0.1794s	
2679/10550 (epoch 12.697), train_loss = 0.85531139, grad/param norm = 5.9069e-02, time/batch = 0.1802s	
2680/10550 (epoch 12.701), train_loss = 0.87417136, grad/param norm = 6.1120e-02, time/batch = 0.1800s	
2681/10550 (epoch 12.706), train_loss = 0.86042757, grad/param norm = 6.3356e-02, time/batch = 0.1815s	
2682/10550 (epoch 12.711), train_loss = 0.87892017, grad/param norm = 5.7883e-02, time/batch = 0.1799s	
2683/10550 (epoch 12.716), train_loss = 0.85702170, grad/param norm = 5.9520e-02, time/batch = 0.1794s	
2684/10550 (epoch 12.720), train_loss = 0.88177761, grad/param norm = 5.9765e-02, time/batch = 0.1800s	
2685/10550 (epoch 12.725), train_loss = 0.84869696, grad/param norm = 5.8986e-02, time/batch = 0.1800s	
2686/10550 (epoch 12.730), train_loss = 0.84865980, grad/param norm = 5.8665e-02, time/batch = 0.1798s	
2687/10550 (epoch 12.735), train_loss = 0.85863671, grad/param norm = 5.7155e-02, time/batch = 0.1797s	
2688/10550 (epoch 12.739), train_loss = 0.84885621, grad/param norm = 5.7884e-02, time/batch = 0.1794s	
2689/10550 (epoch 12.744), train_loss = 0.85565377, grad/param norm = 5.8520e-02, time/batch = 0.1805s	
2690/10550 (epoch 12.749), train_loss = 0.88136171, grad/param norm = 6.0176e-02, time/batch = 0.1799s	
2691/10550 (epoch 12.754), train_loss = 0.87683219, grad/param norm = 5.9199e-02, time/batch = 0.1811s	
2692/10550 (epoch 12.758), train_loss = 0.84925060, grad/param norm = 5.9198e-02, time/batch = 0.1796s	
2693/10550 (epoch 12.763), train_loss = 0.83913743, grad/param norm = 6.2437e-02, time/batch = 0.1798s	
2694/10550 (epoch 12.768), train_loss = 0.88762864, grad/param norm = 6.4265e-02, time/batch = 0.1798s	
2695/10550 (epoch 12.773), train_loss = 0.91016597, grad/param norm = 6.7900e-02, time/batch = 0.1805s	
2696/10550 (epoch 12.777), train_loss = 0.86715551, grad/param norm = 5.9999e-02, time/batch = 0.1799s	
2697/10550 (epoch 12.782), train_loss = 0.90962738, grad/param norm = 6.3745e-02, time/batch = 0.1800s	
2698/10550 (epoch 12.787), train_loss = 0.85388467, grad/param norm = 6.1176e-02, time/batch = 0.1799s	
2699/10550 (epoch 12.791), train_loss = 0.85378531, grad/param norm = 6.1907e-02, time/batch = 0.1801s	
2700/10550 (epoch 12.796), train_loss = 0.87718730, grad/param norm = 6.1027e-02, time/batch = 0.1799s	
2701/10550 (epoch 12.801), train_loss = 0.85160001, grad/param norm = 6.1918e-02, time/batch = 0.1815s	
2702/10550 (epoch 12.806), train_loss = 0.88121228, grad/param norm = 6.5613e-02, time/batch = 0.1800s	
2703/10550 (epoch 12.810), train_loss = 0.90483530, grad/param norm = 6.4272e-02, time/batch = 0.1801s	
2704/10550 (epoch 12.815), train_loss = 0.87588547, grad/param norm = 6.2000e-02, time/batch = 0.1798s	
2705/10550 (epoch 12.820), train_loss = 0.87211731, grad/param norm = 5.9313e-02, time/batch = 0.1795s	
2706/10550 (epoch 12.825), train_loss = 0.88596605, grad/param norm = 6.1956e-02, time/batch = 0.1801s	
2707/10550 (epoch 12.829), train_loss = 0.85644289, grad/param norm = 5.8544e-02, time/batch = 0.1794s	
2708/10550 (epoch 12.834), train_loss = 0.85373951, grad/param norm = 5.8373e-02, time/batch = 0.1799s	
2709/10550 (epoch 12.839), train_loss = 0.85865050, grad/param norm = 6.0878e-02, time/batch = 0.1797s	
2710/10550 (epoch 12.844), train_loss = 0.85440384, grad/param norm = 6.1330e-02, time/batch = 0.1802s	
2711/10550 (epoch 12.848), train_loss = 0.85272933, grad/param norm = 6.0571e-02, time/batch = 0.1808s	
2712/10550 (epoch 12.853), train_loss = 0.87491188, grad/param norm = 6.0275e-02, time/batch = 0.1794s	
2713/10550 (epoch 12.858), train_loss = 0.88591099, grad/param norm = 6.2440e-02, time/batch = 0.1803s	
2714/10550 (epoch 12.863), train_loss = 0.85761551, grad/param norm = 5.8874e-02, time/batch = 0.1802s	
2715/10550 (epoch 12.867), train_loss = 0.88414481, grad/param norm = 6.1459e-02, time/batch = 0.1802s	
2716/10550 (epoch 12.872), train_loss = 0.86533763, grad/param norm = 6.2154e-02, time/batch = 0.1799s	
2717/10550 (epoch 12.877), train_loss = 0.85490987, grad/param norm = 6.0912e-02, time/batch = 0.1797s	
2718/10550 (epoch 12.882), train_loss = 0.85004295, grad/param norm = 5.9619e-02, time/batch = 0.1795s	
2719/10550 (epoch 12.886), train_loss = 0.86960139, grad/param norm = 5.9508e-02, time/batch = 0.1798s	
2720/10550 (epoch 12.891), train_loss = 0.85245010, grad/param norm = 6.1215e-02, time/batch = 0.1801s	
2721/10550 (epoch 12.896), train_loss = 0.85080451, grad/param norm = 6.1143e-02, time/batch = 0.1813s	
2722/10550 (epoch 12.900), train_loss = 0.85432422, grad/param norm = 6.3336e-02, time/batch = 0.1796s	
2723/10550 (epoch 12.905), train_loss = 0.83069631, grad/param norm = 6.0937e-02, time/batch = 0.1799s	
2724/10550 (epoch 12.910), train_loss = 0.85934498, grad/param norm = 6.3124e-02, time/batch = 0.1798s	
2725/10550 (epoch 12.915), train_loss = 0.85788395, grad/param norm = 5.9498e-02, time/batch = 0.1800s	
2726/10550 (epoch 12.919), train_loss = 0.85365137, grad/param norm = 5.9405e-02, time/batch = 0.1801s	
2727/10550 (epoch 12.924), train_loss = 0.86337694, grad/param norm = 6.1527e-02, time/batch = 0.1796s	
2728/10550 (epoch 12.929), train_loss = 0.85186532, grad/param norm = 5.9216e-02, time/batch = 0.1794s	
2729/10550 (epoch 12.934), train_loss = 0.86393666, grad/param norm = 6.2131e-02, time/batch = 0.1797s	
2730/10550 (epoch 12.938), train_loss = 0.86584019, grad/param norm = 6.0632e-02, time/batch = 0.1802s	
2731/10550 (epoch 12.943), train_loss = 0.87190390, grad/param norm = 6.4679e-02, time/batch = 0.1810s	
2732/10550 (epoch 12.948), train_loss = 0.86831880, grad/param norm = 6.0882e-02, time/batch = 0.1797s	
2733/10550 (epoch 12.953), train_loss = 0.88016532, grad/param norm = 6.4572e-02, time/batch = 0.1798s	
2734/10550 (epoch 12.957), train_loss = 0.87976947, grad/param norm = 5.9462e-02, time/batch = 0.1802s	
2735/10550 (epoch 12.962), train_loss = 0.86120832, grad/param norm = 6.0052e-02, time/batch = 0.1804s	
2736/10550 (epoch 12.967), train_loss = 0.87509420, grad/param norm = 5.9470e-02, time/batch = 0.1801s	
2737/10550 (epoch 12.972), train_loss = 0.84553694, grad/param norm = 5.9644e-02, time/batch = 0.1805s	
2738/10550 (epoch 12.976), train_loss = 0.86315316, grad/param norm = 6.0969e-02, time/batch = 0.1795s	
2739/10550 (epoch 12.981), train_loss = 0.85910905, grad/param norm = 5.9081e-02, time/batch = 0.1796s	
2740/10550 (epoch 12.986), train_loss = 0.85165208, grad/param norm = 5.8589e-02, time/batch = 0.1802s	
2741/10550 (epoch 12.991), train_loss = 0.89927492, grad/param norm = 6.2688e-02, time/batch = 0.1811s	
2742/10550 (epoch 12.995), train_loss = 0.86224296, grad/param norm = 6.0937e-02, time/batch = 0.1796s	
decayed learning rate by a factor 0.97 to 0.00177058562	
2743/10550 (epoch 13.000), train_loss = 0.86716833, grad/param norm = 6.2404e-02, time/batch = 0.1803s	
2744/10550 (epoch 13.005), train_loss = 1.05504210, grad/param norm = 6.6538e-02, time/batch = 0.1799s	
2745/10550 (epoch 13.009), train_loss = 0.84698696, grad/param norm = 5.9075e-02, time/batch = 0.1793s	
2746/10550 (epoch 13.014), train_loss = 0.86169651, grad/param norm = 6.0365e-02, time/batch = 0.1799s	
2747/10550 (epoch 13.019), train_loss = 0.89191489, grad/param norm = 6.2577e-02, time/batch = 0.1805s	
2748/10550 (epoch 13.024), train_loss = 0.87717297, grad/param norm = 6.2814e-02, time/batch = 0.1795s	
2749/10550 (epoch 13.028), train_loss = 0.85839411, grad/param norm = 5.7897e-02, time/batch = 0.1797s	
2750/10550 (epoch 13.033), train_loss = 0.87477408, grad/param norm = 5.9555e-02, time/batch = 0.1799s	
2751/10550 (epoch 13.038), train_loss = 0.87318335, grad/param norm = 6.2343e-02, time/batch = 0.1806s	
2752/10550 (epoch 13.043), train_loss = 0.85002003, grad/param norm = 5.9524e-02, time/batch = 0.1796s	
2753/10550 (epoch 13.047), train_loss = 0.83275327, grad/param norm = 5.6756e-02, time/batch = 0.1799s	
2754/10550 (epoch 13.052), train_loss = 0.89483623, grad/param norm = 6.3663e-02, time/batch = 0.1799s	
2755/10550 (epoch 13.057), train_loss = 0.85949849, grad/param norm = 6.1903e-02, time/batch = 0.1801s	
2756/10550 (epoch 13.062), train_loss = 0.87114290, grad/param norm = 6.0026e-02, time/batch = 0.1801s	
2757/10550 (epoch 13.066), train_loss = 0.85651007, grad/param norm = 6.1650e-02, time/batch = 0.1802s	
2758/10550 (epoch 13.071), train_loss = 0.83129793, grad/param norm = 6.0822e-02, time/batch = 0.1797s	
2759/10550 (epoch 13.076), train_loss = 0.86187657, grad/param norm = 6.2570e-02, time/batch = 0.1805s	
2760/10550 (epoch 13.081), train_loss = 0.87789296, grad/param norm = 6.6122e-02, time/batch = 0.1799s	
2761/10550 (epoch 13.085), train_loss = 0.86368242, grad/param norm = 6.1679e-02, time/batch = 0.1809s	
2762/10550 (epoch 13.090), train_loss = 0.83871332, grad/param norm = 6.1257e-02, time/batch = 0.1796s	
2763/10550 (epoch 13.095), train_loss = 0.86375634, grad/param norm = 6.1453e-02, time/batch = 0.1801s	
2764/10550 (epoch 13.100), train_loss = 0.85966585, grad/param norm = 6.2733e-02, time/batch = 0.1803s	
2765/10550 (epoch 13.104), train_loss = 0.83755086, grad/param norm = 5.8955e-02, time/batch = 0.1800s	
2766/10550 (epoch 13.109), train_loss = 0.83730396, grad/param norm = 5.9880e-02, time/batch = 0.1802s	
2767/10550 (epoch 13.114), train_loss = 0.84708089, grad/param norm = 5.9608e-02, time/batch = 0.1799s	
2768/10550 (epoch 13.118), train_loss = 0.82340677, grad/param norm = 5.9172e-02, time/batch = 0.1797s	
2769/10550 (epoch 13.123), train_loss = 0.87996004, grad/param norm = 6.1336e-02, time/batch = 0.1802s	
2770/10550 (epoch 13.128), train_loss = 0.85199674, grad/param norm = 6.2539e-02, time/batch = 0.1802s	
2771/10550 (epoch 13.133), train_loss = 0.82954546, grad/param norm = 6.5882e-02, time/batch = 0.1810s	
2772/10550 (epoch 13.137), train_loss = 0.85334610, grad/param norm = 6.5591e-02, time/batch = 0.1792s	
2773/10550 (epoch 13.142), train_loss = 0.87485342, grad/param norm = 6.2778e-02, time/batch = 0.1796s	
2774/10550 (epoch 13.147), train_loss = 0.85468855, grad/param norm = 6.1544e-02, time/batch = 0.1800s	
2775/10550 (epoch 13.152), train_loss = 0.86387330, grad/param norm = 6.2283e-02, time/batch = 0.1799s	
2776/10550 (epoch 13.156), train_loss = 0.85888077, grad/param norm = 6.2910e-02, time/batch = 0.1802s	
2777/10550 (epoch 13.161), train_loss = 0.85192953, grad/param norm = 6.2320e-02, time/batch = 0.1795s	
2778/10550 (epoch 13.166), train_loss = 0.86371095, grad/param norm = 6.5944e-02, time/batch = 0.1798s	
2779/10550 (epoch 13.171), train_loss = 0.85127070, grad/param norm = 6.3708e-02, time/batch = 0.1800s	
2780/10550 (epoch 13.175), train_loss = 0.86104827, grad/param norm = 5.9158e-02, time/batch = 0.1794s	
2781/10550 (epoch 13.180), train_loss = 0.83809771, grad/param norm = 5.8526e-02, time/batch = 0.1812s	
2782/10550 (epoch 13.185), train_loss = 0.85690860, grad/param norm = 5.8695e-02, time/batch = 0.1795s	
2783/10550 (epoch 13.190), train_loss = 0.82712618, grad/param norm = 6.2086e-02, time/batch = 0.1801s	
2784/10550 (epoch 13.194), train_loss = 0.84442986, grad/param norm = 6.4399e-02, time/batch = 0.1795s	
2785/10550 (epoch 13.199), train_loss = 0.87161732, grad/param norm = 6.4196e-02, time/batch = 0.1800s	
2786/10550 (epoch 13.204), train_loss = 0.84631855, grad/param norm = 6.4595e-02, time/batch = 0.1796s	
2787/10550 (epoch 13.209), train_loss = 0.87780109, grad/param norm = 6.6632e-02, time/batch = 0.1799s	
2788/10550 (epoch 13.213), train_loss = 0.87531763, grad/param norm = 6.1752e-02, time/batch = 0.1798s	
2789/10550 (epoch 13.218), train_loss = 0.86965804, grad/param norm = 6.2409e-02, time/batch = 0.1806s	
2790/10550 (epoch 13.223), train_loss = 0.82503828, grad/param norm = 6.3005e-02, time/batch = 0.1803s	
2791/10550 (epoch 13.227), train_loss = 0.82237095, grad/param norm = 6.0027e-02, time/batch = 0.1806s	
2792/10550 (epoch 13.232), train_loss = 0.85279502, grad/param norm = 6.3309e-02, time/batch = 0.1792s	
2793/10550 (epoch 13.237), train_loss = 0.83563203, grad/param norm = 5.8589e-02, time/batch = 0.1794s	
2794/10550 (epoch 13.242), train_loss = 0.84600661, grad/param norm = 6.1364e-02, time/batch = 0.1793s	
2795/10550 (epoch 13.246), train_loss = 0.82916295, grad/param norm = 5.9833e-02, time/batch = 0.1802s	
2796/10550 (epoch 13.251), train_loss = 0.84677048, grad/param norm = 6.3019e-02, time/batch = 0.1800s	
2797/10550 (epoch 13.256), train_loss = 0.85289470, grad/param norm = 6.1610e-02, time/batch = 0.1806s	
2798/10550 (epoch 13.261), train_loss = 0.82922233, grad/param norm = 5.8460e-02, time/batch = 0.1792s	
2799/10550 (epoch 13.265), train_loss = 0.83648590, grad/param norm = 6.1840e-02, time/batch = 0.1799s	
2800/10550 (epoch 13.270), train_loss = 0.83028505, grad/param norm = 5.8523e-02, time/batch = 0.1800s	
2801/10550 (epoch 13.275), train_loss = 0.84339819, grad/param norm = 5.9260e-02, time/batch = 0.1814s	
2802/10550 (epoch 13.280), train_loss = 0.85552560, grad/param norm = 6.1858e-02, time/batch = 0.1794s	
2803/10550 (epoch 13.284), train_loss = 0.84084104, grad/param norm = 6.1732e-02, time/batch = 0.1803s	
2804/10550 (epoch 13.289), train_loss = 0.83856570, grad/param norm = 6.2201e-02, time/batch = 0.1795s	
2805/10550 (epoch 13.294), train_loss = 0.84416810, grad/param norm = 6.6829e-02, time/batch = 0.1798s	
2806/10550 (epoch 13.299), train_loss = 0.81966712, grad/param norm = 6.1000e-02, time/batch = 0.1801s	
2807/10550 (epoch 13.303), train_loss = 0.85168669, grad/param norm = 6.0530e-02, time/batch = 0.1803s	
2808/10550 (epoch 13.308), train_loss = 0.83365851, grad/param norm = 6.0357e-02, time/batch = 0.1794s	
2809/10550 (epoch 13.313), train_loss = 0.83146950, grad/param norm = 6.1141e-02, time/batch = 0.1802s	
2810/10550 (epoch 13.318), train_loss = 0.84936073, grad/param norm = 6.2314e-02, time/batch = 0.1796s	
2811/10550 (epoch 13.322), train_loss = 0.84251711, grad/param norm = 6.2200e-02, time/batch = 0.1810s	
2812/10550 (epoch 13.327), train_loss = 0.83933522, grad/param norm = 6.6745e-02, time/batch = 0.1796s	
2813/10550 (epoch 13.332), train_loss = 0.86028324, grad/param norm = 6.2917e-02, time/batch = 0.1800s	
2814/10550 (epoch 13.336), train_loss = 0.84286727, grad/param norm = 6.3526e-02, time/batch = 0.1800s	
2815/10550 (epoch 13.341), train_loss = 0.83140743, grad/param norm = 6.7283e-02, time/batch = 0.1802s	
2816/10550 (epoch 13.346), train_loss = 0.86812385, grad/param norm = 6.4470e-02, time/batch = 0.1801s	
2817/10550 (epoch 13.351), train_loss = 0.84505860, grad/param norm = 6.0747e-02, time/batch = 0.1800s	
2818/10550 (epoch 13.355), train_loss = 0.84664071, grad/param norm = 6.0364e-02, time/batch = 0.1796s	
2819/10550 (epoch 13.360), train_loss = 0.87539464, grad/param norm = 6.4113e-02, time/batch = 0.1799s	
2820/10550 (epoch 13.365), train_loss = 0.84740699, grad/param norm = 6.1913e-02, time/batch = 0.1798s	
2821/10550 (epoch 13.370), train_loss = 0.83580263, grad/param norm = 6.1684e-02, time/batch = 0.1810s	
2822/10550 (epoch 13.374), train_loss = 0.84359565, grad/param norm = 6.2085e-02, time/batch = 0.1793s	
2823/10550 (epoch 13.379), train_loss = 0.85136899, grad/param norm = 6.2042e-02, time/batch = 0.1794s	
2824/10550 (epoch 13.384), train_loss = 0.83116211, grad/param norm = 6.1024e-02, time/batch = 0.1799s	
2825/10550 (epoch 13.389), train_loss = 0.82188606, grad/param norm = 6.1357e-02, time/batch = 0.1800s	
2826/10550 (epoch 13.393), train_loss = 0.83100938, grad/param norm = 6.0340e-02, time/batch = 0.1798s	
2827/10550 (epoch 13.398), train_loss = 0.82087612, grad/param norm = 5.9947e-02, time/batch = 0.1800s	
2828/10550 (epoch 13.403), train_loss = 0.86375761, grad/param norm = 6.6774e-02, time/batch = 0.1796s	
2829/10550 (epoch 13.408), train_loss = 0.85575637, grad/param norm = 6.3361e-02, time/batch = 0.1798s	
2830/10550 (epoch 13.412), train_loss = 0.83314649, grad/param norm = 5.8687e-02, time/batch = 0.1797s	
2831/10550 (epoch 13.417), train_loss = 0.83983384, grad/param norm = 6.2447e-02, time/batch = 0.1808s	
2832/10550 (epoch 13.422), train_loss = 0.84923505, grad/param norm = 6.3656e-02, time/batch = 0.1793s	
2833/10550 (epoch 13.427), train_loss = 0.86169850, grad/param norm = 6.0653e-02, time/batch = 0.1795s	
2834/10550 (epoch 13.431), train_loss = 0.84801519, grad/param norm = 6.3704e-02, time/batch = 0.1792s	
2835/10550 (epoch 13.436), train_loss = 0.83032596, grad/param norm = 6.1711e-02, time/batch = 0.1795s	
2836/10550 (epoch 13.441), train_loss = 0.85846491, grad/param norm = 6.2875e-02, time/batch = 0.1798s	
2837/10550 (epoch 13.445), train_loss = 0.86130828, grad/param norm = 6.3143e-02, time/batch = 0.1798s	
2838/10550 (epoch 13.450), train_loss = 0.84682552, grad/param norm = 6.5118e-02, time/batch = 0.1796s	
2839/10550 (epoch 13.455), train_loss = 0.83445816, grad/param norm = 6.0722e-02, time/batch = 0.1801s	
2840/10550 (epoch 13.460), train_loss = 0.81968294, grad/param norm = 6.1860e-02, time/batch = 0.1803s	
2841/10550 (epoch 13.464), train_loss = 0.82414806, grad/param norm = 5.9885e-02, time/batch = 0.1807s	
2842/10550 (epoch 13.469), train_loss = 0.82479447, grad/param norm = 6.1485e-02, time/batch = 0.1799s	
2843/10550 (epoch 13.474), train_loss = 0.85201762, grad/param norm = 6.5039e-02, time/batch = 0.1795s	
2844/10550 (epoch 13.479), train_loss = 0.81700850, grad/param norm = 6.2249e-02, time/batch = 0.1796s	
2845/10550 (epoch 13.483), train_loss = 0.83805302, grad/param norm = 6.3702e-02, time/batch = 0.1800s	
2846/10550 (epoch 13.488), train_loss = 0.84270994, grad/param norm = 6.3828e-02, time/batch = 0.1801s	
2847/10550 (epoch 13.493), train_loss = 0.82402483, grad/param norm = 5.9481e-02, time/batch = 0.1799s	
2848/10550 (epoch 13.498), train_loss = 0.82937288, grad/param norm = 6.0042e-02, time/batch = 0.1792s	
2849/10550 (epoch 13.502), train_loss = 0.83448120, grad/param norm = 5.9641e-02, time/batch = 0.1798s	
2850/10550 (epoch 13.507), train_loss = 0.81742104, grad/param norm = 6.0139e-02, time/batch = 0.1805s	
2851/10550 (epoch 13.512), train_loss = 0.78770172, grad/param norm = 5.9833e-02, time/batch = 0.1810s	
2852/10550 (epoch 13.517), train_loss = 0.83191458, grad/param norm = 6.2731e-02, time/batch = 0.1794s	
2853/10550 (epoch 13.521), train_loss = 0.81959303, grad/param norm = 6.2398e-02, time/batch = 0.1796s	
2854/10550 (epoch 13.526), train_loss = 0.76405840, grad/param norm = 5.8199e-02, time/batch = 0.1798s	
2855/10550 (epoch 13.531), train_loss = 0.80533363, grad/param norm = 5.9026e-02, time/batch = 0.1799s	
2856/10550 (epoch 13.536), train_loss = 0.86120071, grad/param norm = 6.3539e-02, time/batch = 0.1791s	
2857/10550 (epoch 13.540), train_loss = 0.83342819, grad/param norm = 6.0455e-02, time/batch = 0.1796s	
2858/10550 (epoch 13.545), train_loss = 0.82131524, grad/param norm = 6.0936e-02, time/batch = 0.1793s	
2859/10550 (epoch 13.550), train_loss = 0.84101382, grad/param norm = 6.1887e-02, time/batch = 0.1802s	
2860/10550 (epoch 13.555), train_loss = 0.81641231, grad/param norm = 5.9560e-02, time/batch = 0.1797s	
2861/10550 (epoch 13.559), train_loss = 0.84538846, grad/param norm = 6.2685e-02, time/batch = 0.1812s	
2862/10550 (epoch 13.564), train_loss = 0.81499579, grad/param norm = 6.3386e-02, time/batch = 0.1795s	
2863/10550 (epoch 13.569), train_loss = 0.82193335, grad/param norm = 6.1882e-02, time/batch = 0.1793s	
2864/10550 (epoch 13.573), train_loss = 0.84179137, grad/param norm = 6.5910e-02, time/batch = 0.1798s	
2865/10550 (epoch 13.578), train_loss = 0.81517881, grad/param norm = 5.9883e-02, time/batch = 0.1802s	
2866/10550 (epoch 13.583), train_loss = 0.81401872, grad/param norm = 6.2507e-02, time/batch = 0.1801s	
2867/10550 (epoch 13.588), train_loss = 0.80783837, grad/param norm = 6.4663e-02, time/batch = 0.1797s	
2868/10550 (epoch 13.592), train_loss = 0.83918650, grad/param norm = 6.5330e-02, time/batch = 0.1797s	
2869/10550 (epoch 13.597), train_loss = 0.82202864, grad/param norm = 6.4610e-02, time/batch = 0.1799s	
2870/10550 (epoch 13.602), train_loss = 0.84516870, grad/param norm = 6.4481e-02, time/batch = 0.1799s	
2871/10550 (epoch 13.607), train_loss = 0.82778885, grad/param norm = 6.5316e-02, time/batch = 0.1815s	
2872/10550 (epoch 13.611), train_loss = 0.83014260, grad/param norm = 6.9819e-02, time/batch = 0.1800s	
2873/10550 (epoch 13.616), train_loss = 0.81961169, grad/param norm = 6.5212e-02, time/batch = 0.1797s	
2874/10550 (epoch 13.621), train_loss = 0.82006678, grad/param norm = 6.2154e-02, time/batch = 0.1800s	
2875/10550 (epoch 13.626), train_loss = 0.81960304, grad/param norm = 6.3962e-02, time/batch = 0.1798s	
2876/10550 (epoch 13.630), train_loss = 0.84025529, grad/param norm = 6.5741e-02, time/batch = 0.1796s	
2877/10550 (epoch 13.635), train_loss = 0.84797303, grad/param norm = 6.3926e-02, time/batch = 0.1800s	
2878/10550 (epoch 13.640), train_loss = 0.85134618, grad/param norm = 6.1413e-02, time/batch = 0.1795s	
2879/10550 (epoch 13.645), train_loss = 0.83898122, grad/param norm = 6.5807e-02, time/batch = 0.1802s	
2880/10550 (epoch 13.649), train_loss = 0.85171411, grad/param norm = 6.3106e-02, time/batch = 0.1800s	
2881/10550 (epoch 13.654), train_loss = 0.84183452, grad/param norm = 6.1985e-02, time/batch = 0.1814s	
2882/10550 (epoch 13.659), train_loss = 0.83957694, grad/param norm = 6.2834e-02, time/batch = 0.1791s	
2883/10550 (epoch 13.664), train_loss = 0.83637358, grad/param norm = 6.2414e-02, time/batch = 0.1794s	
2884/10550 (epoch 13.668), train_loss = 0.81282472, grad/param norm = 6.3172e-02, time/batch = 0.1801s	
2885/10550 (epoch 13.673), train_loss = 0.82399125, grad/param norm = 6.2228e-02, time/batch = 0.1803s	
2886/10550 (epoch 13.678), train_loss = 0.80504834, grad/param norm = 6.1366e-02, time/batch = 0.1799s	
2887/10550 (epoch 13.682), train_loss = 0.82635389, grad/param norm = 6.3246e-02, time/batch = 0.1802s	
2888/10550 (epoch 13.687), train_loss = 0.80517622, grad/param norm = 6.2761e-02, time/batch = 0.1797s	
2889/10550 (epoch 13.692), train_loss = 0.83616023, grad/param norm = 6.3216e-02, time/batch = 0.1801s	
2890/10550 (epoch 13.697), train_loss = 0.81681433, grad/param norm = 6.4256e-02, time/batch = 0.1798s	
2891/10550 (epoch 13.701), train_loss = 0.82868691, grad/param norm = 6.1174e-02, time/batch = 0.1813s	
2892/10550 (epoch 13.706), train_loss = 0.81031557, grad/param norm = 6.3758e-02, time/batch = 0.1791s	
2893/10550 (epoch 13.711), train_loss = 0.83733163, grad/param norm = 6.1234e-02, time/batch = 0.1795s	
2894/10550 (epoch 13.716), train_loss = 0.81768038, grad/param norm = 6.3765e-02, time/batch = 0.1798s	
2895/10550 (epoch 13.720), train_loss = 0.84073294, grad/param norm = 6.3321e-02, time/batch = 0.1806s	
2896/10550 (epoch 13.725), train_loss = 0.80028675, grad/param norm = 6.0690e-02, time/batch = 0.1803s	
2897/10550 (epoch 13.730), train_loss = 0.80301129, grad/param norm = 6.0644e-02, time/batch = 0.1800s	
2898/10550 (epoch 13.735), train_loss = 0.82658740, grad/param norm = 6.1707e-02, time/batch = 0.1796s	
2899/10550 (epoch 13.739), train_loss = 0.81742201, grad/param norm = 6.3275e-02, time/batch = 0.1797s	
2900/10550 (epoch 13.744), train_loss = 0.81717684, grad/param norm = 6.1699e-02, time/batch = 0.1799s	
2901/10550 (epoch 13.749), train_loss = 0.84973596, grad/param norm = 6.2266e-02, time/batch = 0.1811s	
2902/10550 (epoch 13.754), train_loss = 0.83050539, grad/param norm = 5.9477e-02, time/batch = 0.1801s	
2903/10550 (epoch 13.758), train_loss = 0.80959347, grad/param norm = 6.4780e-02, time/batch = 0.1794s	
2904/10550 (epoch 13.763), train_loss = 0.79025873, grad/param norm = 6.2965e-02, time/batch = 0.1801s	
2905/10550 (epoch 13.768), train_loss = 0.84291710, grad/param norm = 6.8344e-02, time/batch = 0.1803s	
2906/10550 (epoch 13.773), train_loss = 0.86506357, grad/param norm = 6.6363e-02, time/batch = 0.1797s	
2907/10550 (epoch 13.777), train_loss = 0.83608045, grad/param norm = 6.5259e-02, time/batch = 0.1800s	
2908/10550 (epoch 13.782), train_loss = 0.87316946, grad/param norm = 6.6899e-02, time/batch = 0.1801s	
2909/10550 (epoch 13.787), train_loss = 0.81455595, grad/param norm = 6.2440e-02, time/batch = 0.1798s	
2910/10550 (epoch 13.791), train_loss = 0.80288499, grad/param norm = 6.4848e-02, time/batch = 0.1795s	
2911/10550 (epoch 13.796), train_loss = 0.83723237, grad/param norm = 6.1568e-02, time/batch = 0.1811s	
2912/10550 (epoch 13.801), train_loss = 0.81139520, grad/param norm = 6.3414e-02, time/batch = 0.1796s	
2913/10550 (epoch 13.806), train_loss = 0.82981292, grad/param norm = 6.3193e-02, time/batch = 0.1797s	
2914/10550 (epoch 13.810), train_loss = 0.85479278, grad/param norm = 6.5605e-02, time/batch = 0.1800s	
2915/10550 (epoch 13.815), train_loss = 0.83440278, grad/param norm = 6.4195e-02, time/batch = 0.1804s	
2916/10550 (epoch 13.820), train_loss = 0.83589349, grad/param norm = 6.3342e-02, time/batch = 0.1798s	
2917/10550 (epoch 13.825), train_loss = 0.83705940, grad/param norm = 6.3213e-02, time/batch = 0.1799s	
2918/10550 (epoch 13.829), train_loss = 0.81255219, grad/param norm = 6.2108e-02, time/batch = 0.1790s	
2919/10550 (epoch 13.834), train_loss = 0.81478804, grad/param norm = 6.2253e-02, time/batch = 0.1800s	
2920/10550 (epoch 13.839), train_loss = 0.80956717, grad/param norm = 6.0475e-02, time/batch = 0.1801s	
2921/10550 (epoch 13.844), train_loss = 0.82727965, grad/param norm = 6.5435e-02, time/batch = 0.1810s	
2922/10550 (epoch 13.848), train_loss = 0.81372468, grad/param norm = 6.4253e-02, time/batch = 0.1794s	
2923/10550 (epoch 13.853), train_loss = 0.83321697, grad/param norm = 6.2314e-02, time/batch = 0.1794s	
2924/10550 (epoch 13.858), train_loss = 0.85011993, grad/param norm = 6.5113e-02, time/batch = 0.1800s	
2925/10550 (epoch 13.863), train_loss = 0.80841647, grad/param norm = 6.3488e-02, time/batch = 0.1801s	
2926/10550 (epoch 13.867), train_loss = 0.84307012, grad/param norm = 6.5975e-02, time/batch = 0.1797s	
2927/10550 (epoch 13.872), train_loss = 0.83146282, grad/param norm = 6.5926e-02, time/batch = 0.1804s	
2928/10550 (epoch 13.877), train_loss = 0.80997439, grad/param norm = 6.1457e-02, time/batch = 0.1793s	
2929/10550 (epoch 13.882), train_loss = 0.80658551, grad/param norm = 6.2896e-02, time/batch = 0.1803s	
2930/10550 (epoch 13.886), train_loss = 0.82640026, grad/param norm = 6.3299e-02, time/batch = 0.1799s	
2931/10550 (epoch 13.891), train_loss = 0.82023047, grad/param norm = 6.2802e-02, time/batch = 0.1811s	
2932/10550 (epoch 13.896), train_loss = 0.81705101, grad/param norm = 6.3022e-02, time/batch = 0.1795s	
2933/10550 (epoch 13.900), train_loss = 0.80286960, grad/param norm = 6.1485e-02, time/batch = 0.1800s	
2934/10550 (epoch 13.905), train_loss = 0.80058879, grad/param norm = 6.4236e-02, time/batch = 0.1796s	
2935/10550 (epoch 13.910), train_loss = 0.81185813, grad/param norm = 6.2625e-02, time/batch = 0.1800s	
2936/10550 (epoch 13.915), train_loss = 0.81986992, grad/param norm = 6.3364e-02, time/batch = 0.1803s	
2937/10550 (epoch 13.919), train_loss = 0.82736965, grad/param norm = 6.3657e-02, time/batch = 0.1800s	
2938/10550 (epoch 13.924), train_loss = 0.82498139, grad/param norm = 6.4447e-02, time/batch = 0.1797s	
2939/10550 (epoch 13.929), train_loss = 0.82322073, grad/param norm = 6.4244e-02, time/batch = 0.1802s	
2940/10550 (epoch 13.934), train_loss = 0.83015573, grad/param norm = 6.8101e-02, time/batch = 0.1801s	
2941/10550 (epoch 13.938), train_loss = 0.83475980, grad/param norm = 6.3338e-02, time/batch = 0.1807s	
2942/10550 (epoch 13.943), train_loss = 0.82256449, grad/param norm = 6.1686e-02, time/batch = 0.1791s	
2943/10550 (epoch 13.948), train_loss = 0.82642195, grad/param norm = 6.6446e-02, time/batch = 0.1790s	
2944/10550 (epoch 13.953), train_loss = 0.85278117, grad/param norm = 7.2874e-02, time/batch = 0.1794s	
2945/10550 (epoch 13.957), train_loss = 0.83959043, grad/param norm = 6.0454e-02, time/batch = 0.1807s	
2946/10550 (epoch 13.962), train_loss = 0.81559578, grad/param norm = 6.1455e-02, time/batch = 0.1798s	
2947/10550 (epoch 13.967), train_loss = 0.82701951, grad/param norm = 6.0979e-02, time/batch = 0.1800s	
2948/10550 (epoch 13.972), train_loss = 0.81608316, grad/param norm = 6.1645e-02, time/batch = 0.1794s	
2949/10550 (epoch 13.976), train_loss = 0.82366498, grad/param norm = 6.5406e-02, time/batch = 0.1803s	
2950/10550 (epoch 13.981), train_loss = 0.81475860, grad/param norm = 6.1486e-02, time/batch = 0.1803s	
2951/10550 (epoch 13.986), train_loss = 0.80696803, grad/param norm = 6.3563e-02, time/batch = 0.1814s	
2952/10550 (epoch 13.991), train_loss = 0.85285200, grad/param norm = 6.4467e-02, time/batch = 0.1794s	
2953/10550 (epoch 13.995), train_loss = 0.82103098, grad/param norm = 6.0410e-02, time/batch = 0.1797s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
2954/10550 (epoch 14.000), train_loss = 0.81466079, grad/param norm = 6.3126e-02, time/batch = 0.1793s	
2955/10550 (epoch 14.005), train_loss = 1.01488583, grad/param norm = 6.7968e-02, time/batch = 0.1798s	
2956/10550 (epoch 14.009), train_loss = 0.81078060, grad/param norm = 6.0924e-02, time/batch = 0.1802s	
2957/10550 (epoch 14.014), train_loss = 0.82382973, grad/param norm = 6.3227e-02, time/batch = 0.1797s	
2958/10550 (epoch 14.019), train_loss = 0.84461572, grad/param norm = 6.1111e-02, time/batch = 0.1793s	
2959/10550 (epoch 14.024), train_loss = 0.83134688, grad/param norm = 6.1652e-02, time/batch = 0.1797s	
2960/10550 (epoch 14.028), train_loss = 0.82449321, grad/param norm = 6.1556e-02, time/batch = 0.1800s	
2961/10550 (epoch 14.033), train_loss = 0.84229088, grad/param norm = 6.4764e-02, time/batch = 0.1813s	
2962/10550 (epoch 14.038), train_loss = 0.84057120, grad/param norm = 6.5700e-02, time/batch = 0.1795s	
2963/10550 (epoch 14.043), train_loss = 0.80750753, grad/param norm = 6.1250e-02, time/batch = 0.1795s	
2964/10550 (epoch 14.047), train_loss = 0.79370952, grad/param norm = 6.0621e-02, time/batch = 0.1796s	
2965/10550 (epoch 14.052), train_loss = 0.83279394, grad/param norm = 6.3192e-02, time/batch = 0.1804s	
2966/10550 (epoch 14.057), train_loss = 0.81792125, grad/param norm = 6.3289e-02, time/batch = 0.1801s	
2967/10550 (epoch 14.062), train_loss = 0.83781651, grad/param norm = 6.3552e-02, time/batch = 0.1796s	
2968/10550 (epoch 14.066), train_loss = 0.81156942, grad/param norm = 5.9217e-02, time/batch = 0.1794s	
2969/10550 (epoch 14.071), train_loss = 0.79470825, grad/param norm = 6.2766e-02, time/batch = 0.1801s	
2970/10550 (epoch 14.076), train_loss = 0.82602863, grad/param norm = 6.3126e-02, time/batch = 0.1795s	
2971/10550 (epoch 14.081), train_loss = 0.82940791, grad/param norm = 6.4630e-02, time/batch = 0.1809s	
2972/10550 (epoch 14.085), train_loss = 0.81860952, grad/param norm = 6.1784e-02, time/batch = 0.1794s	
2973/10550 (epoch 14.090), train_loss = 0.79871175, grad/param norm = 6.2537e-02, time/batch = 0.1800s	
2974/10550 (epoch 14.095), train_loss = 0.82046829, grad/param norm = 6.2088e-02, time/batch = 0.1799s	
2975/10550 (epoch 14.100), train_loss = 0.81494244, grad/param norm = 6.2973e-02, time/batch = 0.1798s	
2976/10550 (epoch 14.104), train_loss = 0.80570555, grad/param norm = 6.2711e-02, time/batch = 0.1796s	
2977/10550 (epoch 14.109), train_loss = 0.80236479, grad/param norm = 6.3706e-02, time/batch = 0.1798s	
2978/10550 (epoch 14.114), train_loss = 0.81328560, grad/param norm = 6.3124e-02, time/batch = 0.1795s	
2979/10550 (epoch 14.118), train_loss = 0.78459381, grad/param norm = 6.2734e-02, time/batch = 0.1802s	
2980/10550 (epoch 14.123), train_loss = 0.84299176, grad/param norm = 6.4480e-02, time/batch = 0.1798s	
2981/10550 (epoch 14.128), train_loss = 0.81144457, grad/param norm = 6.3647e-02, time/batch = 0.1807s	
2982/10550 (epoch 14.133), train_loss = 0.78748174, grad/param norm = 6.2431e-02, time/batch = 0.1797s	
2983/10550 (epoch 14.137), train_loss = 0.80722765, grad/param norm = 6.2337e-02, time/batch = 0.1797s	
2984/10550 (epoch 14.142), train_loss = 0.82199160, grad/param norm = 6.7252e-02, time/batch = 0.1802s	
2985/10550 (epoch 14.147), train_loss = 0.81175413, grad/param norm = 6.3770e-02, time/batch = 0.1806s	
2986/10550 (epoch 14.152), train_loss = 0.80856721, grad/param norm = 6.2014e-02, time/batch = 0.1803s	
2987/10550 (epoch 14.156), train_loss = 0.81127595, grad/param norm = 6.1122e-02, time/batch = 0.1798s	
2988/10550 (epoch 14.161), train_loss = 0.80232353, grad/param norm = 6.1340e-02, time/batch = 0.1793s	
2989/10550 (epoch 14.166), train_loss = 0.82033245, grad/param norm = 6.4964e-02, time/batch = 0.1794s	
2990/10550 (epoch 14.171), train_loss = 0.80571062, grad/param norm = 6.5600e-02, time/batch = 0.1799s	
2991/10550 (epoch 14.175), train_loss = 0.81922863, grad/param norm = 6.5539e-02, time/batch = 0.1813s	
2992/10550 (epoch 14.180), train_loss = 0.79604110, grad/param norm = 6.2852e-02, time/batch = 0.1789s	
2993/10550 (epoch 14.185), train_loss = 0.81251154, grad/param norm = 6.1373e-02, time/batch = 0.1800s	
2994/10550 (epoch 14.190), train_loss = 0.79222870, grad/param norm = 6.6092e-02, time/batch = 0.1796s	
2995/10550 (epoch 14.194), train_loss = 0.81400639, grad/param norm = 6.4205e-02, time/batch = 0.1802s	
2996/10550 (epoch 14.199), train_loss = 0.82845427, grad/param norm = 6.5902e-02, time/batch = 0.1801s	
2997/10550 (epoch 14.204), train_loss = 0.80941276, grad/param norm = 6.7669e-02, time/batch = 0.1797s	
2998/10550 (epoch 14.209), train_loss = 0.83411047, grad/param norm = 6.6934e-02, time/batch = 0.1798s	
2999/10550 (epoch 14.213), train_loss = 0.84412123, grad/param norm = 6.2673e-02, time/batch = 0.1801s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to cv/lm_lstm_epoch14.22_1.8730.t7	
3000/10550 (epoch 14.218), train_loss = 0.83245165, grad/param norm = 6.3308e-02, time/batch = 0.1799s	
3001/10550 (epoch 14.223), train_loss = 1.37125091, grad/param norm = 8.3724e-02, time/batch = 0.1820s	
3002/10550 (epoch 14.227), train_loss = 0.80063440, grad/param norm = 6.3592e-02, time/batch = 0.1799s	
3003/10550 (epoch 14.232), train_loss = 0.81475438, grad/param norm = 6.0639e-02, time/batch = 0.1802s	
3004/10550 (epoch 14.237), train_loss = 0.80045224, grad/param norm = 6.0131e-02, time/batch = 0.1795s	
3005/10550 (epoch 14.242), train_loss = 0.80603074, grad/param norm = 6.2531e-02, time/batch = 0.1799s	
3006/10550 (epoch 14.246), train_loss = 0.79367523, grad/param norm = 6.2711e-02, time/batch = 0.1796s	
3007/10550 (epoch 14.251), train_loss = 0.81114205, grad/param norm = 6.2773e-02, time/batch = 0.1805s	
3008/10550 (epoch 14.256), train_loss = 0.81742659, grad/param norm = 6.2206e-02, time/batch = 0.1798s	
3009/10550 (epoch 14.261), train_loss = 0.79807526, grad/param norm = 6.2626e-02, time/batch = 0.1804s	
3010/10550 (epoch 14.265), train_loss = 0.79943165, grad/param norm = 6.5460e-02, time/batch = 0.1801s	
3011/10550 (epoch 14.270), train_loss = 0.80546585, grad/param norm = 6.3029e-02, time/batch = 0.1812s	
3012/10550 (epoch 14.275), train_loss = 0.81249298, grad/param norm = 6.2712e-02, time/batch = 0.1801s	
3013/10550 (epoch 14.280), train_loss = 0.80973003, grad/param norm = 6.2880e-02, time/batch = 0.1795s	
3014/10550 (epoch 14.284), train_loss = 0.79820176, grad/param norm = 6.1474e-02, time/batch = 0.1799s	
3015/10550 (epoch 14.289), train_loss = 0.79974970, grad/param norm = 6.3376e-02, time/batch = 0.1795s	
3016/10550 (epoch 14.294), train_loss = 0.79696835, grad/param norm = 6.4847e-02, time/batch = 0.1799s	
3017/10550 (epoch 14.299), train_loss = 0.77780154, grad/param norm = 6.1752e-02, time/batch = 0.1801s	
3018/10550 (epoch 14.303), train_loss = 0.81490488, grad/param norm = 6.2271e-02, time/batch = 0.1798s	
3019/10550 (epoch 14.308), train_loss = 0.79298399, grad/param norm = 6.1537e-02, time/batch = 0.1801s	
3020/10550 (epoch 14.313), train_loss = 0.79358414, grad/param norm = 6.3389e-02, time/batch = 0.1805s	
3021/10550 (epoch 14.318), train_loss = 0.80534894, grad/param norm = 6.3576e-02, time/batch = 0.1809s	
3022/10550 (epoch 14.322), train_loss = 0.79771583, grad/param norm = 6.5609e-02, time/batch = 0.1796s	
3023/10550 (epoch 14.327), train_loss = 0.80010530, grad/param norm = 6.6100e-02, time/batch = 0.1796s	
3024/10550 (epoch 14.332), train_loss = 0.82776198, grad/param norm = 6.7823e-02, time/batch = 0.1800s	
3025/10550 (epoch 14.336), train_loss = 0.80772141, grad/param norm = 6.6950e-02, time/batch = 0.1802s	
3026/10550 (epoch 14.341), train_loss = 0.78355018, grad/param norm = 6.8304e-02, time/batch = 0.1798s	
3027/10550 (epoch 14.346), train_loss = 0.81806874, grad/param norm = 6.6367e-02, time/batch = 0.1798s	
3028/10550 (epoch 14.351), train_loss = 0.80411287, grad/param norm = 6.3819e-02, time/batch = 0.1792s	
3029/10550 (epoch 14.355), train_loss = 0.80447695, grad/param norm = 6.3343e-02, time/batch = 0.1799s	
3030/10550 (epoch 14.360), train_loss = 0.82659337, grad/param norm = 6.4251e-02, time/batch = 0.1801s	
3031/10550 (epoch 14.365), train_loss = 0.80539119, grad/param norm = 6.2121e-02, time/batch = 0.1810s	
3032/10550 (epoch 14.370), train_loss = 0.78772044, grad/param norm = 6.3186e-02, time/batch = 0.1793s	
3033/10550 (epoch 14.374), train_loss = 0.80137231, grad/param norm = 6.3089e-02, time/batch = 0.1799s	
3034/10550 (epoch 14.379), train_loss = 0.81051382, grad/param norm = 6.3916e-02, time/batch = 0.1799s	
3035/10550 (epoch 14.384), train_loss = 0.79723843, grad/param norm = 6.5425e-02, time/batch = 0.1799s	
3036/10550 (epoch 14.389), train_loss = 0.78000241, grad/param norm = 6.2981e-02, time/batch = 0.1802s	
3037/10550 (epoch 14.393), train_loss = 0.78734045, grad/param norm = 6.0869e-02, time/batch = 0.1795s	
3038/10550 (epoch 14.398), train_loss = 0.77678891, grad/param norm = 6.2815e-02, time/batch = 0.1794s	
3039/10550 (epoch 14.403), train_loss = 0.81437363, grad/param norm = 6.6019e-02, time/batch = 0.1799s	
3040/10550 (epoch 14.408), train_loss = 0.81614141, grad/param norm = 6.6983e-02, time/batch = 0.1799s	
3041/10550 (epoch 14.412), train_loss = 0.79826051, grad/param norm = 6.3683e-02, time/batch = 0.1808s	
3042/10550 (epoch 14.417), train_loss = 0.79121547, grad/param norm = 6.0914e-02, time/batch = 0.1800s	
3043/10550 (epoch 14.422), train_loss = 0.79746264, grad/param norm = 6.5210e-02, time/batch = 0.1793s	
3044/10550 (epoch 14.427), train_loss = 0.81926019, grad/param norm = 6.6163e-02, time/batch = 0.1799s	
3045/10550 (epoch 14.431), train_loss = 0.80296017, grad/param norm = 6.2172e-02, time/batch = 0.1797s	
3046/10550 (epoch 14.436), train_loss = 0.78634876, grad/param norm = 6.1942e-02, time/batch = 0.1800s	
3047/10550 (epoch 14.441), train_loss = 0.81299995, grad/param norm = 6.4931e-02, time/batch = 0.1801s	
3048/10550 (epoch 14.445), train_loss = 0.82063902, grad/param norm = 6.5423e-02, time/batch = 0.1794s	
3049/10550 (epoch 14.450), train_loss = 0.80933930, grad/param norm = 6.6808e-02, time/batch = 0.1798s	
3050/10550 (epoch 14.455), train_loss = 0.79523668, grad/param norm = 6.4802e-02, time/batch = 0.1800s	
3051/10550 (epoch 14.460), train_loss = 0.77064509, grad/param norm = 6.1076e-02, time/batch = 0.1809s	
3052/10550 (epoch 14.464), train_loss = 0.79028538, grad/param norm = 6.5479e-02, time/batch = 0.1798s	
3053/10550 (epoch 14.469), train_loss = 0.79046597, grad/param norm = 6.2928e-02, time/batch = 0.1801s	
3054/10550 (epoch 14.474), train_loss = 0.79808784, grad/param norm = 6.5390e-02, time/batch = 0.1799s	
3055/10550 (epoch 14.479), train_loss = 0.77447995, grad/param norm = 6.3933e-02, time/batch = 0.1799s	
3056/10550 (epoch 14.483), train_loss = 0.79665585, grad/param norm = 6.8369e-02, time/batch = 0.1800s	
3057/10550 (epoch 14.488), train_loss = 0.80683982, grad/param norm = 6.5068e-02, time/batch = 0.1796s	
3058/10550 (epoch 14.493), train_loss = 0.79600181, grad/param norm = 6.5824e-02, time/batch = 0.1795s	
3059/10550 (epoch 14.498), train_loss = 0.79531954, grad/param norm = 6.0779e-02, time/batch = 0.1803s	
3060/10550 (epoch 14.502), train_loss = 0.80216941, grad/param norm = 6.2365e-02, time/batch = 0.1799s	
3061/10550 (epoch 14.507), train_loss = 0.78130498, grad/param norm = 6.2340e-02, time/batch = 0.1813s	
3062/10550 (epoch 14.512), train_loss = 0.76200285, grad/param norm = 6.4570e-02, time/batch = 0.1792s	
3063/10550 (epoch 14.517), train_loss = 0.78913058, grad/param norm = 6.6200e-02, time/batch = 0.1796s	
3064/10550 (epoch 14.521), train_loss = 0.78051411, grad/param norm = 6.5395e-02, time/batch = 0.1803s	
3065/10550 (epoch 14.526), train_loss = 0.73671866, grad/param norm = 6.1581e-02, time/batch = 0.1802s	
3066/10550 (epoch 14.531), train_loss = 0.76026749, grad/param norm = 6.2138e-02, time/batch = 0.1800s	
3067/10550 (epoch 14.536), train_loss = 0.81437694, grad/param norm = 6.5006e-02, time/batch = 0.1799s	
3068/10550 (epoch 14.540), train_loss = 0.79191458, grad/param norm = 6.3311e-02, time/batch = 0.1795s	
3069/10550 (epoch 14.545), train_loss = 0.79194376, grad/param norm = 6.5609e-02, time/batch = 0.1802s	
3070/10550 (epoch 14.550), train_loss = 0.80054560, grad/param norm = 6.6524e-02, time/batch = 0.1796s	
3071/10550 (epoch 14.555), train_loss = 0.78899555, grad/param norm = 6.5047e-02, time/batch = 0.1813s	
3072/10550 (epoch 14.559), train_loss = 0.81391182, grad/param norm = 6.7612e-02, time/batch = 0.1797s	
3073/10550 (epoch 14.564), train_loss = 0.77654033, grad/param norm = 6.5038e-02, time/batch = 0.1794s	
3074/10550 (epoch 14.569), train_loss = 0.78743905, grad/param norm = 6.8604e-02, time/batch = 0.1796s	
3075/10550 (epoch 14.573), train_loss = 0.80578791, grad/param norm = 6.8287e-02, time/batch = 0.1804s	
3076/10550 (epoch 14.578), train_loss = 0.78728049, grad/param norm = 6.6503e-02, time/batch = 0.1799s	
3077/10550 (epoch 14.583), train_loss = 0.79427970, grad/param norm = 6.7983e-02, time/batch = 0.1802s	
3078/10550 (epoch 14.588), train_loss = 0.75990116, grad/param norm = 6.1748e-02, time/batch = 0.1797s	
3079/10550 (epoch 14.592), train_loss = 0.79405610, grad/param norm = 6.7679e-02, time/batch = 0.1799s	
3080/10550 (epoch 14.597), train_loss = 0.78829618, grad/param norm = 6.6673e-02, time/batch = 0.1798s	
3081/10550 (epoch 14.602), train_loss = 0.80752776, grad/param norm = 6.8593e-02, time/batch = 0.1811s	
3082/10550 (epoch 14.607), train_loss = 0.78241884, grad/param norm = 6.4473e-02, time/batch = 0.1793s	
3083/10550 (epoch 14.611), train_loss = 0.77150904, grad/param norm = 6.5942e-02, time/batch = 0.1798s	
3084/10550 (epoch 14.616), train_loss = 0.78973401, grad/param norm = 6.7570e-02, time/batch = 0.1797s	
3085/10550 (epoch 14.621), train_loss = 0.78285908, grad/param norm = 6.6727e-02, time/batch = 0.1800s	
3086/10550 (epoch 14.626), train_loss = 0.78213106, grad/param norm = 6.5792e-02, time/batch = 0.1803s	
3087/10550 (epoch 14.630), train_loss = 0.79589807, grad/param norm = 6.7827e-02, time/batch = 0.1797s	
3088/10550 (epoch 14.635), train_loss = 0.81049785, grad/param norm = 6.5998e-02, time/batch = 0.1796s	
3089/10550 (epoch 14.640), train_loss = 0.81304073, grad/param norm = 6.3168e-02, time/batch = 0.1799s	
3090/10550 (epoch 14.645), train_loss = 0.79096979, grad/param norm = 6.5098e-02, time/batch = 0.1802s	
3091/10550 (epoch 14.649), train_loss = 0.80864091, grad/param norm = 6.3876e-02, time/batch = 0.1810s	
3092/10550 (epoch 14.654), train_loss = 0.79815942, grad/param norm = 6.1471e-02, time/batch = 0.1797s	
3093/10550 (epoch 14.659), train_loss = 0.79730113, grad/param norm = 6.3593e-02, time/batch = 0.1797s	
3094/10550 (epoch 14.664), train_loss = 0.79808839, grad/param norm = 6.3546e-02, time/batch = 0.1797s	
3095/10550 (epoch 14.668), train_loss = 0.76097182, grad/param norm = 6.3900e-02, time/batch = 0.1800s	
3096/10550 (epoch 14.673), train_loss = 0.78916999, grad/param norm = 6.5880e-02, time/batch = 0.1800s	
3097/10550 (epoch 14.678), train_loss = 0.76964879, grad/param norm = 6.6265e-02, time/batch = 0.1798s	
3098/10550 (epoch 14.682), train_loss = 0.78533486, grad/param norm = 6.3420e-02, time/batch = 0.1791s	
3099/10550 (epoch 14.687), train_loss = 0.77500355, grad/param norm = 6.4628e-02, time/batch = 0.1801s	
3100/10550 (epoch 14.692), train_loss = 0.79386332, grad/param norm = 6.6420e-02, time/batch = 0.1795s	
3101/10550 (epoch 14.697), train_loss = 0.78215394, grad/param norm = 6.6466e-02, time/batch = 0.1806s	
3102/10550 (epoch 14.701), train_loss = 0.78331116, grad/param norm = 6.3053e-02, time/batch = 0.1796s	
3103/10550 (epoch 14.706), train_loss = 0.77919065, grad/param norm = 6.6455e-02, time/batch = 0.1795s	
3104/10550 (epoch 14.711), train_loss = 0.80381387, grad/param norm = 6.3103e-02, time/batch = 0.1802s	
3105/10550 (epoch 14.716), train_loss = 0.77179003, grad/param norm = 6.5011e-02, time/batch = 0.1804s	
3106/10550 (epoch 14.720), train_loss = 0.80032135, grad/param norm = 6.4550e-02, time/batch = 0.1797s	
3107/10550 (epoch 14.725), train_loss = 0.76947900, grad/param norm = 6.3582e-02, time/batch = 0.1801s	
3108/10550 (epoch 14.730), train_loss = 0.76562111, grad/param norm = 6.3451e-02, time/batch = 0.1794s	
3109/10550 (epoch 14.735), train_loss = 0.78376947, grad/param norm = 6.3866e-02, time/batch = 0.1800s	
3110/10550 (epoch 14.739), train_loss = 0.76796900, grad/param norm = 6.3836e-02, time/batch = 0.1800s	
3111/10550 (epoch 14.744), train_loss = 0.77185276, grad/param norm = 6.1833e-02, time/batch = 0.1806s	
3112/10550 (epoch 14.749), train_loss = 0.80972924, grad/param norm = 6.8156e-02, time/batch = 0.1795s	
3113/10550 (epoch 14.754), train_loss = 0.80078136, grad/param norm = 6.3172e-02, time/batch = 0.1795s	
3114/10550 (epoch 14.758), train_loss = 0.77330867, grad/param norm = 6.7828e-02, time/batch = 0.1799s	
3115/10550 (epoch 14.763), train_loss = 0.75118506, grad/param norm = 6.4018e-02, time/batch = 0.1796s	
3116/10550 (epoch 14.768), train_loss = 0.79416419, grad/param norm = 6.6819e-02, time/batch = 0.1803s	
3117/10550 (epoch 14.773), train_loss = 0.81951783, grad/param norm = 7.2569e-02, time/batch = 0.1799s	
3118/10550 (epoch 14.777), train_loss = 0.78682971, grad/param norm = 6.4821e-02, time/batch = 0.1799s	
3119/10550 (epoch 14.782), train_loss = 0.82322930, grad/param norm = 6.8097e-02, time/batch = 0.1801s	
3120/10550 (epoch 14.787), train_loss = 0.78930887, grad/param norm = 6.8430e-02, time/batch = 0.1794s	
3121/10550 (epoch 14.791), train_loss = 0.76307888, grad/param norm = 6.5121e-02, time/batch = 0.1812s	
3122/10550 (epoch 14.796), train_loss = 0.79821589, grad/param norm = 6.4439e-02, time/batch = 0.1793s	
3123/10550 (epoch 14.801), train_loss = 0.77976761, grad/param norm = 6.6182e-02, time/batch = 0.1794s	
3124/10550 (epoch 14.806), train_loss = 0.79927543, grad/param norm = 6.7125e-02, time/batch = 0.1798s	
3125/10550 (epoch 14.810), train_loss = 0.81442488, grad/param norm = 6.8241e-02, time/batch = 0.1801s	
3126/10550 (epoch 14.815), train_loss = 0.79591677, grad/param norm = 6.6816e-02, time/batch = 0.1798s	
3127/10550 (epoch 14.820), train_loss = 0.80586559, grad/param norm = 6.5601e-02, time/batch = 0.1799s	
3128/10550 (epoch 14.825), train_loss = 0.79677661, grad/param norm = 6.4165e-02, time/batch = 0.1792s	
3129/10550 (epoch 14.829), train_loss = 0.77560370, grad/param norm = 6.4899e-02, time/batch = 0.1804s	
3130/10550 (epoch 14.834), train_loss = 0.77912614, grad/param norm = 6.4528e-02, time/batch = 0.1801s	
3131/10550 (epoch 14.839), train_loss = 0.77813713, grad/param norm = 6.5026e-02, time/batch = 0.1810s	
3132/10550 (epoch 14.844), train_loss = 0.78401381, grad/param norm = 6.6045e-02, time/batch = 0.1794s	
3133/10550 (epoch 14.848), train_loss = 0.77425850, grad/param norm = 6.5105e-02, time/batch = 0.1803s	
3134/10550 (epoch 14.853), train_loss = 0.79064160, grad/param norm = 6.5762e-02, time/batch = 0.1797s	
3135/10550 (epoch 14.858), train_loss = 0.81416958, grad/param norm = 6.6753e-02, time/batch = 0.1802s	
3136/10550 (epoch 14.863), train_loss = 0.76983575, grad/param norm = 6.4554e-02, time/batch = 0.1799s	
3137/10550 (epoch 14.867), train_loss = 0.80248472, grad/param norm = 6.8166e-02, time/batch = 0.1792s	
3138/10550 (epoch 14.872), train_loss = 0.78010217, grad/param norm = 6.4056e-02, time/batch = 0.1792s	
3139/10550 (epoch 14.877), train_loss = 0.77306297, grad/param norm = 6.5716e-02, time/batch = 0.1798s	
3140/10550 (epoch 14.882), train_loss = 0.78287525, grad/param norm = 6.7325e-02, time/batch = 0.1803s	
3141/10550 (epoch 14.886), train_loss = 0.78482524, grad/param norm = 6.4759e-02, time/batch = 0.1812s	
3142/10550 (epoch 14.891), train_loss = 0.76972427, grad/param norm = 6.5939e-02, time/batch = 0.1794s	
3143/10550 (epoch 14.896), train_loss = 0.77354056, grad/param norm = 6.3057e-02, time/batch = 0.1808s	
3144/10550 (epoch 14.900), train_loss = 0.76812646, grad/param norm = 6.4192e-02, time/batch = 0.1796s	
3145/10550 (epoch 14.905), train_loss = 0.75654150, grad/param norm = 6.7279e-02, time/batch = 0.1802s	
3146/10550 (epoch 14.910), train_loss = 0.77813721, grad/param norm = 6.5137e-02, time/batch = 0.1800s	
3147/10550 (epoch 14.915), train_loss = 0.77057878, grad/param norm = 6.4463e-02, time/batch = 0.1795s	
3148/10550 (epoch 14.919), train_loss = 0.78292764, grad/param norm = 6.5547e-02, time/batch = 0.1799s	
3149/10550 (epoch 14.924), train_loss = 0.79021933, grad/param norm = 6.6535e-02, time/batch = 0.1797s	
3150/10550 (epoch 14.929), train_loss = 0.77864453, grad/param norm = 6.6371e-02, time/batch = 0.1799s	
3151/10550 (epoch 14.934), train_loss = 0.76465719, grad/param norm = 6.5617e-02, time/batch = 0.1815s	
3152/10550 (epoch 14.938), train_loss = 0.79547520, grad/param norm = 6.7429e-02, time/batch = 0.1795s	
3153/10550 (epoch 14.943), train_loss = 0.79283986, grad/param norm = 6.6535e-02, time/batch = 0.1800s	
3154/10550 (epoch 14.948), train_loss = 0.78279984, grad/param norm = 6.7012e-02, time/batch = 0.1796s	
3155/10550 (epoch 14.953), train_loss = 0.80188935, grad/param norm = 7.1484e-02, time/batch = 0.1800s	
3156/10550 (epoch 14.957), train_loss = 0.80832686, grad/param norm = 6.8837e-02, time/batch = 0.1800s	
3157/10550 (epoch 14.962), train_loss = 0.78717957, grad/param norm = 6.4195e-02, time/batch = 0.1804s	
3158/10550 (epoch 14.967), train_loss = 0.79552739, grad/param norm = 6.4274e-02, time/batch = 0.1797s	
3159/10550 (epoch 14.972), train_loss = 0.76812941, grad/param norm = 6.2358e-02, time/batch = 0.1802s	
3160/10550 (epoch 14.976), train_loss = 0.76953898, grad/param norm = 6.3959e-02, time/batch = 0.1797s	
3161/10550 (epoch 14.981), train_loss = 0.77659417, grad/param norm = 6.4129e-02, time/batch = 0.1812s	
3162/10550 (epoch 14.986), train_loss = 0.77058305, grad/param norm = 6.4436e-02, time/batch = 0.1794s	
3163/10550 (epoch 14.991), train_loss = 0.81297994, grad/param norm = 6.6209e-02, time/batch = 0.1796s	
3164/10550 (epoch 14.995), train_loss = 0.78862550, grad/param norm = 6.4475e-02, time/batch = 0.1800s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
3165/10550 (epoch 15.000), train_loss = 0.77820077, grad/param norm = 6.5870e-02, time/batch = 0.1794s	
3166/10550 (epoch 15.005), train_loss = 0.97639679, grad/param norm = 7.0522e-02, time/batch = 0.1802s	
3167/10550 (epoch 15.009), train_loss = 0.77173154, grad/param norm = 6.4733e-02, time/batch = 0.1805s	
3168/10550 (epoch 15.014), train_loss = 0.78048445, grad/param norm = 6.3012e-02, time/batch = 0.1799s	
3169/10550 (epoch 15.019), train_loss = 0.81316028, grad/param norm = 6.4953e-02, time/batch = 0.1802s	
3170/10550 (epoch 15.024), train_loss = 0.79128057, grad/param norm = 6.4409e-02, time/batch = 0.1799s	
3171/10550 (epoch 15.028), train_loss = 0.79040769, grad/param norm = 6.7237e-02, time/batch = 0.1813s	
3172/10550 (epoch 15.033), train_loss = 0.80355948, grad/param norm = 6.5496e-02, time/batch = 0.1791s	
3173/10550 (epoch 15.038), train_loss = 0.79040955, grad/param norm = 6.5406e-02, time/batch = 0.1800s	
3174/10550 (epoch 15.043), train_loss = 0.77687220, grad/param norm = 6.7633e-02, time/batch = 0.1801s	
3175/10550 (epoch 15.047), train_loss = 0.75960979, grad/param norm = 6.3771e-02, time/batch = 0.1800s	
3176/10550 (epoch 15.052), train_loss = 0.79214612, grad/param norm = 6.6012e-02, time/batch = 0.1797s	
3177/10550 (epoch 15.057), train_loss = 0.78058821, grad/param norm = 6.5169e-02, time/batch = 0.1795s	
3178/10550 (epoch 15.062), train_loss = 0.79957148, grad/param norm = 6.6703e-02, time/batch = 0.1793s	
3179/10550 (epoch 15.066), train_loss = 0.76870375, grad/param norm = 6.3037e-02, time/batch = 0.1798s	
3180/10550 (epoch 15.071), train_loss = 0.76775905, grad/param norm = 6.6134e-02, time/batch = 0.1804s	
3181/10550 (epoch 15.076), train_loss = 0.77985698, grad/param norm = 6.5016e-02, time/batch = 0.1807s	
3182/10550 (epoch 15.081), train_loss = 0.78663215, grad/param norm = 6.5498e-02, time/batch = 0.1793s	
3183/10550 (epoch 15.085), train_loss = 0.78084867, grad/param norm = 6.5451e-02, time/batch = 0.1800s	
3184/10550 (epoch 15.090), train_loss = 0.77102435, grad/param norm = 6.5819e-02, time/batch = 0.1803s	
3185/10550 (epoch 15.095), train_loss = 0.77794351, grad/param norm = 6.3585e-02, time/batch = 0.1802s	
3186/10550 (epoch 15.100), train_loss = 0.77675277, grad/param norm = 6.4671e-02, time/batch = 0.1798s	
3187/10550 (epoch 15.104), train_loss = 0.76251839, grad/param norm = 6.6823e-02, time/batch = 0.1800s	
3188/10550 (epoch 15.109), train_loss = 0.77078807, grad/param norm = 6.6673e-02, time/batch = 0.1795s	
3189/10550 (epoch 15.114), train_loss = 0.77863815, grad/param norm = 6.5267e-02, time/batch = 0.1802s	
3190/10550 (epoch 15.118), train_loss = 0.76196131, grad/param norm = 6.5391e-02, time/batch = 0.1801s	
3191/10550 (epoch 15.123), train_loss = 0.79892220, grad/param norm = 6.4519e-02, time/batch = 0.1812s	
3192/10550 (epoch 15.128), train_loss = 0.77428599, grad/param norm = 6.5627e-02, time/batch = 0.1790s	
3193/10550 (epoch 15.133), train_loss = 0.76219117, grad/param norm = 6.7780e-02, time/batch = 0.1796s	
3194/10550 (epoch 15.137), train_loss = 0.76654025, grad/param norm = 6.6647e-02, time/batch = 0.1797s	
3195/10550 (epoch 15.142), train_loss = 0.78191267, grad/param norm = 6.9262e-02, time/batch = 0.1796s	
3196/10550 (epoch 15.147), train_loss = 0.77282333, grad/param norm = 6.6043e-02, time/batch = 0.1799s	
3197/10550 (epoch 15.152), train_loss = 0.78871516, grad/param norm = 6.7310e-02, time/batch = 0.1798s	
3198/10550 (epoch 15.156), train_loss = 0.77604389, grad/param norm = 6.4520e-02, time/batch = 0.1797s	
3199/10550 (epoch 15.161), train_loss = 0.76672235, grad/param norm = 6.4635e-02, time/batch = 0.1803s	
3200/10550 (epoch 15.166), train_loss = 0.79397608, grad/param norm = 6.7251e-02, time/batch = 0.1801s	
3201/10550 (epoch 15.171), train_loss = 0.76781594, grad/param norm = 6.6225e-02, time/batch = 0.1813s	
3202/10550 (epoch 15.175), train_loss = 0.78237682, grad/param norm = 6.4036e-02, time/batch = 0.1801s	
3203/10550 (epoch 15.180), train_loss = 0.75465286, grad/param norm = 6.3978e-02, time/batch = 0.1797s	
3204/10550 (epoch 15.185), train_loss = 0.79334422, grad/param norm = 6.9412e-02, time/batch = 0.1800s	
3205/10550 (epoch 15.190), train_loss = 0.75292674, grad/param norm = 6.8763e-02, time/batch = 0.1797s	
3206/10550 (epoch 15.194), train_loss = 0.77417087, grad/param norm = 6.9145e-02, time/batch = 0.1797s	
3207/10550 (epoch 15.199), train_loss = 0.79013205, grad/param norm = 6.6952e-02, time/batch = 0.1803s	
3208/10550 (epoch 15.204), train_loss = 0.76850932, grad/param norm = 7.2218e-02, time/batch = 0.1797s	
3209/10550 (epoch 15.209), train_loss = 0.78855212, grad/param norm = 6.5830e-02, time/batch = 0.1800s	
3210/10550 (epoch 15.213), train_loss = 0.79804714, grad/param norm = 6.7865e-02, time/batch = 0.1801s	
3211/10550 (epoch 15.218), train_loss = 0.78495641, grad/param norm = 6.6014e-02, time/batch = 0.1814s	
3212/10550 (epoch 15.223), train_loss = 0.78508856, grad/param norm = 6.5262e-02, time/batch = 0.1793s	
3213/10550 (epoch 15.227), train_loss = 0.74732473, grad/param norm = 6.2909e-02, time/batch = 0.1795s	
3214/10550 (epoch 15.232), train_loss = 0.77685500, grad/param norm = 6.6804e-02, time/batch = 0.1796s	
3215/10550 (epoch 15.237), train_loss = 0.76897598, grad/param norm = 6.4482e-02, time/batch = 0.1799s	
3216/10550 (epoch 15.242), train_loss = 0.75930620, grad/param norm = 6.4963e-02, time/batch = 0.1797s	
3217/10550 (epoch 15.246), train_loss = 0.75240438, grad/param norm = 6.3151e-02, time/batch = 0.1802s	
3218/10550 (epoch 15.251), train_loss = 0.76089165, grad/param norm = 6.5919e-02, time/batch = 0.1797s	
3219/10550 (epoch 15.256), train_loss = 0.77337644, grad/param norm = 6.3779e-02, time/batch = 0.1800s	
3220/10550 (epoch 15.261), train_loss = 0.74898775, grad/param norm = 6.3130e-02, time/batch = 0.1799s	
3221/10550 (epoch 15.265), train_loss = 0.75940022, grad/param norm = 6.6988e-02, time/batch = 0.1809s	
3222/10550 (epoch 15.270), train_loss = 0.75977877, grad/param norm = 6.2736e-02, time/batch = 0.1795s	
3223/10550 (epoch 15.275), train_loss = 0.76536841, grad/param norm = 6.3248e-02, time/batch = 0.1796s	
3224/10550 (epoch 15.280), train_loss = 0.76994247, grad/param norm = 6.5639e-02, time/batch = 0.1800s	
3225/10550 (epoch 15.284), train_loss = 0.76713492, grad/param norm = 6.7062e-02, time/batch = 0.1798s	
3226/10550 (epoch 15.289), train_loss = 0.75055597, grad/param norm = 6.3885e-02, time/batch = 0.1801s	
3227/10550 (epoch 15.294), train_loss = 0.75723571, grad/param norm = 6.8143e-02, time/batch = 0.1799s	
3228/10550 (epoch 15.299), train_loss = 0.74446884, grad/param norm = 6.5949e-02, time/batch = 0.1794s	
3229/10550 (epoch 15.303), train_loss = 0.77404233, grad/param norm = 6.4469e-02, time/batch = 0.1799s	
3230/10550 (epoch 15.308), train_loss = 0.74925239, grad/param norm = 6.2887e-02, time/batch = 0.1805s	
3231/10550 (epoch 15.313), train_loss = 0.75896958, grad/param norm = 6.5551e-02, time/batch = 0.1812s	
3232/10550 (epoch 15.318), train_loss = 0.76869538, grad/param norm = 6.6372e-02, time/batch = 0.1796s	
3233/10550 (epoch 15.322), train_loss = 0.75814250, grad/param norm = 6.6526e-02, time/batch = 0.1796s	
3234/10550 (epoch 15.327), train_loss = 0.76568947, grad/param norm = 6.8874e-02, time/batch = 0.1798s	
3235/10550 (epoch 15.332), train_loss = 0.77650369, grad/param norm = 6.6502e-02, time/batch = 0.1803s	
3236/10550 (epoch 15.336), train_loss = 0.76467049, grad/param norm = 7.1763e-02, time/batch = 0.1798s	
3237/10550 (epoch 15.341), train_loss = 0.74870008, grad/param norm = 6.7000e-02, time/batch = 0.1802s	
3238/10550 (epoch 15.346), train_loss = 0.77997482, grad/param norm = 7.3266e-02, time/batch = 0.1800s	
3239/10550 (epoch 15.351), train_loss = 0.77419378, grad/param norm = 6.5702e-02, time/batch = 0.1798s	
3240/10550 (epoch 15.355), train_loss = 0.75990115, grad/param norm = 6.5643e-02, time/batch = 0.1805s	
3241/10550 (epoch 15.360), train_loss = 0.78092484, grad/param norm = 6.5692e-02, time/batch = 0.1811s	
3242/10550 (epoch 15.365), train_loss = 0.77373932, grad/param norm = 6.6941e-02, time/batch = 0.1799s	
3243/10550 (epoch 15.370), train_loss = 0.74900996, grad/param norm = 6.4550e-02, time/batch = 0.1802s	
3244/10550 (epoch 15.374), train_loss = 0.76250974, grad/param norm = 6.6442e-02, time/batch = 0.1802s	
3245/10550 (epoch 15.379), train_loss = 0.76696929, grad/param norm = 6.6416e-02, time/batch = 0.1799s	
3246/10550 (epoch 15.384), train_loss = 0.75115617, grad/param norm = 6.5181e-02, time/batch = 0.1796s	
3247/10550 (epoch 15.389), train_loss = 0.75301558, grad/param norm = 6.6838e-02, time/batch = 0.1798s	
3248/10550 (epoch 15.393), train_loss = 0.74870059, grad/param norm = 6.5149e-02, time/batch = 0.1796s	
3249/10550 (epoch 15.398), train_loss = 0.73783699, grad/param norm = 6.4021e-02, time/batch = 0.1801s	
3250/10550 (epoch 15.403), train_loss = 0.77040883, grad/param norm = 6.8207e-02, time/batch = 0.1800s	
3251/10550 (epoch 15.408), train_loss = 0.77879539, grad/param norm = 6.7622e-02, time/batch = 0.1816s	
3252/10550 (epoch 15.412), train_loss = 0.77137925, grad/param norm = 6.6181e-02, time/batch = 0.1797s	
3253/10550 (epoch 15.417), train_loss = 0.75983215, grad/param norm = 6.7398e-02, time/batch = 0.1796s	
3254/10550 (epoch 15.422), train_loss = 0.75995894, grad/param norm = 6.8609e-02, time/batch = 0.1800s	
3255/10550 (epoch 15.427), train_loss = 0.77837694, grad/param norm = 6.6907e-02, time/batch = 0.1801s	
3256/10550 (epoch 15.431), train_loss = 0.77458208, grad/param norm = 6.9989e-02, time/batch = 0.1802s	
3257/10550 (epoch 15.436), train_loss = 0.75327340, grad/param norm = 6.3959e-02, time/batch = 0.1794s	
3258/10550 (epoch 15.441), train_loss = 0.77309805, grad/param norm = 6.6586e-02, time/batch = 0.1800s	
3259/10550 (epoch 15.445), train_loss = 0.78189428, grad/param norm = 7.1152e-02, time/batch = 0.1802s	
3260/10550 (epoch 15.450), train_loss = 0.77615156, grad/param norm = 7.5095e-02, time/batch = 0.1801s	
3261/10550 (epoch 15.455), train_loss = 0.77035695, grad/param norm = 6.8915e-02, time/batch = 0.1813s	
3262/10550 (epoch 15.460), train_loss = 0.74438598, grad/param norm = 6.4945e-02, time/batch = 0.1796s	
3263/10550 (epoch 15.464), train_loss = 0.75283171, grad/param norm = 6.5683e-02, time/batch = 0.1800s	
3264/10550 (epoch 15.469), train_loss = 0.76291103, grad/param norm = 6.5619e-02, time/batch = 0.1799s	
3265/10550 (epoch 15.474), train_loss = 0.76078455, grad/param norm = 6.7074e-02, time/batch = 0.1797s	
3266/10550 (epoch 15.479), train_loss = 0.73301358, grad/param norm = 6.6074e-02, time/batch = 0.1804s	
3267/10550 (epoch 15.483), train_loss = 0.74857911, grad/param norm = 6.4797e-02, time/batch = 0.1799s	
3268/10550 (epoch 15.488), train_loss = 0.75762067, grad/param norm = 6.5059e-02, time/batch = 0.1792s	
3269/10550 (epoch 15.493), train_loss = 0.74418882, grad/param norm = 6.3231e-02, time/batch = 0.1798s	
3270/10550 (epoch 15.498), train_loss = 0.75624660, grad/param norm = 6.3723e-02, time/batch = 0.1798s	
3271/10550 (epoch 15.502), train_loss = 0.75803686, grad/param norm = 6.4571e-02, time/batch = 0.1807s	
3272/10550 (epoch 15.507), train_loss = 0.74086753, grad/param norm = 6.4823e-02, time/batch = 0.1789s	
3273/10550 (epoch 15.512), train_loss = 0.72611500, grad/param norm = 6.5454e-02, time/batch = 0.1795s	
3274/10550 (epoch 15.517), train_loss = 0.74608236, grad/param norm = 6.4965e-02, time/batch = 0.1799s	
3275/10550 (epoch 15.521), train_loss = 0.73880965, grad/param norm = 6.5767e-02, time/batch = 0.1802s	
3276/10550 (epoch 15.526), train_loss = 0.69676665, grad/param norm = 6.2845e-02, time/batch = 0.1801s	
3277/10550 (epoch 15.531), train_loss = 0.72559346, grad/param norm = 6.6139e-02, time/batch = 0.1804s	
3278/10550 (epoch 15.536), train_loss = 0.77778806, grad/param norm = 6.9161e-02, time/batch = 0.1789s	
3279/10550 (epoch 15.540), train_loss = 0.76260683, grad/param norm = 6.5901e-02, time/batch = 0.1803s	
3280/10550 (epoch 15.545), train_loss = 0.75108668, grad/param norm = 6.4131e-02, time/batch = 0.1800s	
3281/10550 (epoch 15.550), train_loss = 0.76221740, grad/param norm = 6.7189e-02, time/batch = 0.1809s	
3282/10550 (epoch 15.555), train_loss = 0.74798747, grad/param norm = 6.4609e-02, time/batch = 0.1797s	
3283/10550 (epoch 15.559), train_loss = 0.76233475, grad/param norm = 7.0599e-02, time/batch = 0.1800s	
3284/10550 (epoch 15.564), train_loss = 0.72658796, grad/param norm = 6.7937e-02, time/batch = 0.1798s	
3285/10550 (epoch 15.569), train_loss = 0.74331187, grad/param norm = 6.7179e-02, time/batch = 0.1798s	
3286/10550 (epoch 15.573), train_loss = 0.76405804, grad/param norm = 6.8293e-02, time/batch = 0.1799s	
3287/10550 (epoch 15.578), train_loss = 0.74794097, grad/param norm = 6.6000e-02, time/batch = 0.1803s	
3288/10550 (epoch 15.583), train_loss = 0.75315315, grad/param norm = 6.7948e-02, time/batch = 0.1797s	
3289/10550 (epoch 15.588), train_loss = 0.73192534, grad/param norm = 6.6461e-02, time/batch = 0.1800s	
3290/10550 (epoch 15.592), train_loss = 0.74700806, grad/param norm = 6.4401e-02, time/batch = 0.1804s	
3291/10550 (epoch 15.597), train_loss = 0.74881107, grad/param norm = 6.5345e-02, time/batch = 0.1806s	
3292/10550 (epoch 15.602), train_loss = 0.77748623, grad/param norm = 7.0558e-02, time/batch = 0.1794s	
3293/10550 (epoch 15.607), train_loss = 0.74794634, grad/param norm = 6.7251e-02, time/batch = 0.1795s	
3294/10550 (epoch 15.611), train_loss = 0.74266350, grad/param norm = 6.8948e-02, time/batch = 0.1801s	
3295/10550 (epoch 15.616), train_loss = 0.73914186, grad/param norm = 6.5531e-02, time/batch = 0.1800s	
3296/10550 (epoch 15.621), train_loss = 0.74999258, grad/param norm = 6.7142e-02, time/batch = 0.1798s	
3297/10550 (epoch 15.626), train_loss = 0.73940621, grad/param norm = 6.8587e-02, time/batch = 0.1800s	
3298/10550 (epoch 15.630), train_loss = 0.75760896, grad/param norm = 6.8346e-02, time/batch = 0.1791s	
3299/10550 (epoch 15.635), train_loss = 0.77732309, grad/param norm = 6.6692e-02, time/batch = 0.1801s	
3300/10550 (epoch 15.640), train_loss = 0.78347335, grad/param norm = 6.8858e-02, time/batch = 0.1799s	
3301/10550 (epoch 15.645), train_loss = 0.75538764, grad/param norm = 6.7711e-02, time/batch = 0.1813s	
3302/10550 (epoch 15.649), train_loss = 0.77432404, grad/param norm = 7.1445e-02, time/batch = 0.1790s	
3303/10550 (epoch 15.654), train_loss = 0.75678405, grad/param norm = 6.4295e-02, time/batch = 0.1798s	
3304/10550 (epoch 15.659), train_loss = 0.74962361, grad/param norm = 6.3728e-02, time/batch = 0.1796s	
3305/10550 (epoch 15.664), train_loss = 0.76014695, grad/param norm = 6.6213e-02, time/batch = 0.1803s	
3306/10550 (epoch 15.668), train_loss = 0.72469682, grad/param norm = 6.8665e-02, time/batch = 0.1797s	
3307/10550 (epoch 15.673), train_loss = 0.74567694, grad/param norm = 6.5708e-02, time/batch = 0.1800s	
3308/10550 (epoch 15.678), train_loss = 0.73223351, grad/param norm = 6.6172e-02, time/batch = 0.1793s	
3309/10550 (epoch 15.682), train_loss = 0.74172938, grad/param norm = 6.7047e-02, time/batch = 0.1802s	
3310/10550 (epoch 15.687), train_loss = 0.72562201, grad/param norm = 6.4210e-02, time/batch = 0.1805s	
3311/10550 (epoch 15.692), train_loss = 0.74775152, grad/param norm = 6.6990e-02, time/batch = 0.1808s	
3312/10550 (epoch 15.697), train_loss = 0.74075100, grad/param norm = 6.8273e-02, time/batch = 0.1790s	
3313/10550 (epoch 15.701), train_loss = 0.74723260, grad/param norm = 6.7266e-02, time/batch = 0.1800s	
3314/10550 (epoch 15.706), train_loss = 0.73597642, grad/param norm = 7.0313e-02, time/batch = 0.1795s	
3315/10550 (epoch 15.711), train_loss = 0.75731037, grad/param norm = 6.5857e-02, time/batch = 0.1797s	
3316/10550 (epoch 15.716), train_loss = 0.73840615, grad/param norm = 6.7296e-02, time/batch = 0.1799s	
3317/10550 (epoch 15.720), train_loss = 0.75046976, grad/param norm = 6.4677e-02, time/batch = 0.1800s	
3318/10550 (epoch 15.725), train_loss = 0.72494557, grad/param norm = 6.6133e-02, time/batch = 0.1800s	
3319/10550 (epoch 15.730), train_loss = 0.73414099, grad/param norm = 6.5525e-02, time/batch = 0.1785s	
3320/10550 (epoch 15.735), train_loss = 0.75133007, grad/param norm = 6.4911e-02, time/batch = 0.1802s	
3321/10550 (epoch 15.739), train_loss = 0.73203736, grad/param norm = 6.7819e-02, time/batch = 0.1810s	
3322/10550 (epoch 15.744), train_loss = 0.73783321, grad/param norm = 6.6262e-02, time/batch = 0.1790s	
3323/10550 (epoch 15.749), train_loss = 0.76865947, grad/param norm = 6.7735e-02, time/batch = 0.1793s	
3324/10550 (epoch 15.754), train_loss = 0.76225871, grad/param norm = 6.5664e-02, time/batch = 0.1799s	
3325/10550 (epoch 15.758), train_loss = 0.72691616, grad/param norm = 6.7392e-02, time/batch = 0.1799s	
3326/10550 (epoch 15.763), train_loss = 0.72374180, grad/param norm = 7.0664e-02, time/batch = 0.1800s	
3327/10550 (epoch 15.768), train_loss = 0.75505747, grad/param norm = 6.8001e-02, time/batch = 0.1794s	
3328/10550 (epoch 15.773), train_loss = 0.77986572, grad/param norm = 7.1743e-02, time/batch = 0.1794s	
3329/10550 (epoch 15.777), train_loss = 0.75551836, grad/param norm = 6.6256e-02, time/batch = 0.1801s	
3330/10550 (epoch 15.782), train_loss = 0.78210325, grad/param norm = 6.8333e-02, time/batch = 0.1805s	
3331/10550 (epoch 15.787), train_loss = 0.73889968, grad/param norm = 6.8158e-02, time/batch = 0.1810s	
3332/10550 (epoch 15.791), train_loss = 0.71999881, grad/param norm = 6.6539e-02, time/batch = 0.1794s	
3333/10550 (epoch 15.796), train_loss = 0.76237761, grad/param norm = 6.7076e-02, time/batch = 0.1796s	
3334/10550 (epoch 15.801), train_loss = 0.73992741, grad/param norm = 6.7018e-02, time/batch = 0.1794s	
3335/10550 (epoch 15.806), train_loss = 0.74341301, grad/param norm = 6.7185e-02, time/batch = 0.1803s	
3336/10550 (epoch 15.810), train_loss = 0.76539420, grad/param norm = 6.7927e-02, time/batch = 0.1803s	
3337/10550 (epoch 15.815), train_loss = 0.74725252, grad/param norm = 6.7458e-02, time/batch = 0.1803s	
3338/10550 (epoch 15.820), train_loss = 0.76152892, grad/param norm = 6.7849e-02, time/batch = 0.1795s	
3339/10550 (epoch 15.825), train_loss = 0.76869697, grad/param norm = 6.8814e-02, time/batch = 0.1799s	
3340/10550 (epoch 15.829), train_loss = 0.74252244, grad/param norm = 6.7454e-02, time/batch = 0.1807s	
3341/10550 (epoch 15.834), train_loss = 0.74131856, grad/param norm = 6.9185e-02, time/batch = 0.1809s	
3342/10550 (epoch 15.839), train_loss = 0.73940124, grad/param norm = 6.6288e-02, time/batch = 0.1795s	
3343/10550 (epoch 15.844), train_loss = 0.75322447, grad/param norm = 7.2372e-02, time/batch = 0.1798s	
3344/10550 (epoch 15.848), train_loss = 0.74436565, grad/param norm = 7.0255e-02, time/batch = 0.1794s	
3345/10550 (epoch 15.853), train_loss = 0.75457806, grad/param norm = 6.7525e-02, time/batch = 0.1799s	
3346/10550 (epoch 15.858), train_loss = 0.77703635, grad/param norm = 7.0102e-02, time/batch = 0.1808s	
3347/10550 (epoch 15.863), train_loss = 0.74260450, grad/param norm = 6.7158e-02, time/batch = 0.1805s	
3348/10550 (epoch 15.867), train_loss = 0.74803392, grad/param norm = 6.6600e-02, time/batch = 0.1794s	
3349/10550 (epoch 15.872), train_loss = 0.75215758, grad/param norm = 6.9544e-02, time/batch = 0.1806s	
3350/10550 (epoch 15.877), train_loss = 0.73511375, grad/param norm = 6.6288e-02, time/batch = 0.1804s	
3351/10550 (epoch 15.882), train_loss = 0.73467649, grad/param norm = 6.7305e-02, time/batch = 0.1814s	
3352/10550 (epoch 15.886), train_loss = 0.74775907, grad/param norm = 6.8070e-02, time/batch = 0.1797s	
3353/10550 (epoch 15.891), train_loss = 0.73443191, grad/param norm = 6.7884e-02, time/batch = 0.1796s	
3354/10550 (epoch 15.896), train_loss = 0.73545456, grad/param norm = 6.5741e-02, time/batch = 0.1795s	
3355/10550 (epoch 15.900), train_loss = 0.73001069, grad/param norm = 6.7906e-02, time/batch = 0.1802s	
3356/10550 (epoch 15.905), train_loss = 0.71865340, grad/param norm = 6.7024e-02, time/batch = 0.1802s	
3357/10550 (epoch 15.910), train_loss = 0.73691370, grad/param norm = 6.7492e-02, time/batch = 0.1802s	
3358/10550 (epoch 15.915), train_loss = 0.73693434, grad/param norm = 6.7846e-02, time/batch = 0.1798s	
3359/10550 (epoch 15.919), train_loss = 0.74209362, grad/param norm = 6.5361e-02, time/batch = 0.1803s	
3360/10550 (epoch 15.924), train_loss = 0.73788034, grad/param norm = 6.4825e-02, time/batch = 0.1804s	
3361/10550 (epoch 15.929), train_loss = 0.73988950, grad/param norm = 6.7521e-02, time/batch = 0.1808s	
3362/10550 (epoch 15.934), train_loss = 0.73164162, grad/param norm = 6.9953e-02, time/batch = 0.1796s	
3363/10550 (epoch 15.938), train_loss = 0.76704281, grad/param norm = 7.0753e-02, time/batch = 0.1795s	
3364/10550 (epoch 15.943), train_loss = 0.74963311, grad/param norm = 6.7242e-02, time/batch = 0.1800s	
3365/10550 (epoch 15.948), train_loss = 0.74355815, grad/param norm = 7.1196e-02, time/batch = 0.1798s	
3366/10550 (epoch 15.953), train_loss = 0.76409126, grad/param norm = 7.1559e-02, time/batch = 0.1802s	
3367/10550 (epoch 15.957), train_loss = 0.76557569, grad/param norm = 7.2774e-02, time/batch = 0.1799s	
3368/10550 (epoch 15.962), train_loss = 0.73660536, grad/param norm = 6.6718e-02, time/batch = 0.1799s	
3369/10550 (epoch 15.967), train_loss = 0.75998862, grad/param norm = 6.8564e-02, time/batch = 0.1803s	
3370/10550 (epoch 15.972), train_loss = 0.73730357, grad/param norm = 6.7777e-02, time/batch = 0.1800s	
3371/10550 (epoch 15.976), train_loss = 0.74206098, grad/param norm = 6.7579e-02, time/batch = 0.1808s	
3372/10550 (epoch 15.981), train_loss = 0.73905981, grad/param norm = 6.7519e-02, time/batch = 0.1793s	
3373/10550 (epoch 15.986), train_loss = 0.73308671, grad/param norm = 6.7233e-02, time/batch = 0.1798s	
3374/10550 (epoch 15.991), train_loss = 0.77764266, grad/param norm = 6.8075e-02, time/batch = 0.1800s	
3375/10550 (epoch 15.995), train_loss = 0.75091708, grad/param norm = 6.6870e-02, time/batch = 0.1801s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
3376/10550 (epoch 16.000), train_loss = 0.73700607, grad/param norm = 6.7345e-02, time/batch = 0.1802s	
3377/10550 (epoch 16.005), train_loss = 0.93684129, grad/param norm = 7.2035e-02, time/batch = 0.1803s	
3378/10550 (epoch 16.009), train_loss = 0.72875477, grad/param norm = 6.5283e-02, time/batch = 0.1799s	
3379/10550 (epoch 16.014), train_loss = 0.74315901, grad/param norm = 6.8311e-02, time/batch = 0.1801s	
3380/10550 (epoch 16.019), train_loss = 0.77945284, grad/param norm = 6.7398e-02, time/batch = 0.1802s	
3381/10550 (epoch 16.024), train_loss = 0.76418524, grad/param norm = 6.9123e-02, time/batch = 0.1812s	
3382/10550 (epoch 16.028), train_loss = 0.74199042, grad/param norm = 6.6011e-02, time/batch = 0.1800s	
3383/10550 (epoch 16.033), train_loss = 0.77321093, grad/param norm = 6.6138e-02, time/batch = 0.1796s	
3384/10550 (epoch 16.038), train_loss = 0.75217947, grad/param norm = 6.8428e-02, time/batch = 0.1797s	
3385/10550 (epoch 16.043), train_loss = 0.73225665, grad/param norm = 6.6642e-02, time/batch = 0.1801s	
3386/10550 (epoch 16.047), train_loss = 0.71777448, grad/param norm = 6.4434e-02, time/batch = 0.1801s	
3387/10550 (epoch 16.052), train_loss = 0.76365066, grad/param norm = 6.8113e-02, time/batch = 0.1797s	
3388/10550 (epoch 16.057), train_loss = 0.72915139, grad/param norm = 6.6290e-02, time/batch = 0.1797s	
3389/10550 (epoch 16.062), train_loss = 0.75220178, grad/param norm = 6.7298e-02, time/batch = 0.1798s	
3390/10550 (epoch 16.066), train_loss = 0.74040062, grad/param norm = 6.4994e-02, time/batch = 0.1808s	
3391/10550 (epoch 16.071), train_loss = 0.72115844, grad/param norm = 6.6272e-02, time/batch = 0.1815s	
3392/10550 (epoch 16.076), train_loss = 0.74496308, grad/param norm = 7.0775e-02, time/batch = 0.1783s	
3393/10550 (epoch 16.081), train_loss = 0.75831868, grad/param norm = 6.8238e-02, time/batch = 0.1791s	
3394/10550 (epoch 16.085), train_loss = 0.74044753, grad/param norm = 6.8452e-02, time/batch = 0.1793s	
3395/10550 (epoch 16.090), train_loss = 0.72537654, grad/param norm = 6.5476e-02, time/batch = 0.1794s	
3396/10550 (epoch 16.095), train_loss = 0.74534145, grad/param norm = 6.6556e-02, time/batch = 0.1789s	
3397/10550 (epoch 16.100), train_loss = 0.73904695, grad/param norm = 6.7288e-02, time/batch = 0.1786s	
3398/10550 (epoch 16.104), train_loss = 0.73059212, grad/param norm = 6.7058e-02, time/batch = 0.1786s	
3399/10550 (epoch 16.109), train_loss = 0.73929815, grad/param norm = 6.8988e-02, time/batch = 0.1795s	
3400/10550 (epoch 16.114), train_loss = 0.73842445, grad/param norm = 6.9736e-02, time/batch = 0.1792s	
3401/10550 (epoch 16.118), train_loss = 0.71301863, grad/param norm = 6.5035e-02, time/batch = 0.1812s	
3402/10550 (epoch 16.123), train_loss = 0.75932690, grad/param norm = 6.5824e-02, time/batch = 0.1789s	
3403/10550 (epoch 16.128), train_loss = 0.73777957, grad/param norm = 6.8876e-02, time/batch = 0.1792s	
3404/10550 (epoch 16.133), train_loss = 0.71562944, grad/param norm = 6.7746e-02, time/batch = 0.1796s	
3405/10550 (epoch 16.137), train_loss = 0.73388656, grad/param norm = 6.8854e-02, time/batch = 0.1794s	
3406/10550 (epoch 16.142), train_loss = 0.75088759, grad/param norm = 7.1958e-02, time/batch = 0.1792s	
3407/10550 (epoch 16.147), train_loss = 0.73110435, grad/param norm = 6.6683e-02, time/batch = 0.1791s	
3408/10550 (epoch 16.152), train_loss = 0.75008848, grad/param norm = 6.8909e-02, time/batch = 0.1783s	
3409/10550 (epoch 16.156), train_loss = 0.73797751, grad/param norm = 6.5552e-02, time/batch = 0.1796s	
3410/10550 (epoch 16.161), train_loss = 0.73064277, grad/param norm = 6.7122e-02, time/batch = 0.1795s	
3411/10550 (epoch 16.166), train_loss = 0.74822652, grad/param norm = 6.5743e-02, time/batch = 0.1808s	
3412/10550 (epoch 16.171), train_loss = 0.72448208, grad/param norm = 6.5859e-02, time/batch = 0.1790s	
3413/10550 (epoch 16.175), train_loss = 0.73920114, grad/param norm = 7.0571e-02, time/batch = 0.1788s	
3414/10550 (epoch 16.180), train_loss = 0.71753902, grad/param norm = 6.5995e-02, time/batch = 0.1795s	
3415/10550 (epoch 16.185), train_loss = 0.75658309, grad/param norm = 6.8459e-02, time/batch = 0.1793s	
3416/10550 (epoch 16.190), train_loss = 0.72228695, grad/param norm = 7.2529e-02, time/batch = 0.1793s	
3417/10550 (epoch 16.194), train_loss = 0.73201823, grad/param norm = 7.0020e-02, time/batch = 0.1795s	
3418/10550 (epoch 16.199), train_loss = 0.75860987, grad/param norm = 7.2920e-02, time/batch = 0.1785s	
3419/10550 (epoch 16.204), train_loss = 0.73316744, grad/param norm = 7.4031e-02, time/batch = 0.1790s	
3420/10550 (epoch 16.209), train_loss = 0.75473649, grad/param norm = 7.1228e-02, time/batch = 0.1791s	
3421/10550 (epoch 16.213), train_loss = 0.75867156, grad/param norm = 6.9192e-02, time/batch = 0.1809s	
3422/10550 (epoch 16.218), train_loss = 0.74769114, grad/param norm = 6.7571e-02, time/batch = 0.1791s	
3423/10550 (epoch 16.223), train_loss = 0.73070887, grad/param norm = 6.6380e-02, time/batch = 0.1794s	
3424/10550 (epoch 16.227), train_loss = 0.71114325, grad/param norm = 6.5726e-02, time/batch = 0.1797s	
3425/10550 (epoch 16.232), train_loss = 0.72971962, grad/param norm = 7.0925e-02, time/batch = 0.1791s	
3426/10550 (epoch 16.237), train_loss = 0.72833889, grad/param norm = 6.6500e-02, time/batch = 0.1793s	
3427/10550 (epoch 16.242), train_loss = 0.73062978, grad/param norm = 6.9531e-02, time/batch = 0.1796s	
3428/10550 (epoch 16.246), train_loss = 0.72115158, grad/param norm = 6.6216e-02, time/batch = 0.1785s	
3429/10550 (epoch 16.251), train_loss = 0.72822617, grad/param norm = 6.5912e-02, time/batch = 0.1788s	
3430/10550 (epoch 16.256), train_loss = 0.75040292, grad/param norm = 6.8888e-02, time/batch = 0.1793s	
3431/10550 (epoch 16.261), train_loss = 0.73117555, grad/param norm = 6.7655e-02, time/batch = 0.1812s	
3432/10550 (epoch 16.265), train_loss = 0.71064113, grad/param norm = 6.8399e-02, time/batch = 0.1789s	
3433/10550 (epoch 16.270), train_loss = 0.72935429, grad/param norm = 6.7381e-02, time/batch = 0.1795s	
3434/10550 (epoch 16.275), train_loss = 0.73560711, grad/param norm = 6.5833e-02, time/batch = 0.1795s	
3435/10550 (epoch 16.280), train_loss = 0.73211947, grad/param norm = 6.8471e-02, time/batch = 0.1793s	
3436/10550 (epoch 16.284), train_loss = 0.72373770, grad/param norm = 6.6726e-02, time/batch = 0.1790s	
3437/10550 (epoch 16.289), train_loss = 0.71458398, grad/param norm = 6.7768e-02, time/batch = 0.1793s	
3438/10550 (epoch 16.294), train_loss = 0.72692435, grad/param norm = 6.9768e-02, time/batch = 0.1790s	
3439/10550 (epoch 16.299), train_loss = 0.70311724, grad/param norm = 6.4479e-02, time/batch = 0.1794s	
3440/10550 (epoch 16.303), train_loss = 0.74226228, grad/param norm = 6.7892e-02, time/batch = 0.1795s	
3441/10550 (epoch 16.308), train_loss = 0.70837419, grad/param norm = 6.5277e-02, time/batch = 0.1813s	
3442/10550 (epoch 16.313), train_loss = 0.71914329, grad/param norm = 6.6817e-02, time/batch = 0.1782s	
3443/10550 (epoch 16.318), train_loss = 0.71886345, grad/param norm = 6.6842e-02, time/batch = 0.1791s	
3444/10550 (epoch 16.322), train_loss = 0.72156586, grad/param norm = 6.6768e-02, time/batch = 0.1792s	
3445/10550 (epoch 16.327), train_loss = 0.71860282, grad/param norm = 6.7027e-02, time/batch = 0.1795s	
3446/10550 (epoch 16.332), train_loss = 0.74452845, grad/param norm = 7.1257e-02, time/batch = 0.1792s	
3447/10550 (epoch 16.336), train_loss = 0.72875010, grad/param norm = 7.3321e-02, time/batch = 0.1793s	
3448/10550 (epoch 16.341), train_loss = 0.70791236, grad/param norm = 6.9383e-02, time/batch = 0.1787s	
3449/10550 (epoch 16.346), train_loss = 0.74565459, grad/param norm = 7.3409e-02, time/batch = 0.1789s	
3450/10550 (epoch 16.351), train_loss = 0.74658007, grad/param norm = 7.1612e-02, time/batch = 0.1782s	
3451/10550 (epoch 16.355), train_loss = 0.71926215, grad/param norm = 6.5791e-02, time/batch = 0.1806s	
3452/10550 (epoch 16.360), train_loss = 0.75191183, grad/param norm = 6.9495e-02, time/batch = 0.1786s	
3453/10550 (epoch 16.365), train_loss = 0.73136777, grad/param norm = 6.7494e-02, time/batch = 0.1788s	
3454/10550 (epoch 16.370), train_loss = 0.72036882, grad/param norm = 6.8576e-02, time/batch = 0.1791s	
3455/10550 (epoch 16.374), train_loss = 0.72763196, grad/param norm = 6.8563e-02, time/batch = 0.1788s	
3456/10550 (epoch 16.379), train_loss = 0.73741825, grad/param norm = 6.8894e-02, time/batch = 0.1788s	
3457/10550 (epoch 16.384), train_loss = 0.72696276, grad/param norm = 6.8861e-02, time/batch = 0.1783s	
3458/10550 (epoch 16.389), train_loss = 0.71971101, grad/param norm = 6.8939e-02, time/batch = 0.1784s	
3459/10550 (epoch 16.393), train_loss = 0.71214428, grad/param norm = 6.6159e-02, time/batch = 0.1790s	
3460/10550 (epoch 16.398), train_loss = 0.70563006, grad/param norm = 6.6379e-02, time/batch = 0.1785s	
3461/10550 (epoch 16.403), train_loss = 0.73282396, grad/param norm = 7.0088e-02, time/batch = 0.1803s	
3462/10550 (epoch 16.408), train_loss = 0.74018209, grad/param norm = 7.0154e-02, time/batch = 0.1786s	
3463/10550 (epoch 16.412), train_loss = 0.73346253, grad/param norm = 6.8291e-02, time/batch = 0.1790s	
3464/10550 (epoch 16.417), train_loss = 0.71604458, grad/param norm = 6.4765e-02, time/batch = 0.1787s	
3465/10550 (epoch 16.422), train_loss = 0.71896238, grad/param norm = 6.9369e-02, time/batch = 0.1788s	
3466/10550 (epoch 16.427), train_loss = 0.73540389, grad/param norm = 6.9785e-02, time/batch = 0.1787s	
3467/10550 (epoch 16.431), train_loss = 0.73742660, grad/param norm = 6.8280e-02, time/batch = 0.1790s	
3468/10550 (epoch 16.436), train_loss = 0.71198622, grad/param norm = 6.6747e-02, time/batch = 0.1780s	
3469/10550 (epoch 16.441), train_loss = 0.73674798, grad/param norm = 6.9872e-02, time/batch = 0.1789s	
3470/10550 (epoch 16.445), train_loss = 0.74666859, grad/param norm = 7.0994e-02, time/batch = 0.1789s	
3471/10550 (epoch 16.450), train_loss = 0.73121639, grad/param norm = 6.9672e-02, time/batch = 0.1801s	
3472/10550 (epoch 16.455), train_loss = 0.72220101, grad/param norm = 7.0875e-02, time/batch = 0.1787s	
3473/10550 (epoch 16.460), train_loss = 0.70671589, grad/param norm = 6.8761e-02, time/batch = 0.1788s	
3474/10550 (epoch 16.464), train_loss = 0.71699852, grad/param norm = 6.7153e-02, time/batch = 0.1790s	
3475/10550 (epoch 16.469), train_loss = 0.72690385, grad/param norm = 6.7013e-02, time/batch = 0.1786s	
3476/10550 (epoch 16.474), train_loss = 0.72566268, grad/param norm = 6.7743e-02, time/batch = 0.1785s	
3477/10550 (epoch 16.479), train_loss = 0.70215180, grad/param norm = 6.7018e-02, time/batch = 0.1793s	
3478/10550 (epoch 16.483), train_loss = 0.71122333, grad/param norm = 6.8257e-02, time/batch = 0.1781s	
3479/10550 (epoch 16.488), train_loss = 0.72889414, grad/param norm = 6.8124e-02, time/batch = 0.1787s	
3480/10550 (epoch 16.493), train_loss = 0.70986395, grad/param norm = 6.9243e-02, time/batch = 0.1786s	
3481/10550 (epoch 16.498), train_loss = 0.71981786, grad/param norm = 6.6720e-02, time/batch = 0.1806s	
3482/10550 (epoch 16.502), train_loss = 0.72101418, grad/param norm = 6.6792e-02, time/batch = 0.1783s	
3483/10550 (epoch 16.507), train_loss = 0.71553155, grad/param norm = 6.7594e-02, time/batch = 0.1788s	
3484/10550 (epoch 16.512), train_loss = 0.69043788, grad/param norm = 6.7152e-02, time/batch = 0.1789s	
3485/10550 (epoch 16.517), train_loss = 0.71926101, grad/param norm = 6.8131e-02, time/batch = 0.1785s	
3486/10550 (epoch 16.521), train_loss = 0.70776954, grad/param norm = 7.0842e-02, time/batch = 0.1787s	
3487/10550 (epoch 16.526), train_loss = 0.67164339, grad/param norm = 6.6621e-02, time/batch = 0.1787s	
3488/10550 (epoch 16.531), train_loss = 0.67777667, grad/param norm = 6.6401e-02, time/batch = 0.1786s	
3489/10550 (epoch 16.536), train_loss = 0.74766782, grad/param norm = 6.9963e-02, time/batch = 0.1792s	
3490/10550 (epoch 16.540), train_loss = 0.72834518, grad/param norm = 6.9075e-02, time/batch = 0.1784s	
3491/10550 (epoch 16.545), train_loss = 0.71688677, grad/param norm = 6.9098e-02, time/batch = 0.1808s	
3492/10550 (epoch 16.550), train_loss = 0.72557503, grad/param norm = 6.8311e-02, time/batch = 0.1783s	
3493/10550 (epoch 16.555), train_loss = 0.71664280, grad/param norm = 6.8150e-02, time/batch = 0.1789s	
3494/10550 (epoch 16.559), train_loss = 0.72005032, grad/param norm = 6.7353e-02, time/batch = 0.1791s	
3495/10550 (epoch 16.564), train_loss = 0.68714373, grad/param norm = 6.6051e-02, time/batch = 0.1789s	
3496/10550 (epoch 16.569), train_loss = 0.70677379, grad/param norm = 6.9409e-02, time/batch = 0.1788s	
3497/10550 (epoch 16.573), train_loss = 0.73658874, grad/param norm = 6.9831e-02, time/batch = 0.1787s	
3498/10550 (epoch 16.578), train_loss = 0.71145851, grad/param norm = 6.7506e-02, time/batch = 0.1780s	
3499/10550 (epoch 16.583), train_loss = 0.70952175, grad/param norm = 6.9129e-02, time/batch = 0.1789s	
3500/10550 (epoch 16.588), train_loss = 0.69473971, grad/param norm = 7.0646e-02, time/batch = 0.1786s	
3501/10550 (epoch 16.592), train_loss = 0.72021018, grad/param norm = 6.9861e-02, time/batch = 0.1803s	
3502/10550 (epoch 16.597), train_loss = 0.71619497, grad/param norm = 6.8741e-02, time/batch = 0.1785s	
3503/10550 (epoch 16.602), train_loss = 0.72915883, grad/param norm = 6.9682e-02, time/batch = 0.1782s	
3504/10550 (epoch 16.607), train_loss = 0.70912822, grad/param norm = 6.8584e-02, time/batch = 0.1787s	
3505/10550 (epoch 16.611), train_loss = 0.70501556, grad/param norm = 7.1645e-02, time/batch = 0.1786s	
3506/10550 (epoch 16.616), train_loss = 0.71879180, grad/param norm = 7.1066e-02, time/batch = 0.1791s	
3507/10550 (epoch 16.621), train_loss = 0.71073302, grad/param norm = 6.8487e-02, time/batch = 0.1789s	
3508/10550 (epoch 16.626), train_loss = 0.71877157, grad/param norm = 7.2773e-02, time/batch = 0.1788s	
3509/10550 (epoch 16.630), train_loss = 0.72305646, grad/param norm = 7.0174e-02, time/batch = 0.1787s	
3510/10550 (epoch 16.635), train_loss = 0.73396060, grad/param norm = 7.0221e-02, time/batch = 0.1790s	
3511/10550 (epoch 16.640), train_loss = 0.73034230, grad/param norm = 6.5944e-02, time/batch = 0.1802s	
3512/10550 (epoch 16.645), train_loss = 0.72245068, grad/param norm = 7.0928e-02, time/batch = 0.1785s	
3513/10550 (epoch 16.649), train_loss = 0.72417908, grad/param norm = 6.8350e-02, time/batch = 0.1789s	
3514/10550 (epoch 16.654), train_loss = 0.72735090, grad/param norm = 6.9304e-02, time/batch = 0.1794s	
3515/10550 (epoch 16.659), train_loss = 0.72012630, grad/param norm = 6.8449e-02, time/batch = 0.1790s	
3516/10550 (epoch 16.664), train_loss = 0.72872554, grad/param norm = 6.7946e-02, time/batch = 0.1782s	
3517/10550 (epoch 16.668), train_loss = 0.69010605, grad/param norm = 6.9075e-02, time/batch = 0.1787s	
3518/10550 (epoch 16.673), train_loss = 0.71109420, grad/param norm = 6.9143e-02, time/batch = 0.1780s	
3519/10550 (epoch 16.678), train_loss = 0.69949130, grad/param norm = 6.7601e-02, time/batch = 0.1787s	
3520/10550 (epoch 16.682), train_loss = 0.70859544, grad/param norm = 7.0305e-02, time/batch = 0.1782s	
3521/10550 (epoch 16.687), train_loss = 0.69060241, grad/param norm = 6.8148e-02, time/batch = 0.1802s	
3522/10550 (epoch 16.692), train_loss = 0.71340392, grad/param norm = 6.6892e-02, time/batch = 0.1785s	
3523/10550 (epoch 16.697), train_loss = 0.69714683, grad/param norm = 6.8350e-02, time/batch = 0.1790s	
3524/10550 (epoch 16.701), train_loss = 0.70904451, grad/param norm = 6.8204e-02, time/batch = 0.1794s	
3525/10550 (epoch 16.706), train_loss = 0.69165518, grad/param norm = 6.7205e-02, time/batch = 0.1791s	
3526/10550 (epoch 16.711), train_loss = 0.73632015, grad/param norm = 6.9918e-02, time/batch = 0.1788s	
3527/10550 (epoch 16.716), train_loss = 0.70319614, grad/param norm = 6.8210e-02, time/batch = 0.1786s	
3528/10550 (epoch 16.720), train_loss = 0.71960069, grad/param norm = 6.8201e-02, time/batch = 0.1785s	
3529/10550 (epoch 16.725), train_loss = 0.68925254, grad/param norm = 6.7903e-02, time/batch = 0.1790s	
3530/10550 (epoch 16.730), train_loss = 0.68150479, grad/param norm = 6.7050e-02, time/batch = 0.1790s	
3531/10550 (epoch 16.735), train_loss = 0.70730561, grad/param norm = 6.7278e-02, time/batch = 0.1804s	
3532/10550 (epoch 16.739), train_loss = 0.69870719, grad/param norm = 6.7554e-02, time/batch = 0.1780s	
3533/10550 (epoch 16.744), train_loss = 0.69942470, grad/param norm = 6.8565e-02, time/batch = 0.1785s	
3534/10550 (epoch 16.749), train_loss = 0.72659684, grad/param norm = 7.0041e-02, time/batch = 0.1789s	
3535/10550 (epoch 16.754), train_loss = 0.72937235, grad/param norm = 6.7774e-02, time/batch = 0.1789s	
3536/10550 (epoch 16.758), train_loss = 0.69863397, grad/param norm = 7.0305e-02, time/batch = 0.1787s	
3537/10550 (epoch 16.763), train_loss = 0.67532875, grad/param norm = 6.6143e-02, time/batch = 0.1787s	
3538/10550 (epoch 16.768), train_loss = 0.70668676, grad/param norm = 6.8162e-02, time/batch = 0.1783s	
3539/10550 (epoch 16.773), train_loss = 0.73728338, grad/param norm = 7.5129e-02, time/batch = 0.1786s	
3540/10550 (epoch 16.777), train_loss = 0.71338045, grad/param norm = 6.5731e-02, time/batch = 0.1785s	
3541/10550 (epoch 16.782), train_loss = 0.73740589, grad/param norm = 6.9479e-02, time/batch = 0.1808s	
3542/10550 (epoch 16.787), train_loss = 0.70930610, grad/param norm = 7.1247e-02, time/batch = 0.1787s	
3543/10550 (epoch 16.791), train_loss = 0.69419759, grad/param norm = 7.0486e-02, time/batch = 0.1782s	
3544/10550 (epoch 16.796), train_loss = 0.73029734, grad/param norm = 6.7368e-02, time/batch = 0.1786s	
3545/10550 (epoch 16.801), train_loss = 0.70717332, grad/param norm = 7.0944e-02, time/batch = 0.1790s	
3546/10550 (epoch 16.806), train_loss = 0.70915685, grad/param norm = 6.8566e-02, time/batch = 0.1787s	
3547/10550 (epoch 16.810), train_loss = 0.73450826, grad/param norm = 7.2462e-02, time/batch = 0.1788s	
3548/10550 (epoch 16.815), train_loss = 0.71985079, grad/param norm = 7.2333e-02, time/batch = 0.1784s	
3549/10550 (epoch 16.820), train_loss = 0.72608495, grad/param norm = 7.0089e-02, time/batch = 0.1790s	
3550/10550 (epoch 16.825), train_loss = 0.71997698, grad/param norm = 6.9554e-02, time/batch = 0.1786s	
3551/10550 (epoch 16.829), train_loss = 0.70473739, grad/param norm = 6.9761e-02, time/batch = 0.1802s	
3552/10550 (epoch 16.834), train_loss = 0.70491276, grad/param norm = 6.9285e-02, time/batch = 0.1790s	
3553/10550 (epoch 16.839), train_loss = 0.70580453, grad/param norm = 6.7954e-02, time/batch = 0.1785s	
3554/10550 (epoch 16.844), train_loss = 0.71553675, grad/param norm = 6.9122e-02, time/batch = 0.1785s	
3555/10550 (epoch 16.848), train_loss = 0.71177255, grad/param norm = 7.1475e-02, time/batch = 0.1792s	
3556/10550 (epoch 16.853), train_loss = 0.73340414, grad/param norm = 7.4334e-02, time/batch = 0.1782s	
3557/10550 (epoch 16.858), train_loss = 0.73757218, grad/param norm = 7.2188e-02, time/batch = 0.1787s	
3558/10550 (epoch 16.863), train_loss = 0.70041592, grad/param norm = 6.7598e-02, time/batch = 0.1781s	
3559/10550 (epoch 16.867), train_loss = 0.71365575, grad/param norm = 6.9543e-02, time/batch = 0.1787s	
3560/10550 (epoch 16.872), train_loss = 0.70892401, grad/param norm = 6.7519e-02, time/batch = 0.1790s	
3561/10550 (epoch 16.877), train_loss = 0.69699310, grad/param norm = 6.6802e-02, time/batch = 0.1802s	
3562/10550 (epoch 16.882), train_loss = 0.70696425, grad/param norm = 6.8627e-02, time/batch = 0.1785s	
3563/10550 (epoch 16.886), train_loss = 0.71124339, grad/param norm = 6.8757e-02, time/batch = 0.1791s	
3564/10550 (epoch 16.891), train_loss = 0.69991726, grad/param norm = 7.0242e-02, time/batch = 0.1783s	
3565/10550 (epoch 16.896), train_loss = 0.70024815, grad/param norm = 6.6603e-02, time/batch = 0.1791s	
3566/10550 (epoch 16.900), train_loss = 0.69143895, grad/param norm = 6.7431e-02, time/batch = 0.1786s	
3567/10550 (epoch 16.905), train_loss = 0.68336013, grad/param norm = 6.8255e-02, time/batch = 0.1786s	
3568/10550 (epoch 16.910), train_loss = 0.69856517, grad/param norm = 7.3174e-02, time/batch = 0.1781s	
3569/10550 (epoch 16.915), train_loss = 0.70129335, grad/param norm = 6.8406e-02, time/batch = 0.1791s	
3570/10550 (epoch 16.919), train_loss = 0.70918831, grad/param norm = 6.9658e-02, time/batch = 0.1786s	
3571/10550 (epoch 16.924), train_loss = 0.70912016, grad/param norm = 6.9227e-02, time/batch = 0.1803s	
3572/10550 (epoch 16.929), train_loss = 0.70734365, grad/param norm = 6.9050e-02, time/batch = 0.1785s	
3573/10550 (epoch 16.934), train_loss = 0.70470283, grad/param norm = 7.2129e-02, time/batch = 0.1783s	
3574/10550 (epoch 16.938), train_loss = 0.71868859, grad/param norm = 7.0792e-02, time/batch = 0.1790s	
3575/10550 (epoch 16.943), train_loss = 0.71089362, grad/param norm = 6.9838e-02, time/batch = 0.1792s	
3576/10550 (epoch 16.948), train_loss = 0.72017305, grad/param norm = 7.1270e-02, time/batch = 0.1787s	
3577/10550 (epoch 16.953), train_loss = 0.72375078, grad/param norm = 7.0678e-02, time/batch = 0.1783s	
3578/10550 (epoch 16.957), train_loss = 0.73111291, grad/param norm = 7.4373e-02, time/batch = 0.1780s	
3579/10550 (epoch 16.962), train_loss = 0.71985180, grad/param norm = 7.1712e-02, time/batch = 0.1788s	
3580/10550 (epoch 16.967), train_loss = 0.72701170, grad/param norm = 6.7874e-02, time/batch = 0.1785s	
3581/10550 (epoch 16.972), train_loss = 0.70087077, grad/param norm = 6.8041e-02, time/batch = 0.1808s	
3582/10550 (epoch 16.976), train_loss = 0.69235981, grad/param norm = 6.8104e-02, time/batch = 0.1785s	
3583/10550 (epoch 16.981), train_loss = 0.71022739, grad/param norm = 6.8930e-02, time/batch = 0.1786s	
3584/10550 (epoch 16.986), train_loss = 0.70186996, grad/param norm = 6.8990e-02, time/batch = 0.1786s	
3585/10550 (epoch 16.991), train_loss = 0.74423156, grad/param norm = 7.2789e-02, time/batch = 0.1787s	
3586/10550 (epoch 16.995), train_loss = 0.70647018, grad/param norm = 6.7027e-02, time/batch = 0.1786s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
3587/10550 (epoch 17.000), train_loss = 0.71427430, grad/param norm = 6.8338e-02, time/batch = 0.1786s	
3588/10550 (epoch 17.005), train_loss = 0.90192696, grad/param norm = 7.3521e-02, time/batch = 0.1782s	
3589/10550 (epoch 17.009), train_loss = 0.69995844, grad/param norm = 6.9292e-02, time/batch = 0.1793s	
3590/10550 (epoch 17.014), train_loss = 0.71406481, grad/param norm = 6.8789e-02, time/batch = 0.1790s	
3591/10550 (epoch 17.019), train_loss = 0.74498271, grad/param norm = 6.9814e-02, time/batch = 0.1802s	
3592/10550 (epoch 17.024), train_loss = 0.73631110, grad/param norm = 7.2159e-02, time/batch = 0.1787s	
3593/10550 (epoch 17.028), train_loss = 0.71524701, grad/param norm = 7.0293e-02, time/batch = 0.1783s	
3594/10550 (epoch 17.033), train_loss = 0.73808986, grad/param norm = 6.8687e-02, time/batch = 0.1790s	
3595/10550 (epoch 17.038), train_loss = 0.71681298, grad/param norm = 6.9860e-02, time/batch = 0.1790s	
3596/10550 (epoch 17.043), train_loss = 0.69663371, grad/param norm = 6.7330e-02, time/batch = 0.1790s	
3597/10550 (epoch 17.047), train_loss = 0.68694427, grad/param norm = 6.6066e-02, time/batch = 0.1785s	
3598/10550 (epoch 17.052), train_loss = 0.72930124, grad/param norm = 6.9223e-02, time/batch = 0.1781s	
3599/10550 (epoch 17.057), train_loss = 0.70052783, grad/param norm = 6.7333e-02, time/batch = 0.1788s	
3600/10550 (epoch 17.062), train_loss = 0.72255191, grad/param norm = 7.0314e-02, time/batch = 0.1789s	
3601/10550 (epoch 17.066), train_loss = 0.70059995, grad/param norm = 6.6410e-02, time/batch = 0.1803s	
3602/10550 (epoch 17.071), train_loss = 0.68172413, grad/param norm = 7.0171e-02, time/batch = 0.1780s	
3603/10550 (epoch 17.076), train_loss = 0.71530369, grad/param norm = 7.1343e-02, time/batch = 0.1789s	
3604/10550 (epoch 17.081), train_loss = 0.72293503, grad/param norm = 7.2850e-02, time/batch = 0.1792s	
3605/10550 (epoch 17.085), train_loss = 0.71158716, grad/param norm = 7.0296e-02, time/batch = 0.1786s	
3606/10550 (epoch 17.090), train_loss = 0.70051737, grad/param norm = 7.1409e-02, time/batch = 0.1787s	
3607/10550 (epoch 17.095), train_loss = 0.71701224, grad/param norm = 6.9878e-02, time/batch = 0.1780s	
3608/10550 (epoch 17.100), train_loss = 0.70468997, grad/param norm = 6.8986e-02, time/batch = 0.1780s	
3609/10550 (epoch 17.104), train_loss = 0.69741653, grad/param norm = 6.8220e-02, time/batch = 0.1789s	
3610/10550 (epoch 17.109), train_loss = 0.70135667, grad/param norm = 6.9373e-02, time/batch = 0.1789s	
3611/10550 (epoch 17.114), train_loss = 0.70779540, grad/param norm = 6.9721e-02, time/batch = 0.1808s	
3612/10550 (epoch 17.118), train_loss = 0.67169239, grad/param norm = 6.6544e-02, time/batch = 0.1788s	
3613/10550 (epoch 17.123), train_loss = 0.72743130, grad/param norm = 6.9631e-02, time/batch = 0.1786s	
3614/10550 (epoch 17.128), train_loss = 0.70610427, grad/param norm = 6.9028e-02, time/batch = 0.1789s	
3615/10550 (epoch 17.133), train_loss = 0.68529240, grad/param norm = 7.1342e-02, time/batch = 0.1790s	
3616/10550 (epoch 17.137), train_loss = 0.69968130, grad/param norm = 7.1694e-02, time/batch = 0.1786s	
3617/10550 (epoch 17.142), train_loss = 0.71331575, grad/param norm = 7.2764e-02, time/batch = 0.1789s	
3618/10550 (epoch 17.147), train_loss = 0.69511020, grad/param norm = 6.7517e-02, time/batch = 0.1785s	
3619/10550 (epoch 17.152), train_loss = 0.71864404, grad/param norm = 7.2196e-02, time/batch = 0.1791s	
3620/10550 (epoch 17.156), train_loss = 0.70446626, grad/param norm = 6.8663e-02, time/batch = 0.1787s	
3621/10550 (epoch 17.161), train_loss = 0.70115167, grad/param norm = 7.0313e-02, time/batch = 0.1804s	
3622/10550 (epoch 17.166), train_loss = 0.71502207, grad/param norm = 7.1335e-02, time/batch = 0.1781s	
3623/10550 (epoch 17.171), train_loss = 0.68456994, grad/param norm = 6.9252e-02, time/batch = 0.1784s	
3624/10550 (epoch 17.175), train_loss = 0.69709478, grad/param norm = 6.8626e-02, time/batch = 0.1796s	
3625/10550 (epoch 17.180), train_loss = 0.70029545, grad/param norm = 7.2841e-02, time/batch = 0.1789s	
3626/10550 (epoch 17.185), train_loss = 0.72310233, grad/param norm = 7.0156e-02, time/batch = 0.1784s	
3627/10550 (epoch 17.190), train_loss = 0.68288779, grad/param norm = 7.2322e-02, time/batch = 0.1791s	
3628/10550 (epoch 17.194), train_loss = 0.71250671, grad/param norm = 7.5378e-02, time/batch = 0.1783s	
3629/10550 (epoch 17.199), train_loss = 0.71831864, grad/param norm = 6.8415e-02, time/batch = 0.1789s	
3630/10550 (epoch 17.204), train_loss = 0.69677699, grad/param norm = 7.1061e-02, time/batch = 0.1786s	
3631/10550 (epoch 17.209), train_loss = 0.72768629, grad/param norm = 7.5183e-02, time/batch = 0.1806s	
3632/10550 (epoch 17.213), train_loss = 0.72490055, grad/param norm = 6.9585e-02, time/batch = 0.1784s	
3633/10550 (epoch 17.218), train_loss = 0.70344072, grad/param norm = 6.7499e-02, time/batch = 0.1787s	
3634/10550 (epoch 17.223), train_loss = 0.69431697, grad/param norm = 6.8670e-02, time/batch = 0.1791s	
3635/10550 (epoch 17.227), train_loss = 0.68141297, grad/param norm = 6.8279e-02, time/batch = 0.1790s	
3636/10550 (epoch 17.232), train_loss = 0.68795018, grad/param norm = 6.8423e-02, time/batch = 0.1787s	
3637/10550 (epoch 17.237), train_loss = 0.69366373, grad/param norm = 6.4856e-02, time/batch = 0.1788s	
3638/10550 (epoch 17.242), train_loss = 0.69073725, grad/param norm = 7.0600e-02, time/batch = 0.1785s	
3639/10550 (epoch 17.246), train_loss = 0.68189537, grad/param norm = 6.8152e-02, time/batch = 0.1792s	
3640/10550 (epoch 17.251), train_loss = 0.70944961, grad/param norm = 6.9558e-02, time/batch = 0.1791s	
3641/10550 (epoch 17.256), train_loss = 0.70813104, grad/param norm = 6.6501e-02, time/batch = 0.1808s	
3642/10550 (epoch 17.261), train_loss = 0.68468409, grad/param norm = 6.6395e-02, time/batch = 0.1785s	
3643/10550 (epoch 17.265), train_loss = 0.67239492, grad/param norm = 6.8986e-02, time/batch = 0.1791s	
3644/10550 (epoch 17.270), train_loss = 0.69845543, grad/param norm = 6.8822e-02, time/batch = 0.1789s	
3645/10550 (epoch 17.275), train_loss = 0.69453149, grad/param norm = 6.7040e-02, time/batch = 0.1786s	
3646/10550 (epoch 17.280), train_loss = 0.69474833, grad/param norm = 6.9992e-02, time/batch = 0.1788s	
3647/10550 (epoch 17.284), train_loss = 0.68116824, grad/param norm = 6.6868e-02, time/batch = 0.1787s	
3648/10550 (epoch 17.289), train_loss = 0.68872084, grad/param norm = 7.0215e-02, time/batch = 0.1787s	
3649/10550 (epoch 17.294), train_loss = 0.68258146, grad/param norm = 7.1104e-02, time/batch = 0.1792s	
3650/10550 (epoch 17.299), train_loss = 0.67874789, grad/param norm = 6.8477e-02, time/batch = 0.1789s	
3651/10550 (epoch 17.303), train_loss = 0.71338027, grad/param norm = 6.9428e-02, time/batch = 0.1807s	
3652/10550 (epoch 17.308), train_loss = 0.67630306, grad/param norm = 6.6814e-02, time/batch = 0.1784s	
3653/10550 (epoch 17.313), train_loss = 0.67456707, grad/param norm = 6.6777e-02, time/batch = 0.1788s	
3654/10550 (epoch 17.318), train_loss = 0.68887488, grad/param norm = 6.8753e-02, time/batch = 0.1788s	
3655/10550 (epoch 17.322), train_loss = 0.69529256, grad/param norm = 7.0425e-02, time/batch = 0.1787s	
3656/10550 (epoch 17.327), train_loss = 0.69435648, grad/param norm = 7.1626e-02, time/batch = 0.1787s	
3657/10550 (epoch 17.332), train_loss = 0.70035264, grad/param norm = 7.1981e-02, time/batch = 0.1788s	
3658/10550 (epoch 17.336), train_loss = 0.68324875, grad/param norm = 6.9283e-02, time/batch = 0.1786s	
3659/10550 (epoch 17.341), train_loss = 0.66852918, grad/param norm = 7.1371e-02, time/batch = 0.1785s	
3660/10550 (epoch 17.346), train_loss = 0.70610669, grad/param norm = 7.3803e-02, time/batch = 0.1788s	
3661/10550 (epoch 17.351), train_loss = 0.70280782, grad/param norm = 7.1912e-02, time/batch = 0.1802s	
3662/10550 (epoch 17.355), train_loss = 0.68508376, grad/param norm = 6.8583e-02, time/batch = 0.1786s	
3663/10550 (epoch 17.360), train_loss = 0.71850840, grad/param norm = 7.3203e-02, time/batch = 0.1785s	
3664/10550 (epoch 17.365), train_loss = 0.69389178, grad/param norm = 6.8458e-02, time/batch = 0.1789s	
3665/10550 (epoch 17.370), train_loss = 0.69698003, grad/param norm = 7.4394e-02, time/batch = 0.1785s	
3666/10550 (epoch 17.374), train_loss = 0.69714328, grad/param norm = 7.2414e-02, time/batch = 0.1788s	
3667/10550 (epoch 17.379), train_loss = 0.70612676, grad/param norm = 7.3897e-02, time/batch = 0.1787s	
3668/10550 (epoch 17.384), train_loss = 0.69168694, grad/param norm = 6.9140e-02, time/batch = 0.1779s	
3669/10550 (epoch 17.389), train_loss = 0.68671640, grad/param norm = 7.1994e-02, time/batch = 0.1789s	
3670/10550 (epoch 17.393), train_loss = 0.67796437, grad/param norm = 6.8417e-02, time/batch = 0.1785s	
3671/10550 (epoch 17.398), train_loss = 0.67653561, grad/param norm = 6.8479e-02, time/batch = 0.1803s	
3672/10550 (epoch 17.403), train_loss = 0.69031845, grad/param norm = 7.0966e-02, time/batch = 0.1785s	
3673/10550 (epoch 17.408), train_loss = 0.70591561, grad/param norm = 7.4965e-02, time/batch = 0.1791s	
3674/10550 (epoch 17.412), train_loss = 0.69110542, grad/param norm = 6.8400e-02, time/batch = 0.1791s	
3675/10550 (epoch 17.417), train_loss = 0.68859495, grad/param norm = 7.0493e-02, time/batch = 0.1787s	
3676/10550 (epoch 17.422), train_loss = 0.68690844, grad/param norm = 6.9979e-02, time/batch = 0.1785s	
3677/10550 (epoch 17.427), train_loss = 0.70805686, grad/param norm = 7.3040e-02, time/batch = 0.1792s	
3678/10550 (epoch 17.431), train_loss = 0.70338673, grad/param norm = 7.0530e-02, time/batch = 0.1787s	
3679/10550 (epoch 17.436), train_loss = 0.68296065, grad/param norm = 6.8349e-02, time/batch = 0.1790s	
3680/10550 (epoch 17.441), train_loss = 0.69461011, grad/param norm = 7.0406e-02, time/batch = 0.1792s	
3681/10550 (epoch 17.445), train_loss = 0.69752156, grad/param norm = 6.9529e-02, time/batch = 0.1803s	
3682/10550 (epoch 17.450), train_loss = 0.69866717, grad/param norm = 7.1204e-02, time/batch = 0.1787s	
3683/10550 (epoch 17.455), train_loss = 0.68917335, grad/param norm = 7.2315e-02, time/batch = 0.1789s	
3684/10550 (epoch 17.460), train_loss = 0.66693457, grad/param norm = 6.8509e-02, time/batch = 0.1788s	
3685/10550 (epoch 17.464), train_loss = 0.70017446, grad/param norm = 7.5123e-02, time/batch = 0.1788s	
3686/10550 (epoch 17.469), train_loss = 0.69109713, grad/param norm = 7.1964e-02, time/batch = 0.1788s	
3687/10550 (epoch 17.474), train_loss = 0.69845593, grad/param norm = 7.3441e-02, time/batch = 0.1784s	
3688/10550 (epoch 17.479), train_loss = 0.65857185, grad/param norm = 6.7038e-02, time/batch = 0.1786s	
3689/10550 (epoch 17.483), train_loss = 0.67947840, grad/param norm = 7.0420e-02, time/batch = 0.1789s	
3690/10550 (epoch 17.488), train_loss = 0.68678392, grad/param norm = 7.0350e-02, time/batch = 0.1789s	
3691/10550 (epoch 17.493), train_loss = 0.67105897, grad/param norm = 6.6190e-02, time/batch = 0.1806s	
3692/10550 (epoch 17.498), train_loss = 0.68629118, grad/param norm = 6.6719e-02, time/batch = 0.1786s	
3693/10550 (epoch 17.502), train_loss = 0.68997821, grad/param norm = 6.8028e-02, time/batch = 0.1784s	
3694/10550 (epoch 17.507), train_loss = 0.67591947, grad/param norm = 6.6886e-02, time/batch = 0.1791s	
3695/10550 (epoch 17.512), train_loss = 0.65368770, grad/param norm = 7.1487e-02, time/batch = 0.1787s	
3696/10550 (epoch 17.517), train_loss = 0.68378460, grad/param norm = 7.1633e-02, time/batch = 0.1788s	
3697/10550 (epoch 17.521), train_loss = 0.67719370, grad/param norm = 6.9783e-02, time/batch = 0.1788s	
3698/10550 (epoch 17.526), train_loss = 0.63642726, grad/param norm = 6.7339e-02, time/batch = 0.1784s	
3699/10550 (epoch 17.531), train_loss = 0.64770671, grad/param norm = 7.0077e-02, time/batch = 0.1791s	
3700/10550 (epoch 17.536), train_loss = 0.71793404, grad/param norm = 7.1758e-02, time/batch = 0.1789s	
3701/10550 (epoch 17.540), train_loss = 0.70143962, grad/param norm = 7.2546e-02, time/batch = 0.1806s	
3702/10550 (epoch 17.545), train_loss = 0.68331705, grad/param norm = 7.0436e-02, time/batch = 0.1785s	
3703/10550 (epoch 17.550), train_loss = 0.68762494, grad/param norm = 7.0695e-02, time/batch = 0.1782s	
3704/10550 (epoch 17.555), train_loss = 0.69033941, grad/param norm = 6.9995e-02, time/batch = 0.1791s	
3705/10550 (epoch 17.559), train_loss = 0.69011600, grad/param norm = 7.4093e-02, time/batch = 0.1790s	
3706/10550 (epoch 17.564), train_loss = 0.66330672, grad/param norm = 6.7842e-02, time/batch = 0.1782s	
3707/10550 (epoch 17.569), train_loss = 0.67158055, grad/param norm = 6.9610e-02, time/batch = 0.1788s	
3708/10550 (epoch 17.573), train_loss = 0.69680779, grad/param norm = 7.0787e-02, time/batch = 0.1782s	
3709/10550 (epoch 17.578), train_loss = 0.67887615, grad/param norm = 7.0820e-02, time/batch = 0.1791s	
3710/10550 (epoch 17.583), train_loss = 0.67589139, grad/param norm = 7.1279e-02, time/batch = 0.1787s	
3711/10550 (epoch 17.588), train_loss = 0.66431793, grad/param norm = 6.8511e-02, time/batch = 0.1803s	
3712/10550 (epoch 17.592), train_loss = 0.68248241, grad/param norm = 7.2203e-02, time/batch = 0.1787s	
3713/10550 (epoch 17.597), train_loss = 0.69289949, grad/param norm = 7.2365e-02, time/batch = 0.1788s	
3714/10550 (epoch 17.602), train_loss = 0.71313370, grad/param norm = 7.3898e-02, time/batch = 0.1784s	
3715/10550 (epoch 17.607), train_loss = 0.68458417, grad/param norm = 7.3415e-02, time/batch = 0.1789s	
3716/10550 (epoch 17.611), train_loss = 0.66117053, grad/param norm = 7.2428e-02, time/batch = 0.1783s	
3717/10550 (epoch 17.616), train_loss = 0.68030254, grad/param norm = 7.2206e-02, time/batch = 0.1789s	
3718/10550 (epoch 17.621), train_loss = 0.67158722, grad/param norm = 7.0109e-02, time/batch = 0.1782s	
3719/10550 (epoch 17.626), train_loss = 0.68221937, grad/param norm = 7.1103e-02, time/batch = 0.1786s	
3720/10550 (epoch 17.630), train_loss = 0.69052672, grad/param norm = 7.3425e-02, time/batch = 0.1787s	
3721/10550 (epoch 17.635), train_loss = 0.70847811, grad/param norm = 7.3559e-02, time/batch = 0.1806s	
3722/10550 (epoch 17.640), train_loss = 0.70822736, grad/param norm = 6.8152e-02, time/batch = 0.1780s	
3723/10550 (epoch 17.645), train_loss = 0.69679327, grad/param norm = 7.4125e-02, time/batch = 0.1786s	
3724/10550 (epoch 17.649), train_loss = 0.69690195, grad/param norm = 7.0799e-02, time/batch = 0.1791s	
3725/10550 (epoch 17.654), train_loss = 0.68655711, grad/param norm = 6.8209e-02, time/batch = 0.1792s	
3726/10550 (epoch 17.659), train_loss = 0.68210150, grad/param norm = 7.0397e-02, time/batch = 0.1787s	
3727/10550 (epoch 17.664), train_loss = 0.69148390, grad/param norm = 7.0887e-02, time/batch = 0.1787s	
3728/10550 (epoch 17.668), train_loss = 0.66240753, grad/param norm = 7.1838e-02, time/batch = 0.1782s	
3729/10550 (epoch 17.673), train_loss = 0.67188370, grad/param norm = 7.0327e-02, time/batch = 0.1787s	
3730/10550 (epoch 17.678), train_loss = 0.66926490, grad/param norm = 7.1540e-02, time/batch = 0.1788s	
3731/10550 (epoch 17.682), train_loss = 0.66557590, grad/param norm = 6.8731e-02, time/batch = 0.1805s	
3732/10550 (epoch 17.687), train_loss = 0.66014047, grad/param norm = 6.8444e-02, time/batch = 0.1785s	
3733/10550 (epoch 17.692), train_loss = 0.67680542, grad/param norm = 6.9732e-02, time/batch = 0.1783s	
3734/10550 (epoch 17.697), train_loss = 0.65269388, grad/param norm = 7.0777e-02, time/batch = 0.1791s	
3735/10550 (epoch 17.701), train_loss = 0.66159017, grad/param norm = 6.9085e-02, time/batch = 0.1790s	
3736/10550 (epoch 17.706), train_loss = 0.64497667, grad/param norm = 6.9913e-02, time/batch = 0.1789s	
3737/10550 (epoch 17.711), train_loss = 0.69015276, grad/param norm = 6.9646e-02, time/batch = 0.1782s	
3738/10550 (epoch 17.716), train_loss = 0.67260622, grad/param norm = 7.0464e-02, time/batch = 0.1785s	
3739/10550 (epoch 17.720), train_loss = 0.69495361, grad/param norm = 7.1800e-02, time/batch = 0.1786s	
3740/10550 (epoch 17.725), train_loss = 0.66039613, grad/param norm = 6.8642e-02, time/batch = 0.1788s	
3741/10550 (epoch 17.730), train_loss = 0.65063073, grad/param norm = 6.9321e-02, time/batch = 0.1800s	
3742/10550 (epoch 17.735), train_loss = 0.67409136, grad/param norm = 6.9599e-02, time/batch = 0.1789s	
3743/10550 (epoch 17.739), train_loss = 0.66013076, grad/param norm = 6.8762e-02, time/batch = 0.1783s	
3744/10550 (epoch 17.744), train_loss = 0.66646127, grad/param norm = 6.9961e-02, time/batch = 0.1789s	
3745/10550 (epoch 17.749), train_loss = 0.69670375, grad/param norm = 7.0583e-02, time/batch = 0.1790s	
3746/10550 (epoch 17.754), train_loss = 0.69296145, grad/param norm = 7.2323e-02, time/batch = 0.1789s	
3747/10550 (epoch 17.758), train_loss = 0.65877217, grad/param norm = 7.4442e-02, time/batch = 0.1787s	
3748/10550 (epoch 17.763), train_loss = 0.65510321, grad/param norm = 7.2262e-02, time/batch = 0.1784s	
3749/10550 (epoch 17.768), train_loss = 0.67515443, grad/param norm = 6.8867e-02, time/batch = 0.1786s	
3750/10550 (epoch 17.773), train_loss = 0.68345954, grad/param norm = 6.9519e-02, time/batch = 0.1790s	
3751/10550 (epoch 17.777), train_loss = 0.68171123, grad/param norm = 7.0203e-02, time/batch = 0.1805s	
3752/10550 (epoch 17.782), train_loss = 0.70296142, grad/param norm = 6.9896e-02, time/batch = 0.1783s	
3753/10550 (epoch 17.787), train_loss = 0.66868095, grad/param norm = 7.0928e-02, time/batch = 0.1787s	
3754/10550 (epoch 17.791), train_loss = 0.65426074, grad/param norm = 6.8176e-02, time/batch = 0.1792s	
3755/10550 (epoch 17.796), train_loss = 0.69336235, grad/param norm = 7.1489e-02, time/batch = 0.1789s	
3756/10550 (epoch 17.801), train_loss = 0.67531911, grad/param norm = 7.1954e-02, time/batch = 0.1788s	
3757/10550 (epoch 17.806), train_loss = 0.68006557, grad/param norm = 7.2434e-02, time/batch = 0.1786s	
3758/10550 (epoch 17.810), train_loss = 0.69616817, grad/param norm = 7.3449e-02, time/batch = 0.1783s	
3759/10550 (epoch 17.815), train_loss = 0.68730206, grad/param norm = 7.6447e-02, time/batch = 0.1787s	
3760/10550 (epoch 17.820), train_loss = 0.69407057, grad/param norm = 7.2513e-02, time/batch = 0.1784s	
3761/10550 (epoch 17.825), train_loss = 0.68871194, grad/param norm = 7.0265e-02, time/batch = 0.1803s	
3762/10550 (epoch 17.829), train_loss = 0.66549825, grad/param norm = 6.8889e-02, time/batch = 0.1781s	
3763/10550 (epoch 17.834), train_loss = 0.67960788, grad/param norm = 7.4995e-02, time/batch = 0.1788s	
3764/10550 (epoch 17.839), train_loss = 0.67521641, grad/param norm = 7.3169e-02, time/batch = 0.1785s	
3765/10550 (epoch 17.844), train_loss = 0.68791719, grad/param norm = 7.2551e-02, time/batch = 0.1788s	
3766/10550 (epoch 17.848), train_loss = 0.67526486, grad/param norm = 7.1049e-02, time/batch = 0.1784s	
3767/10550 (epoch 17.853), train_loss = 0.69050471, grad/param norm = 6.9324e-02, time/batch = 0.1787s	
3768/10550 (epoch 17.858), train_loss = 0.71803458, grad/param norm = 7.4822e-02, time/batch = 0.1783s	
3769/10550 (epoch 17.863), train_loss = 0.67393348, grad/param norm = 7.5382e-02, time/batch = 0.1790s	
3770/10550 (epoch 17.867), train_loss = 0.69726906, grad/param norm = 7.4353e-02, time/batch = 0.1783s	
3771/10550 (epoch 17.872), train_loss = 0.69241400, grad/param norm = 7.3027e-02, time/batch = 0.1807s	
3772/10550 (epoch 17.877), train_loss = 0.67184989, grad/param norm = 7.0488e-02, time/batch = 0.1782s	
3773/10550 (epoch 17.882), train_loss = 0.67199856, grad/param norm = 6.8758e-02, time/batch = 0.1790s	
3774/10550 (epoch 17.886), train_loss = 0.67016790, grad/param norm = 6.8998e-02, time/batch = 0.1784s	
3775/10550 (epoch 17.891), train_loss = 0.65837133, grad/param norm = 7.0314e-02, time/batch = 0.1789s	
3776/10550 (epoch 17.896), train_loss = 0.67597317, grad/param norm = 7.1788e-02, time/batch = 0.1788s	
3777/10550 (epoch 17.900), train_loss = 0.66680363, grad/param norm = 6.8254e-02, time/batch = 0.1790s	
3778/10550 (epoch 17.905), train_loss = 0.66081619, grad/param norm = 7.3695e-02, time/batch = 0.1781s	
3779/10550 (epoch 17.910), train_loss = 0.65622689, grad/param norm = 6.9121e-02, time/batch = 0.1787s	
3780/10550 (epoch 17.915), train_loss = 0.66498182, grad/param norm = 7.0617e-02, time/batch = 0.1785s	
3781/10550 (epoch 17.919), train_loss = 0.67700579, grad/param norm = 7.0776e-02, time/batch = 0.1806s	
3782/10550 (epoch 17.924), train_loss = 0.67486375, grad/param norm = 7.1780e-02, time/batch = 0.1784s	
3783/10550 (epoch 17.929), train_loss = 0.68453991, grad/param norm = 7.2800e-02, time/batch = 0.1793s	
3784/10550 (epoch 17.934), train_loss = 0.66331064, grad/param norm = 7.4524e-02, time/batch = 0.1791s	
3785/10550 (epoch 17.938), train_loss = 0.67843644, grad/param norm = 7.1025e-02, time/batch = 0.1793s	
3786/10550 (epoch 17.943), train_loss = 0.67405271, grad/param norm = 6.9392e-02, time/batch = 0.1786s	
3787/10550 (epoch 17.948), train_loss = 0.68290567, grad/param norm = 7.3092e-02, time/batch = 0.1785s	
3788/10550 (epoch 17.953), train_loss = 0.68937900, grad/param norm = 7.3728e-02, time/batch = 0.1782s	
3789/10550 (epoch 17.957), train_loss = 0.69260544, grad/param norm = 7.3988e-02, time/batch = 0.1786s	
3790/10550 (epoch 17.962), train_loss = 0.67938621, grad/param norm = 7.3702e-02, time/batch = 0.1787s	
3791/10550 (epoch 17.967), train_loss = 0.69254165, grad/param norm = 6.9203e-02, time/batch = 0.1799s	
3792/10550 (epoch 17.972), train_loss = 0.66762147, grad/param norm = 7.0914e-02, time/batch = 0.1787s	
3793/10550 (epoch 17.976), train_loss = 0.66253436, grad/param norm = 6.9713e-02, time/batch = 0.1789s	
3794/10550 (epoch 17.981), train_loss = 0.66778205, grad/param norm = 6.8859e-02, time/batch = 0.1788s	
3795/10550 (epoch 17.986), train_loss = 0.66614974, grad/param norm = 7.1310e-02, time/batch = 0.1789s	
3796/10550 (epoch 17.991), train_loss = 0.70300227, grad/param norm = 7.1522e-02, time/batch = 0.1785s	
3797/10550 (epoch 17.995), train_loss = 0.68375926, grad/param norm = 6.8249e-02, time/batch = 0.1787s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
3798/10550 (epoch 18.000), train_loss = 0.67889830, grad/param norm = 7.0142e-02, time/batch = 0.1779s	
3799/10550 (epoch 18.005), train_loss = 0.86962876, grad/param norm = 7.6371e-02, time/batch = 0.1785s	
3800/10550 (epoch 18.009), train_loss = 0.66141707, grad/param norm = 6.8566e-02, time/batch = 0.1787s	
3801/10550 (epoch 18.014), train_loss = 0.68612906, grad/param norm = 7.1901e-02, time/batch = 0.1804s	
3802/10550 (epoch 18.019), train_loss = 0.72046103, grad/param norm = 7.4920e-02, time/batch = 0.1779s	
3803/10550 (epoch 18.024), train_loss = 0.70108655, grad/param norm = 7.2513e-02, time/batch = 0.1788s	
3804/10550 (epoch 18.028), train_loss = 0.68406975, grad/param norm = 7.2894e-02, time/batch = 0.1789s	
3805/10550 (epoch 18.033), train_loss = 0.70143316, grad/param norm = 7.1789e-02, time/batch = 0.1790s	
3806/10550 (epoch 18.038), train_loss = 0.67743966, grad/param norm = 7.1731e-02, time/batch = 0.1789s	
3807/10550 (epoch 18.043), train_loss = 0.65776502, grad/param norm = 6.7946e-02, time/batch = 0.1789s	
3808/10550 (epoch 18.047), train_loss = 0.66170550, grad/param norm = 6.7894e-02, time/batch = 0.1784s	
3809/10550 (epoch 18.052), train_loss = 0.69510008, grad/param norm = 7.1633e-02, time/batch = 0.1789s	
3810/10550 (epoch 18.057), train_loss = 0.66865384, grad/param norm = 6.9459e-02, time/batch = 0.1787s	
3811/10550 (epoch 18.062), train_loss = 0.68668079, grad/param norm = 7.0886e-02, time/batch = 0.1803s	
3812/10550 (epoch 18.066), train_loss = 0.67146285, grad/param norm = 6.8172e-02, time/batch = 0.1785s	
3813/10550 (epoch 18.071), train_loss = 0.66384231, grad/param norm = 7.4943e-02, time/batch = 0.1787s	
3814/10550 (epoch 18.076), train_loss = 0.67552268, grad/param norm = 7.2418e-02, time/batch = 0.1791s	
3815/10550 (epoch 18.081), train_loss = 0.68397565, grad/param norm = 7.5171e-02, time/batch = 0.1790s	
3816/10550 (epoch 18.085), train_loss = 0.67095932, grad/param norm = 7.0736e-02, time/batch = 0.1789s	
3817/10550 (epoch 18.090), train_loss = 0.65969063, grad/param norm = 7.0416e-02, time/batch = 0.1786s	
3818/10550 (epoch 18.095), train_loss = 0.69591189, grad/param norm = 7.2105e-02, time/batch = 0.1778s	
3819/10550 (epoch 18.100), train_loss = 0.66893601, grad/param norm = 7.0980e-02, time/batch = 0.1786s	
3820/10550 (epoch 18.104), train_loss = 0.67737487, grad/param norm = 7.1574e-02, time/batch = 0.1789s	
3821/10550 (epoch 18.109), train_loss = 0.67237204, grad/param norm = 7.3707e-02, time/batch = 0.1804s	
3822/10550 (epoch 18.114), train_loss = 0.67676874, grad/param norm = 7.2970e-02, time/batch = 0.1781s	
3823/10550 (epoch 18.118), train_loss = 0.65056377, grad/param norm = 6.9841e-02, time/batch = 0.1786s	
3824/10550 (epoch 18.123), train_loss = 0.69047614, grad/param norm = 7.1276e-02, time/batch = 0.1788s	
3825/10550 (epoch 18.128), train_loss = 0.66389724, grad/param norm = 7.3303e-02, time/batch = 0.1785s	
3826/10550 (epoch 18.133), train_loss = 0.65477502, grad/param norm = 7.4704e-02, time/batch = 0.1788s	
3827/10550 (epoch 18.137), train_loss = 0.67595235, grad/param norm = 7.3863e-02, time/batch = 0.1788s	
3828/10550 (epoch 18.142), train_loss = 0.67741977, grad/param norm = 7.3575e-02, time/batch = 0.1782s	
3829/10550 (epoch 18.147), train_loss = 0.66912067, grad/param norm = 7.2253e-02, time/batch = 0.1787s	
3830/10550 (epoch 18.152), train_loss = 0.69154453, grad/param norm = 7.5596e-02, time/batch = 0.1787s	
3831/10550 (epoch 18.156), train_loss = 0.67547356, grad/param norm = 7.1898e-02, time/batch = 0.1806s	
3832/10550 (epoch 18.161), train_loss = 0.67018026, grad/param norm = 6.9770e-02, time/batch = 0.1785s	
3833/10550 (epoch 18.166), train_loss = 0.68055877, grad/param norm = 7.0847e-02, time/batch = 0.1788s	
3834/10550 (epoch 18.171), train_loss = 0.65428878, grad/param norm = 7.1379e-02, time/batch = 0.1786s	
3835/10550 (epoch 18.175), train_loss = 0.67556103, grad/param norm = 7.4970e-02, time/batch = 0.1786s	
3836/10550 (epoch 18.180), train_loss = 0.65364847, grad/param norm = 6.9260e-02, time/batch = 0.1791s	
3837/10550 (epoch 18.185), train_loss = 0.67869096, grad/param norm = 7.1302e-02, time/batch = 0.1787s	
3838/10550 (epoch 18.190), train_loss = 0.64741034, grad/param norm = 7.4154e-02, time/batch = 0.1780s	
3839/10550 (epoch 18.194), train_loss = 0.67031293, grad/param norm = 7.2974e-02, time/batch = 0.1789s	
3840/10550 (epoch 18.199), train_loss = 0.67955374, grad/param norm = 7.2919e-02, time/batch = 0.1786s	
3841/10550 (epoch 18.204), train_loss = 0.66147485, grad/param norm = 7.5253e-02, time/batch = 0.1805s	
3842/10550 (epoch 18.209), train_loss = 0.68876614, grad/param norm = 7.3528e-02, time/batch = 0.1782s	
3843/10550 (epoch 18.213), train_loss = 0.69738793, grad/param norm = 7.6750e-02, time/batch = 0.1785s	
3844/10550 (epoch 18.218), train_loss = 0.69474477, grad/param norm = 7.1358e-02, time/batch = 0.1788s	
3845/10550 (epoch 18.223), train_loss = 0.66751725, grad/param norm = 6.9933e-02, time/batch = 0.1786s	
3846/10550 (epoch 18.227), train_loss = 0.65602300, grad/param norm = 7.0307e-02, time/batch = 0.1783s	
3847/10550 (epoch 18.232), train_loss = 0.65564204, grad/param norm = 6.9560e-02, time/batch = 0.1792s	
3848/10550 (epoch 18.237), train_loss = 0.66642845, grad/param norm = 7.1700e-02, time/batch = 0.1781s	
3849/10550 (epoch 18.242), train_loss = 0.65832518, grad/param norm = 7.2480e-02, time/batch = 0.1782s	
3850/10550 (epoch 18.246), train_loss = 0.65168563, grad/param norm = 7.0135e-02, time/batch = 0.1789s	
3851/10550 (epoch 18.251), train_loss = 0.67434376, grad/param norm = 7.0856e-02, time/batch = 0.1799s	
3852/10550 (epoch 18.256), train_loss = 0.67344503, grad/param norm = 6.8939e-02, time/batch = 0.1785s	
3853/10550 (epoch 18.261), train_loss = 0.64468832, grad/param norm = 6.6354e-02, time/batch = 0.1787s	
3854/10550 (epoch 18.265), train_loss = 0.63634097, grad/param norm = 7.0457e-02, time/batch = 0.1787s	
3855/10550 (epoch 18.270), train_loss = 0.65115735, grad/param norm = 6.9032e-02, time/batch = 0.1786s	
3856/10550 (epoch 18.275), train_loss = 0.66082479, grad/param norm = 7.0448e-02, time/batch = 0.1785s	
3857/10550 (epoch 18.280), train_loss = 0.66152074, grad/param norm = 6.9645e-02, time/batch = 0.1788s	
3858/10550 (epoch 18.284), train_loss = 0.66286637, grad/param norm = 7.2317e-02, time/batch = 0.1783s	
3859/10550 (epoch 18.289), train_loss = 0.65068852, grad/param norm = 7.0428e-02, time/batch = 0.1788s	
3860/10550 (epoch 18.294), train_loss = 0.64352368, grad/param norm = 7.1754e-02, time/batch = 0.1787s	
3861/10550 (epoch 18.299), train_loss = 0.64793841, grad/param norm = 7.1095e-02, time/batch = 0.1806s	
3862/10550 (epoch 18.303), train_loss = 0.67389420, grad/param norm = 7.2313e-02, time/batch = 0.1785s	
3863/10550 (epoch 18.308), train_loss = 0.65361948, grad/param norm = 6.9618e-02, time/batch = 0.1787s	
3864/10550 (epoch 18.313), train_loss = 0.64629184, grad/param norm = 7.0703e-02, time/batch = 0.1791s	
3865/10550 (epoch 18.318), train_loss = 0.66695716, grad/param norm = 7.2929e-02, time/batch = 0.1791s	
3866/10550 (epoch 18.322), train_loss = 0.66532245, grad/param norm = 7.4716e-02, time/batch = 0.1790s	
3867/10550 (epoch 18.327), train_loss = 0.67337857, grad/param norm = 7.4180e-02, time/batch = 0.1787s	
3868/10550 (epoch 18.332), train_loss = 0.68582817, grad/param norm = 7.5424e-02, time/batch = 0.1778s	
3869/10550 (epoch 18.336), train_loss = 0.65520553, grad/param norm = 7.5837e-02, time/batch = 0.1789s	
3870/10550 (epoch 18.341), train_loss = 0.64908726, grad/param norm = 7.4264e-02, time/batch = 0.1785s	
3871/10550 (epoch 18.346), train_loss = 0.66453659, grad/param norm = 7.3880e-02, time/batch = 0.1805s	
3872/10550 (epoch 18.351), train_loss = 0.66534264, grad/param norm = 7.2997e-02, time/batch = 0.1782s	
3873/10550 (epoch 18.355), train_loss = 0.66355521, grad/param norm = 7.3235e-02, time/batch = 0.1786s	
3874/10550 (epoch 18.360), train_loss = 0.68677526, grad/param norm = 7.3114e-02, time/batch = 0.1784s	
3875/10550 (epoch 18.365), train_loss = 0.66444140, grad/param norm = 7.0957e-02, time/batch = 0.1788s	
3876/10550 (epoch 18.370), train_loss = 0.65239812, grad/param norm = 7.2316e-02, time/batch = 0.1789s	
3877/10550 (epoch 18.374), train_loss = 0.66237407, grad/param norm = 7.3994e-02, time/batch = 0.1787s	
3878/10550 (epoch 18.379), train_loss = 0.68587075, grad/param norm = 7.6874e-02, time/batch = 0.1785s	
3879/10550 (epoch 18.384), train_loss = 0.66797102, grad/param norm = 7.6336e-02, time/batch = 0.1787s	
3880/10550 (epoch 18.389), train_loss = 0.64964310, grad/param norm = 6.8451e-02, time/batch = 0.1784s	
3881/10550 (epoch 18.393), train_loss = 0.64981752, grad/param norm = 7.0503e-02, time/batch = 0.1802s	
3882/10550 (epoch 18.398), train_loss = 0.63771264, grad/param norm = 6.8226e-02, time/batch = 0.1783s	
3883/10550 (epoch 18.403), train_loss = 0.66357514, grad/param norm = 7.1715e-02, time/batch = 0.1786s	
3884/10550 (epoch 18.408), train_loss = 0.66470151, grad/param norm = 7.6494e-02, time/batch = 0.1788s	
3885/10550 (epoch 18.412), train_loss = 0.66211783, grad/param norm = 7.3690e-02, time/batch = 0.1792s	
3886/10550 (epoch 18.417), train_loss = 0.67346675, grad/param norm = 7.3632e-02, time/batch = 0.1791s	
3887/10550 (epoch 18.422), train_loss = 0.65974181, grad/param norm = 7.4686e-02, time/batch = 0.1787s	
3888/10550 (epoch 18.427), train_loss = 0.67644154, grad/param norm = 7.4084e-02, time/batch = 0.1782s	
3889/10550 (epoch 18.431), train_loss = 0.66386543, grad/param norm = 7.2807e-02, time/batch = 0.1787s	
3890/10550 (epoch 18.436), train_loss = 0.64869848, grad/param norm = 7.1215e-02, time/batch = 0.1785s	
3891/10550 (epoch 18.441), train_loss = 0.66508763, grad/param norm = 7.0253e-02, time/batch = 0.1808s	
3892/10550 (epoch 18.445), train_loss = 0.67746224, grad/param norm = 7.4096e-02, time/batch = 0.1783s	
3893/10550 (epoch 18.450), train_loss = 0.66344023, grad/param norm = 7.2330e-02, time/batch = 0.1786s	
3894/10550 (epoch 18.455), train_loss = 0.65896446, grad/param norm = 7.4408e-02, time/batch = 0.1785s	
3895/10550 (epoch 18.460), train_loss = 0.64772929, grad/param norm = 7.3618e-02, time/batch = 0.1787s	
3896/10550 (epoch 18.464), train_loss = 0.66755236, grad/param norm = 7.3154e-02, time/batch = 0.1784s	
3897/10550 (epoch 18.469), train_loss = 0.66718116, grad/param norm = 7.3929e-02, time/batch = 0.1789s	
3898/10550 (epoch 18.474), train_loss = 0.66200425, grad/param norm = 7.2571e-02, time/batch = 0.1783s	
3899/10550 (epoch 18.479), train_loss = 0.63634912, grad/param norm = 7.1966e-02, time/batch = 0.1790s	
3900/10550 (epoch 18.483), train_loss = 0.64840996, grad/param norm = 6.9875e-02, time/batch = 0.1785s	
3901/10550 (epoch 18.488), train_loss = 0.66197329, grad/param norm = 7.4994e-02, time/batch = 0.1805s	
3902/10550 (epoch 18.493), train_loss = 0.63530478, grad/param norm = 6.8374e-02, time/batch = 0.1785s	
3903/10550 (epoch 18.498), train_loss = 0.65983987, grad/param norm = 6.7786e-02, time/batch = 0.1785s	
3904/10550 (epoch 18.502), train_loss = 0.65139348, grad/param norm = 6.7999e-02, time/batch = 0.1790s	
3905/10550 (epoch 18.507), train_loss = 0.63959904, grad/param norm = 6.5724e-02, time/batch = 0.1790s	
3906/10550 (epoch 18.512), train_loss = 0.62694152, grad/param norm = 6.9029e-02, time/batch = 0.1787s	
3907/10550 (epoch 18.517), train_loss = 0.64884971, grad/param norm = 7.2236e-02, time/batch = 0.1785s	
3908/10550 (epoch 18.521), train_loss = 0.64089933, grad/param norm = 7.3524e-02, time/batch = 0.1780s	
3909/10550 (epoch 18.526), train_loss = 0.60433117, grad/param norm = 7.0909e-02, time/batch = 0.1788s	
3910/10550 (epoch 18.531), train_loss = 0.60876522, grad/param norm = 6.7115e-02, time/batch = 0.1792s	
3911/10550 (epoch 18.536), train_loss = 0.67869579, grad/param norm = 7.1657e-02, time/batch = 0.1803s	
3912/10550 (epoch 18.540), train_loss = 0.66499371, grad/param norm = 7.2868e-02, time/batch = 0.1782s	
3913/10550 (epoch 18.545), train_loss = 0.63724727, grad/param norm = 7.0694e-02, time/batch = 0.1783s	
3914/10550 (epoch 18.550), train_loss = 0.65578429, grad/param norm = 7.1326e-02, time/batch = 0.1786s	
3915/10550 (epoch 18.555), train_loss = 0.65831923, grad/param norm = 7.1273e-02, time/batch = 0.1784s	
3916/10550 (epoch 18.559), train_loss = 0.65272791, grad/param norm = 7.2367e-02, time/batch = 0.1786s	
3917/10550 (epoch 18.564), train_loss = 0.64023216, grad/param norm = 7.3214e-02, time/batch = 0.1789s	
3918/10550 (epoch 18.569), train_loss = 0.64614518, grad/param norm = 7.1284e-02, time/batch = 0.1780s	
3919/10550 (epoch 18.573), train_loss = 0.65229007, grad/param norm = 6.9929e-02, time/batch = 0.1784s	
3920/10550 (epoch 18.578), train_loss = 0.63939923, grad/param norm = 6.9575e-02, time/batch = 0.1786s	
3921/10550 (epoch 18.583), train_loss = 0.64462425, grad/param norm = 7.0304e-02, time/batch = 0.1806s	
3922/10550 (epoch 18.588), train_loss = 0.62630296, grad/param norm = 7.1076e-02, time/batch = 0.1783s	
3923/10550 (epoch 18.592), train_loss = 0.65032818, grad/param norm = 7.3908e-02, time/batch = 0.1781s	
3924/10550 (epoch 18.597), train_loss = 0.63585623, grad/param norm = 7.0799e-02, time/batch = 0.1790s	
3925/10550 (epoch 18.602), train_loss = 0.66622718, grad/param norm = 7.6001e-02, time/batch = 0.1787s	
3926/10550 (epoch 18.607), train_loss = 0.64739298, grad/param norm = 7.2142e-02, time/batch = 0.1790s	
3927/10550 (epoch 18.611), train_loss = 0.63352381, grad/param norm = 7.5883e-02, time/batch = 0.1786s	
3928/10550 (epoch 18.616), train_loss = 0.64201145, grad/param norm = 7.1520e-02, time/batch = 0.1780s	
3929/10550 (epoch 18.621), train_loss = 0.64351756, grad/param norm = 7.0538e-02, time/batch = 0.1791s	
3930/10550 (epoch 18.626), train_loss = 0.64962227, grad/param norm = 7.3944e-02, time/batch = 0.1785s	
3931/10550 (epoch 18.630), train_loss = 0.65461622, grad/param norm = 7.6928e-02, time/batch = 0.1807s	
3932/10550 (epoch 18.635), train_loss = 0.67412001, grad/param norm = 7.3536e-02, time/batch = 0.1786s	
3933/10550 (epoch 18.640), train_loss = 0.68678087, grad/param norm = 7.4022e-02, time/batch = 0.1783s	
3934/10550 (epoch 18.645), train_loss = 0.66247841, grad/param norm = 7.6214e-02, time/batch = 0.1784s	
3935/10550 (epoch 18.649), train_loss = 0.66573852, grad/param norm = 7.3309e-02, time/batch = 0.1786s	
3936/10550 (epoch 18.654), train_loss = 0.66576673, grad/param norm = 7.3262e-02, time/batch = 0.1789s	
3937/10550 (epoch 18.659), train_loss = 0.64587289, grad/param norm = 7.0280e-02, time/batch = 0.1786s	
3938/10550 (epoch 18.664), train_loss = 0.64863555, grad/param norm = 6.9804e-02, time/batch = 0.1784s	
3939/10550 (epoch 18.668), train_loss = 0.63652459, grad/param norm = 7.4890e-02, time/batch = 0.1785s	
3940/10550 (epoch 18.673), train_loss = 0.63333401, grad/param norm = 7.0432e-02, time/batch = 0.1789s	
3941/10550 (epoch 18.678), train_loss = 0.63686786, grad/param norm = 7.0349e-02, time/batch = 0.1807s	
3942/10550 (epoch 18.682), train_loss = 0.64023883, grad/param norm = 7.0383e-02, time/batch = 0.1788s	
3943/10550 (epoch 18.687), train_loss = 0.63054223, grad/param norm = 6.9328e-02, time/batch = 0.1788s	
3944/10550 (epoch 18.692), train_loss = 0.64047983, grad/param norm = 7.2196e-02, time/batch = 0.1783s	
3945/10550 (epoch 18.697), train_loss = 0.62941031, grad/param norm = 7.0982e-02, time/batch = 0.1787s	
3946/10550 (epoch 18.701), train_loss = 0.64180721, grad/param norm = 7.1771e-02, time/batch = 0.1788s	
3947/10550 (epoch 18.706), train_loss = 0.62135087, grad/param norm = 7.2598e-02, time/batch = 0.1786s	
3948/10550 (epoch 18.711), train_loss = 0.65311114, grad/param norm = 7.0899e-02, time/batch = 0.1782s	
3949/10550 (epoch 18.716), train_loss = 0.64362398, grad/param norm = 7.3254e-02, time/batch = 0.1786s	
3950/10550 (epoch 18.720), train_loss = 0.67014414, grad/param norm = 7.2636e-02, time/batch = 0.1787s	
3951/10550 (epoch 18.725), train_loss = 0.63125818, grad/param norm = 7.2326e-02, time/batch = 0.1802s	
3952/10550 (epoch 18.730), train_loss = 0.60914925, grad/param norm = 7.0054e-02, time/batch = 0.1781s	
3953/10550 (epoch 18.735), train_loss = 0.63770732, grad/param norm = 7.3164e-02, time/batch = 0.1787s	
3954/10550 (epoch 18.739), train_loss = 0.62617963, grad/param norm = 7.0698e-02, time/batch = 0.1790s	
3955/10550 (epoch 18.744), train_loss = 0.63435756, grad/param norm = 7.0215e-02, time/batch = 0.1786s	
3956/10550 (epoch 18.749), train_loss = 0.67610963, grad/param norm = 7.3608e-02, time/batch = 0.1787s	
3957/10550 (epoch 18.754), train_loss = 0.65239055, grad/param norm = 6.9440e-02, time/batch = 0.1787s	
3958/10550 (epoch 18.758), train_loss = 0.62957632, grad/param norm = 7.3886e-02, time/batch = 0.1779s	
3959/10550 (epoch 18.763), train_loss = 0.61378598, grad/param norm = 7.2714e-02, time/batch = 0.1789s	
3960/10550 (epoch 18.768), train_loss = 0.64860516, grad/param norm = 7.4384e-02, time/batch = 0.1787s	
3961/10550 (epoch 18.773), train_loss = 0.67825509, grad/param norm = 7.8913e-02, time/batch = 0.1805s	
3962/10550 (epoch 18.777), train_loss = 0.65263248, grad/param norm = 7.4940e-02, time/batch = 0.1782s	
3963/10550 (epoch 18.782), train_loss = 0.67956071, grad/param norm = 7.3061e-02, time/batch = 0.1786s	
3964/10550 (epoch 18.787), train_loss = 0.63755036, grad/param norm = 7.1602e-02, time/batch = 0.1786s	
3965/10550 (epoch 18.791), train_loss = 0.62316629, grad/param norm = 7.2565e-02, time/batch = 0.1791s	
3966/10550 (epoch 18.796), train_loss = 0.65692661, grad/param norm = 7.0825e-02, time/batch = 0.1792s	
3967/10550 (epoch 18.801), train_loss = 0.64632418, grad/param norm = 7.4435e-02, time/batch = 0.1783s	
3968/10550 (epoch 18.806), train_loss = 0.65545075, grad/param norm = 7.5576e-02, time/batch = 0.1783s	
3969/10550 (epoch 18.810), train_loss = 0.66084854, grad/param norm = 7.3856e-02, time/batch = 0.1794s	
3970/10550 (epoch 18.815), train_loss = 0.64967012, grad/param norm = 7.3933e-02, time/batch = 0.1786s	
3971/10550 (epoch 18.820), train_loss = 0.66438377, grad/param norm = 7.6209e-02, time/batch = 0.1799s	
3972/10550 (epoch 18.825), train_loss = 0.65853585, grad/param norm = 7.0642e-02, time/batch = 0.1782s	
3973/10550 (epoch 18.829), train_loss = 0.65489709, grad/param norm = 7.5083e-02, time/batch = 0.1788s	
3974/10550 (epoch 18.834), train_loss = 0.63997499, grad/param norm = 7.3041e-02, time/batch = 0.1787s	
3975/10550 (epoch 18.839), train_loss = 0.63195844, grad/param norm = 7.2946e-02, time/batch = 0.1787s	
3976/10550 (epoch 18.844), train_loss = 0.65611778, grad/param norm = 7.4386e-02, time/batch = 0.1786s	
3977/10550 (epoch 18.848), train_loss = 0.64694430, grad/param norm = 7.4608e-02, time/batch = 0.1791s	
3978/10550 (epoch 18.853), train_loss = 0.65237653, grad/param norm = 7.2012e-02, time/batch = 0.1780s	
3979/10550 (epoch 18.858), train_loss = 0.67982837, grad/param norm = 7.5083e-02, time/batch = 0.1789s	
3980/10550 (epoch 18.863), train_loss = 0.63422210, grad/param norm = 7.1020e-02, time/batch = 0.1787s	
3981/10550 (epoch 18.867), train_loss = 0.64907361, grad/param norm = 7.1468e-02, time/batch = 0.1802s	
3982/10550 (epoch 18.872), train_loss = 0.67290353, grad/param norm = 7.8214e-02, time/batch = 0.1780s	
3983/10550 (epoch 18.877), train_loss = 0.63735148, grad/param norm = 7.6067e-02, time/batch = 0.1789s	
3984/10550 (epoch 18.882), train_loss = 0.64067788, grad/param norm = 7.2311e-02, time/batch = 0.1785s	
3985/10550 (epoch 18.886), train_loss = 0.63420039, grad/param norm = 7.0357e-02, time/batch = 0.1790s	
3986/10550 (epoch 18.891), train_loss = 0.62888024, grad/param norm = 7.2584e-02, time/batch = 0.1785s	
3987/10550 (epoch 18.896), train_loss = 0.64127968, grad/param norm = 7.4459e-02, time/batch = 0.1784s	
3988/10550 (epoch 18.900), train_loss = 0.63918052, grad/param norm = 7.0823e-02, time/batch = 0.1783s	
3989/10550 (epoch 18.905), train_loss = 0.61977563, grad/param norm = 7.1839e-02, time/batch = 0.1791s	
3990/10550 (epoch 18.910), train_loss = 0.63456104, grad/param norm = 7.5375e-02, time/batch = 0.1787s	
3991/10550 (epoch 18.915), train_loss = 0.64225654, grad/param norm = 7.3274e-02, time/batch = 0.1806s	
3992/10550 (epoch 18.919), train_loss = 0.64960859, grad/param norm = 7.2505e-02, time/batch = 0.1788s	
3993/10550 (epoch 18.924), train_loss = 0.65010865, grad/param norm = 7.3738e-02, time/batch = 0.1786s	
3994/10550 (epoch 18.929), train_loss = 0.64820349, grad/param norm = 7.2159e-02, time/batch = 0.1792s	
3995/10550 (epoch 18.934), train_loss = 0.62734306, grad/param norm = 7.1977e-02, time/batch = 0.1786s	
3996/10550 (epoch 18.938), train_loss = 0.65649925, grad/param norm = 7.4594e-02, time/batch = 0.1789s	
3997/10550 (epoch 18.943), train_loss = 0.64150116, grad/param norm = 7.1677e-02, time/batch = 0.1787s	
3998/10550 (epoch 18.948), train_loss = 0.64232423, grad/param norm = 7.4295e-02, time/batch = 0.1779s	
3999/10550 (epoch 18.953), train_loss = 0.66299247, grad/param norm = 7.7922e-02, time/batch = 0.1788s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to cv/lm_lstm_epoch18.96_2.2595.t7	
4000/10550 (epoch 18.957), train_loss = 0.65171670, grad/param norm = 7.2918e-02, time/batch = 0.1787s	
4001/10550 (epoch 18.962), train_loss = 1.45860745, grad/param norm = 1.0710e-01, time/batch = 0.1823s	
4002/10550 (epoch 18.967), train_loss = 0.69593107, grad/param norm = 7.5464e-02, time/batch = 0.1796s	
4003/10550 (epoch 18.972), train_loss = 0.65086583, grad/param norm = 7.2517e-02, time/batch = 0.1803s	
4004/10550 (epoch 18.976), train_loss = 0.64762914, grad/param norm = 7.5802e-02, time/batch = 0.1796s	
4005/10550 (epoch 18.981), train_loss = 0.65245750, grad/param norm = 7.5721e-02, time/batch = 0.1800s	
4006/10550 (epoch 18.986), train_loss = 0.64149157, grad/param norm = 7.1468e-02, time/batch = 0.1802s	
4007/10550 (epoch 18.991), train_loss = 0.67670255, grad/param norm = 7.4556e-02, time/batch = 0.1799s	
4008/10550 (epoch 18.995), train_loss = 0.64209663, grad/param norm = 7.0078e-02, time/batch = 0.1799s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
4009/10550 (epoch 19.000), train_loss = 0.65091391, grad/param norm = 7.0120e-02, time/batch = 0.1800s	
4010/10550 (epoch 19.005), train_loss = 0.83514097, grad/param norm = 7.6563e-02, time/batch = 0.1799s	
4011/10550 (epoch 19.009), train_loss = 0.63411867, grad/param norm = 7.0551e-02, time/batch = 0.1807s	
4012/10550 (epoch 19.014), train_loss = 0.65349346, grad/param norm = 7.2425e-02, time/batch = 0.1794s	
4013/10550 (epoch 19.019), train_loss = 0.68147464, grad/param norm = 7.3136e-02, time/batch = 0.1796s	
4014/10550 (epoch 19.024), train_loss = 0.65978881, grad/param norm = 7.3076e-02, time/batch = 0.1798s	
4015/10550 (epoch 19.028), train_loss = 0.66032592, grad/param norm = 7.2473e-02, time/batch = 0.1794s	
4016/10550 (epoch 19.033), train_loss = 0.67709905, grad/param norm = 7.1289e-02, time/batch = 0.1797s	
4017/10550 (epoch 19.038), train_loss = 0.65316226, grad/param norm = 7.5134e-02, time/batch = 0.1799s	
4018/10550 (epoch 19.043), train_loss = 0.64200589, grad/param norm = 6.9552e-02, time/batch = 0.1798s	
4019/10550 (epoch 19.047), train_loss = 0.63137699, grad/param norm = 6.9727e-02, time/batch = 0.1800s	
4020/10550 (epoch 19.052), train_loss = 0.65620412, grad/param norm = 7.2111e-02, time/batch = 0.1799s	
4021/10550 (epoch 19.057), train_loss = 0.64171737, grad/param norm = 7.0452e-02, time/batch = 0.1812s	
4022/10550 (epoch 19.062), train_loss = 0.65711711, grad/param norm = 7.1667e-02, time/batch = 0.1790s	
4023/10550 (epoch 19.066), train_loss = 0.64570179, grad/param norm = 6.7961e-02, time/batch = 0.1800s	
4024/10550 (epoch 19.071), train_loss = 0.63091745, grad/param norm = 7.3556e-02, time/batch = 0.1802s	
4025/10550 (epoch 19.076), train_loss = 0.65793260, grad/param norm = 7.7482e-02, time/batch = 0.1798s	
4026/10550 (epoch 19.081), train_loss = 0.65426389, grad/param norm = 7.2165e-02, time/batch = 0.1798s	
4027/10550 (epoch 19.085), train_loss = 0.63413001, grad/param norm = 7.2276e-02, time/batch = 0.1794s	
4028/10550 (epoch 19.090), train_loss = 0.62809602, grad/param norm = 7.0738e-02, time/batch = 0.1801s	
4029/10550 (epoch 19.095), train_loss = 0.66663471, grad/param norm = 7.4110e-02, time/batch = 0.1799s	
4030/10550 (epoch 19.100), train_loss = 0.64134390, grad/param norm = 7.3055e-02, time/batch = 0.1799s	
4031/10550 (epoch 19.104), train_loss = 0.63132894, grad/param norm = 6.9583e-02, time/batch = 0.1803s	
4032/10550 (epoch 19.109), train_loss = 0.63123161, grad/param norm = 7.2605e-02, time/batch = 0.1796s	
4033/10550 (epoch 19.114), train_loss = 0.62962430, grad/param norm = 7.3201e-02, time/batch = 0.1799s	
4034/10550 (epoch 19.118), train_loss = 0.61936738, grad/param norm = 7.2822e-02, time/batch = 0.1798s	
4035/10550 (epoch 19.123), train_loss = 0.65048998, grad/param norm = 7.0075e-02, time/batch = 0.1794s	
4036/10550 (epoch 19.128), train_loss = 0.63947166, grad/param norm = 7.3477e-02, time/batch = 0.1803s	
4037/10550 (epoch 19.133), train_loss = 0.61995912, grad/param norm = 7.2282e-02, time/batch = 0.1795s	
4038/10550 (epoch 19.137), train_loss = 0.64225301, grad/param norm = 7.5022e-02, time/batch = 0.1803s	
4039/10550 (epoch 19.142), train_loss = 0.65615495, grad/param norm = 7.9406e-02, time/batch = 0.1799s	
4040/10550 (epoch 19.147), train_loss = 0.64084265, grad/param norm = 7.1617e-02, time/batch = 0.1795s	
4041/10550 (epoch 19.152), train_loss = 0.66161772, grad/param norm = 7.5206e-02, time/batch = 0.1811s	
4042/10550 (epoch 19.156), train_loss = 0.64130241, grad/param norm = 7.0278e-02, time/batch = 0.1791s	
4043/10550 (epoch 19.161), train_loss = 0.63896400, grad/param norm = 7.1522e-02, time/batch = 0.1792s	
4044/10550 (epoch 19.166), train_loss = 0.65660858, grad/param norm = 7.0804e-02, time/batch = 0.1801s	
4045/10550 (epoch 19.171), train_loss = 0.62966439, grad/param norm = 7.1711e-02, time/batch = 0.1795s	
4046/10550 (epoch 19.175), train_loss = 0.62927674, grad/param norm = 7.0765e-02, time/batch = 0.1798s	
4047/10550 (epoch 19.180), train_loss = 0.63097913, grad/param norm = 7.3516e-02, time/batch = 0.1799s	
4048/10550 (epoch 19.185), train_loss = 0.65732458, grad/param norm = 7.5029e-02, time/batch = 0.1794s	
4049/10550 (epoch 19.190), train_loss = 0.60787209, grad/param norm = 7.2917e-02, time/batch = 0.1802s	
4050/10550 (epoch 19.194), train_loss = 0.64483313, grad/param norm = 7.5258e-02, time/batch = 0.1800s	
4051/10550 (epoch 19.199), train_loss = 0.66726222, grad/param norm = 7.5123e-02, time/batch = 0.1808s	
4052/10550 (epoch 19.204), train_loss = 0.64331014, grad/param norm = 7.7449e-02, time/batch = 0.1793s	
4053/10550 (epoch 19.209), train_loss = 0.65929403, grad/param norm = 7.4991e-02, time/batch = 0.1800s	
4054/10550 (epoch 19.213), train_loss = 0.67710513, grad/param norm = 7.7282e-02, time/batch = 0.1798s	
4055/10550 (epoch 19.218), train_loss = 0.64565467, grad/param norm = 7.2276e-02, time/batch = 0.1799s	
4056/10550 (epoch 19.223), train_loss = 0.63681560, grad/param norm = 7.3140e-02, time/batch = 0.1796s	
4057/10550 (epoch 19.227), train_loss = 0.62440924, grad/param norm = 7.0442e-02, time/batch = 0.1800s	
4058/10550 (epoch 19.232), train_loss = 0.62088793, grad/param norm = 7.1368e-02, time/batch = 0.1793s	
4059/10550 (epoch 19.237), train_loss = 0.62504271, grad/param norm = 6.8712e-02, time/batch = 0.1801s	
4060/10550 (epoch 19.242), train_loss = 0.62712962, grad/param norm = 7.3306e-02, time/batch = 0.1801s	
4061/10550 (epoch 19.246), train_loss = 0.61544067, grad/param norm = 7.1147e-02, time/batch = 0.1810s	
4062/10550 (epoch 19.251), train_loss = 0.64670953, grad/param norm = 7.3902e-02, time/batch = 0.1794s	
4063/10550 (epoch 19.256), train_loss = 0.64570565, grad/param norm = 7.1394e-02, time/batch = 0.1796s	
4064/10550 (epoch 19.261), train_loss = 0.62651512, grad/param norm = 7.1056e-02, time/batch = 0.1800s	
4065/10550 (epoch 19.265), train_loss = 0.61873655, grad/param norm = 7.5413e-02, time/batch = 0.1799s	
4066/10550 (epoch 19.270), train_loss = 0.62372939, grad/param norm = 7.0835e-02, time/batch = 0.1799s	
4067/10550 (epoch 19.275), train_loss = 0.64154154, grad/param norm = 7.1563e-02, time/batch = 0.1803s	
4068/10550 (epoch 19.280), train_loss = 0.63994082, grad/param norm = 7.6806e-02, time/batch = 0.1796s	
4069/10550 (epoch 19.284), train_loss = 0.63161428, grad/param norm = 7.2346e-02, time/batch = 0.1799s	
4070/10550 (epoch 19.289), train_loss = 0.61995312, grad/param norm = 7.1695e-02, time/batch = 0.1800s	
4071/10550 (epoch 19.294), train_loss = 0.61969130, grad/param norm = 7.4527e-02, time/batch = 0.1812s	
4072/10550 (epoch 19.299), train_loss = 0.61098011, grad/param norm = 7.2964e-02, time/batch = 0.1795s	
4073/10550 (epoch 19.303), train_loss = 0.63122579, grad/param norm = 7.0131e-02, time/batch = 0.1797s	
4074/10550 (epoch 19.308), train_loss = 0.61916248, grad/param norm = 7.2832e-02, time/batch = 0.1799s	
4075/10550 (epoch 19.313), train_loss = 0.62480257, grad/param norm = 7.3977e-02, time/batch = 0.1798s	
4076/10550 (epoch 19.318), train_loss = 0.61949206, grad/param norm = 7.3251e-02, time/batch = 0.1797s	
4077/10550 (epoch 19.322), train_loss = 0.63258042, grad/param norm = 7.3662e-02, time/batch = 0.1800s	
4078/10550 (epoch 19.327), train_loss = 0.62779338, grad/param norm = 7.2947e-02, time/batch = 0.1795s	
4079/10550 (epoch 19.332), train_loss = 0.63904229, grad/param norm = 7.2006e-02, time/batch = 0.1798s	
4080/10550 (epoch 19.336), train_loss = 0.61396140, grad/param norm = 7.3721e-02, time/batch = 0.1801s	
4081/10550 (epoch 19.341), train_loss = 0.60697017, grad/param norm = 7.5771e-02, time/batch = 0.1810s	
4082/10550 (epoch 19.346), train_loss = 0.63864013, grad/param norm = 7.6041e-02, time/batch = 0.1799s	
4083/10550 (epoch 19.351), train_loss = 0.63574395, grad/param norm = 7.3610e-02, time/batch = 0.1795s	
4084/10550 (epoch 19.355), train_loss = 0.62930193, grad/param norm = 7.2208e-02, time/batch = 0.1799s	
4085/10550 (epoch 19.360), train_loss = 0.64682542, grad/param norm = 7.5333e-02, time/batch = 0.1801s	
4086/10550 (epoch 19.365), train_loss = 0.63367314, grad/param norm = 7.2689e-02, time/batch = 0.1800s	
4087/10550 (epoch 19.370), train_loss = 0.62616837, grad/param norm = 7.4083e-02, time/batch = 0.1801s	
4088/10550 (epoch 19.374), train_loss = 0.61683081, grad/param norm = 7.1990e-02, time/batch = 0.1795s	
4089/10550 (epoch 19.379), train_loss = 0.65984159, grad/param norm = 7.9525e-02, time/batch = 0.1796s	
4090/10550 (epoch 19.384), train_loss = 0.62843745, grad/param norm = 7.3787e-02, time/batch = 0.1799s	
4091/10550 (epoch 19.389), train_loss = 0.63127556, grad/param norm = 7.2695e-02, time/batch = 0.1805s	
4092/10550 (epoch 19.393), train_loss = 0.61931480, grad/param norm = 7.1966e-02, time/batch = 0.1799s	
4093/10550 (epoch 19.398), train_loss = 0.62657443, grad/param norm = 7.4085e-02, time/batch = 0.1800s	
4094/10550 (epoch 19.403), train_loss = 0.62662188, grad/param norm = 7.4768e-02, time/batch = 0.1800s	
4095/10550 (epoch 19.408), train_loss = 0.63220644, grad/param norm = 7.5355e-02, time/batch = 0.1797s	
4096/10550 (epoch 19.412), train_loss = 0.63498845, grad/param norm = 7.3312e-02, time/batch = 0.1802s	
4097/10550 (epoch 19.417), train_loss = 0.62775417, grad/param norm = 7.1186e-02, time/batch = 0.1798s	
4098/10550 (epoch 19.422), train_loss = 0.62027882, grad/param norm = 7.4118e-02, time/batch = 0.1801s	
4099/10550 (epoch 19.427), train_loss = 0.63901802, grad/param norm = 7.2836e-02, time/batch = 0.1801s	
4100/10550 (epoch 19.431), train_loss = 0.64064156, grad/param norm = 7.2826e-02, time/batch = 0.1801s	
4101/10550 (epoch 19.436), train_loss = 0.61398681, grad/param norm = 7.0475e-02, time/batch = 0.1814s	
4102/10550 (epoch 19.441), train_loss = 0.64569439, grad/param norm = 7.2484e-02, time/batch = 0.1794s	
4103/10550 (epoch 19.445), train_loss = 0.64487576, grad/param norm = 7.7122e-02, time/batch = 0.1794s	
4104/10550 (epoch 19.450), train_loss = 0.62580634, grad/param norm = 7.3598e-02, time/batch = 0.1795s	
4105/10550 (epoch 19.455), train_loss = 0.63027991, grad/param norm = 7.1120e-02, time/batch = 0.1803s	
4106/10550 (epoch 19.460), train_loss = 0.61435070, grad/param norm = 7.2245e-02, time/batch = 0.1798s	
4107/10550 (epoch 19.464), train_loss = 0.64245379, grad/param norm = 7.6254e-02, time/batch = 0.1794s	
4108/10550 (epoch 19.469), train_loss = 0.63409963, grad/param norm = 7.3470e-02, time/batch = 0.1795s	
4109/10550 (epoch 19.474), train_loss = 0.62722970, grad/param norm = 7.3673e-02, time/batch = 0.1803s	
4110/10550 (epoch 19.479), train_loss = 0.60847745, grad/param norm = 7.2927e-02, time/batch = 0.1801s	
4111/10550 (epoch 19.483), train_loss = 0.61986989, grad/param norm = 7.4623e-02, time/batch = 0.1812s	
4112/10550 (epoch 19.488), train_loss = 0.63562074, grad/param norm = 7.8750e-02, time/batch = 0.1795s	
4113/10550 (epoch 19.493), train_loss = 0.60973883, grad/param norm = 7.3192e-02, time/batch = 0.1802s	
4114/10550 (epoch 19.498), train_loss = 0.63455955, grad/param norm = 7.0811e-02, time/batch = 0.1800s	
4115/10550 (epoch 19.502), train_loss = 0.62653394, grad/param norm = 7.0705e-02, time/batch = 0.1804s	
4116/10550 (epoch 19.507), train_loss = 0.61916648, grad/param norm = 7.0499e-02, time/batch = 0.1799s	
4117/10550 (epoch 19.512), train_loss = 0.59819210, grad/param norm = 7.0113e-02, time/batch = 0.1801s	
4118/10550 (epoch 19.517), train_loss = 0.62486212, grad/param norm = 7.6800e-02, time/batch = 0.1794s	
4119/10550 (epoch 19.521), train_loss = 0.60889263, grad/param norm = 7.1640e-02, time/batch = 0.1799s	
4120/10550 (epoch 19.526), train_loss = 0.57954427, grad/param norm = 7.0139e-02, time/batch = 0.1802s	
4121/10550 (epoch 19.531), train_loss = 0.58818558, grad/param norm = 7.3554e-02, time/batch = 0.1812s	
4122/10550 (epoch 19.536), train_loss = 0.63911081, grad/param norm = 7.2165e-02, time/batch = 0.1793s	
4123/10550 (epoch 19.540), train_loss = 0.63699870, grad/param norm = 7.6082e-02, time/batch = 0.1801s	
4124/10550 (epoch 19.545), train_loss = 0.60649362, grad/param norm = 7.1698e-02, time/batch = 0.1805s	
4125/10550 (epoch 19.550), train_loss = 0.62255853, grad/param norm = 7.0853e-02, time/batch = 0.1802s	
4126/10550 (epoch 19.555), train_loss = 0.62172359, grad/param norm = 7.2186e-02, time/batch = 0.1796s	
4127/10550 (epoch 19.559), train_loss = 0.61389005, grad/param norm = 7.2797e-02, time/batch = 0.1801s	
4128/10550 (epoch 19.564), train_loss = 0.60255776, grad/param norm = 7.0227e-02, time/batch = 0.1792s	
4129/10550 (epoch 19.569), train_loss = 0.61377470, grad/param norm = 7.4372e-02, time/batch = 0.1801s	
4130/10550 (epoch 19.573), train_loss = 0.62962967, grad/param norm = 7.3115e-02, time/batch = 0.1806s	
4131/10550 (epoch 19.578), train_loss = 0.61475518, grad/param norm = 7.0355e-02, time/batch = 0.1810s	
4132/10550 (epoch 19.583), train_loss = 0.62080085, grad/param norm = 7.3874e-02, time/batch = 0.1802s	
4133/10550 (epoch 19.588), train_loss = 0.59076830, grad/param norm = 7.1431e-02, time/batch = 0.1798s	
4134/10550 (epoch 19.592), train_loss = 0.61654553, grad/param norm = 7.2711e-02, time/batch = 0.1799s	
4135/10550 (epoch 19.597), train_loss = 0.61646157, grad/param norm = 7.4588e-02, time/batch = 0.1798s	
4136/10550 (epoch 19.602), train_loss = 0.62998520, grad/param norm = 7.5627e-02, time/batch = 0.1798s	
4137/10550 (epoch 19.607), train_loss = 0.61982527, grad/param norm = 7.3003e-02, time/batch = 0.1795s	
4138/10550 (epoch 19.611), train_loss = 0.60883935, grad/param norm = 7.6297e-02, time/batch = 0.1796s	
4139/10550 (epoch 19.616), train_loss = 0.61216430, grad/param norm = 7.4113e-02, time/batch = 0.1798s	
4140/10550 (epoch 19.621), train_loss = 0.61342802, grad/param norm = 7.4590e-02, time/batch = 0.1800s	
4141/10550 (epoch 19.626), train_loss = 0.61697624, grad/param norm = 7.4544e-02, time/batch = 0.1812s	
4142/10550 (epoch 19.630), train_loss = 0.62797421, grad/param norm = 7.8149e-02, time/batch = 0.1791s	
4143/10550 (epoch 19.635), train_loss = 0.65232945, grad/param norm = 7.6722e-02, time/batch = 0.1799s	
4144/10550 (epoch 19.640), train_loss = 0.63929619, grad/param norm = 7.1327e-02, time/batch = 0.1800s	
4145/10550 (epoch 19.645), train_loss = 0.62125225, grad/param norm = 7.4881e-02, time/batch = 0.1798s	
4146/10550 (epoch 19.649), train_loss = 0.64892078, grad/param norm = 7.6752e-02, time/batch = 0.1796s	
4147/10550 (epoch 19.654), train_loss = 0.62791966, grad/param norm = 7.3117e-02, time/batch = 0.1798s	
4148/10550 (epoch 19.659), train_loss = 0.61896014, grad/param norm = 7.2525e-02, time/batch = 0.1797s	
4149/10550 (epoch 19.664), train_loss = 0.62008890, grad/param norm = 7.2031e-02, time/batch = 0.1786s	
4150/10550 (epoch 19.668), train_loss = 0.59899783, grad/param norm = 7.4981e-02, time/batch = 0.1796s	
4151/10550 (epoch 19.673), train_loss = 0.61144103, grad/param norm = 7.3335e-02, time/batch = 0.1808s	
4152/10550 (epoch 19.678), train_loss = 0.60710572, grad/param norm = 7.3483e-02, time/batch = 0.1794s	
4153/10550 (epoch 19.682), train_loss = 0.60604275, grad/param norm = 7.4745e-02, time/batch = 0.1804s	
4154/10550 (epoch 19.687), train_loss = 0.60702748, grad/param norm = 7.3139e-02, time/batch = 0.1802s	
4155/10550 (epoch 19.692), train_loss = 0.61737585, grad/param norm = 7.3839e-02, time/batch = 0.1802s	
4156/10550 (epoch 19.697), train_loss = 0.60465128, grad/param norm = 7.4121e-02, time/batch = 0.1797s	
4157/10550 (epoch 19.701), train_loss = 0.60315980, grad/param norm = 7.2786e-02, time/batch = 0.1800s	
4158/10550 (epoch 19.706), train_loss = 0.59243736, grad/param norm = 7.3485e-02, time/batch = 0.1799s	
4159/10550 (epoch 19.711), train_loss = 0.62572705, grad/param norm = 7.4563e-02, time/batch = 0.1802s	
4160/10550 (epoch 19.716), train_loss = 0.61065386, grad/param norm = 7.2971e-02, time/batch = 0.1797s	
4161/10550 (epoch 19.720), train_loss = 0.63707662, grad/param norm = 7.6043e-02, time/batch = 0.1809s	
4162/10550 (epoch 19.725), train_loss = 0.59022076, grad/param norm = 6.8552e-02, time/batch = 0.1797s	
4163/10550 (epoch 19.730), train_loss = 0.58317171, grad/param norm = 7.5196e-02, time/batch = 0.1796s	
4164/10550 (epoch 19.735), train_loss = 0.61126100, grad/param norm = 7.2632e-02, time/batch = 0.1796s	
4165/10550 (epoch 19.739), train_loss = 0.59734719, grad/param norm = 7.0996e-02, time/batch = 0.1803s	
4166/10550 (epoch 19.744), train_loss = 0.59755315, grad/param norm = 7.3097e-02, time/batch = 0.1798s	
4167/10550 (epoch 19.749), train_loss = 0.64188333, grad/param norm = 7.5043e-02, time/batch = 0.1802s	
4168/10550 (epoch 19.754), train_loss = 0.62046981, grad/param norm = 7.1072e-02, time/batch = 0.1796s	
4169/10550 (epoch 19.758), train_loss = 0.60542581, grad/param norm = 7.5665e-02, time/batch = 0.1795s	
4170/10550 (epoch 19.763), train_loss = 0.59503893, grad/param norm = 7.4896e-02, time/batch = 0.1801s	
4171/10550 (epoch 19.768), train_loss = 0.61267118, grad/param norm = 7.4064e-02, time/batch = 0.1807s	
4172/10550 (epoch 19.773), train_loss = 0.63367920, grad/param norm = 7.4505e-02, time/batch = 0.1790s	
4173/10550 (epoch 19.777), train_loss = 0.61444278, grad/param norm = 7.2245e-02, time/batch = 0.1801s	
4174/10550 (epoch 19.782), train_loss = 0.63881652, grad/param norm = 7.4870e-02, time/batch = 0.1799s	
4175/10550 (epoch 19.787), train_loss = 0.60256918, grad/param norm = 7.3227e-02, time/batch = 0.1801s	
4176/10550 (epoch 19.791), train_loss = 0.59163691, grad/param norm = 7.2562e-02, time/batch = 0.1800s	
4177/10550 (epoch 19.796), train_loss = 0.62276164, grad/param norm = 7.4569e-02, time/batch = 0.1796s	
4178/10550 (epoch 19.801), train_loss = 0.62346987, grad/param norm = 7.5472e-02, time/batch = 0.1795s	
4179/10550 (epoch 19.806), train_loss = 0.61236673, grad/param norm = 7.3357e-02, time/batch = 0.1800s	
4180/10550 (epoch 19.810), train_loss = 0.63310467, grad/param norm = 7.7086e-02, time/batch = 0.1798s	
4181/10550 (epoch 19.815), train_loss = 0.61690218, grad/param norm = 7.3997e-02, time/batch = 0.1810s	
4182/10550 (epoch 19.820), train_loss = 0.61094647, grad/param norm = 7.2864e-02, time/batch = 0.1793s	
4183/10550 (epoch 19.825), train_loss = 0.61747371, grad/param norm = 7.0931e-02, time/batch = 0.1797s	
4184/10550 (epoch 19.829), train_loss = 0.61140713, grad/param norm = 7.3330e-02, time/batch = 0.1798s	
4185/10550 (epoch 19.834), train_loss = 0.61553161, grad/param norm = 7.3508e-02, time/batch = 0.1803s	
4186/10550 (epoch 19.839), train_loss = 0.60114323, grad/param norm = 7.2422e-02, time/batch = 0.1800s	
4187/10550 (epoch 19.844), train_loss = 0.63149835, grad/param norm = 7.7394e-02, time/batch = 0.1802s	
4188/10550 (epoch 19.848), train_loss = 0.62047104, grad/param norm = 7.6562e-02, time/batch = 0.1793s	
4189/10550 (epoch 19.853), train_loss = 0.62662772, grad/param norm = 7.7120e-02, time/batch = 0.1802s	
4190/10550 (epoch 19.858), train_loss = 0.64459094, grad/param norm = 7.7262e-02, time/batch = 0.1804s	
4191/10550 (epoch 19.863), train_loss = 0.59846337, grad/param norm = 7.2314e-02, time/batch = 0.1813s	
4192/10550 (epoch 19.867), train_loss = 0.63115563, grad/param norm = 7.7421e-02, time/batch = 0.1794s	
4193/10550 (epoch 19.872), train_loss = 0.62089928, grad/param norm = 7.5724e-02, time/batch = 0.1802s	
4194/10550 (epoch 19.877), train_loss = 0.60772509, grad/param norm = 7.3669e-02, time/batch = 0.1801s	
4195/10550 (epoch 19.882), train_loss = 0.61306559, grad/param norm = 7.5445e-02, time/batch = 0.1797s	
4196/10550 (epoch 19.886), train_loss = 0.60924586, grad/param norm = 7.3384e-02, time/batch = 0.1793s	
4197/10550 (epoch 19.891), train_loss = 0.60316902, grad/param norm = 7.3844e-02, time/batch = 0.1797s	
4198/10550 (epoch 19.896), train_loss = 0.61265456, grad/param norm = 7.5865e-02, time/batch = 0.1794s	
4199/10550 (epoch 19.900), train_loss = 0.61999564, grad/param norm = 7.3895e-02, time/batch = 0.1802s	
4200/10550 (epoch 19.905), train_loss = 0.59509036, grad/param norm = 7.4313e-02, time/batch = 0.1799s	
4201/10550 (epoch 19.910), train_loss = 0.59854259, grad/param norm = 7.4582e-02, time/batch = 0.1809s	
4202/10550 (epoch 19.915), train_loss = 0.61202910, grad/param norm = 7.2350e-02, time/batch = 0.1792s	
4203/10550 (epoch 19.919), train_loss = 0.61970619, grad/param norm = 7.2439e-02, time/batch = 0.1797s	
4204/10550 (epoch 19.924), train_loss = 0.61368418, grad/param norm = 7.1960e-02, time/batch = 0.1800s	
4205/10550 (epoch 19.929), train_loss = 0.61984563, grad/param norm = 7.4904e-02, time/batch = 0.1804s	
4206/10550 (epoch 19.934), train_loss = 0.60974382, grad/param norm = 7.8342e-02, time/batch = 0.1798s	
4207/10550 (epoch 19.938), train_loss = 0.62239895, grad/param norm = 7.5088e-02, time/batch = 0.1795s	
4208/10550 (epoch 19.943), train_loss = 0.60979950, grad/param norm = 7.2428e-02, time/batch = 0.1792s	
4209/10550 (epoch 19.948), train_loss = 0.61841608, grad/param norm = 7.5216e-02, time/batch = 0.1799s	
4210/10550 (epoch 19.953), train_loss = 0.62725115, grad/param norm = 7.5948e-02, time/batch = 0.1793s	
4211/10550 (epoch 19.957), train_loss = 0.62262084, grad/param norm = 7.3911e-02, time/batch = 0.1814s	
4212/10550 (epoch 19.962), train_loss = 0.65056436, grad/param norm = 7.7033e-02, time/batch = 0.1793s	
4213/10550 (epoch 19.967), train_loss = 0.64004654, grad/param norm = 7.2448e-02, time/batch = 0.1798s	
4214/10550 (epoch 19.972), train_loss = 0.60806679, grad/param norm = 7.2314e-02, time/batch = 0.1795s	
4215/10550 (epoch 19.976), train_loss = 0.60612345, grad/param norm = 7.1655e-02, time/batch = 0.1800s	
4216/10550 (epoch 19.981), train_loss = 0.61354741, grad/param norm = 7.3406e-02, time/batch = 0.1794s	
4217/10550 (epoch 19.986), train_loss = 0.61040805, grad/param norm = 7.2917e-02, time/batch = 0.1801s	
4218/10550 (epoch 19.991), train_loss = 0.63922341, grad/param norm = 7.5208e-02, time/batch = 0.1801s	
4219/10550 (epoch 19.995), train_loss = 0.61466548, grad/param norm = 7.1837e-02, time/batch = 0.1802s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
4220/10550 (epoch 20.000), train_loss = 0.62682832, grad/param norm = 7.4429e-02, time/batch = 0.1802s	
4221/10550 (epoch 20.005), train_loss = 0.81115984, grad/param norm = 7.9635e-02, time/batch = 0.1808s	
4222/10550 (epoch 20.009), train_loss = 0.59871706, grad/param norm = 6.9580e-02, time/batch = 0.1795s	
4223/10550 (epoch 20.014), train_loss = 0.61760454, grad/param norm = 7.1936e-02, time/batch = 0.1800s	
4224/10550 (epoch 20.019), train_loss = 0.65571127, grad/param norm = 7.6766e-02, time/batch = 0.1799s	
4225/10550 (epoch 20.024), train_loss = 0.63356485, grad/param norm = 7.4656e-02, time/batch = 0.1798s	
4226/10550 (epoch 20.028), train_loss = 0.61889486, grad/param norm = 7.1763e-02, time/batch = 0.1801s	
4227/10550 (epoch 20.033), train_loss = 0.64399560, grad/param norm = 7.6093e-02, time/batch = 0.1802s	
4228/10550 (epoch 20.038), train_loss = 0.62619378, grad/param norm = 7.4852e-02, time/batch = 0.1795s	
4229/10550 (epoch 20.043), train_loss = 0.60359938, grad/param norm = 7.2067e-02, time/batch = 0.1801s	
4230/10550 (epoch 20.047), train_loss = 0.59954441, grad/param norm = 7.1438e-02, time/batch = 0.1801s	
4231/10550 (epoch 20.052), train_loss = 0.62176293, grad/param norm = 7.3407e-02, time/batch = 0.1811s	
4232/10550 (epoch 20.057), train_loss = 0.61049598, grad/param norm = 7.4651e-02, time/batch = 0.1794s	
4233/10550 (epoch 20.062), train_loss = 0.62582493, grad/param norm = 7.4690e-02, time/batch = 0.1796s	
4234/10550 (epoch 20.066), train_loss = 0.61522191, grad/param norm = 7.2339e-02, time/batch = 0.1796s	
4235/10550 (epoch 20.071), train_loss = 0.59856756, grad/param norm = 7.4647e-02, time/batch = 0.1800s	
4236/10550 (epoch 20.076), train_loss = 0.61932629, grad/param norm = 7.8701e-02, time/batch = 0.1793s	
4237/10550 (epoch 20.081), train_loss = 0.62816814, grad/param norm = 7.7309e-02, time/batch = 0.1797s	
4238/10550 (epoch 20.085), train_loss = 0.61415520, grad/param norm = 7.4167e-02, time/batch = 0.1793s	
4239/10550 (epoch 20.090), train_loss = 0.60578943, grad/param norm = 7.3821e-02, time/batch = 0.1794s	
4240/10550 (epoch 20.095), train_loss = 0.63364895, grad/param norm = 7.1620e-02, time/batch = 0.1801s	
4241/10550 (epoch 20.100), train_loss = 0.61002648, grad/param norm = 7.3630e-02, time/batch = 0.1807s	
4242/10550 (epoch 20.104), train_loss = 0.61183408, grad/param norm = 7.2967e-02, time/batch = 0.1788s	
4243/10550 (epoch 20.109), train_loss = 0.60284074, grad/param norm = 7.3314e-02, time/batch = 0.1803s	
4244/10550 (epoch 20.114), train_loss = 0.62130433, grad/param norm = 7.5298e-02, time/batch = 0.1802s	
4245/10550 (epoch 20.118), train_loss = 0.60030412, grad/param norm = 7.2238e-02, time/batch = 0.1802s	
4246/10550 (epoch 20.123), train_loss = 0.63184486, grad/param norm = 7.5217e-02, time/batch = 0.1802s	
4247/10550 (epoch 20.128), train_loss = 0.60458288, grad/param norm = 7.2990e-02, time/batch = 0.1801s	
4248/10550 (epoch 20.133), train_loss = 0.58555437, grad/param norm = 7.3267e-02, time/batch = 0.1792s	
4249/10550 (epoch 20.137), train_loss = 0.61369010, grad/param norm = 7.7352e-02, time/batch = 0.1802s	
4250/10550 (epoch 20.142), train_loss = 0.63589546, grad/param norm = 8.0768e-02, time/batch = 0.1804s	
4251/10550 (epoch 20.147), train_loss = 0.60473508, grad/param norm = 7.4615e-02, time/batch = 0.1811s	
4252/10550 (epoch 20.152), train_loss = 0.62670648, grad/param norm = 7.4960e-02, time/batch = 0.1793s	
4253/10550 (epoch 20.156), train_loss = 0.60222509, grad/param norm = 7.3094e-02, time/batch = 0.1796s	
4254/10550 (epoch 20.161), train_loss = 0.60939293, grad/param norm = 7.3413e-02, time/batch = 0.1802s	
4255/10550 (epoch 20.166), train_loss = 0.62861970, grad/param norm = 7.5947e-02, time/batch = 0.1798s	
4256/10550 (epoch 20.171), train_loss = 0.59721542, grad/param norm = 7.1635e-02, time/batch = 0.1797s	
4257/10550 (epoch 20.175), train_loss = 0.60800777, grad/param norm = 7.4798e-02, time/batch = 0.1797s	
4258/10550 (epoch 20.180), train_loss = 0.59329205, grad/param norm = 7.2985e-02, time/batch = 0.1796s	
4259/10550 (epoch 20.185), train_loss = 0.62435330, grad/param norm = 7.4719e-02, time/batch = 0.1800s	
4260/10550 (epoch 20.190), train_loss = 0.58838274, grad/param norm = 7.7483e-02, time/batch = 0.1796s	
4261/10550 (epoch 20.194), train_loss = 0.60721210, grad/param norm = 7.5371e-02, time/batch = 0.1812s	
4262/10550 (epoch 20.199), train_loss = 0.64383968, grad/param norm = 7.9817e-02, time/batch = 0.1793s	
4263/10550 (epoch 20.204), train_loss = 0.60670065, grad/param norm = 7.6693e-02, time/batch = 0.1799s	
4264/10550 (epoch 20.209), train_loss = 0.61613309, grad/param norm = 7.4456e-02, time/batch = 0.1796s	
4265/10550 (epoch 20.213), train_loss = 0.63498698, grad/param norm = 7.6334e-02, time/batch = 0.1798s	
4266/10550 (epoch 20.218), train_loss = 0.61342483, grad/param norm = 7.1155e-02, time/batch = 0.1799s	
4267/10550 (epoch 20.223), train_loss = 0.59606803, grad/param norm = 7.1794e-02, time/batch = 0.1798s	
4268/10550 (epoch 20.227), train_loss = 0.58390388, grad/param norm = 6.9522e-02, time/batch = 0.1797s	
4269/10550 (epoch 20.232), train_loss = 0.59343326, grad/param norm = 7.5207e-02, time/batch = 0.1800s	
4270/10550 (epoch 20.237), train_loss = 0.59992128, grad/param norm = 7.2449e-02, time/batch = 0.1798s	
4271/10550 (epoch 20.242), train_loss = 0.59466986, grad/param norm = 7.6337e-02, time/batch = 0.1810s	
4272/10550 (epoch 20.246), train_loss = 0.58216386, grad/param norm = 7.0058e-02, time/batch = 0.1793s	
4273/10550 (epoch 20.251), train_loss = 0.60944134, grad/param norm = 7.1112e-02, time/batch = 0.1798s	
4274/10550 (epoch 20.256), train_loss = 0.61920162, grad/param norm = 7.3000e-02, time/batch = 0.1799s	
4275/10550 (epoch 20.261), train_loss = 0.59127177, grad/param norm = 6.9945e-02, time/batch = 0.1796s	
4276/10550 (epoch 20.265), train_loss = 0.58499854, grad/param norm = 7.4306e-02, time/batch = 0.1800s	
4277/10550 (epoch 20.270), train_loss = 0.60587442, grad/param norm = 7.3675e-02, time/batch = 0.1799s	
4278/10550 (epoch 20.275), train_loss = 0.61462248, grad/param norm = 7.1049e-02, time/batch = 0.1793s	
4279/10550 (epoch 20.280), train_loss = 0.60766346, grad/param norm = 7.5875e-02, time/batch = 0.1800s	
4280/10550 (epoch 20.284), train_loss = 0.59986692, grad/param norm = 7.4874e-02, time/batch = 0.1796s	
4281/10550 (epoch 20.289), train_loss = 0.61380166, grad/param norm = 7.6909e-02, time/batch = 0.1810s	
4282/10550 (epoch 20.294), train_loss = 0.59914487, grad/param norm = 7.7992e-02, time/batch = 0.1791s	
4283/10550 (epoch 20.299), train_loss = 0.57850625, grad/param norm = 7.2461e-02, time/batch = 0.1797s	
4284/10550 (epoch 20.303), train_loss = 0.61497836, grad/param norm = 7.4833e-02, time/batch = 0.1787s	
4285/10550 (epoch 20.308), train_loss = 0.59015708, grad/param norm = 7.0442e-02, time/batch = 0.1799s	
4286/10550 (epoch 20.313), train_loss = 0.58271662, grad/param norm = 7.1822e-02, time/batch = 0.1795s	
4287/10550 (epoch 20.318), train_loss = 0.59232551, grad/param norm = 7.0655e-02, time/batch = 0.1801s	
4288/10550 (epoch 20.322), train_loss = 0.60718540, grad/param norm = 7.9582e-02, time/batch = 0.1793s	
4289/10550 (epoch 20.327), train_loss = 0.60347687, grad/param norm = 7.7456e-02, time/batch = 0.1800s	
4290/10550 (epoch 20.332), train_loss = 0.62317710, grad/param norm = 7.6483e-02, time/batch = 0.1801s	
4291/10550 (epoch 20.336), train_loss = 0.58660844, grad/param norm = 7.3650e-02, time/batch = 0.1813s	
4292/10550 (epoch 20.341), train_loss = 0.58998604, grad/param norm = 7.5893e-02, time/batch = 0.1794s	
4293/10550 (epoch 20.346), train_loss = 0.60501352, grad/param norm = 7.6871e-02, time/batch = 0.1798s	
4294/10550 (epoch 20.351), train_loss = 0.60380154, grad/param norm = 7.5247e-02, time/batch = 0.1797s	
4295/10550 (epoch 20.355), train_loss = 0.60758081, grad/param norm = 7.4010e-02, time/batch = 0.1801s	
4296/10550 (epoch 20.360), train_loss = 0.62137872, grad/param norm = 7.8120e-02, time/batch = 0.1794s	
4297/10550 (epoch 20.365), train_loss = 0.60124020, grad/param norm = 7.3565e-02, time/batch = 0.1795s	
4298/10550 (epoch 20.370), train_loss = 0.58905127, grad/param norm = 7.1861e-02, time/batch = 0.1801s	
4299/10550 (epoch 20.374), train_loss = 0.59820391, grad/param norm = 7.2910e-02, time/batch = 0.1799s	
4300/10550 (epoch 20.379), train_loss = 0.61611431, grad/param norm = 7.6640e-02, time/batch = 0.1796s	
4301/10550 (epoch 20.384), train_loss = 0.59530029, grad/param norm = 7.6815e-02, time/batch = 0.1813s	
4302/10550 (epoch 20.389), train_loss = 0.59915324, grad/param norm = 7.4372e-02, time/batch = 0.1792s	
4303/10550 (epoch 20.393), train_loss = 0.60417268, grad/param norm = 7.5051e-02, time/batch = 0.1796s	
4304/10550 (epoch 20.398), train_loss = 0.58987194, grad/param norm = 7.3031e-02, time/batch = 0.1802s	
4305/10550 (epoch 20.403), train_loss = 0.59322055, grad/param norm = 7.3863e-02, time/batch = 0.1802s	
4306/10550 (epoch 20.408), train_loss = 0.60642831, grad/param norm = 7.6326e-02, time/batch = 0.1798s	
4307/10550 (epoch 20.412), train_loss = 0.60030438, grad/param norm = 7.5307e-02, time/batch = 0.1806s	
4308/10550 (epoch 20.417), train_loss = 0.60025002, grad/param norm = 7.6587e-02, time/batch = 0.1795s	
4309/10550 (epoch 20.422), train_loss = 0.61701317, grad/param norm = 8.0550e-02, time/batch = 0.1803s	
4310/10550 (epoch 20.427), train_loss = 0.60026270, grad/param norm = 7.5594e-02, time/batch = 0.1797s	
4311/10550 (epoch 20.431), train_loss = 0.60134472, grad/param norm = 7.6162e-02, time/batch = 0.1811s	
4312/10550 (epoch 20.436), train_loss = 0.58616341, grad/param norm = 7.5045e-02, time/batch = 0.1795s	
4313/10550 (epoch 20.441), train_loss = 0.59944407, grad/param norm = 7.2881e-02, time/batch = 0.1798s	
4314/10550 (epoch 20.445), train_loss = 0.59955296, grad/param norm = 7.3730e-02, time/batch = 0.1803s	
4315/10550 (epoch 20.450), train_loss = 0.59401859, grad/param norm = 7.2668e-02, time/batch = 0.1802s	
4316/10550 (epoch 20.455), train_loss = 0.59990133, grad/param norm = 7.7325e-02, time/batch = 0.1801s	
4317/10550 (epoch 20.460), train_loss = 0.58259892, grad/param norm = 7.2912e-02, time/batch = 0.1799s	
4318/10550 (epoch 20.464), train_loss = 0.61445064, grad/param norm = 7.4107e-02, time/batch = 0.1795s	
4319/10550 (epoch 20.469), train_loss = 0.59834606, grad/param norm = 7.3173e-02, time/batch = 0.1799s	
4320/10550 (epoch 20.474), train_loss = 0.59096564, grad/param norm = 7.4639e-02, time/batch = 0.1805s	
4321/10550 (epoch 20.479), train_loss = 0.57448713, grad/param norm = 7.2407e-02, time/batch = 0.1812s	
4322/10550 (epoch 20.483), train_loss = 0.58089451, grad/param norm = 7.6296e-02, time/batch = 0.1796s	
4323/10550 (epoch 20.488), train_loss = 0.59757925, grad/param norm = 7.6732e-02, time/batch = 0.1799s	
4324/10550 (epoch 20.493), train_loss = 0.57170061, grad/param norm = 7.0152e-02, time/batch = 0.1798s	
4325/10550 (epoch 20.498), train_loss = 0.60884465, grad/param norm = 7.1903e-02, time/batch = 0.1801s	
4326/10550 (epoch 20.502), train_loss = 0.59824279, grad/param norm = 7.2321e-02, time/batch = 0.1803s	
4327/10550 (epoch 20.507), train_loss = 0.59095593, grad/param norm = 7.5378e-02, time/batch = 0.1799s	
4328/10550 (epoch 20.512), train_loss = 0.57506989, grad/param norm = 7.1998e-02, time/batch = 0.1792s	
4329/10550 (epoch 20.517), train_loss = 0.58827502, grad/param norm = 7.2942e-02, time/batch = 0.1801s	
4330/10550 (epoch 20.521), train_loss = 0.58915999, grad/param norm = 7.5563e-02, time/batch = 0.1802s	
4331/10550 (epoch 20.526), train_loss = 0.56274797, grad/param norm = 7.1667e-02, time/batch = 0.1811s	
4332/10550 (epoch 20.531), train_loss = 0.55917552, grad/param norm = 7.5185e-02, time/batch = 0.1795s	
4333/10550 (epoch 20.536), train_loss = 0.61285987, grad/param norm = 7.5866e-02, time/batch = 0.1800s	
4334/10550 (epoch 20.540), train_loss = 0.59892368, grad/param norm = 7.6861e-02, time/batch = 0.1797s	
4335/10550 (epoch 20.545), train_loss = 0.58956876, grad/param norm = 7.3173e-02, time/batch = 0.1807s	
4336/10550 (epoch 20.550), train_loss = 0.59983433, grad/param norm = 7.2937e-02, time/batch = 0.1795s	
4337/10550 (epoch 20.555), train_loss = 0.59159153, grad/param norm = 7.2317e-02, time/batch = 0.1799s	
4338/10550 (epoch 20.559), train_loss = 0.58477847, grad/param norm = 7.3322e-02, time/batch = 0.1797s	
4339/10550 (epoch 20.564), train_loss = 0.56438312, grad/param norm = 7.2105e-02, time/batch = 0.1800s	
4340/10550 (epoch 20.569), train_loss = 0.57906797, grad/param norm = 7.2188e-02, time/batch = 0.1797s	
4341/10550 (epoch 20.573), train_loss = 0.60125837, grad/param norm = 7.5397e-02, time/batch = 0.1808s	
4342/10550 (epoch 20.578), train_loss = 0.57478174, grad/param norm = 7.2552e-02, time/batch = 0.1793s	
4343/10550 (epoch 20.583), train_loss = 0.58037696, grad/param norm = 7.1504e-02, time/batch = 0.1797s	
4344/10550 (epoch 20.588), train_loss = 0.56995529, grad/param norm = 7.3739e-02, time/batch = 0.1797s	
4345/10550 (epoch 20.592), train_loss = 0.58437981, grad/param norm = 7.4400e-02, time/batch = 0.1806s	
4346/10550 (epoch 20.597), train_loss = 0.58287321, grad/param norm = 7.4991e-02, time/batch = 0.1801s	
4347/10550 (epoch 20.602), train_loss = 0.59238865, grad/param norm = 7.4586e-02, time/batch = 0.1796s	
4348/10550 (epoch 20.607), train_loss = 0.58804960, grad/param norm = 7.3733e-02, time/batch = 0.1797s	
4349/10550 (epoch 20.611), train_loss = 0.56830021, grad/param norm = 7.6394e-02, time/batch = 0.1799s	
4350/10550 (epoch 20.616), train_loss = 0.58031721, grad/param norm = 7.5463e-02, time/batch = 0.1797s	
4351/10550 (epoch 20.621), train_loss = 0.58485988, grad/param norm = 7.4226e-02, time/batch = 0.1812s	
4352/10550 (epoch 20.626), train_loss = 0.58857659, grad/param norm = 7.9339e-02, time/batch = 0.1794s	
4353/10550 (epoch 20.630), train_loss = 0.59446929, grad/param norm = 7.7888e-02, time/batch = 0.1796s	
4354/10550 (epoch 20.635), train_loss = 0.61566492, grad/param norm = 7.8938e-02, time/batch = 0.1801s	
4355/10550 (epoch 20.640), train_loss = 0.61616413, grad/param norm = 7.4584e-02, time/batch = 0.1795s	
4356/10550 (epoch 20.645), train_loss = 0.60142937, grad/param norm = 7.8163e-02, time/batch = 0.1799s	
4357/10550 (epoch 20.649), train_loss = 0.61719467, grad/param norm = 7.9605e-02, time/batch = 0.1807s	
4358/10550 (epoch 20.654), train_loss = 0.60408938, grad/param norm = 7.3776e-02, time/batch = 0.1797s	
4359/10550 (epoch 20.659), train_loss = 0.58734937, grad/param norm = 7.2697e-02, time/batch = 0.1802s	
4360/10550 (epoch 20.664), train_loss = 0.58011273, grad/param norm = 7.4044e-02, time/batch = 0.1799s	
4361/10550 (epoch 20.668), train_loss = 0.56662287, grad/param norm = 7.2972e-02, time/batch = 0.1811s	
4362/10550 (epoch 20.673), train_loss = 0.58062238, grad/param norm = 7.7348e-02, time/batch = 0.1800s	
4363/10550 (epoch 20.678), train_loss = 0.57005361, grad/param norm = 7.2044e-02, time/batch = 0.1797s	
4364/10550 (epoch 20.682), train_loss = 0.58438095, grad/param norm = 7.5335e-02, time/batch = 0.1795s	
4365/10550 (epoch 20.687), train_loss = 0.57607216, grad/param norm = 7.4640e-02, time/batch = 0.1803s	
4366/10550 (epoch 20.692), train_loss = 0.58986613, grad/param norm = 7.4580e-02, time/batch = 0.1799s	
4367/10550 (epoch 20.697), train_loss = 0.57343171, grad/param norm = 7.2574e-02, time/batch = 0.1796s	
4368/10550 (epoch 20.701), train_loss = 0.58108624, grad/param norm = 7.5079e-02, time/batch = 0.1792s	
4369/10550 (epoch 20.706), train_loss = 0.56141737, grad/param norm = 7.7012e-02, time/batch = 0.1801s	
4370/10550 (epoch 20.711), train_loss = 0.58894208, grad/param norm = 7.2448e-02, time/batch = 0.1802s	
4371/10550 (epoch 20.716), train_loss = 0.58044105, grad/param norm = 7.5185e-02, time/batch = 0.1811s	
4372/10550 (epoch 20.720), train_loss = 0.60317187, grad/param norm = 7.5386e-02, time/batch = 0.1793s	
4373/10550 (epoch 20.725), train_loss = 0.57103492, grad/param norm = 7.3184e-02, time/batch = 0.1797s	
4374/10550 (epoch 20.730), train_loss = 0.54844217, grad/param norm = 7.4004e-02, time/batch = 0.1795s	
4375/10550 (epoch 20.735), train_loss = 0.56820331, grad/param norm = 7.3747e-02, time/batch = 0.1804s	
4376/10550 (epoch 20.739), train_loss = 0.57693519, grad/param norm = 7.4469e-02, time/batch = 0.1798s	
4377/10550 (epoch 20.744), train_loss = 0.57017489, grad/param norm = 7.3444e-02, time/batch = 0.1794s	
4378/10550 (epoch 20.749), train_loss = 0.61950064, grad/param norm = 7.7676e-02, time/batch = 0.1798s	
4379/10550 (epoch 20.754), train_loss = 0.59334915, grad/param norm = 7.3690e-02, time/batch = 0.1807s	
4380/10550 (epoch 20.758), train_loss = 0.56391780, grad/param norm = 7.2641e-02, time/batch = 0.1796s	
4381/10550 (epoch 20.763), train_loss = 0.55969904, grad/param norm = 7.6715e-02, time/batch = 0.1808s	
4382/10550 (epoch 20.768), train_loss = 0.57646323, grad/param norm = 7.4702e-02, time/batch = 0.1799s	
4383/10550 (epoch 20.773), train_loss = 0.60379378, grad/param norm = 7.5825e-02, time/batch = 0.1799s	
4384/10550 (epoch 20.777), train_loss = 0.58740625, grad/param norm = 7.4718e-02, time/batch = 0.1801s	
4385/10550 (epoch 20.782), train_loss = 0.61310661, grad/param norm = 7.7378e-02, time/batch = 0.1794s	
4386/10550 (epoch 20.787), train_loss = 0.58629336, grad/param norm = 7.7604e-02, time/batch = 0.1797s	
4387/10550 (epoch 20.791), train_loss = 0.56891213, grad/param norm = 7.4259e-02, time/batch = 0.1800s	
4388/10550 (epoch 20.796), train_loss = 0.59632387, grad/param norm = 7.4987e-02, time/batch = 0.1791s	
4389/10550 (epoch 20.801), train_loss = 0.59208959, grad/param norm = 8.0759e-02, time/batch = 0.1803s	
4390/10550 (epoch 20.806), train_loss = 0.59141998, grad/param norm = 7.9108e-02, time/batch = 0.1800s	
4391/10550 (epoch 20.810), train_loss = 0.60549903, grad/param norm = 7.7939e-02, time/batch = 0.1812s	
4392/10550 (epoch 20.815), train_loss = 0.58236139, grad/param norm = 7.5164e-02, time/batch = 0.1794s	
4393/10550 (epoch 20.820), train_loss = 0.58836213, grad/param norm = 7.5923e-02, time/batch = 0.1799s	
4394/10550 (epoch 20.825), train_loss = 0.59850319, grad/param norm = 7.3197e-02, time/batch = 0.1802s	
4395/10550 (epoch 20.829), train_loss = 0.59170449, grad/param norm = 7.4067e-02, time/batch = 0.1802s	
4396/10550 (epoch 20.834), train_loss = 0.57192462, grad/param norm = 7.5855e-02, time/batch = 0.1799s	
4397/10550 (epoch 20.839), train_loss = 0.57037627, grad/param norm = 7.1440e-02, time/batch = 0.1800s	
4398/10550 (epoch 20.844), train_loss = 0.59438345, grad/param norm = 7.7294e-02, time/batch = 0.1794s	
4399/10550 (epoch 20.848), train_loss = 0.58402699, grad/param norm = 7.6599e-02, time/batch = 0.1801s	
4400/10550 (epoch 20.853), train_loss = 0.59398132, grad/param norm = 7.5229e-02, time/batch = 0.1803s	
4401/10550 (epoch 20.858), train_loss = 0.61735260, grad/param norm = 7.7077e-02, time/batch = 0.1809s	
4402/10550 (epoch 20.863), train_loss = 0.58822390, grad/param norm = 7.8087e-02, time/batch = 0.1796s	
4403/10550 (epoch 20.867), train_loss = 0.59959461, grad/param norm = 7.8880e-02, time/batch = 0.1799s	
4404/10550 (epoch 20.872), train_loss = 0.60024584, grad/param norm = 7.6845e-02, time/batch = 0.1799s	
4405/10550 (epoch 20.877), train_loss = 0.56938070, grad/param norm = 7.2471e-02, time/batch = 0.1801s	
4406/10550 (epoch 20.882), train_loss = 0.56823479, grad/param norm = 7.3766e-02, time/batch = 0.1799s	
4407/10550 (epoch 20.886), train_loss = 0.57786965, grad/param norm = 7.5113e-02, time/batch = 0.1797s	
4408/10550 (epoch 20.891), train_loss = 0.57537001, grad/param norm = 7.4259e-02, time/batch = 0.1794s	
4409/10550 (epoch 20.896), train_loss = 0.58702346, grad/param norm = 7.5462e-02, time/batch = 0.1803s	
4410/10550 (epoch 20.900), train_loss = 0.58929695, grad/param norm = 7.4911e-02, time/batch = 0.1794s	
4411/10550 (epoch 20.905), train_loss = 0.56735592, grad/param norm = 7.5262e-02, time/batch = 0.1812s	
4412/10550 (epoch 20.910), train_loss = 0.57629931, grad/param norm = 7.8928e-02, time/batch = 0.1794s	
4413/10550 (epoch 20.915), train_loss = 0.58044425, grad/param norm = 7.5650e-02, time/batch = 0.1803s	
4414/10550 (epoch 20.919), train_loss = 0.58969416, grad/param norm = 7.7288e-02, time/batch = 0.1799s	
4415/10550 (epoch 20.924), train_loss = 0.58876480, grad/param norm = 7.9107e-02, time/batch = 0.1800s	
4416/10550 (epoch 20.929), train_loss = 0.59855663, grad/param norm = 7.6445e-02, time/batch = 0.1797s	
4417/10550 (epoch 20.934), train_loss = 0.56268047, grad/param norm = 7.4303e-02, time/batch = 0.1802s	
4418/10550 (epoch 20.938), train_loss = 0.60794069, grad/param norm = 7.7710e-02, time/batch = 0.1797s	
4419/10550 (epoch 20.943), train_loss = 0.59255508, grad/param norm = 7.4429e-02, time/batch = 0.1807s	
4420/10550 (epoch 20.948), train_loss = 0.58391868, grad/param norm = 7.5492e-02, time/batch = 0.1801s	
4421/10550 (epoch 20.953), train_loss = 0.60208479, grad/param norm = 7.7836e-02, time/batch = 0.1808s	
4422/10550 (epoch 20.957), train_loss = 0.59392357, grad/param norm = 7.5481e-02, time/batch = 0.1796s	
4423/10550 (epoch 20.962), train_loss = 0.61554697, grad/param norm = 7.6459e-02, time/batch = 0.1801s	
4424/10550 (epoch 20.967), train_loss = 0.61083945, grad/param norm = 7.7070e-02, time/batch = 0.1803s	
4425/10550 (epoch 20.972), train_loss = 0.59484059, grad/param norm = 7.7281e-02, time/batch = 0.1798s	
4426/10550 (epoch 20.976), train_loss = 0.57918562, grad/param norm = 7.6583e-02, time/batch = 0.1799s	
4427/10550 (epoch 20.981), train_loss = 0.58100011, grad/param norm = 7.6318e-02, time/batch = 0.1798s	
4428/10550 (epoch 20.986), train_loss = 0.58745033, grad/param norm = 7.4804e-02, time/batch = 0.1800s	
4429/10550 (epoch 20.991), train_loss = 0.60869906, grad/param norm = 7.7876e-02, time/batch = 0.1800s	
4430/10550 (epoch 20.995), train_loss = 0.58619697, grad/param norm = 7.4387e-02, time/batch = 0.1801s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
4431/10550 (epoch 21.000), train_loss = 0.58928495, grad/param norm = 7.2912e-02, time/batch = 0.1809s	
4432/10550 (epoch 21.005), train_loss = 0.77431388, grad/param norm = 8.1110e-02, time/batch = 0.1797s	
4433/10550 (epoch 21.009), train_loss = 0.59040355, grad/param norm = 7.3872e-02, time/batch = 0.1801s	
4434/10550 (epoch 21.014), train_loss = 0.59897100, grad/param norm = 7.5067e-02, time/batch = 0.1798s	
4435/10550 (epoch 21.019), train_loss = 0.62037090, grad/param norm = 7.4843e-02, time/batch = 0.1800s	
4436/10550 (epoch 21.024), train_loss = 0.59547494, grad/param norm = 7.3563e-02, time/batch = 0.1796s	
4437/10550 (epoch 21.028), train_loss = 0.58903363, grad/param norm = 7.6664e-02, time/batch = 0.1799s	
4438/10550 (epoch 21.033), train_loss = 0.60057677, grad/param norm = 7.4649e-02, time/batch = 0.1795s	
4439/10550 (epoch 21.038), train_loss = 0.57800351, grad/param norm = 7.3806e-02, time/batch = 0.1799s	
4440/10550 (epoch 21.043), train_loss = 0.56905553, grad/param norm = 7.2045e-02, time/batch = 0.1797s	
4441/10550 (epoch 21.047), train_loss = 0.57092268, grad/param norm = 7.2817e-02, time/batch = 0.1812s	
4442/10550 (epoch 21.052), train_loss = 0.58470187, grad/param norm = 7.3081e-02, time/batch = 0.1793s	
4443/10550 (epoch 21.057), train_loss = 0.58792551, grad/param norm = 7.4555e-02, time/batch = 0.1801s	
4444/10550 (epoch 21.062), train_loss = 0.60094148, grad/param norm = 7.5700e-02, time/batch = 0.1801s	
4445/10550 (epoch 21.066), train_loss = 0.58794417, grad/param norm = 7.4850e-02, time/batch = 0.1799s	
4446/10550 (epoch 21.071), train_loss = 0.57320223, grad/param norm = 7.2927e-02, time/batch = 0.1793s	
4447/10550 (epoch 21.076), train_loss = 0.58855847, grad/param norm = 7.5947e-02, time/batch = 0.1797s	
4448/10550 (epoch 21.081), train_loss = 0.59577923, grad/param norm = 7.6674e-02, time/batch = 0.1798s	
4449/10550 (epoch 21.085), train_loss = 0.57905499, grad/param norm = 7.4844e-02, time/batch = 0.1801s	
4450/10550 (epoch 21.090), train_loss = 0.57942567, grad/param norm = 7.6650e-02, time/batch = 0.1797s	
4451/10550 (epoch 21.095), train_loss = 0.59947667, grad/param norm = 7.4101e-02, time/batch = 0.1809s	
4452/10550 (epoch 21.100), train_loss = 0.58685910, grad/param norm = 7.5529e-02, time/batch = 0.1791s	
4453/10550 (epoch 21.104), train_loss = 0.58107781, grad/param norm = 7.4277e-02, time/batch = 0.1799s	
4454/10550 (epoch 21.109), train_loss = 0.57352522, grad/param norm = 7.5193e-02, time/batch = 0.1796s	
4455/10550 (epoch 21.114), train_loss = 0.58365706, grad/param norm = 7.8349e-02, time/batch = 0.1803s	
4456/10550 (epoch 21.118), train_loss = 0.57987210, grad/param norm = 7.4462e-02, time/batch = 0.1796s	
4457/10550 (epoch 21.123), train_loss = 0.59583834, grad/param norm = 7.6284e-02, time/batch = 0.1796s	
4458/10550 (epoch 21.128), train_loss = 0.58397824, grad/param norm = 7.6871e-02, time/batch = 0.1800s	
4459/10550 (epoch 21.133), train_loss = 0.56397412, grad/param norm = 7.5530e-02, time/batch = 0.1797s	
4460/10550 (epoch 21.137), train_loss = 0.56991371, grad/param norm = 7.4586e-02, time/batch = 0.1800s	
4461/10550 (epoch 21.142), train_loss = 0.60165335, grad/param norm = 8.2727e-02, time/batch = 0.1808s	
4462/10550 (epoch 21.147), train_loss = 0.57483543, grad/param norm = 7.4505e-02, time/batch = 0.1795s	
4463/10550 (epoch 21.152), train_loss = 0.59999157, grad/param norm = 7.7631e-02, time/batch = 0.1798s	
4464/10550 (epoch 21.156), train_loss = 0.57847935, grad/param norm = 7.4734e-02, time/batch = 0.1798s	
4465/10550 (epoch 21.161), train_loss = 0.58775390, grad/param norm = 7.5765e-02, time/batch = 0.1800s	
4466/10550 (epoch 21.166), train_loss = 0.59709975, grad/param norm = 7.3695e-02, time/batch = 0.1797s	
4467/10550 (epoch 21.171), train_loss = 0.56338308, grad/param norm = 7.2043e-02, time/batch = 0.1803s	
4468/10550 (epoch 21.175), train_loss = 0.57462279, grad/param norm = 7.2054e-02, time/batch = 0.1791s	
4469/10550 (epoch 21.180), train_loss = 0.56018093, grad/param norm = 7.4854e-02, time/batch = 0.1801s	
4470/10550 (epoch 21.185), train_loss = 0.57838859, grad/param norm = 7.3844e-02, time/batch = 0.1801s	
4471/10550 (epoch 21.190), train_loss = 0.54935494, grad/param norm = 7.5852e-02, time/batch = 0.1812s	
4472/10550 (epoch 21.194), train_loss = 0.57087453, grad/param norm = 7.5700e-02, time/batch = 0.1792s	
4473/10550 (epoch 21.199), train_loss = 0.60321357, grad/param norm = 7.7589e-02, time/batch = 0.1802s	
4474/10550 (epoch 21.204), train_loss = 0.57817172, grad/param norm = 7.8606e-02, time/batch = 0.1806s	
4475/10550 (epoch 21.209), train_loss = 0.59813479, grad/param norm = 7.9272e-02, time/batch = 0.1799s	
4476/10550 (epoch 21.213), train_loss = 0.61216077, grad/param norm = 7.9708e-02, time/batch = 0.1800s	
4477/10550 (epoch 21.218), train_loss = 0.59557838, grad/param norm = 7.6125e-02, time/batch = 0.1800s	
4478/10550 (epoch 21.223), train_loss = 0.57900275, grad/param norm = 7.4914e-02, time/batch = 0.1791s	
4479/10550 (epoch 21.227), train_loss = 0.56391997, grad/param norm = 7.2021e-02, time/batch = 0.1804s	
4480/10550 (epoch 21.232), train_loss = 0.56856701, grad/param norm = 7.4837e-02, time/batch = 0.1799s	
4481/10550 (epoch 21.237), train_loss = 0.57376189, grad/param norm = 7.6328e-02, time/batch = 0.1814s	
4482/10550 (epoch 21.242), train_loss = 0.56969183, grad/param norm = 7.6514e-02, time/batch = 0.1793s	
4483/10550 (epoch 21.246), train_loss = 0.55544590, grad/param norm = 7.3690e-02, time/batch = 0.1798s	
4484/10550 (epoch 21.251), train_loss = 0.57257671, grad/param norm = 7.2934e-02, time/batch = 0.1801s	
4485/10550 (epoch 21.256), train_loss = 0.59146749, grad/param norm = 7.4581e-02, time/batch = 0.1799s	
4486/10550 (epoch 21.261), train_loss = 0.56807365, grad/param norm = 7.0741e-02, time/batch = 0.1798s	
4487/10550 (epoch 21.265), train_loss = 0.55405928, grad/param norm = 7.5389e-02, time/batch = 0.1799s	
4488/10550 (epoch 21.270), train_loss = 0.56477056, grad/param norm = 7.5410e-02, time/batch = 0.1798s	
4489/10550 (epoch 21.275), train_loss = 0.57231451, grad/param norm = 7.2993e-02, time/batch = 0.1803s	
4490/10550 (epoch 21.280), train_loss = 0.57371202, grad/param norm = 7.6764e-02, time/batch = 0.1800s	
4491/10550 (epoch 21.284), train_loss = 0.57300930, grad/param norm = 7.5853e-02, time/batch = 0.1811s	
4492/10550 (epoch 21.289), train_loss = 0.56793022, grad/param norm = 7.3472e-02, time/batch = 0.1793s	
4493/10550 (epoch 21.294), train_loss = 0.55686631, grad/param norm = 7.4346e-02, time/batch = 0.1798s	
4494/10550 (epoch 21.299), train_loss = 0.54898074, grad/param norm = 7.1841e-02, time/batch = 0.1796s	
4495/10550 (epoch 21.303), train_loss = 0.58983573, grad/param norm = 7.6076e-02, time/batch = 0.1797s	
4496/10550 (epoch 21.308), train_loss = 0.56445449, grad/param norm = 7.2245e-02, time/batch = 0.1803s	
4497/10550 (epoch 21.313), train_loss = 0.54429918, grad/param norm = 7.0982e-02, time/batch = 0.1799s	
4498/10550 (epoch 21.318), train_loss = 0.57052564, grad/param norm = 7.6252e-02, time/batch = 0.1796s	
4499/10550 (epoch 21.322), train_loss = 0.56879543, grad/param norm = 7.2269e-02, time/batch = 0.1799s	
4500/10550 (epoch 21.327), train_loss = 0.57803445, grad/param norm = 7.7716e-02, time/batch = 0.1800s	
4501/10550 (epoch 21.332), train_loss = 0.60084158, grad/param norm = 7.8239e-02, time/batch = 0.1806s	
4502/10550 (epoch 21.336), train_loss = 0.57231443, grad/param norm = 7.8426e-02, time/batch = 0.1794s	
4503/10550 (epoch 21.341), train_loss = 0.54941095, grad/param norm = 7.3838e-02, time/batch = 0.1797s	
4504/10550 (epoch 21.346), train_loss = 0.57547625, grad/param norm = 7.5303e-02, time/batch = 0.1801s	
4505/10550 (epoch 21.351), train_loss = 0.57502562, grad/param norm = 7.6005e-02, time/batch = 0.1797s	
4506/10550 (epoch 21.355), train_loss = 0.57214539, grad/param norm = 7.4274e-02, time/batch = 0.1799s	
4507/10550 (epoch 21.360), train_loss = 0.59165314, grad/param norm = 7.7901e-02, time/batch = 0.1803s	
4508/10550 (epoch 21.365), train_loss = 0.56557405, grad/param norm = 7.7359e-02, time/batch = 0.1794s	
4509/10550 (epoch 21.370), train_loss = 0.56175979, grad/param norm = 7.5853e-02, time/batch = 0.1800s	
4510/10550 (epoch 21.374), train_loss = 0.56836817, grad/param norm = 7.5539e-02, time/batch = 0.1797s	
4511/10550 (epoch 21.379), train_loss = 0.58697752, grad/param norm = 7.7480e-02, time/batch = 0.1813s	
4512/10550 (epoch 21.384), train_loss = 0.56710287, grad/param norm = 7.6343e-02, time/batch = 0.1797s	
4513/10550 (epoch 21.389), train_loss = 0.57862914, grad/param norm = 7.6928e-02, time/batch = 0.1795s	
4514/10550 (epoch 21.393), train_loss = 0.55929157, grad/param norm = 7.1544e-02, time/batch = 0.1798s	
4515/10550 (epoch 21.398), train_loss = 0.55960696, grad/param norm = 7.3151e-02, time/batch = 0.1797s	
4516/10550 (epoch 21.403), train_loss = 0.57449657, grad/param norm = 7.6580e-02, time/batch = 0.1793s	
4517/10550 (epoch 21.408), train_loss = 0.57658034, grad/param norm = 7.7643e-02, time/batch = 0.1795s	
4518/10550 (epoch 21.412), train_loss = 0.57079863, grad/param norm = 7.5478e-02, time/batch = 0.1796s	
4519/10550 (epoch 21.417), train_loss = 0.57267217, grad/param norm = 7.2898e-02, time/batch = 0.1798s	
4520/10550 (epoch 21.422), train_loss = 0.57497921, grad/param norm = 8.0606e-02, time/batch = 0.1804s	
4521/10550 (epoch 21.427), train_loss = 0.58089771, grad/param norm = 7.6603e-02, time/batch = 0.1810s	
4522/10550 (epoch 21.431), train_loss = 0.58424323, grad/param norm = 7.6686e-02, time/batch = 0.1794s	
4523/10550 (epoch 21.436), train_loss = 0.55672724, grad/param norm = 7.5391e-02, time/batch = 0.1798s	
4524/10550 (epoch 21.441), train_loss = 0.58322820, grad/param norm = 7.7803e-02, time/batch = 0.1801s	
4525/10550 (epoch 21.445), train_loss = 0.57930421, grad/param norm = 7.3631e-02, time/batch = 0.1801s	
4526/10550 (epoch 21.450), train_loss = 0.55731527, grad/param norm = 7.4209e-02, time/batch = 0.1799s	
4527/10550 (epoch 21.455), train_loss = 0.57329220, grad/param norm = 7.5288e-02, time/batch = 0.1798s	
4528/10550 (epoch 21.460), train_loss = 0.55018504, grad/param norm = 7.5999e-02, time/batch = 0.1802s	
4529/10550 (epoch 21.464), train_loss = 0.58777181, grad/param norm = 7.5726e-02, time/batch = 0.1805s	
4530/10550 (epoch 21.469), train_loss = 0.56818550, grad/param norm = 7.6530e-02, time/batch = 0.1801s	
4531/10550 (epoch 21.474), train_loss = 0.57311901, grad/param norm = 7.8663e-02, time/batch = 0.1812s	
4532/10550 (epoch 21.479), train_loss = 0.55648293, grad/param norm = 7.5606e-02, time/batch = 0.1793s	
4533/10550 (epoch 21.483), train_loss = 0.56262331, grad/param norm = 7.8957e-02, time/batch = 0.1799s	
4534/10550 (epoch 21.488), train_loss = 0.57581358, grad/param norm = 8.0486e-02, time/batch = 0.1797s	
4535/10550 (epoch 21.493), train_loss = 0.56187066, grad/param norm = 7.7329e-02, time/batch = 0.1792s	
4536/10550 (epoch 21.498), train_loss = 0.57211867, grad/param norm = 7.5161e-02, time/batch = 0.1801s	
4537/10550 (epoch 21.502), train_loss = 0.56238273, grad/param norm = 7.3602e-02, time/batch = 0.1803s	
4538/10550 (epoch 21.507), train_loss = 0.56528288, grad/param norm = 7.5307e-02, time/batch = 0.1795s	
4539/10550 (epoch 21.512), train_loss = 0.55249463, grad/param norm = 7.4022e-02, time/batch = 0.1800s	
4540/10550 (epoch 21.517), train_loss = 0.56614594, grad/param norm = 7.5573e-02, time/batch = 0.1802s	
4541/10550 (epoch 21.521), train_loss = 0.55197183, grad/param norm = 7.2107e-02, time/batch = 0.1809s	
4542/10550 (epoch 21.526), train_loss = 0.52576367, grad/param norm = 7.3671e-02, time/batch = 0.1789s	
4543/10550 (epoch 21.531), train_loss = 0.54075953, grad/param norm = 7.3099e-02, time/batch = 0.1795s	
4544/10550 (epoch 21.536), train_loss = 0.57571660, grad/param norm = 7.4348e-02, time/batch = 0.1798s	
4545/10550 (epoch 21.540), train_loss = 0.58264922, grad/param norm = 8.0246e-02, time/batch = 0.1798s	
4546/10550 (epoch 21.545), train_loss = 0.55767098, grad/param norm = 7.8019e-02, time/batch = 0.1803s	
4547/10550 (epoch 21.550), train_loss = 0.57456669, grad/param norm = 7.4358e-02, time/batch = 0.1802s	
4548/10550 (epoch 21.555), train_loss = 0.56262434, grad/param norm = 7.3430e-02, time/batch = 0.1798s	
4549/10550 (epoch 21.559), train_loss = 0.56311304, grad/param norm = 7.8141e-02, time/batch = 0.1798s	
4550/10550 (epoch 21.564), train_loss = 0.54956973, grad/param norm = 7.7241e-02, time/batch = 0.1798s	
4551/10550 (epoch 21.569), train_loss = 0.54684940, grad/param norm = 7.4649e-02, time/batch = 0.1811s	
4552/10550 (epoch 21.573), train_loss = 0.57561330, grad/param norm = 7.5087e-02, time/batch = 0.1796s	
4553/10550 (epoch 21.578), train_loss = 0.56249986, grad/param norm = 7.3655e-02, time/batch = 0.1798s	
4554/10550 (epoch 21.583), train_loss = 0.55921634, grad/param norm = 7.3102e-02, time/batch = 0.1799s	
4555/10550 (epoch 21.588), train_loss = 0.54797309, grad/param norm = 7.3578e-02, time/batch = 0.1801s	
4556/10550 (epoch 21.592), train_loss = 0.56456089, grad/param norm = 7.6048e-02, time/batch = 0.1796s	
4557/10550 (epoch 21.597), train_loss = 0.55202204, grad/param norm = 7.4239e-02, time/batch = 0.1795s	
4558/10550 (epoch 21.602), train_loss = 0.57033259, grad/param norm = 7.8820e-02, time/batch = 0.1794s	
4559/10550 (epoch 21.607), train_loss = 0.56279756, grad/param norm = 7.5213e-02, time/batch = 0.1801s	
4560/10550 (epoch 21.611), train_loss = 0.53871794, grad/param norm = 7.8190e-02, time/batch = 0.1806s	
4561/10550 (epoch 21.616), train_loss = 0.54452957, grad/param norm = 7.6871e-02, time/batch = 0.1813s	
4562/10550 (epoch 21.621), train_loss = 0.55977559, grad/param norm = 7.6609e-02, time/batch = 0.1794s	
4563/10550 (epoch 21.626), train_loss = 0.55187735, grad/param norm = 7.6831e-02, time/batch = 0.1797s	
4564/10550 (epoch 21.630), train_loss = 0.57054688, grad/param norm = 8.4570e-02, time/batch = 0.1798s	
4565/10550 (epoch 21.635), train_loss = 0.58905238, grad/param norm = 7.8652e-02, time/batch = 0.1799s	
4566/10550 (epoch 21.640), train_loss = 0.57744298, grad/param norm = 7.3655e-02, time/batch = 0.1801s	
4567/10550 (epoch 21.645), train_loss = 0.55365068, grad/param norm = 7.5557e-02, time/batch = 0.1800s	
4568/10550 (epoch 21.649), train_loss = 0.58619569, grad/param norm = 8.0215e-02, time/batch = 0.1797s	
4569/10550 (epoch 21.654), train_loss = 0.56979994, grad/param norm = 7.6216e-02, time/batch = 0.1799s	
4570/10550 (epoch 21.659), train_loss = 0.54899958, grad/param norm = 7.1555e-02, time/batch = 0.1802s	
4571/10550 (epoch 21.664), train_loss = 0.56009007, grad/param norm = 7.3211e-02, time/batch = 0.1805s	
4572/10550 (epoch 21.668), train_loss = 0.54249035, grad/param norm = 7.6477e-02, time/batch = 0.1791s	
4573/10550 (epoch 21.673), train_loss = 0.55096959, grad/param norm = 7.7086e-02, time/batch = 0.1798s	
4574/10550 (epoch 21.678), train_loss = 0.54514753, grad/param norm = 7.3661e-02, time/batch = 0.1799s	
4575/10550 (epoch 21.682), train_loss = 0.54945184, grad/param norm = 7.3031e-02, time/batch = 0.1796s	
4576/10550 (epoch 21.687), train_loss = 0.53309144, grad/param norm = 7.0237e-02, time/batch = 0.1797s	
4577/10550 (epoch 21.692), train_loss = 0.54928471, grad/param norm = 7.5378e-02, time/batch = 0.1800s	
4578/10550 (epoch 21.697), train_loss = 0.54972245, grad/param norm = 7.9407e-02, time/batch = 0.1799s	
4579/10550 (epoch 21.701), train_loss = 0.55005613, grad/param norm = 7.3960e-02, time/batch = 0.1803s	
4580/10550 (epoch 21.706), train_loss = 0.53394286, grad/param norm = 7.6077e-02, time/batch = 0.1801s	
4581/10550 (epoch 21.711), train_loss = 0.56312137, grad/param norm = 7.6678e-02, time/batch = 0.1810s	
4582/10550 (epoch 21.716), train_loss = 0.55641242, grad/param norm = 7.7045e-02, time/batch = 0.1794s	
4583/10550 (epoch 21.720), train_loss = 0.58173027, grad/param norm = 7.9044e-02, time/batch = 0.1792s	
4584/10550 (epoch 21.725), train_loss = 0.54181850, grad/param norm = 7.5438e-02, time/batch = 0.1799s	
4585/10550 (epoch 21.730), train_loss = 0.52369961, grad/param norm = 7.3516e-02, time/batch = 0.1799s	
4586/10550 (epoch 21.735), train_loss = 0.55402244, grad/param norm = 7.5298e-02, time/batch = 0.1802s	
4587/10550 (epoch 21.739), train_loss = 0.55489969, grad/param norm = 7.6272e-02, time/batch = 0.1799s	
4588/10550 (epoch 21.744), train_loss = 0.53969756, grad/param norm = 7.4381e-02, time/batch = 0.1797s	
4589/10550 (epoch 21.749), train_loss = 0.57343120, grad/param norm = 7.4128e-02, time/batch = 0.1803s	
4590/10550 (epoch 21.754), train_loss = 0.56256112, grad/param norm = 7.4799e-02, time/batch = 0.1801s	
4591/10550 (epoch 21.758), train_loss = 0.52772602, grad/param norm = 7.7823e-02, time/batch = 0.1810s	
4592/10550 (epoch 21.763), train_loss = 0.52375357, grad/param norm = 7.3781e-02, time/batch = 0.1794s	
4593/10550 (epoch 21.768), train_loss = 0.55790661, grad/param norm = 7.4929e-02, time/batch = 0.1798s	
4594/10550 (epoch 21.773), train_loss = 0.56433889, grad/param norm = 7.6938e-02, time/batch = 0.1801s	
4595/10550 (epoch 21.777), train_loss = 0.55305092, grad/param norm = 7.2049e-02, time/batch = 0.1803s	
4596/10550 (epoch 21.782), train_loss = 0.58633837, grad/param norm = 7.9718e-02, time/batch = 0.1795s	
4597/10550 (epoch 21.787), train_loss = 0.54056662, grad/param norm = 7.4482e-02, time/batch = 0.1799s	
4598/10550 (epoch 21.791), train_loss = 0.53348612, grad/param norm = 7.4709e-02, time/batch = 0.1800s	
4599/10550 (epoch 21.796), train_loss = 0.57177872, grad/param norm = 7.8318e-02, time/batch = 0.1792s	
4600/10550 (epoch 21.801), train_loss = 0.56171538, grad/param norm = 7.6203e-02, time/batch = 0.1795s	
4601/10550 (epoch 21.806), train_loss = 0.56564318, grad/param norm = 8.0429e-02, time/batch = 0.1814s	
4602/10550 (epoch 21.810), train_loss = 0.58449132, grad/param norm = 8.0948e-02, time/batch = 0.1798s	
4603/10550 (epoch 21.815), train_loss = 0.55485320, grad/param norm = 7.5370e-02, time/batch = 0.1800s	
4604/10550 (epoch 21.820), train_loss = 0.54780282, grad/param norm = 7.5255e-02, time/batch = 0.1799s	
4605/10550 (epoch 21.825), train_loss = 0.57133437, grad/param norm = 7.6954e-02, time/batch = 0.1800s	
4606/10550 (epoch 21.829), train_loss = 0.55075889, grad/param norm = 7.2804e-02, time/batch = 0.1799s	
4607/10550 (epoch 21.834), train_loss = 0.55509251, grad/param norm = 7.8474e-02, time/batch = 0.1801s	
4608/10550 (epoch 21.839), train_loss = 0.56205139, grad/param norm = 7.7866e-02, time/batch = 0.1792s	
4609/10550 (epoch 21.844), train_loss = 0.56932678, grad/param norm = 7.9897e-02, time/batch = 0.1803s	
4610/10550 (epoch 21.848), train_loss = 0.55856844, grad/param norm = 7.5636e-02, time/batch = 0.1801s	
4611/10550 (epoch 21.853), train_loss = 0.56431800, grad/param norm = 7.6170e-02, time/batch = 0.1812s	
4612/10550 (epoch 21.858), train_loss = 0.58438952, grad/param norm = 7.9058e-02, time/batch = 0.1790s	
4613/10550 (epoch 21.863), train_loss = 0.55399193, grad/param norm = 7.6729e-02, time/batch = 0.1797s	
4614/10550 (epoch 21.867), train_loss = 0.56327248, grad/param norm = 7.8120e-02, time/batch = 0.1800s	
4615/10550 (epoch 21.872), train_loss = 0.56306810, grad/param norm = 7.5563e-02, time/batch = 0.1803s	
4616/10550 (epoch 21.877), train_loss = 0.55632262, grad/param norm = 7.3435e-02, time/batch = 0.1797s	
4617/10550 (epoch 21.882), train_loss = 0.54716736, grad/param norm = 7.6178e-02, time/batch = 0.1795s	
4618/10550 (epoch 21.886), train_loss = 0.54785411, grad/param norm = 7.6626e-02, time/batch = 0.1800s	
4619/10550 (epoch 21.891), train_loss = 0.55181005, grad/param norm = 7.8363e-02, time/batch = 0.1800s	
4620/10550 (epoch 21.896), train_loss = 0.56000639, grad/param norm = 7.4404e-02, time/batch = 0.1802s	
4621/10550 (epoch 21.900), train_loss = 0.55888153, grad/param norm = 7.6499e-02, time/batch = 0.1813s	
4622/10550 (epoch 21.905), train_loss = 0.54561931, grad/param norm = 7.8522e-02, time/batch = 0.1795s	
4623/10550 (epoch 21.910), train_loss = 0.54735514, grad/param norm = 7.7550e-02, time/batch = 0.1796s	
4624/10550 (epoch 21.915), train_loss = 0.54824494, grad/param norm = 7.4371e-02, time/batch = 0.1797s	
4625/10550 (epoch 21.919), train_loss = 0.56784691, grad/param norm = 7.5492e-02, time/batch = 0.1799s	
4626/10550 (epoch 21.924), train_loss = 0.55819812, grad/param norm = 7.5297e-02, time/batch = 0.1800s	
4627/10550 (epoch 21.929), train_loss = 0.56074512, grad/param norm = 7.5838e-02, time/batch = 0.1802s	
4628/10550 (epoch 21.934), train_loss = 0.53916731, grad/param norm = 7.5350e-02, time/batch = 0.1795s	
4629/10550 (epoch 21.938), train_loss = 0.58397978, grad/param norm = 8.2584e-02, time/batch = 0.1803s	
4630/10550 (epoch 21.943), train_loss = 0.55939893, grad/param norm = 7.6172e-02, time/batch = 0.1802s	
4631/10550 (epoch 21.948), train_loss = 0.55729591, grad/param norm = 7.6763e-02, time/batch = 0.1814s	
4632/10550 (epoch 21.953), train_loss = 0.57646562, grad/param norm = 7.8372e-02, time/batch = 0.1792s	
4633/10550 (epoch 21.957), train_loss = 0.56886733, grad/param norm = 7.8639e-02, time/batch = 0.1803s	
4634/10550 (epoch 21.962), train_loss = 0.56858213, grad/param norm = 7.6847e-02, time/batch = 0.1800s	
4635/10550 (epoch 21.967), train_loss = 0.58380135, grad/param norm = 8.2582e-02, time/batch = 0.1800s	
4636/10550 (epoch 21.972), train_loss = 0.56082929, grad/param norm = 7.4970e-02, time/batch = 0.1799s	
4637/10550 (epoch 21.976), train_loss = 0.55209041, grad/param norm = 7.4632e-02, time/batch = 0.1802s	
4638/10550 (epoch 21.981), train_loss = 0.56425286, grad/param norm = 7.9041e-02, time/batch = 0.1797s	
4639/10550 (epoch 21.986), train_loss = 0.55114619, grad/param norm = 7.6460e-02, time/batch = 0.1800s	
4640/10550 (epoch 21.991), train_loss = 0.58116090, grad/param norm = 8.1888e-02, time/batch = 0.1804s	
4641/10550 (epoch 21.995), train_loss = 0.56427936, grad/param norm = 7.6632e-02, time/batch = 0.1809s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
4642/10550 (epoch 22.000), train_loss = 0.56626656, grad/param norm = 7.6735e-02, time/batch = 0.1791s	
4643/10550 (epoch 22.005), train_loss = 0.74369041, grad/param norm = 8.2433e-02, time/batch = 0.1797s	
4644/10550 (epoch 22.009), train_loss = 0.55388645, grad/param norm = 7.2877e-02, time/batch = 0.1801s	
4645/10550 (epoch 22.014), train_loss = 0.57721793, grad/param norm = 7.9740e-02, time/batch = 0.1803s	
4646/10550 (epoch 22.019), train_loss = 0.59852518, grad/param norm = 7.7642e-02, time/batch = 0.1795s	
4647/10550 (epoch 22.024), train_loss = 0.57169948, grad/param norm = 7.5470e-02, time/batch = 0.1799s	
4648/10550 (epoch 22.028), train_loss = 0.56553602, grad/param norm = 7.5375e-02, time/batch = 0.1794s	
4649/10550 (epoch 22.033), train_loss = 0.56375130, grad/param norm = 7.6976e-02, time/batch = 0.1802s	
4650/10550 (epoch 22.038), train_loss = 0.56404087, grad/param norm = 7.8158e-02, time/batch = 0.1793s	
4651/10550 (epoch 22.043), train_loss = 0.54717180, grad/param norm = 7.2832e-02, time/batch = 0.1808s	
4652/10550 (epoch 22.047), train_loss = 0.55119392, grad/param norm = 7.4411e-02, time/batch = 0.1794s	
4653/10550 (epoch 22.052), train_loss = 0.56639439, grad/param norm = 7.5211e-02, time/batch = 0.1799s	
4654/10550 (epoch 22.057), train_loss = 0.54286002, grad/param norm = 7.1558e-02, time/batch = 0.1798s	
4655/10550 (epoch 22.062), train_loss = 0.57050714, grad/param norm = 7.7345e-02, time/batch = 0.1803s	
4656/10550 (epoch 22.066), train_loss = 0.55739034, grad/param norm = 7.4160e-02, time/batch = 0.1797s	
4657/10550 (epoch 22.071), train_loss = 0.55180309, grad/param norm = 7.7736e-02, time/batch = 0.1796s	
4658/10550 (epoch 22.076), train_loss = 0.56904564, grad/param norm = 7.8438e-02, time/batch = 0.1791s	
4659/10550 (epoch 22.081), train_loss = 0.56594423, grad/param norm = 7.5273e-02, time/batch = 0.1798s	
4660/10550 (epoch 22.085), train_loss = 0.55186485, grad/param norm = 7.5275e-02, time/batch = 0.1800s	
4661/10550 (epoch 22.090), train_loss = 0.55317762, grad/param norm = 7.7811e-02, time/batch = 0.1810s	
4662/10550 (epoch 22.095), train_loss = 0.57809097, grad/param norm = 7.9371e-02, time/batch = 0.1791s	
4663/10550 (epoch 22.100), train_loss = 0.56597636, grad/param norm = 7.9438e-02, time/batch = 0.1797s	
4664/10550 (epoch 22.104), train_loss = 0.55759613, grad/param norm = 7.6023e-02, time/batch = 0.1803s	
4665/10550 (epoch 22.109), train_loss = 0.55628491, grad/param norm = 7.9496e-02, time/batch = 0.1801s	
4666/10550 (epoch 22.114), train_loss = 0.57239756, grad/param norm = 8.0987e-02, time/batch = 0.1803s	
4667/10550 (epoch 22.118), train_loss = 0.54505061, grad/param norm = 7.3539e-02, time/batch = 0.1800s	
4668/10550 (epoch 22.123), train_loss = 0.57033512, grad/param norm = 7.7199e-02, time/batch = 0.1800s	
4669/10550 (epoch 22.128), train_loss = 0.55075329, grad/param norm = 7.6468e-02, time/batch = 0.1800s	
4670/10550 (epoch 22.133), train_loss = 0.53868876, grad/param norm = 7.6560e-02, time/batch = 0.1797s	
4671/10550 (epoch 22.137), train_loss = 0.56165587, grad/param norm = 8.0249e-02, time/batch = 0.1809s	
4672/10550 (epoch 22.142), train_loss = 0.56439386, grad/param norm = 7.8962e-02, time/batch = 0.1790s	
4673/10550 (epoch 22.147), train_loss = 0.55239481, grad/param norm = 7.6883e-02, time/batch = 0.1792s	
4674/10550 (epoch 22.152), train_loss = 0.57206258, grad/param norm = 7.8930e-02, time/batch = 0.1797s	
4675/10550 (epoch 22.156), train_loss = 0.55359801, grad/param norm = 7.7240e-02, time/batch = 0.1797s	
4676/10550 (epoch 22.161), train_loss = 0.55210294, grad/param norm = 7.5806e-02, time/batch = 0.1797s	
4677/10550 (epoch 22.166), train_loss = 0.57179164, grad/param norm = 7.3949e-02, time/batch = 0.1796s	
4678/10550 (epoch 22.171), train_loss = 0.53670136, grad/param norm = 7.2969e-02, time/batch = 0.1796s	
4679/10550 (epoch 22.175), train_loss = 0.56363903, grad/param norm = 7.8924e-02, time/batch = 0.1800s	
4680/10550 (epoch 22.180), train_loss = 0.52545595, grad/param norm = 7.3843e-02, time/batch = 0.1802s	
4681/10550 (epoch 22.185), train_loss = 0.56250201, grad/param norm = 7.6564e-02, time/batch = 0.1814s	
4682/10550 (epoch 22.190), train_loss = 0.52836021, grad/param norm = 7.7945e-02, time/batch = 0.1795s	
4683/10550 (epoch 22.194), train_loss = 0.56110829, grad/param norm = 7.9398e-02, time/batch = 0.1800s	
4684/10550 (epoch 22.199), train_loss = 0.57724608, grad/param norm = 8.2617e-02, time/batch = 0.1798s	
4685/10550 (epoch 22.204), train_loss = 0.54879575, grad/param norm = 7.8932e-02, time/batch = 0.1800s	
4686/10550 (epoch 22.209), train_loss = 0.58054153, grad/param norm = 8.1484e-02, time/batch = 0.1800s	
4687/10550 (epoch 22.213), train_loss = 0.57794323, grad/param norm = 7.9645e-02, time/batch = 0.1799s	
4688/10550 (epoch 22.218), train_loss = 0.56206360, grad/param norm = 7.8864e-02, time/batch = 0.1800s	
4689/10550 (epoch 22.223), train_loss = 0.55253827, grad/param norm = 7.7916e-02, time/batch = 0.1805s	
4690/10550 (epoch 22.227), train_loss = 0.54949259, grad/param norm = 7.4130e-02, time/batch = 0.1801s	
4691/10550 (epoch 22.232), train_loss = 0.53362147, grad/param norm = 7.3574e-02, time/batch = 0.1806s	
4692/10550 (epoch 22.237), train_loss = 0.54659244, grad/param norm = 7.2392e-02, time/batch = 0.1793s	
4693/10550 (epoch 22.242), train_loss = 0.53773869, grad/param norm = 7.5876e-02, time/batch = 0.1796s	
4694/10550 (epoch 22.246), train_loss = 0.53759394, grad/param norm = 7.5597e-02, time/batch = 0.1795s	
4695/10550 (epoch 22.251), train_loss = 0.54388430, grad/param norm = 7.4968e-02, time/batch = 0.1801s	
4696/10550 (epoch 22.256), train_loss = 0.56457360, grad/param norm = 7.5215e-02, time/batch = 0.1797s	
4697/10550 (epoch 22.261), train_loss = 0.53848272, grad/param norm = 7.4793e-02, time/batch = 0.1793s	
4698/10550 (epoch 22.265), train_loss = 0.52283543, grad/param norm = 7.4707e-02, time/batch = 0.1791s	
4699/10550 (epoch 22.270), train_loss = 0.53966456, grad/param norm = 7.3101e-02, time/batch = 0.1800s	
4700/10550 (epoch 22.275), train_loss = 0.56306318, grad/param norm = 7.5502e-02, time/batch = 0.1799s	
4701/10550 (epoch 22.280), train_loss = 0.54712808, grad/param norm = 7.5164e-02, time/batch = 0.1810s	
4702/10550 (epoch 22.284), train_loss = 0.54408927, grad/param norm = 7.7999e-02, time/batch = 0.1793s	
4703/10550 (epoch 22.289), train_loss = 0.54636113, grad/param norm = 7.6234e-02, time/batch = 0.1796s	
4704/10550 (epoch 22.294), train_loss = 0.54047391, grad/param norm = 8.1775e-02, time/batch = 0.1788s	
4705/10550 (epoch 22.299), train_loss = 0.53332748, grad/param norm = 7.5386e-02, time/batch = 0.1801s	
4706/10550 (epoch 22.303), train_loss = 0.55111974, grad/param norm = 7.4377e-02, time/batch = 0.1800s	
4707/10550 (epoch 22.308), train_loss = 0.54610323, grad/param norm = 7.8485e-02, time/batch = 0.1799s	
4708/10550 (epoch 22.313), train_loss = 0.53589439, grad/param norm = 7.4258e-02, time/batch = 0.1790s	
4709/10550 (epoch 22.318), train_loss = 0.54069579, grad/param norm = 7.4966e-02, time/batch = 0.1797s	
4710/10550 (epoch 22.322), train_loss = 0.53980520, grad/param norm = 7.3808e-02, time/batch = 0.1798s	
4711/10550 (epoch 22.327), train_loss = 0.55495978, grad/param norm = 7.7764e-02, time/batch = 0.1813s	
4712/10550 (epoch 22.332), train_loss = 0.56644686, grad/param norm = 7.8064e-02, time/batch = 0.1796s	
4713/10550 (epoch 22.336), train_loss = 0.54109864, grad/param norm = 7.8065e-02, time/batch = 0.1796s	
4714/10550 (epoch 22.341), train_loss = 0.52498094, grad/param norm = 7.8600e-02, time/batch = 0.1800s	
4715/10550 (epoch 22.346), train_loss = 0.54634291, grad/param norm = 7.9711e-02, time/batch = 0.1803s	
4716/10550 (epoch 22.351), train_loss = 0.54945388, grad/param norm = 7.9517e-02, time/batch = 0.1796s	
4717/10550 (epoch 22.355), train_loss = 0.54059001, grad/param norm = 7.3919e-02, time/batch = 0.1802s	
4718/10550 (epoch 22.360), train_loss = 0.57042257, grad/param norm = 7.8943e-02, time/batch = 0.1793s	
4719/10550 (epoch 22.365), train_loss = 0.55009698, grad/param norm = 7.5750e-02, time/batch = 0.1801s	
4720/10550 (epoch 22.370), train_loss = 0.54364932, grad/param norm = 8.0170e-02, time/batch = 0.1799s	
4721/10550 (epoch 22.374), train_loss = 0.52358028, grad/param norm = 7.2302e-02, time/batch = 0.1805s	
4722/10550 (epoch 22.379), train_loss = 0.55483017, grad/param norm = 7.7954e-02, time/batch = 0.1796s	
4723/10550 (epoch 22.384), train_loss = 0.52982306, grad/param norm = 7.5624e-02, time/batch = 0.1795s	
4724/10550 (epoch 22.389), train_loss = 0.54643560, grad/param norm = 7.7409e-02, time/batch = 0.1799s	
4725/10550 (epoch 22.393), train_loss = 0.53256218, grad/param norm = 7.5881e-02, time/batch = 0.1803s	
4726/10550 (epoch 22.398), train_loss = 0.53448356, grad/param norm = 7.6082e-02, time/batch = 0.1802s	
4727/10550 (epoch 22.403), train_loss = 0.53768720, grad/param norm = 7.6726e-02, time/batch = 0.1797s	
4728/10550 (epoch 22.408), train_loss = 0.54661317, grad/param norm = 8.0113e-02, time/batch = 0.1796s	
4729/10550 (epoch 22.412), train_loss = 0.54433644, grad/param norm = 7.6139e-02, time/batch = 0.1808s	
4730/10550 (epoch 22.417), train_loss = 0.54631945, grad/param norm = 7.2831e-02, time/batch = 0.1799s	
4731/10550 (epoch 22.422), train_loss = 0.54228880, grad/param norm = 8.0958e-02, time/batch = 0.1810s	
4732/10550 (epoch 22.427), train_loss = 0.55226670, grad/param norm = 7.4816e-02, time/batch = 0.1789s	
4733/10550 (epoch 22.431), train_loss = 0.55060753, grad/param norm = 7.5218e-02, time/batch = 0.1794s	
4734/10550 (epoch 22.436), train_loss = 0.53602605, grad/param norm = 7.6759e-02, time/batch = 0.1803s	
4735/10550 (epoch 22.441), train_loss = 0.54329078, grad/param norm = 7.8309e-02, time/batch = 0.1796s	
4736/10550 (epoch 22.445), train_loss = 0.55029439, grad/param norm = 7.6691e-02, time/batch = 0.1799s	
4737/10550 (epoch 22.450), train_loss = 0.54688838, grad/param norm = 7.7893e-02, time/batch = 0.1799s	
4738/10550 (epoch 22.455), train_loss = 0.53454876, grad/param norm = 7.3753e-02, time/batch = 0.1796s	
4739/10550 (epoch 22.460), train_loss = 0.52942832, grad/param norm = 7.5670e-02, time/batch = 0.1798s	
4740/10550 (epoch 22.464), train_loss = 0.56043359, grad/param norm = 7.4622e-02, time/batch = 0.1800s	
4741/10550 (epoch 22.469), train_loss = 0.54062211, grad/param norm = 7.7102e-02, time/batch = 0.1809s	
4742/10550 (epoch 22.474), train_loss = 0.54863013, grad/param norm = 7.8500e-02, time/batch = 0.1801s	
4743/10550 (epoch 22.479), train_loss = 0.52749578, grad/param norm = 7.5523e-02, time/batch = 0.1797s	
4744/10550 (epoch 22.483), train_loss = 0.52569461, grad/param norm = 7.4952e-02, time/batch = 0.1798s	
4745/10550 (epoch 22.488), train_loss = 0.54155944, grad/param norm = 7.8252e-02, time/batch = 0.1803s	
4746/10550 (epoch 22.493), train_loss = 0.51893430, grad/param norm = 7.2724e-02, time/batch = 0.1802s	
4747/10550 (epoch 22.498), train_loss = 0.55405043, grad/param norm = 7.5944e-02, time/batch = 0.1801s	
4748/10550 (epoch 22.502), train_loss = 0.54640446, grad/param norm = 7.6910e-02, time/batch = 0.1795s	
4749/10550 (epoch 22.507), train_loss = 0.52622387, grad/param norm = 7.2545e-02, time/batch = 0.1797s	
4750/10550 (epoch 22.512), train_loss = 0.52192007, grad/param norm = 7.6554e-02, time/batch = 0.1804s	
4751/10550 (epoch 22.517), train_loss = 0.54091901, grad/param norm = 7.6360e-02, time/batch = 0.1809s	
4752/10550 (epoch 22.521), train_loss = 0.53625237, grad/param norm = 7.4865e-02, time/batch = 0.1793s	
4753/10550 (epoch 22.526), train_loss = 0.49587442, grad/param norm = 7.1057e-02, time/batch = 0.1798s	
4754/10550 (epoch 22.531), train_loss = 0.50449556, grad/param norm = 7.3921e-02, time/batch = 0.1797s	
4755/10550 (epoch 22.536), train_loss = 0.54447126, grad/param norm = 7.2606e-02, time/batch = 0.1796s	
4756/10550 (epoch 22.540), train_loss = 0.54783851, grad/param norm = 7.7573e-02, time/batch = 0.1799s	
4757/10550 (epoch 22.545), train_loss = 0.54343095, grad/param norm = 8.0954e-02, time/batch = 0.1798s	
4758/10550 (epoch 22.550), train_loss = 0.54531496, grad/param norm = 7.4693e-02, time/batch = 0.1797s	
4759/10550 (epoch 22.555), train_loss = 0.53916055, grad/param norm = 7.4482e-02, time/batch = 0.1800s	
4760/10550 (epoch 22.559), train_loss = 0.54243390, grad/param norm = 7.6894e-02, time/batch = 0.1797s	
4761/10550 (epoch 22.564), train_loss = 0.51317514, grad/param norm = 7.4374e-02, time/batch = 0.1812s	
4762/10550 (epoch 22.569), train_loss = 0.52057567, grad/param norm = 7.2511e-02, time/batch = 0.1797s	
4763/10550 (epoch 22.573), train_loss = 0.53990327, grad/param norm = 7.5230e-02, time/batch = 0.1799s	
4764/10550 (epoch 22.578), train_loss = 0.53628932, grad/param norm = 7.6362e-02, time/batch = 0.1800s	
4765/10550 (epoch 22.583), train_loss = 0.53445082, grad/param norm = 7.3777e-02, time/batch = 0.1802s	
4766/10550 (epoch 22.588), train_loss = 0.51462290, grad/param norm = 7.5714e-02, time/batch = 0.1798s	
4767/10550 (epoch 22.592), train_loss = 0.52939249, grad/param norm = 7.6892e-02, time/batch = 0.1798s	
4768/10550 (epoch 22.597), train_loss = 0.53250596, grad/param norm = 7.3653e-02, time/batch = 0.1794s	
4769/10550 (epoch 22.602), train_loss = 0.53250909, grad/param norm = 7.7256e-02, time/batch = 0.1804s	
4770/10550 (epoch 22.607), train_loss = 0.52805154, grad/param norm = 7.5898e-02, time/batch = 0.1798s	
4771/10550 (epoch 22.611), train_loss = 0.51160823, grad/param norm = 7.8765e-02, time/batch = 0.1810s	
4772/10550 (epoch 22.616), train_loss = 0.51273598, grad/param norm = 7.5072e-02, time/batch = 0.1791s	
4773/10550 (epoch 22.621), train_loss = 0.53089676, grad/param norm = 7.6853e-02, time/batch = 0.1800s	
4774/10550 (epoch 22.626), train_loss = 0.52689550, grad/param norm = 7.8072e-02, time/batch = 0.1796s	
4775/10550 (epoch 22.630), train_loss = 0.53020283, grad/param norm = 7.9185e-02, time/batch = 0.1798s	
4776/10550 (epoch 22.635), train_loss = 0.56776911, grad/param norm = 8.0898e-02, time/batch = 0.1799s	
4777/10550 (epoch 22.640), train_loss = 0.55679551, grad/param norm = 7.5033e-02, time/batch = 0.1799s	
4778/10550 (epoch 22.645), train_loss = 0.53173179, grad/param norm = 7.7374e-02, time/batch = 0.1799s	
4779/10550 (epoch 22.649), train_loss = 0.55552040, grad/param norm = 8.0705e-02, time/batch = 0.1804s	
4780/10550 (epoch 22.654), train_loss = 0.53340104, grad/param norm = 7.5908e-02, time/batch = 0.1802s	
4781/10550 (epoch 22.659), train_loss = 0.52280611, grad/param norm = 7.3301e-02, time/batch = 0.1808s	
4782/10550 (epoch 22.664), train_loss = 0.52919683, grad/param norm = 7.3335e-02, time/batch = 0.1798s	
4783/10550 (epoch 22.668), train_loss = 0.51210166, grad/param norm = 7.7309e-02, time/batch = 0.1797s	
4784/10550 (epoch 22.673), train_loss = 0.51758292, grad/param norm = 7.3795e-02, time/batch = 0.1801s	
4785/10550 (epoch 22.678), train_loss = 0.51651950, grad/param norm = 7.5040e-02, time/batch = 0.1803s	
4786/10550 (epoch 22.682), train_loss = 0.53661592, grad/param norm = 7.8259e-02, time/batch = 0.1797s	
4787/10550 (epoch 22.687), train_loss = 0.51276079, grad/param norm = 7.3326e-02, time/batch = 0.1802s	
4788/10550 (epoch 22.692), train_loss = 0.51561673, grad/param norm = 7.3536e-02, time/batch = 0.1792s	
4789/10550 (epoch 22.697), train_loss = 0.51831240, grad/param norm = 7.3401e-02, time/batch = 0.1805s	
4790/10550 (epoch 22.701), train_loss = 0.52934477, grad/param norm = 7.9043e-02, time/batch = 0.1799s	
4791/10550 (epoch 22.706), train_loss = 0.50398214, grad/param norm = 7.6938e-02, time/batch = 0.1812s	
4792/10550 (epoch 22.711), train_loss = 0.54815436, grad/param norm = 7.6487e-02, time/batch = 0.1795s	
4793/10550 (epoch 22.716), train_loss = 0.51515788, grad/param norm = 7.3552e-02, time/batch = 0.1798s	
4794/10550 (epoch 22.720), train_loss = 0.55472764, grad/param norm = 7.7351e-02, time/batch = 0.1796s	
4795/10550 (epoch 22.725), train_loss = 0.51865616, grad/param norm = 7.6483e-02, time/batch = 0.1796s	
4796/10550 (epoch 22.730), train_loss = 0.50061672, grad/param norm = 7.5767e-02, time/batch = 0.1798s	
4797/10550 (epoch 22.735), train_loss = 0.52918861, grad/param norm = 7.6803e-02, time/batch = 0.1798s	
4798/10550 (epoch 22.739), train_loss = 0.50772133, grad/param norm = 7.2928e-02, time/batch = 0.1797s	
4799/10550 (epoch 22.744), train_loss = 0.50925647, grad/param norm = 7.3423e-02, time/batch = 0.1802s	
4800/10550 (epoch 22.749), train_loss = 0.55006737, grad/param norm = 7.8489e-02, time/batch = 0.1798s	
4801/10550 (epoch 22.754), train_loss = 0.53564198, grad/param norm = 7.4670e-02, time/batch = 0.1811s	
4802/10550 (epoch 22.758), train_loss = 0.51258928, grad/param norm = 7.8526e-02, time/batch = 0.1799s	
4803/10550 (epoch 22.763), train_loss = 0.50714470, grad/param norm = 8.0904e-02, time/batch = 0.1797s	
4804/10550 (epoch 22.768), train_loss = 0.52583873, grad/param norm = 7.9149e-02, time/batch = 0.1800s	
4805/10550 (epoch 22.773), train_loss = 0.54752029, grad/param norm = 8.0788e-02, time/batch = 0.1797s	
4806/10550 (epoch 22.777), train_loss = 0.53209823, grad/param norm = 7.8890e-02, time/batch = 0.1795s	
4807/10550 (epoch 22.782), train_loss = 0.55586434, grad/param norm = 7.6638e-02, time/batch = 0.1796s	
4808/10550 (epoch 22.787), train_loss = 0.52090266, grad/param norm = 7.5214e-02, time/batch = 0.1797s	
4809/10550 (epoch 22.791), train_loss = 0.51486460, grad/param norm = 7.4591e-02, time/batch = 0.1802s	
4810/10550 (epoch 22.796), train_loss = 0.54202506, grad/param norm = 7.7746e-02, time/batch = 0.1801s	
4811/10550 (epoch 22.801), train_loss = 0.54841093, grad/param norm = 8.2625e-02, time/batch = 0.1812s	
4812/10550 (epoch 22.806), train_loss = 0.53737296, grad/param norm = 7.8963e-02, time/batch = 0.1792s	
4813/10550 (epoch 22.810), train_loss = 0.55225527, grad/param norm = 8.0444e-02, time/batch = 0.1801s	
4814/10550 (epoch 22.815), train_loss = 0.51772732, grad/param norm = 7.5342e-02, time/batch = 0.1802s	
4815/10550 (epoch 22.820), train_loss = 0.52395760, grad/param norm = 7.6043e-02, time/batch = 0.1801s	
4816/10550 (epoch 22.825), train_loss = 0.53523563, grad/param norm = 7.5922e-02, time/batch = 0.1801s	
4817/10550 (epoch 22.829), train_loss = 0.52117834, grad/param norm = 7.6849e-02, time/batch = 0.1799s	
4818/10550 (epoch 22.834), train_loss = 0.53056046, grad/param norm = 8.0141e-02, time/batch = 0.1798s	
4819/10550 (epoch 22.839), train_loss = 0.53431691, grad/param norm = 7.7955e-02, time/batch = 0.1800s	
4820/10550 (epoch 22.844), train_loss = 0.52953569, grad/param norm = 7.7971e-02, time/batch = 0.1804s	
4821/10550 (epoch 22.848), train_loss = 0.53118220, grad/param norm = 7.8832e-02, time/batch = 0.1810s	
4822/10550 (epoch 22.853), train_loss = 0.54392488, grad/param norm = 7.8513e-02, time/batch = 0.1795s	
4823/10550 (epoch 22.858), train_loss = 0.56667986, grad/param norm = 8.3116e-02, time/batch = 0.1798s	
4824/10550 (epoch 22.863), train_loss = 0.53299188, grad/param norm = 7.7066e-02, time/batch = 0.1799s	
4825/10550 (epoch 22.867), train_loss = 0.52751001, grad/param norm = 7.4731e-02, time/batch = 0.1801s	
4826/10550 (epoch 22.872), train_loss = 0.54672861, grad/param norm = 7.8669e-02, time/batch = 0.1799s	
4827/10550 (epoch 22.877), train_loss = 0.52385524, grad/param norm = 7.6144e-02, time/batch = 0.1798s	
4828/10550 (epoch 22.882), train_loss = 0.51877386, grad/param norm = 7.6371e-02, time/batch = 0.1794s	
4829/10550 (epoch 22.886), train_loss = 0.53771206, grad/param norm = 7.7898e-02, time/batch = 0.1799s	
4830/10550 (epoch 22.891), train_loss = 0.51487677, grad/param norm = 7.8349e-02, time/batch = 0.1796s	
4831/10550 (epoch 22.896), train_loss = 0.53405775, grad/param norm = 7.7771e-02, time/batch = 0.1813s	
4832/10550 (epoch 22.900), train_loss = 0.54431159, grad/param norm = 7.7878e-02, time/batch = 0.1790s	
4833/10550 (epoch 22.905), train_loss = 0.51741188, grad/param norm = 7.8534e-02, time/batch = 0.1795s	
4834/10550 (epoch 22.910), train_loss = 0.52039740, grad/param norm = 7.6421e-02, time/batch = 0.1797s	
4835/10550 (epoch 22.915), train_loss = 0.52748609, grad/param norm = 7.7918e-02, time/batch = 0.1801s	
4836/10550 (epoch 22.919), train_loss = 0.52905717, grad/param norm = 7.5480e-02, time/batch = 0.1793s	
4837/10550 (epoch 22.924), train_loss = 0.53186376, grad/param norm = 7.7228e-02, time/batch = 0.1800s	
4838/10550 (epoch 22.929), train_loss = 0.53175544, grad/param norm = 7.5726e-02, time/batch = 0.1793s	
4839/10550 (epoch 22.934), train_loss = 0.51372182, grad/param norm = 7.7143e-02, time/batch = 0.1796s	
4840/10550 (epoch 22.938), train_loss = 0.55031275, grad/param norm = 8.1039e-02, time/batch = 0.1799s	
4841/10550 (epoch 22.943), train_loss = 0.53896137, grad/param norm = 7.6304e-02, time/batch = 0.1811s	
4842/10550 (epoch 22.948), train_loss = 0.54109368, grad/param norm = 7.8157e-02, time/batch = 0.1795s	
4843/10550 (epoch 22.953), train_loss = 0.55648784, grad/param norm = 8.2122e-02, time/batch = 0.1798s	
4844/10550 (epoch 22.957), train_loss = 0.53472611, grad/param norm = 7.6657e-02, time/batch = 0.1803s	
4845/10550 (epoch 22.962), train_loss = 0.55001863, grad/param norm = 8.1186e-02, time/batch = 0.1799s	
4846/10550 (epoch 22.967), train_loss = 0.55802324, grad/param norm = 7.8523e-02, time/batch = 0.1791s	
4847/10550 (epoch 22.972), train_loss = 0.54100752, grad/param norm = 7.9233e-02, time/batch = 0.1798s	
4848/10550 (epoch 22.976), train_loss = 0.52407107, grad/param norm = 7.4538e-02, time/batch = 0.1795s	
4849/10550 (epoch 22.981), train_loss = 0.52561956, grad/param norm = 7.5024e-02, time/batch = 0.1802s	
4850/10550 (epoch 22.986), train_loss = 0.53298503, grad/param norm = 8.0485e-02, time/batch = 0.1798s	
4851/10550 (epoch 22.991), train_loss = 0.55598497, grad/param norm = 8.1631e-02, time/batch = 0.1812s	
4852/10550 (epoch 22.995), train_loss = 0.53163769, grad/param norm = 7.7214e-02, time/batch = 0.1791s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
4853/10550 (epoch 23.000), train_loss = 0.53877138, grad/param norm = 7.4427e-02, time/batch = 0.1797s	
4854/10550 (epoch 23.005), train_loss = 0.70616147, grad/param norm = 8.2013e-02, time/batch = 0.1802s	
4855/10550 (epoch 23.009), train_loss = 0.52702290, grad/param norm = 7.6076e-02, time/batch = 0.1795s	
4856/10550 (epoch 23.014), train_loss = 0.54127490, grad/param norm = 8.0345e-02, time/batch = 0.1799s	
4857/10550 (epoch 23.019), train_loss = 0.56173648, grad/param norm = 7.7105e-02, time/batch = 0.1794s	
4858/10550 (epoch 23.024), train_loss = 0.55687058, grad/param norm = 8.1382e-02, time/batch = 0.1794s	
4859/10550 (epoch 23.028), train_loss = 0.53895385, grad/param norm = 7.6486e-02, time/batch = 0.1802s	
4860/10550 (epoch 23.033), train_loss = 0.54737369, grad/param norm = 7.9874e-02, time/batch = 0.1798s	
4861/10550 (epoch 23.038), train_loss = 0.54085801, grad/param norm = 7.9105e-02, time/batch = 0.1805s	
4862/10550 (epoch 23.043), train_loss = 0.52362339, grad/param norm = 7.4733e-02, time/batch = 0.1791s	
4863/10550 (epoch 23.047), train_loss = 0.52292881, grad/param norm = 7.5368e-02, time/batch = 0.1802s	
4864/10550 (epoch 23.052), train_loss = 0.53364065, grad/param norm = 7.5980e-02, time/batch = 0.1802s	
4865/10550 (epoch 23.057), train_loss = 0.53787028, grad/param norm = 7.8506e-02, time/batch = 0.1799s	
4866/10550 (epoch 23.062), train_loss = 0.53699358, grad/param norm = 7.6755e-02, time/batch = 0.1802s	
4867/10550 (epoch 23.066), train_loss = 0.53211836, grad/param norm = 7.5502e-02, time/batch = 0.1798s	
4868/10550 (epoch 23.071), train_loss = 0.53190858, grad/param norm = 7.9442e-02, time/batch = 0.1795s	
4869/10550 (epoch 23.076), train_loss = 0.54101978, grad/param norm = 7.9698e-02, time/batch = 0.1797s	
4870/10550 (epoch 23.081), train_loss = 0.53594958, grad/param norm = 7.8520e-02, time/batch = 0.1801s	
4871/10550 (epoch 23.085), train_loss = 0.52342073, grad/param norm = 7.6277e-02, time/batch = 0.1811s	
4872/10550 (epoch 23.090), train_loss = 0.52322456, grad/param norm = 7.7688e-02, time/batch = 0.1797s	
4873/10550 (epoch 23.095), train_loss = 0.54310893, grad/param norm = 7.7121e-02, time/batch = 0.1797s	
4874/10550 (epoch 23.100), train_loss = 0.53043608, grad/param norm = 7.6723e-02, time/batch = 0.1799s	
4875/10550 (epoch 23.104), train_loss = 0.52783764, grad/param norm = 7.6480e-02, time/batch = 0.1798s	
4876/10550 (epoch 23.109), train_loss = 0.53309224, grad/param norm = 7.6444e-02, time/batch = 0.1796s	
4877/10550 (epoch 23.114), train_loss = 0.52715687, grad/param norm = 7.6093e-02, time/batch = 0.1799s	
4878/10550 (epoch 23.118), train_loss = 0.51599659, grad/param norm = 7.5612e-02, time/batch = 0.1798s	
4879/10550 (epoch 23.123), train_loss = 0.54657763, grad/param norm = 7.7938e-02, time/batch = 0.1799s	
4880/10550 (epoch 23.128), train_loss = 0.53221845, grad/param norm = 7.8062e-02, time/batch = 0.1797s	
4881/10550 (epoch 23.133), train_loss = 0.50900404, grad/param norm = 7.6690e-02, time/batch = 0.1813s	
4882/10550 (epoch 23.137), train_loss = 0.52131041, grad/param norm = 7.8065e-02, time/batch = 0.1796s	
4883/10550 (epoch 23.142), train_loss = 0.54896892, grad/param norm = 8.2429e-02, time/batch = 0.1801s	
4884/10550 (epoch 23.147), train_loss = 0.53065416, grad/param norm = 7.8291e-02, time/batch = 0.1797s	
4885/10550 (epoch 23.152), train_loss = 0.54664706, grad/param norm = 7.8247e-02, time/batch = 0.1800s	
4886/10550 (epoch 23.156), train_loss = 0.52982751, grad/param norm = 7.7163e-02, time/batch = 0.1793s	
4887/10550 (epoch 23.161), train_loss = 0.52531645, grad/param norm = 7.5273e-02, time/batch = 0.1804s	
4888/10550 (epoch 23.166), train_loss = 0.54962174, grad/param norm = 7.7703e-02, time/batch = 0.1795s	
4889/10550 (epoch 23.171), train_loss = 0.50670144, grad/param norm = 7.3975e-02, time/batch = 0.1797s	
4890/10550 (epoch 23.175), train_loss = 0.51818899, grad/param norm = 7.7068e-02, time/batch = 0.1796s	
4891/10550 (epoch 23.180), train_loss = 0.52011266, grad/param norm = 7.7983e-02, time/batch = 0.1809s	
4892/10550 (epoch 23.185), train_loss = 0.53680377, grad/param norm = 7.7255e-02, time/batch = 0.1794s	
4893/10550 (epoch 23.190), train_loss = 0.49945952, grad/param norm = 7.9522e-02, time/batch = 0.1803s	
4894/10550 (epoch 23.194), train_loss = 0.53102555, grad/param norm = 8.0729e-02, time/batch = 0.1804s	
4895/10550 (epoch 23.199), train_loss = 0.54575009, grad/param norm = 7.8525e-02, time/batch = 0.1800s	
4896/10550 (epoch 23.204), train_loss = 0.51898220, grad/param norm = 7.7932e-02, time/batch = 0.1795s	
4897/10550 (epoch 23.209), train_loss = 0.54753857, grad/param norm = 8.0133e-02, time/batch = 0.1799s	
4898/10550 (epoch 23.213), train_loss = 0.54646874, grad/param norm = 8.0855e-02, time/batch = 0.1797s	
4899/10550 (epoch 23.218), train_loss = 0.53505396, grad/param norm = 7.7854e-02, time/batch = 0.1800s	
4900/10550 (epoch 23.223), train_loss = 0.53451486, grad/param norm = 7.7509e-02, time/batch = 0.1797s	
4901/10550 (epoch 23.227), train_loss = 0.52808924, grad/param norm = 7.4359e-02, time/batch = 0.1808s	
4902/10550 (epoch 23.232), train_loss = 0.51345945, grad/param norm = 7.5647e-02, time/batch = 0.1791s	
4903/10550 (epoch 23.237), train_loss = 0.52069829, grad/param norm = 7.2443e-02, time/batch = 0.1798s	
4904/10550 (epoch 23.242), train_loss = 0.50868545, grad/param norm = 7.6815e-02, time/batch = 0.1798s	
4905/10550 (epoch 23.246), train_loss = 0.51607147, grad/param norm = 7.7210e-02, time/batch = 0.1795s	
4906/10550 (epoch 23.251), train_loss = 0.52794161, grad/param norm = 7.5757e-02, time/batch = 0.1801s	
4907/10550 (epoch 23.256), train_loss = 0.53221297, grad/param norm = 7.4959e-02, time/batch = 0.1806s	
4908/10550 (epoch 23.261), train_loss = 0.51727761, grad/param norm = 7.3657e-02, time/batch = 0.1794s	
4909/10550 (epoch 23.265), train_loss = 0.50162014, grad/param norm = 7.7593e-02, time/batch = 0.1801s	
4910/10550 (epoch 23.270), train_loss = 0.52386972, grad/param norm = 7.9445e-02, time/batch = 0.1798s	
4911/10550 (epoch 23.275), train_loss = 0.53097685, grad/param norm = 7.3306e-02, time/batch = 0.1814s	
4912/10550 (epoch 23.280), train_loss = 0.52376287, grad/param norm = 8.0336e-02, time/batch = 0.1794s	
4913/10550 (epoch 23.284), train_loss = 0.51769027, grad/param norm = 7.7730e-02, time/batch = 0.1794s	
4914/10550 (epoch 23.289), train_loss = 0.52976275, grad/param norm = 7.9297e-02, time/batch = 0.1798s	
4915/10550 (epoch 23.294), train_loss = 0.52326557, grad/param norm = 7.9514e-02, time/batch = 0.1801s	
4916/10550 (epoch 23.299), train_loss = 0.50175010, grad/param norm = 7.5737e-02, time/batch = 0.1796s	
4917/10550 (epoch 23.303), train_loss = 0.53323700, grad/param norm = 7.7852e-02, time/batch = 0.1801s	
4918/10550 (epoch 23.308), train_loss = 0.51147225, grad/param norm = 7.5658e-02, time/batch = 0.1794s	
4919/10550 (epoch 23.313), train_loss = 0.50946713, grad/param norm = 7.4837e-02, time/batch = 0.1804s	
4920/10550 (epoch 23.318), train_loss = 0.53191748, grad/param norm = 8.0064e-02, time/batch = 0.1800s	
4921/10550 (epoch 23.322), train_loss = 0.52833148, grad/param norm = 7.8190e-02, time/batch = 0.1808s	
4922/10550 (epoch 23.327), train_loss = 0.51734752, grad/param norm = 7.5943e-02, time/batch = 0.1793s	
4923/10550 (epoch 23.332), train_loss = 0.52974076, grad/param norm = 7.6120e-02, time/batch = 0.1799s	
4924/10550 (epoch 23.336), train_loss = 0.51227881, grad/param norm = 7.7371e-02, time/batch = 0.1795s	
4925/10550 (epoch 23.341), train_loss = 0.49801573, grad/param norm = 7.7902e-02, time/batch = 0.1800s	
4926/10550 (epoch 23.346), train_loss = 0.52042195, grad/param norm = 8.2231e-02, time/batch = 0.1800s	
4927/10550 (epoch 23.351), train_loss = 0.52856393, grad/param norm = 7.8074e-02, time/batch = 0.1804s	
4928/10550 (epoch 23.355), train_loss = 0.51359813, grad/param norm = 7.7300e-02, time/batch = 0.1799s	
4929/10550 (epoch 23.360), train_loss = 0.53723473, grad/param norm = 7.8236e-02, time/batch = 0.1797s	
4930/10550 (epoch 23.365), train_loss = 0.52515789, grad/param norm = 7.6796e-02, time/batch = 0.1797s	
4931/10550 (epoch 23.370), train_loss = 0.52460847, grad/param norm = 7.7792e-02, time/batch = 0.1812s	
4932/10550 (epoch 23.374), train_loss = 0.50845007, grad/param norm = 7.7638e-02, time/batch = 0.1792s	
4933/10550 (epoch 23.379), train_loss = 0.53009488, grad/param norm = 8.0026e-02, time/batch = 0.1796s	
4934/10550 (epoch 23.384), train_loss = 0.52039498, grad/param norm = 8.1910e-02, time/batch = 0.1793s	
4935/10550 (epoch 23.389), train_loss = 0.52763858, grad/param norm = 7.8667e-02, time/batch = 0.1801s	
4936/10550 (epoch 23.393), train_loss = 0.52318530, grad/param norm = 7.6219e-02, time/batch = 0.1793s	
4937/10550 (epoch 23.398), train_loss = 0.50315693, grad/param norm = 7.7533e-02, time/batch = 0.1801s	
4938/10550 (epoch 23.403), train_loss = 0.52376979, grad/param norm = 8.2312e-02, time/batch = 0.1794s	
4939/10550 (epoch 23.408), train_loss = 0.53074149, grad/param norm = 8.4419e-02, time/batch = 0.1800s	
4940/10550 (epoch 23.412), train_loss = 0.51675962, grad/param norm = 7.9405e-02, time/batch = 0.1799s	
4941/10550 (epoch 23.417), train_loss = 0.53434713, grad/param norm = 7.7898e-02, time/batch = 0.1809s	
4942/10550 (epoch 23.422), train_loss = 0.52553998, grad/param norm = 8.1361e-02, time/batch = 0.1790s	
4943/10550 (epoch 23.427), train_loss = 0.53154665, grad/param norm = 7.9342e-02, time/batch = 0.1796s	
4944/10550 (epoch 23.431), train_loss = 0.53937024, grad/param norm = 7.7996e-02, time/batch = 0.1796s	
4945/10550 (epoch 23.436), train_loss = 0.50458846, grad/param norm = 7.5407e-02, time/batch = 0.1801s	
4946/10550 (epoch 23.441), train_loss = 0.52687861, grad/param norm = 7.8217e-02, time/batch = 0.1799s	
4947/10550 (epoch 23.445), train_loss = 0.52987882, grad/param norm = 7.8832e-02, time/batch = 0.1796s	
4948/10550 (epoch 23.450), train_loss = 0.51924810, grad/param norm = 7.9408e-02, time/batch = 0.1798s	
4949/10550 (epoch 23.455), train_loss = 0.52068597, grad/param norm = 7.5435e-02, time/batch = 0.1799s	
4950/10550 (epoch 23.460), train_loss = 0.50196705, grad/param norm = 7.7329e-02, time/batch = 0.1795s	
4951/10550 (epoch 23.464), train_loss = 0.53103299, grad/param norm = 7.9056e-02, time/batch = 0.1807s	
4952/10550 (epoch 23.469), train_loss = 0.51850282, grad/param norm = 7.9585e-02, time/batch = 0.1797s	
4953/10550 (epoch 23.474), train_loss = 0.52922162, grad/param norm = 7.9419e-02, time/batch = 0.1801s	
4954/10550 (epoch 23.479), train_loss = 0.50219629, grad/param norm = 7.7512e-02, time/batch = 0.1801s	
4955/10550 (epoch 23.483), train_loss = 0.51440822, grad/param norm = 8.0193e-02, time/batch = 0.1797s	
4956/10550 (epoch 23.488), train_loss = 0.52023043, grad/param norm = 7.8098e-02, time/batch = 0.1800s	
4957/10550 (epoch 23.493), train_loss = 0.50263912, grad/param norm = 7.8807e-02, time/batch = 0.1800s	
4958/10550 (epoch 23.498), train_loss = 0.53147305, grad/param norm = 7.8718e-02, time/batch = 0.1793s	
4959/10550 (epoch 23.502), train_loss = 0.51474853, grad/param norm = 7.5027e-02, time/batch = 0.1800s	
4960/10550 (epoch 23.507), train_loss = 0.51648318, grad/param norm = 7.9165e-02, time/batch = 0.1799s	
4961/10550 (epoch 23.512), train_loss = 0.50227030, grad/param norm = 7.7961e-02, time/batch = 0.1808s	
4962/10550 (epoch 23.517), train_loss = 0.50892322, grad/param norm = 7.7092e-02, time/batch = 0.1798s	
4963/10550 (epoch 23.521), train_loss = 0.51312183, grad/param norm = 8.0743e-02, time/batch = 0.1798s	
4964/10550 (epoch 23.526), train_loss = 0.48981310, grad/param norm = 7.6625e-02, time/batch = 0.1807s	
4965/10550 (epoch 23.531), train_loss = 0.48398692, grad/param norm = 7.5211e-02, time/batch = 0.1798s	
4966/10550 (epoch 23.536), train_loss = 0.52534567, grad/param norm = 8.0492e-02, time/batch = 0.1795s	
4967/10550 (epoch 23.540), train_loss = 0.51778556, grad/param norm = 7.6908e-02, time/batch = 0.1799s	
4968/10550 (epoch 23.545), train_loss = 0.50940728, grad/param norm = 7.7626e-02, time/batch = 0.1795s	
4969/10550 (epoch 23.550), train_loss = 0.53987934, grad/param norm = 7.8199e-02, time/batch = 0.1806s	
4970/10550 (epoch 23.555), train_loss = 0.52516519, grad/param norm = 7.7256e-02, time/batch = 0.1799s	
4971/10550 (epoch 23.559), train_loss = 0.51680746, grad/param norm = 7.6110e-02, time/batch = 0.1814s	
4972/10550 (epoch 23.564), train_loss = 0.48817025, grad/param norm = 7.2550e-02, time/batch = 0.1792s	
4973/10550 (epoch 23.569), train_loss = 0.50605940, grad/param norm = 7.5115e-02, time/batch = 0.1796s	
4974/10550 (epoch 23.573), train_loss = 0.52618270, grad/param norm = 8.0220e-02, time/batch = 0.1798s	
4975/10550 (epoch 23.578), train_loss = 0.50986746, grad/param norm = 7.3972e-02, time/batch = 0.1802s	
4976/10550 (epoch 23.583), train_loss = 0.51480035, grad/param norm = 7.6641e-02, time/batch = 0.1798s	
4977/10550 (epoch 23.588), train_loss = 0.49492506, grad/param norm = 7.8622e-02, time/batch = 0.1803s	
4978/10550 (epoch 23.592), train_loss = 0.50986457, grad/param norm = 8.0934e-02, time/batch = 0.1796s	
4979/10550 (epoch 23.597), train_loss = 0.52488270, grad/param norm = 8.0010e-02, time/batch = 0.1796s	
4980/10550 (epoch 23.602), train_loss = 0.53015051, grad/param norm = 8.2163e-02, time/batch = 0.1802s	
4981/10550 (epoch 23.607), train_loss = 0.51094024, grad/param norm = 7.8581e-02, time/batch = 0.1809s	
4982/10550 (epoch 23.611), train_loss = 0.49231912, grad/param norm = 7.9261e-02, time/batch = 0.1794s	
4983/10550 (epoch 23.616), train_loss = 0.48611478, grad/param norm = 7.8183e-02, time/batch = 0.1800s	
4984/10550 (epoch 23.621), train_loss = 0.51825252, grad/param norm = 8.0886e-02, time/batch = 0.1795s	
4985/10550 (epoch 23.626), train_loss = 0.51578658, grad/param norm = 8.0107e-02, time/batch = 0.1801s	
4986/10550 (epoch 23.630), train_loss = 0.51009963, grad/param norm = 8.2245e-02, time/batch = 0.1796s	
4987/10550 (epoch 23.635), train_loss = 0.53434750, grad/param norm = 7.8825e-02, time/batch = 0.1799s	
4988/10550 (epoch 23.640), train_loss = 0.52984370, grad/param norm = 7.5095e-02, time/batch = 0.1793s	
4989/10550 (epoch 23.645), train_loss = 0.50499258, grad/param norm = 7.7215e-02, time/batch = 0.1798s	
4990/10550 (epoch 23.649), train_loss = 0.54112604, grad/param norm = 8.0563e-02, time/batch = 0.1795s	
4991/10550 (epoch 23.654), train_loss = 0.52550101, grad/param norm = 7.9486e-02, time/batch = 0.1808s	
4992/10550 (epoch 23.659), train_loss = 0.50038279, grad/param norm = 7.4220e-02, time/batch = 0.1789s	
4993/10550 (epoch 23.664), train_loss = 0.50538965, grad/param norm = 7.7134e-02, time/batch = 0.1800s	
4994/10550 (epoch 23.668), train_loss = 0.49288999, grad/param norm = 7.7697e-02, time/batch = 0.1803s	
4995/10550 (epoch 23.673), train_loss = 0.49814133, grad/param norm = 7.6799e-02, time/batch = 0.1798s	
4996/10550 (epoch 23.678), train_loss = 0.48910916, grad/param norm = 7.3216e-02, time/batch = 0.1796s	
4997/10550 (epoch 23.682), train_loss = 0.48489266, grad/param norm = 7.4265e-02, time/batch = 0.1798s	
4998/10550 (epoch 23.687), train_loss = 0.49323249, grad/param norm = 7.5403e-02, time/batch = 0.1791s	
4999/10550 (epoch 23.692), train_loss = 0.49148385, grad/param norm = 7.5401e-02, time/batch = 0.1802s	
evaluating loss over split index 2	
1/12...	
2/12...	
3/12...	
4/12...	
5/12...	
6/12...	
7/12...	
8/12...	
9/12...	
10/12...	
11/12...	
12/12...	
saving checkpoint to cv/lm_lstm_epoch23.70_2.3934.t7	
5000/10550 (epoch 23.697), train_loss = 0.50236578, grad/param norm = 7.8234e-02, time/batch = 0.1799s	
5001/10550 (epoch 23.701), train_loss = 1.46284268, grad/param norm = 1.2139e-01, time/batch = 0.1821s	
5002/10550 (epoch 23.706), train_loss = 0.52150937, grad/param norm = 8.5159e-02, time/batch = 0.1800s	
5003/10550 (epoch 23.711), train_loss = 0.53159243, grad/param norm = 7.9423e-02, time/batch = 0.1800s	
5004/10550 (epoch 23.716), train_loss = 0.52313757, grad/param norm = 7.9040e-02, time/batch = 0.1798s	
5005/10550 (epoch 23.720), train_loss = 0.54465858, grad/param norm = 8.1569e-02, time/batch = 0.1798s	
5006/10550 (epoch 23.725), train_loss = 0.50414642, grad/param norm = 7.5289e-02, time/batch = 0.1801s	
5007/10550 (epoch 23.730), train_loss = 0.48752090, grad/param norm = 7.8598e-02, time/batch = 0.1800s	
5008/10550 (epoch 23.735), train_loss = 0.49543474, grad/param norm = 7.2689e-02, time/batch = 0.1797s	
5009/10550 (epoch 23.739), train_loss = 0.49363336, grad/param norm = 7.4362e-02, time/batch = 0.1801s	
5010/10550 (epoch 23.744), train_loss = 0.49885333, grad/param norm = 7.5249e-02, time/batch = 0.1800s	
5011/10550 (epoch 23.749), train_loss = 0.52180779, grad/param norm = 7.6904e-02, time/batch = 0.1807s	
5012/10550 (epoch 23.754), train_loss = 0.51145976, grad/param norm = 7.8533e-02, time/batch = 0.1795s	
5013/10550 (epoch 23.758), train_loss = 0.49160898, grad/param norm = 7.8442e-02, time/batch = 0.1803s	
5014/10550 (epoch 23.763), train_loss = 0.49789840, grad/param norm = 8.0996e-02, time/batch = 0.1799s	
5015/10550 (epoch 23.768), train_loss = 0.50952760, grad/param norm = 7.5683e-02, time/batch = 0.1796s	
5016/10550 (epoch 23.773), train_loss = 0.52765789, grad/param norm = 8.1727e-02, time/batch = 0.1799s	
5017/10550 (epoch 23.777), train_loss = 0.50703922, grad/param norm = 7.5600e-02, time/batch = 0.1798s	
5018/10550 (epoch 23.782), train_loss = 0.53977456, grad/param norm = 8.2903e-02, time/batch = 0.1796s	
5019/10550 (epoch 23.787), train_loss = 0.49073958, grad/param norm = 7.5813e-02, time/batch = 0.1798s	
5020/10550 (epoch 23.791), train_loss = 0.49043905, grad/param norm = 7.6548e-02, time/batch = 0.1797s	
5021/10550 (epoch 23.796), train_loss = 0.52087465, grad/param norm = 7.7263e-02, time/batch = 0.1801s	
5022/10550 (epoch 23.801), train_loss = 0.50737269, grad/param norm = 7.6560e-02, time/batch = 0.1798s	
5023/10550 (epoch 23.806), train_loss = 0.51706200, grad/param norm = 7.8810e-02, time/batch = 0.1798s	
5024/10550 (epoch 23.810), train_loss = 0.52924759, grad/param norm = 7.7676e-02, time/batch = 0.1801s	
5025/10550 (epoch 23.815), train_loss = 0.50960440, grad/param norm = 7.6556e-02, time/batch = 0.1799s	
5026/10550 (epoch 23.820), train_loss = 0.49575115, grad/param norm = 7.3910e-02, time/batch = 0.1798s	
5027/10550 (epoch 23.825), train_loss = 0.50909913, grad/param norm = 7.8583e-02, time/batch = 0.1799s	
5028/10550 (epoch 23.829), train_loss = 0.51479871, grad/param norm = 7.7602e-02, time/batch = 0.1798s	
5029/10550 (epoch 23.834), train_loss = 0.50716644, grad/param norm = 7.9581e-02, time/batch = 0.1799s	
5030/10550 (epoch 23.839), train_loss = 0.50766337, grad/param norm = 7.7970e-02, time/batch = 0.1796s	
5031/10550 (epoch 23.844), train_loss = 0.50675063, grad/param norm = 7.8547e-02, time/batch = 0.1805s	
5032/10550 (epoch 23.848), train_loss = 0.50815361, grad/param norm = 7.7246e-02, time/batch = 0.1787s	
5033/10550 (epoch 23.853), train_loss = 0.51872906, grad/param norm = 7.9009e-02, time/batch = 0.1797s	
5034/10550 (epoch 23.858), train_loss = 0.53532493, grad/param norm = 8.0098e-02, time/batch = 0.1798s	
5035/10550 (epoch 23.863), train_loss = 0.50391876, grad/param norm = 7.6830e-02, time/batch = 0.1799s	
5036/10550 (epoch 23.867), train_loss = 0.49970440, grad/param norm = 7.5041e-02, time/batch = 0.1798s	
5037/10550 (epoch 23.872), train_loss = 0.52057368, grad/param norm = 7.8865e-02, time/batch = 0.1797s	
5038/10550 (epoch 23.877), train_loss = 0.49996112, grad/param norm = 7.5661e-02, time/batch = 0.1792s	
5039/10550 (epoch 23.882), train_loss = 0.50577441, grad/param norm = 7.8679e-02, time/batch = 0.1803s	
5040/10550 (epoch 23.886), train_loss = 0.50229420, grad/param norm = 7.7069e-02, time/batch = 0.1802s	
5041/10550 (epoch 23.891), train_loss = 0.49322230, grad/param norm = 7.7265e-02, time/batch = 0.1813s	
5042/10550 (epoch 23.896), train_loss = 0.51150142, grad/param norm = 8.2742e-02, time/batch = 0.1795s	
5043/10550 (epoch 23.900), train_loss = 0.49977136, grad/param norm = 7.4950e-02, time/batch = 0.1796s	
5044/10550 (epoch 23.905), train_loss = 0.48999890, grad/param norm = 7.6666e-02, time/batch = 0.1796s	
5045/10550 (epoch 23.910), train_loss = 0.48705797, grad/param norm = 7.7546e-02, time/batch = 0.1797s	
5046/10550 (epoch 23.915), train_loss = 0.50129091, grad/param norm = 7.7825e-02, time/batch = 0.1799s	
5047/10550 (epoch 23.919), train_loss = 0.51392080, grad/param norm = 7.8690e-02, time/batch = 0.1802s	
5048/10550 (epoch 23.924), train_loss = 0.51362620, grad/param norm = 7.7315e-02, time/batch = 0.1799s	
5049/10550 (epoch 23.929), train_loss = 0.51601839, grad/param norm = 7.6214e-02, time/batch = 0.1802s	
5050/10550 (epoch 23.934), train_loss = 0.48742801, grad/param norm = 7.5235e-02, time/batch = 0.1797s	
5051/10550 (epoch 23.938), train_loss = 0.52195532, grad/param norm = 8.2103e-02, time/batch = 0.1814s	
5052/10550 (epoch 23.943), train_loss = 0.51772856, grad/param norm = 8.0551e-02, time/batch = 0.1797s	
5053/10550 (epoch 23.948), train_loss = 0.51872467, grad/param norm = 8.1001e-02, time/batch = 0.1793s	
5054/10550 (epoch 23.953), train_loss = 0.52804802, grad/param norm = 8.0199e-02, time/batch = 0.1803s	
5055/10550 (epoch 23.957), train_loss = 0.50748618, grad/param norm = 7.8937e-02, time/batch = 0.1802s	
5056/10550 (epoch 23.962), train_loss = 0.50986095, grad/param norm = 7.6112e-02, time/batch = 0.1800s	
5057/10550 (epoch 23.967), train_loss = 0.52588838, grad/param norm = 7.9177e-02, time/batch = 0.1797s	
5058/10550 (epoch 23.972), train_loss = 0.50193947, grad/param norm = 7.8302e-02, time/batch = 0.1799s	
5059/10550 (epoch 23.976), train_loss = 0.50054821, grad/param norm = 7.7414e-02, time/batch = 0.1803s	
5060/10550 (epoch 23.981), train_loss = 0.50004296, grad/param norm = 7.6258e-02, time/batch = 0.1799s	
5061/10550 (epoch 23.986), train_loss = 0.49877058, grad/param norm = 7.7689e-02, time/batch = 0.1809s	
5062/10550 (epoch 23.991), train_loss = 0.52009489, grad/param norm = 8.1177e-02, time/batch = 0.1793s	
5063/10550 (epoch 23.995), train_loss = 0.50833882, grad/param norm = 7.7559e-02, time/batch = 0.1796s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
5064/10550 (epoch 24.000), train_loss = 0.51634177, grad/param norm = 7.9105e-02, time/batch = 0.1797s	
5065/10550 (epoch 24.005), train_loss = 0.68717825, grad/param norm = 8.1745e-02, time/batch = 0.1802s	
5066/10550 (epoch 24.009), train_loss = 0.50637595, grad/param norm = 8.0009e-02, time/batch = 0.1800s	
5067/10550 (epoch 24.014), train_loss = 0.51034839, grad/param norm = 7.7209e-02, time/batch = 0.1800s	
5068/10550 (epoch 24.019), train_loss = 0.54281842, grad/param norm = 8.2210e-02, time/batch = 0.1794s	
5069/10550 (epoch 24.024), train_loss = 0.53046851, grad/param norm = 8.0031e-02, time/batch = 0.1801s	
5070/10550 (epoch 24.028), train_loss = 0.50530760, grad/param norm = 7.8374e-02, time/batch = 0.1801s	
5071/10550 (epoch 24.033), train_loss = 0.52396395, grad/param norm = 7.7380e-02, time/batch = 0.1813s	
5072/10550 (epoch 24.038), train_loss = 0.50655940, grad/param norm = 7.7624e-02, time/batch = 0.1799s	
5073/10550 (epoch 24.043), train_loss = 0.49901318, grad/param norm = 7.6303e-02, time/batch = 0.1798s	
5074/10550 (epoch 24.047), train_loss = 0.50228715, grad/param norm = 7.6834e-02, time/batch = 0.1797s	
5075/10550 (epoch 24.052), train_loss = 0.51322467, grad/param norm = 7.7671e-02, time/batch = 0.1800s	
5076/10550 (epoch 24.057), train_loss = 0.51597172, grad/param norm = 7.8407e-02, time/batch = 0.1805s	
5077/10550 (epoch 24.062), train_loss = 0.51174493, grad/param norm = 7.6302e-02, time/batch = 0.1797s	
5078/10550 (epoch 24.066), train_loss = 0.50722904, grad/param norm = 7.5740e-02, time/batch = 0.1796s	
5079/10550 (epoch 24.071), train_loss = 0.50307061, grad/param norm = 7.5380e-02, time/batch = 0.1799s	
5080/10550 (epoch 24.076), train_loss = 0.49159970, grad/param norm = 7.7013e-02, time/batch = 0.1796s	
5081/10550 (epoch 24.081), train_loss = 0.51345471, grad/param norm = 7.7584e-02, time/batch = 0.1813s	
5082/10550 (epoch 24.085), train_loss = 0.50549675, grad/param norm = 7.8901e-02, time/batch = 0.1798s	
5083/10550 (epoch 24.090), train_loss = 0.49697203, grad/param norm = 7.8101e-02, time/batch = 0.1796s	
5084/10550 (epoch 24.095), train_loss = 0.52101422, grad/param norm = 7.6251e-02, time/batch = 0.1798s	
5085/10550 (epoch 24.100), train_loss = 0.51835172, grad/param norm = 8.0034e-02, time/batch = 0.1803s	
5086/10550 (epoch 24.104), train_loss = 0.49928791, grad/param norm = 7.5075e-02, time/batch = 0.1802s	
5087/10550 (epoch 24.109), train_loss = 0.49522855, grad/param norm = 7.5490e-02, time/batch = 0.1798s	
5088/10550 (epoch 24.114), train_loss = 0.51226970, grad/param norm = 7.9646e-02, time/batch = 0.1796s	
5089/10550 (epoch 24.118), train_loss = 0.49375055, grad/param norm = 7.4721e-02, time/batch = 0.1799s	
5090/10550 (epoch 24.123), train_loss = 0.50792870, grad/param norm = 7.7835e-02, time/batch = 0.1799s	
5091/10550 (epoch 24.128), train_loss = 0.50254383, grad/param norm = 7.6254e-02, time/batch = 0.1808s	
5092/10550 (epoch 24.133), train_loss = 0.49807900, grad/param norm = 8.0322e-02, time/batch = 0.1794s	
5093/10550 (epoch 24.137), train_loss = 0.50179885, grad/param norm = 7.9701e-02, time/batch = 0.1801s	
5094/10550 (epoch 24.142), train_loss = 0.52553789, grad/param norm = 8.3732e-02, time/batch = 0.1801s	
5095/10550 (epoch 24.147), train_loss = 0.49932092, grad/param norm = 7.6598e-02, time/batch = 0.1800s	
5096/10550 (epoch 24.152), train_loss = 0.51693842, grad/param norm = 7.9529e-02, time/batch = 0.1799s	
5097/10550 (epoch 24.156), train_loss = 0.50191500, grad/param norm = 8.0178e-02, time/batch = 0.1803s	
5098/10550 (epoch 24.161), train_loss = 0.50710244, grad/param norm = 7.8564e-02, time/batch = 0.1796s	
5099/10550 (epoch 24.166), train_loss = 0.53340324, grad/param norm = 8.0066e-02, time/batch = 0.1797s	
5100/10550 (epoch 24.171), train_loss = 0.49388249, grad/param norm = 7.8301e-02, time/batch = 0.1797s	
5101/10550 (epoch 24.175), train_loss = 0.50576210, grad/param norm = 7.8861e-02, time/batch = 0.1809s	
5102/10550 (epoch 24.180), train_loss = 0.49707824, grad/param norm = 7.9878e-02, time/batch = 0.1797s	
5103/10550 (epoch 24.185), train_loss = 0.51647988, grad/param norm = 7.9447e-02, time/batch = 0.1798s	
5104/10550 (epoch 24.190), train_loss = 0.47682232, grad/param norm = 7.9748e-02, time/batch = 0.1799s	
5105/10550 (epoch 24.194), train_loss = 0.50590786, grad/param norm = 8.0806e-02, time/batch = 0.1803s	
5106/10550 (epoch 24.199), train_loss = 0.52740981, grad/param norm = 8.1139e-02, time/batch = 0.1799s	
5107/10550 (epoch 24.204), train_loss = 0.50075882, grad/param norm = 7.9889e-02, time/batch = 0.1799s	
5108/10550 (epoch 24.209), train_loss = 0.51302213, grad/param norm = 7.7310e-02, time/batch = 0.1798s	
5109/10550 (epoch 24.213), train_loss = 0.52537610, grad/param norm = 7.8997e-02, time/batch = 0.1804s	
5110/10550 (epoch 24.218), train_loss = 0.50249929, grad/param norm = 7.8782e-02, time/batch = 0.1796s	
5111/10550 (epoch 24.223), train_loss = 0.50116379, grad/param norm = 7.7332e-02, time/batch = 0.1808s	
5112/10550 (epoch 24.227), train_loss = 0.49162991, grad/param norm = 7.3828e-02, time/batch = 0.1794s	
5113/10550 (epoch 24.232), train_loss = 0.48544610, grad/param norm = 7.6975e-02, time/batch = 0.1793s	
5114/10550 (epoch 24.237), train_loss = 0.50584984, grad/param norm = 8.0540e-02, time/batch = 0.1798s	
5115/10550 (epoch 24.242), train_loss = 0.49102005, grad/param norm = 7.9147e-02, time/batch = 0.1796s	
5116/10550 (epoch 24.246), train_loss = 0.48146756, grad/param norm = 7.6522e-02, time/batch = 0.1799s	
5117/10550 (epoch 24.251), train_loss = 0.50495090, grad/param norm = 7.7130e-02, time/batch = 0.1798s	
5118/10550 (epoch 24.256), train_loss = 0.51248030, grad/param norm = 7.7889e-02, time/batch = 0.1795s	
5119/10550 (epoch 24.261), train_loss = 0.48079567, grad/param norm = 7.4846e-02, time/batch = 0.1801s	
5120/10550 (epoch 24.265), train_loss = 0.47893680, grad/param norm = 7.8146e-02, time/batch = 0.1802s	
5121/10550 (epoch 24.270), train_loss = 0.49235888, grad/param norm = 7.7834e-02, time/batch = 0.1809s	
5122/10550 (epoch 24.275), train_loss = 0.51888604, grad/param norm = 7.6425e-02, time/batch = 0.1797s	
5123/10550 (epoch 24.280), train_loss = 0.48990994, grad/param norm = 7.6224e-02, time/batch = 0.1799s	
5124/10550 (epoch 24.284), train_loss = 0.49258637, grad/param norm = 7.7274e-02, time/batch = 0.1805s	
5125/10550 (epoch 24.289), train_loss = 0.49300478, grad/param norm = 7.6204e-02, time/batch = 0.1798s	
5126/10550 (epoch 24.294), train_loss = 0.49442016, grad/param norm = 8.1449e-02, time/batch = 0.1801s	
5127/10550 (epoch 24.299), train_loss = 0.47666685, grad/param norm = 7.5152e-02, time/batch = 0.1802s	
5128/10550 (epoch 24.303), train_loss = 0.51294431, grad/param norm = 8.0677e-02, time/batch = 0.1792s	
5129/10550 (epoch 24.308), train_loss = 0.49485041, grad/param norm = 7.9056e-02, time/batch = 0.1806s	
5130/10550 (epoch 24.313), train_loss = 0.49047433, grad/param norm = 7.7863e-02, time/batch = 0.1801s	
5131/10550 (epoch 24.318), train_loss = 0.48213118, grad/param norm = 7.7134e-02, time/batch = 0.1813s	
5132/10550 (epoch 24.322), train_loss = 0.50077856, grad/param norm = 7.7992e-02, time/batch = 0.1793s	
5133/10550 (epoch 24.327), train_loss = 0.50595957, grad/param norm = 7.9743e-02, time/batch = 0.1793s	
5134/10550 (epoch 24.332), train_loss = 0.50005684, grad/param norm = 7.6767e-02, time/batch = 0.1796s	
5135/10550 (epoch 24.336), train_loss = 0.49316736, grad/param norm = 8.0046e-02, time/batch = 0.1800s	
5136/10550 (epoch 24.341), train_loss = 0.47127201, grad/param norm = 7.6089e-02, time/batch = 0.1797s	
5137/10550 (epoch 24.346), train_loss = 0.50926719, grad/param norm = 8.4152e-02, time/batch = 0.1798s	
5138/10550 (epoch 24.351), train_loss = 0.50017523, grad/param norm = 7.8048e-02, time/batch = 0.1797s	
5139/10550 (epoch 24.355), train_loss = 0.49857492, grad/param norm = 7.7778e-02, time/batch = 0.1802s	
5140/10550 (epoch 24.360), train_loss = 0.50902078, grad/param norm = 8.3006e-02, time/batch = 0.1798s	
5141/10550 (epoch 24.365), train_loss = 0.49424522, grad/param norm = 7.6924e-02, time/batch = 0.1811s	
5142/10550 (epoch 24.370), train_loss = 0.48468343, grad/param norm = 7.4854e-02, time/batch = 0.1793s	
5143/10550 (epoch 24.374), train_loss = 0.48682710, grad/param norm = 7.8170e-02, time/batch = 0.1794s	
5144/10550 (epoch 24.379), train_loss = 0.49780829, grad/param norm = 7.8338e-02, time/batch = 0.1800s	
5145/10550 (epoch 24.384), train_loss = 0.49120713, grad/param norm = 7.9508e-02, time/batch = 0.1800s	
5146/10550 (epoch 24.389), train_loss = 0.50060934, grad/param norm = 7.7738e-02, time/batch = 0.1797s	
5147/10550 (epoch 24.393), train_loss = 0.49123192, grad/param norm = 7.6304e-02, time/batch = 0.1797s	
5148/10550 (epoch 24.398), train_loss = 0.48238501, grad/param norm = 7.4613e-02, time/batch = 0.1799s	
5149/10550 (epoch 24.403), train_loss = 0.50037196, grad/param norm = 8.0297e-02, time/batch = 0.1803s	
5150/10550 (epoch 24.408), train_loss = 0.50444851, grad/param norm = 8.1824e-02, time/batch = 0.1801s	
5151/10550 (epoch 24.412), train_loss = 0.49520308, grad/param norm = 7.7361e-02, time/batch = 0.1811s	
5152/10550 (epoch 24.417), train_loss = 0.50505734, grad/param norm = 7.7479e-02, time/batch = 0.1789s	
5153/10550 (epoch 24.422), train_loss = 0.50552941, grad/param norm = 8.0787e-02, time/batch = 0.1797s	
5154/10550 (epoch 24.427), train_loss = 0.50159459, grad/param norm = 7.6604e-02, time/batch = 0.1801s	
5155/10550 (epoch 24.431), train_loss = 0.50387459, grad/param norm = 7.6709e-02, time/batch = 0.1804s	
5156/10550 (epoch 24.436), train_loss = 0.48801832, grad/param norm = 7.8281e-02, time/batch = 0.1800s	
5157/10550 (epoch 24.441), train_loss = 0.51047304, grad/param norm = 8.1667e-02, time/batch = 0.1801s	
5158/10550 (epoch 24.445), train_loss = 0.49867855, grad/param norm = 7.9282e-02, time/batch = 0.1794s	
5159/10550 (epoch 24.450), train_loss = 0.49850188, grad/param norm = 7.7595e-02, time/batch = 0.1804s	
5160/10550 (epoch 24.455), train_loss = 0.49749463, grad/param norm = 7.9131e-02, time/batch = 0.1798s	
5161/10550 (epoch 24.460), train_loss = 0.48337517, grad/param norm = 7.7457e-02, time/batch = 0.1814s	
5162/10550 (epoch 24.464), train_loss = 0.50340473, grad/param norm = 7.7026e-02, time/batch = 0.1797s	
5163/10550 (epoch 24.469), train_loss = 0.49324337, grad/param norm = 7.7840e-02, time/batch = 0.1797s	
5164/10550 (epoch 24.474), train_loss = 0.50114815, grad/param norm = 7.8322e-02, time/batch = 0.1799s	
5165/10550 (epoch 24.479), train_loss = 0.48120966, grad/param norm = 7.6117e-02, time/batch = 0.1800s	
5166/10550 (epoch 24.483), train_loss = 0.48240536, grad/param norm = 7.8063e-02, time/batch = 0.1801s	
5167/10550 (epoch 24.488), train_loss = 0.50608249, grad/param norm = 8.0320e-02, time/batch = 0.1797s	
5168/10550 (epoch 24.493), train_loss = 0.48083938, grad/param norm = 7.7576e-02, time/batch = 0.1794s	
5169/10550 (epoch 24.498), train_loss = 0.49794680, grad/param norm = 7.6052e-02, time/batch = 0.1800s	
5170/10550 (epoch 24.502), train_loss = 0.49052339, grad/param norm = 7.5686e-02, time/batch = 0.1799s	
5171/10550 (epoch 24.507), train_loss = 0.47568306, grad/param norm = 7.4151e-02, time/batch = 0.1812s	
5172/10550 (epoch 24.512), train_loss = 0.49011332, grad/param norm = 8.0670e-02, time/batch = 0.1795s	
5173/10550 (epoch 24.517), train_loss = 0.48236627, grad/param norm = 7.8107e-02, time/batch = 0.1795s	
5174/10550 (epoch 24.521), train_loss = 0.49064605, grad/param norm = 7.7369e-02, time/batch = 0.1799s	
5175/10550 (epoch 24.526), train_loss = 0.44603930, grad/param norm = 7.3301e-02, time/batch = 0.1800s	
5176/10550 (epoch 24.531), train_loss = 0.46236816, grad/param norm = 7.4123e-02, time/batch = 0.1800s	
5177/10550 (epoch 24.536), train_loss = 0.50882885, grad/param norm = 7.8588e-02, time/batch = 0.1798s	
5178/10550 (epoch 24.540), train_loss = 0.48942050, grad/param norm = 8.0228e-02, time/batch = 0.1798s	
5179/10550 (epoch 24.545), train_loss = 0.48642792, grad/param norm = 7.7279e-02, time/batch = 0.1796s	
5180/10550 (epoch 24.550), train_loss = 0.50941675, grad/param norm = 8.0038e-02, time/batch = 0.1795s	
5181/10550 (epoch 24.555), train_loss = 0.49479061, grad/param norm = 7.7869e-02, time/batch = 0.1810s	
5182/10550 (epoch 24.559), train_loss = 0.48620052, grad/param norm = 7.9374e-02, time/batch = 0.1792s	
5183/10550 (epoch 24.564), train_loss = 0.47295767, grad/param norm = 7.5418e-02, time/batch = 0.1797s	
5184/10550 (epoch 24.569), train_loss = 0.48346482, grad/param norm = 7.5902e-02, time/batch = 0.1800s	
5185/10550 (epoch 24.573), train_loss = 0.49131385, grad/param norm = 7.5915e-02, time/batch = 0.1795s	
5186/10550 (epoch 24.578), train_loss = 0.49048051, grad/param norm = 7.8419e-02, time/batch = 0.1797s	
5187/10550 (epoch 24.583), train_loss = 0.49345846, grad/param norm = 7.9239e-02, time/batch = 0.1794s	
5188/10550 (epoch 24.588), train_loss = 0.46269774, grad/param norm = 7.4265e-02, time/batch = 0.1792s	
5189/10550 (epoch 24.592), train_loss = 0.48846076, grad/param norm = 7.9488e-02, time/batch = 0.1799s	
5190/10550 (epoch 24.597), train_loss = 0.49102206, grad/param norm = 8.2407e-02, time/batch = 0.1800s	
5191/10550 (epoch 24.602), train_loss = 0.48772144, grad/param norm = 7.7891e-02, time/batch = 0.1813s	
5192/10550 (epoch 24.607), train_loss = 0.47596340, grad/param norm = 7.6334e-02, time/batch = 0.1793s	
5193/10550 (epoch 24.611), train_loss = 0.46952395, grad/param norm = 7.8270e-02, time/batch = 0.1800s	
5194/10550 (epoch 24.616), train_loss = 0.48395544, grad/param norm = 7.9268e-02, time/batch = 0.1797s	
5195/10550 (epoch 24.621), train_loss = 0.48227994, grad/param norm = 7.5679e-02, time/batch = 0.1800s	
5196/10550 (epoch 24.626), train_loss = 0.47840730, grad/param norm = 8.0675e-02, time/batch = 0.1800s	
5197/10550 (epoch 24.630), train_loss = 0.48591040, grad/param norm = 8.1487e-02, time/batch = 0.1801s	
5198/10550 (epoch 24.635), train_loss = 0.52722739, grad/param norm = 8.8282e-02, time/batch = 0.1793s	
5199/10550 (epoch 24.640), train_loss = 0.49946675, grad/param norm = 7.5581e-02, time/batch = 0.1801s	
5200/10550 (epoch 24.645), train_loss = 0.48315458, grad/param norm = 7.6328e-02, time/batch = 0.1803s	
5201/10550 (epoch 24.649), train_loss = 0.49481136, grad/param norm = 7.6675e-02, time/batch = 0.1810s	
5202/10550 (epoch 24.654), train_loss = 0.48377428, grad/param norm = 7.6055e-02, time/batch = 0.1797s	
5203/10550 (epoch 24.659), train_loss = 0.47904066, grad/param norm = 7.6728e-02, time/batch = 0.1800s	
5204/10550 (epoch 24.664), train_loss = 0.48891848, grad/param norm = 7.9951e-02, time/batch = 0.1796s	
5205/10550 (epoch 24.668), train_loss = 0.47415695, grad/param norm = 8.1757e-02, time/batch = 0.1798s	
5206/10550 (epoch 24.673), train_loss = 0.47517763, grad/param norm = 7.8002e-02, time/batch = 0.1798s	
5207/10550 (epoch 24.678), train_loss = 0.46497154, grad/param norm = 7.4067e-02, time/batch = 0.1803s	
5208/10550 (epoch 24.682), train_loss = 0.47389341, grad/param norm = 7.6001e-02, time/batch = 0.1800s	
5209/10550 (epoch 24.687), train_loss = 0.46831334, grad/param norm = 7.7520e-02, time/batch = 0.1797s	
5210/10550 (epoch 24.692), train_loss = 0.47610137, grad/param norm = 7.6985e-02, time/batch = 0.1802s	
5211/10550 (epoch 24.697), train_loss = 0.46992837, grad/param norm = 7.7802e-02, time/batch = 0.1813s	
5212/10550 (epoch 24.701), train_loss = 0.51467463, grad/param norm = 7.9945e-02, time/batch = 0.1796s	
5213/10550 (epoch 24.706), train_loss = 0.46262585, grad/param norm = 8.0156e-02, time/batch = 0.1799s	
5214/10550 (epoch 24.711), train_loss = 0.49873681, grad/param norm = 7.6889e-02, time/batch = 0.1803s	
5215/10550 (epoch 24.716), train_loss = 0.48359513, grad/param norm = 7.6025e-02, time/batch = 0.1800s	
5216/10550 (epoch 24.720), train_loss = 0.50335440, grad/param norm = 7.7056e-02, time/batch = 0.1804s	
5217/10550 (epoch 24.725), train_loss = 0.48756778, grad/param norm = 7.5220e-02, time/batch = 0.1800s	
5218/10550 (epoch 24.730), train_loss = 0.45932220, grad/param norm = 7.7973e-02, time/batch = 0.1798s	
5219/10550 (epoch 24.735), train_loss = 0.48112270, grad/param norm = 8.0318e-02, time/batch = 0.1801s	
5220/10550 (epoch 24.739), train_loss = 0.47093228, grad/param norm = 7.8248e-02, time/batch = 0.1800s	
5221/10550 (epoch 24.744), train_loss = 0.46761683, grad/param norm = 7.6615e-02, time/batch = 0.1810s	
5222/10550 (epoch 24.749), train_loss = 0.49851499, grad/param norm = 7.7275e-02, time/batch = 0.1794s	
5223/10550 (epoch 24.754), train_loss = 0.47723430, grad/param norm = 7.4642e-02, time/batch = 0.1798s	
5224/10550 (epoch 24.758), train_loss = 0.46635063, grad/param norm = 7.8899e-02, time/batch = 0.1801s	
5225/10550 (epoch 24.763), train_loss = 0.45147604, grad/param norm = 7.6613e-02, time/batch = 0.1800s	
5226/10550 (epoch 24.768), train_loss = 0.47360533, grad/param norm = 7.5227e-02, time/batch = 0.1796s	
5227/10550 (epoch 24.773), train_loss = 0.48761906, grad/param norm = 7.9465e-02, time/batch = 0.1802s	
5228/10550 (epoch 24.777), train_loss = 0.48291767, grad/param norm = 7.4073e-02, time/batch = 0.1793s	
5229/10550 (epoch 24.782), train_loss = 0.50763375, grad/param norm = 7.9468e-02, time/batch = 0.1803s	
5230/10550 (epoch 24.787), train_loss = 0.47395243, grad/param norm = 7.9850e-02, time/batch = 0.1800s	
5231/10550 (epoch 24.791), train_loss = 0.46851431, grad/param norm = 7.6975e-02, time/batch = 0.1807s	
5232/10550 (epoch 24.796), train_loss = 0.49748843, grad/param norm = 7.8980e-02, time/batch = 0.1795s	
5233/10550 (epoch 24.801), train_loss = 0.48690664, grad/param norm = 7.7208e-02, time/batch = 0.1792s	
5234/10550 (epoch 24.806), train_loss = 0.49084753, grad/param norm = 8.0506e-02, time/batch = 0.1798s	
5235/10550 (epoch 24.810), train_loss = 0.50421270, grad/param norm = 7.8089e-02, time/batch = 0.1800s	
5236/10550 (epoch 24.815), train_loss = 0.47641709, grad/param norm = 7.6416e-02, time/batch = 0.1797s	
5237/10550 (epoch 24.820), train_loss = 0.46611688, grad/param norm = 7.6475e-02, time/batch = 0.1801s	
5238/10550 (epoch 24.825), train_loss = 0.49150341, grad/param norm = 7.6352e-02, time/batch = 0.1794s	
5239/10550 (epoch 24.829), train_loss = 0.47283044, grad/param norm = 7.5837e-02, time/batch = 0.1802s	
5240/10550 (epoch 24.834), train_loss = 0.48272968, grad/param norm = 7.9845e-02, time/batch = 0.1798s	
5241/10550 (epoch 24.839), train_loss = 0.47991782, grad/param norm = 7.6866e-02, time/batch = 0.1810s	
5242/10550 (epoch 24.844), train_loss = 0.47363319, grad/param norm = 7.9238e-02, time/batch = 0.1790s	
5243/10550 (epoch 24.848), train_loss = 0.48448256, grad/param norm = 7.9818e-02, time/batch = 0.1795s	
5244/10550 (epoch 24.853), train_loss = 0.50116975, grad/param norm = 8.0276e-02, time/batch = 0.1795s	
5245/10550 (epoch 24.858), train_loss = 0.51294123, grad/param norm = 8.5003e-02, time/batch = 0.1801s	
5246/10550 (epoch 24.863), train_loss = 0.48296387, grad/param norm = 7.7762e-02, time/batch = 0.1797s	
5247/10550 (epoch 24.867), train_loss = 0.48909218, grad/param norm = 7.9534e-02, time/batch = 0.1797s	
5248/10550 (epoch 24.872), train_loss = 0.49770781, grad/param norm = 7.7520e-02, time/batch = 0.1795s	
5249/10550 (epoch 24.877), train_loss = 0.46940996, grad/param norm = 7.6529e-02, time/batch = 0.1802s	
5250/10550 (epoch 24.882), train_loss = 0.48802025, grad/param norm = 8.1430e-02, time/batch = 0.1803s	
5251/10550 (epoch 24.886), train_loss = 0.47524129, grad/param norm = 7.7364e-02, time/batch = 0.1804s	
5252/10550 (epoch 24.891), train_loss = 0.46278226, grad/param norm = 7.6541e-02, time/batch = 0.1796s	
5253/10550 (epoch 24.896), train_loss = 0.46989299, grad/param norm = 7.8990e-02, time/batch = 0.1798s	
5254/10550 (epoch 24.900), train_loss = 0.48667784, grad/param norm = 7.7243e-02, time/batch = 0.1797s	
5255/10550 (epoch 24.905), train_loss = 0.45823357, grad/param norm = 7.6771e-02, time/batch = 0.1802s	
5256/10550 (epoch 24.910), train_loss = 0.46049743, grad/param norm = 7.8194e-02, time/batch = 0.1799s	
5257/10550 (epoch 24.915), train_loss = 0.47173480, grad/param norm = 7.8365e-02, time/batch = 0.1800s	
5258/10550 (epoch 24.919), train_loss = 0.46428962, grad/param norm = 7.4873e-02, time/batch = 0.1794s	
5259/10550 (epoch 24.924), train_loss = 0.48339985, grad/param norm = 7.7355e-02, time/batch = 0.1800s	
5260/10550 (epoch 24.929), train_loss = 0.49728059, grad/param norm = 7.9373e-02, time/batch = 0.1797s	
5261/10550 (epoch 24.934), train_loss = 0.46943259, grad/param norm = 7.8958e-02, time/batch = 0.1808s	
5262/10550 (epoch 24.938), train_loss = 0.49407609, grad/param norm = 8.0562e-02, time/batch = 0.1790s	
5263/10550 (epoch 24.943), train_loss = 0.49291718, grad/param norm = 7.7598e-02, time/batch = 0.1800s	
5264/10550 (epoch 24.948), train_loss = 0.47817965, grad/param norm = 7.7875e-02, time/batch = 0.1797s	
5265/10550 (epoch 24.953), train_loss = 0.51576743, grad/param norm = 8.3138e-02, time/batch = 0.1801s	
5266/10550 (epoch 24.957), train_loss = 0.49360097, grad/param norm = 7.8338e-02, time/batch = 0.1801s	
5267/10550 (epoch 24.962), train_loss = 0.48895014, grad/param norm = 7.8237e-02, time/batch = 0.1798s	
5268/10550 (epoch 24.967), train_loss = 0.49910125, grad/param norm = 7.9035e-02, time/batch = 0.1791s	
5269/10550 (epoch 24.972), train_loss = 0.47186305, grad/param norm = 7.7969e-02, time/batch = 0.1801s	
5270/10550 (epoch 24.976), train_loss = 0.46702366, grad/param norm = 7.2809e-02, time/batch = 0.1799s	
5271/10550 (epoch 24.981), train_loss = 0.46811233, grad/param norm = 7.6764e-02, time/batch = 0.1809s	
5272/10550 (epoch 24.986), train_loss = 0.47239903, grad/param norm = 7.6402e-02, time/batch = 0.1792s	
5273/10550 (epoch 24.991), train_loss = 0.49248993, grad/param norm = 8.0324e-02, time/batch = 0.1796s	
5274/10550 (epoch 24.995), train_loss = 0.47745182, grad/param norm = 7.7715e-02, time/batch = 0.1798s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
5275/10550 (epoch 25.000), train_loss = 0.49148463, grad/param norm = 7.8890e-02, time/batch = 0.1796s	
5276/10550 (epoch 25.005), train_loss = 0.67804139, grad/param norm = 8.5628e-02, time/batch = 0.1799s	
5277/10550 (epoch 25.009), train_loss = 0.49140234, grad/param norm = 8.0226e-02, time/batch = 0.1798s	
5278/10550 (epoch 25.014), train_loss = 0.48827173, grad/param norm = 7.6195e-02, time/batch = 0.1794s	
5279/10550 (epoch 25.019), train_loss = 0.52041127, grad/param norm = 8.1960e-02, time/batch = 0.1802s	
5280/10550 (epoch 25.024), train_loss = 0.49325935, grad/param norm = 8.0203e-02, time/batch = 0.1796s	
5281/10550 (epoch 25.028), train_loss = 0.47912943, grad/param norm = 7.8065e-02, time/batch = 0.1812s	
5282/10550 (epoch 25.033), train_loss = 0.49607948, grad/param norm = 7.6981e-02, time/batch = 0.1795s	
5283/10550 (epoch 25.038), train_loss = 0.48921622, grad/param norm = 7.6282e-02, time/batch = 0.1798s	
5284/10550 (epoch 25.043), train_loss = 0.46886045, grad/param norm = 7.5203e-02, time/batch = 0.1799s	
5285/10550 (epoch 25.047), train_loss = 0.47400476, grad/param norm = 7.6709e-02, time/batch = 0.1795s	
5286/10550 (epoch 25.052), train_loss = 0.48532049, grad/param norm = 7.7629e-02, time/batch = 0.1800s	
5287/10550 (epoch 25.057), train_loss = 0.48605902, grad/param norm = 7.4816e-02, time/batch = 0.1799s	
5288/10550 (epoch 25.062), train_loss = 0.48425344, grad/param norm = 7.7320e-02, time/batch = 0.1796s	
5289/10550 (epoch 25.066), train_loss = 0.47243376, grad/param norm = 7.4948e-02, time/batch = 0.1799s	
5290/10550 (epoch 25.071), train_loss = 0.47932806, grad/param norm = 7.8711e-02, time/batch = 0.1801s	
5291/10550 (epoch 25.076), train_loss = 0.49015966, grad/param norm = 8.3111e-02, time/batch = 0.1807s	
5292/10550 (epoch 25.081), train_loss = 0.48243024, grad/param norm = 7.7749e-02, time/batch = 0.1792s	
5293/10550 (epoch 25.085), train_loss = 0.47782670, grad/param norm = 7.8116e-02, time/batch = 0.1799s	
5294/10550 (epoch 25.090), train_loss = 0.47878738, grad/param norm = 7.7280e-02, time/batch = 0.1797s	
5295/10550 (epoch 25.095), train_loss = 0.49840170, grad/param norm = 7.8054e-02, time/batch = 0.1803s	
5296/10550 (epoch 25.100), train_loss = 0.49244168, grad/param norm = 7.9311e-02, time/batch = 0.1799s	
5297/10550 (epoch 25.104), train_loss = 0.48303617, grad/param norm = 7.7013e-02, time/batch = 0.1797s	
5298/10550 (epoch 25.109), train_loss = 0.47819361, grad/param norm = 7.7006e-02, time/batch = 0.1798s	
5299/10550 (epoch 25.114), train_loss = 0.48204236, grad/param norm = 7.5744e-02, time/batch = 0.1799s	
5300/10550 (epoch 25.118), train_loss = 0.46114459, grad/param norm = 7.6946e-02, time/batch = 0.1796s	
5301/10550 (epoch 25.123), train_loss = 0.48732922, grad/param norm = 8.0133e-02, time/batch = 0.1807s	
5302/10550 (epoch 25.128), train_loss = 0.47009636, grad/param norm = 7.7631e-02, time/batch = 0.1791s	
5303/10550 (epoch 25.133), train_loss = 0.45193803, grad/param norm = 7.4568e-02, time/batch = 0.1798s	
5304/10550 (epoch 25.137), train_loss = 0.47491982, grad/param norm = 8.0398e-02, time/batch = 0.1798s	
5305/10550 (epoch 25.142), train_loss = 0.50198413, grad/param norm = 8.2131e-02, time/batch = 0.1794s	
5306/10550 (epoch 25.147), train_loss = 0.47826894, grad/param norm = 7.7799e-02, time/batch = 0.1801s	
5307/10550 (epoch 25.152), train_loss = 0.47746264, grad/param norm = 7.7143e-02, time/batch = 0.1799s	
5308/10550 (epoch 25.156), train_loss = 0.47389361, grad/param norm = 7.5272e-02, time/batch = 0.1793s	
5309/10550 (epoch 25.161), train_loss = 0.48089878, grad/param norm = 7.9289e-02, time/batch = 0.1803s	
5310/10550 (epoch 25.166), train_loss = 0.49871706, grad/param norm = 7.8177e-02, time/batch = 0.1799s	
5311/10550 (epoch 25.171), train_loss = 0.46524910, grad/param norm = 7.5322e-02, time/batch = 0.1815s	
5312/10550 (epoch 25.175), train_loss = 0.48342077, grad/param norm = 7.9031e-02, time/batch = 0.1795s	
5313/10550 (epoch 25.180), train_loss = 0.46419641, grad/param norm = 7.9114e-02, time/batch = 0.1790s	
5314/10550 (epoch 25.185), train_loss = 0.49141667, grad/param norm = 8.2285e-02, time/batch = 0.1798s	
5315/10550 (epoch 25.190), train_loss = 0.45940541, grad/param norm = 7.9798e-02, time/batch = 0.1800s	
5316/10550 (epoch 25.194), train_loss = 0.47218996, grad/param norm = 7.9876e-02, time/batch = 0.1798s	
5317/10550 (epoch 25.199), train_loss = 0.49445268, grad/param norm = 7.9760e-02, time/batch = 0.1799s	
5318/10550 (epoch 25.204), train_loss = 0.48026077, grad/param norm = 8.0355e-02, time/batch = 0.1799s	
5319/10550 (epoch 25.209), train_loss = 0.49901345, grad/param norm = 7.9403e-02, time/batch = 0.1796s	
5320/10550 (epoch 25.213), train_loss = 0.50364035, grad/param norm = 8.4901e-02, time/batch = 0.1800s	
5321/10550 (epoch 25.218), train_loss = 0.47643924, grad/param norm = 7.9857e-02, time/batch = 0.1807s	
5322/10550 (epoch 25.223), train_loss = 0.47921039, grad/param norm = 7.7522e-02, time/batch = 0.1790s	
5323/10550 (epoch 25.227), train_loss = 0.47206189, grad/param norm = 7.4869e-02, time/batch = 0.1802s	
5324/10550 (epoch 25.232), train_loss = 0.46944350, grad/param norm = 7.8803e-02, time/batch = 0.1797s	
5325/10550 (epoch 25.237), train_loss = 0.47530840, grad/param norm = 7.5458e-02, time/batch = 0.1796s	
5326/10550 (epoch 25.242), train_loss = 0.47329437, grad/param norm = 8.2708e-02, time/batch = 0.1799s	
5327/10550 (epoch 25.246), train_loss = 0.45954187, grad/param norm = 7.5918e-02, time/batch = 0.1801s	
5328/10550 (epoch 25.251), train_loss = 0.49456390, grad/param norm = 7.7105e-02, time/batch = 0.1801s	
5329/10550 (epoch 25.256), train_loss = 0.47608994, grad/param norm = 7.6088e-02, time/batch = 0.1801s	
5330/10550 (epoch 25.261), train_loss = 0.46356419, grad/param norm = 7.5432e-02, time/batch = 0.1798s	
5331/10550 (epoch 25.265), train_loss = 0.45375413, grad/param norm = 7.5510e-02, time/batch = 0.1811s	
5332/10550 (epoch 25.270), train_loss = 0.46603838, grad/param norm = 7.7833e-02, time/batch = 0.1788s	
5333/10550 (epoch 25.275), train_loss = 0.48209947, grad/param norm = 7.3576e-02, time/batch = 0.1802s	
5334/10550 (epoch 25.280), train_loss = 0.46781375, grad/param norm = 7.8607e-02, time/batch = 0.1792s	
5335/10550 (epoch 25.284), train_loss = 0.46421922, grad/param norm = 7.8198e-02, time/batch = 0.1803s	
5336/10550 (epoch 25.289), train_loss = 0.47721501, grad/param norm = 8.2952e-02, time/batch = 0.1801s	
5337/10550 (epoch 25.294), train_loss = 0.46355531, grad/param norm = 7.8780e-02, time/batch = 0.1807s	
5338/10550 (epoch 25.299), train_loss = 0.45522124, grad/param norm = 7.5398e-02, time/batch = 0.1794s	
5339/10550 (epoch 25.303), train_loss = 0.48679559, grad/param norm = 7.7304e-02, time/batch = 0.1800s	
5340/10550 (epoch 25.308), train_loss = 0.45829317, grad/param norm = 7.5959e-02, time/batch = 0.1796s	
5341/10550 (epoch 25.313), train_loss = 0.46386794, grad/param norm = 7.7926e-02, time/batch = 0.1807s	
5342/10550 (epoch 25.318), train_loss = 0.46204765, grad/param norm = 7.6132e-02, time/batch = 0.1795s	
5343/10550 (epoch 25.322), train_loss = 0.46954389, grad/param norm = 8.0100e-02, time/batch = 0.1801s	
5344/10550 (epoch 25.327), train_loss = 0.47485622, grad/param norm = 7.8066e-02, time/batch = 0.1805s	
5345/10550 (epoch 25.332), train_loss = 0.49163296, grad/param norm = 8.1300e-02, time/batch = 0.1797s	
5346/10550 (epoch 25.336), train_loss = 0.47365475, grad/param norm = 7.8100e-02, time/batch = 0.1796s	
5347/10550 (epoch 25.341), train_loss = 0.45529090, grad/param norm = 7.7395e-02, time/batch = 0.1797s	
5348/10550 (epoch 25.346), train_loss = 0.47728598, grad/param norm = 8.2132e-02, time/batch = 0.1797s	
5349/10550 (epoch 25.351), train_loss = 0.47487574, grad/param norm = 8.2330e-02, time/batch = 0.1803s	
5350/10550 (epoch 25.355), train_loss = 0.46620578, grad/param norm = 7.8059e-02, time/batch = 0.1798s	
5351/10550 (epoch 25.360), train_loss = 0.48850402, grad/param norm = 7.9700e-02, time/batch = 0.1810s	
5352/10550 (epoch 25.365), train_loss = 0.47779323, grad/param norm = 7.9115e-02, time/batch = 0.1793s	
5353/10550 (epoch 25.370), train_loss = 0.46890197, grad/param norm = 7.7185e-02, time/batch = 0.1798s	
5354/10550 (epoch 25.374), train_loss = 0.46106363, grad/param norm = 7.6651e-02, time/batch = 0.1800s	
5355/10550 (epoch 25.379), train_loss = 0.47700572, grad/param norm = 8.0987e-02, time/batch = 0.1802s	
5356/10550 (epoch 25.384), train_loss = 0.47714354, grad/param norm = 7.7761e-02, time/batch = 0.1794s	
5357/10550 (epoch 25.389), train_loss = 0.47922722, grad/param norm = 8.0842e-02, time/batch = 0.1801s	
5358/10550 (epoch 25.393), train_loss = 0.47342982, grad/param norm = 7.8310e-02, time/batch = 0.1794s	
5359/10550 (epoch 25.398), train_loss = 0.46512671, grad/param norm = 7.9841e-02, time/batch = 0.1799s	
5360/10550 (epoch 25.403), train_loss = 0.46718699, grad/param norm = 8.1457e-02, time/batch = 0.1801s	
5361/10550 (epoch 25.408), train_loss = 0.47108958, grad/param norm = 8.0620e-02, time/batch = 0.1812s	
5362/10550 (epoch 25.412), train_loss = 0.46986455, grad/param norm = 7.8848e-02, time/batch = 0.1795s	
5363/10550 (epoch 25.417), train_loss = 0.47608358, grad/param norm = 7.7872e-02, time/batch = 0.1792s	
