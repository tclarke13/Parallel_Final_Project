using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 105, val: 6, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 3320385	
cloning rnn	
cloning criterion	
1/5250 (epoch 0.010), train_loss = 4.13903290, grad/param norm = 8.6213e-01, time/batch = 0.6357s	
2/5250 (epoch 0.019), train_loss = 4.36212113, grad/param norm = 1.3426e+00, time/batch = 0.2594s	
3/5250 (epoch 0.029), train_loss = 4.10593066, grad/param norm = 1.2030e+00, time/batch = 0.2588s	
4/5250 (epoch 0.038), train_loss = 3.71216202, grad/param norm = 1.1263e+00, time/batch = 0.2591s	
5/5250 (epoch 0.048), train_loss = 3.82849610, grad/param norm = 8.7699e-01, time/batch = 0.2588s	
6/5250 (epoch 0.057), train_loss = 3.84239271, grad/param norm = 6.1486e+00, time/batch = 0.2591s	
7/5250 (epoch 0.067), train_loss = 3.57266363, grad/param norm = 8.7874e-01, time/batch = 0.2591s	
8/5250 (epoch 0.076), train_loss = 3.40504638, grad/param norm = 7.1263e-01, time/batch = 0.2591s	
9/5250 (epoch 0.086), train_loss = 3.43439732, grad/param norm = 6.2008e-01, time/batch = 0.2590s	
10/5250 (epoch 0.095), train_loss = 3.34758724, grad/param norm = 4.2757e-01, time/batch = 0.2590s	
11/5250 (epoch 0.105), train_loss = 3.32894665, grad/param norm = 3.9859e-01, time/batch = 0.2590s	
12/5250 (epoch 0.114), train_loss = 3.35896380, grad/param norm = 3.4628e-01, time/batch = 0.2580s	
13/5250 (epoch 0.124), train_loss = 3.33064321, grad/param norm = 2.8004e-01, time/batch = 0.2582s	
14/5250 (epoch 0.133), train_loss = 3.34760040, grad/param norm = 1.9026e-01, time/batch = 0.2581s	
15/5250 (epoch 0.143), train_loss = 3.33817011, grad/param norm = 1.7513e-01, time/batch = 0.2581s	
16/5250 (epoch 0.152), train_loss = 3.34178368, grad/param norm = 1.6421e-01, time/batch = 0.2581s	
17/5250 (epoch 0.162), train_loss = 3.31985889, grad/param norm = 1.6582e-01, time/batch = 0.2584s	
18/5250 (epoch 0.171), train_loss = 3.31449883, grad/param norm = 1.3953e-01, time/batch = 0.2587s	
19/5250 (epoch 0.181), train_loss = 3.34536726, grad/param norm = 1.1879e-01, time/batch = 0.2583s	
20/5250 (epoch 0.190), train_loss = 3.32132627, grad/param norm = 1.1499e-01, time/batch = 0.2590s	
21/5250 (epoch 0.200), train_loss = 3.31763278, grad/param norm = 1.1170e-01, time/batch = 0.2592s	
22/5250 (epoch 0.210), train_loss = 3.30259984, grad/param norm = 1.3422e-01, time/batch = 0.2578s	
23/5250 (epoch 0.219), train_loss = 3.29121032, grad/param norm = 1.5208e-01, time/batch = 0.2582s	
24/5250 (epoch 0.229), train_loss = 3.32933851, grad/param norm = 1.5833e-01, time/batch = 0.2582s	
25/5250 (epoch 0.238), train_loss = 3.32407269, grad/param norm = 1.6278e-01, time/batch = 0.2584s	
26/5250 (epoch 0.248), train_loss = 3.29718957, grad/param norm = 1.8950e-01, time/batch = 0.2581s	
27/5250 (epoch 0.257), train_loss = 3.33312341, grad/param norm = 2.3147e-01, time/batch = 0.2585s	
28/5250 (epoch 0.267), train_loss = 3.34549089, grad/param norm = 2.5082e-01, time/batch = 0.2584s	
29/5250 (epoch 0.276), train_loss = 3.33297989, grad/param norm = 2.5738e-01, time/batch = 0.2588s	
30/5250 (epoch 0.286), train_loss = 3.33001921, grad/param norm = 2.5414e-01, time/batch = 0.2585s	
31/5250 (epoch 0.295), train_loss = 3.31086610, grad/param norm = 2.3315e-01, time/batch = 0.2589s	
32/5250 (epoch 0.305), train_loss = 3.34210444, grad/param norm = 2.4570e-01, time/batch = 0.2584s	
33/5250 (epoch 0.314), train_loss = 3.35632318, grad/param norm = 2.3932e-01, time/batch = 0.2583s	
34/5250 (epoch 0.324), train_loss = 3.32362362, grad/param norm = 2.8751e-01, time/batch = 0.2584s	
35/5250 (epoch 0.333), train_loss = 3.32641323, grad/param norm = 3.5695e-01, time/batch = 0.2581s	
36/5250 (epoch 0.343), train_loss = 3.33626866, grad/param norm = 3.5514e-01, time/batch = 0.2583s	
37/5250 (epoch 0.352), train_loss = 3.30514419, grad/param norm = 2.6918e-01, time/batch = 0.2582s	
38/5250 (epoch 0.362), train_loss = 3.32056877, grad/param norm = 2.2581e-01, time/batch = 0.2584s	
39/5250 (epoch 0.371), train_loss = 3.29935954, grad/param norm = 1.8304e-01, time/batch = 0.2582s	
40/5250 (epoch 0.381), train_loss = 3.29485262, grad/param norm = 2.1070e-01, time/batch = 0.2584s	
41/5250 (epoch 0.390), train_loss = 3.32572542, grad/param norm = 2.2731e-01, time/batch = 0.2594s	
42/5250 (epoch 0.400), train_loss = 3.31394836, grad/param norm = 2.5160e-01, time/batch = 0.2581s	
43/5250 (epoch 0.410), train_loss = 3.29994820, grad/param norm = 3.0323e-01, time/batch = 0.2586s	
44/5250 (epoch 0.419), train_loss = 3.30187673, grad/param norm = 3.7430e-01, time/batch = 0.2580s	
45/5250 (epoch 0.429), train_loss = 3.31733195, grad/param norm = 3.5337e-01, time/batch = 0.2581s	
46/5250 (epoch 0.438), train_loss = 3.30413797, grad/param norm = 3.3113e-01, time/batch = 0.2582s	
47/5250 (epoch 0.448), train_loss = 3.32984839, grad/param norm = 2.7927e-01, time/batch = 0.2581s	
48/5250 (epoch 0.457), train_loss = 3.29998364, grad/param norm = 2.1173e-01, time/batch = 0.2583s	
49/5250 (epoch 0.467), train_loss = 3.27423007, grad/param norm = 1.7634e-01, time/batch = 0.2587s	
50/5250 (epoch 0.476), train_loss = 3.44854940, grad/param norm = 1.1764e+00, time/batch = 0.2587s	
51/5250 (epoch 0.486), train_loss = 3.36334134, grad/param norm = 2.5182e-01, time/batch = 0.2594s	
52/5250 (epoch 0.495), train_loss = 3.29252829, grad/param norm = 2.4563e-01, time/batch = 0.2582s	
53/5250 (epoch 0.505), train_loss = 3.29778330, grad/param norm = 2.4822e-01, time/batch = 0.2584s	
54/5250 (epoch 0.514), train_loss = 3.29987195, grad/param norm = 2.8946e-01, time/batch = 0.2581s	
55/5250 (epoch 0.524), train_loss = 3.31149459, grad/param norm = 3.3511e-01, time/batch = 0.2580s	
56/5250 (epoch 0.533), train_loss = 3.31113769, grad/param norm = 3.0787e-01, time/batch = 0.2579s	
57/5250 (epoch 0.543), train_loss = 3.29657039, grad/param norm = 2.6153e-01, time/batch = 0.2581s	
58/5250 (epoch 0.552), train_loss = 3.29837614, grad/param norm = 2.0894e-01, time/batch = 0.2585s	
59/5250 (epoch 0.562), train_loss = 3.28682718, grad/param norm = 2.1223e-01, time/batch = 0.2586s	
60/5250 (epoch 0.571), train_loss = 3.27859137, grad/param norm = 2.4786e-01, time/batch = 0.2587s	
61/5250 (epoch 0.581), train_loss = 3.29326257, grad/param norm = 2.7484e-01, time/batch = 0.2594s	
62/5250 (epoch 0.590), train_loss = 3.30604054, grad/param norm = 2.4068e-01, time/batch = 0.2584s	
63/5250 (epoch 0.600), train_loss = 3.29725688, grad/param norm = 1.8526e-01, time/batch = 0.2582s	
64/5250 (epoch 0.610), train_loss = 3.26353218, grad/param norm = 1.7682e-01, time/batch = 0.2581s	
65/5250 (epoch 0.619), train_loss = 3.25540002, grad/param norm = 1.9274e-01, time/batch = 0.2580s	
66/5250 (epoch 0.629), train_loss = 3.24243255, grad/param norm = 2.4524e-01, time/batch = 0.2579s	
67/5250 (epoch 0.638), train_loss = 3.24418367, grad/param norm = 2.8128e-01, time/batch = 0.2579s	
68/5250 (epoch 0.648), train_loss = 3.20956929, grad/param norm = 3.0350e-01, time/batch = 0.2583s	
69/5250 (epoch 0.657), train_loss = 3.20554870, grad/param norm = 3.2111e-01, time/batch = 0.2613s	
70/5250 (epoch 0.667), train_loss = 3.22328118, grad/param norm = 3.4846e-01, time/batch = 0.2584s	
71/5250 (epoch 0.676), train_loss = 3.19924245, grad/param norm = 3.1834e-01, time/batch = 0.2594s	
72/5250 (epoch 0.686), train_loss = 3.20587437, grad/param norm = 3.1532e-01, time/batch = 0.2584s	
73/5250 (epoch 0.695), train_loss = 3.24102106, grad/param norm = 3.7898e-01, time/batch = 0.2582s	
74/5250 (epoch 0.705), train_loss = 3.30907551, grad/param norm = 6.6071e-01, time/batch = 0.2578s	
75/5250 (epoch 0.714), train_loss = 3.40839348, grad/param norm = 3.3682e-01, time/batch = 0.2582s	
76/5250 (epoch 0.724), train_loss = 3.32105769, grad/param norm = 2.3313e-01, time/batch = 0.2583s	
77/5250 (epoch 0.733), train_loss = 3.29701830, grad/param norm = 1.5148e-01, time/batch = 0.2581s	
78/5250 (epoch 0.743), train_loss = 3.22399720, grad/param norm = 1.0015e-01, time/batch = 0.2583s	
79/5250 (epoch 0.752), train_loss = 3.20635032, grad/param norm = 1.6719e-01, time/batch = 0.2585s	
80/5250 (epoch 0.762), train_loss = 3.29324823, grad/param norm = 1.4252e-01, time/batch = 0.2581s	
81/5250 (epoch 0.771), train_loss = 3.21093582, grad/param norm = 1.1403e-01, time/batch = 0.2598s	
82/5250 (epoch 0.781), train_loss = 3.18659086, grad/param norm = 8.9041e-02, time/batch = 0.2582s	
83/5250 (epoch 0.790), train_loss = 3.18767208, grad/param norm = 1.8651e-01, time/batch = 0.2585s	
84/5250 (epoch 0.800), train_loss = 3.23441190, grad/param norm = 1.4900e-01, time/batch = 0.2579s	
85/5250 (epoch 0.810), train_loss = 3.18334981, grad/param norm = 1.8344e-01, time/batch = 0.2581s	
86/5250 (epoch 0.819), train_loss = 3.19222310, grad/param norm = 2.1606e-01, time/batch = 0.2577s	
87/5250 (epoch 0.829), train_loss = 3.18620833, grad/param norm = 2.3483e-01, time/batch = 0.2589s	
88/5250 (epoch 0.838), train_loss = 3.19512274, grad/param norm = 2.1317e-01, time/batch = 0.2575s	
89/5250 (epoch 0.848), train_loss = 3.16663251, grad/param norm = 1.7459e-01, time/batch = 0.2579s	
90/5250 (epoch 0.857), train_loss = 3.16005536, grad/param norm = 1.5001e-01, time/batch = 0.2578s	
91/5250 (epoch 0.867), train_loss = 3.14864699, grad/param norm = 1.5173e-01, time/batch = 0.2587s	
92/5250 (epoch 0.876), train_loss = 3.14132065, grad/param norm = 1.5729e-01, time/batch = 0.2587s	
93/5250 (epoch 0.886), train_loss = 3.14194267, grad/param norm = 1.9379e-01, time/batch = 0.2577s	
94/5250 (epoch 0.895), train_loss = 3.14135894, grad/param norm = 2.5550e-01, time/batch = 0.2576s	
95/5250 (epoch 0.905), train_loss = 3.15426819, grad/param norm = 2.7312e-01, time/batch = 0.2577s	
96/5250 (epoch 0.914), train_loss = 3.13203669, grad/param norm = 2.6613e-01, time/batch = 0.2577s	
97/5250 (epoch 0.924), train_loss = 3.15263866, grad/param norm = 3.7805e-01, time/batch = 0.2576s	
98/5250 (epoch 0.933), train_loss = 3.21564857, grad/param norm = 5.5767e-01, time/batch = 0.2577s	
99/5250 (epoch 0.943), train_loss = 3.24485496, grad/param norm = 5.0124e-01, time/batch = 0.2579s	
100/5250 (epoch 0.952), train_loss = 3.17227428, grad/param norm = 3.6231e-01, time/batch = 0.2581s	
101/5250 (epoch 0.962), train_loss = 3.22010821, grad/param norm = 2.1978e-01, time/batch = 0.2589s	
102/5250 (epoch 0.971), train_loss = 3.13675306, grad/param norm = 1.8720e-01, time/batch = 0.2575s	
103/5250 (epoch 0.981), train_loss = 3.14950434, grad/param norm = 2.6085e-01, time/batch = 0.2574s	
104/5250 (epoch 0.990), train_loss = 3.11303512, grad/param norm = 2.4707e-01, time/batch = 0.2576s	
105/5250 (epoch 1.000), train_loss = 3.08893965, grad/param norm = 2.2740e-01, time/batch = 0.2575s	
106/5250 (epoch 1.010), train_loss = 3.11160975, grad/param norm = 2.5205e-01, time/batch = 0.2577s	
107/5250 (epoch 1.019), train_loss = 3.12233769, grad/param norm = 2.4133e-01, time/batch = 0.2577s	
108/5250 (epoch 1.029), train_loss = 3.07183700, grad/param norm = 2.6506e-01, time/batch = 0.2574s	
109/5250 (epoch 1.038), train_loss = 3.09062316, grad/param norm = 2.7283e-01, time/batch = 0.2579s	
110/5250 (epoch 1.048), train_loss = 3.07627234, grad/param norm = 2.6738e-01, time/batch = 0.2584s	
111/5250 (epoch 1.057), train_loss = 3.08684346, grad/param norm = 2.5648e-01, time/batch = 0.2587s	
112/5250 (epoch 1.067), train_loss = 3.06587952, grad/param norm = 2.6593e-01, time/batch = 0.2576s	
113/5250 (epoch 1.076), train_loss = 3.03791757, grad/param norm = 2.8930e-01, time/batch = 0.2577s	
114/5250 (epoch 1.086), train_loss = 3.05933567, grad/param norm = 3.9369e-01, time/batch = 0.2574s	
115/5250 (epoch 1.095), train_loss = 3.07776544, grad/param norm = 3.4064e-01, time/batch = 0.2577s	
116/5250 (epoch 1.105), train_loss = 3.09927267, grad/param norm = 3.7327e-01, time/batch = 0.2579s	
117/5250 (epoch 1.114), train_loss = 3.14571018, grad/param norm = 4.3253e-01, time/batch = 0.2575s	
118/5250 (epoch 1.124), train_loss = 3.16838324, grad/param norm = 3.4171e-01, time/batch = 0.2580s	
119/5250 (epoch 1.133), train_loss = 3.07491489, grad/param norm = 3.8148e-01, time/batch = 0.2580s	
120/5250 (epoch 1.143), train_loss = 3.07167389, grad/param norm = 2.4738e-01, time/batch = 0.2583s	
121/5250 (epoch 1.152), train_loss = 3.06633652, grad/param norm = 5.3157e-01, time/batch = 0.2586s	
122/5250 (epoch 1.162), train_loss = 3.11354925, grad/param norm = 2.8377e-01, time/batch = 0.2574s	
123/5250 (epoch 1.171), train_loss = 2.99593435, grad/param norm = 3.0540e-01, time/batch = 0.2578s	
124/5250 (epoch 1.181), train_loss = 2.98746718, grad/param norm = 3.2616e-01, time/batch = 0.2574s	
125/5250 (epoch 1.190), train_loss = 2.95670588, grad/param norm = 2.8636e-01, time/batch = 0.2573s	
126/5250 (epoch 1.200), train_loss = 2.92217332, grad/param norm = 2.5251e-01, time/batch = 0.2573s	
127/5250 (epoch 1.210), train_loss = 2.91909681, grad/param norm = 2.8651e-01, time/batch = 0.2576s	
128/5250 (epoch 1.219), train_loss = 2.92723261, grad/param norm = 3.7450e-01, time/batch = 0.2576s	
129/5250 (epoch 1.229), train_loss = 2.94961668, grad/param norm = 4.2612e-01, time/batch = 0.2582s	
130/5250 (epoch 1.238), train_loss = 2.89490813, grad/param norm = 3.3344e-01, time/batch = 0.2579s	
131/5250 (epoch 1.248), train_loss = 2.84292372, grad/param norm = 2.9444e-01, time/batch = 0.2584s	
132/5250 (epoch 1.257), train_loss = 2.83789050, grad/param norm = 3.3685e-01, time/batch = 0.2579s	
133/5250 (epoch 1.267), train_loss = 2.88264934, grad/param norm = 4.4805e-01, time/batch = 0.2603s	
134/5250 (epoch 1.276), train_loss = 2.87929789, grad/param norm = 3.2124e-01, time/batch = 0.2574s	
135/5250 (epoch 1.286), train_loss = 2.79928596, grad/param norm = 1.9416e-01, time/batch = 0.2576s	
136/5250 (epoch 1.295), train_loss = 2.78621994, grad/param norm = 1.9276e-01, time/batch = 0.2577s	
137/5250 (epoch 1.305), train_loss = 2.79517574, grad/param norm = 1.8362e-01, time/batch = 0.2571s	
138/5250 (epoch 1.314), train_loss = 2.75979515, grad/param norm = 1.7708e-01, time/batch = 0.2577s	
139/5250 (epoch 1.324), train_loss = 2.73768719, grad/param norm = 1.8078e-01, time/batch = 0.2580s	
140/5250 (epoch 1.333), train_loss = 2.73276682, grad/param norm = 2.5646e-01, time/batch = 0.2580s	
141/5250 (epoch 1.343), train_loss = 2.81478827, grad/param norm = 5.1418e-01, time/batch = 0.2586s	
142/5250 (epoch 1.352), train_loss = 2.96152798, grad/param norm = 8.2022e-01, time/batch = 0.2577s	
143/5250 (epoch 1.362), train_loss = 3.00700747, grad/param norm = 6.3958e-01, time/batch = 0.2578s	
144/5250 (epoch 1.371), train_loss = 2.81807173, grad/param norm = 2.4952e-01, time/batch = 0.2574s	
145/5250 (epoch 1.381), train_loss = 2.74298081, grad/param norm = 2.1319e-01, time/batch = 0.2575s	
146/5250 (epoch 1.390), train_loss = 2.73203902, grad/param norm = 1.6677e-01, time/batch = 0.2577s	
147/5250 (epoch 1.400), train_loss = 2.68361713, grad/param norm = 1.3816e-01, time/batch = 0.2574s	
148/5250 (epoch 1.410), train_loss = 2.66105224, grad/param norm = 1.3345e-01, time/batch = 0.2574s	
149/5250 (epoch 1.419), train_loss = 2.64305953, grad/param norm = 1.3802e-01, time/batch = 0.2573s	
150/5250 (epoch 1.429), train_loss = 2.64651890, grad/param norm = 2.1662e-01, time/batch = 0.2578s	
151/5250 (epoch 1.438), train_loss = 2.72334753, grad/param norm = 3.6115e-01, time/batch = 0.2585s	
152/5250 (epoch 1.448), train_loss = 2.69314017, grad/param norm = 2.8883e-01, time/batch = 0.2578s	
153/5250 (epoch 1.457), train_loss = 2.63439169, grad/param norm = 2.2066e-01, time/batch = 0.2582s	
154/5250 (epoch 1.467), train_loss = 2.65176147, grad/param norm = 2.8096e-01, time/batch = 0.2580s	
155/5250 (epoch 1.476), train_loss = 2.66082520, grad/param norm = 3.0134e-01, time/batch = 0.2578s	
156/5250 (epoch 1.486), train_loss = 2.68712217, grad/param norm = 4.0555e-01, time/batch = 0.2579s	
157/5250 (epoch 1.495), train_loss = 2.66335416, grad/param norm = 3.7869e-01, time/batch = 0.2574s	
158/5250 (epoch 1.505), train_loss = 2.61863848, grad/param norm = 2.9735e-01, time/batch = 0.2574s	
159/5250 (epoch 1.514), train_loss = 2.59608189, grad/param norm = 2.4233e-01, time/batch = 0.2577s	
160/5250 (epoch 1.524), train_loss = 2.54726424, grad/param norm = 1.2464e-01, time/batch = 0.2579s	
161/5250 (epoch 1.533), train_loss = 2.52737682, grad/param norm = 1.0127e-01, time/batch = 0.2587s	
162/5250 (epoch 1.543), train_loss = 2.51960037, grad/param norm = 1.4198e-01, time/batch = 0.2576s	
163/5250 (epoch 1.552), train_loss = 2.53587805, grad/param norm = 2.3885e-01, time/batch = 0.2580s	
164/5250 (epoch 1.562), train_loss = 2.60781903, grad/param norm = 3.1526e-01, time/batch = 0.2579s	
165/5250 (epoch 1.571), train_loss = 2.68277232, grad/param norm = 4.7148e-01, time/batch = 0.2601s	
166/5250 (epoch 1.581), train_loss = 2.60941617, grad/param norm = 2.6572e-01, time/batch = 0.2575s	
167/5250 (epoch 1.590), train_loss = 2.59804318, grad/param norm = 2.7694e-01, time/batch = 0.2577s	
168/5250 (epoch 1.600), train_loss = 2.58635257, grad/param norm = 2.8674e-01, time/batch = 0.2576s	
169/5250 (epoch 1.610), train_loss = 2.53229010, grad/param norm = 3.0965e-01, time/batch = 0.2576s	
170/5250 (epoch 1.619), train_loss = 2.52154652, grad/param norm = 3.0075e-01, time/batch = 0.2580s	
171/5250 (epoch 1.629), train_loss = 2.53423012, grad/param norm = 2.4383e-01, time/batch = 0.2586s	
172/5250 (epoch 1.638), train_loss = 2.50708407, grad/param norm = 1.9903e-01, time/batch = 0.2576s	
173/5250 (epoch 1.648), train_loss = 2.47306801, grad/param norm = 1.6084e-01, time/batch = 0.2579s	
174/5250 (epoch 1.657), train_loss = 2.44946360, grad/param norm = 1.6071e-01, time/batch = 0.2577s	
175/5250 (epoch 1.667), train_loss = 2.48415658, grad/param norm = 1.6038e-01, time/batch = 0.2575s	
176/5250 (epoch 1.676), train_loss = 2.46290867, grad/param norm = 1.6032e-01, time/batch = 0.2573s	
177/5250 (epoch 1.686), train_loss = 2.48461758, grad/param norm = 1.9124e-01, time/batch = 0.2573s	
178/5250 (epoch 1.695), train_loss = 2.46002972, grad/param norm = 2.6290e-01, time/batch = 0.2575s	
179/5250 (epoch 1.705), train_loss = 2.50602862, grad/param norm = 3.6597e-01, time/batch = 0.2578s	
180/5250 (epoch 1.714), train_loss = 2.50777413, grad/param norm = 3.3130e-01, time/batch = 0.2581s	
181/5250 (epoch 1.724), train_loss = 2.48448794, grad/param norm = 3.6366e-01, time/batch = 0.2586s	
182/5250 (epoch 1.733), train_loss = 2.49762147, grad/param norm = 3.5155e-01, time/batch = 0.2578s	
183/5250 (epoch 1.743), train_loss = 2.45234180, grad/param norm = 2.0257e-01, time/batch = 0.2575s	
184/5250 (epoch 1.752), train_loss = 2.44714903, grad/param norm = 1.6895e-01, time/batch = 0.2572s	
185/5250 (epoch 1.762), train_loss = 2.44079738, grad/param norm = 1.8205e-01, time/batch = 0.2576s	
186/5250 (epoch 1.771), train_loss = 2.39514023, grad/param norm = 1.8438e-01, time/batch = 0.2577s	
187/5250 (epoch 1.781), train_loss = 2.41592256, grad/param norm = 1.7219e-01, time/batch = 0.2576s	
188/5250 (epoch 1.790), train_loss = 2.40932410, grad/param norm = 1.6979e-01, time/batch = 0.2578s	
189/5250 (epoch 1.800), train_loss = 2.40126357, grad/param norm = 1.7447e-01, time/batch = 0.2584s	
190/5250 (epoch 1.810), train_loss = 2.38303245, grad/param norm = 2.0850e-01, time/batch = 0.2579s	
191/5250 (epoch 1.819), train_loss = 2.40629361, grad/param norm = 2.3979e-01, time/batch = 0.2588s	
192/5250 (epoch 1.829), train_loss = 2.41736249, grad/param norm = 2.1118e-01, time/batch = 0.2577s	
193/5250 (epoch 1.838), train_loss = 2.40534939, grad/param norm = 2.2372e-01, time/batch = 0.2578s	
194/5250 (epoch 1.848), train_loss = 2.39335801, grad/param norm = 2.0081e-01, time/batch = 0.2575s	
195/5250 (epoch 1.857), train_loss = 2.39282873, grad/param norm = 2.4777e-01, time/batch = 0.2573s	
196/5250 (epoch 1.867), train_loss = 2.43213977, grad/param norm = 3.3792e-01, time/batch = 0.2578s	
197/5250 (epoch 1.876), train_loss = 2.47592160, grad/param norm = 4.3560e-01, time/batch = 0.2593s	
198/5250 (epoch 1.886), train_loss = 2.46097720, grad/param norm = 3.2444e-01, time/batch = 0.2573s	
199/5250 (epoch 1.895), train_loss = 2.41116724, grad/param norm = 2.6191e-01, time/batch = 0.2580s	
200/5250 (epoch 1.905), train_loss = 2.38964768, grad/param norm = 2.3380e-01, time/batch = 0.2581s	
201/5250 (epoch 1.914), train_loss = 2.36241455, grad/param norm = 1.9736e-01, time/batch = 0.2585s	
202/5250 (epoch 1.924), train_loss = 2.32928285, grad/param norm = 1.2191e-01, time/batch = 0.2575s	
203/5250 (epoch 1.933), train_loss = 2.31580752, grad/param norm = 9.7638e-02, time/batch = 0.2579s	
204/5250 (epoch 1.943), train_loss = 2.30331374, grad/param norm = 9.9370e-02, time/batch = 0.2578s	
205/5250 (epoch 1.952), train_loss = 2.31623348, grad/param norm = 1.2489e-01, time/batch = 0.2579s	
206/5250 (epoch 1.962), train_loss = 2.31660646, grad/param norm = 1.9966e-01, time/batch = 0.2575s	
207/5250 (epoch 1.971), train_loss = 2.34525660, grad/param norm = 2.3575e-01, time/batch = 0.2573s	
208/5250 (epoch 1.981), train_loss = 2.35545500, grad/param norm = 2.9431e-01, time/batch = 0.2574s	
209/5250 (epoch 1.990), train_loss = 2.38335089, grad/param norm = 3.1933e-01, time/batch = 0.2578s	
210/5250 (epoch 2.000), train_loss = 2.32941160, grad/param norm = 2.9165e-01, time/batch = 0.2581s	
211/5250 (epoch 2.010), train_loss = 2.39107299, grad/param norm = 2.4745e-01, time/batch = 0.2588s	
212/5250 (epoch 2.019), train_loss = 2.34125567, grad/param norm = 2.0757e-01, time/batch = 0.2574s	
213/5250 (epoch 2.029), train_loss = 2.31221891, grad/param norm = 1.7634e-01, time/batch = 0.2576s	
214/5250 (epoch 2.038), train_loss = 2.32498414, grad/param norm = 1.4672e-01, time/batch = 0.2577s	
215/5250 (epoch 2.048), train_loss = 2.28558047, grad/param norm = 1.3209e-01, time/batch = 0.2576s	
216/5250 (epoch 2.057), train_loss = 2.29392193, grad/param norm = 1.3857e-01, time/batch = 0.2573s	
217/5250 (epoch 2.067), train_loss = 2.31468561, grad/param norm = 1.5215e-01, time/batch = 0.2575s	
218/5250 (epoch 2.076), train_loss = 2.27560249, grad/param norm = 1.8370e-01, time/batch = 0.2576s	
219/5250 (epoch 2.086), train_loss = 2.27094689, grad/param norm = 2.0682e-01, time/batch = 0.2575s	
220/5250 (epoch 2.095), train_loss = 2.28654910, grad/param norm = 2.0330e-01, time/batch = 0.2582s	
221/5250 (epoch 2.105), train_loss = 2.26705931, grad/param norm = 1.9777e-01, time/batch = 0.2597s	
222/5250 (epoch 2.114), train_loss = 2.25688778, grad/param norm = 1.7714e-01, time/batch = 0.2578s	
223/5250 (epoch 2.124), train_loss = 2.25211820, grad/param norm = 1.8152e-01, time/batch = 0.2576s	
224/5250 (epoch 2.133), train_loss = 2.24275319, grad/param norm = 1.8178e-01, time/batch = 0.2577s	
225/5250 (epoch 2.143), train_loss = 2.19775731, grad/param norm = 1.5068e-01, time/batch = 0.2578s	
226/5250 (epoch 2.152), train_loss = 2.23350314, grad/param norm = 1.5658e-01, time/batch = 0.2573s	
227/5250 (epoch 2.162), train_loss = 2.25454279, grad/param norm = 1.7252e-01, time/batch = 0.2577s	
228/5250 (epoch 2.171), train_loss = 2.27513052, grad/param norm = 1.9828e-01, time/batch = 0.2575s	
229/5250 (epoch 2.181), train_loss = 2.30885303, grad/param norm = 2.5575e-01, time/batch = 0.2600s	
230/5250 (epoch 2.190), train_loss = 2.28414479, grad/param norm = 2.2967e-01, time/batch = 0.2581s	
231/5250 (epoch 2.200), train_loss = 2.21987241, grad/param norm = 1.8811e-01, time/batch = 0.2591s	
232/5250 (epoch 2.210), train_loss = 2.23896760, grad/param norm = 1.8776e-01, time/batch = 0.2575s	
233/5250 (epoch 2.219), train_loss = 2.25935995, grad/param norm = 1.6293e-01, time/batch = 0.2575s	
234/5250 (epoch 2.229), train_loss = 2.25259359, grad/param norm = 2.2364e-01, time/batch = 0.2581s	
235/5250 (epoch 2.238), train_loss = 2.23331591, grad/param norm = 2.1589e-01, time/batch = 0.2578s	
236/5250 (epoch 2.248), train_loss = 2.19712408, grad/param norm = 1.6548e-01, time/batch = 0.2575s	
237/5250 (epoch 2.257), train_loss = 2.17147228, grad/param norm = 1.5497e-01, time/batch = 0.2576s	
238/5250 (epoch 2.267), train_loss = 2.17700221, grad/param norm = 1.6448e-01, time/batch = 0.2577s	
239/5250 (epoch 2.276), train_loss = 2.17709740, grad/param norm = 1.5678e-01, time/batch = 0.2579s	
240/5250 (epoch 2.286), train_loss = 2.15846861, grad/param norm = 1.7046e-01, time/batch = 0.2581s	
241/5250 (epoch 2.295), train_loss = 2.20814363, grad/param norm = 1.7539e-01, time/batch = 0.2588s	
242/5250 (epoch 2.305), train_loss = 2.22332639, grad/param norm = 1.6830e-01, time/batch = 0.2575s	
243/5250 (epoch 2.314), train_loss = 2.16153854, grad/param norm = 1.4335e-01, time/batch = 0.2578s	
244/5250 (epoch 2.324), train_loss = 2.16101778, grad/param norm = 1.4447e-01, time/batch = 0.2574s	
245/5250 (epoch 2.333), train_loss = 2.17774668, grad/param norm = 1.6703e-01, time/batch = 0.2575s	
246/5250 (epoch 2.343), train_loss = 2.17841355, grad/param norm = 2.2359e-01, time/batch = 0.2574s	
247/5250 (epoch 2.352), train_loss = 2.18798813, grad/param norm = 2.5020e-01, time/batch = 0.2575s	
248/5250 (epoch 2.362), train_loss = 2.19812746, grad/param norm = 2.6396e-01, time/batch = 0.2577s	
249/5250 (epoch 2.371), train_loss = 2.19639102, grad/param norm = 2.2070e-01, time/batch = 0.2581s	
250/5250 (epoch 2.381), train_loss = 2.14246216, grad/param norm = 1.8109e-01, time/batch = 0.2582s	
251/5250 (epoch 2.390), train_loss = 2.17287613, grad/param norm = 1.4183e-01, time/batch = 0.2589s	
252/5250 (epoch 2.400), train_loss = 2.11418443, grad/param norm = 1.5176e-01, time/batch = 0.2574s	
253/5250 (epoch 2.410), train_loss = 2.15734109, grad/param norm = 1.8402e-01, time/batch = 0.2580s	
254/5250 (epoch 2.419), train_loss = 2.16348966, grad/param norm = 1.7713e-01, time/batch = 0.2579s	
255/5250 (epoch 2.429), train_loss = 2.13142172, grad/param norm = 1.3132e-01, time/batch = 0.2578s	
256/5250 (epoch 2.438), train_loss = 2.14301387, grad/param norm = 1.1288e-01, time/batch = 0.2573s	
257/5250 (epoch 2.448), train_loss = 2.09501131, grad/param norm = 1.2617e-01, time/batch = 0.2575s	
258/5250 (epoch 2.457), train_loss = 2.11040954, grad/param norm = 1.7624e-01, time/batch = 0.2580s	
259/5250 (epoch 2.467), train_loss = 2.08963358, grad/param norm = 1.7085e-01, time/batch = 0.2577s	
260/5250 (epoch 2.476), train_loss = 2.08542010, grad/param norm = 1.6209e-01, time/batch = 0.2606s	
261/5250 (epoch 2.486), train_loss = 2.11412792, grad/param norm = 1.6110e-01, time/batch = 0.2596s	
262/5250 (epoch 2.495), train_loss = 2.06989329, grad/param norm = 1.3605e-01, time/batch = 0.2571s	
263/5250 (epoch 2.505), train_loss = 2.08437358, grad/param norm = 1.4889e-01, time/batch = 0.2581s	
264/5250 (epoch 2.514), train_loss = 2.09687748, grad/param norm = 1.7482e-01, time/batch = 0.2573s	
265/5250 (epoch 2.524), train_loss = 2.09491917, grad/param norm = 1.8693e-01, time/batch = 0.2574s	
266/5250 (epoch 2.533), train_loss = 2.10923217, grad/param norm = 1.6096e-01, time/batch = 0.2577s	
267/5250 (epoch 2.543), train_loss = 2.06490796, grad/param norm = 1.2794e-01, time/batch = 0.2575s	
268/5250 (epoch 2.552), train_loss = 2.05433815, grad/param norm = 1.1780e-01, time/batch = 0.2578s	
269/5250 (epoch 2.562), train_loss = 2.07519806, grad/param norm = 1.4650e-01, time/batch = 0.2577s	
270/5250 (epoch 2.571), train_loss = 2.08032943, grad/param norm = 1.8888e-01, time/batch = 0.2582s	
271/5250 (epoch 2.581), train_loss = 2.13908032, grad/param norm = 2.5856e-01, time/batch = 0.2589s	
272/5250 (epoch 2.590), train_loss = 2.12017337, grad/param norm = 1.7321e-01, time/batch = 0.2577s	
273/5250 (epoch 2.600), train_loss = 2.10967606, grad/param norm = 1.5102e-01, time/batch = 0.2580s	
274/5250 (epoch 2.610), train_loss = 2.08203141, grad/param norm = 1.7079e-01, time/batch = 0.2576s	
275/5250 (epoch 2.619), train_loss = 2.06879157, grad/param norm = 1.7556e-01, time/batch = 0.2575s	
276/5250 (epoch 2.629), train_loss = 2.13183074, grad/param norm = 1.9110e-01, time/batch = 0.2577s	
277/5250 (epoch 2.638), train_loss = 2.07661177, grad/param norm = 1.5757e-01, time/batch = 0.2575s	
278/5250 (epoch 2.648), train_loss = 2.03922358, grad/param norm = 1.0495e-01, time/batch = 0.2578s	
279/5250 (epoch 2.657), train_loss = 1.99796262, grad/param norm = 8.5232e-02, time/batch = 0.2579s	
280/5250 (epoch 2.667), train_loss = 2.02546383, grad/param norm = 9.0250e-02, time/batch = 0.2581s	
281/5250 (epoch 2.676), train_loss = 2.02997681, grad/param norm = 1.2838e-01, time/batch = 0.2587s	
282/5250 (epoch 2.686), train_loss = 2.07834758, grad/param norm = 1.6771e-01, time/batch = 0.2576s	
283/5250 (epoch 2.695), train_loss = 2.03220567, grad/param norm = 1.5934e-01, time/batch = 0.2577s	
284/5250 (epoch 2.705), train_loss = 2.00824487, grad/param norm = 1.4149e-01, time/batch = 0.2573s	
285/5250 (epoch 2.714), train_loss = 2.03848670, grad/param norm = 1.5019e-01, time/batch = 0.2580s	
286/5250 (epoch 2.724), train_loss = 2.01114430, grad/param norm = 1.5391e-01, time/batch = 0.2573s	
287/5250 (epoch 2.733), train_loss = 2.00933688, grad/param norm = 1.2234e-01, time/batch = 0.2575s	
288/5250 (epoch 2.743), train_loss = 1.98893605, grad/param norm = 9.8853e-02, time/batch = 0.2579s	
289/5250 (epoch 2.752), train_loss = 1.99270785, grad/param norm = 1.1121e-01, time/batch = 0.2577s	
290/5250 (epoch 2.762), train_loss = 1.99082834, grad/param norm = 1.4019e-01, time/batch = 0.2580s	
291/5250 (epoch 2.771), train_loss = 2.00653238, grad/param norm = 1.5423e-01, time/batch = 0.2595s	
292/5250 (epoch 2.781), train_loss = 2.01523250, grad/param norm = 1.5790e-01, time/batch = 0.2599s	
293/5250 (epoch 2.790), train_loss = 2.04263541, grad/param norm = 1.6775e-01, time/batch = 0.2578s	
294/5250 (epoch 2.800), train_loss = 2.02806203, grad/param norm = 1.6804e-01, time/batch = 0.2573s	
295/5250 (epoch 2.810), train_loss = 2.00464199, grad/param norm = 1.5504e-01, time/batch = 0.2577s	
296/5250 (epoch 2.819), train_loss = 1.99942106, grad/param norm = 1.4658e-01, time/batch = 0.2576s	
297/5250 (epoch 2.829), train_loss = 1.99821388, grad/param norm = 1.2290e-01, time/batch = 0.2575s	
298/5250 (epoch 2.838), train_loss = 1.95527792, grad/param norm = 1.1403e-01, time/batch = 0.2579s	
299/5250 (epoch 2.848), train_loss = 1.96741246, grad/param norm = 1.4297e-01, time/batch = 0.2581s	
300/5250 (epoch 2.857), train_loss = 1.99733564, grad/param norm = 1.6220e-01, time/batch = 0.2580s	
301/5250 (epoch 2.867), train_loss = 1.98008576, grad/param norm = 1.6593e-01, time/batch = 0.2590s	
302/5250 (epoch 2.876), train_loss = 2.00848648, grad/param norm = 1.9892e-01, time/batch = 0.2576s	
303/5250 (epoch 2.886), train_loss = 2.00436014, grad/param norm = 1.9047e-01, time/batch = 0.2576s	
304/5250 (epoch 2.895), train_loss = 2.00515361, grad/param norm = 1.8175e-01, time/batch = 0.2577s	
305/5250 (epoch 2.905), train_loss = 1.98476805, grad/param norm = 1.6075e-01, time/batch = 0.2575s	
306/5250 (epoch 2.914), train_loss = 1.97224191, grad/param norm = 1.5865e-01, time/batch = 0.2577s	
307/5250 (epoch 2.924), train_loss = 1.96071670, grad/param norm = 1.2712e-01, time/batch = 0.2573s	
308/5250 (epoch 2.933), train_loss = 1.96381557, grad/param norm = 1.1847e-01, time/batch = 0.2578s	
309/5250 (epoch 2.943), train_loss = 1.96034399, grad/param norm = 9.9724e-02, time/batch = 0.2577s	
310/5250 (epoch 2.952), train_loss = 1.96532685, grad/param norm = 1.0050e-01, time/batch = 0.2581s	
311/5250 (epoch 2.962), train_loss = 1.94371902, grad/param norm = 1.0214e-01, time/batch = 0.2586s	
312/5250 (epoch 2.971), train_loss = 1.93139236, grad/param norm = 1.0034e-01, time/batch = 0.2575s	
313/5250 (epoch 2.981), train_loss = 1.95966218, grad/param norm = 9.7278e-02, time/batch = 0.2577s	
314/5250 (epoch 2.990), train_loss = 1.93704119, grad/param norm = 9.4494e-02, time/batch = 0.2575s	
315/5250 (epoch 3.000), train_loss = 1.90556731, grad/param norm = 1.0127e-01, time/batch = 0.2573s	
316/5250 (epoch 3.010), train_loss = 2.00029937, grad/param norm = 1.1338e-01, time/batch = 0.2575s	
317/5250 (epoch 3.019), train_loss = 1.92895170, grad/param norm = 1.3341e-01, time/batch = 0.2579s	
318/5250 (epoch 3.029), train_loss = 1.94333276, grad/param norm = 1.3889e-01, time/batch = 0.2580s	
319/5250 (epoch 3.038), train_loss = 1.95665418, grad/param norm = 1.2814e-01, time/batch = 0.2581s	
320/5250 (epoch 3.048), train_loss = 1.90051079, grad/param norm = 1.1565e-01, time/batch = 0.2581s	
321/5250 (epoch 3.057), train_loss = 1.91386062, grad/param norm = 9.9455e-02, time/batch = 0.2590s	
322/5250 (epoch 3.067), train_loss = 1.90906832, grad/param norm = 1.0142e-01, time/batch = 0.2577s	
323/5250 (epoch 3.076), train_loss = 1.92062282, grad/param norm = 1.2230e-01, time/batch = 0.2579s	
324/5250 (epoch 3.086), train_loss = 1.87267479, grad/param norm = 1.2145e-01, time/batch = 0.2608s	
325/5250 (epoch 3.095), train_loss = 1.91980893, grad/param norm = 1.3480e-01, time/batch = 0.2578s	
326/5250 (epoch 3.105), train_loss = 1.94035303, grad/param norm = 1.5978e-01, time/batch = 0.2576s	
327/5250 (epoch 3.114), train_loss = 1.92430339, grad/param norm = 1.5079e-01, time/batch = 0.2580s	
328/5250 (epoch 3.124), train_loss = 1.91367195, grad/param norm = 1.3277e-01, time/batch = 0.2577s	
329/5250 (epoch 3.133), train_loss = 1.90469538, grad/param norm = 1.3158e-01, time/batch = 0.2580s	
330/5250 (epoch 3.143), train_loss = 1.86251387, grad/param norm = 1.2770e-01, time/batch = 0.2582s	
331/5250 (epoch 3.152), train_loss = 1.87450300, grad/param norm = 1.1451e-01, time/batch = 0.2588s	
332/5250 (epoch 3.162), train_loss = 1.87610857, grad/param norm = 1.2489e-01, time/batch = 0.2576s	
333/5250 (epoch 3.171), train_loss = 1.92480413, grad/param norm = 1.6204e-01, time/batch = 0.2578s	
334/5250 (epoch 3.181), train_loss = 1.92867268, grad/param norm = 1.5382e-01, time/batch = 0.2580s	
335/5250 (epoch 3.190), train_loss = 1.88118458, grad/param norm = 1.0336e-01, time/batch = 0.2577s	
336/5250 (epoch 3.200), train_loss = 1.85231357, grad/param norm = 8.8248e-02, time/batch = 0.2575s	
337/5250 (epoch 3.210), train_loss = 1.85694740, grad/param norm = 7.8638e-02, time/batch = 0.2575s	
338/5250 (epoch 3.219), train_loss = 1.87409479, grad/param norm = 7.5311e-02, time/batch = 0.2576s	
339/5250 (epoch 3.229), train_loss = 1.85555424, grad/param norm = 8.6634e-02, time/batch = 0.2576s	
340/5250 (epoch 3.238), train_loss = 1.85126945, grad/param norm = 1.3589e-01, time/batch = 0.2580s	
341/5250 (epoch 3.248), train_loss = 1.92531194, grad/param norm = 1.4436e-01, time/batch = 0.2586s	
342/5250 (epoch 3.257), train_loss = 1.89119486, grad/param norm = 1.4867e-01, time/batch = 0.2577s	
343/5250 (epoch 3.267), train_loss = 1.85758361, grad/param norm = 1.1150e-01, time/batch = 0.2580s	
344/5250 (epoch 3.276), train_loss = 1.84803185, grad/param norm = 9.3970e-02, time/batch = 0.2576s	
345/5250 (epoch 3.286), train_loss = 1.79123408, grad/param norm = 9.0370e-02, time/batch = 0.2578s	
346/5250 (epoch 3.295), train_loss = 1.82464047, grad/param norm = 8.9616e-02, time/batch = 0.2575s	
347/5250 (epoch 3.305), train_loss = 1.82981897, grad/param norm = 1.1182e-01, time/batch = 0.2578s	
348/5250 (epoch 3.314), train_loss = 1.79617794, grad/param norm = 1.2209e-01, time/batch = 0.2576s	
349/5250 (epoch 3.324), train_loss = 1.84295574, grad/param norm = 1.4424e-01, time/batch = 0.2581s	
350/5250 (epoch 3.333), train_loss = 1.85455355, grad/param norm = 1.5048e-01, time/batch = 0.2581s	
351/5250 (epoch 3.343), train_loss = 1.84514964, grad/param norm = 1.3723e-01, time/batch = 0.2588s	
352/5250 (epoch 3.352), train_loss = 1.82944887, grad/param norm = 1.3500e-01, time/batch = 0.2574s	
353/5250 (epoch 3.362), train_loss = 1.82902845, grad/param norm = 1.4114e-01, time/batch = 0.2580s	
354/5250 (epoch 3.371), train_loss = 1.80813752, grad/param norm = 1.3157e-01, time/batch = 0.2578s	
355/5250 (epoch 3.381), train_loss = 1.80726557, grad/param norm = 1.1496e-01, time/batch = 0.2577s	
356/5250 (epoch 3.390), train_loss = 1.83337779, grad/param norm = 1.0292e-01, time/batch = 0.2606s	
357/5250 (epoch 3.400), train_loss = 1.78596111, grad/param norm = 8.9927e-02, time/batch = 0.2576s	
358/5250 (epoch 3.410), train_loss = 1.81864487, grad/param norm = 9.4184e-02, time/batch = 0.2580s	
359/5250 (epoch 3.419), train_loss = 1.81255167, grad/param norm = 1.1831e-01, time/batch = 0.2579s	
360/5250 (epoch 3.429), train_loss = 1.83974983, grad/param norm = 1.3204e-01, time/batch = 0.2582s	
361/5250 (epoch 3.438), train_loss = 1.85866677, grad/param norm = 1.1583e-01, time/batch = 0.2589s	
362/5250 (epoch 3.448), train_loss = 1.79648999, grad/param norm = 9.7041e-02, time/batch = 0.2581s	
363/5250 (epoch 3.457), train_loss = 1.77609513, grad/param norm = 1.0817e-01, time/batch = 0.2577s	
364/5250 (epoch 3.467), train_loss = 1.78198265, grad/param norm = 1.1024e-01, time/batch = 0.2579s	
365/5250 (epoch 3.476), train_loss = 1.77267884, grad/param norm = 1.0651e-01, time/batch = 0.2577s	
366/5250 (epoch 3.486), train_loss = 1.80200430, grad/param norm = 1.1005e-01, time/batch = 0.2574s	
367/5250 (epoch 3.495), train_loss = 1.79479512, grad/param norm = 1.0610e-01, time/batch = 0.2576s	
368/5250 (epoch 3.505), train_loss = 1.82274938, grad/param norm = 1.0844e-01, time/batch = 0.2578s	
369/5250 (epoch 3.514), train_loss = 1.81405928, grad/param norm = 1.1018e-01, time/batch = 0.2582s	
370/5250 (epoch 3.524), train_loss = 1.77703361, grad/param norm = 8.9738e-02, time/batch = 0.2581s	
371/5250 (epoch 3.533), train_loss = 1.77294345, grad/param norm = 8.5879e-02, time/batch = 0.2588s	
372/5250 (epoch 3.543), train_loss = 1.75540655, grad/param norm = 8.3026e-02, time/batch = 0.2581s	
373/5250 (epoch 3.552), train_loss = 1.76387811, grad/param norm = 7.6353e-02, time/batch = 0.2578s	
374/5250 (epoch 3.562), train_loss = 1.76895027, grad/param norm = 7.7129e-02, time/batch = 0.2579s	
375/5250 (epoch 3.571), train_loss = 1.76250494, grad/param norm = 9.2255e-02, time/batch = 0.2579s	
376/5250 (epoch 3.581), train_loss = 1.78798241, grad/param norm = 1.1308e-01, time/batch = 0.2581s	
377/5250 (epoch 3.590), train_loss = 1.78433711, grad/param norm = 1.3915e-01, time/batch = 0.2575s	
378/5250 (epoch 3.600), train_loss = 1.82088998, grad/param norm = 1.5192e-01, time/batch = 0.2576s	
379/5250 (epoch 3.610), train_loss = 1.82057552, grad/param norm = 1.6050e-01, time/batch = 0.2579s	
380/5250 (epoch 3.619), train_loss = 1.78946568, grad/param norm = 1.3179e-01, time/batch = 0.2580s	
381/5250 (epoch 3.629), train_loss = 1.81389457, grad/param norm = 1.1002e-01, time/batch = 0.2590s	
382/5250 (epoch 3.638), train_loss = 1.76555858, grad/param norm = 9.0774e-02, time/batch = 0.2579s	
383/5250 (epoch 3.648), train_loss = 1.75737565, grad/param norm = 7.2193e-02, time/batch = 0.2577s	
384/5250 (epoch 3.657), train_loss = 1.72661756, grad/param norm = 7.4380e-02, time/batch = 0.2580s	
385/5250 (epoch 3.667), train_loss = 1.75194622, grad/param norm = 8.5542e-02, time/batch = 0.2577s	
386/5250 (epoch 3.676), train_loss = 1.74677668, grad/param norm = 9.1427e-02, time/batch = 0.2577s	
387/5250 (epoch 3.686), train_loss = 1.76451638, grad/param norm = 9.2237e-02, time/batch = 0.2577s	
388/5250 (epoch 3.695), train_loss = 1.74244478, grad/param norm = 1.0115e-01, time/batch = 0.2602s	
389/5250 (epoch 3.705), train_loss = 1.73706924, grad/param norm = 1.0591e-01, time/batch = 0.2581s	
390/5250 (epoch 3.714), train_loss = 1.75913136, grad/param norm = 1.0782e-01, time/batch = 0.2579s	
391/5250 (epoch 3.724), train_loss = 1.72979273, grad/param norm = 1.0606e-01, time/batch = 0.2589s	
392/5250 (epoch 3.733), train_loss = 1.72965180, grad/param norm = 1.0057e-01, time/batch = 0.2578s	
393/5250 (epoch 3.743), train_loss = 1.71704412, grad/param norm = 1.0156e-01, time/batch = 0.2581s	
394/5250 (epoch 3.752), train_loss = 1.74300877, grad/param norm = 1.1381e-01, time/batch = 0.2577s	
395/5250 (epoch 3.762), train_loss = 1.73387801, grad/param norm = 1.3076e-01, time/batch = 0.2579s	
396/5250 (epoch 3.771), train_loss = 1.71691743, grad/param norm = 1.2266e-01, time/batch = 0.2573s	
397/5250 (epoch 3.781), train_loss = 1.72472036, grad/param norm = 9.7477e-02, time/batch = 0.2577s	
398/5250 (epoch 3.790), train_loss = 1.73359800, grad/param norm = 8.4454e-02, time/batch = 0.2577s	
399/5250 (epoch 3.800), train_loss = 1.71995215, grad/param norm = 7.7903e-02, time/batch = 0.2578s	
400/5250 (epoch 3.810), train_loss = 1.69344625, grad/param norm = 7.8833e-02, time/batch = 0.2582s	
401/5250 (epoch 3.819), train_loss = 1.71403615, grad/param norm = 9.0618e-02, time/batch = 0.2586s	
402/5250 (epoch 3.829), train_loss = 1.73664954, grad/param norm = 1.0601e-01, time/batch = 0.2577s	
403/5250 (epoch 3.838), train_loss = 1.71331059, grad/param norm = 9.9257e-02, time/batch = 0.2581s	
404/5250 (epoch 3.848), train_loss = 1.69615670, grad/param norm = 9.8805e-02, time/batch = 0.2577s	
405/5250 (epoch 3.857), train_loss = 1.72980782, grad/param norm = 9.2859e-02, time/batch = 0.2577s	
406/5250 (epoch 3.867), train_loss = 1.71171402, grad/param norm = 1.0695e-01, time/batch = 0.2579s	
407/5250 (epoch 3.876), train_loss = 1.74566967, grad/param norm = 9.5887e-02, time/batch = 0.2574s	
408/5250 (epoch 3.886), train_loss = 1.71067992, grad/param norm = 1.0629e-01, time/batch = 0.2574s	
409/5250 (epoch 3.895), train_loss = 1.74781110, grad/param norm = 1.1240e-01, time/batch = 0.2579s	
410/5250 (epoch 3.905), train_loss = 1.72288500, grad/param norm = 9.6770e-02, time/batch = 0.2579s	
411/5250 (epoch 3.914), train_loss = 1.72425728, grad/param norm = 9.1451e-02, time/batch = 0.2587s	
412/5250 (epoch 3.924), train_loss = 1.69984109, grad/param norm = 7.3560e-02, time/batch = 0.2579s	
413/5250 (epoch 3.933), train_loss = 1.68893604, grad/param norm = 6.7477e-02, time/batch = 0.2577s	
414/5250 (epoch 3.943), train_loss = 1.72364002, grad/param norm = 7.7405e-02, time/batch = 0.2576s	
415/5250 (epoch 3.952), train_loss = 1.72538026, grad/param norm = 9.7215e-02, time/batch = 0.2575s	
416/5250 (epoch 3.962), train_loss = 1.72055113, grad/param norm = 1.1936e-01, time/batch = 0.2581s	
417/5250 (epoch 3.971), train_loss = 1.70670462, grad/param norm = 1.1553e-01, time/batch = 0.2577s	
418/5250 (epoch 3.981), train_loss = 1.71328381, grad/param norm = 1.0797e-01, time/batch = 0.2575s	
419/5250 (epoch 3.990), train_loss = 1.71628467, grad/param norm = 9.3592e-02, time/batch = 0.2581s	
420/5250 (epoch 4.000), train_loss = 1.68740907, grad/param norm = 1.0541e-01, time/batch = 0.2607s	
421/5250 (epoch 4.010), train_loss = 1.82648542, grad/param norm = 1.0493e-01, time/batch = 0.2593s	
422/5250 (epoch 4.019), train_loss = 1.69354089, grad/param norm = 9.4018e-02, time/batch = 0.2580s	
423/5250 (epoch 4.029), train_loss = 1.67575984, grad/param norm = 7.2767e-02, time/batch = 0.2581s	
424/5250 (epoch 4.038), train_loss = 1.66472497, grad/param norm = 7.7607e-02, time/batch = 0.2580s	
425/5250 (epoch 4.048), train_loss = 1.65563467, grad/param norm = 8.7924e-02, time/batch = 0.2581s	
426/5250 (epoch 4.057), train_loss = 1.67628810, grad/param norm = 8.4820e-02, time/batch = 0.2577s	
427/5250 (epoch 4.067), train_loss = 1.65912167, grad/param norm = 7.7987e-02, time/batch = 0.2577s	
428/5250 (epoch 4.076), train_loss = 1.65894940, grad/param norm = 7.6341e-02, time/batch = 0.2582s	
429/5250 (epoch 4.086), train_loss = 1.59577044, grad/param norm = 8.0348e-02, time/batch = 0.2582s	
430/5250 (epoch 4.095), train_loss = 1.65477341, grad/param norm = 9.5040e-02, time/batch = 0.2580s	
431/5250 (epoch 4.105), train_loss = 1.67706020, grad/param norm = 9.3399e-02, time/batch = 0.2593s	
432/5250 (epoch 4.114), train_loss = 1.64135649, grad/param norm = 8.5400e-02, time/batch = 0.2576s	
433/5250 (epoch 4.124), train_loss = 1.65116123, grad/param norm = 9.2635e-02, time/batch = 0.2577s	
434/5250 (epoch 4.133), train_loss = 1.64934926, grad/param norm = 1.0218e-01, time/batch = 0.2578s	
435/5250 (epoch 4.143), train_loss = 1.61926616, grad/param norm = 9.5927e-02, time/batch = 0.2580s	
436/5250 (epoch 4.152), train_loss = 1.61482064, grad/param norm = 9.4755e-02, time/batch = 0.2575s	
437/5250 (epoch 4.162), train_loss = 1.65823256, grad/param norm = 1.0023e-01, time/batch = 0.2575s	
438/5250 (epoch 4.171), train_loss = 1.66392171, grad/param norm = 8.8243e-02, time/batch = 0.2574s	
439/5250 (epoch 4.181), train_loss = 1.65812481, grad/param norm = 8.4364e-02, time/batch = 0.2582s	
440/5250 (epoch 4.190), train_loss = 1.63984495, grad/param norm = 9.0011e-02, time/batch = 0.2580s	
441/5250 (epoch 4.200), train_loss = 1.63880158, grad/param norm = 9.5624e-02, time/batch = 0.2586s	
442/5250 (epoch 4.210), train_loss = 1.64784285, grad/param norm = 1.0497e-01, time/batch = 0.2577s	
443/5250 (epoch 4.219), train_loss = 1.69312205, grad/param norm = 1.0466e-01, time/batch = 0.2582s	
444/5250 (epoch 4.229), train_loss = 1.64713153, grad/param norm = 1.0183e-01, time/batch = 0.2576s	
445/5250 (epoch 4.238), train_loss = 1.63080115, grad/param norm = 8.2114e-02, time/batch = 0.2578s	
446/5250 (epoch 4.248), train_loss = 1.63589112, grad/param norm = 8.4471e-02, time/batch = 0.2578s	
447/5250 (epoch 4.257), train_loss = 1.62067236, grad/param norm = 7.8276e-02, time/batch = 0.2576s	
448/5250 (epoch 4.267), train_loss = 1.61402911, grad/param norm = 8.1485e-02, time/batch = 0.2577s	
449/5250 (epoch 4.276), train_loss = 1.63431562, grad/param norm = 9.3116e-02, time/batch = 0.2578s	
450/5250 (epoch 4.286), train_loss = 1.60717422, grad/param norm = 8.5880e-02, time/batch = 0.2584s	
451/5250 (epoch 4.295), train_loss = 1.62414871, grad/param norm = 7.5578e-02, time/batch = 0.2591s	
452/5250 (epoch 4.305), train_loss = 1.61577238, grad/param norm = 7.2206e-02, time/batch = 0.2601s	
453/5250 (epoch 4.314), train_loss = 1.56734533, grad/param norm = 6.4168e-02, time/batch = 0.2578s	
454/5250 (epoch 4.324), train_loss = 1.60764057, grad/param norm = 7.1689e-02, time/batch = 0.2577s	
455/5250 (epoch 4.333), train_loss = 1.62625362, grad/param norm = 8.6413e-02, time/batch = 0.2580s	
456/5250 (epoch 4.343), train_loss = 1.63021887, grad/param norm = 8.9586e-02, time/batch = 0.2577s	
457/5250 (epoch 4.352), train_loss = 1.63694594, grad/param norm = 9.2787e-02, time/batch = 0.2579s	
458/5250 (epoch 4.362), train_loss = 1.61688896, grad/param norm = 7.5057e-02, time/batch = 0.2578s	
459/5250 (epoch 4.371), train_loss = 1.57894102, grad/param norm = 6.3668e-02, time/batch = 0.2580s	
460/5250 (epoch 4.381), train_loss = 1.58699157, grad/param norm = 7.1848e-02, time/batch = 0.2581s	
461/5250 (epoch 4.390), train_loss = 1.62510264, grad/param norm = 8.2974e-02, time/batch = 0.2585s	
462/5250 (epoch 4.400), train_loss = 1.59520564, grad/param norm = 8.4023e-02, time/batch = 0.2582s	
463/5250 (epoch 4.410), train_loss = 1.62609343, grad/param norm = 8.5722e-02, time/batch = 0.2582s	
464/5250 (epoch 4.419), train_loss = 1.60694577, grad/param norm = 9.7083e-02, time/batch = 0.2577s	
465/5250 (epoch 4.429), train_loss = 1.61834349, grad/param norm = 9.5849e-02, time/batch = 0.2575s	
466/5250 (epoch 4.438), train_loss = 1.63373162, grad/param norm = 8.5950e-02, time/batch = 0.2581s	
467/5250 (epoch 4.448), train_loss = 1.57454405, grad/param norm = 7.1723e-02, time/batch = 0.2577s	
468/5250 (epoch 4.457), train_loss = 1.55933376, grad/param norm = 7.3116e-02, time/batch = 0.2576s	
469/5250 (epoch 4.467), train_loss = 1.59253937, grad/param norm = 8.6212e-02, time/batch = 0.2579s	
470/5250 (epoch 4.476), train_loss = 1.59385856, grad/param norm = 8.7744e-02, time/batch = 0.2584s	
471/5250 (epoch 4.486), train_loss = 1.61736579, grad/param norm = 8.8217e-02, time/batch = 0.2593s	
472/5250 (epoch 4.495), train_loss = 1.60396317, grad/param norm = 8.5984e-02, time/batch = 0.2577s	
473/5250 (epoch 4.505), train_loss = 1.60473162, grad/param norm = 7.2862e-02, time/batch = 0.2582s	
474/5250 (epoch 4.514), train_loss = 1.59339287, grad/param norm = 7.4813e-02, time/batch = 0.2578s	
475/5250 (epoch 4.524), train_loss = 1.56868560, grad/param norm = 7.9436e-02, time/batch = 0.2577s	
476/5250 (epoch 4.533), train_loss = 1.58487374, grad/param norm = 8.6503e-02, time/batch = 0.2575s	
477/5250 (epoch 4.543), train_loss = 1.56731601, grad/param norm = 8.3994e-02, time/batch = 0.2578s	
478/5250 (epoch 4.552), train_loss = 1.59049470, grad/param norm = 8.6785e-02, time/batch = 0.2581s	
479/5250 (epoch 4.562), train_loss = 1.60335533, grad/param norm = 8.1977e-02, time/batch = 0.2579s	
480/5250 (epoch 4.571), train_loss = 1.60308727, grad/param norm = 8.5484e-02, time/batch = 0.2583s	
481/5250 (epoch 4.581), train_loss = 1.61523610, grad/param norm = 7.4479e-02, time/batch = 0.2590s	
482/5250 (epoch 4.590), train_loss = 1.57662898, grad/param norm = 6.6252e-02, time/batch = 0.2578s	
483/5250 (epoch 4.600), train_loss = 1.59420449, grad/param norm = 6.8199e-02, time/batch = 0.2580s	
484/5250 (epoch 4.610), train_loss = 1.58704966, grad/param norm = 7.6041e-02, time/batch = 0.2592s	
485/5250 (epoch 4.619), train_loss = 1.56869942, grad/param norm = 7.1183e-02, time/batch = 0.2577s	
486/5250 (epoch 4.629), train_loss = 1.59129519, grad/param norm = 7.2251e-02, time/batch = 0.2576s	
487/5250 (epoch 4.638), train_loss = 1.58637719, grad/param norm = 8.4416e-02, time/batch = 0.2576s	
488/5250 (epoch 4.648), train_loss = 1.59373555, grad/param norm = 7.7968e-02, time/batch = 0.2577s	
489/5250 (epoch 4.657), train_loss = 1.56441990, grad/param norm = 6.9989e-02, time/batch = 0.2583s	
490/5250 (epoch 4.667), train_loss = 1.57693319, grad/param norm = 6.5525e-02, time/batch = 0.2581s	
491/5250 (epoch 4.676), train_loss = 1.56119199, grad/param norm = 6.4660e-02, time/batch = 0.2588s	
492/5250 (epoch 4.686), train_loss = 1.58913281, grad/param norm = 6.4584e-02, time/batch = 0.2577s	
493/5250 (epoch 4.695), train_loss = 1.57017820, grad/param norm = 6.4494e-02, time/batch = 0.2579s	
494/5250 (epoch 4.705), train_loss = 1.55332209, grad/param norm = 5.9975e-02, time/batch = 0.2579s	
495/5250 (epoch 4.714), train_loss = 1.56698706, grad/param norm = 6.1002e-02, time/batch = 0.2577s	
496/5250 (epoch 4.724), train_loss = 1.54713014, grad/param norm = 6.5744e-02, time/batch = 0.2577s	
497/5250 (epoch 4.733), train_loss = 1.54305559, grad/param norm = 7.1137e-02, time/batch = 0.2575s	
498/5250 (epoch 4.743), train_loss = 1.53234910, grad/param norm = 8.0136e-02, time/batch = 0.2575s	
499/5250 (epoch 4.752), train_loss = 1.55952405, grad/param norm = 8.6330e-02, time/batch = 0.2585s	
500/5250 (epoch 4.762), train_loss = 1.55840232, grad/param norm = 9.5201e-02, time/batch = 0.2585s	
501/5250 (epoch 4.771), train_loss = 1.55232548, grad/param norm = 1.0514e-01, time/batch = 0.2591s	
502/5250 (epoch 4.781), train_loss = 1.58032940, grad/param norm = 9.6624e-02, time/batch = 0.2577s	
503/5250 (epoch 4.790), train_loss = 1.57713741, grad/param norm = 8.3909e-02, time/batch = 0.2581s	
504/5250 (epoch 4.800), train_loss = 1.56221770, grad/param norm = 7.9524e-02, time/batch = 0.2575s	
505/5250 (epoch 4.810), train_loss = 1.54745195, grad/param norm = 8.3377e-02, time/batch = 0.2575s	
506/5250 (epoch 4.819), train_loss = 1.56176003, grad/param norm = 8.3210e-02, time/batch = 0.2576s	
507/5250 (epoch 4.829), train_loss = 1.55922141, grad/param norm = 7.4417e-02, time/batch = 0.2575s	
508/5250 (epoch 4.838), train_loss = 1.52540704, grad/param norm = 6.6232e-02, time/batch = 0.2578s	
509/5250 (epoch 4.848), train_loss = 1.51680164, grad/param norm = 7.0522e-02, time/batch = 0.2584s	
510/5250 (epoch 4.857), train_loss = 1.55202142, grad/param norm = 7.5397e-02, time/batch = 0.2579s	
511/5250 (epoch 4.867), train_loss = 1.52858148, grad/param norm = 7.6479e-02, time/batch = 0.2589s	
512/5250 (epoch 4.876), train_loss = 1.55253364, grad/param norm = 7.1664e-02, time/batch = 0.2576s	
513/5250 (epoch 4.886), train_loss = 1.52212357, grad/param norm = 7.3558e-02, time/batch = 0.2579s	
514/5250 (epoch 4.895), train_loss = 1.56576789, grad/param norm = 8.0938e-02, time/batch = 0.2578s	
515/5250 (epoch 4.905), train_loss = 1.56790580, grad/param norm = 8.7974e-02, time/batch = 0.2581s	
516/5250 (epoch 4.914), train_loss = 1.57376243, grad/param norm = 8.1604e-02, time/batch = 0.2591s	
517/5250 (epoch 4.924), train_loss = 1.55075136, grad/param norm = 6.5372e-02, time/batch = 0.2579s	
518/5250 (epoch 4.933), train_loss = 1.53259861, grad/param norm = 6.0035e-02, time/batch = 0.2579s	
519/5250 (epoch 4.943), train_loss = 1.56573361, grad/param norm = 5.8445e-02, time/batch = 0.2582s	
520/5250 (epoch 4.952), train_loss = 1.55843945, grad/param norm = 6.2688e-02, time/batch = 0.2581s	
521/5250 (epoch 4.962), train_loss = 1.54841499, grad/param norm = 7.0641e-02, time/batch = 0.2590s	
522/5250 (epoch 4.971), train_loss = 1.53486068, grad/param norm = 6.8319e-02, time/batch = 0.2575s	
523/5250 (epoch 4.981), train_loss = 1.55473507, grad/param norm = 6.1748e-02, time/batch = 0.2576s	
524/5250 (epoch 4.990), train_loss = 1.54741495, grad/param norm = 6.6399e-02, time/batch = 0.2579s	
525/5250 (epoch 5.000), train_loss = 1.53909173, grad/param norm = 9.1320e-02, time/batch = 0.2578s	
526/5250 (epoch 5.010), train_loss = 1.70051327, grad/param norm = 1.1952e-01, time/batch = 0.2575s	
527/5250 (epoch 5.019), train_loss = 1.56310316, grad/param norm = 1.1045e-01, time/batch = 0.2577s	
528/5250 (epoch 5.029), train_loss = 1.54932453, grad/param norm = 9.1388e-02, time/batch = 0.2577s	
529/5250 (epoch 5.038), train_loss = 1.51654708, grad/param norm = 6.8412e-02, time/batch = 0.2577s	
530/5250 (epoch 5.048), train_loss = 1.49206614, grad/param norm = 7.0649e-02, time/batch = 0.2580s	
531/5250 (epoch 5.057), train_loss = 1.52021222, grad/param norm = 6.0571e-02, time/batch = 0.2586s	
532/5250 (epoch 5.067), train_loss = 1.50563536, grad/param norm = 5.4395e-02, time/batch = 0.2578s	
533/5250 (epoch 5.076), train_loss = 1.50410088, grad/param norm = 4.8394e-02, time/batch = 0.2583s	
534/5250 (epoch 5.086), train_loss = 1.43767556, grad/param norm = 5.7169e-02, time/batch = 0.2580s	
535/5250 (epoch 5.095), train_loss = 1.48783212, grad/param norm = 6.2486e-02, time/batch = 0.2578s	
536/5250 (epoch 5.105), train_loss = 1.50418253, grad/param norm = 6.3284e-02, time/batch = 0.2576s	
537/5250 (epoch 5.114), train_loss = 1.48761929, grad/param norm = 6.4491e-02, time/batch = 0.2578s	
538/5250 (epoch 5.124), train_loss = 1.49948415, grad/param norm = 6.9920e-02, time/batch = 0.2579s	
539/5250 (epoch 5.133), train_loss = 1.49823214, grad/param norm = 8.1681e-02, time/batch = 0.2577s	
540/5250 (epoch 5.143), train_loss = 1.48150326, grad/param norm = 8.4904e-02, time/batch = 0.2581s	
541/5250 (epoch 5.152), train_loss = 1.47477346, grad/param norm = 8.4246e-02, time/batch = 0.2589s	
542/5250 (epoch 5.162), train_loss = 1.51333397, grad/param norm = 8.6775e-02, time/batch = 0.2577s	
543/5250 (epoch 5.171), train_loss = 1.52288136, grad/param norm = 7.8095e-02, time/batch = 0.2579s	
544/5250 (epoch 5.181), train_loss = 1.51210153, grad/param norm = 6.4719e-02, time/batch = 0.2577s	
545/5250 (epoch 5.190), train_loss = 1.49313441, grad/param norm = 5.5584e-02, time/batch = 0.2576s	
546/5250 (epoch 5.200), train_loss = 1.48827461, grad/param norm = 6.1479e-02, time/batch = 0.2576s	
547/5250 (epoch 5.210), train_loss = 1.49145343, grad/param norm = 5.9920e-02, time/batch = 0.2583s	
548/5250 (epoch 5.219), train_loss = 1.52366400, grad/param norm = 5.8364e-02, time/batch = 0.2593s	
549/5250 (epoch 5.229), train_loss = 1.48745402, grad/param norm = 5.8677e-02, time/batch = 0.2580s	
550/5250 (epoch 5.238), train_loss = 1.47713293, grad/param norm = 6.1112e-02, time/batch = 0.2586s	
551/5250 (epoch 5.248), train_loss = 1.49296433, grad/param norm = 6.3872e-02, time/batch = 0.2591s	
552/5250 (epoch 5.257), train_loss = 1.47441490, grad/param norm = 6.4504e-02, time/batch = 0.2581s	
553/5250 (epoch 5.267), train_loss = 1.47378375, grad/param norm = 6.7607e-02, time/batch = 0.2580s	
554/5250 (epoch 5.276), train_loss = 1.47542555, grad/param norm = 7.0441e-02, time/batch = 0.2576s	
555/5250 (epoch 5.286), train_loss = 1.45461737, grad/param norm = 6.4871e-02, time/batch = 0.2576s	
556/5250 (epoch 5.295), train_loss = 1.47674137, grad/param norm = 6.5114e-02, time/batch = 0.2576s	
557/5250 (epoch 5.305), train_loss = 1.48094864, grad/param norm = 6.7034e-02, time/batch = 0.2579s	
558/5250 (epoch 5.314), train_loss = 1.45081420, grad/param norm = 6.7068e-02, time/batch = 0.2578s	
559/5250 (epoch 5.324), train_loss = 1.49219527, grad/param norm = 6.5207e-02, time/batch = 0.2580s	
560/5250 (epoch 5.333), train_loss = 1.48472935, grad/param norm = 6.2588e-02, time/batch = 0.2581s	
561/5250 (epoch 5.343), train_loss = 1.48382599, grad/param norm = 5.8976e-02, time/batch = 0.2591s	
562/5250 (epoch 5.352), train_loss = 1.49526322, grad/param norm = 7.1601e-02, time/batch = 0.2579s	
563/5250 (epoch 5.362), train_loss = 1.50748258, grad/param norm = 7.5455e-02, time/batch = 0.2582s	
564/5250 (epoch 5.371), train_loss = 1.46598923, grad/param norm = 6.8236e-02, time/batch = 0.2576s	
565/5250 (epoch 5.381), train_loss = 1.46900393, grad/param norm = 6.4882e-02, time/batch = 0.2579s	
566/5250 (epoch 5.390), train_loss = 1.48632178, grad/param norm = 6.9579e-02, time/batch = 0.2579s	
567/5250 (epoch 5.400), train_loss = 1.46389340, grad/param norm = 6.1526e-02, time/batch = 0.2574s	
568/5250 (epoch 5.410), train_loss = 1.47778667, grad/param norm = 5.6356e-02, time/batch = 0.2578s	
569/5250 (epoch 5.419), train_loss = 1.46007885, grad/param norm = 5.6022e-02, time/batch = 0.2582s	
570/5250 (epoch 5.429), train_loss = 1.47546438, grad/param norm = 6.2549e-02, time/batch = 0.2584s	
571/5250 (epoch 5.438), train_loss = 1.50982464, grad/param norm = 7.2049e-02, time/batch = 0.2596s	
572/5250 (epoch 5.448), train_loss = 1.46664179, grad/param norm = 8.2549e-02, time/batch = 0.2577s	
573/5250 (epoch 5.457), train_loss = 1.46712731, grad/param norm = 9.6447e-02, time/batch = 0.2579s	
574/5250 (epoch 5.467), train_loss = 1.48056766, grad/param norm = 9.2541e-02, time/batch = 0.2581s	
575/5250 (epoch 5.476), train_loss = 1.45938599, grad/param norm = 6.9791e-02, time/batch = 0.2580s	
576/5250 (epoch 5.486), train_loss = 1.47343010, grad/param norm = 6.6758e-02, time/batch = 0.2575s	
577/5250 (epoch 5.495), train_loss = 1.47174224, grad/param norm = 6.8199e-02, time/batch = 0.2576s	
578/5250 (epoch 5.505), train_loss = 1.48297360, grad/param norm = 7.2289e-02, time/batch = 0.2581s	
579/5250 (epoch 5.514), train_loss = 1.47813235, grad/param norm = 6.3424e-02, time/batch = 0.2594s	
580/5250 (epoch 5.524), train_loss = 1.44441792, grad/param norm = 5.9406e-02, time/batch = 0.2583s	
581/5250 (epoch 5.533), train_loss = 1.46723912, grad/param norm = 6.0242e-02, time/batch = 0.2597s	
582/5250 (epoch 5.543), train_loss = 1.44432394, grad/param norm = 6.0087e-02, time/batch = 0.2576s	
583/5250 (epoch 5.552), train_loss = 1.45919391, grad/param norm = 5.5006e-02, time/batch = 0.2580s	
584/5250 (epoch 5.562), train_loss = 1.46895859, grad/param norm = 6.0068e-02, time/batch = 0.2574s	
585/5250 (epoch 5.571), train_loss = 1.47851253, grad/param norm = 6.6772e-02, time/batch = 0.2579s	
586/5250 (epoch 5.581), train_loss = 1.49272552, grad/param norm = 6.3331e-02, time/batch = 0.2578s	
587/5250 (epoch 5.590), train_loss = 1.45906588, grad/param norm = 5.9871e-02, time/batch = 0.2578s	
588/5250 (epoch 5.600), train_loss = 1.47754837, grad/param norm = 6.2229e-02, time/batch = 0.2575s	
589/5250 (epoch 5.610), train_loss = 1.46837573, grad/param norm = 6.7089e-02, time/batch = 0.2580s	
590/5250 (epoch 5.619), train_loss = 1.45863229, grad/param norm = 6.5200e-02, time/batch = 0.2580s	
591/5250 (epoch 5.629), train_loss = 1.46650041, grad/param norm = 6.0928e-02, time/batch = 0.2590s	
592/5250 (epoch 5.638), train_loss = 1.45640983, grad/param norm = 6.6616e-02, time/batch = 0.2574s	
593/5250 (epoch 5.648), train_loss = 1.47058210, grad/param norm = 7.4977e-02, time/batch = 0.2577s	
594/5250 (epoch 5.657), train_loss = 1.45060936, grad/param norm = 7.1906e-02, time/batch = 0.2575s	
595/5250 (epoch 5.667), train_loss = 1.46377559, grad/param norm = 6.2110e-02, time/batch = 0.2577s	
596/5250 (epoch 5.676), train_loss = 1.44071894, grad/param norm = 5.3321e-02, time/batch = 0.2574s	
597/5250 (epoch 5.686), train_loss = 1.46609545, grad/param norm = 5.0128e-02, time/batch = 0.2579s	
598/5250 (epoch 5.695), train_loss = 1.44979043, grad/param norm = 5.2853e-02, time/batch = 0.2582s	
599/5250 (epoch 5.705), train_loss = 1.43227314, grad/param norm = 5.0035e-02, time/batch = 0.2577s	
600/5250 (epoch 5.714), train_loss = 1.45573820, grad/param norm = 5.3630e-02, time/batch = 0.2579s	
601/5250 (epoch 5.724), train_loss = 1.43559583, grad/param norm = 5.7602e-02, time/batch = 0.2589s	
602/5250 (epoch 5.733), train_loss = 1.43796325, grad/param norm = 5.8204e-02, time/batch = 0.2576s	
603/5250 (epoch 5.743), train_loss = 1.42517515, grad/param norm = 5.9419e-02, time/batch = 0.2575s	
604/5250 (epoch 5.752), train_loss = 1.44596065, grad/param norm = 5.8215e-02, time/batch = 0.2574s	
605/5250 (epoch 5.762), train_loss = 1.43417312, grad/param norm = 6.3494e-02, time/batch = 0.2578s	
606/5250 (epoch 5.771), train_loss = 1.43831825, grad/param norm = 6.7639e-02, time/batch = 0.2579s	
607/5250 (epoch 5.781), train_loss = 1.45398463, grad/param norm = 6.0337e-02, time/batch = 0.2577s	
608/5250 (epoch 5.790), train_loss = 1.46037328, grad/param norm = 6.1724e-02, time/batch = 0.2582s	
609/5250 (epoch 5.800), train_loss = 1.45080512, grad/param norm = 7.6394e-02, time/batch = 0.2581s	
610/5250 (epoch 5.810), train_loss = 1.44583979, grad/param norm = 7.7763e-02, time/batch = 0.2585s	
611/5250 (epoch 5.819), train_loss = 1.45110653, grad/param norm = 7.2937e-02, time/batch = 0.2599s	
612/5250 (epoch 5.829), train_loss = 1.45477216, grad/param norm = 7.4519e-02, time/batch = 0.2573s	
613/5250 (epoch 5.838), train_loss = 1.42713375, grad/param norm = 7.0258e-02, time/batch = 0.2579s	
614/5250 (epoch 5.848), train_loss = 1.42907183, grad/param norm = 6.9956e-02, time/batch = 0.2575s	
615/5250 (epoch 5.857), train_loss = 1.44635254, grad/param norm = 6.4586e-02, time/batch = 0.2576s	
616/5250 (epoch 5.867), train_loss = 1.43331501, grad/param norm = 6.3762e-02, time/batch = 0.2576s	
617/5250 (epoch 5.876), train_loss = 1.45017393, grad/param norm = 6.8712e-02, time/batch = 0.2576s	
618/5250 (epoch 5.886), train_loss = 1.42473984, grad/param norm = 6.3921e-02, time/batch = 0.2573s	
619/5250 (epoch 5.895), train_loss = 1.44832773, grad/param norm = 5.9578e-02, time/batch = 0.2577s	
620/5250 (epoch 5.905), train_loss = 1.44797943, grad/param norm = 5.3865e-02, time/batch = 0.2582s	
621/5250 (epoch 5.914), train_loss = 1.44926574, grad/param norm = 5.9508e-02, time/batch = 0.2588s	
622/5250 (epoch 5.924), train_loss = 1.45069037, grad/param norm = 5.7991e-02, time/batch = 0.2575s	
623/5250 (epoch 5.933), train_loss = 1.42328786, grad/param norm = 5.5065e-02, time/batch = 0.2582s	
624/5250 (epoch 5.943), train_loss = 1.45471141, grad/param norm = 5.4944e-02, time/batch = 0.2572s	
625/5250 (epoch 5.952), train_loss = 1.45970936, grad/param norm = 6.5436e-02, time/batch = 0.2577s	
626/5250 (epoch 5.962), train_loss = 1.44978645, grad/param norm = 6.0076e-02, time/batch = 0.2578s	
627/5250 (epoch 5.971), train_loss = 1.41945517, grad/param norm = 4.7900e-02, time/batch = 0.2576s	
628/5250 (epoch 5.981), train_loss = 1.44195595, grad/param norm = 4.7278e-02, time/batch = 0.2573s	
629/5250 (epoch 5.990), train_loss = 1.44933361, grad/param norm = 6.1009e-02, time/batch = 0.2578s	
630/5250 (epoch 6.000), train_loss = 1.44769627, grad/param norm = 7.5000e-02, time/batch = 0.2583s	
631/5250 (epoch 6.010), train_loss = 1.59246810, grad/param norm = 8.0725e-02, time/batch = 0.2588s	
632/5250 (epoch 6.019), train_loss = 1.43359967, grad/param norm = 7.3082e-02, time/batch = 0.2576s	
633/5250 (epoch 6.029), train_loss = 1.43557241, grad/param norm = 6.7520e-02, time/batch = 0.2579s	
634/5250 (epoch 6.038), train_loss = 1.40616219, grad/param norm = 5.9835e-02, time/batch = 0.2576s	
635/5250 (epoch 6.048), train_loss = 1.38356272, grad/param norm = 5.8092e-02, time/batch = 0.2576s	
636/5250 (epoch 6.057), train_loss = 1.40328404, grad/param norm = 5.6299e-02, time/batch = 0.2575s	
637/5250 (epoch 6.067), train_loss = 1.39963652, grad/param norm = 5.2710e-02, time/batch = 0.2573s	
638/5250 (epoch 6.076), train_loss = 1.41481151, grad/param norm = 5.3687e-02, time/batch = 0.2580s	
639/5250 (epoch 6.086), train_loss = 1.35534908, grad/param norm = 5.6369e-02, time/batch = 0.2580s	
640/5250 (epoch 6.095), train_loss = 1.39544447, grad/param norm = 6.2464e-02, time/batch = 0.2583s	
641/5250 (epoch 6.105), train_loss = 1.42488597, grad/param norm = 6.1827e-02, time/batch = 0.2591s	
642/5250 (epoch 6.114), train_loss = 1.39482869, grad/param norm = 5.7163e-02, time/batch = 0.2581s	
643/5250 (epoch 6.124), train_loss = 1.40076679, grad/param norm = 6.0240e-02, time/batch = 0.2606s	
644/5250 (epoch 6.133), train_loss = 1.38987365, grad/param norm = 6.2618e-02, time/batch = 0.2576s	
645/5250 (epoch 6.143), train_loss = 1.36852547, grad/param norm = 5.8806e-02, time/batch = 0.2578s	
646/5250 (epoch 6.152), train_loss = 1.36309169, grad/param norm = 5.0226e-02, time/batch = 0.2578s	
647/5250 (epoch 6.162), train_loss = 1.39611126, grad/param norm = 5.1587e-02, time/batch = 0.2577s	
648/5250 (epoch 6.171), train_loss = 1.41060636, grad/param norm = 4.8626e-02, time/batch = 0.2578s	
649/5250 (epoch 6.181), train_loss = 1.40268230, grad/param norm = 4.9038e-02, time/batch = 0.2582s	
650/5250 (epoch 6.190), train_loss = 1.40220432, grad/param norm = 5.6220e-02, time/batch = 0.2583s	
651/5250 (epoch 6.200), train_loss = 1.39542271, grad/param norm = 5.8495e-02, time/batch = 0.2586s	
652/5250 (epoch 6.210), train_loss = 1.39678214, grad/param norm = 6.3146e-02, time/batch = 0.2580s	
653/5250 (epoch 6.219), train_loss = 1.44003066, grad/param norm = 6.9508e-02, time/batch = 0.2581s	
654/5250 (epoch 6.229), train_loss = 1.40937981, grad/param norm = 7.4062e-02, time/batch = 0.2578s	
655/5250 (epoch 6.238), train_loss = 1.40664336, grad/param norm = 6.9675e-02, time/batch = 0.2575s	
656/5250 (epoch 6.248), train_loss = 1.40258961, grad/param norm = 6.2178e-02, time/batch = 0.2578s	
657/5250 (epoch 6.257), train_loss = 1.37634312, grad/param norm = 5.5693e-02, time/batch = 0.2577s	
658/5250 (epoch 6.267), train_loss = 1.37454205, grad/param norm = 5.7596e-02, time/batch = 0.2572s	
659/5250 (epoch 6.276), train_loss = 1.38480222, grad/param norm = 5.9882e-02, time/batch = 0.2583s	
660/5250 (epoch 6.286), train_loss = 1.36808900, grad/param norm = 5.4857e-02, time/batch = 0.2582s	
661/5250 (epoch 6.295), train_loss = 1.38759050, grad/param norm = 5.5599e-02, time/batch = 0.2588s	
662/5250 (epoch 6.305), train_loss = 1.38745149, grad/param norm = 6.2735e-02, time/batch = 0.2576s	
663/5250 (epoch 6.314), train_loss = 1.37058306, grad/param norm = 5.7030e-02, time/batch = 0.2582s	
664/5250 (epoch 6.324), train_loss = 1.39402677, grad/param norm = 5.5484e-02, time/batch = 0.2582s	
665/5250 (epoch 6.333), train_loss = 1.39419851, grad/param norm = 5.8208e-02, time/batch = 0.2579s	
666/5250 (epoch 6.343), train_loss = 1.38734989, grad/param norm = 5.2616e-02, time/batch = 0.2575s	
667/5250 (epoch 6.352), train_loss = 1.39477296, grad/param norm = 5.2070e-02, time/batch = 0.2578s	
668/5250 (epoch 6.362), train_loss = 1.40089507, grad/param norm = 5.0729e-02, time/batch = 0.2576s	
669/5250 (epoch 6.371), train_loss = 1.36772760, grad/param norm = 5.0553e-02, time/batch = 0.2578s	
670/5250 (epoch 6.381), train_loss = 1.37035939, grad/param norm = 4.9866e-02, time/batch = 0.2582s	
671/5250 (epoch 6.390), train_loss = 1.38028821, grad/param norm = 5.2642e-02, time/batch = 0.2586s	
672/5250 (epoch 6.400), train_loss = 1.36996383, grad/param norm = 5.1758e-02, time/batch = 0.2579s	
673/5250 (epoch 6.410), train_loss = 1.38814375, grad/param norm = 5.8172e-02, time/batch = 0.2577s	
674/5250 (epoch 6.419), train_loss = 1.38297077, grad/param norm = 6.2489e-02, time/batch = 0.2578s	
675/5250 (epoch 6.429), train_loss = 1.39471350, grad/param norm = 6.4138e-02, time/batch = 0.2604s	
676/5250 (epoch 6.438), train_loss = 1.41511479, grad/param norm = 6.1639e-02, time/batch = 0.2577s	
677/5250 (epoch 6.448), train_loss = 1.35987987, grad/param norm = 5.3940e-02, time/batch = 0.2580s	
678/5250 (epoch 6.457), train_loss = 1.35155038, grad/param norm = 5.1027e-02, time/batch = 0.2576s	
679/5250 (epoch 6.467), train_loss = 1.36361521, grad/param norm = 5.2758e-02, time/batch = 0.2578s	
680/5250 (epoch 6.476), train_loss = 1.37092702, grad/param norm = 5.8452e-02, time/batch = 0.2579s	
681/5250 (epoch 6.486), train_loss = 1.39117046, grad/param norm = 5.8196e-02, time/batch = 0.2591s	
682/5250 (epoch 6.495), train_loss = 1.39030942, grad/param norm = 5.4674e-02, time/batch = 0.2574s	
683/5250 (epoch 6.505), train_loss = 1.39846555, grad/param norm = 5.7968e-02, time/batch = 0.2582s	
684/5250 (epoch 6.514), train_loss = 1.40238555, grad/param norm = 6.3661e-02, time/batch = 0.2575s	
685/5250 (epoch 6.524), train_loss = 1.37173947, grad/param norm = 5.6711e-02, time/batch = 0.2575s	
686/5250 (epoch 6.533), train_loss = 1.37962530, grad/param norm = 5.4802e-02, time/batch = 0.2577s	
687/5250 (epoch 6.543), train_loss = 1.36119058, grad/param norm = 5.1241e-02, time/batch = 0.2577s	
688/5250 (epoch 6.552), train_loss = 1.36427565, grad/param norm = 4.5973e-02, time/batch = 0.2576s	
689/5250 (epoch 6.562), train_loss = 1.36842295, grad/param norm = 4.7340e-02, time/batch = 0.2578s	
690/5250 (epoch 6.571), train_loss = 1.37035542, grad/param norm = 4.9234e-02, time/batch = 0.2581s	
691/5250 (epoch 6.581), train_loss = 1.40585906, grad/param norm = 5.6524e-02, time/batch = 0.2588s	
692/5250 (epoch 6.590), train_loss = 1.39253762, grad/param norm = 5.6583e-02, time/batch = 0.2577s	
693/5250 (epoch 6.600), train_loss = 1.39993180, grad/param norm = 5.9383e-02, time/batch = 0.2578s	
694/5250 (epoch 6.610), train_loss = 1.39637927, grad/param norm = 6.2557e-02, time/batch = 0.2577s	
695/5250 (epoch 6.619), train_loss = 1.38431168, grad/param norm = 6.3654e-02, time/batch = 0.2578s	
696/5250 (epoch 6.629), train_loss = 1.39520558, grad/param norm = 6.1036e-02, time/batch = 0.2579s	
697/5250 (epoch 6.638), train_loss = 1.38177930, grad/param norm = 5.8954e-02, time/batch = 0.2581s	
698/5250 (epoch 6.648), train_loss = 1.38995617, grad/param norm = 5.1530e-02, time/batch = 0.2575s	
699/5250 (epoch 6.657), train_loss = 1.36543146, grad/param norm = 5.3002e-02, time/batch = 0.2579s	
700/5250 (epoch 6.667), train_loss = 1.38450456, grad/param norm = 5.4140e-02, time/batch = 0.2584s	
701/5250 (epoch 6.676), train_loss = 1.36269595, grad/param norm = 5.6770e-02, time/batch = 0.2590s	
702/5250 (epoch 6.686), train_loss = 1.39268582, grad/param norm = 5.6632e-02, time/batch = 0.2577s	
703/5250 (epoch 6.695), train_loss = 1.36762711, grad/param norm = 5.4449e-02, time/batch = 0.2581s	
704/5250 (epoch 6.705), train_loss = 1.35299046, grad/param norm = 5.6289e-02, time/batch = 0.2578s	
705/5250 (epoch 6.714), train_loss = 1.37904820, grad/param norm = 5.7671e-02, time/batch = 0.2580s	
706/5250 (epoch 6.724), train_loss = 1.36362007, grad/param norm = 6.4287e-02, time/batch = 0.2580s	
707/5250 (epoch 6.733), train_loss = 1.36268253, grad/param norm = 6.3472e-02, time/batch = 0.2604s	
708/5250 (epoch 6.743), train_loss = 1.34618914, grad/param norm = 5.3762e-02, time/batch = 0.2576s	
709/5250 (epoch 6.752), train_loss = 1.35571786, grad/param norm = 5.0743e-02, time/batch = 0.2581s	
710/5250 (epoch 6.762), train_loss = 1.34735736, grad/param norm = 5.6168e-02, time/batch = 0.2583s	
711/5250 (epoch 6.771), train_loss = 1.34994771, grad/param norm = 6.6233e-02, time/batch = 0.2588s	
712/5250 (epoch 6.781), train_loss = 1.37990318, grad/param norm = 5.7995e-02, time/batch = 0.2575s	
713/5250 (epoch 6.790), train_loss = 1.38388464, grad/param norm = 4.9843e-02, time/batch = 0.2580s	
714/5250 (epoch 6.800), train_loss = 1.35741390, grad/param norm = 4.5467e-02, time/batch = 0.2578s	
715/5250 (epoch 6.810), train_loss = 1.34390949, grad/param norm = 4.0911e-02, time/batch = 0.2578s	
716/5250 (epoch 6.819), train_loss = 1.35623940, grad/param norm = 4.4094e-02, time/batch = 0.2577s	
717/5250 (epoch 6.829), train_loss = 1.36145053, grad/param norm = 4.4539e-02, time/batch = 0.2576s	
718/5250 (epoch 6.838), train_loss = 1.32532189, grad/param norm = 4.3658e-02, time/batch = 0.2578s	
719/5250 (epoch 6.848), train_loss = 1.33149756, grad/param norm = 4.9285e-02, time/batch = 0.2580s	
720/5250 (epoch 6.857), train_loss = 1.35964997, grad/param norm = 5.3060e-02, time/batch = 0.2581s	
721/5250 (epoch 6.867), train_loss = 1.34666939, grad/param norm = 5.3481e-02, time/batch = 0.2588s	
722/5250 (epoch 6.876), train_loss = 1.36215101, grad/param norm = 5.6720e-02, time/batch = 0.2577s	
723/5250 (epoch 6.886), train_loss = 1.34182061, grad/param norm = 5.3701e-02, time/batch = 0.2580s	
724/5250 (epoch 6.895), train_loss = 1.37195782, grad/param norm = 5.6170e-02, time/batch = 0.2575s	
725/5250 (epoch 6.905), train_loss = 1.37617422, grad/param norm = 5.6811e-02, time/batch = 0.2578s	
726/5250 (epoch 6.914), train_loss = 1.38129596, grad/param norm = 5.9288e-02, time/batch = 0.2575s	
727/5250 (epoch 6.924), train_loss = 1.37921776, grad/param norm = 5.5379e-02, time/batch = 0.2574s	
728/5250 (epoch 6.933), train_loss = 1.34955958, grad/param norm = 5.2306e-02, time/batch = 0.2578s	
729/5250 (epoch 6.943), train_loss = 1.37841244, grad/param norm = 5.2496e-02, time/batch = 0.2582s	
730/5250 (epoch 6.952), train_loss = 1.37705070, grad/param norm = 5.0334e-02, time/batch = 0.2579s	
731/5250 (epoch 6.962), train_loss = 1.36112119, grad/param norm = 4.8646e-02, time/batch = 0.2588s	
732/5250 (epoch 6.971), train_loss = 1.35025703, grad/param norm = 5.2738e-02, time/batch = 0.2573s	
733/5250 (epoch 6.981), train_loss = 1.37891189, grad/param norm = 5.9052e-02, time/batch = 0.2577s	
734/5250 (epoch 6.990), train_loss = 1.37441048, grad/param norm = 5.4024e-02, time/batch = 0.2577s	
735/5250 (epoch 7.000), train_loss = 1.36313543, grad/param norm = 5.4770e-02, time/batch = 0.2576s	
736/5250 (epoch 7.010), train_loss = 1.52740084, grad/param norm = 5.9962e-02, time/batch = 0.2575s	
737/5250 (epoch 7.019), train_loss = 1.35357564, grad/param norm = 5.6098e-02, time/batch = 0.2577s	
738/5250 (epoch 7.029), train_loss = 1.35862970, grad/param norm = 4.6781e-02, time/batch = 0.2580s	
739/5250 (epoch 7.038), train_loss = 1.32611472, grad/param norm = 4.0987e-02, time/batch = 0.2608s	
740/5250 (epoch 7.048), train_loss = 1.30697743, grad/param norm = 4.1576e-02, time/batch = 0.2582s	
741/5250 (epoch 7.057), train_loss = 1.32070801, grad/param norm = 4.3483e-02, time/batch = 0.2590s	
742/5250 (epoch 7.067), train_loss = 1.33328285, grad/param norm = 4.8367e-02, time/batch = 0.2576s	
743/5250 (epoch 7.076), train_loss = 1.35176848, grad/param norm = 5.7321e-02, time/batch = 0.2578s	
744/5250 (epoch 7.086), train_loss = 1.29005998, grad/param norm = 5.0492e-02, time/batch = 0.2578s	
745/5250 (epoch 7.095), train_loss = 1.31302788, grad/param norm = 4.6068e-02, time/batch = 0.2575s	
746/5250 (epoch 7.105), train_loss = 1.33358623, grad/param norm = 4.4544e-02, time/batch = 0.2583s	
747/5250 (epoch 7.114), train_loss = 1.31041221, grad/param norm = 4.2530e-02, time/batch = 0.2574s	
748/5250 (epoch 7.124), train_loss = 1.32600316, grad/param norm = 4.4982e-02, time/batch = 0.2577s	
749/5250 (epoch 7.133), train_loss = 1.30814329, grad/param norm = 4.5682e-02, time/batch = 0.2579s	
750/5250 (epoch 7.143), train_loss = 1.29052219, grad/param norm = 4.4256e-02, time/batch = 0.2580s	
751/5250 (epoch 7.152), train_loss = 1.29335346, grad/param norm = 4.4751e-02, time/batch = 0.2590s	
752/5250 (epoch 7.162), train_loss = 1.32803292, grad/param norm = 4.9378e-02, time/batch = 0.2575s	
753/5250 (epoch 7.171), train_loss = 1.34202549, grad/param norm = 5.4580e-02, time/batch = 0.2581s	
754/5250 (epoch 7.181), train_loss = 1.35465341, grad/param norm = 5.7100e-02, time/batch = 0.2579s	
755/5250 (epoch 7.190), train_loss = 1.34671828, grad/param norm = 5.6244e-02, time/batch = 0.2574s	
756/5250 (epoch 7.200), train_loss = 1.33271355, grad/param norm = 5.1889e-02, time/batch = 0.2580s	
757/5250 (epoch 7.210), train_loss = 1.31778532, grad/param norm = 5.0031e-02, time/batch = 0.2578s	
758/5250 (epoch 7.219), train_loss = 1.36176744, grad/param norm = 5.6925e-02, time/batch = 0.2580s	
759/5250 (epoch 7.229), train_loss = 1.33796339, grad/param norm = 7.1913e-02, time/batch = 0.2581s	
760/5250 (epoch 7.238), train_loss = 1.35229636, grad/param norm = 7.6539e-02, time/batch = 0.2584s	
761/5250 (epoch 7.248), train_loss = 1.35438320, grad/param norm = 7.5648e-02, time/batch = 0.2587s	
762/5250 (epoch 7.257), train_loss = 1.32955645, grad/param norm = 6.0105e-02, time/batch = 0.2577s	
763/5250 (epoch 7.267), train_loss = 1.30165530, grad/param norm = 4.6247e-02, time/batch = 0.2580s	
764/5250 (epoch 7.276), train_loss = 1.30159958, grad/param norm = 4.3901e-02, time/batch = 0.2576s	
765/5250 (epoch 7.286), train_loss = 1.28777349, grad/param norm = 4.2746e-02, time/batch = 0.2578s	
766/5250 (epoch 7.295), train_loss = 1.31439200, grad/param norm = 4.6794e-02, time/batch = 0.2577s	
767/5250 (epoch 7.305), train_loss = 1.31049212, grad/param norm = 5.1106e-02, time/batch = 0.2576s	
768/5250 (epoch 7.314), train_loss = 1.28997530, grad/param norm = 4.6608e-02, time/batch = 0.2579s	
769/5250 (epoch 7.324), train_loss = 1.31299178, grad/param norm = 4.6007e-02, time/batch = 0.2578s	
770/5250 (epoch 7.333), train_loss = 1.30768127, grad/param norm = 4.7454e-02, time/batch = 0.2586s	
771/5250 (epoch 7.343), train_loss = 1.31605582, grad/param norm = 5.2527e-02, time/batch = 0.2586s	
772/5250 (epoch 7.352), train_loss = 1.33592612, grad/param norm = 6.1973e-02, time/batch = 0.2576s	
773/5250 (epoch 7.362), train_loss = 1.34319274, grad/param norm = 5.8198e-02, time/batch = 0.2579s	
774/5250 (epoch 7.371), train_loss = 1.31012513, grad/param norm = 5.2949e-02, time/batch = 0.2577s	
775/5250 (epoch 7.381), train_loss = 1.30687477, grad/param norm = 5.4584e-02, time/batch = 0.2579s	
776/5250 (epoch 7.390), train_loss = 1.31933137, grad/param norm = 5.1607e-02, time/batch = 0.2574s	
777/5250 (epoch 7.400), train_loss = 1.30846890, grad/param norm = 5.0099e-02, time/batch = 0.2582s	
778/5250 (epoch 7.410), train_loss = 1.32564707, grad/param norm = 5.2272e-02, time/batch = 0.2576s	
779/5250 (epoch 7.419), train_loss = 1.31454167, grad/param norm = 5.2286e-02, time/batch = 0.2579s	
780/5250 (epoch 7.429), train_loss = 1.32525877, grad/param norm = 5.1596e-02, time/batch = 0.2581s	
781/5250 (epoch 7.438), train_loss = 1.33866038, grad/param norm = 4.9726e-02, time/batch = 0.2592s	
782/5250 (epoch 7.448), train_loss = 1.29796663, grad/param norm = 4.6146e-02, time/batch = 0.2576s	
783/5250 (epoch 7.457), train_loss = 1.29403016, grad/param norm = 4.6624e-02, time/batch = 0.2578s	
784/5250 (epoch 7.467), train_loss = 1.30089789, grad/param norm = 4.5190e-02, time/batch = 0.2578s	
785/5250 (epoch 7.476), train_loss = 1.28911944, grad/param norm = 4.5211e-02, time/batch = 0.2576s	
786/5250 (epoch 7.486), train_loss = 1.31723004, grad/param norm = 5.2918e-02, time/batch = 0.2576s	
787/5250 (epoch 7.495), train_loss = 1.33007852, grad/param norm = 6.1809e-02, time/batch = 0.2572s	
788/5250 (epoch 7.505), train_loss = 1.34573726, grad/param norm = 7.0249e-02, time/batch = 0.2577s	
789/5250 (epoch 7.514), train_loss = 1.35394172, grad/param norm = 7.0609e-02, time/batch = 0.2585s	
790/5250 (epoch 7.524), train_loss = 1.32311855, grad/param norm = 5.8883e-02, time/batch = 0.2582s	
791/5250 (epoch 7.533), train_loss = 1.31487893, grad/param norm = 5.4563e-02, time/batch = 0.2590s	
792/5250 (epoch 7.543), train_loss = 1.30028113, grad/param norm = 5.2429e-02, time/batch = 0.2580s	
793/5250 (epoch 7.552), train_loss = 1.30524661, grad/param norm = 4.8069e-02, time/batch = 0.2577s	
794/5250 (epoch 7.562), train_loss = 1.31382201, grad/param norm = 5.2265e-02, time/batch = 0.2575s	
795/5250 (epoch 7.571), train_loss = 1.31293795, grad/param norm = 5.2491e-02, time/batch = 0.2580s	
796/5250 (epoch 7.581), train_loss = 1.33717869, grad/param norm = 5.2330e-02, time/batch = 0.2575s	
797/5250 (epoch 7.590), train_loss = 1.31608139, grad/param norm = 4.6999e-02, time/batch = 0.2579s	
798/5250 (epoch 7.600), train_loss = 1.33040357, grad/param norm = 4.6474e-02, time/batch = 0.2580s	
799/5250 (epoch 7.610), train_loss = 1.33753083, grad/param norm = 5.4064e-02, time/batch = 0.2582s	
800/5250 (epoch 7.619), train_loss = 1.33313933, grad/param norm = 5.5641e-02, time/batch = 0.2582s	
801/5250 (epoch 7.629), train_loss = 1.33044952, grad/param norm = 5.5820e-02, time/batch = 0.2595s	
802/5250 (epoch 7.638), train_loss = 1.32108536, grad/param norm = 5.8931e-02, time/batch = 0.2585s	
803/5250 (epoch 7.648), train_loss = 1.32754824, grad/param norm = 5.7393e-02, time/batch = 0.2602s	
804/5250 (epoch 7.657), train_loss = 1.30221807, grad/param norm = 5.0592e-02, time/batch = 0.2583s	
805/5250 (epoch 7.667), train_loss = 1.31194487, grad/param norm = 4.6786e-02, time/batch = 0.2583s	
806/5250 (epoch 7.676), train_loss = 1.29238527, grad/param norm = 4.3201e-02, time/batch = 0.2580s	
807/5250 (epoch 7.686), train_loss = 1.31682470, grad/param norm = 4.4143e-02, time/batch = 0.2582s	
808/5250 (epoch 7.695), train_loss = 1.31104724, grad/param norm = 4.8247e-02, time/batch = 0.2583s	
809/5250 (epoch 7.705), train_loss = 1.29860667, grad/param norm = 5.4029e-02, time/batch = 0.2585s	
810/5250 (epoch 7.714), train_loss = 1.32511374, grad/param norm = 5.7139e-02, time/batch = 0.2586s	
811/5250 (epoch 7.724), train_loss = 1.29862988, grad/param norm = 5.4816e-02, time/batch = 0.2594s	
812/5250 (epoch 7.733), train_loss = 1.29218071, grad/param norm = 4.7735e-02, time/batch = 0.2585s	
813/5250 (epoch 7.743), train_loss = 1.27940355, grad/param norm = 5.1169e-02, time/batch = 0.2584s	
814/5250 (epoch 7.752), train_loss = 1.28933864, grad/param norm = 5.4909e-02, time/batch = 0.2584s	
815/5250 (epoch 7.762), train_loss = 1.28702396, grad/param norm = 5.5098e-02, time/batch = 0.2584s	
816/5250 (epoch 7.771), train_loss = 1.28924517, grad/param norm = 6.0289e-02, time/batch = 0.2581s	
817/5250 (epoch 7.781), train_loss = 1.32224830, grad/param norm = 6.1207e-02, time/batch = 0.2580s	
818/5250 (epoch 7.790), train_loss = 1.32850762, grad/param norm = 5.6047e-02, time/batch = 0.2583s	
819/5250 (epoch 7.800), train_loss = 1.29744491, grad/param norm = 4.4701e-02, time/batch = 0.2584s	
820/5250 (epoch 7.810), train_loss = 1.28547326, grad/param norm = 4.5071e-02, time/batch = 0.2588s	
821/5250 (epoch 7.819), train_loss = 1.29872441, grad/param norm = 4.4836e-02, time/batch = 0.2601s	
822/5250 (epoch 7.829), train_loss = 1.30122638, grad/param norm = 4.3564e-02, time/batch = 0.2581s	
823/5250 (epoch 7.838), train_loss = 1.25874769, grad/param norm = 4.1445e-02, time/batch = 0.2584s	
824/5250 (epoch 7.848), train_loss = 1.26978669, grad/param norm = 4.6070e-02, time/batch = 0.2585s	
825/5250 (epoch 7.857), train_loss = 1.30737455, grad/param norm = 5.7854e-02, time/batch = 0.2580s	
826/5250 (epoch 7.867), train_loss = 1.30374594, grad/param norm = 6.3778e-02, time/batch = 0.2581s	
827/5250 (epoch 7.876), train_loss = 1.30760414, grad/param norm = 5.7043e-02, time/batch = 0.2581s	
828/5250 (epoch 7.886), train_loss = 1.28077295, grad/param norm = 4.6297e-02, time/batch = 0.2580s	
829/5250 (epoch 7.895), train_loss = 1.30473202, grad/param norm = 4.7107e-02, time/batch = 0.2587s	
830/5250 (epoch 7.905), train_loss = 1.31156221, grad/param norm = 5.0238e-02, time/batch = 0.2591s	
831/5250 (epoch 7.914), train_loss = 1.31821979, grad/param norm = 5.1868e-02, time/batch = 0.2593s	
832/5250 (epoch 7.924), train_loss = 1.31936507, grad/param norm = 5.6859e-02, time/batch = 0.2580s	
833/5250 (epoch 7.933), train_loss = 1.29772786, grad/param norm = 5.3163e-02, time/batch = 0.2586s	
834/5250 (epoch 7.943), train_loss = 1.32233194, grad/param norm = 5.2213e-02, time/batch = 0.2586s	
835/5250 (epoch 7.952), train_loss = 1.32342515, grad/param norm = 5.1630e-02, time/batch = 0.2598s	
836/5250 (epoch 7.962), train_loss = 1.30119474, grad/param norm = 4.7038e-02, time/batch = 0.2580s	
837/5250 (epoch 7.971), train_loss = 1.28871964, grad/param norm = 4.3537e-02, time/batch = 0.2584s	
838/5250 (epoch 7.981), train_loss = 1.30533982, grad/param norm = 4.4778e-02, time/batch = 0.2584s	
839/5250 (epoch 7.990), train_loss = 1.30463639, grad/param norm = 4.3816e-02, time/batch = 0.2588s	
840/5250 (epoch 8.000), train_loss = 1.29939127, grad/param norm = 5.2292e-02, time/batch = 0.2585s	
841/5250 (epoch 8.010), train_loss = 1.47392004, grad/param norm = 6.6889e-02, time/batch = 0.2603s	
842/5250 (epoch 8.019), train_loss = 1.29513594, grad/param norm = 6.5171e-02, time/batch = 0.2580s	
843/5250 (epoch 8.029), train_loss = 1.30412706, grad/param norm = 5.9303e-02, time/batch = 0.2583s	
844/5250 (epoch 8.038), train_loss = 1.28201199, grad/param norm = 5.4891e-02, time/batch = 0.2582s	
845/5250 (epoch 8.048), train_loss = 1.25707808, grad/param norm = 4.9686e-02, time/batch = 0.2581s	
846/5250 (epoch 8.057), train_loss = 1.26546411, grad/param norm = 4.5501e-02, time/batch = 0.2585s	
847/5250 (epoch 8.067), train_loss = 1.26830168, grad/param norm = 4.3641e-02, time/batch = 0.2584s	
848/5250 (epoch 8.076), train_loss = 1.28602285, grad/param norm = 4.3047e-02, time/batch = 0.2580s	
849/5250 (epoch 8.086), train_loss = 1.22707845, grad/param norm = 4.4164e-02, time/batch = 0.2589s	
850/5250 (epoch 8.095), train_loss = 1.26189333, grad/param norm = 4.8520e-02, time/batch = 0.2586s	
851/5250 (epoch 8.105), train_loss = 1.28677079, grad/param norm = 5.0324e-02, time/batch = 0.2592s	
852/5250 (epoch 8.114), train_loss = 1.26394952, grad/param norm = 4.6050e-02, time/batch = 0.2583s	
853/5250 (epoch 8.124), train_loss = 1.27449528, grad/param norm = 4.5602e-02, time/batch = 0.2584s	
854/5250 (epoch 8.133), train_loss = 1.26180291, grad/param norm = 4.8683e-02, time/batch = 0.2583s	
855/5250 (epoch 8.143), train_loss = 1.24687856, grad/param norm = 4.9252e-02, time/batch = 0.2582s	
856/5250 (epoch 8.152), train_loss = 1.24437205, grad/param norm = 4.6357e-02, time/batch = 0.2581s	
857/5250 (epoch 8.162), train_loss = 1.26885560, grad/param norm = 4.6414e-02, time/batch = 0.2579s	
858/5250 (epoch 8.171), train_loss = 1.27008183, grad/param norm = 4.3534e-02, time/batch = 0.2582s	
859/5250 (epoch 8.181), train_loss = 1.27271589, grad/param norm = 4.3463e-02, time/batch = 0.2588s	
860/5250 (epoch 8.190), train_loss = 1.27483757, grad/param norm = 4.0643e-02, time/batch = 0.2584s	
861/5250 (epoch 8.200), train_loss = 1.26395590, grad/param norm = 4.0353e-02, time/batch = 0.2593s	
862/5250 (epoch 8.210), train_loss = 1.25606556, grad/param norm = 4.1503e-02, time/batch = 0.2582s	
863/5250 (epoch 8.219), train_loss = 1.30107792, grad/param norm = 4.9456e-02, time/batch = 0.2582s	
864/5250 (epoch 8.229), train_loss = 1.27138479, grad/param norm = 4.7018e-02, time/batch = 0.2580s	
865/5250 (epoch 8.238), train_loss = 1.25952785, grad/param norm = 4.5761e-02, time/batch = 0.2584s	
866/5250 (epoch 8.248), train_loss = 1.27696634, grad/param norm = 5.2410e-02, time/batch = 0.2595s	
867/5250 (epoch 8.257), train_loss = 1.27193959, grad/param norm = 5.4382e-02, time/batch = 0.2588s	
868/5250 (epoch 8.267), train_loss = 1.26508147, grad/param norm = 6.1949e-02, time/batch = 0.2584s	
869/5250 (epoch 8.276), train_loss = 1.26185701, grad/param norm = 5.5819e-02, time/batch = 0.2585s	
870/5250 (epoch 8.286), train_loss = 1.24694588, grad/param norm = 4.8930e-02, time/batch = 0.2585s	
871/5250 (epoch 8.295), train_loss = 1.26655120, grad/param norm = 4.9373e-02, time/batch = 0.2595s	
872/5250 (epoch 8.305), train_loss = 1.25785062, grad/param norm = 4.8069e-02, time/batch = 0.2582s	
873/5250 (epoch 8.314), train_loss = 1.24296275, grad/param norm = 4.6234e-02, time/batch = 0.2587s	
874/5250 (epoch 8.324), train_loss = 1.26259852, grad/param norm = 4.7581e-02, time/batch = 0.2581s	
875/5250 (epoch 8.333), train_loss = 1.25630937, grad/param norm = 5.2460e-02, time/batch = 0.2581s	
876/5250 (epoch 8.343), train_loss = 1.26508353, grad/param norm = 5.9017e-02, time/batch = 0.2582s	
877/5250 (epoch 8.352), train_loss = 1.27428542, grad/param norm = 5.7346e-02, time/batch = 0.2578s	
878/5250 (epoch 8.362), train_loss = 1.27865611, grad/param norm = 5.2676e-02, time/batch = 0.2584s	
879/5250 (epoch 8.371), train_loss = 1.25322768, grad/param norm = 4.6579e-02, time/batch = 0.2584s	
880/5250 (epoch 8.381), train_loss = 1.24052418, grad/param norm = 4.5166e-02, time/batch = 0.2587s	
881/5250 (epoch 8.390), train_loss = 1.25102053, grad/param norm = 4.5335e-02, time/batch = 0.2597s	
882/5250 (epoch 8.400), train_loss = 1.24746532, grad/param norm = 4.0017e-02, time/batch = 0.2583s	
883/5250 (epoch 8.410), train_loss = 1.25693225, grad/param norm = 4.3929e-02, time/batch = 0.2582s	
884/5250 (epoch 8.419), train_loss = 1.26130363, grad/param norm = 4.8809e-02, time/batch = 0.2584s	
885/5250 (epoch 8.429), train_loss = 1.26887984, grad/param norm = 4.9876e-02, time/batch = 0.2580s	
886/5250 (epoch 8.438), train_loss = 1.28715819, grad/param norm = 5.3211e-02, time/batch = 0.2580s	
887/5250 (epoch 8.448), train_loss = 1.24842660, grad/param norm = 5.4454e-02, time/batch = 0.2581s	
888/5250 (epoch 8.457), train_loss = 1.24757711, grad/param norm = 5.4865e-02, time/batch = 0.2584s	
889/5250 (epoch 8.467), train_loss = 1.25018362, grad/param norm = 5.1770e-02, time/batch = 0.2585s	
890/5250 (epoch 8.476), train_loss = 1.24040476, grad/param norm = 4.9962e-02, time/batch = 0.2585s	
891/5250 (epoch 8.486), train_loss = 1.26524956, grad/param norm = 5.1845e-02, time/batch = 0.2597s	
892/5250 (epoch 8.495), train_loss = 1.27652098, grad/param norm = 5.1548e-02, time/batch = 0.2581s	
893/5250 (epoch 8.505), train_loss = 1.27941448, grad/param norm = 5.6675e-02, time/batch = 0.2585s	
894/5250 (epoch 8.514), train_loss = 1.27751051, grad/param norm = 5.4238e-02, time/batch = 0.2583s	
895/5250 (epoch 8.524), train_loss = 1.25276861, grad/param norm = 4.8974e-02, time/batch = 0.2582s	
896/5250 (epoch 8.533), train_loss = 1.25180562, grad/param norm = 4.3703e-02, time/batch = 0.2584s	
897/5250 (epoch 8.543), train_loss = 1.23442732, grad/param norm = 3.9220e-02, time/batch = 0.2581s	
898/5250 (epoch 8.552), train_loss = 1.23795429, grad/param norm = 3.7828e-02, time/batch = 0.2607s	
899/5250 (epoch 8.562), train_loss = 1.23992305, grad/param norm = 4.0593e-02, time/batch = 0.2589s	
900/5250 (epoch 8.571), train_loss = 1.24830357, grad/param norm = 4.3425e-02, time/batch = 0.2586s	
901/5250 (epoch 8.581), train_loss = 1.27524905, grad/param norm = 4.7543e-02, time/batch = 0.2594s	
902/5250 (epoch 8.590), train_loss = 1.26514075, grad/param norm = 5.0862e-02, time/batch = 0.2583s	
903/5250 (epoch 8.600), train_loss = 1.28174341, grad/param norm = 5.4059e-02, time/batch = 0.2582s	
904/5250 (epoch 8.610), train_loss = 1.28208499, grad/param norm = 5.7305e-02, time/batch = 0.2579s	
905/5250 (epoch 8.619), train_loss = 1.27345620, grad/param norm = 5.4752e-02, time/batch = 0.2581s	
906/5250 (epoch 8.629), train_loss = 1.26848228, grad/param norm = 5.2099e-02, time/batch = 0.2583s	
907/5250 (epoch 8.638), train_loss = 1.25822240, grad/param norm = 4.9170e-02, time/batch = 0.2581s	
908/5250 (epoch 8.648), train_loss = 1.26142989, grad/param norm = 4.4639e-02, time/batch = 0.2581s	
909/5250 (epoch 8.657), train_loss = 1.24679328, grad/param norm = 4.2832e-02, time/batch = 0.2583s	
910/5250 (epoch 8.667), train_loss = 1.25851648, grad/param norm = 4.2503e-02, time/batch = 0.2588s	
911/5250 (epoch 8.676), train_loss = 1.24504685, grad/param norm = 4.5221e-02, time/batch = 0.2594s	
912/5250 (epoch 8.686), train_loss = 1.26663132, grad/param norm = 4.6834e-02, time/batch = 0.2581s	
913/5250 (epoch 8.695), train_loss = 1.25471223, grad/param norm = 4.6673e-02, time/batch = 0.2582s	
914/5250 (epoch 8.705), train_loss = 1.23933335, grad/param norm = 4.3193e-02, time/batch = 0.2585s	
915/5250 (epoch 8.714), train_loss = 1.25871985, grad/param norm = 4.6751e-02, time/batch = 0.2580s	
916/5250 (epoch 8.724), train_loss = 1.23850480, grad/param norm = 4.8091e-02, time/batch = 0.2582s	
917/5250 (epoch 8.733), train_loss = 1.24506263, grad/param norm = 5.3415e-02, time/batch = 0.2584s	
918/5250 (epoch 8.743), train_loss = 1.24638774, grad/param norm = 5.2659e-02, time/batch = 0.2578s	
919/5250 (epoch 8.752), train_loss = 1.24594436, grad/param norm = 5.4452e-02, time/batch = 0.2584s	
920/5250 (epoch 8.762), train_loss = 1.24196081, grad/param norm = 5.0748e-02, time/batch = 0.2587s	
921/5250 (epoch 8.771), train_loss = 1.22767597, grad/param norm = 4.7900e-02, time/batch = 0.2597s	
922/5250 (epoch 8.781), train_loss = 1.24996542, grad/param norm = 4.4715e-02, time/batch = 0.2580s	
923/5250 (epoch 8.790), train_loss = 1.25324917, grad/param norm = 4.4683e-02, time/batch = 0.2584s	
924/5250 (epoch 8.800), train_loss = 1.23688016, grad/param norm = 4.4867e-02, time/batch = 0.2582s	
925/5250 (epoch 8.810), train_loss = 1.23998130, grad/param norm = 4.5471e-02, time/batch = 0.2583s	
926/5250 (epoch 8.819), train_loss = 1.24872648, grad/param norm = 5.1434e-02, time/batch = 0.2582s	
927/5250 (epoch 8.829), train_loss = 1.25815138, grad/param norm = 5.0403e-02, time/batch = 0.2583s	
928/5250 (epoch 8.838), train_loss = 1.20349291, grad/param norm = 4.1722e-02, time/batch = 0.2580s	
929/5250 (epoch 8.848), train_loss = 1.20985272, grad/param norm = 4.2702e-02, time/batch = 0.2584s	
930/5250 (epoch 8.857), train_loss = 1.23525226, grad/param norm = 4.2168e-02, time/batch = 0.2636s	
931/5250 (epoch 8.867), train_loss = 1.23416182, grad/param norm = 4.5455e-02, time/batch = 0.2595s	
932/5250 (epoch 8.876), train_loss = 1.24075001, grad/param norm = 5.0310e-02, time/batch = 0.2583s	
933/5250 (epoch 8.886), train_loss = 1.23723309, grad/param norm = 4.8429e-02, time/batch = 0.2581s	
934/5250 (epoch 8.895), train_loss = 1.25874002, grad/param norm = 4.9951e-02, time/batch = 0.2581s	
935/5250 (epoch 8.905), train_loss = 1.26019748, grad/param norm = 4.9930e-02, time/batch = 0.2582s	
936/5250 (epoch 8.914), train_loss = 1.26961906, grad/param norm = 5.3813e-02, time/batch = 0.2583s	
937/5250 (epoch 8.924), train_loss = 1.26153258, grad/param norm = 5.1769e-02, time/batch = 0.2579s	
938/5250 (epoch 8.933), train_loss = 1.23680096, grad/param norm = 4.8003e-02, time/batch = 0.2582s	
939/5250 (epoch 8.943), train_loss = 1.26435611, grad/param norm = 4.7701e-02, time/batch = 0.2589s	
940/5250 (epoch 8.952), train_loss = 1.27224273, grad/param norm = 5.4000e-02, time/batch = 0.2588s	
941/5250 (epoch 8.962), train_loss = 1.25403200, grad/param norm = 5.6582e-02, time/batch = 0.2594s	
942/5250 (epoch 8.971), train_loss = 1.25670016, grad/param norm = 5.8355e-02, time/batch = 0.2585s	
943/5250 (epoch 8.981), train_loss = 1.27194017, grad/param norm = 6.1520e-02, time/batch = 0.2583s	
944/5250 (epoch 8.990), train_loss = 1.27335240, grad/param norm = 5.8461e-02, time/batch = 0.2587s	
945/5250 (epoch 9.000), train_loss = 1.25358211, grad/param norm = 4.6863e-02, time/batch = 0.2582s	
946/5250 (epoch 9.010), train_loss = 1.40833727, grad/param norm = 4.7842e-02, time/batch = 0.2579s	
947/5250 (epoch 9.019), train_loss = 1.22213934, grad/param norm = 4.1097e-02, time/batch = 0.2581s	
948/5250 (epoch 9.029), train_loss = 1.23658528, grad/param norm = 4.0524e-02, time/batch = 0.2582s	
949/5250 (epoch 9.038), train_loss = 1.21640895, grad/param norm = 3.8125e-02, time/batch = 0.2583s	
950/5250 (epoch 9.048), train_loss = 1.19317407, grad/param norm = 3.9730e-02, time/batch = 0.2586s	
951/5250 (epoch 9.057), train_loss = 1.20043181, grad/param norm = 4.0003e-02, time/batch = 0.2594s	
952/5250 (epoch 9.067), train_loss = 1.21610844, grad/param norm = 4.3239e-02, time/batch = 0.2584s	
953/5250 (epoch 9.076), train_loss = 1.23474920, grad/param norm = 4.4796e-02, time/batch = 0.2584s	
954/5250 (epoch 9.086), train_loss = 1.17867628, grad/param norm = 4.6034e-02, time/batch = 0.2581s	
955/5250 (epoch 9.095), train_loss = 1.20495445, grad/param norm = 4.8071e-02, time/batch = 0.2582s	
956/5250 (epoch 9.105), train_loss = 1.22526045, grad/param norm = 4.4682e-02, time/batch = 0.2584s	
957/5250 (epoch 9.114), train_loss = 1.20342351, grad/param norm = 4.4304e-02, time/batch = 0.2586s	
958/5250 (epoch 9.124), train_loss = 1.23089006, grad/param norm = 4.6524e-02, time/batch = 0.2581s	
959/5250 (epoch 9.133), train_loss = 1.21080701, grad/param norm = 5.0667e-02, time/batch = 0.2585s	
960/5250 (epoch 9.143), train_loss = 1.19640454, grad/param norm = 4.8816e-02, time/batch = 0.2586s	
961/5250 (epoch 9.152), train_loss = 1.19725537, grad/param norm = 4.6420e-02, time/batch = 0.2598s	
962/5250 (epoch 9.162), train_loss = 1.22295866, grad/param norm = 4.9756e-02, time/batch = 0.2611s	
963/5250 (epoch 9.171), train_loss = 1.22158887, grad/param norm = 4.5336e-02, time/batch = 0.2582s	
964/5250 (epoch 9.181), train_loss = 1.22516850, grad/param norm = 4.6493e-02, time/batch = 0.2581s	
965/5250 (epoch 9.190), train_loss = 1.23226249, grad/param norm = 4.9294e-02, time/batch = 0.2582s	
966/5250 (epoch 9.200), train_loss = 1.21895483, grad/param norm = 4.9415e-02, time/batch = 0.2585s	
967/5250 (epoch 9.210), train_loss = 1.20782385, grad/param norm = 4.9312e-02, time/batch = 0.2583s	
968/5250 (epoch 9.219), train_loss = 1.24371531, grad/param norm = 5.1167e-02, time/batch = 0.2585s	
969/5250 (epoch 9.229), train_loss = 1.22110965, grad/param norm = 5.3784e-02, time/batch = 0.2586s	
970/5250 (epoch 9.238), train_loss = 1.21701932, grad/param norm = 5.2001e-02, time/batch = 0.2591s	
971/5250 (epoch 9.248), train_loss = 1.21679820, grad/param norm = 5.2392e-02, time/batch = 0.2595s	
972/5250 (epoch 9.257), train_loss = 1.21092630, grad/param norm = 4.4586e-02, time/batch = 0.2581s	
973/5250 (epoch 9.267), train_loss = 1.19712619, grad/param norm = 4.4831e-02, time/batch = 0.2582s	
974/5250 (epoch 9.276), train_loss = 1.19898397, grad/param norm = 4.9704e-02, time/batch = 0.2584s	
975/5250 (epoch 9.286), train_loss = 1.19622483, grad/param norm = 5.4276e-02, time/batch = 0.2581s	
976/5250 (epoch 9.295), train_loss = 1.22972518, grad/param norm = 5.9184e-02, time/batch = 0.2584s	
977/5250 (epoch 9.305), train_loss = 1.21831562, grad/param norm = 5.7599e-02, time/batch = 0.2583s	
978/5250 (epoch 9.314), train_loss = 1.20265450, grad/param norm = 4.9889e-02, time/batch = 0.2583s	
979/5250 (epoch 9.324), train_loss = 1.21205734, grad/param norm = 4.3015e-02, time/batch = 0.2583s	
980/5250 (epoch 9.333), train_loss = 1.19858129, grad/param norm = 4.1312e-02, time/batch = 0.2586s	
981/5250 (epoch 9.343), train_loss = 1.19664773, grad/param norm = 4.1459e-02, time/batch = 0.2593s	
982/5250 (epoch 9.352), train_loss = 1.20557515, grad/param norm = 4.3017e-02, time/batch = 0.2584s	
983/5250 (epoch 9.362), train_loss = 1.21725361, grad/param norm = 4.5356e-02, time/batch = 0.2583s	
984/5250 (epoch 9.371), train_loss = 1.20283094, grad/param norm = 4.5647e-02, time/batch = 0.2584s	
985/5250 (epoch 9.381), train_loss = 1.19507015, grad/param norm = 4.7675e-02, time/batch = 0.2585s	
986/5250 (epoch 9.390), train_loss = 1.19608154, grad/param norm = 4.6025e-02, time/batch = 0.2580s	
987/5250 (epoch 9.400), train_loss = 1.20062814, grad/param norm = 4.4478e-02, time/batch = 0.2580s	
988/5250 (epoch 9.410), train_loss = 1.21089151, grad/param norm = 4.5465e-02, time/batch = 0.2583s	
989/5250 (epoch 9.419), train_loss = 1.20317844, grad/param norm = 4.5289e-02, time/batch = 0.2585s	
990/5250 (epoch 9.429), train_loss = 1.21947172, grad/param norm = 4.7431e-02, time/batch = 0.2588s	
991/5250 (epoch 9.438), train_loss = 1.23815850, grad/param norm = 5.1500e-02, time/batch = 0.2593s	
992/5250 (epoch 9.448), train_loss = 1.19036067, grad/param norm = 4.7712e-02, time/batch = 0.2584s	
993/5250 (epoch 9.457), train_loss = 1.20060926, grad/param norm = 5.2573e-02, time/batch = 0.2586s	
994/5250 (epoch 9.467), train_loss = 1.21319421, grad/param norm = 5.6703e-02, time/batch = 0.2610s	
995/5250 (epoch 9.476), train_loss = 1.20514814, grad/param norm = 5.6093e-02, time/batch = 0.2578s	
996/5250 (epoch 9.486), train_loss = 1.22312465, grad/param norm = 5.4409e-02, time/batch = 0.2581s	
997/5250 (epoch 9.495), train_loss = 1.23100734, grad/param norm = 4.7375e-02, time/batch = 0.2583s	
998/5250 (epoch 9.505), train_loss = 1.21755965, grad/param norm = 4.4133e-02, time/batch = 0.2583s	
999/5250 (epoch 9.514), train_loss = 1.21659631, grad/param norm = 4.4019e-02, time/batch = 0.2582s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch9.52_1.5528.t7	
1000/5250 (epoch 9.524), train_loss = 1.20249577, grad/param norm = 4.6475e-02, time/batch = 0.2588s	
1001/5250 (epoch 9.533), train_loss = 1.56367884, grad/param norm = 6.4473e-02, time/batch = 0.2605s	
1002/5250 (epoch 9.543), train_loss = 1.22106906, grad/param norm = 5.6642e-02, time/batch = 0.2591s	
1003/5250 (epoch 9.552), train_loss = 1.20779820, grad/param norm = 5.0159e-02, time/batch = 0.2592s	
1004/5250 (epoch 9.562), train_loss = 1.20515526, grad/param norm = 4.7537e-02, time/batch = 0.2594s	
1005/5250 (epoch 9.571), train_loss = 1.20379732, grad/param norm = 4.6445e-02, time/batch = 0.2596s	
1006/5250 (epoch 9.581), train_loss = 1.22327900, grad/param norm = 4.6721e-02, time/batch = 0.2594s	
1007/5250 (epoch 9.590), train_loss = 1.20461075, grad/param norm = 4.4659e-02, time/batch = 0.2592s	
1008/5250 (epoch 9.600), train_loss = 1.21616004, grad/param norm = 4.2036e-02, time/batch = 0.2596s	
1009/5250 (epoch 9.610), train_loss = 1.21593307, grad/param norm = 4.2561e-02, time/batch = 0.2594s	
1010/5250 (epoch 9.619), train_loss = 1.21393211, grad/param norm = 4.5825e-02, time/batch = 0.2594s	
1011/5250 (epoch 9.629), train_loss = 1.21054899, grad/param norm = 4.5277e-02, time/batch = 0.2594s	
1012/5250 (epoch 9.638), train_loss = 1.20217882, grad/param norm = 4.5391e-02, time/batch = 0.2590s	
1013/5250 (epoch 9.648), train_loss = 1.20908459, grad/param norm = 4.2109e-02, time/batch = 0.2595s	
1014/5250 (epoch 9.657), train_loss = 1.19742398, grad/param norm = 4.3585e-02, time/batch = 0.2587s	
1015/5250 (epoch 9.667), train_loss = 1.20564341, grad/param norm = 4.4015e-02, time/batch = 0.2591s	
1016/5250 (epoch 9.676), train_loss = 1.19069562, grad/param norm = 4.4413e-02, time/batch = 0.2593s	
1017/5250 (epoch 9.686), train_loss = 1.20725937, grad/param norm = 4.6489e-02, time/batch = 0.2593s	
1018/5250 (epoch 9.695), train_loss = 1.20306470, grad/param norm = 5.0000e-02, time/batch = 0.2594s	
1019/5250 (epoch 9.705), train_loss = 1.20308985, grad/param norm = 5.2922e-02, time/batch = 0.2593s	
1020/5250 (epoch 9.714), train_loss = 1.21856020, grad/param norm = 5.1079e-02, time/batch = 0.2594s	
1021/5250 (epoch 9.724), train_loss = 1.19761708, grad/param norm = 5.3087e-02, time/batch = 0.2596s	
1022/5250 (epoch 9.733), train_loss = 1.18700159, grad/param norm = 4.6931e-02, time/batch = 0.2596s	
1023/5250 (epoch 9.743), train_loss = 1.17914346, grad/param norm = 4.1581e-02, time/batch = 0.2598s	
1024/5250 (epoch 9.752), train_loss = 1.18131923, grad/param norm = 4.0935e-02, time/batch = 0.2596s	
1025/5250 (epoch 9.762), train_loss = 1.17981907, grad/param norm = 4.2572e-02, time/batch = 0.2588s	
1026/5250 (epoch 9.771), train_loss = 1.17421655, grad/param norm = 4.3854e-02, time/batch = 0.2589s	
1027/5250 (epoch 9.781), train_loss = 1.19911375, grad/param norm = 4.5326e-02, time/batch = 0.2593s	
1028/5250 (epoch 9.790), train_loss = 1.20810618, grad/param norm = 4.7264e-02, time/batch = 0.2589s	
1029/5250 (epoch 9.800), train_loss = 1.19596517, grad/param norm = 5.0442e-02, time/batch = 0.2592s	
1030/5250 (epoch 9.810), train_loss = 1.20221335, grad/param norm = 4.9022e-02, time/batch = 0.2590s	
1031/5250 (epoch 9.819), train_loss = 1.20217033, grad/param norm = 5.1062e-02, time/batch = 0.2594s	
1032/5250 (epoch 9.829), train_loss = 1.21037062, grad/param norm = 5.1025e-02, time/batch = 0.2590s	
1033/5250 (epoch 9.838), train_loss = 1.17138390, grad/param norm = 4.8635e-02, time/batch = 0.2593s	
1034/5250 (epoch 9.848), train_loss = 1.17057262, grad/param norm = 4.9134e-02, time/batch = 0.2590s	
1035/5250 (epoch 9.857), train_loss = 1.19753851, grad/param norm = 4.9252e-02, time/batch = 0.2590s	
1036/5250 (epoch 9.867), train_loss = 1.18284213, grad/param norm = 4.6962e-02, time/batch = 0.2590s	
1037/5250 (epoch 9.876), train_loss = 1.18149745, grad/param norm = 4.7372e-02, time/batch = 0.2592s	
1038/5250 (epoch 9.886), train_loss = 1.18073027, grad/param norm = 4.2914e-02, time/batch = 0.2591s	
1039/5250 (epoch 9.895), train_loss = 1.20239709, grad/param norm = 4.6180e-02, time/batch = 0.2593s	
1040/5250 (epoch 9.905), train_loss = 1.20697362, grad/param norm = 4.8235e-02, time/batch = 0.2593s	
1041/5250 (epoch 9.914), train_loss = 1.21169611, grad/param norm = 4.6753e-02, time/batch = 0.2594s	
1042/5250 (epoch 9.924), train_loss = 1.20212343, grad/param norm = 4.5857e-02, time/batch = 0.2590s	
1043/5250 (epoch 9.933), train_loss = 1.19869124, grad/param norm = 5.2001e-02, time/batch = 0.2598s	
1044/5250 (epoch 9.943), train_loss = 1.23382623, grad/param norm = 5.5712e-02, time/batch = 0.2594s	
1045/5250 (epoch 9.952), train_loss = 1.23218716, grad/param norm = 5.1908e-02, time/batch = 0.2594s	
1046/5250 (epoch 9.962), train_loss = 1.20234395, grad/param norm = 4.7375e-02, time/batch = 0.2596s	
1047/5250 (epoch 9.971), train_loss = 1.19678922, grad/param norm = 4.4020e-02, time/batch = 0.2591s	
1048/5250 (epoch 9.981), train_loss = 1.20173434, grad/param norm = 4.5206e-02, time/batch = 0.2593s	
1049/5250 (epoch 9.990), train_loss = 1.21304232, grad/param norm = 5.1571e-02, time/batch = 0.2591s	
decayed learning rate by a factor 0.97 to 0.00194	
1050/5250 (epoch 10.000), train_loss = 1.22284375, grad/param norm = 5.9482e-02, time/batch = 0.2593s	
1051/5250 (epoch 10.010), train_loss = 1.38256395, grad/param norm = 5.8336e-02, time/batch = 0.2594s	
1052/5250 (epoch 10.019), train_loss = 1.18121173, grad/param norm = 4.4488e-02, time/batch = 0.2591s	
1053/5250 (epoch 10.029), train_loss = 1.18837039, grad/param norm = 4.0268e-02, time/batch = 0.2595s	
1054/5250 (epoch 10.038), train_loss = 1.17407609, grad/param norm = 4.4026e-02, time/batch = 0.2588s	
1055/5250 (epoch 10.048), train_loss = 1.15208413, grad/param norm = 4.0835e-02, time/batch = 0.2596s	
1056/5250 (epoch 10.057), train_loss = 1.14452905, grad/param norm = 3.8899e-02, time/batch = 0.2589s	
1057/5250 (epoch 10.067), train_loss = 1.16072429, grad/param norm = 4.0076e-02, time/batch = 0.2596s	
1058/5250 (epoch 10.076), train_loss = 1.17877241, grad/param norm = 4.0783e-02, time/batch = 0.2592s	
1059/5250 (epoch 10.086), train_loss = 1.12668987, grad/param norm = 4.0439e-02, time/batch = 0.2592s	
1060/5250 (epoch 10.095), train_loss = 1.14787935, grad/param norm = 4.3887e-02, time/batch = 0.2593s	
1061/5250 (epoch 10.105), train_loss = 1.17512560, grad/param norm = 4.4367e-02, time/batch = 0.2596s	
1062/5250 (epoch 10.114), train_loss = 1.15248790, grad/param norm = 4.4286e-02, time/batch = 0.2594s	
1063/5250 (epoch 10.124), train_loss = 1.17460016, grad/param norm = 4.6065e-02, time/batch = 0.2598s	
1064/5250 (epoch 10.133), train_loss = 1.15475253, grad/param norm = 4.7544e-02, time/batch = 0.2594s	
1065/5250 (epoch 10.143), train_loss = 1.14529682, grad/param norm = 4.9198e-02, time/batch = 0.2601s	
1066/5250 (epoch 10.152), train_loss = 1.15513491, grad/param norm = 5.0818e-02, time/batch = 0.2594s	
1067/5250 (epoch 10.162), train_loss = 1.18024412, grad/param norm = 5.1780e-02, time/batch = 0.2589s	
1068/5250 (epoch 10.171), train_loss = 1.16655540, grad/param norm = 4.8628e-02, time/batch = 0.2593s	
1069/5250 (epoch 10.181), train_loss = 1.17870147, grad/param norm = 4.8979e-02, time/batch = 0.2596s	
1070/5250 (epoch 10.190), train_loss = 1.19420440, grad/param norm = 5.5978e-02, time/batch = 0.2588s	
1071/5250 (epoch 10.200), train_loss = 1.18374461, grad/param norm = 4.9965e-02, time/batch = 0.2595s	
1072/5250 (epoch 10.210), train_loss = 1.15811092, grad/param norm = 4.6662e-02, time/batch = 0.2591s	
1073/5250 (epoch 10.219), train_loss = 1.18937092, grad/param norm = 4.6124e-02, time/batch = 0.2589s	
1074/5250 (epoch 10.229), train_loss = 1.16193344, grad/param norm = 4.2597e-02, time/batch = 0.2593s	
1075/5250 (epoch 10.238), train_loss = 1.15313009, grad/param norm = 4.2883e-02, time/batch = 0.2594s	
1076/5250 (epoch 10.248), train_loss = 1.15509257, grad/param norm = 4.5108e-02, time/batch = 0.2595s	
1077/5250 (epoch 10.257), train_loss = 1.16895344, grad/param norm = 4.8031e-02, time/batch = 0.2592s	
1078/5250 (epoch 10.267), train_loss = 1.15440372, grad/param norm = 4.3557e-02, time/batch = 0.2595s	
1079/5250 (epoch 10.276), train_loss = 1.14352276, grad/param norm = 4.4109e-02, time/batch = 0.2592s	
1080/5250 (epoch 10.286), train_loss = 1.13698613, grad/param norm = 4.4573e-02, time/batch = 0.2594s	
1081/5250 (epoch 10.295), train_loss = 1.16081186, grad/param norm = 4.5766e-02, time/batch = 0.2592s	
1082/5250 (epoch 10.305), train_loss = 1.15290371, grad/param norm = 4.3237e-02, time/batch = 0.2592s	
1083/5250 (epoch 10.314), train_loss = 1.14288247, grad/param norm = 4.3999e-02, time/batch = 0.2594s	
1084/5250 (epoch 10.324), train_loss = 1.15959704, grad/param norm = 4.5147e-02, time/batch = 0.2591s	
1085/5250 (epoch 10.333), train_loss = 1.15361132, grad/param norm = 4.5530e-02, time/batch = 0.2597s	
1086/5250 (epoch 10.343), train_loss = 1.15178244, grad/param norm = 4.4485e-02, time/batch = 0.2592s	
1087/5250 (epoch 10.352), train_loss = 1.15975682, grad/param norm = 4.9556e-02, time/batch = 0.2589s	
1088/5250 (epoch 10.362), train_loss = 1.17389616, grad/param norm = 5.3389e-02, time/batch = 0.2598s	
1089/5250 (epoch 10.371), train_loss = 1.15675148, grad/param norm = 4.5761e-02, time/batch = 0.2592s	
1090/5250 (epoch 10.381), train_loss = 1.14426574, grad/param norm = 4.6556e-02, time/batch = 0.2588s	
1091/5250 (epoch 10.390), train_loss = 1.14436433, grad/param norm = 4.9965e-02, time/batch = 0.2596s	
1092/5250 (epoch 10.400), train_loss = 1.16007021, grad/param norm = 5.8466e-02, time/batch = 0.2590s	
1093/5250 (epoch 10.410), train_loss = 1.18216326, grad/param norm = 6.1447e-02, time/batch = 0.2594s	
1094/5250 (epoch 10.419), train_loss = 1.17053966, grad/param norm = 5.4846e-02, time/batch = 0.2598s	
1095/5250 (epoch 10.429), train_loss = 1.17910103, grad/param norm = 5.3963e-02, time/batch = 0.2594s	
1096/5250 (epoch 10.438), train_loss = 1.17888601, grad/param norm = 4.5848e-02, time/batch = 0.2593s	
1097/5250 (epoch 10.448), train_loss = 1.13194156, grad/param norm = 4.2695e-02, time/batch = 0.2588s	
1098/5250 (epoch 10.457), train_loss = 1.13866061, grad/param norm = 4.4334e-02, time/batch = 0.2591s	
1099/5250 (epoch 10.467), train_loss = 1.15119604, grad/param norm = 4.6035e-02, time/batch = 0.2593s	
1100/5250 (epoch 10.476), train_loss = 1.13788278, grad/param norm = 4.4345e-02, time/batch = 0.2592s	
1101/5250 (epoch 10.486), train_loss = 1.15574067, grad/param norm = 4.4011e-02, time/batch = 0.2596s	
1102/5250 (epoch 10.495), train_loss = 1.17675146, grad/param norm = 4.8656e-02, time/batch = 0.2592s	
1103/5250 (epoch 10.505), train_loss = 1.17808251, grad/param norm = 5.1785e-02, time/batch = 0.2590s	
1104/5250 (epoch 10.514), train_loss = 1.17759984, grad/param norm = 5.1349e-02, time/batch = 0.2590s	
1105/5250 (epoch 10.524), train_loss = 1.16540467, grad/param norm = 5.2185e-02, time/batch = 0.2596s	
1106/5250 (epoch 10.533), train_loss = 1.18616280, grad/param norm = 5.4840e-02, time/batch = 0.2591s	
1107/5250 (epoch 10.543), train_loss = 1.15508583, grad/param norm = 5.0228e-02, time/batch = 0.2589s	
1108/5250 (epoch 10.552), train_loss = 1.15181181, grad/param norm = 4.5926e-02, time/batch = 0.2588s	
1109/5250 (epoch 10.562), train_loss = 1.15083019, grad/param norm = 4.6487e-02, time/batch = 0.2592s	
1110/5250 (epoch 10.571), train_loss = 1.15653007, grad/param norm = 4.6090e-02, time/batch = 0.2589s	
1111/5250 (epoch 10.581), train_loss = 1.16986431, grad/param norm = 4.6378e-02, time/batch = 0.2594s	
1112/5250 (epoch 10.590), train_loss = 1.15785253, grad/param norm = 4.7148e-02, time/batch = 0.2593s	
1113/5250 (epoch 10.600), train_loss = 1.16734356, grad/param norm = 4.7404e-02, time/batch = 0.2595s	
1114/5250 (epoch 10.610), train_loss = 1.16757723, grad/param norm = 4.4588e-02, time/batch = 0.2592s	
1115/5250 (epoch 10.619), train_loss = 1.16031520, grad/param norm = 4.4503e-02, time/batch = 0.2595s	
1116/5250 (epoch 10.629), train_loss = 1.15769599, grad/param norm = 4.5802e-02, time/batch = 0.2592s	
1117/5250 (epoch 10.638), train_loss = 1.14976131, grad/param norm = 4.8519e-02, time/batch = 0.2598s	
1118/5250 (epoch 10.648), train_loss = 1.16938686, grad/param norm = 5.2519e-02, time/batch = 0.2591s	
1119/5250 (epoch 10.657), train_loss = 1.15975595, grad/param norm = 5.1400e-02, time/batch = 0.2593s	
1120/5250 (epoch 10.667), train_loss = 1.15955281, grad/param norm = 4.7830e-02, time/batch = 0.2592s	
1121/5250 (epoch 10.676), train_loss = 1.14361639, grad/param norm = 4.3425e-02, time/batch = 0.2590s	
1122/5250 (epoch 10.686), train_loss = 1.15085619, grad/param norm = 4.6310e-02, time/batch = 0.2590s	
1123/5250 (epoch 10.695), train_loss = 1.15101715, grad/param norm = 4.8919e-02, time/batch = 0.2594s	
1124/5250 (epoch 10.705), train_loss = 1.14932065, grad/param norm = 5.2401e-02, time/batch = 0.2593s	
1125/5250 (epoch 10.714), train_loss = 1.16775042, grad/param norm = 4.9039e-02, time/batch = 0.2593s	
1126/5250 (epoch 10.724), train_loss = 1.13927470, grad/param norm = 4.7172e-02, time/batch = 0.2594s	
1127/5250 (epoch 10.733), train_loss = 1.13656940, grad/param norm = 5.0414e-02, time/batch = 0.2593s	
1128/5250 (epoch 10.743), train_loss = 1.14624838, grad/param norm = 5.6415e-02, time/batch = 0.2592s	
1129/5250 (epoch 10.752), train_loss = 1.14942658, grad/param norm = 5.4514e-02, time/batch = 0.2593s	
1130/5250 (epoch 10.762), train_loss = 1.14022188, grad/param norm = 5.0259e-02, time/batch = 0.2591s	
1131/5250 (epoch 10.771), train_loss = 1.12791947, grad/param norm = 5.0258e-02, time/batch = 0.2593s	
1132/5250 (epoch 10.781), train_loss = 1.14723771, grad/param norm = 4.4866e-02, time/batch = 0.2589s	
1133/5250 (epoch 10.790), train_loss = 1.15253631, grad/param norm = 4.5630e-02, time/batch = 0.2591s	
1134/5250 (epoch 10.800), train_loss = 1.13974786, grad/param norm = 4.6437e-02, time/batch = 0.2595s	
1135/5250 (epoch 10.810), train_loss = 1.14321258, grad/param norm = 4.3423e-02, time/batch = 0.2592s	
1136/5250 (epoch 10.819), train_loss = 1.15061241, grad/param norm = 4.6071e-02, time/batch = 0.2593s	
1137/5250 (epoch 10.829), train_loss = 1.15113263, grad/param norm = 4.6524e-02, time/batch = 0.2594s	
1138/5250 (epoch 10.838), train_loss = 1.11234234, grad/param norm = 4.4185e-02, time/batch = 0.2594s	
1139/5250 (epoch 10.848), train_loss = 1.11608131, grad/param norm = 4.6256e-02, time/batch = 0.2590s	
1140/5250 (epoch 10.857), train_loss = 1.14648684, grad/param norm = 4.9850e-02, time/batch = 0.2591s	
1141/5250 (epoch 10.867), train_loss = 1.14124325, grad/param norm = 4.7424e-02, time/batch = 0.2592s	
1142/5250 (epoch 10.876), train_loss = 1.12748347, grad/param norm = 5.0265e-02, time/batch = 0.2591s	
1143/5250 (epoch 10.886), train_loss = 1.14517600, grad/param norm = 4.8939e-02, time/batch = 0.2590s	
1144/5250 (epoch 10.895), train_loss = 1.15872086, grad/param norm = 5.1061e-02, time/batch = 0.2593s	
1145/5250 (epoch 10.905), train_loss = 1.15345659, grad/param norm = 4.6106e-02, time/batch = 0.2594s	
1146/5250 (epoch 10.914), train_loss = 1.16023602, grad/param norm = 4.6447e-02, time/batch = 0.2592s	
1147/5250 (epoch 10.924), train_loss = 1.15421690, grad/param norm = 5.0902e-02, time/batch = 0.2591s	
1148/5250 (epoch 10.933), train_loss = 1.14785020, grad/param norm = 5.0359e-02, time/batch = 0.2596s	
1149/5250 (epoch 10.943), train_loss = 1.17041922, grad/param norm = 4.8840e-02, time/batch = 0.2593s	
1150/5250 (epoch 10.952), train_loss = 1.16590685, grad/param norm = 4.5040e-02, time/batch = 0.2587s	
1151/5250 (epoch 10.962), train_loss = 1.14771920, grad/param norm = 4.7611e-02, time/batch = 0.2593s	
1152/5250 (epoch 10.971), train_loss = 1.16393443, grad/param norm = 5.1669e-02, time/batch = 0.2589s	
1153/5250 (epoch 10.981), train_loss = 1.16762886, grad/param norm = 5.2477e-02, time/batch = 0.2593s	
1154/5250 (epoch 10.990), train_loss = 1.16043805, grad/param norm = 4.9902e-02, time/batch = 0.2589s	
decayed learning rate by a factor 0.97 to 0.0018818	
1155/5250 (epoch 11.000), train_loss = 1.15666501, grad/param norm = 4.7502e-02, time/batch = 0.2595s	
1156/5250 (epoch 11.010), train_loss = 1.32063787, grad/param norm = 5.1130e-02, time/batch = 0.2594s	
1157/5250 (epoch 11.019), train_loss = 1.13635885, grad/param norm = 5.3898e-02, time/batch = 0.2587s	
1158/5250 (epoch 11.029), train_loss = 1.15536992, grad/param norm = 5.5304e-02, time/batch = 0.2590s	
1159/5250 (epoch 11.038), train_loss = 1.13420239, grad/param norm = 5.0821e-02, time/batch = 0.2593s	
1160/5250 (epoch 11.048), train_loss = 1.11119393, grad/param norm = 4.8557e-02, time/batch = 0.2589s	
1161/5250 (epoch 11.057), train_loss = 1.10832166, grad/param norm = 4.6240e-02, time/batch = 0.2594s	
1162/5250 (epoch 11.067), train_loss = 1.11815336, grad/param norm = 4.7400e-02, time/batch = 0.2595s	
1163/5250 (epoch 11.076), train_loss = 1.13642897, grad/param norm = 4.4059e-02, time/batch = 0.2592s	
1164/5250 (epoch 11.086), train_loss = 1.08368031, grad/param norm = 4.3523e-02, time/batch = 0.2595s	
1165/5250 (epoch 11.095), train_loss = 1.09432991, grad/param norm = 4.2451e-02, time/batch = 0.2583s	
1166/5250 (epoch 11.105), train_loss = 1.11889318, grad/param norm = 4.3595e-02, time/batch = 0.2594s	
1167/5250 (epoch 11.114), train_loss = 1.09853760, grad/param norm = 4.2421e-02, time/batch = 0.2592s	
1168/5250 (epoch 11.124), train_loss = 1.12934402, grad/param norm = 4.8224e-02, time/batch = 0.2595s	
1169/5250 (epoch 11.133), train_loss = 1.10409333, grad/param norm = 4.5548e-02, time/batch = 0.2585s	
1170/5250 (epoch 11.143), train_loss = 1.09112405, grad/param norm = 4.5523e-02, time/batch = 0.2598s	
1171/5250 (epoch 11.152), train_loss = 1.09495682, grad/param norm = 4.6499e-02, time/batch = 0.2595s	
1172/5250 (epoch 11.162), train_loss = 1.12076852, grad/param norm = 4.5731e-02, time/batch = 0.2587s	
1173/5250 (epoch 11.171), train_loss = 1.11056617, grad/param norm = 4.5466e-02, time/batch = 0.2593s	
1174/5250 (epoch 11.181), train_loss = 1.12390087, grad/param norm = 4.7380e-02, time/batch = 0.2597s	
1175/5250 (epoch 11.190), train_loss = 1.13140489, grad/param norm = 4.7556e-02, time/batch = 0.2593s	
1176/5250 (epoch 11.200), train_loss = 1.12799879, grad/param norm = 4.8509e-02, time/batch = 0.2593s	
1177/5250 (epoch 11.210), train_loss = 1.11508445, grad/param norm = 4.6542e-02, time/batch = 0.2595s	
1178/5250 (epoch 11.219), train_loss = 1.14299146, grad/param norm = 5.1091e-02, time/batch = 0.2593s	
1179/5250 (epoch 11.229), train_loss = 1.12457636, grad/param norm = 4.9185e-02, time/batch = 0.2593s	
1180/5250 (epoch 11.238), train_loss = 1.11236924, grad/param norm = 4.8761e-02, time/batch = 0.2594s	
1181/5250 (epoch 11.248), train_loss = 1.11444396, grad/param norm = 4.8880e-02, time/batch = 0.2596s	
1182/5250 (epoch 11.257), train_loss = 1.11488546, grad/param norm = 4.6721e-02, time/batch = 0.2593s	
1183/5250 (epoch 11.267), train_loss = 1.10824472, grad/param norm = 4.7802e-02, time/batch = 0.2599s	
1184/5250 (epoch 11.276), train_loss = 1.09977515, grad/param norm = 4.6530e-02, time/batch = 0.2594s	
1185/5250 (epoch 11.286), train_loss = 1.08717986, grad/param norm = 4.4580e-02, time/batch = 0.2594s	
1186/5250 (epoch 11.295), train_loss = 1.11099590, grad/param norm = 4.7191e-02, time/batch = 0.2593s	
1187/5250 (epoch 11.305), train_loss = 1.10582422, grad/param norm = 4.6660e-02, time/batch = 0.2591s	
1188/5250 (epoch 11.314), train_loss = 1.09453444, grad/param norm = 4.7015e-02, time/batch = 0.2595s	
1189/5250 (epoch 11.324), train_loss = 1.11111845, grad/param norm = 4.6391e-02, time/batch = 0.2595s	
1190/5250 (epoch 11.333), train_loss = 1.10789393, grad/param norm = 4.7119e-02, time/batch = 0.2596s	
1191/5250 (epoch 11.343), train_loss = 1.10623664, grad/param norm = 4.6633e-02, time/batch = 0.2589s	
1192/5250 (epoch 11.352), train_loss = 1.10629833, grad/param norm = 4.6333e-02, time/batch = 0.2589s	
1193/5250 (epoch 11.362), train_loss = 1.11139681, grad/param norm = 4.6744e-02, time/batch = 0.2594s	
1194/5250 (epoch 11.371), train_loss = 1.11637190, grad/param norm = 5.0706e-02, time/batch = 0.2595s	
1195/5250 (epoch 11.381), train_loss = 1.10796590, grad/param norm = 5.0151e-02, time/batch = 0.2595s	
1196/5250 (epoch 11.390), train_loss = 1.09867657, grad/param norm = 5.1612e-02, time/batch = 0.2592s	
1197/5250 (epoch 11.400), train_loss = 1.11028158, grad/param norm = 5.9185e-02, time/batch = 0.2594s	
1198/5250 (epoch 11.410), train_loss = 1.13437189, grad/param norm = 6.5151e-02, time/batch = 0.2595s	
1199/5250 (epoch 11.419), train_loss = 1.13727068, grad/param norm = 6.2759e-02, time/batch = 0.2597s	
1200/5250 (epoch 11.429), train_loss = 1.12759564, grad/param norm = 5.1570e-02, time/batch = 0.2592s	
1201/5250 (epoch 11.438), train_loss = 1.13366639, grad/param norm = 4.7782e-02, time/batch = 0.2597s	
1202/5250 (epoch 11.448), train_loss = 1.08762171, grad/param norm = 4.5103e-02, time/batch = 0.2593s	
1203/5250 (epoch 11.457), train_loss = 1.09101350, grad/param norm = 4.5686e-02, time/batch = 0.2590s	
1204/5250 (epoch 11.467), train_loss = 1.10058311, grad/param norm = 4.4287e-02, time/batch = 0.2590s	
1205/5250 (epoch 11.476), train_loss = 1.08189388, grad/param norm = 4.6457e-02, time/batch = 0.2594s	
1206/5250 (epoch 11.486), train_loss = 1.10785991, grad/param norm = 4.8689e-02, time/batch = 0.2589s	
1207/5250 (epoch 11.495), train_loss = 1.12787024, grad/param norm = 4.9350e-02, time/batch = 0.2595s	
1208/5250 (epoch 11.505), train_loss = 1.11825503, grad/param norm = 4.5703e-02, time/batch = 0.2587s	
1209/5250 (epoch 11.514), train_loss = 1.12140658, grad/param norm = 4.9379e-02, time/batch = 0.2593s	
1210/5250 (epoch 11.524), train_loss = 1.12006465, grad/param norm = 5.3488e-02, time/batch = 0.2594s	
1211/5250 (epoch 11.533), train_loss = 1.12851541, grad/param norm = 5.0757e-02, time/batch = 0.2591s	
1212/5250 (epoch 11.543), train_loss = 1.10353766, grad/param norm = 4.7212e-02, time/batch = 0.2595s	
1213/5250 (epoch 11.552), train_loss = 1.09789230, grad/param norm = 4.6067e-02, time/batch = 0.2595s	
1214/5250 (epoch 11.562), train_loss = 1.10012057, grad/param norm = 4.5389e-02, time/batch = 0.2594s	
1215/5250 (epoch 11.571), train_loss = 1.10432396, grad/param norm = 4.4584e-02, time/batch = 0.2591s	
1216/5250 (epoch 11.581), train_loss = 1.11877558, grad/param norm = 4.6379e-02, time/batch = 0.2597s	
1217/5250 (epoch 11.590), train_loss = 1.11695894, grad/param norm = 5.5790e-02, time/batch = 0.2595s	
1218/5250 (epoch 11.600), train_loss = 1.13452914, grad/param norm = 5.3337e-02, time/batch = 0.2593s	
1219/5250 (epoch 11.610), train_loss = 1.12886984, grad/param norm = 4.8109e-02, time/batch = 0.2595s	
1220/5250 (epoch 11.619), train_loss = 1.11154323, grad/param norm = 4.3750e-02, time/batch = 0.2594s	
1221/5250 (epoch 11.629), train_loss = 1.10544861, grad/param norm = 4.5571e-02, time/batch = 0.2593s	
1222/5250 (epoch 11.638), train_loss = 1.10436801, grad/param norm = 4.7875e-02, time/batch = 0.2592s	
1223/5250 (epoch 11.648), train_loss = 1.12116570, grad/param norm = 5.0962e-02, time/batch = 0.2594s	
1224/5250 (epoch 11.657), train_loss = 1.11036793, grad/param norm = 5.0479e-02, time/batch = 0.2591s	
1225/5250 (epoch 11.667), train_loss = 1.11682686, grad/param norm = 5.4583e-02, time/batch = 0.2590s	
1226/5250 (epoch 11.676), train_loss = 1.10916728, grad/param norm = 5.6454e-02, time/batch = 0.2593s	
1227/5250 (epoch 11.686), train_loss = 1.11707844, grad/param norm = 5.4448e-02, time/batch = 0.2593s	
1228/5250 (epoch 11.695), train_loss = 1.11172084, grad/param norm = 5.4602e-02, time/batch = 0.2592s	
1229/5250 (epoch 11.705), train_loss = 1.10457286, grad/param norm = 5.3315e-02, time/batch = 0.2592s	
1230/5250 (epoch 11.714), train_loss = 1.12867714, grad/param norm = 5.2953e-02, time/batch = 0.2589s	
1231/5250 (epoch 11.724), train_loss = 1.09240346, grad/param norm = 4.9434e-02, time/batch = 0.2593s	
1232/5250 (epoch 11.733), train_loss = 1.07577759, grad/param norm = 4.5451e-02, time/batch = 0.2589s	
1233/5250 (epoch 11.743), train_loss = 1.07730112, grad/param norm = 4.5656e-02, time/batch = 0.2602s	
1234/5250 (epoch 11.752), train_loss = 1.08631000, grad/param norm = 4.6079e-02, time/batch = 0.2605s	
1235/5250 (epoch 11.762), train_loss = 1.08623160, grad/param norm = 4.6442e-02, time/batch = 0.2593s	
1236/5250 (epoch 11.771), train_loss = 1.08050539, grad/param norm = 5.2221e-02, time/batch = 0.2592s	
1237/5250 (epoch 11.781), train_loss = 1.10335683, grad/param norm = 4.6143e-02, time/batch = 0.2596s	
1238/5250 (epoch 11.790), train_loss = 1.10552143, grad/param norm = 4.6296e-02, time/batch = 0.2595s	
1239/5250 (epoch 11.800), train_loss = 1.08512305, grad/param norm = 4.8648e-02, time/batch = 0.2596s	
1240/5250 (epoch 11.810), train_loss = 1.09660087, grad/param norm = 4.5256e-02, time/batch = 0.2593s	
1241/5250 (epoch 11.819), train_loss = 1.09265651, grad/param norm = 4.7134e-02, time/batch = 0.2595s	
1242/5250 (epoch 11.829), train_loss = 1.09820563, grad/param norm = 4.9181e-02, time/batch = 0.2591s	
1243/5250 (epoch 11.838), train_loss = 1.07182598, grad/param norm = 5.1417e-02, time/batch = 0.2594s	
1244/5250 (epoch 11.848), train_loss = 1.07203542, grad/param norm = 4.7954e-02, time/batch = 0.2592s	
1245/5250 (epoch 11.857), train_loss = 1.09253308, grad/param norm = 4.6726e-02, time/batch = 0.2591s	
1246/5250 (epoch 11.867), train_loss = 1.09658074, grad/param norm = 5.0140e-02, time/batch = 0.2591s	
1247/5250 (epoch 11.876), train_loss = 1.07891433, grad/param norm = 4.8415e-02, time/batch = 0.2592s	
1248/5250 (epoch 11.886), train_loss = 1.09562803, grad/param norm = 5.0907e-02, time/batch = 0.2587s	
1249/5250 (epoch 11.895), train_loss = 1.11531422, grad/param norm = 5.4097e-02, time/batch = 0.2594s	
1250/5250 (epoch 11.905), train_loss = 1.10795432, grad/param norm = 5.1675e-02, time/batch = 0.2596s	
1251/5250 (epoch 11.914), train_loss = 1.11555551, grad/param norm = 4.9350e-02, time/batch = 0.2592s	
1252/5250 (epoch 11.924), train_loss = 1.09211974, grad/param norm = 4.4673e-02, time/batch = 0.2588s	
1253/5250 (epoch 11.933), train_loss = 1.08484053, grad/param norm = 4.5722e-02, time/batch = 0.2591s	
1254/5250 (epoch 11.943), train_loss = 1.11606146, grad/param norm = 4.9078e-02, time/batch = 0.2589s	
1255/5250 (epoch 11.952), train_loss = 1.12636061, grad/param norm = 5.3630e-02, time/batch = 0.2589s	
1256/5250 (epoch 11.962), train_loss = 1.10035178, grad/param norm = 4.9120e-02, time/batch = 0.2595s	
1257/5250 (epoch 11.971), train_loss = 1.11153034, grad/param norm = 5.0434e-02, time/batch = 0.2592s	
1258/5250 (epoch 11.981), train_loss = 1.11881169, grad/param norm = 5.4555e-02, time/batch = 0.2590s	
1259/5250 (epoch 11.990), train_loss = 1.11976741, grad/param norm = 5.8509e-02, time/batch = 0.2592s	
decayed learning rate by a factor 0.97 to 0.001825346	
1260/5250 (epoch 12.000), train_loss = 1.11317692, grad/param norm = 5.2278e-02, time/batch = 0.2593s	
1261/5250 (epoch 12.010), train_loss = 1.28492023, grad/param norm = 5.7512e-02, time/batch = 0.2591s	
1262/5250 (epoch 12.019), train_loss = 1.09072736, grad/param norm = 5.3276e-02, time/batch = 0.2588s	
1263/5250 (epoch 12.029), train_loss = 1.09842564, grad/param norm = 4.8790e-02, time/batch = 0.2594s	
1264/5250 (epoch 12.038), train_loss = 1.07956516, grad/param norm = 4.6680e-02, time/batch = 0.2592s	
1265/5250 (epoch 12.048), train_loss = 1.05730078, grad/param norm = 4.3789e-02, time/batch = 0.2592s	
1266/5250 (epoch 12.057), train_loss = 1.05353693, grad/param norm = 4.2852e-02, time/batch = 0.2593s	
1267/5250 (epoch 12.067), train_loss = 1.06344245, grad/param norm = 4.5245e-02, time/batch = 0.2589s	
1268/5250 (epoch 12.076), train_loss = 1.10119603, grad/param norm = 5.5709e-02, time/batch = 0.2590s	
1269/5250 (epoch 12.086), train_loss = 1.05446449, grad/param norm = 4.8980e-02, time/batch = 0.2595s	
1270/5250 (epoch 12.095), train_loss = 1.05209524, grad/param norm = 4.4972e-02, time/batch = 0.2596s	
1271/5250 (epoch 12.105), train_loss = 1.07165753, grad/param norm = 4.4504e-02, time/batch = 0.2593s	
1272/5250 (epoch 12.114), train_loss = 1.05046229, grad/param norm = 4.4399e-02, time/batch = 0.2590s	
1273/5250 (epoch 12.124), train_loss = 1.07848350, grad/param norm = 4.3947e-02, time/batch = 0.2593s	
1274/5250 (epoch 12.133), train_loss = 1.05719295, grad/param norm = 4.9835e-02, time/batch = 0.2591s	
1275/5250 (epoch 12.143), train_loss = 1.04706241, grad/param norm = 4.7414e-02, time/batch = 0.2593s	
1276/5250 (epoch 12.152), train_loss = 1.04417241, grad/param norm = 4.7172e-02, time/batch = 0.2607s	
1277/5250 (epoch 12.162), train_loss = 1.07944944, grad/param norm = 5.0926e-02, time/batch = 0.2591s	
1278/5250 (epoch 12.171), train_loss = 1.06763792, grad/param norm = 4.7509e-02, time/batch = 0.2597s	
1279/5250 (epoch 12.181), train_loss = 1.07061895, grad/param norm = 4.7610e-02, time/batch = 0.2591s	
1280/5250 (epoch 12.190), train_loss = 1.08411344, grad/param norm = 4.8933e-02, time/batch = 0.2595s	
1281/5250 (epoch 12.200), train_loss = 1.08072558, grad/param norm = 5.1254e-02, time/batch = 0.2596s	
1282/5250 (epoch 12.210), train_loss = 1.07832095, grad/param norm = 5.2155e-02, time/batch = 0.2591s	
1283/5250 (epoch 12.219), train_loss = 1.08848209, grad/param norm = 5.0427e-02, time/batch = 0.2594s	
1284/5250 (epoch 12.229), train_loss = 1.07423489, grad/param norm = 5.0752e-02, time/batch = 0.2592s	
1285/5250 (epoch 12.238), train_loss = 1.06867391, grad/param norm = 4.9539e-02, time/batch = 0.2597s	
1286/5250 (epoch 12.248), train_loss = 1.06259961, grad/param norm = 4.9063e-02, time/batch = 0.2596s	
1287/5250 (epoch 12.257), train_loss = 1.06679557, grad/param norm = 4.7074e-02, time/batch = 0.2593s	
1288/5250 (epoch 12.267), train_loss = 1.05908123, grad/param norm = 4.4626e-02, time/batch = 0.2597s	
1289/5250 (epoch 12.276), train_loss = 1.04093414, grad/param norm = 4.1513e-02, time/batch = 0.2593s	
1290/5250 (epoch 12.286), train_loss = 1.03862370, grad/param norm = 4.6789e-02, time/batch = 0.2590s	
1291/5250 (epoch 12.295), train_loss = 1.06304968, grad/param norm = 4.8320e-02, time/batch = 0.2599s	
1292/5250 (epoch 12.305), train_loss = 1.05823835, grad/param norm = 4.9589e-02, time/batch = 0.2591s	
1293/5250 (epoch 12.314), train_loss = 1.04851557, grad/param norm = 4.9699e-02, time/batch = 0.2590s	
1294/5250 (epoch 12.324), train_loss = 1.06708031, grad/param norm = 5.1272e-02, time/batch = 0.2593s	
1295/5250 (epoch 12.333), train_loss = 1.06491457, grad/param norm = 5.0084e-02, time/batch = 0.2596s	
1296/5250 (epoch 12.343), train_loss = 1.05806765, grad/param norm = 4.8777e-02, time/batch = 0.2592s	
1297/5250 (epoch 12.352), train_loss = 1.06402283, grad/param norm = 4.9806e-02, time/batch = 0.2593s	
1298/5250 (epoch 12.362), train_loss = 1.06521114, grad/param norm = 5.0679e-02, time/batch = 0.2592s	
1299/5250 (epoch 12.371), train_loss = 1.06997754, grad/param norm = 5.1479e-02, time/batch = 0.2589s	
1300/5250 (epoch 12.381), train_loss = 1.05808535, grad/param norm = 4.7891e-02, time/batch = 0.2597s	
1301/5250 (epoch 12.390), train_loss = 1.04663661, grad/param norm = 5.2420e-02, time/batch = 0.2596s	
1302/5250 (epoch 12.400), train_loss = 1.05848945, grad/param norm = 5.6857e-02, time/batch = 0.2591s	
1303/5250 (epoch 12.410), train_loss = 1.06462900, grad/param norm = 4.9389e-02, time/batch = 0.2595s	
1304/5250 (epoch 12.419), train_loss = 1.06116056, grad/param norm = 4.8920e-02, time/batch = 0.2593s	
1305/5250 (epoch 12.429), train_loss = 1.06796056, grad/param norm = 4.7074e-02, time/batch = 0.2589s	
1306/5250 (epoch 12.438), train_loss = 1.08259218, grad/param norm = 5.3140e-02, time/batch = 0.2592s	
1307/5250 (epoch 12.448), train_loss = 1.04717339, grad/param norm = 5.1323e-02, time/batch = 0.2593s	
1308/5250 (epoch 12.457), train_loss = 1.04382822, grad/param norm = 4.9332e-02, time/batch = 0.2618s	
1309/5250 (epoch 12.467), train_loss = 1.05698200, grad/param norm = 5.1286e-02, time/batch = 0.2592s	
1310/5250 (epoch 12.476), train_loss = 1.04215347, grad/param norm = 5.1150e-02, time/batch = 0.2592s	
1311/5250 (epoch 12.486), train_loss = 1.06479883, grad/param norm = 5.0705e-02, time/batch = 0.2595s	
1312/5250 (epoch 12.495), train_loss = 1.07727390, grad/param norm = 4.8795e-02, time/batch = 0.2591s	
1313/5250 (epoch 12.505), train_loss = 1.07460814, grad/param norm = 5.1651e-02, time/batch = 0.2594s	
1314/5250 (epoch 12.514), train_loss = 1.08012203, grad/param norm = 5.3460e-02, time/batch = 0.2592s	
1315/5250 (epoch 12.524), train_loss = 1.07037058, grad/param norm = 5.4730e-02, time/batch = 0.2589s	
1316/5250 (epoch 12.533), train_loss = 1.07642290, grad/param norm = 5.0960e-02, time/batch = 0.2590s	
1317/5250 (epoch 12.543), train_loss = 1.05173173, grad/param norm = 4.7838e-02, time/batch = 0.2593s	
1318/5250 (epoch 12.552), train_loss = 1.05382929, grad/param norm = 4.9124e-02, time/batch = 0.2589s	
1319/5250 (epoch 12.562), train_loss = 1.05562990, grad/param norm = 5.0575e-02, time/batch = 0.2590s	
1320/5250 (epoch 12.571), train_loss = 1.07218997, grad/param norm = 5.4589e-02, time/batch = 0.2594s	
1321/5250 (epoch 12.581), train_loss = 1.08315963, grad/param norm = 5.3830e-02, time/batch = 0.2591s	
1322/5250 (epoch 12.590), train_loss = 1.05664091, grad/param norm = 4.9938e-02, time/batch = 0.2593s	
1323/5250 (epoch 12.600), train_loss = 1.08147611, grad/param norm = 5.4013e-02, time/batch = 0.2591s	
1324/5250 (epoch 12.610), train_loss = 1.09380179, grad/param norm = 5.6147e-02, time/batch = 0.2590s	
1325/5250 (epoch 12.619), train_loss = 1.07759384, grad/param norm = 5.3500e-02, time/batch = 0.2597s	
1326/5250 (epoch 12.629), train_loss = 1.05943818, grad/param norm = 4.7881e-02, time/batch = 0.2589s	
1327/5250 (epoch 12.638), train_loss = 1.05506375, grad/param norm = 4.6198e-02, time/batch = 0.2592s	
1328/5250 (epoch 12.648), train_loss = 1.06414485, grad/param norm = 4.6322e-02, time/batch = 0.2593s	
1329/5250 (epoch 12.657), train_loss = 1.05961218, grad/param norm = 4.8472e-02, time/batch = 0.2596s	
1330/5250 (epoch 12.667), train_loss = 1.06621049, grad/param norm = 4.8933e-02, time/batch = 0.2593s	
1331/5250 (epoch 12.676), train_loss = 1.05654566, grad/param norm = 4.9988e-02, time/batch = 0.2590s	
1332/5250 (epoch 12.686), train_loss = 1.06405809, grad/param norm = 5.1978e-02, time/batch = 0.2588s	
1333/5250 (epoch 12.695), train_loss = 1.06254913, grad/param norm = 5.5141e-02, time/batch = 0.2595s	
1334/5250 (epoch 12.705), train_loss = 1.05826628, grad/param norm = 5.5827e-02, time/batch = 0.2590s	
1335/5250 (epoch 12.714), train_loss = 1.07311778, grad/param norm = 4.8988e-02, time/batch = 0.2595s	
1336/5250 (epoch 12.724), train_loss = 1.04733557, grad/param norm = 4.9189e-02, time/batch = 0.2594s	
1337/5250 (epoch 12.733), train_loss = 1.03382958, grad/param norm = 5.1322e-02, time/batch = 0.2592s	
1338/5250 (epoch 12.743), train_loss = 1.04003680, grad/param norm = 5.3884e-02, time/batch = 0.2596s	
1339/5250 (epoch 12.752), train_loss = 1.04782043, grad/param norm = 5.2737e-02, time/batch = 0.2593s	
1340/5250 (epoch 12.762), train_loss = 1.04039727, grad/param norm = 4.8711e-02, time/batch = 0.2591s	
1341/5250 (epoch 12.771), train_loss = 1.02907514, grad/param norm = 5.1537e-02, time/batch = 0.2593s	
1342/5250 (epoch 12.781), train_loss = 1.07036429, grad/param norm = 5.5561e-02, time/batch = 0.2592s	
1343/5250 (epoch 12.790), train_loss = 1.07081887, grad/param norm = 5.4185e-02, time/batch = 0.2592s	
1344/5250 (epoch 12.800), train_loss = 1.03909126, grad/param norm = 5.1048e-02, time/batch = 0.2593s	
1345/5250 (epoch 12.810), train_loss = 1.06129237, grad/param norm = 5.4452e-02, time/batch = 0.2597s	
1346/5250 (epoch 12.819), train_loss = 1.05166649, grad/param norm = 5.1080e-02, time/batch = 0.2593s	
1347/5250 (epoch 12.829), train_loss = 1.05308418, grad/param norm = 5.1200e-02, time/batch = 0.2592s	
1348/5250 (epoch 12.838), train_loss = 1.02393417, grad/param norm = 5.1308e-02, time/batch = 0.2594s	
1349/5250 (epoch 12.848), train_loss = 1.02720329, grad/param norm = 5.0633e-02, time/batch = 0.2589s	
1350/5250 (epoch 12.857), train_loss = 1.04586385, grad/param norm = 5.1036e-02, time/batch = 0.2591s	
1351/5250 (epoch 12.867), train_loss = 1.03878374, grad/param norm = 4.7520e-02, time/batch = 0.2593s	
1352/5250 (epoch 12.876), train_loss = 1.02642140, grad/param norm = 4.6531e-02, time/batch = 0.2588s	
1353/5250 (epoch 12.886), train_loss = 1.04335227, grad/param norm = 4.7659e-02, time/batch = 0.2591s	
1354/5250 (epoch 12.895), train_loss = 1.05816607, grad/param norm = 5.0200e-02, time/batch = 0.2595s	
1355/5250 (epoch 12.905), train_loss = 1.06022745, grad/param norm = 5.5239e-02, time/batch = 0.2591s	
1356/5250 (epoch 12.914), train_loss = 1.07970122, grad/param norm = 5.9492e-02, time/batch = 0.2590s	
1357/5250 (epoch 12.924), train_loss = 1.07047573, grad/param norm = 5.9867e-02, time/batch = 0.2592s	
1358/5250 (epoch 12.933), train_loss = 1.06003916, grad/param norm = 5.6905e-02, time/batch = 0.2593s	
1359/5250 (epoch 12.943), train_loss = 1.07074909, grad/param norm = 5.2605e-02, time/batch = 0.2590s	
1360/5250 (epoch 12.952), train_loss = 1.06531840, grad/param norm = 4.8564e-02, time/batch = 0.2592s	
1361/5250 (epoch 12.962), train_loss = 1.04271876, grad/param norm = 4.9781e-02, time/batch = 0.2592s	
1362/5250 (epoch 12.971), train_loss = 1.06200237, grad/param norm = 4.9512e-02, time/batch = 0.2591s	
1363/5250 (epoch 12.981), train_loss = 1.06094771, grad/param norm = 4.9502e-02, time/batch = 0.2592s	
1364/5250 (epoch 12.990), train_loss = 1.05185429, grad/param norm = 4.7561e-02, time/batch = 0.2592s	
decayed learning rate by a factor 0.97 to 0.00177058562	
1365/5250 (epoch 13.000), train_loss = 1.05713934, grad/param norm = 5.3081e-02, time/batch = 0.2588s	
1366/5250 (epoch 13.010), train_loss = 1.23767380, grad/param norm = 5.6846e-02, time/batch = 0.2594s	
1367/5250 (epoch 13.019), train_loss = 1.03793087, grad/param norm = 4.9587e-02, time/batch = 0.2594s	
1368/5250 (epoch 13.029), train_loss = 1.04639077, grad/param norm = 4.7804e-02, time/batch = 0.2595s	
1369/5250 (epoch 13.038), train_loss = 1.03341404, grad/param norm = 4.8134e-02, time/batch = 0.2592s	
1370/5250 (epoch 13.048), train_loss = 1.02002841, grad/param norm = 4.7566e-02, time/batch = 0.2591s	
1371/5250 (epoch 13.057), train_loss = 1.00644981, grad/param norm = 4.4973e-02, time/batch = 0.2590s	
1372/5250 (epoch 13.067), train_loss = 1.01960688, grad/param norm = 4.7162e-02, time/batch = 0.2589s	
1373/5250 (epoch 13.076), train_loss = 1.04973715, grad/param norm = 5.7641e-02, time/batch = 0.2593s	
1374/5250 (epoch 13.086), train_loss = 1.01731606, grad/param norm = 4.9601e-02, time/batch = 0.2590s	
1375/5250 (epoch 13.095), train_loss = 1.01706125, grad/param norm = 5.0642e-02, time/batch = 0.2591s	
1376/5250 (epoch 13.105), train_loss = 1.03912085, grad/param norm = 5.4724e-02, time/batch = 0.2592s	
1377/5250 (epoch 13.114), train_loss = 1.01251504, grad/param norm = 4.8556e-02, time/batch = 0.2601s	
1378/5250 (epoch 13.124), train_loss = 1.04691970, grad/param norm = 5.0938e-02, time/batch = 0.2589s	
1379/5250 (epoch 13.133), train_loss = 1.01435843, grad/param norm = 4.5636e-02, time/batch = 0.2594s	
1380/5250 (epoch 13.143), train_loss = 0.99632081, grad/param norm = 4.7177e-02, time/batch = 0.2594s	
1381/5250 (epoch 13.152), train_loss = 0.99260524, grad/param norm = 4.9491e-02, time/batch = 0.2591s	
1382/5250 (epoch 13.162), train_loss = 1.02755853, grad/param norm = 5.0678e-02, time/batch = 0.2590s	
1383/5250 (epoch 13.171), train_loss = 1.02407900, grad/param norm = 5.1054e-02, time/batch = 0.2594s	
1384/5250 (epoch 13.181), train_loss = 1.02350456, grad/param norm = 5.1489e-02, time/batch = 0.2594s	
1385/5250 (epoch 13.190), train_loss = 1.03577299, grad/param norm = 5.3685e-02, time/batch = 0.2589s	
1386/5250 (epoch 13.200), train_loss = 1.02434103, grad/param norm = 4.8875e-02, time/batch = 0.2593s	
1387/5250 (epoch 13.210), train_loss = 1.02011766, grad/param norm = 4.8086e-02, time/batch = 0.2589s	
1388/5250 (epoch 13.219), train_loss = 1.04229176, grad/param norm = 5.0254e-02, time/batch = 0.2593s	
1389/5250 (epoch 13.229), train_loss = 1.02638671, grad/param norm = 5.6139e-02, time/batch = 0.2589s	
1390/5250 (epoch 13.238), train_loss = 1.02833448, grad/param norm = 5.3206e-02, time/batch = 0.2595s	
1391/5250 (epoch 13.248), train_loss = 1.01893968, grad/param norm = 5.1008e-02, time/batch = 0.2592s	
1392/5250 (epoch 13.257), train_loss = 1.02996301, grad/param norm = 5.6525e-02, time/batch = 0.2593s	
1393/5250 (epoch 13.267), train_loss = 1.02255299, grad/param norm = 4.8614e-02, time/batch = 0.2591s	
1394/5250 (epoch 13.276), train_loss = 1.00403109, grad/param norm = 4.7905e-02, time/batch = 0.2590s	
1395/5250 (epoch 13.286), train_loss = 0.99533042, grad/param norm = 5.0104e-02, time/batch = 0.2592s	
1396/5250 (epoch 13.295), train_loss = 1.00823517, grad/param norm = 4.6849e-02, time/batch = 0.2595s	
1397/5250 (epoch 13.305), train_loss = 1.00955322, grad/param norm = 5.2331e-02, time/batch = 0.2593s	
1398/5250 (epoch 13.314), train_loss = 1.00223404, grad/param norm = 4.8158e-02, time/batch = 0.2589s	
1399/5250 (epoch 13.324), train_loss = 1.01112440, grad/param norm = 4.7451e-02, time/batch = 0.2590s	
1400/5250 (epoch 13.333), train_loss = 1.01703415, grad/param norm = 5.1028e-02, time/batch = 0.2594s	
1401/5250 (epoch 13.343), train_loss = 1.01881418, grad/param norm = 5.3968e-02, time/batch = 0.2589s	
1402/5250 (epoch 13.352), train_loss = 1.02029926, grad/param norm = 5.5023e-02, time/batch = 0.2593s	
1403/5250 (epoch 13.362), train_loss = 1.02416239, grad/param norm = 5.4945e-02, time/batch = 0.2592s	
1404/5250 (epoch 13.371), train_loss = 1.01871474, grad/param norm = 5.2743e-02, time/batch = 0.2591s	
1405/5250 (epoch 13.381), train_loss = 1.01583548, grad/param norm = 5.0273e-02, time/batch = 0.2594s	
1406/5250 (epoch 13.390), train_loss = 1.00211644, grad/param norm = 5.3559e-02, time/batch = 0.2590s	
1407/5250 (epoch 13.400), train_loss = 1.00672853, grad/param norm = 5.3397e-02, time/batch = 0.2590s	
1408/5250 (epoch 13.410), train_loss = 1.03588732, grad/param norm = 6.4520e-02, time/batch = 0.2594s	
1409/5250 (epoch 13.419), train_loss = 1.04802821, grad/param norm = 6.4497e-02, time/batch = 0.2591s	
1410/5250 (epoch 13.429), train_loss = 1.04138854, grad/param norm = 6.0714e-02, time/batch = 0.2590s	
1411/5250 (epoch 13.438), train_loss = 1.03819160, grad/param norm = 5.3051e-02, time/batch = 0.2596s	
1412/5250 (epoch 13.448), train_loss = 0.99750143, grad/param norm = 4.7493e-02, time/batch = 0.2587s	
1413/5250 (epoch 13.457), train_loss = 1.00120965, grad/param norm = 4.9800e-02, time/batch = 0.2595s	
1414/5250 (epoch 13.467), train_loss = 1.01605348, grad/param norm = 5.4436e-02, time/batch = 0.2591s	
1415/5250 (epoch 13.476), train_loss = 1.00449696, grad/param norm = 5.2653e-02, time/batch = 0.2596s	
1416/5250 (epoch 13.486), train_loss = 1.02002104, grad/param norm = 5.1754e-02, time/batch = 0.2593s	
1417/5250 (epoch 13.495), train_loss = 1.03079288, grad/param norm = 5.3215e-02, time/batch = 0.2592s	
1418/5250 (epoch 13.505), train_loss = 1.03242042, grad/param norm = 5.4269e-02, time/batch = 0.2593s	
1419/5250 (epoch 13.514), train_loss = 1.04018077, grad/param norm = 5.8810e-02, time/batch = 0.2587s	
1420/5250 (epoch 13.524), train_loss = 1.02940126, grad/param norm = 5.8630e-02, time/batch = 0.2588s	
1421/5250 (epoch 13.533), train_loss = 1.02561196, grad/param norm = 5.1948e-02, time/batch = 0.2591s	
1422/5250 (epoch 13.543), train_loss = 1.00419667, grad/param norm = 4.7834e-02, time/batch = 0.2590s	
1423/5250 (epoch 13.552), train_loss = 0.99982707, grad/param norm = 4.7637e-02, time/batch = 0.2590s	
1424/5250 (epoch 13.562), train_loss = 1.00116678, grad/param norm = 4.8214e-02, time/batch = 0.2594s	
1425/5250 (epoch 13.571), train_loss = 1.02270442, grad/param norm = 5.3128e-02, time/batch = 0.2589s	
1426/5250 (epoch 13.581), train_loss = 1.03393302, grad/param norm = 5.4432e-02, time/batch = 0.2590s	
1427/5250 (epoch 13.590), train_loss = 1.01183876, grad/param norm = 5.3386e-02, time/batch = 0.2590s	
1428/5250 (epoch 13.600), train_loss = 1.02725444, grad/param norm = 5.0288e-02, time/batch = 0.2591s	
1429/5250 (epoch 13.610), train_loss = 1.03819439, grad/param norm = 5.1648e-02, time/batch = 0.2594s	
1430/5250 (epoch 13.619), train_loss = 1.02335086, grad/param norm = 4.7190e-02, time/batch = 0.2594s	
1431/5250 (epoch 13.629), train_loss = 1.00774659, grad/param norm = 5.0946e-02, time/batch = 0.2588s	
1432/5250 (epoch 13.638), train_loss = 1.01318859, grad/param norm = 5.5040e-02, time/batch = 0.2590s	
1433/5250 (epoch 13.648), train_loss = 1.02959608, grad/param norm = 5.3568e-02, time/batch = 0.2595s	
1434/5250 (epoch 13.657), train_loss = 1.01052728, grad/param norm = 4.9390e-02, time/batch = 0.2588s	
1435/5250 (epoch 13.667), train_loss = 1.01861476, grad/param norm = 4.8314e-02, time/batch = 0.2590s	
1436/5250 (epoch 13.676), train_loss = 1.00149650, grad/param norm = 5.0278e-02, time/batch = 0.2590s	
1437/5250 (epoch 13.686), train_loss = 1.01314738, grad/param norm = 5.0661e-02, time/batch = 0.2593s	
1438/5250 (epoch 13.695), train_loss = 1.00534090, grad/param norm = 5.2040e-02, time/batch = 0.2594s	
1439/5250 (epoch 13.705), train_loss = 1.00823221, grad/param norm = 5.7791e-02, time/batch = 0.2593s	
1440/5250 (epoch 13.714), train_loss = 1.03674572, grad/param norm = 5.6886e-02, time/batch = 0.2593s	
1441/5250 (epoch 13.724), train_loss = 1.00731148, grad/param norm = 5.3860e-02, time/batch = 0.2589s	
1442/5250 (epoch 13.733), train_loss = 0.98305056, grad/param norm = 5.2120e-02, time/batch = 0.2591s	
1443/5250 (epoch 13.743), train_loss = 0.99784893, grad/param norm = 5.7031e-02, time/batch = 0.2594s	
1444/5250 (epoch 13.752), train_loss = 1.00673128, grad/param norm = 5.7724e-02, time/batch = 0.2590s	
1445/5250 (epoch 13.762), train_loss = 1.01511590, grad/param norm = 5.8224e-02, time/batch = 0.2594s	
1446/5250 (epoch 13.771), train_loss = 0.99735315, grad/param norm = 5.8432e-02, time/batch = 0.2596s	
1447/5250 (epoch 13.781), train_loss = 1.01743337, grad/param norm = 5.5871e-02, time/batch = 0.2592s	
1448/5250 (epoch 13.790), train_loss = 1.02212589, grad/param norm = 5.1881e-02, time/batch = 0.2591s	
1449/5250 (epoch 13.800), train_loss = 0.99456689, grad/param norm = 5.3538e-02, time/batch = 0.2593s	
1450/5250 (epoch 13.810), train_loss = 1.01636361, grad/param norm = 5.5416e-02, time/batch = 0.2595s	
1451/5250 (epoch 13.819), train_loss = 1.00967009, grad/param norm = 5.0698e-02, time/batch = 0.2592s	
1452/5250 (epoch 13.829), train_loss = 1.00709292, grad/param norm = 5.6044e-02, time/batch = 0.2593s	
1453/5250 (epoch 13.838), train_loss = 0.98054642, grad/param norm = 5.3987e-02, time/batch = 0.2591s	
1454/5250 (epoch 13.848), train_loss = 0.98473778, grad/param norm = 5.3090e-02, time/batch = 0.2594s	
1455/5250 (epoch 13.857), train_loss = 0.99730504, grad/param norm = 4.9829e-02, time/batch = 0.2592s	
1456/5250 (epoch 13.867), train_loss = 0.99511192, grad/param norm = 5.3612e-02, time/batch = 0.2591s	
1457/5250 (epoch 13.876), train_loss = 0.98244564, grad/param norm = 4.9096e-02, time/batch = 0.2593s	
1458/5250 (epoch 13.886), train_loss = 1.00055912, grad/param norm = 5.2367e-02, time/batch = 0.2591s	
1459/5250 (epoch 13.895), train_loss = 1.00854803, grad/param norm = 5.4069e-02, time/batch = 0.2592s	
1460/5250 (epoch 13.905), train_loss = 1.01022653, grad/param norm = 5.3195e-02, time/batch = 0.2593s	
1461/5250 (epoch 13.914), train_loss = 1.01764373, grad/param norm = 5.3699e-02, time/batch = 0.2592s	
1462/5250 (epoch 13.924), train_loss = 1.01279081, grad/param norm = 5.6178e-02, time/batch = 0.2589s	
1463/5250 (epoch 13.933), train_loss = 1.01277615, grad/param norm = 5.7426e-02, time/batch = 0.2591s	
1464/5250 (epoch 13.943), train_loss = 1.02737407, grad/param norm = 5.4999e-02, time/batch = 0.2590s	
1465/5250 (epoch 13.952), train_loss = 1.02444377, grad/param norm = 5.5247e-02, time/batch = 0.2592s	
1466/5250 (epoch 13.962), train_loss = 1.00022655, grad/param norm = 5.3080e-02, time/batch = 0.2594s	
1467/5250 (epoch 13.971), train_loss = 1.01758050, grad/param norm = 5.2280e-02, time/batch = 0.2595s	
1468/5250 (epoch 13.981), train_loss = 1.01023869, grad/param norm = 5.0433e-02, time/batch = 0.2592s	
1469/5250 (epoch 13.990), train_loss = 1.00219565, grad/param norm = 4.9960e-02, time/batch = 0.2589s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
1470/5250 (epoch 14.000), train_loss = 1.00469268, grad/param norm = 5.2768e-02, time/batch = 0.2588s	
1471/5250 (epoch 14.010), train_loss = 1.18917625, grad/param norm = 6.3151e-02, time/batch = 0.2594s	
1472/5250 (epoch 14.019), train_loss = 1.00121540, grad/param norm = 5.5750e-02, time/batch = 0.2594s	
1473/5250 (epoch 14.029), train_loss = 1.00962371, grad/param norm = 5.4932e-02, time/batch = 0.2593s	
1474/5250 (epoch 14.038), train_loss = 0.99149947, grad/param norm = 5.3681e-02, time/batch = 0.2588s	
1475/5250 (epoch 14.048), train_loss = 0.97557710, grad/param norm = 4.9489e-02, time/batch = 0.2591s	
1476/5250 (epoch 14.057), train_loss = 0.96156188, grad/param norm = 4.7558e-02, time/batch = 0.2592s	
1477/5250 (epoch 14.067), train_loss = 0.97227495, grad/param norm = 4.9748e-02, time/batch = 0.2591s	
1478/5250 (epoch 14.076), train_loss = 0.99444429, grad/param norm = 5.0384e-02, time/batch = 0.2594s	
1479/5250 (epoch 14.086), train_loss = 0.97377752, grad/param norm = 5.3948e-02, time/batch = 0.2588s	
1480/5250 (epoch 14.095), train_loss = 0.97719693, grad/param norm = 5.1394e-02, time/batch = 0.2595s	
1481/5250 (epoch 14.105), train_loss = 0.98146761, grad/param norm = 4.9228e-02, time/batch = 0.2593s	
1482/5250 (epoch 14.114), train_loss = 0.96780993, grad/param norm = 5.0257e-02, time/batch = 0.2591s	
1483/5250 (epoch 14.124), train_loss = 1.00026696, grad/param norm = 5.3068e-02, time/batch = 0.2594s	
1484/5250 (epoch 14.133), train_loss = 0.98794864, grad/param norm = 5.5265e-02, time/batch = 0.2593s	
1485/5250 (epoch 14.143), train_loss = 0.96430857, grad/param norm = 5.1701e-02, time/batch = 0.2596s	
1486/5250 (epoch 14.152), train_loss = 0.94994071, grad/param norm = 5.1256e-02, time/batch = 0.2593s	
1487/5250 (epoch 14.162), train_loss = 0.97837624, grad/param norm = 5.0468e-02, time/batch = 0.2589s	
1488/5250 (epoch 14.171), train_loss = 0.97111421, grad/param norm = 5.0636e-02, time/batch = 0.2594s	
1489/5250 (epoch 14.181), train_loss = 0.97578430, grad/param norm = 5.2453e-02, time/batch = 0.2588s	
1490/5250 (epoch 14.190), train_loss = 0.98791285, grad/param norm = 5.5268e-02, time/batch = 0.2594s	
1491/5250 (epoch 14.200), train_loss = 0.98629030, grad/param norm = 5.5750e-02, time/batch = 0.2593s	
1492/5250 (epoch 14.210), train_loss = 0.97986663, grad/param norm = 5.2953e-02, time/batch = 0.2592s	
1493/5250 (epoch 14.219), train_loss = 0.99880044, grad/param norm = 5.3217e-02, time/batch = 0.2591s	
1494/5250 (epoch 14.229), train_loss = 0.97404187, grad/param norm = 5.1315e-02, time/batch = 0.2594s	
1495/5250 (epoch 14.238), train_loss = 0.97368691, grad/param norm = 5.4411e-02, time/batch = 0.2592s	
1496/5250 (epoch 14.248), train_loss = 0.98334886, grad/param norm = 5.5027e-02, time/batch = 0.2591s	
1497/5250 (epoch 14.257), train_loss = 0.98203050, grad/param norm = 5.5747e-02, time/batch = 0.2588s	
1498/5250 (epoch 14.267), train_loss = 0.98413497, grad/param norm = 5.5521e-02, time/batch = 0.2589s	
1499/5250 (epoch 14.276), train_loss = 0.96463498, grad/param norm = 5.0043e-02, time/batch = 0.2588s	
1500/5250 (epoch 14.286), train_loss = 0.95266367, grad/param norm = 5.0050e-02, time/batch = 0.2590s	
1501/5250 (epoch 14.295), train_loss = 0.97775669, grad/param norm = 5.7651e-02, time/batch = 0.2592s	
1502/5250 (epoch 14.305), train_loss = 0.96984380, grad/param norm = 5.4094e-02, time/batch = 0.2586s	
1503/5250 (epoch 14.314), train_loss = 0.96203751, grad/param norm = 5.4672e-02, time/batch = 0.2592s	
1504/5250 (epoch 14.324), train_loss = 0.98198285, grad/param norm = 5.6205e-02, time/batch = 0.2590s	
1505/5250 (epoch 14.333), train_loss = 0.97274286, grad/param norm = 5.3503e-02, time/batch = 0.2593s	
1506/5250 (epoch 14.343), train_loss = 0.96430825, grad/param norm = 4.8975e-02, time/batch = 0.2591s	
1507/5250 (epoch 14.352), train_loss = 0.96392905, grad/param norm = 5.3083e-02, time/batch = 0.2593s	
1508/5250 (epoch 14.362), train_loss = 0.98385537, grad/param norm = 5.8038e-02, time/batch = 0.2587s	
1509/5250 (epoch 14.371), train_loss = 0.98106773, grad/param norm = 5.8891e-02, time/batch = 0.2592s	
1510/5250 (epoch 14.381), train_loss = 0.97631616, grad/param norm = 5.2045e-02, time/batch = 0.2589s	
1511/5250 (epoch 14.390), train_loss = 0.95485749, grad/param norm = 5.2099e-02, time/batch = 0.2594s	
1512/5250 (epoch 14.400), train_loss = 0.96254718, grad/param norm = 5.6185e-02, time/batch = 0.2587s	
1513/5250 (epoch 14.410), train_loss = 0.97449758, grad/param norm = 5.3650e-02, time/batch = 0.2590s	
1514/5250 (epoch 14.419), train_loss = 0.98468432, grad/param norm = 5.6171e-02, time/batch = 0.2590s	
1515/5250 (epoch 14.429), train_loss = 0.98289722, grad/param norm = 5.5101e-02, time/batch = 0.2591s	
1516/5250 (epoch 14.438), train_loss = 0.98878212, grad/param norm = 5.4707e-02, time/batch = 0.2592s	
1517/5250 (epoch 14.448), train_loss = 0.96051766, grad/param norm = 5.4316e-02, time/batch = 0.2588s	
1518/5250 (epoch 14.457), train_loss = 0.96437604, grad/param norm = 5.3434e-02, time/batch = 0.2589s	
1519/5250 (epoch 14.467), train_loss = 0.96331306, grad/param norm = 4.9886e-02, time/batch = 0.2590s	
1520/5250 (epoch 14.476), train_loss = 0.95667063, grad/param norm = 5.6931e-02, time/batch = 0.2602s	
1521/5250 (epoch 14.486), train_loss = 0.98707147, grad/param norm = 5.8404e-02, time/batch = 0.2596s	
1522/5250 (epoch 14.495), train_loss = 0.98802047, grad/param norm = 5.5143e-02, time/batch = 0.2591s	
1523/5250 (epoch 14.505), train_loss = 0.99804299, grad/param norm = 6.3052e-02, time/batch = 0.2594s	
1524/5250 (epoch 14.514), train_loss = 1.00569836, grad/param norm = 6.2277e-02, time/batch = 0.2592s	
1525/5250 (epoch 14.524), train_loss = 0.98676246, grad/param norm = 5.9968e-02, time/batch = 0.2593s	
1526/5250 (epoch 14.533), train_loss = 0.98206144, grad/param norm = 5.5999e-02, time/batch = 0.2595s	
1527/5250 (epoch 14.543), train_loss = 0.96547277, grad/param norm = 5.2587e-02, time/batch = 0.2590s	
1528/5250 (epoch 14.552), train_loss = 0.95762449, grad/param norm = 5.1329e-02, time/batch = 0.2592s	
1529/5250 (epoch 14.562), train_loss = 0.96338858, grad/param norm = 5.2330e-02, time/batch = 0.2589s	
1530/5250 (epoch 14.571), train_loss = 0.97278294, grad/param norm = 5.0425e-02, time/batch = 0.2591s	
1531/5250 (epoch 14.581), train_loss = 0.97726100, grad/param norm = 5.1644e-02, time/batch = 0.2590s	
1532/5250 (epoch 14.590), train_loss = 0.95870676, grad/param norm = 5.0389e-02, time/batch = 0.2592s	
1533/5250 (epoch 14.600), train_loss = 0.99458725, grad/param norm = 6.2620e-02, time/batch = 0.2594s	
1534/5250 (epoch 14.610), train_loss = 0.99841122, grad/param norm = 5.5128e-02, time/batch = 0.2590s	
1535/5250 (epoch 14.619), train_loss = 0.98828017, grad/param norm = 5.5556e-02, time/batch = 0.2590s	
1536/5250 (epoch 14.629), train_loss = 0.96904023, grad/param norm = 5.4418e-02, time/batch = 0.2588s	
1537/5250 (epoch 14.638), train_loss = 0.96394417, grad/param norm = 5.4423e-02, time/batch = 0.2589s	
1538/5250 (epoch 14.648), train_loss = 0.97611100, grad/param norm = 5.0032e-02, time/batch = 0.2591s	
1539/5250 (epoch 14.657), train_loss = 0.95941940, grad/param norm = 5.0296e-02, time/batch = 0.2591s	
1540/5250 (epoch 14.667), train_loss = 0.96790364, grad/param norm = 5.4438e-02, time/batch = 0.2593s	
1541/5250 (epoch 14.676), train_loss = 0.95295280, grad/param norm = 4.9620e-02, time/batch = 0.2594s	
1542/5250 (epoch 14.686), train_loss = 0.96652310, grad/param norm = 5.4582e-02, time/batch = 0.2594s	
1543/5250 (epoch 14.695), train_loss = 0.97004707, grad/param norm = 5.8113e-02, time/batch = 0.2588s	
1544/5250 (epoch 14.705), train_loss = 0.96052179, grad/param norm = 5.9753e-02, time/batch = 0.2592s	
1545/5250 (epoch 14.714), train_loss = 0.98631367, grad/param norm = 5.8721e-02, time/batch = 0.2590s	
1546/5250 (epoch 14.724), train_loss = 0.96775327, grad/param norm = 5.6630e-02, time/batch = 0.2592s	
1547/5250 (epoch 14.733), train_loss = 0.94909615, grad/param norm = 5.7097e-02, time/batch = 0.2590s	
1548/5250 (epoch 14.743), train_loss = 0.95249403, grad/param norm = 5.3442e-02, time/batch = 0.2587s	
1549/5250 (epoch 14.752), train_loss = 0.95787955, grad/param norm = 5.8029e-02, time/batch = 0.2594s	
1550/5250 (epoch 14.762), train_loss = 0.96421127, grad/param norm = 5.3206e-02, time/batch = 0.2592s	
1551/5250 (epoch 14.771), train_loss = 0.94202298, grad/param norm = 5.1426e-02, time/batch = 0.2586s	
1552/5250 (epoch 14.781), train_loss = 0.96961460, grad/param norm = 5.5484e-02, time/batch = 0.2593s	
1553/5250 (epoch 14.790), train_loss = 0.97719663, grad/param norm = 5.4592e-02, time/batch = 0.2596s	
1554/5250 (epoch 14.800), train_loss = 0.94786725, grad/param norm = 5.3852e-02, time/batch = 0.2594s	
1555/5250 (epoch 14.810), train_loss = 0.96485958, grad/param norm = 5.7168e-02, time/batch = 0.2592s	
1556/5250 (epoch 14.819), train_loss = 0.96394124, grad/param norm = 5.3724e-02, time/batch = 0.2577s	
1557/5250 (epoch 14.829), train_loss = 0.95999406, grad/param norm = 5.5055e-02, time/batch = 0.2593s	
1558/5250 (epoch 14.838), train_loss = 0.92695458, grad/param norm = 5.5387e-02, time/batch = 0.2588s	
1559/5250 (epoch 14.848), train_loss = 0.95266387, grad/param norm = 6.0186e-02, time/batch = 0.2588s	
1560/5250 (epoch 14.857), train_loss = 0.96457476, grad/param norm = 5.7800e-02, time/batch = 0.2591s	
1561/5250 (epoch 14.867), train_loss = 0.95231677, grad/param norm = 5.7156e-02, time/batch = 0.2593s	
1562/5250 (epoch 14.876), train_loss = 0.94621502, grad/param norm = 5.6124e-02, time/batch = 0.2589s	
1563/5250 (epoch 14.886), train_loss = 0.95912813, grad/param norm = 5.4271e-02, time/batch = 0.2590s	
1564/5250 (epoch 14.895), train_loss = 0.95997777, grad/param norm = 5.5014e-02, time/batch = 0.2592s	
1565/5250 (epoch 14.905), train_loss = 0.95951246, grad/param norm = 5.5375e-02, time/batch = 0.2593s	
1566/5250 (epoch 14.914), train_loss = 0.97042545, grad/param norm = 5.5238e-02, time/batch = 0.2592s	
1567/5250 (epoch 14.924), train_loss = 0.96230127, grad/param norm = 5.6660e-02, time/batch = 0.2591s	
1568/5250 (epoch 14.933), train_loss = 0.95472588, grad/param norm = 5.2964e-02, time/batch = 0.2591s	
1569/5250 (epoch 14.943), train_loss = 0.97110279, grad/param norm = 5.5363e-02, time/batch = 0.2592s	
1570/5250 (epoch 14.952), train_loss = 0.98644634, grad/param norm = 5.9031e-02, time/batch = 0.2592s	
1571/5250 (epoch 14.962), train_loss = 0.95932576, grad/param norm = 5.8344e-02, time/batch = 0.2594s	
1572/5250 (epoch 14.971), train_loss = 0.97680037, grad/param norm = 5.8048e-02, time/batch = 0.2590s	
1573/5250 (epoch 14.981), train_loss = 0.98063800, grad/param norm = 5.8084e-02, time/batch = 0.2587s	
1574/5250 (epoch 14.990), train_loss = 0.97127149, grad/param norm = 5.6838e-02, time/batch = 0.2595s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
1575/5250 (epoch 15.000), train_loss = 0.95418205, grad/param norm = 5.4024e-02, time/batch = 0.2592s	
1576/5250 (epoch 15.010), train_loss = 1.13564526, grad/param norm = 5.7299e-02, time/batch = 0.2593s	
1577/5250 (epoch 15.019), train_loss = 0.95720937, grad/param norm = 5.8397e-02, time/batch = 0.2592s	
1578/5250 (epoch 15.029), train_loss = 0.96623965, grad/param norm = 5.6005e-02, time/batch = 0.2589s	
1579/5250 (epoch 15.038), train_loss = 0.94789705, grad/param norm = 5.4424e-02, time/batch = 0.2589s	
1580/5250 (epoch 15.048), train_loss = 0.93708338, grad/param norm = 5.1984e-02, time/batch = 0.2589s	
1581/5250 (epoch 15.057), train_loss = 0.92804059, grad/param norm = 5.3959e-02, time/batch = 0.2591s	
1582/5250 (epoch 15.067), train_loss = 0.93526263, grad/param norm = 5.5417e-02, time/batch = 0.2589s	
1583/5250 (epoch 15.076), train_loss = 0.95285766, grad/param norm = 5.5313e-02, time/batch = 0.2592s	
1584/5250 (epoch 15.086), train_loss = 0.93311521, grad/param norm = 5.5647e-02, time/batch = 0.2591s	
1585/5250 (epoch 15.095), train_loss = 0.93021281, grad/param norm = 5.0964e-02, time/batch = 0.2590s	
1586/5250 (epoch 15.105), train_loss = 0.93286041, grad/param norm = 5.0866e-02, time/batch = 0.2593s	
1587/5250 (epoch 15.114), train_loss = 0.92496884, grad/param norm = 5.4923e-02, time/batch = 0.2591s	
1588/5250 (epoch 15.124), train_loss = 0.95372508, grad/param norm = 5.0885e-02, time/batch = 0.2595s	
1589/5250 (epoch 15.133), train_loss = 0.93866683, grad/param norm = 5.4980e-02, time/batch = 0.2591s	
1590/5250 (epoch 15.143), train_loss = 0.92438596, grad/param norm = 5.3845e-02, time/batch = 0.2589s	
1591/5250 (epoch 15.152), train_loss = 0.91165588, grad/param norm = 5.3770e-02, time/batch = 0.2594s	
1592/5250 (epoch 15.162), train_loss = 0.94173365, grad/param norm = 5.9403e-02, time/batch = 0.2594s	
1593/5250 (epoch 15.171), train_loss = 0.93721338, grad/param norm = 5.5338e-02, time/batch = 0.2594s	
1594/5250 (epoch 15.181), train_loss = 0.93588091, grad/param norm = 5.4254e-02, time/batch = 0.2589s	
1595/5250 (epoch 15.190), train_loss = 0.93997406, grad/param norm = 5.4052e-02, time/batch = 0.2591s	
1596/5250 (epoch 15.200), train_loss = 0.93975131, grad/param norm = 5.5484e-02, time/batch = 0.2592s	
1597/5250 (epoch 15.210), train_loss = 0.93861367, grad/param norm = 5.5942e-02, time/batch = 0.2587s	
1598/5250 (epoch 15.219), train_loss = 0.95251868, grad/param norm = 5.3801e-02, time/batch = 0.2589s	
1599/5250 (epoch 15.229), train_loss = 0.93626342, grad/param norm = 5.8600e-02, time/batch = 0.2593s	
1600/5250 (epoch 15.238), train_loss = 0.93931384, grad/param norm = 6.0418e-02, time/batch = 0.2593s	
1601/5250 (epoch 15.248), train_loss = 0.93740198, grad/param norm = 5.4146e-02, time/batch = 0.2594s	
1602/5250 (epoch 15.257), train_loss = 0.93616820, grad/param norm = 5.4147e-02, time/batch = 0.2594s	
1603/5250 (epoch 15.267), train_loss = 0.93761780, grad/param norm = 5.4703e-02, time/batch = 0.2594s	
1604/5250 (epoch 15.276), train_loss = 0.92645465, grad/param norm = 5.2308e-02, time/batch = 0.2586s	
1605/5250 (epoch 15.286), train_loss = 0.91193180, grad/param norm = 5.6452e-02, time/batch = 0.2590s	
1606/5250 (epoch 15.295), train_loss = 0.92694543, grad/param norm = 5.2982e-02, time/batch = 0.2591s	
1607/5250 (epoch 15.305), train_loss = 0.91865528, grad/param norm = 5.5493e-02, time/batch = 0.2597s	
1608/5250 (epoch 15.314), train_loss = 0.91527727, grad/param norm = 5.5747e-02, time/batch = 0.2590s	
1609/5250 (epoch 15.324), train_loss = 0.93393221, grad/param norm = 5.5613e-02, time/batch = 0.2594s	
1610/5250 (epoch 15.333), train_loss = 0.93237212, grad/param norm = 5.6926e-02, time/batch = 0.2593s	
1611/5250 (epoch 15.343), train_loss = 0.93022986, grad/param norm = 6.1243e-02, time/batch = 0.2592s	
1612/5250 (epoch 15.352), train_loss = 0.93550410, grad/param norm = 6.2122e-02, time/batch = 0.2580s	
1613/5250 (epoch 15.362), train_loss = 0.92637772, grad/param norm = 5.6047e-02, time/batch = 0.2595s	
1614/5250 (epoch 15.371), train_loss = 0.93204849, grad/param norm = 5.6546e-02, time/batch = 0.2589s	
1615/5250 (epoch 15.381), train_loss = 0.94515721, grad/param norm = 6.1813e-02, time/batch = 0.2590s	
1616/5250 (epoch 15.390), train_loss = 0.92149282, grad/param norm = 5.8266e-02, time/batch = 0.2593s	
1617/5250 (epoch 15.400), train_loss = 0.92814955, grad/param norm = 5.8346e-02, time/batch = 0.2587s	
1618/5250 (epoch 15.410), train_loss = 0.94246286, grad/param norm = 6.2488e-02, time/batch = 0.2592s	
1619/5250 (epoch 15.419), train_loss = 0.93703033, grad/param norm = 5.4186e-02, time/batch = 0.2591s	
1620/5250 (epoch 15.429), train_loss = 0.93200085, grad/param norm = 5.4805e-02, time/batch = 0.2591s	
1621/5250 (epoch 15.438), train_loss = 0.94914748, grad/param norm = 5.5024e-02, time/batch = 0.2591s	
1622/5250 (epoch 15.448), train_loss = 0.91659704, grad/param norm = 5.7489e-02, time/batch = 0.2588s	
1623/5250 (epoch 15.457), train_loss = 0.92304546, grad/param norm = 5.4823e-02, time/batch = 0.2591s	
1624/5250 (epoch 15.467), train_loss = 0.92014812, grad/param norm = 5.5309e-02, time/batch = 0.2592s	
1625/5250 (epoch 15.476), train_loss = 0.90568106, grad/param norm = 5.3469e-02, time/batch = 0.2590s	
1626/5250 (epoch 15.486), train_loss = 0.92631791, grad/param norm = 5.2483e-02, time/batch = 0.2592s	
1627/5250 (epoch 15.495), train_loss = 0.94252530, grad/param norm = 5.4203e-02, time/batch = 0.2591s	
1628/5250 (epoch 15.505), train_loss = 0.94593227, grad/param norm = 6.2439e-02, time/batch = 0.2589s	
1629/5250 (epoch 15.514), train_loss = 0.95820112, grad/param norm = 6.1755e-02, time/batch = 0.2590s	
1630/5250 (epoch 15.524), train_loss = 0.95753862, grad/param norm = 6.9868e-02, time/batch = 0.2593s	
1631/5250 (epoch 15.533), train_loss = 0.95162541, grad/param norm = 6.8085e-02, time/batch = 0.2592s	
1632/5250 (epoch 15.543), train_loss = 0.93528567, grad/param norm = 5.8643e-02, time/batch = 0.2591s	
1633/5250 (epoch 15.552), train_loss = 0.91950503, grad/param norm = 5.3617e-02, time/batch = 0.2590s	
1634/5250 (epoch 15.562), train_loss = 0.91948494, grad/param norm = 5.4046e-02, time/batch = 0.2592s	
1635/5250 (epoch 15.571), train_loss = 0.92353093, grad/param norm = 5.2268e-02, time/batch = 0.2591s	
1636/5250 (epoch 15.581), train_loss = 0.93503465, grad/param norm = 5.5423e-02, time/batch = 0.2591s	
1637/5250 (epoch 15.590), train_loss = 0.92379243, grad/param norm = 5.7496e-02, time/batch = 0.2589s	
1638/5250 (epoch 15.600), train_loss = 0.93346668, grad/param norm = 5.5701e-02, time/batch = 0.2588s	
1639/5250 (epoch 15.610), train_loss = 0.94928776, grad/param norm = 5.8036e-02, time/batch = 0.2591s	
1640/5250 (epoch 15.619), train_loss = 0.94199831, grad/param norm = 5.3674e-02, time/batch = 0.2594s	
1641/5250 (epoch 15.629), train_loss = 0.92055243, grad/param norm = 5.5067e-02, time/batch = 0.2590s	
1642/5250 (epoch 15.638), train_loss = 0.91736572, grad/param norm = 5.7119e-02, time/batch = 0.2591s	
1643/5250 (epoch 15.648), train_loss = 0.95843880, grad/param norm = 6.4982e-02, time/batch = 0.2595s	
1644/5250 (epoch 15.657), train_loss = 0.93479557, grad/param norm = 5.7220e-02, time/batch = 0.2591s	
1645/5250 (epoch 15.667), train_loss = 0.92758920, grad/param norm = 5.6190e-02, time/batch = 0.2593s	
1646/5250 (epoch 15.676), train_loss = 0.92074454, grad/param norm = 5.6847e-02, time/batch = 0.2589s	
1647/5250 (epoch 15.686), train_loss = 0.92132956, grad/param norm = 5.6173e-02, time/batch = 0.2591s	
1648/5250 (epoch 15.695), train_loss = 0.91469904, grad/param norm = 5.5578e-02, time/batch = 0.2593s	
1649/5250 (epoch 15.705), train_loss = 0.91705171, grad/param norm = 6.1682e-02, time/batch = 0.2593s	
1650/5250 (epoch 15.714), train_loss = 0.95464022, grad/param norm = 6.7092e-02, time/batch = 0.2591s	
1651/5250 (epoch 15.724), train_loss = 0.92340936, grad/param norm = 5.6083e-02, time/batch = 0.2593s	
1652/5250 (epoch 15.733), train_loss = 0.90065452, grad/param norm = 5.7200e-02, time/batch = 0.2588s	
1653/5250 (epoch 15.743), train_loss = 0.91084637, grad/param norm = 5.9151e-02, time/batch = 0.2593s	
1654/5250 (epoch 15.752), train_loss = 0.91412470, grad/param norm = 5.9359e-02, time/batch = 0.2592s	
1655/5250 (epoch 15.762), train_loss = 0.91769017, grad/param norm = 5.2682e-02, time/batch = 0.2591s	
1656/5250 (epoch 15.771), train_loss = 0.90269033, grad/param norm = 5.5624e-02, time/batch = 0.2592s	
1657/5250 (epoch 15.781), train_loss = 0.92195679, grad/param norm = 5.4719e-02, time/batch = 0.2592s	
1658/5250 (epoch 15.790), train_loss = 0.92433492, grad/param norm = 5.7573e-02, time/batch = 0.2592s	
1659/5250 (epoch 15.800), train_loss = 0.90981574, grad/param norm = 5.6843e-02, time/batch = 0.2592s	
1660/5250 (epoch 15.810), train_loss = 0.91801959, grad/param norm = 5.5279e-02, time/batch = 0.2589s	
1661/5250 (epoch 15.819), train_loss = 0.92342505, grad/param norm = 5.7701e-02, time/batch = 0.2592s	
1662/5250 (epoch 15.829), train_loss = 0.92659811, grad/param norm = 5.8815e-02, time/batch = 0.2592s	
1663/5250 (epoch 15.838), train_loss = 0.88771856, grad/param norm = 5.9456e-02, time/batch = 0.2602s	
1664/5250 (epoch 15.848), train_loss = 0.90400732, grad/param norm = 6.2586e-02, time/batch = 0.2589s	
1665/5250 (epoch 15.857), train_loss = 0.91963457, grad/param norm = 5.8786e-02, time/batch = 0.2592s	
1666/5250 (epoch 15.867), train_loss = 0.90942791, grad/param norm = 6.1132e-02, time/batch = 0.2597s	
1667/5250 (epoch 15.876), train_loss = 0.91882953, grad/param norm = 6.1397e-02, time/batch = 0.2590s	
1668/5250 (epoch 15.886), train_loss = 0.92863586, grad/param norm = 5.8962e-02, time/batch = 0.2592s	
1669/5250 (epoch 15.895), train_loss = 0.92720106, grad/param norm = 6.1494e-02, time/batch = 0.2592s	
1670/5250 (epoch 15.905), train_loss = 0.92456631, grad/param norm = 5.9165e-02, time/batch = 0.2591s	
1671/5250 (epoch 15.914), train_loss = 0.93108893, grad/param norm = 6.1907e-02, time/batch = 0.2593s	
1672/5250 (epoch 15.924), train_loss = 0.91945919, grad/param norm = 5.8918e-02, time/batch = 0.2590s	
1673/5250 (epoch 15.933), train_loss = 0.91477881, grad/param norm = 5.6275e-02, time/batch = 0.2592s	
1674/5250 (epoch 15.943), train_loss = 0.92458113, grad/param norm = 5.7083e-02, time/batch = 0.2599s	
1675/5250 (epoch 15.952), train_loss = 0.92746351, grad/param norm = 5.5027e-02, time/batch = 0.2592s	
1676/5250 (epoch 15.962), train_loss = 0.90218262, grad/param norm = 5.4977e-02, time/batch = 0.2591s	
1677/5250 (epoch 15.971), train_loss = 0.92575167, grad/param norm = 5.5107e-02, time/batch = 0.2590s	
1678/5250 (epoch 15.981), train_loss = 0.92217464, grad/param norm = 5.7274e-02, time/batch = 0.2592s	
1679/5250 (epoch 15.990), train_loss = 0.92496766, grad/param norm = 5.8686e-02, time/batch = 0.2593s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
1680/5250 (epoch 16.000), train_loss = 0.91357276, grad/param norm = 6.0376e-02, time/batch = 0.2592s	
1681/5250 (epoch 16.010), train_loss = 1.10038872, grad/param norm = 6.3663e-02, time/batch = 0.2592s	
1682/5250 (epoch 16.019), train_loss = 0.91039498, grad/param norm = 5.5716e-02, time/batch = 0.2591s	
1683/5250 (epoch 16.029), train_loss = 0.92174611, grad/param norm = 5.8410e-02, time/batch = 0.2592s	
1684/5250 (epoch 16.038), train_loss = 0.90562481, grad/param norm = 5.9023e-02, time/batch = 0.2593s	
1685/5250 (epoch 16.048), train_loss = 0.89757416, grad/param norm = 5.8158e-02, time/batch = 0.2589s	
1686/5250 (epoch 16.057), train_loss = 0.89043560, grad/param norm = 5.5630e-02, time/batch = 0.2590s	
1687/5250 (epoch 16.067), train_loss = 0.89031991, grad/param norm = 5.3326e-02, time/batch = 0.2589s	
1688/5250 (epoch 16.076), train_loss = 0.90471660, grad/param norm = 5.7276e-02, time/batch = 0.2591s	
1689/5250 (epoch 16.086), train_loss = 0.88985227, grad/param norm = 5.4142e-02, time/batch = 0.2591s	
1690/5250 (epoch 16.095), train_loss = 0.89133215, grad/param norm = 5.3727e-02, time/batch = 0.2590s	
1691/5250 (epoch 16.105), train_loss = 0.90337879, grad/param norm = 5.6715e-02, time/batch = 0.2594s	
1692/5250 (epoch 16.114), train_loss = 0.88502177, grad/param norm = 5.6233e-02, time/batch = 0.2590s	
1693/5250 (epoch 16.124), train_loss = 0.91423805, grad/param norm = 5.8171e-02, time/batch = 0.2590s	
1694/5250 (epoch 16.133), train_loss = 0.89263644, grad/param norm = 5.2510e-02, time/batch = 0.2594s	
1695/5250 (epoch 16.143), train_loss = 0.87493853, grad/param norm = 5.2966e-02, time/batch = 0.2592s	
1696/5250 (epoch 16.152), train_loss = 0.86903990, grad/param norm = 5.4353e-02, time/batch = 0.2592s	
1697/5250 (epoch 16.162), train_loss = 0.88833656, grad/param norm = 5.6863e-02, time/batch = 0.2592s	
1698/5250 (epoch 16.171), train_loss = 0.88387778, grad/param norm = 5.3613e-02, time/batch = 0.2591s	
1699/5250 (epoch 16.181), train_loss = 0.88810915, grad/param norm = 5.4461e-02, time/batch = 0.2590s	
1700/5250 (epoch 16.190), train_loss = 0.89707854, grad/param norm = 5.8098e-02, time/batch = 0.2594s	
1701/5250 (epoch 16.200), train_loss = 0.90435172, grad/param norm = 5.9443e-02, time/batch = 0.2596s	
1702/5250 (epoch 16.210), train_loss = 0.89331335, grad/param norm = 5.6080e-02, time/batch = 0.2594s	
1703/5250 (epoch 16.219), train_loss = 0.91451222, grad/param norm = 5.8138e-02, time/batch = 0.2593s	
1704/5250 (epoch 16.229), train_loss = 0.89230552, grad/param norm = 5.7127e-02, time/batch = 0.2594s	
1705/5250 (epoch 16.238), train_loss = 0.88720288, grad/param norm = 5.6637e-02, time/batch = 0.2591s	
1706/5250 (epoch 16.248), train_loss = 0.89798698, grad/param norm = 6.0525e-02, time/batch = 0.2596s	
1707/5250 (epoch 16.257), train_loss = 0.89967370, grad/param norm = 5.9024e-02, time/batch = 0.2593s	
1708/5250 (epoch 16.267), train_loss = 0.89122336, grad/param norm = 5.5343e-02, time/batch = 0.2589s	
1709/5250 (epoch 16.276), train_loss = 0.88532617, grad/param norm = 5.4868e-02, time/batch = 0.2592s	
1710/5250 (epoch 16.286), train_loss = 0.87563945, grad/param norm = 5.3293e-02, time/batch = 0.2593s	
1711/5250 (epoch 16.295), train_loss = 0.88148317, grad/param norm = 5.6473e-02, time/batch = 0.2590s	
1712/5250 (epoch 16.305), train_loss = 0.87246665, grad/param norm = 5.5119e-02, time/batch = 0.2592s	
1713/5250 (epoch 16.314), train_loss = 0.86282416, grad/param norm = 5.5624e-02, time/batch = 0.2589s	
1714/5250 (epoch 16.324), train_loss = 0.88384216, grad/param norm = 5.5660e-02, time/batch = 0.2589s	
1715/5250 (epoch 16.333), train_loss = 0.88183503, grad/param norm = 5.6563e-02, time/batch = 0.2591s	
1716/5250 (epoch 16.343), train_loss = 0.88271760, grad/param norm = 5.7468e-02, time/batch = 0.2592s	
1717/5250 (epoch 16.352), train_loss = 0.89217212, grad/param norm = 6.4526e-02, time/batch = 0.2594s	
1718/5250 (epoch 16.362), train_loss = 0.90010344, grad/param norm = 6.6567e-02, time/batch = 0.2593s	
1719/5250 (epoch 16.371), train_loss = 0.91253724, grad/param norm = 7.3022e-02, time/batch = 0.2594s	
1720/5250 (epoch 16.381), train_loss = 0.89870162, grad/param norm = 5.5882e-02, time/batch = 0.2590s	
1721/5250 (epoch 16.390), train_loss = 0.86699091, grad/param norm = 5.4915e-02, time/batch = 0.2593s	
1722/5250 (epoch 16.400), train_loss = 0.88428916, grad/param norm = 6.0673e-02, time/batch = 0.2587s	
1723/5250 (epoch 16.410), train_loss = 0.89455481, grad/param norm = 6.4046e-02, time/batch = 0.2593s	
1724/5250 (epoch 16.419), train_loss = 0.89985990, grad/param norm = 6.0310e-02, time/batch = 0.2593s	
1725/5250 (epoch 16.429), train_loss = 0.89568838, grad/param norm = 5.9902e-02, time/batch = 0.2595s	
1726/5250 (epoch 16.438), train_loss = 0.90297683, grad/param norm = 5.8640e-02, time/batch = 0.2591s	
1727/5250 (epoch 16.448), train_loss = 0.86846822, grad/param norm = 5.3404e-02, time/batch = 0.2590s	
1728/5250 (epoch 16.457), train_loss = 0.88802102, grad/param norm = 5.8376e-02, time/batch = 0.2589s	
1729/5250 (epoch 16.467), train_loss = 0.88347802, grad/param norm = 5.6813e-02, time/batch = 0.2591s	
1730/5250 (epoch 16.476), train_loss = 0.86872688, grad/param norm = 5.7436e-02, time/batch = 0.2590s	
1731/5250 (epoch 16.486), train_loss = 0.89750453, grad/param norm = 6.4078e-02, time/batch = 0.2592s	
1732/5250 (epoch 16.495), train_loss = 0.91227288, grad/param norm = 6.1998e-02, time/batch = 0.2589s	
1733/5250 (epoch 16.505), train_loss = 0.90462149, grad/param norm = 5.9384e-02, time/batch = 0.2591s	
1734/5250 (epoch 16.514), train_loss = 0.91340907, grad/param norm = 6.5398e-02, time/batch = 0.2594s	
1735/5250 (epoch 16.524), train_loss = 0.91561862, grad/param norm = 6.4967e-02, time/batch = 0.2586s	
1736/5250 (epoch 16.533), train_loss = 0.89840344, grad/param norm = 6.0476e-02, time/batch = 0.2590s	
1737/5250 (epoch 16.543), train_loss = 0.89315347, grad/param norm = 6.2376e-02, time/batch = 0.2589s	
1738/5250 (epoch 16.552), train_loss = 0.89271195, grad/param norm = 6.2171e-02, time/batch = 0.2593s	
1739/5250 (epoch 16.562), train_loss = 0.88911697, grad/param norm = 5.9876e-02, time/batch = 0.2596s	
1740/5250 (epoch 16.571), train_loss = 0.89017536, grad/param norm = 5.6875e-02, time/batch = 0.2592s	
1741/5250 (epoch 16.581), train_loss = 0.89284676, grad/param norm = 5.8706e-02, time/batch = 0.2594s	
1742/5250 (epoch 16.590), train_loss = 0.87449460, grad/param norm = 5.5569e-02, time/batch = 0.2592s	
1743/5250 (epoch 16.600), train_loss = 0.89446403, grad/param norm = 6.0609e-02, time/batch = 0.2592s	
1744/5250 (epoch 16.610), train_loss = 0.89946870, grad/param norm = 5.8836e-02, time/batch = 0.2592s	
1745/5250 (epoch 16.619), train_loss = 0.89878067, grad/param norm = 5.5724e-02, time/batch = 0.2594s	
1746/5250 (epoch 16.629), train_loss = 0.87875292, grad/param norm = 5.6780e-02, time/batch = 0.2595s	
1747/5250 (epoch 16.638), train_loss = 0.87391065, grad/param norm = 6.0887e-02, time/batch = 0.2589s	
1748/5250 (epoch 16.648), train_loss = 0.90392308, grad/param norm = 5.8473e-02, time/batch = 0.2591s	
1749/5250 (epoch 16.657), train_loss = 0.89377381, grad/param norm = 6.1064e-02, time/batch = 0.2593s	
1750/5250 (epoch 16.667), train_loss = 0.89354712, grad/param norm = 6.1833e-02, time/batch = 0.2590s	
1751/5250 (epoch 16.676), train_loss = 0.87999958, grad/param norm = 6.2906e-02, time/batch = 0.2590s	
1752/5250 (epoch 16.686), train_loss = 0.88412398, grad/param norm = 6.2484e-02, time/batch = 0.2591s	
1753/5250 (epoch 16.695), train_loss = 0.87426281, grad/param norm = 5.8166e-02, time/batch = 0.2598s	
1754/5250 (epoch 16.705), train_loss = 0.86214218, grad/param norm = 5.7212e-02, time/batch = 0.2591s	
1755/5250 (epoch 16.714), train_loss = 0.89208819, grad/param norm = 6.1250e-02, time/batch = 0.2589s	
1756/5250 (epoch 16.724), train_loss = 0.87490410, grad/param norm = 5.5798e-02, time/batch = 0.2588s	
1757/5250 (epoch 16.733), train_loss = 0.86222033, grad/param norm = 5.8533e-02, time/batch = 0.2595s	
1758/5250 (epoch 16.743), train_loss = 0.86725908, grad/param norm = 5.9793e-02, time/batch = 0.2592s	
1759/5250 (epoch 16.752), train_loss = 0.87551406, grad/param norm = 6.4935e-02, time/batch = 0.2591s	
1760/5250 (epoch 16.762), train_loss = 0.87514951, grad/param norm = 5.4910e-02, time/batch = 0.2595s	
1761/5250 (epoch 16.771), train_loss = 0.86187823, grad/param norm = 5.6015e-02, time/batch = 0.2593s	
1762/5250 (epoch 16.781), train_loss = 0.87701053, grad/param norm = 5.5629e-02, time/batch = 0.2590s	
1763/5250 (epoch 16.790), train_loss = 0.88481855, grad/param norm = 6.3523e-02, time/batch = 0.2593s	
1764/5250 (epoch 16.800), train_loss = 0.87546188, grad/param norm = 6.2387e-02, time/batch = 0.2591s	
1765/5250 (epoch 16.810), train_loss = 0.87982882, grad/param norm = 5.8905e-02, time/batch = 0.2587s	
1766/5250 (epoch 16.819), train_loss = 0.88415153, grad/param norm = 6.2215e-02, time/batch = 0.2589s	
1767/5250 (epoch 16.829), train_loss = 0.88326294, grad/param norm = 5.8607e-02, time/batch = 0.2589s	
1768/5250 (epoch 16.838), train_loss = 0.84464713, grad/param norm = 5.7316e-02, time/batch = 0.2595s	
1769/5250 (epoch 16.848), train_loss = 0.86001556, grad/param norm = 6.3860e-02, time/batch = 0.2594s	
1770/5250 (epoch 16.857), train_loss = 0.88905019, grad/param norm = 6.5343e-02, time/batch = 0.2588s	
1771/5250 (epoch 16.867), train_loss = 0.86692894, grad/param norm = 6.1017e-02, time/batch = 0.2594s	
1772/5250 (epoch 16.876), train_loss = 0.86534188, grad/param norm = 5.9733e-02, time/batch = 0.2590s	
1773/5250 (epoch 16.886), train_loss = 0.87891072, grad/param norm = 5.5380e-02, time/batch = 0.2596s	
1774/5250 (epoch 16.895), train_loss = 0.87171646, grad/param norm = 5.8206e-02, time/batch = 0.2592s	
1775/5250 (epoch 16.905), train_loss = 0.88526971, grad/param norm = 6.2454e-02, time/batch = 0.2592s	
1776/5250 (epoch 16.914), train_loss = 0.89861020, grad/param norm = 6.7070e-02, time/batch = 0.2591s	
1777/5250 (epoch 16.924), train_loss = 0.88785989, grad/param norm = 6.6415e-02, time/batch = 0.2587s	
1778/5250 (epoch 16.933), train_loss = 0.88337926, grad/param norm = 6.0173e-02, time/batch = 0.2590s	
1779/5250 (epoch 16.943), train_loss = 0.89187417, grad/param norm = 6.1768e-02, time/batch = 0.2587s	
1780/5250 (epoch 16.952), train_loss = 0.89524131, grad/param norm = 6.3406e-02, time/batch = 0.2591s	
1781/5250 (epoch 16.962), train_loss = 0.86948459, grad/param norm = 6.1545e-02, time/batch = 0.2592s	
1782/5250 (epoch 16.971), train_loss = 0.88146356, grad/param norm = 5.6644e-02, time/batch = 0.2592s	
1783/5250 (epoch 16.981), train_loss = 0.87584316, grad/param norm = 5.5856e-02, time/batch = 0.2594s	
1784/5250 (epoch 16.990), train_loss = 0.87752093, grad/param norm = 5.9768e-02, time/batch = 0.2593s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
1785/5250 (epoch 17.000), train_loss = 0.86908072, grad/param norm = 5.9347e-02, time/batch = 0.2590s	
1786/5250 (epoch 17.010), train_loss = 1.06248296, grad/param norm = 6.9577e-02, time/batch = 0.2590s	
1787/5250 (epoch 17.019), train_loss = 0.88114344, grad/param norm = 6.4856e-02, time/batch = 0.2589s	
1788/5250 (epoch 17.029), train_loss = 0.88436121, grad/param norm = 5.9765e-02, time/batch = 0.2593s	
1789/5250 (epoch 17.038), train_loss = 0.85531135, grad/param norm = 5.5822e-02, time/batch = 0.2593s	
1790/5250 (epoch 17.048), train_loss = 0.84595592, grad/param norm = 5.4846e-02, time/batch = 0.2593s	
1791/5250 (epoch 17.057), train_loss = 0.84288625, grad/param norm = 5.5174e-02, time/batch = 0.2595s	
1792/5250 (epoch 17.067), train_loss = 0.85820142, grad/param norm = 6.2605e-02, time/batch = 0.2590s	
1793/5250 (epoch 17.076), train_loss = 0.86869529, grad/param norm = 6.5501e-02, time/batch = 0.2595s	
1794/5250 (epoch 17.086), train_loss = 0.85622280, grad/param norm = 5.9594e-02, time/batch = 0.2594s	
1795/5250 (epoch 17.095), train_loss = 0.85260412, grad/param norm = 5.4885e-02, time/batch = 0.2591s	
1796/5250 (epoch 17.105), train_loss = 0.85754714, grad/param norm = 5.6068e-02, time/batch = 0.2589s	
1797/5250 (epoch 17.114), train_loss = 0.84144236, grad/param norm = 5.7394e-02, time/batch = 0.2587s	
1798/5250 (epoch 17.124), train_loss = 0.88671368, grad/param norm = 6.7283e-02, time/batch = 0.2591s	
1799/5250 (epoch 17.133), train_loss = 0.87779429, grad/param norm = 6.6972e-02, time/batch = 0.2592s	
1800/5250 (epoch 17.143), train_loss = 0.84854368, grad/param norm = 5.8414e-02, time/batch = 0.2591s	
1801/5250 (epoch 17.152), train_loss = 0.82781312, grad/param norm = 5.6676e-02, time/batch = 0.2592s	
1802/5250 (epoch 17.162), train_loss = 0.84895890, grad/param norm = 5.8525e-02, time/batch = 0.2588s	
1803/5250 (epoch 17.171), train_loss = 0.84657367, grad/param norm = 6.1346e-02, time/batch = 0.2590s	
1804/5250 (epoch 17.181), train_loss = 0.85452187, grad/param norm = 5.6563e-02, time/batch = 0.2591s	
1805/5250 (epoch 17.190), train_loss = 0.84647838, grad/param norm = 5.3995e-02, time/batch = 0.2598s	
1806/5250 (epoch 17.200), train_loss = 0.84519660, grad/param norm = 5.5336e-02, time/batch = 0.2594s	
1807/5250 (epoch 17.210), train_loss = 0.86211376, grad/param norm = 6.2373e-02, time/batch = 0.2590s	
1808/5250 (epoch 17.219), train_loss = 0.87541322, grad/param norm = 6.1502e-02, time/batch = 0.2592s	
1809/5250 (epoch 17.229), train_loss = 0.86561225, grad/param norm = 6.2773e-02, time/batch = 0.2597s	
1810/5250 (epoch 17.238), train_loss = 0.85550706, grad/param norm = 6.3261e-02, time/batch = 0.2595s	
1811/5250 (epoch 17.248), train_loss = 0.86097299, grad/param norm = 6.2543e-02, time/batch = 0.2593s	
1812/5250 (epoch 17.257), train_loss = 0.85629501, grad/param norm = 5.7012e-02, time/batch = 0.2591s	
1813/5250 (epoch 17.267), train_loss = 0.85201411, grad/param norm = 5.8223e-02, time/batch = 0.2590s	
1814/5250 (epoch 17.276), train_loss = 0.84554099, grad/param norm = 5.6412e-02, time/batch = 0.2589s	
1815/5250 (epoch 17.286), train_loss = 0.84748159, grad/param norm = 6.0457e-02, time/batch = 0.2595s	
1816/5250 (epoch 17.295), train_loss = 0.85359256, grad/param norm = 6.1061e-02, time/batch = 0.2589s	
1817/5250 (epoch 17.305), train_loss = 0.83633327, grad/param norm = 6.1595e-02, time/batch = 0.2591s	
1818/5250 (epoch 17.314), train_loss = 0.82922615, grad/param norm = 5.9840e-02, time/batch = 0.2592s	
1819/5250 (epoch 17.324), train_loss = 0.84585048, grad/param norm = 6.0840e-02, time/batch = 0.2592s	
1820/5250 (epoch 17.333), train_loss = 0.84595244, grad/param norm = 5.9206e-02, time/batch = 0.2594s	
1821/5250 (epoch 17.343), train_loss = 0.83883813, grad/param norm = 5.8967e-02, time/batch = 0.2592s	
1822/5250 (epoch 17.352), train_loss = 0.84154285, grad/param norm = 5.8512e-02, time/batch = 0.2591s	
1823/5250 (epoch 17.362), train_loss = 0.85061838, grad/param norm = 6.4995e-02, time/batch = 0.2592s	
1824/5250 (epoch 17.371), train_loss = 0.85485379, grad/param norm = 6.2447e-02, time/batch = 0.2592s	
1825/5250 (epoch 17.381), train_loss = 0.86872339, grad/param norm = 6.6395e-02, time/batch = 0.2593s	
1826/5250 (epoch 17.390), train_loss = 0.84300865, grad/param norm = 6.3505e-02, time/batch = 0.2592s	
1827/5250 (epoch 17.400), train_loss = 0.85367928, grad/param norm = 6.5061e-02, time/batch = 0.2591s	
1828/5250 (epoch 17.410), train_loss = 0.84975440, grad/param norm = 6.5591e-02, time/batch = 0.2593s	
1829/5250 (epoch 17.419), train_loss = 0.86327618, grad/param norm = 6.4128e-02, time/batch = 0.2591s	
1830/5250 (epoch 17.429), train_loss = 0.86580222, grad/param norm = 6.3467e-02, time/batch = 0.2595s	
1831/5250 (epoch 17.438), train_loss = 0.86419503, grad/param norm = 5.8572e-02, time/batch = 0.2592s	
1832/5250 (epoch 17.448), train_loss = 0.82844600, grad/param norm = 5.6558e-02, time/batch = 0.2594s	
1833/5250 (epoch 17.457), train_loss = 0.83909323, grad/param norm = 5.6672e-02, time/batch = 0.2593s	
1834/5250 (epoch 17.467), train_loss = 0.84411154, grad/param norm = 6.0270e-02, time/batch = 0.2593s	
1835/5250 (epoch 17.476), train_loss = 0.83584018, grad/param norm = 6.3458e-02, time/batch = 0.2585s	
1836/5250 (epoch 17.486), train_loss = 0.84855026, grad/param norm = 6.1736e-02, time/batch = 0.2590s	
1837/5250 (epoch 17.495), train_loss = 0.85525005, grad/param norm = 5.6579e-02, time/batch = 0.2593s	
1838/5250 (epoch 17.505), train_loss = 0.85942387, grad/param norm = 6.1065e-02, time/batch = 0.2589s	
1839/5250 (epoch 17.514), train_loss = 0.86698179, grad/param norm = 6.2194e-02, time/batch = 0.2590s	
1840/5250 (epoch 17.524), train_loss = 0.85437240, grad/param norm = 5.9324e-02, time/batch = 0.2592s	
1841/5250 (epoch 17.533), train_loss = 0.85923165, grad/param norm = 6.2132e-02, time/batch = 0.2595s	
1842/5250 (epoch 17.543), train_loss = 0.84387861, grad/param norm = 6.3035e-02, time/batch = 0.2589s	
1843/5250 (epoch 17.552), train_loss = 0.84919754, grad/param norm = 6.0838e-02, time/batch = 0.2592s	
1844/5250 (epoch 17.562), train_loss = 0.83512345, grad/param norm = 5.6777e-02, time/batch = 0.2590s	
1845/5250 (epoch 17.571), train_loss = 0.84879327, grad/param norm = 6.0767e-02, time/batch = 0.2588s	
1846/5250 (epoch 17.581), train_loss = 0.84965519, grad/param norm = 5.9524e-02, time/batch = 0.2594s	
1847/5250 (epoch 17.590), train_loss = 0.83428794, grad/param norm = 6.0860e-02, time/batch = 0.2589s	
1848/5250 (epoch 17.600), train_loss = 0.85649396, grad/param norm = 6.4065e-02, time/batch = 0.2591s	
1849/5250 (epoch 17.610), train_loss = 0.85461503, grad/param norm = 6.1355e-02, time/batch = 0.2587s	
1850/5250 (epoch 17.619), train_loss = 0.85736670, grad/param norm = 6.0383e-02, time/batch = 0.2592s	
1851/5250 (epoch 17.629), train_loss = 0.83631879, grad/param norm = 5.6751e-02, time/batch = 0.2591s	
1852/5250 (epoch 17.638), train_loss = 0.82658144, grad/param norm = 5.6569e-02, time/batch = 0.2589s	
1853/5250 (epoch 17.648), train_loss = 0.86349267, grad/param norm = 6.2507e-02, time/batch = 0.2591s	
1854/5250 (epoch 17.657), train_loss = 0.84632280, grad/param norm = 6.2369e-02, time/batch = 0.2592s	
1855/5250 (epoch 17.667), train_loss = 0.84795617, grad/param norm = 6.1335e-02, time/batch = 0.2593s	
1856/5250 (epoch 17.676), train_loss = 0.83453866, grad/param norm = 6.2393e-02, time/batch = 0.2592s	
1857/5250 (epoch 17.686), train_loss = 0.84353262, grad/param norm = 6.3130e-02, time/batch = 0.2590s	
1858/5250 (epoch 17.695), train_loss = 0.84805486, grad/param norm = 6.6205e-02, time/batch = 0.2588s	
1859/5250 (epoch 17.705), train_loss = 0.84004372, grad/param norm = 6.3213e-02, time/batch = 0.2589s	
1860/5250 (epoch 17.714), train_loss = 0.85488990, grad/param norm = 6.5889e-02, time/batch = 0.2591s	
1861/5250 (epoch 17.724), train_loss = 0.84138351, grad/param norm = 6.2921e-02, time/batch = 0.2593s	
1862/5250 (epoch 17.733), train_loss = 0.83057337, grad/param norm = 6.2285e-02, time/batch = 0.2587s	
1863/5250 (epoch 17.743), train_loss = 0.83237872, grad/param norm = 6.0479e-02, time/batch = 0.2587s	
1864/5250 (epoch 17.752), train_loss = 0.83955602, grad/param norm = 6.5058e-02, time/batch = 0.2589s	
1865/5250 (epoch 17.762), train_loss = 0.84324187, grad/param norm = 6.0258e-02, time/batch = 0.2594s	
1866/5250 (epoch 17.771), train_loss = 0.83078035, grad/param norm = 5.9089e-02, time/batch = 0.2593s	
1867/5250 (epoch 17.781), train_loss = 0.83852029, grad/param norm = 6.2437e-02, time/batch = 0.2591s	
1868/5250 (epoch 17.790), train_loss = 0.84676266, grad/param norm = 6.2308e-02, time/batch = 0.2591s	
1869/5250 (epoch 17.800), train_loss = 0.83037217, grad/param norm = 6.3068e-02, time/batch = 0.2594s	
1870/5250 (epoch 17.810), train_loss = 0.84980063, grad/param norm = 6.6857e-02, time/batch = 0.2593s	
1871/5250 (epoch 17.819), train_loss = 0.85409565, grad/param norm = 6.8143e-02, time/batch = 0.2591s	
1872/5250 (epoch 17.829), train_loss = 0.84409112, grad/param norm = 6.0495e-02, time/batch = 0.2589s	
1873/5250 (epoch 17.838), train_loss = 0.81457726, grad/param norm = 6.2133e-02, time/batch = 0.2592s	
1874/5250 (epoch 17.848), train_loss = 0.81910366, grad/param norm = 6.3249e-02, time/batch = 0.2595s	
1875/5250 (epoch 17.857), train_loss = 0.83887383, grad/param norm = 6.4854e-02, time/batch = 0.2591s	
1876/5250 (epoch 17.867), train_loss = 0.82625594, grad/param norm = 6.0413e-02, time/batch = 0.2593s	
1877/5250 (epoch 17.876), train_loss = 0.83353922, grad/param norm = 7.0491e-02, time/batch = 0.2590s	
1878/5250 (epoch 17.886), train_loss = 0.84739322, grad/param norm = 6.2130e-02, time/batch = 0.2593s	
1879/5250 (epoch 17.895), train_loss = 0.83409627, grad/param norm = 6.0112e-02, time/batch = 0.2590s	
1880/5250 (epoch 17.905), train_loss = 0.83618248, grad/param norm = 6.1414e-02, time/batch = 0.2591s	
1881/5250 (epoch 17.914), train_loss = 0.84410813, grad/param norm = 6.3008e-02, time/batch = 0.2592s	
1882/5250 (epoch 17.924), train_loss = 0.83918864, grad/param norm = 6.5272e-02, time/batch = 0.2591s	
1883/5250 (epoch 17.933), train_loss = 0.84605027, grad/param norm = 6.5361e-02, time/batch = 0.2591s	
1884/5250 (epoch 17.943), train_loss = 0.85044261, grad/param norm = 6.2157e-02, time/batch = 0.2594s	
1885/5250 (epoch 17.952), train_loss = 0.84896850, grad/param norm = 6.1961e-02, time/batch = 0.2591s	
1886/5250 (epoch 17.962), train_loss = 0.82289055, grad/param norm = 5.9878e-02, time/batch = 0.2587s	
1887/5250 (epoch 17.971), train_loss = 0.84308368, grad/param norm = 6.1522e-02, time/batch = 0.2592s	
1888/5250 (epoch 17.981), train_loss = 0.84316183, grad/param norm = 6.3963e-02, time/batch = 0.2593s	
1889/5250 (epoch 17.990), train_loss = 0.83940714, grad/param norm = 6.2916e-02, time/batch = 0.2591s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
1890/5250 (epoch 18.000), train_loss = 0.82795930, grad/param norm = 6.3249e-02, time/batch = 0.2593s	
1891/5250 (epoch 18.010), train_loss = 1.01588755, grad/param norm = 6.5713e-02, time/batch = 0.2590s	
1892/5250 (epoch 18.019), train_loss = 0.83991428, grad/param norm = 6.4775e-02, time/batch = 0.2590s	
1893/5250 (epoch 18.029), train_loss = 0.83768164, grad/param norm = 6.1500e-02, time/batch = 0.2589s	
1894/5250 (epoch 18.038), train_loss = 0.82633252, grad/param norm = 6.1788e-02, time/batch = 0.2593s	
1895/5250 (epoch 18.048), train_loss = 0.81483781, grad/param norm = 6.1321e-02, time/batch = 0.2594s	
1896/5250 (epoch 18.057), train_loss = 0.80731535, grad/param norm = 5.7821e-02, time/batch = 0.2590s	
1897/5250 (epoch 18.067), train_loss = 0.81746995, grad/param norm = 6.2193e-02, time/batch = 0.2590s	
1898/5250 (epoch 18.076), train_loss = 0.82620572, grad/param norm = 6.4381e-02, time/batch = 0.2593s	
1899/5250 (epoch 18.086), train_loss = 0.82318285, grad/param norm = 6.1898e-02, time/batch = 0.2590s	
1900/5250 (epoch 18.095), train_loss = 0.82094072, grad/param norm = 6.1261e-02, time/batch = 0.2588s	
1901/5250 (epoch 18.105), train_loss = 0.82529585, grad/param norm = 6.0266e-02, time/batch = 0.2589s	
1902/5250 (epoch 18.114), train_loss = 0.80586524, grad/param norm = 5.7579e-02, time/batch = 0.2593s	
1903/5250 (epoch 18.124), train_loss = 0.83612865, grad/param norm = 6.3148e-02, time/batch = 0.2591s	
1904/5250 (epoch 18.133), train_loss = 0.83168481, grad/param norm = 6.2788e-02, time/batch = 0.2591s	
1905/5250 (epoch 18.143), train_loss = 0.81538609, grad/param norm = 6.0609e-02, time/batch = 0.2587s	
1906/5250 (epoch 18.152), train_loss = 0.79860743, grad/param norm = 5.8719e-02, time/batch = 0.2590s	
1907/5250 (epoch 18.162), train_loss = 0.80783595, grad/param norm = 5.9753e-02, time/batch = 0.2594s	
1908/5250 (epoch 18.171), train_loss = 0.81043181, grad/param norm = 6.1309e-02, time/batch = 0.2592s	
1909/5250 (epoch 18.181), train_loss = 0.82018584, grad/param norm = 6.3151e-02, time/batch = 0.2594s	
1910/5250 (epoch 18.190), train_loss = 0.80916115, grad/param norm = 5.8642e-02, time/batch = 0.2591s	
1911/5250 (epoch 18.200), train_loss = 0.81017731, grad/param norm = 6.0895e-02, time/batch = 0.2595s	
1912/5250 (epoch 18.210), train_loss = 0.81386367, grad/param norm = 6.1023e-02, time/batch = 0.2588s	
1913/5250 (epoch 18.219), train_loss = 0.82727453, grad/param norm = 6.1412e-02, time/batch = 0.2593s	
1914/5250 (epoch 18.229), train_loss = 0.81580739, grad/param norm = 6.1928e-02, time/batch = 0.2591s	
1915/5250 (epoch 18.238), train_loss = 0.81420284, grad/param norm = 6.0913e-02, time/batch = 0.2590s	
1916/5250 (epoch 18.248), train_loss = 0.81448036, grad/param norm = 6.2437e-02, time/batch = 0.2592s	
1917/5250 (epoch 18.257), train_loss = 0.82066728, grad/param norm = 5.9913e-02, time/batch = 0.2594s	
1918/5250 (epoch 18.267), train_loss = 0.81328891, grad/param norm = 5.7633e-02, time/batch = 0.2593s	
1919/5250 (epoch 18.276), train_loss = 0.80580742, grad/param norm = 5.8011e-02, time/batch = 0.2594s	
1920/5250 (epoch 18.286), train_loss = 0.80101123, grad/param norm = 5.8151e-02, time/batch = 0.2591s	
1921/5250 (epoch 18.295), train_loss = 0.80243047, grad/param norm = 5.7026e-02, time/batch = 0.2590s	
1922/5250 (epoch 18.305), train_loss = 0.80167840, grad/param norm = 7.0465e-02, time/batch = 0.2589s	
1923/5250 (epoch 18.314), train_loss = 0.79946548, grad/param norm = 6.6009e-02, time/batch = 0.2592s	
1924/5250 (epoch 18.324), train_loss = 0.80943329, grad/param norm = 6.2184e-02, time/batch = 0.2590s	
1925/5250 (epoch 18.333), train_loss = 0.80981491, grad/param norm = 6.6575e-02, time/batch = 0.2591s	
1926/5250 (epoch 18.343), train_loss = 0.80434392, grad/param norm = 6.3518e-02, time/batch = 0.2591s	
1927/5250 (epoch 18.352), train_loss = 0.79586491, grad/param norm = 6.2401e-02, time/batch = 0.2594s	
1928/5250 (epoch 18.362), train_loss = 0.81599203, grad/param norm = 6.5753e-02, time/batch = 0.2594s	
1929/5250 (epoch 18.371), train_loss = 0.81819213, grad/param norm = 6.8472e-02, time/batch = 0.2589s	
1930/5250 (epoch 18.381), train_loss = 0.83165602, grad/param norm = 6.4851e-02, time/batch = 0.2594s	
1931/5250 (epoch 18.390), train_loss = 0.80762428, grad/param norm = 6.3988e-02, time/batch = 0.2588s	
1932/5250 (epoch 18.400), train_loss = 0.81129910, grad/param norm = 6.3821e-02, time/batch = 0.2591s	
1933/5250 (epoch 18.410), train_loss = 0.80853229, grad/param norm = 6.8268e-02, time/batch = 0.2593s	
1934/5250 (epoch 18.419), train_loss = 0.81942957, grad/param norm = 6.7141e-02, time/batch = 0.2591s	
1935/5250 (epoch 18.429), train_loss = 0.82125685, grad/param norm = 6.5041e-02, time/batch = 0.2592s	
1936/5250 (epoch 18.438), train_loss = 0.82708784, grad/param norm = 6.0928e-02, time/batch = 0.2593s	
1937/5250 (epoch 18.448), train_loss = 0.79469268, grad/param norm = 6.0767e-02, time/batch = 0.2591s	
1938/5250 (epoch 18.457), train_loss = 0.79673329, grad/param norm = 5.6641e-02, time/batch = 0.2588s	
1939/5250 (epoch 18.467), train_loss = 0.80088340, grad/param norm = 6.0883e-02, time/batch = 0.2593s	
1940/5250 (epoch 18.476), train_loss = 0.78485703, grad/param norm = 5.8052e-02, time/batch = 0.2593s	
1941/5250 (epoch 18.486), train_loss = 0.79892481, grad/param norm = 6.2013e-02, time/batch = 0.2596s	
1942/5250 (epoch 18.495), train_loss = 0.82723412, grad/param norm = 6.5806e-02, time/batch = 0.2591s	
1943/5250 (epoch 18.505), train_loss = 0.83384968, grad/param norm = 6.7046e-02, time/batch = 0.2594s	
1944/5250 (epoch 18.514), train_loss = 0.82498310, grad/param norm = 6.4580e-02, time/batch = 0.2592s	
1945/5250 (epoch 18.524), train_loss = 0.82606707, grad/param norm = 6.9569e-02, time/batch = 0.2592s	
1946/5250 (epoch 18.533), train_loss = 0.82811576, grad/param norm = 6.9006e-02, time/batch = 0.2592s	
1947/5250 (epoch 18.543), train_loss = 0.80736966, grad/param norm = 6.1898e-02, time/batch = 0.2578s	
1948/5250 (epoch 18.552), train_loss = 0.81457777, grad/param norm = 6.7006e-02, time/batch = 0.2598s	
1949/5250 (epoch 18.562), train_loss = 0.81363731, grad/param norm = 6.2240e-02, time/batch = 0.2593s	
1950/5250 (epoch 18.571), train_loss = 0.81467432, grad/param norm = 6.6101e-02, time/batch = 0.2590s	
1951/5250 (epoch 18.581), train_loss = 0.81854428, grad/param norm = 6.4045e-02, time/batch = 0.2590s	
1952/5250 (epoch 18.590), train_loss = 0.80968249, grad/param norm = 6.7359e-02, time/batch = 0.2594s	
1953/5250 (epoch 18.600), train_loss = 0.81478420, grad/param norm = 6.2597e-02, time/batch = 0.2596s	
1954/5250 (epoch 18.610), train_loss = 0.81608413, grad/param norm = 6.5630e-02, time/batch = 0.2590s	
1955/5250 (epoch 18.619), train_loss = 0.82753128, grad/param norm = 6.4695e-02, time/batch = 0.2595s	
1956/5250 (epoch 18.629), train_loss = 0.80962343, grad/param norm = 6.3718e-02, time/batch = 0.2590s	
1957/5250 (epoch 18.638), train_loss = 0.80512896, grad/param norm = 6.4151e-02, time/batch = 0.2593s	
1958/5250 (epoch 18.648), train_loss = 0.82344463, grad/param norm = 6.2663e-02, time/batch = 0.2592s	
1959/5250 (epoch 18.657), train_loss = 0.81031274, grad/param norm = 6.3222e-02, time/batch = 0.2592s	
1960/5250 (epoch 18.667), train_loss = 0.81781254, grad/param norm = 6.4868e-02, time/batch = 0.2594s	
1961/5250 (epoch 18.676), train_loss = 0.79746329, grad/param norm = 6.3534e-02, time/batch = 0.2593s	
1962/5250 (epoch 18.686), train_loss = 0.80522859, grad/param norm = 6.5942e-02, time/batch = 0.2587s	
1963/5250 (epoch 18.695), train_loss = 0.80142138, grad/param norm = 6.4608e-02, time/batch = 0.2588s	
1964/5250 (epoch 18.705), train_loss = 0.79794140, grad/param norm = 6.4256e-02, time/batch = 0.2594s	
1965/5250 (epoch 18.714), train_loss = 0.81798503, grad/param norm = 6.8400e-02, time/batch = 0.2590s	
1966/5250 (epoch 18.724), train_loss = 0.80392600, grad/param norm = 6.2747e-02, time/batch = 0.2592s	
1967/5250 (epoch 18.733), train_loss = 0.77746577, grad/param norm = 6.0974e-02, time/batch = 0.2590s	
1968/5250 (epoch 18.743), train_loss = 0.79648012, grad/param norm = 6.4675e-02, time/batch = 0.2594s	
1969/5250 (epoch 18.752), train_loss = 0.80322553, grad/param norm = 6.8877e-02, time/batch = 0.2591s	
1970/5250 (epoch 18.762), train_loss = 0.80564718, grad/param norm = 6.5835e-02, time/batch = 0.2588s	
1971/5250 (epoch 18.771), train_loss = 0.79219218, grad/param norm = 6.0118e-02, time/batch = 0.2592s	
1972/5250 (epoch 18.781), train_loss = 0.79945656, grad/param norm = 6.0223e-02, time/batch = 0.2591s	
1973/5250 (epoch 18.790), train_loss = 0.80395668, grad/param norm = 6.4199e-02, time/batch = 0.2593s	
1974/5250 (epoch 18.800), train_loss = 0.79092531, grad/param norm = 6.2434e-02, time/batch = 0.2591s	
1975/5250 (epoch 18.810), train_loss = 0.80429030, grad/param norm = 6.4089e-02, time/batch = 0.2593s	
1976/5250 (epoch 18.819), train_loss = 0.80670616, grad/param norm = 6.1110e-02, time/batch = 0.2591s	
1977/5250 (epoch 18.829), train_loss = 0.81041034, grad/param norm = 7.2136e-02, time/batch = 0.2594s	
1978/5250 (epoch 18.838), train_loss = 0.79112152, grad/param norm = 7.0527e-02, time/batch = 0.2586s	
1979/5250 (epoch 18.848), train_loss = 0.78375042, grad/param norm = 6.4674e-02, time/batch = 0.2592s	
1980/5250 (epoch 18.857), train_loss = 0.79484275, grad/param norm = 6.3499e-02, time/batch = 0.2591s	
1981/5250 (epoch 18.867), train_loss = 0.79054104, grad/param norm = 6.4621e-02, time/batch = 0.2594s	
1982/5250 (epoch 18.876), train_loss = 0.79153072, grad/param norm = 6.4662e-02, time/batch = 0.2592s	
1983/5250 (epoch 18.886), train_loss = 0.81065151, grad/param norm = 6.6707e-02, time/batch = 0.2597s	
1984/5250 (epoch 18.895), train_loss = 0.80189488, grad/param norm = 6.5286e-02, time/batch = 0.2589s	
1985/5250 (epoch 18.905), train_loss = 0.80135058, grad/param norm = 6.3919e-02, time/batch = 0.2590s	
1986/5250 (epoch 18.914), train_loss = 0.80277645, grad/param norm = 6.5622e-02, time/batch = 0.2593s	
1987/5250 (epoch 18.924), train_loss = 0.79419774, grad/param norm = 6.2535e-02, time/batch = 0.2591s	
1988/5250 (epoch 18.933), train_loss = 0.79662177, grad/param norm = 6.3131e-02, time/batch = 0.2589s	
1989/5250 (epoch 18.943), train_loss = 0.81704963, grad/param norm = 6.5174e-02, time/batch = 0.2593s	
1990/5250 (epoch 18.952), train_loss = 0.82002970, grad/param norm = 6.8596e-02, time/batch = 0.2588s	
1991/5250 (epoch 18.962), train_loss = 0.78959400, grad/param norm = 6.6546e-02, time/batch = 0.2594s	
1992/5250 (epoch 18.971), train_loss = 0.80084826, grad/param norm = 6.0186e-02, time/batch = 0.2591s	
1993/5250 (epoch 18.981), train_loss = 0.79499513, grad/param norm = 6.2323e-02, time/batch = 0.2592s	
1994/5250 (epoch 18.990), train_loss = 0.79845743, grad/param norm = 6.3257e-02, time/batch = 0.2592s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1995/5250 (epoch 19.000), train_loss = 0.78887392, grad/param norm = 6.7413e-02, time/batch = 0.2590s	
1996/5250 (epoch 19.010), train_loss = 0.99337467, grad/param norm = 7.4264e-02, time/batch = 0.2592s	
1997/5250 (epoch 19.019), train_loss = 0.80035595, grad/param norm = 6.4326e-02, time/batch = 0.2591s	
1998/5250 (epoch 19.029), train_loss = 0.80508240, grad/param norm = 6.4623e-02, time/batch = 0.2595s	
1999/5250 (epoch 19.038), train_loss = 0.78693389, grad/param norm = 6.0652e-02, time/batch = 0.2591s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch19.05_1.6397.t7	
2000/5250 (epoch 19.048), train_loss = 0.77287681, grad/param norm = 6.0434e-02, time/batch = 0.2592s	
2001/5250 (epoch 19.057), train_loss = 1.35307739, grad/param norm = 8.0380e-02, time/batch = 0.2598s	
2002/5250 (epoch 19.067), train_loss = 0.81890073, grad/param norm = 6.5506e-02, time/batch = 0.2590s	
2003/5250 (epoch 19.076), train_loss = 0.80110130, grad/param norm = 6.2581e-02, time/batch = 0.2595s	
2004/5250 (epoch 19.086), train_loss = 0.78320820, grad/param norm = 6.0378e-02, time/batch = 0.2592s	
2005/5250 (epoch 19.095), train_loss = 0.78658004, grad/param norm = 6.1924e-02, time/batch = 0.2592s	
2006/5250 (epoch 19.105), train_loss = 0.79459676, grad/param norm = 6.0337e-02, time/batch = 0.2592s	
2007/5250 (epoch 19.114), train_loss = 0.77370888, grad/param norm = 6.2077e-02, time/batch = 0.2590s	
2008/5250 (epoch 19.124), train_loss = 0.80040902, grad/param norm = 6.3239e-02, time/batch = 0.2591s	
2009/5250 (epoch 19.133), train_loss = 0.79669701, grad/param norm = 6.4759e-02, time/batch = 0.2595s	
2010/5250 (epoch 19.143), train_loss = 0.77523880, grad/param norm = 6.1335e-02, time/batch = 0.2594s	
2011/5250 (epoch 19.152), train_loss = 0.76618823, grad/param norm = 6.3948e-02, time/batch = 0.2594s	
2012/5250 (epoch 19.162), train_loss = 0.77946945, grad/param norm = 6.1758e-02, time/batch = 0.2593s	
2013/5250 (epoch 19.171), train_loss = 0.77426608, grad/param norm = 6.1475e-02, time/batch = 0.2590s	
2014/5250 (epoch 19.181), train_loss = 0.77709904, grad/param norm = 5.8704e-02, time/batch = 0.2595s	
2015/5250 (epoch 19.190), train_loss = 0.77346579, grad/param norm = 6.0909e-02, time/batch = 0.2591s	
2016/5250 (epoch 19.200), train_loss = 0.77212173, grad/param norm = 5.9845e-02, time/batch = 0.2595s	
2017/5250 (epoch 19.210), train_loss = 0.77450696, grad/param norm = 6.3141e-02, time/batch = 0.2591s	
2018/5250 (epoch 19.219), train_loss = 0.79836677, grad/param norm = 6.5853e-02, time/batch = 0.2595s	
2019/5250 (epoch 19.229), train_loss = 0.78920346, grad/param norm = 6.5446e-02, time/batch = 0.2593s	
2020/5250 (epoch 19.238), train_loss = 0.78160619, grad/param norm = 6.3659e-02, time/batch = 0.2594s	
2021/5250 (epoch 19.248), train_loss = 0.78294468, grad/param norm = 6.4857e-02, time/batch = 0.2590s	
2022/5250 (epoch 19.257), train_loss = 0.78586565, grad/param norm = 6.6009e-02, time/batch = 0.2589s	
2023/5250 (epoch 19.267), train_loss = 0.78020438, grad/param norm = 5.9066e-02, time/batch = 0.2592s	
2024/5250 (epoch 19.276), train_loss = 0.76467510, grad/param norm = 5.7841e-02, time/batch = 0.2595s	
2025/5250 (epoch 19.286), train_loss = 0.76834185, grad/param norm = 6.3580e-02, time/batch = 0.2594s	
2026/5250 (epoch 19.295), train_loss = 0.76621192, grad/param norm = 5.9624e-02, time/batch = 0.2590s	
2027/5250 (epoch 19.305), train_loss = 0.74556238, grad/param norm = 5.9094e-02, time/batch = 0.2592s	
2028/5250 (epoch 19.314), train_loss = 0.75199053, grad/param norm = 6.4612e-02, time/batch = 0.2593s	
2029/5250 (epoch 19.324), train_loss = 0.78206219, grad/param norm = 7.0254e-02, time/batch = 0.2591s	
2030/5250 (epoch 19.333), train_loss = 0.77890384, grad/param norm = 6.8043e-02, time/batch = 0.2593s	
2031/5250 (epoch 19.343), train_loss = 0.77255709, grad/param norm = 6.5387e-02, time/batch = 0.2594s	
2032/5250 (epoch 19.352), train_loss = 0.76776979, grad/param norm = 6.4056e-02, time/batch = 0.2593s	
2033/5250 (epoch 19.362), train_loss = 0.76965207, grad/param norm = 6.2671e-02, time/batch = 0.2593s	
2034/5250 (epoch 19.371), train_loss = 0.77222014, grad/param norm = 6.2367e-02, time/batch = 0.2597s	
2035/5250 (epoch 19.381), train_loss = 0.79457785, grad/param norm = 7.0289e-02, time/batch = 0.2591s	
2036/5250 (epoch 19.390), train_loss = 0.77236554, grad/param norm = 6.3308e-02, time/batch = 0.2592s	
2037/5250 (epoch 19.400), train_loss = 0.78017810, grad/param norm = 6.6958e-02, time/batch = 0.2591s	
2038/5250 (epoch 19.410), train_loss = 0.78113493, grad/param norm = 6.9395e-02, time/batch = 0.2593s	
2039/5250 (epoch 19.419), train_loss = 0.79143642, grad/param norm = 7.4113e-02, time/batch = 0.2586s	
2040/5250 (epoch 19.429), train_loss = 0.78328428, grad/param norm = 6.7324e-02, time/batch = 0.2595s	
2041/5250 (epoch 19.438), train_loss = 0.78992052, grad/param norm = 6.3558e-02, time/batch = 0.2597s	
2042/5250 (epoch 19.448), train_loss = 0.75882591, grad/param norm = 6.2026e-02, time/batch = 0.2598s	
2043/5250 (epoch 19.457), train_loss = 0.76582179, grad/param norm = 6.1834e-02, time/batch = 0.2592s	
2044/5250 (epoch 19.467), train_loss = 0.76601398, grad/param norm = 6.2568e-02, time/batch = 0.2587s	
2045/5250 (epoch 19.476), train_loss = 0.75625662, grad/param norm = 6.2492e-02, time/batch = 0.2591s	
2046/5250 (epoch 19.486), train_loss = 0.76905593, grad/param norm = 6.8466e-02, time/batch = 0.2595s	
2047/5250 (epoch 19.495), train_loss = 0.78319225, grad/param norm = 6.3906e-02, time/batch = 0.2590s	
2048/5250 (epoch 19.505), train_loss = 0.78179708, grad/param norm = 6.3539e-02, time/batch = 0.2594s	
2049/5250 (epoch 19.514), train_loss = 0.78447224, grad/param norm = 7.0195e-02, time/batch = 0.2594s	
2050/5250 (epoch 19.524), train_loss = 0.78433676, grad/param norm = 6.8611e-02, time/batch = 0.2595s	
2051/5250 (epoch 19.533), train_loss = 0.78586312, grad/param norm = 6.8222e-02, time/batch = 0.2597s	
2052/5250 (epoch 19.543), train_loss = 0.77479383, grad/param norm = 6.5450e-02, time/batch = 0.2591s	
2053/5250 (epoch 19.552), train_loss = 0.77266011, grad/param norm = 6.5679e-02, time/batch = 0.2595s	
2054/5250 (epoch 19.562), train_loss = 0.77692770, grad/param norm = 6.2574e-02, time/batch = 0.2592s	
2055/5250 (epoch 19.571), train_loss = 0.77380815, grad/param norm = 6.1052e-02, time/batch = 0.2592s	
2056/5250 (epoch 19.581), train_loss = 0.77534439, grad/param norm = 6.6340e-02, time/batch = 0.2597s	
2057/5250 (epoch 19.590), train_loss = 0.77826853, grad/param norm = 6.9595e-02, time/batch = 0.2596s	
2058/5250 (epoch 19.600), train_loss = 0.77892530, grad/param norm = 6.5818e-02, time/batch = 0.2589s	
2059/5250 (epoch 19.610), train_loss = 0.78601437, grad/param norm = 7.2118e-02, time/batch = 0.2593s	
2060/5250 (epoch 19.619), train_loss = 0.78955980, grad/param norm = 6.5848e-02, time/batch = 0.2594s	
2061/5250 (epoch 19.629), train_loss = 0.77467060, grad/param norm = 6.5542e-02, time/batch = 0.2592s	
2062/5250 (epoch 19.638), train_loss = 0.75855983, grad/param norm = 6.3506e-02, time/batch = 0.2589s	
2063/5250 (epoch 19.648), train_loss = 0.78065909, grad/param norm = 6.4589e-02, time/batch = 0.2589s	
2064/5250 (epoch 19.657), train_loss = 0.76458797, grad/param norm = 6.2901e-02, time/batch = 0.2592s	
2065/5250 (epoch 19.667), train_loss = 0.76909853, grad/param norm = 6.3251e-02, time/batch = 0.2591s	
2066/5250 (epoch 19.676), train_loss = 0.75828358, grad/param norm = 6.3007e-02, time/batch = 0.2587s	
2067/5250 (epoch 19.686), train_loss = 0.76252177, grad/param norm = 6.7162e-02, time/batch = 0.2592s	
2068/5250 (epoch 19.695), train_loss = 0.76218721, grad/param norm = 6.4593e-02, time/batch = 0.2592s	
2069/5250 (epoch 19.705), train_loss = 0.76224910, grad/param norm = 6.7136e-02, time/batch = 0.2592s	
2070/5250 (epoch 19.714), train_loss = 0.77573530, grad/param norm = 6.8671e-02, time/batch = 0.2593s	
2071/5250 (epoch 19.724), train_loss = 0.77294030, grad/param norm = 6.7852e-02, time/batch = 0.2594s	
2072/5250 (epoch 19.733), train_loss = 0.75228177, grad/param norm = 6.3598e-02, time/batch = 0.2589s	
2073/5250 (epoch 19.743), train_loss = 0.75990241, grad/param norm = 6.5312e-02, time/batch = 0.2595s	
2074/5250 (epoch 19.752), train_loss = 0.76457599, grad/param norm = 6.9154e-02, time/batch = 0.2595s	
2075/5250 (epoch 19.762), train_loss = 0.77631928, grad/param norm = 7.0951e-02, time/batch = 0.2591s	
2076/5250 (epoch 19.771), train_loss = 0.76705075, grad/param norm = 6.3284e-02, time/batch = 0.2593s	
2077/5250 (epoch 19.781), train_loss = 0.77012795, grad/param norm = 6.3779e-02, time/batch = 0.2594s	
2078/5250 (epoch 19.790), train_loss = 0.76508564, grad/param norm = 6.5885e-02, time/batch = 0.2594s	
2079/5250 (epoch 19.800), train_loss = 0.75248048, grad/param norm = 6.4392e-02, time/batch = 0.2595s	
2080/5250 (epoch 19.810), train_loss = 0.76760508, grad/param norm = 6.4187e-02, time/batch = 0.2593s	
2081/5250 (epoch 19.819), train_loss = 0.77414985, grad/param norm = 6.4233e-02, time/batch = 0.2593s	
2082/5250 (epoch 19.829), train_loss = 0.76327911, grad/param norm = 6.6795e-02, time/batch = 0.2590s	
2083/5250 (epoch 19.838), train_loss = 0.73956573, grad/param norm = 6.3489e-02, time/batch = 0.2588s	
2084/5250 (epoch 19.848), train_loss = 0.74655904, grad/param norm = 6.4160e-02, time/batch = 0.2592s	
2085/5250 (epoch 19.857), train_loss = 0.76267666, grad/param norm = 7.1041e-02, time/batch = 0.2591s	
2086/5250 (epoch 19.867), train_loss = 0.75936815, grad/param norm = 6.4025e-02, time/batch = 0.2590s	
2087/5250 (epoch 19.876), train_loss = 0.74446794, grad/param norm = 6.2371e-02, time/batch = 0.2589s	
2088/5250 (epoch 19.886), train_loss = 0.76771726, grad/param norm = 6.6309e-02, time/batch = 0.2600s	
2089/5250 (epoch 19.895), train_loss = 0.75468682, grad/param norm = 6.3519e-02, time/batch = 0.2591s	
2090/5250 (epoch 19.905), train_loss = 0.75925803, grad/param norm = 6.4900e-02, time/batch = 0.2592s	
2091/5250 (epoch 19.914), train_loss = 0.77073340, grad/param norm = 7.0920e-02, time/batch = 0.2595s	
2092/5250 (epoch 19.924), train_loss = 0.77412506, grad/param norm = 7.4055e-02, time/batch = 0.2590s	
2093/5250 (epoch 19.933), train_loss = 0.77744096, grad/param norm = 7.4036e-02, time/batch = 0.2593s	
2094/5250 (epoch 19.943), train_loss = 0.77934130, grad/param norm = 6.6085e-02, time/batch = 0.2589s	
2095/5250 (epoch 19.952), train_loss = 0.78140590, grad/param norm = 6.6203e-02, time/batch = 0.2595s	
2096/5250 (epoch 19.962), train_loss = 0.75350912, grad/param norm = 6.8137e-02, time/batch = 0.2590s	
2097/5250 (epoch 19.971), train_loss = 0.78225285, grad/param norm = 7.2875e-02, time/batch = 0.2590s	
2098/5250 (epoch 19.981), train_loss = 0.76763855, grad/param norm = 6.5650e-02, time/batch = 0.2596s	
2099/5250 (epoch 19.990), train_loss = 0.76322517, grad/param norm = 6.6553e-02, time/batch = 0.2596s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
2100/5250 (epoch 20.000), train_loss = 0.74602324, grad/param norm = 6.7137e-02, time/batch = 0.2590s	
2101/5250 (epoch 20.010), train_loss = 0.94193293, grad/param norm = 7.1102e-02, time/batch = 0.2592s	
2102/5250 (epoch 20.019), train_loss = 0.76958711, grad/param norm = 6.9451e-02, time/batch = 0.2586s	
2103/5250 (epoch 20.029), train_loss = 0.76466086, grad/param norm = 6.4927e-02, time/batch = 0.2591s	
2104/5250 (epoch 20.038), train_loss = 0.75844087, grad/param norm = 6.5826e-02, time/batch = 0.2594s	
2105/5250 (epoch 20.048), train_loss = 0.73700037, grad/param norm = 6.2412e-02, time/batch = 0.2589s	
2106/5250 (epoch 20.057), train_loss = 0.77715416, grad/param norm = 6.3050e-02, time/batch = 0.2594s	
2107/5250 (epoch 20.067), train_loss = 0.75031703, grad/param norm = 6.0098e-02, time/batch = 0.2594s	
2108/5250 (epoch 20.076), train_loss = 0.75210976, grad/param norm = 6.1542e-02, time/batch = 0.2593s	
2109/5250 (epoch 20.086), train_loss = 0.74773411, grad/param norm = 6.4538e-02, time/batch = 0.2586s	
2110/5250 (epoch 20.095), train_loss = 0.74582533, grad/param norm = 6.0056e-02, time/batch = 0.2591s	
2111/5250 (epoch 20.105), train_loss = 0.75312964, grad/param norm = 6.3937e-02, time/batch = 0.2590s	
2112/5250 (epoch 20.114), train_loss = 0.73913624, grad/param norm = 6.3358e-02, time/batch = 0.2593s	
2113/5250 (epoch 20.124), train_loss = 0.75804942, grad/param norm = 6.4359e-02, time/batch = 0.2594s	
2114/5250 (epoch 20.133), train_loss = 0.75681231, grad/param norm = 6.6175e-02, time/batch = 0.2591s	
2115/5250 (epoch 20.143), train_loss = 0.74342532, grad/param norm = 6.4209e-02, time/batch = 0.2591s	
2116/5250 (epoch 20.152), train_loss = 0.72847581, grad/param norm = 6.0752e-02, time/batch = 0.2591s	
2117/5250 (epoch 20.162), train_loss = 0.73952067, grad/param norm = 6.2433e-02, time/batch = 0.2591s	
2118/5250 (epoch 20.171), train_loss = 0.74745494, grad/param norm = 6.9720e-02, time/batch = 0.2594s	
2119/5250 (epoch 20.181), train_loss = 0.74806760, grad/param norm = 6.5078e-02, time/batch = 0.2594s	
2120/5250 (epoch 20.190), train_loss = 0.73707331, grad/param norm = 6.1123e-02, time/batch = 0.2595s	
2121/5250 (epoch 20.200), train_loss = 0.73503187, grad/param norm = 6.1797e-02, time/batch = 0.2592s	
2122/5250 (epoch 20.210), train_loss = 0.74253873, grad/param norm = 6.4205e-02, time/batch = 0.2589s	
2123/5250 (epoch 20.219), train_loss = 0.75760276, grad/param norm = 6.4180e-02, time/batch = 0.2596s	
2124/5250 (epoch 20.229), train_loss = 0.74949753, grad/param norm = 6.8620e-02, time/batch = 0.2592s	
2125/5250 (epoch 20.238), train_loss = 0.74850036, grad/param norm = 6.7849e-02, time/batch = 0.2594s	
2126/5250 (epoch 20.248), train_loss = 0.74544646, grad/param norm = 6.4428e-02, time/batch = 0.2590s	
2127/5250 (epoch 20.257), train_loss = 0.74410351, grad/param norm = 6.4495e-02, time/batch = 0.2589s	
2128/5250 (epoch 20.267), train_loss = 0.74954749, grad/param norm = 6.3997e-02, time/batch = 0.2593s	
2129/5250 (epoch 20.276), train_loss = 0.74024584, grad/param norm = 6.2637e-02, time/batch = 0.2589s	
2130/5250 (epoch 20.286), train_loss = 0.73180178, grad/param norm = 6.2255e-02, time/batch = 0.2591s	
2131/5250 (epoch 20.295), train_loss = 0.74417539, grad/param norm = 6.8369e-02, time/batch = 0.2593s	
2132/5250 (epoch 20.305), train_loss = 0.72094884, grad/param norm = 6.9281e-02, time/batch = 0.2592s	
2133/5250 (epoch 20.314), train_loss = 0.72296822, grad/param norm = 6.6571e-02, time/batch = 0.2592s	
2134/5250 (epoch 20.324), train_loss = 0.73221104, grad/param norm = 6.3056e-02, time/batch = 0.2591s	
2135/5250 (epoch 20.333), train_loss = 0.73492511, grad/param norm = 6.4869e-02, time/batch = 0.2591s	
2136/5250 (epoch 20.343), train_loss = 0.73946622, grad/param norm = 6.9345e-02, time/batch = 0.2596s	
2137/5250 (epoch 20.352), train_loss = 0.73707343, grad/param norm = 7.0782e-02, time/batch = 0.2595s	
2138/5250 (epoch 20.362), train_loss = 0.74168961, grad/param norm = 6.8940e-02, time/batch = 0.2592s	
2139/5250 (epoch 20.371), train_loss = 0.73750975, grad/param norm = 6.6993e-02, time/batch = 0.2589s	
2140/5250 (epoch 20.381), train_loss = 0.74785404, grad/param norm = 6.5497e-02, time/batch = 0.2589s	
2141/5250 (epoch 20.390), train_loss = 0.72915234, grad/param norm = 6.2847e-02, time/batch = 0.2593s	
2142/5250 (epoch 20.400), train_loss = 0.73867640, grad/param norm = 6.2449e-02, time/batch = 0.2589s	
2143/5250 (epoch 20.410), train_loss = 0.72405777, grad/param norm = 6.5672e-02, time/batch = 0.2594s	
2144/5250 (epoch 20.419), train_loss = 0.74176042, grad/param norm = 6.8723e-02, time/batch = 0.2592s	
2145/5250 (epoch 20.429), train_loss = 0.74647919, grad/param norm = 7.0140e-02, time/batch = 0.2591s	
2146/5250 (epoch 20.438), train_loss = 0.76688884, grad/param norm = 7.4224e-02, time/batch = 0.2592s	
2147/5250 (epoch 20.448), train_loss = 0.72905512, grad/param norm = 6.5586e-02, time/batch = 0.2590s	
2148/5250 (epoch 20.457), train_loss = 0.72518246, grad/param norm = 5.9443e-02, time/batch = 0.2589s	
2149/5250 (epoch 20.467), train_loss = 0.72182254, grad/param norm = 6.0055e-02, time/batch = 0.2589s	
2150/5250 (epoch 20.476), train_loss = 0.71139652, grad/param norm = 6.1893e-02, time/batch = 0.2587s	
2151/5250 (epoch 20.486), train_loss = 0.72316633, grad/param norm = 6.5016e-02, time/batch = 0.2588s	
2152/5250 (epoch 20.495), train_loss = 0.74757537, grad/param norm = 6.8119e-02, time/batch = 0.2589s	
2153/5250 (epoch 20.505), train_loss = 0.75963663, grad/param norm = 7.0473e-02, time/batch = 0.2593s	
2154/5250 (epoch 20.514), train_loss = 0.75822249, grad/param norm = 7.1420e-02, time/batch = 0.2590s	
2155/5250 (epoch 20.524), train_loss = 0.74959990, grad/param norm = 6.9133e-02, time/batch = 0.2594s	
2156/5250 (epoch 20.533), train_loss = 0.75254130, grad/param norm = 7.1878e-02, time/batch = 0.2589s	
2157/5250 (epoch 20.543), train_loss = 0.74404730, grad/param norm = 7.0794e-02, time/batch = 0.2591s	
2158/5250 (epoch 20.552), train_loss = 0.73401920, grad/param norm = 6.6998e-02, time/batch = 0.2597s	
2159/5250 (epoch 20.562), train_loss = 0.73928981, grad/param norm = 6.5047e-02, time/batch = 0.2591s	
2160/5250 (epoch 20.571), train_loss = 0.74044985, grad/param norm = 6.5376e-02, time/batch = 0.2595s	
2161/5250 (epoch 20.581), train_loss = 0.73637061, grad/param norm = 6.5548e-02, time/batch = 0.2603s	
2162/5250 (epoch 20.590), train_loss = 0.72862660, grad/param norm = 6.5767e-02, time/batch = 0.2592s	
2163/5250 (epoch 20.600), train_loss = 0.75153677, grad/param norm = 7.0617e-02, time/batch = 0.2594s	
2164/5250 (epoch 20.610), train_loss = 0.75069051, grad/param norm = 7.3586e-02, time/batch = 0.2594s	
2165/5250 (epoch 20.619), train_loss = 0.74814187, grad/param norm = 6.3242e-02, time/batch = 0.2590s	
2166/5250 (epoch 20.629), train_loss = 0.72714079, grad/param norm = 6.7246e-02, time/batch = 0.2594s	
2167/5250 (epoch 20.638), train_loss = 0.72829648, grad/param norm = 6.7396e-02, time/batch = 0.2594s	
2168/5250 (epoch 20.648), train_loss = 0.73914576, grad/param norm = 6.3915e-02, time/batch = 0.2588s	
2169/5250 (epoch 20.657), train_loss = 0.72824732, grad/param norm = 6.3688e-02, time/batch = 0.2592s	
2170/5250 (epoch 20.667), train_loss = 0.74029876, grad/param norm = 6.8139e-02, time/batch = 0.2592s	
2171/5250 (epoch 20.676), train_loss = 0.72133013, grad/param norm = 6.4346e-02, time/batch = 0.2600s	
2172/5250 (epoch 20.686), train_loss = 0.72927783, grad/param norm = 7.3690e-02, time/batch = 0.2589s	
2173/5250 (epoch 20.695), train_loss = 0.73448181, grad/param norm = 6.9008e-02, time/batch = 0.2590s	
2174/5250 (epoch 20.705), train_loss = 0.73769723, grad/param norm = 6.8864e-02, time/batch = 0.2593s	
2175/5250 (epoch 20.714), train_loss = 0.74306787, grad/param norm = 7.1978e-02, time/batch = 0.2593s	
2176/5250 (epoch 20.724), train_loss = 0.74704356, grad/param norm = 7.7104e-02, time/batch = 0.2591s	
2177/5250 (epoch 20.733), train_loss = 0.73137071, grad/param norm = 6.9328e-02, time/batch = 0.2595s	
2178/5250 (epoch 20.743), train_loss = 0.73366076, grad/param norm = 6.8430e-02, time/batch = 0.2589s	
2179/5250 (epoch 20.752), train_loss = 0.72353485, grad/param norm = 6.7990e-02, time/batch = 0.2587s	
2180/5250 (epoch 20.762), train_loss = 0.73274660, grad/param norm = 6.6329e-02, time/batch = 0.2591s	
2181/5250 (epoch 20.771), train_loss = 0.73530119, grad/param norm = 7.2738e-02, time/batch = 0.2594s	
2182/5250 (epoch 20.781), train_loss = 0.74090100, grad/param norm = 6.8976e-02, time/batch = 0.2591s	
2183/5250 (epoch 20.790), train_loss = 0.73505110, grad/param norm = 6.8283e-02, time/batch = 0.2596s	
2184/5250 (epoch 20.800), train_loss = 0.71227753, grad/param norm = 6.3069e-02, time/batch = 0.2591s	
2185/5250 (epoch 20.810), train_loss = 0.72538678, grad/param norm = 6.5627e-02, time/batch = 0.2587s	
2186/5250 (epoch 20.819), train_loss = 0.74088700, grad/param norm = 7.1034e-02, time/batch = 0.2594s	
2187/5250 (epoch 20.829), train_loss = 0.73328992, grad/param norm = 6.6897e-02, time/batch = 0.2595s	
2188/5250 (epoch 20.838), train_loss = 0.70026507, grad/param norm = 6.4806e-02, time/batch = 0.2593s	
2189/5250 (epoch 20.848), train_loss = 0.71874496, grad/param norm = 6.9232e-02, time/batch = 0.2596s	
2190/5250 (epoch 20.857), train_loss = 0.72437449, grad/param norm = 6.9931e-02, time/batch = 0.2598s	
2191/5250 (epoch 20.867), train_loss = 0.72763770, grad/param norm = 7.1264e-02, time/batch = 0.2602s	
2192/5250 (epoch 20.876), train_loss = 0.71409068, grad/param norm = 6.7013e-02, time/batch = 0.2592s	
2193/5250 (epoch 20.886), train_loss = 0.73922027, grad/param norm = 7.2648e-02, time/batch = 0.2594s	
2194/5250 (epoch 20.895), train_loss = 0.72388749, grad/param norm = 6.4599e-02, time/batch = 0.2591s	
2195/5250 (epoch 20.905), train_loss = 0.72139401, grad/param norm = 6.5193e-02, time/batch = 0.2588s	
2196/5250 (epoch 20.914), train_loss = 0.72769055, grad/param norm = 6.7882e-02, time/batch = 0.2590s	
2197/5250 (epoch 20.924), train_loss = 0.72474115, grad/param norm = 6.7837e-02, time/batch = 0.2590s	
2198/5250 (epoch 20.933), train_loss = 0.72607841, grad/param norm = 6.9013e-02, time/batch = 0.2590s	
2199/5250 (epoch 20.943), train_loss = 0.74485377, grad/param norm = 7.3553e-02, time/batch = 0.2591s	
2200/5250 (epoch 20.952), train_loss = 0.76250921, grad/param norm = 7.5711e-02, time/batch = 0.2596s	
2201/5250 (epoch 20.962), train_loss = 0.73008232, grad/param norm = 7.1185e-02, time/batch = 0.2593s	
2202/5250 (epoch 20.971), train_loss = 0.74883769, grad/param norm = 7.2175e-02, time/batch = 0.2595s	
2203/5250 (epoch 20.981), train_loss = 0.73356471, grad/param norm = 6.9109e-02, time/batch = 0.2591s	
2204/5250 (epoch 20.990), train_loss = 0.72952586, grad/param norm = 6.8194e-02, time/batch = 0.2594s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
2205/5250 (epoch 21.000), train_loss = 0.71218036, grad/param norm = 6.7568e-02, time/batch = 0.2592s	
2206/5250 (epoch 21.010), train_loss = 0.91745972, grad/param norm = 7.6631e-02, time/batch = 0.2590s	
2207/5250 (epoch 21.019), train_loss = 0.73459866, grad/param norm = 7.1415e-02, time/batch = 0.2593s	
2208/5250 (epoch 21.029), train_loss = 0.73074454, grad/param norm = 6.6674e-02, time/batch = 0.2591s	
2209/5250 (epoch 21.038), train_loss = 0.72178340, grad/param norm = 6.4958e-02, time/batch = 0.2594s	
2210/5250 (epoch 21.048), train_loss = 0.70551616, grad/param norm = 6.4011e-02, time/batch = 0.2589s	
2211/5250 (epoch 21.057), train_loss = 0.74083299, grad/param norm = 6.7040e-02, time/batch = 0.2593s	
2212/5250 (epoch 21.067), train_loss = 0.71691946, grad/param norm = 6.4857e-02, time/batch = 0.2597s	
2213/5250 (epoch 21.076), train_loss = 0.71579698, grad/param norm = 6.4328e-02, time/batch = 0.2594s	
2214/5250 (epoch 21.086), train_loss = 0.70347243, grad/param norm = 6.2808e-02, time/batch = 0.2594s	
2215/5250 (epoch 21.095), train_loss = 0.71071030, grad/param norm = 6.3274e-02, time/batch = 0.2590s	
2216/5250 (epoch 21.105), train_loss = 0.71786817, grad/param norm = 6.3820e-02, time/batch = 0.2592s	
2217/5250 (epoch 21.114), train_loss = 0.70390705, grad/param norm = 6.3912e-02, time/batch = 0.2590s	
2218/5250 (epoch 21.124), train_loss = 0.71872799, grad/param norm = 6.2224e-02, time/batch = 0.2593s	
2219/5250 (epoch 21.133), train_loss = 0.72121637, grad/param norm = 7.0722e-02, time/batch = 0.2592s	
2220/5250 (epoch 21.143), train_loss = 0.70656897, grad/param norm = 6.2683e-02, time/batch = 0.2592s	
2221/5250 (epoch 21.152), train_loss = 0.69650336, grad/param norm = 6.4677e-02, time/batch = 0.2593s	
2222/5250 (epoch 21.162), train_loss = 0.71011414, grad/param norm = 6.6999e-02, time/batch = 0.2593s	
2223/5250 (epoch 21.171), train_loss = 0.70501593, grad/param norm = 6.6105e-02, time/batch = 0.2591s	
2224/5250 (epoch 21.181), train_loss = 0.71358645, grad/param norm = 6.9125e-02, time/batch = 0.2595s	
2225/5250 (epoch 21.190), train_loss = 0.71455651, grad/param norm = 6.9660e-02, time/batch = 0.2591s	
2226/5250 (epoch 21.200), train_loss = 0.70945626, grad/param norm = 6.5058e-02, time/batch = 0.2591s	
2227/5250 (epoch 21.210), train_loss = 0.70691368, grad/param norm = 6.4341e-02, time/batch = 0.2594s	
2228/5250 (epoch 21.219), train_loss = 0.72100137, grad/param norm = 6.7643e-02, time/batch = 0.2590s	
2229/5250 (epoch 21.229), train_loss = 0.71356090, grad/param norm = 6.5553e-02, time/batch = 0.2590s	
2230/5250 (epoch 21.238), train_loss = 0.71064191, grad/param norm = 6.6343e-02, time/batch = 0.2604s	
2231/5250 (epoch 21.248), train_loss = 0.71699614, grad/param norm = 6.8955e-02, time/batch = 0.2592s	
2232/5250 (epoch 21.257), train_loss = 0.71118839, grad/param norm = 6.5794e-02, time/batch = 0.2590s	
2233/5250 (epoch 21.267), train_loss = 0.71407340, grad/param norm = 6.6098e-02, time/batch = 0.2599s	
2234/5250 (epoch 21.276), train_loss = 0.70791544, grad/param norm = 6.4695e-02, time/batch = 0.2590s	
2235/5250 (epoch 21.286), train_loss = 0.70401687, grad/param norm = 6.5881e-02, time/batch = 0.2593s	
2236/5250 (epoch 21.295), train_loss = 0.70381302, grad/param norm = 6.5626e-02, time/batch = 0.2592s	
2237/5250 (epoch 21.305), train_loss = 0.68191378, grad/param norm = 6.7439e-02, time/batch = 0.2595s	
2238/5250 (epoch 21.314), train_loss = 0.68959810, grad/param norm = 7.0605e-02, time/batch = 0.2592s	
2239/5250 (epoch 21.324), train_loss = 0.71602111, grad/param norm = 7.1858e-02, time/batch = 0.2589s	
2240/5250 (epoch 21.333), train_loss = 0.71036596, grad/param norm = 7.2028e-02, time/batch = 0.2590s	
2241/5250 (epoch 21.343), train_loss = 0.69820503, grad/param norm = 6.5792e-02, time/batch = 0.2595s	
2242/5250 (epoch 21.352), train_loss = 0.69958737, grad/param norm = 6.9700e-02, time/batch = 0.2588s	
2243/5250 (epoch 21.362), train_loss = 0.71260137, grad/param norm = 7.1442e-02, time/batch = 0.2592s	
2244/5250 (epoch 21.371), train_loss = 0.70402574, grad/param norm = 6.8962e-02, time/batch = 0.2593s	
2245/5250 (epoch 21.381), train_loss = 0.71451373, grad/param norm = 6.6452e-02, time/batch = 0.2590s	
2246/5250 (epoch 21.390), train_loss = 0.70993091, grad/param norm = 7.4316e-02, time/batch = 0.2593s	
2247/5250 (epoch 21.400), train_loss = 0.71446260, grad/param norm = 6.6980e-02, time/batch = 0.2591s	
2248/5250 (epoch 21.410), train_loss = 0.68728885, grad/param norm = 6.5588e-02, time/batch = 0.2592s	
2249/5250 (epoch 21.419), train_loss = 0.70676512, grad/param norm = 7.1714e-02, time/batch = 0.2589s	
2250/5250 (epoch 21.429), train_loss = 0.70502655, grad/param norm = 6.8080e-02, time/batch = 0.2591s	
2251/5250 (epoch 21.438), train_loss = 0.72098027, grad/param norm = 6.9000e-02, time/batch = 0.2594s	
2252/5250 (epoch 21.448), train_loss = 0.70137362, grad/param norm = 7.1062e-02, time/batch = 0.2591s	
2253/5250 (epoch 21.457), train_loss = 0.71846996, grad/param norm = 7.8262e-02, time/batch = 0.2594s	
2254/5250 (epoch 21.467), train_loss = 0.72037439, grad/param norm = 7.5248e-02, time/batch = 0.2594s	
2255/5250 (epoch 21.476), train_loss = 0.69157966, grad/param norm = 6.6580e-02, time/batch = 0.2591s	
2256/5250 (epoch 21.486), train_loss = 0.69182571, grad/param norm = 6.4854e-02, time/batch = 0.2592s	
2257/5250 (epoch 21.495), train_loss = 0.71233732, grad/param norm = 6.9246e-02, time/batch = 0.2592s	
2258/5250 (epoch 21.505), train_loss = 0.72206391, grad/param norm = 6.9919e-02, time/batch = 0.2590s	
2259/5250 (epoch 21.514), train_loss = 0.72430747, grad/param norm = 7.5359e-02, time/batch = 0.2585s	
2260/5250 (epoch 21.524), train_loss = 0.72246043, grad/param norm = 7.3234e-02, time/batch = 0.2594s	
2261/5250 (epoch 21.533), train_loss = 0.71203081, grad/param norm = 7.1129e-02, time/batch = 0.2589s	
2262/5250 (epoch 21.543), train_loss = 0.70716195, grad/param norm = 6.7680e-02, time/batch = 0.2591s	
2263/5250 (epoch 21.552), train_loss = 0.69603188, grad/param norm = 6.5808e-02, time/batch = 0.2589s	
2264/5250 (epoch 21.562), train_loss = 0.70933448, grad/param norm = 7.0184e-02, time/batch = 0.2594s	
2265/5250 (epoch 21.571), train_loss = 0.71034645, grad/param norm = 6.8166e-02, time/batch = 0.2595s	
2266/5250 (epoch 21.581), train_loss = 0.70081303, grad/param norm = 6.6681e-02, time/batch = 0.2593s	
2267/5250 (epoch 21.590), train_loss = 0.69734829, grad/param norm = 6.7887e-02, time/batch = 0.2594s	
2268/5250 (epoch 21.600), train_loss = 0.70308186, grad/param norm = 6.6795e-02, time/batch = 0.2591s	
2269/5250 (epoch 21.610), train_loss = 0.70346759, grad/param norm = 6.8493e-02, time/batch = 0.2595s	
2270/5250 (epoch 21.619), train_loss = 0.71569152, grad/param norm = 7.2339e-02, time/batch = 0.2592s	
2271/5250 (epoch 21.629), train_loss = 0.70245787, grad/param norm = 6.9946e-02, time/batch = 0.2592s	
2272/5250 (epoch 21.638), train_loss = 0.69755695, grad/param norm = 7.0221e-02, time/batch = 0.2589s	
2273/5250 (epoch 21.648), train_loss = 0.71230584, grad/param norm = 6.8910e-02, time/batch = 0.2597s	
2274/5250 (epoch 21.657), train_loss = 0.69707046, grad/param norm = 6.8632e-02, time/batch = 0.2590s	
2275/5250 (epoch 21.667), train_loss = 0.70953363, grad/param norm = 6.8344e-02, time/batch = 0.2592s	
2276/5250 (epoch 21.676), train_loss = 0.69290466, grad/param norm = 6.6002e-02, time/batch = 0.2592s	
2277/5250 (epoch 21.686), train_loss = 0.69023280, grad/param norm = 6.8480e-02, time/batch = 0.2594s	
2278/5250 (epoch 21.695), train_loss = 0.69858665, grad/param norm = 7.1870e-02, time/batch = 0.2592s	
2279/5250 (epoch 21.705), train_loss = 0.70940767, grad/param norm = 7.3935e-02, time/batch = 0.2590s	
2280/5250 (epoch 21.714), train_loss = 0.69796666, grad/param norm = 6.8286e-02, time/batch = 0.2598s	
2281/5250 (epoch 21.724), train_loss = 0.70168910, grad/param norm = 6.8594e-02, time/batch = 0.2594s	
2282/5250 (epoch 21.733), train_loss = 0.68407556, grad/param norm = 6.8019e-02, time/batch = 0.2587s	
2283/5250 (epoch 21.743), train_loss = 0.70583586, grad/param norm = 6.9814e-02, time/batch = 0.2593s	
2284/5250 (epoch 21.752), train_loss = 0.70370171, grad/param norm = 7.2968e-02, time/batch = 0.2592s	
2285/5250 (epoch 21.762), train_loss = 0.70642250, grad/param norm = 6.9260e-02, time/batch = 0.2594s	
2286/5250 (epoch 21.771), train_loss = 0.69810808, grad/param norm = 6.7588e-02, time/batch = 0.2595s	
2287/5250 (epoch 21.781), train_loss = 0.70258025, grad/param norm = 7.2224e-02, time/batch = 0.2592s	
2288/5250 (epoch 21.790), train_loss = 0.70688461, grad/param norm = 7.0464e-02, time/batch = 0.2593s	
2289/5250 (epoch 21.800), train_loss = 0.68413410, grad/param norm = 7.3596e-02, time/batch = 0.2593s	
2290/5250 (epoch 21.810), train_loss = 0.70801817, grad/param norm = 6.8764e-02, time/batch = 0.2591s	
2291/5250 (epoch 21.819), train_loss = 0.70218802, grad/param norm = 6.6388e-02, time/batch = 0.2594s	
2292/5250 (epoch 21.829), train_loss = 0.69333584, grad/param norm = 6.8002e-02, time/batch = 0.2590s	
2293/5250 (epoch 21.838), train_loss = 0.67541324, grad/param norm = 6.6219e-02, time/batch = 0.2593s	
2294/5250 (epoch 21.848), train_loss = 0.67527145, grad/param norm = 6.5382e-02, time/batch = 0.2594s	
2295/5250 (epoch 21.857), train_loss = 0.68879898, grad/param norm = 7.0432e-02, time/batch = 0.2593s	
2296/5250 (epoch 21.867), train_loss = 0.68938035, grad/param norm = 7.1201e-02, time/batch = 0.2592s	
2297/5250 (epoch 21.876), train_loss = 0.68865454, grad/param norm = 7.0754e-02, time/batch = 0.2591s	
2298/5250 (epoch 21.886), train_loss = 0.70502923, grad/param norm = 7.3586e-02, time/batch = 0.2594s	
2299/5250 (epoch 21.895), train_loss = 0.69580861, grad/param norm = 7.0884e-02, time/batch = 0.2592s	
2300/5250 (epoch 21.905), train_loss = 0.70730104, grad/param norm = 7.3477e-02, time/batch = 0.2597s	
2301/5250 (epoch 21.914), train_loss = 0.69388774, grad/param norm = 7.1687e-02, time/batch = 0.2592s	
2302/5250 (epoch 21.924), train_loss = 0.69645257, grad/param norm = 7.1253e-02, time/batch = 0.2589s	
2303/5250 (epoch 21.933), train_loss = 0.69920889, grad/param norm = 7.1224e-02, time/batch = 0.2597s	
2304/5250 (epoch 21.943), train_loss = 0.70300091, grad/param norm = 6.7635e-02, time/batch = 0.2592s	
2305/5250 (epoch 21.952), train_loss = 0.71687811, grad/param norm = 6.8724e-02, time/batch = 0.2598s	
2306/5250 (epoch 21.962), train_loss = 0.69774182, grad/param norm = 7.6033e-02, time/batch = 0.2593s	
2307/5250 (epoch 21.971), train_loss = 0.71139678, grad/param norm = 7.0998e-02, time/batch = 0.2594s	
2308/5250 (epoch 21.981), train_loss = 0.70291591, grad/param norm = 7.1662e-02, time/batch = 0.2592s	
2309/5250 (epoch 21.990), train_loss = 0.69873015, grad/param norm = 7.0867e-02, time/batch = 0.2592s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
2310/5250 (epoch 22.000), train_loss = 0.67430773, grad/param norm = 6.6734e-02, time/batch = 0.2596s	
2311/5250 (epoch 22.010), train_loss = 0.87682954, grad/param norm = 7.0945e-02, time/batch = 0.2594s	
2312/5250 (epoch 22.019), train_loss = 0.69731769, grad/param norm = 6.8902e-02, time/batch = 0.2592s	
2313/5250 (epoch 22.029), train_loss = 0.70210677, grad/param norm = 7.4206e-02, time/batch = 0.2594s	
2314/5250 (epoch 22.038), train_loss = 0.69725376, grad/param norm = 6.8002e-02, time/batch = 0.2591s	
2315/5250 (epoch 22.048), train_loss = 0.67000399, grad/param norm = 6.4532e-02, time/batch = 0.2603s	
2316/5250 (epoch 22.057), train_loss = 0.69111350, grad/param norm = 6.4422e-02, time/batch = 0.2592s	
2317/5250 (epoch 22.067), train_loss = 0.68343132, grad/param norm = 6.7914e-02, time/batch = 0.2585s	
2318/5250 (epoch 22.076), train_loss = 0.68816521, grad/param norm = 6.8542e-02, time/batch = 0.2580s	
2319/5250 (epoch 22.086), train_loss = 0.67898412, grad/param norm = 6.8027e-02, time/batch = 0.2583s	
2320/5250 (epoch 22.095), train_loss = 0.68804286, grad/param norm = 6.9131e-02, time/batch = 0.2584s	
2321/5250 (epoch 22.105), train_loss = 0.67716848, grad/param norm = 6.4043e-02, time/batch = 0.2594s	
2322/5250 (epoch 22.114), train_loss = 0.66425795, grad/param norm = 6.3741e-02, time/batch = 0.2582s	
2323/5250 (epoch 22.124), train_loss = 0.68981063, grad/param norm = 6.8955e-02, time/batch = 0.2583s	
2324/5250 (epoch 22.133), train_loss = 0.68844630, grad/param norm = 7.0717e-02, time/batch = 0.2582s	
2325/5250 (epoch 22.143), train_loss = 0.67681761, grad/param norm = 6.7083e-02, time/batch = 0.2581s	
2326/5250 (epoch 22.152), train_loss = 0.66305448, grad/param norm = 6.5960e-02, time/batch = 0.2582s	
2327/5250 (epoch 22.162), train_loss = 0.66912559, grad/param norm = 6.7191e-02, time/batch = 0.2583s	
2328/5250 (epoch 22.171), train_loss = 0.67701633, grad/param norm = 6.9678e-02, time/batch = 0.2579s	
2329/5250 (epoch 22.181), train_loss = 0.68637816, grad/param norm = 7.2019e-02, time/batch = 0.2581s	
2330/5250 (epoch 22.190), train_loss = 0.67824013, grad/param norm = 6.7613e-02, time/batch = 0.2590s	
2331/5250 (epoch 22.200), train_loss = 0.67653801, grad/param norm = 6.6764e-02, time/batch = 0.2589s	
2332/5250 (epoch 22.210), train_loss = 0.67335677, grad/param norm = 6.6296e-02, time/batch = 0.2576s	
2333/5250 (epoch 22.219), train_loss = 0.68405665, grad/param norm = 6.5466e-02, time/batch = 0.2578s	
2334/5250 (epoch 22.229), train_loss = 0.68402470, grad/param norm = 6.9469e-02, time/batch = 0.2572s	
2335/5250 (epoch 22.238), train_loss = 0.67473316, grad/param norm = 6.5953e-02, time/batch = 0.2583s	
2336/5250 (epoch 22.248), train_loss = 0.67942655, grad/param norm = 7.0237e-02, time/batch = 0.2578s	
2337/5250 (epoch 22.257), train_loss = 0.66492440, grad/param norm = 6.3609e-02, time/batch = 0.2577s	
2338/5250 (epoch 22.267), train_loss = 0.67144893, grad/param norm = 6.4577e-02, time/batch = 0.2579s	
2339/5250 (epoch 22.276), train_loss = 0.67433203, grad/param norm = 6.5353e-02, time/batch = 0.2574s	
2340/5250 (epoch 22.286), train_loss = 0.66783129, grad/param norm = 6.5935e-02, time/batch = 0.2579s	
2341/5250 (epoch 22.295), train_loss = 0.67295899, grad/param norm = 6.8728e-02, time/batch = 0.2586s	
2342/5250 (epoch 22.305), train_loss = 0.65472217, grad/param norm = 7.2591e-02, time/batch = 0.2576s	
2343/5250 (epoch 22.314), train_loss = 0.65895890, grad/param norm = 7.4264e-02, time/batch = 0.2576s	
2344/5250 (epoch 22.324), train_loss = 0.67664156, grad/param norm = 6.8444e-02, time/batch = 0.2582s	
2345/5250 (epoch 22.333), train_loss = 0.66465391, grad/param norm = 6.8226e-02, time/batch = 0.2573s	
2346/5250 (epoch 22.343), train_loss = 0.67112241, grad/param norm = 7.2475e-02, time/batch = 0.2575s	
2347/5250 (epoch 22.352), train_loss = 0.67036397, grad/param norm = 6.9983e-02, time/batch = 0.2573s	
2348/5250 (epoch 22.362), train_loss = 0.67027791, grad/param norm = 6.9034e-02, time/batch = 0.2578s	
2349/5250 (epoch 22.371), train_loss = 0.67226149, grad/param norm = 6.9612e-02, time/batch = 0.2576s	
2350/5250 (epoch 22.381), train_loss = 0.67855761, grad/param norm = 7.0396e-02, time/batch = 0.2576s	
2351/5250 (epoch 22.390), train_loss = 0.67540975, grad/param norm = 7.1607e-02, time/batch = 0.2590s	
2352/5250 (epoch 22.400), train_loss = 0.68168511, grad/param norm = 6.8659e-02, time/batch = 0.2572s	
2353/5250 (epoch 22.410), train_loss = 0.66843779, grad/param norm = 7.2001e-02, time/batch = 0.2578s	
2354/5250 (epoch 22.419), train_loss = 0.66730698, grad/param norm = 6.8881e-02, time/batch = 0.2578s	
2355/5250 (epoch 22.429), train_loss = 0.66869761, grad/param norm = 7.0782e-02, time/batch = 0.2575s	
2356/5250 (epoch 22.438), train_loss = 0.69155881, grad/param norm = 7.6549e-02, time/batch = 0.2582s	
2357/5250 (epoch 22.448), train_loss = 0.66251781, grad/param norm = 6.5075e-02, time/batch = 0.2574s	
2358/5250 (epoch 22.457), train_loss = 0.66531804, grad/param norm = 6.6858e-02, time/batch = 0.2574s	
2359/5250 (epoch 22.467), train_loss = 0.66927675, grad/param norm = 7.1893e-02, time/batch = 0.2575s	
2360/5250 (epoch 22.476), train_loss = 0.67224992, grad/param norm = 7.9490e-02, time/batch = 0.2579s	
2361/5250 (epoch 22.486), train_loss = 0.67082610, grad/param norm = 7.6933e-02, time/batch = 0.2593s	
2362/5250 (epoch 22.495), train_loss = 0.68042343, grad/param norm = 6.8423e-02, time/batch = 0.2578s	
2363/5250 (epoch 22.505), train_loss = 0.68200631, grad/param norm = 6.8760e-02, time/batch = 0.2576s	
2364/5250 (epoch 22.514), train_loss = 0.68596371, grad/param norm = 7.2734e-02, time/batch = 0.2575s	
2365/5250 (epoch 22.524), train_loss = 0.67857454, grad/param norm = 7.2103e-02, time/batch = 0.2577s	
2366/5250 (epoch 22.533), train_loss = 0.67810053, grad/param norm = 6.9947e-02, time/batch = 0.2577s	
2367/5250 (epoch 22.543), train_loss = 0.67434676, grad/param norm = 7.2400e-02, time/batch = 0.2576s	
2368/5250 (epoch 22.552), train_loss = 0.67263911, grad/param norm = 7.1287e-02, time/batch = 0.2579s	
2369/5250 (epoch 22.562), train_loss = 0.67305092, grad/param norm = 6.6372e-02, time/batch = 0.2577s	
2370/5250 (epoch 22.571), train_loss = 0.66680321, grad/param norm = 6.8201e-02, time/batch = 0.2578s	
2371/5250 (epoch 22.581), train_loss = 0.67051931, grad/param norm = 6.9209e-02, time/batch = 0.2594s	
2372/5250 (epoch 22.590), train_loss = 0.65974584, grad/param norm = 6.6228e-02, time/batch = 0.2575s	
2373/5250 (epoch 22.600), train_loss = 0.67461240, grad/param norm = 7.0911e-02, time/batch = 0.2576s	
2374/5250 (epoch 22.610), train_loss = 0.67119070, grad/param norm = 6.9171e-02, time/batch = 0.2577s	
2375/5250 (epoch 22.619), train_loss = 0.67553760, grad/param norm = 6.9841e-02, time/batch = 0.2578s	
2376/5250 (epoch 22.629), train_loss = 0.65879849, grad/param norm = 6.7946e-02, time/batch = 0.2574s	
2377/5250 (epoch 22.638), train_loss = 0.65619564, grad/param norm = 6.8409e-02, time/batch = 0.2575s	
2378/5250 (epoch 22.648), train_loss = 0.67342124, grad/param norm = 7.0326e-02, time/batch = 0.2579s	
2379/5250 (epoch 22.657), train_loss = 0.66429460, grad/param norm = 7.0110e-02, time/batch = 0.2576s	
2380/5250 (epoch 22.667), train_loss = 0.67603289, grad/param norm = 7.5868e-02, time/batch = 0.2579s	
2381/5250 (epoch 22.676), train_loss = 0.66920425, grad/param norm = 7.3824e-02, time/batch = 0.2587s	
2382/5250 (epoch 22.686), train_loss = 0.66059090, grad/param norm = 7.1801e-02, time/batch = 0.2576s	
2383/5250 (epoch 22.695), train_loss = 0.66758925, grad/param norm = 7.3073e-02, time/batch = 0.2576s	
2384/5250 (epoch 22.705), train_loss = 0.66523917, grad/param norm = 6.9533e-02, time/batch = 0.2575s	
2385/5250 (epoch 22.714), train_loss = 0.67088539, grad/param norm = 7.0289e-02, time/batch = 0.2579s	
2386/5250 (epoch 22.724), train_loss = 0.65864212, grad/param norm = 7.0633e-02, time/batch = 0.2581s	
2387/5250 (epoch 22.733), train_loss = 0.64817857, grad/param norm = 7.0101e-02, time/batch = 0.2578s	
2388/5250 (epoch 22.743), train_loss = 0.66596408, grad/param norm = 6.8776e-02, time/batch = 0.2573s	
2389/5250 (epoch 22.752), train_loss = 0.65950091, grad/param norm = 7.2763e-02, time/batch = 0.2578s	
2390/5250 (epoch 22.762), train_loss = 0.67216346, grad/param norm = 7.0730e-02, time/batch = 0.2580s	
2391/5250 (epoch 22.771), train_loss = 0.66164350, grad/param norm = 6.7366e-02, time/batch = 0.2588s	
2392/5250 (epoch 22.781), train_loss = 0.66130971, grad/param norm = 6.7658e-02, time/batch = 0.2574s	
2393/5250 (epoch 22.790), train_loss = 0.66882825, grad/param norm = 6.9711e-02, time/batch = 0.2578s	
2394/5250 (epoch 22.800), train_loss = 0.63864642, grad/param norm = 6.5559e-02, time/batch = 0.2578s	
2395/5250 (epoch 22.810), train_loss = 0.66206617, grad/param norm = 7.2722e-02, time/batch = 0.2580s	
2396/5250 (epoch 22.819), train_loss = 0.68888912, grad/param norm = 7.7856e-02, time/batch = 0.2576s	
2397/5250 (epoch 22.829), train_loss = 0.66856061, grad/param norm = 7.6247e-02, time/batch = 0.2577s	
2398/5250 (epoch 22.838), train_loss = 0.65036741, grad/param norm = 7.0450e-02, time/batch = 0.2578s	
2399/5250 (epoch 22.848), train_loss = 0.64454972, grad/param norm = 6.6265e-02, time/batch = 0.2578s	
2400/5250 (epoch 22.857), train_loss = 0.65406096, grad/param norm = 7.0432e-02, time/batch = 0.2578s	
2401/5250 (epoch 22.867), train_loss = 0.65117897, grad/param norm = 6.9702e-02, time/batch = 0.2586s	
2402/5250 (epoch 22.876), train_loss = 0.64953286, grad/param norm = 6.8084e-02, time/batch = 0.2577s	
2403/5250 (epoch 22.886), train_loss = 0.66728301, grad/param norm = 7.0181e-02, time/batch = 0.2581s	
2404/5250 (epoch 22.895), train_loss = 0.65926569, grad/param norm = 7.3504e-02, time/batch = 0.2576s	
2405/5250 (epoch 22.905), train_loss = 0.66717814, grad/param norm = 6.9769e-02, time/batch = 0.2577s	
2406/5250 (epoch 22.914), train_loss = 0.66549634, grad/param norm = 7.5994e-02, time/batch = 0.2577s	
2407/5250 (epoch 22.924), train_loss = 0.66423572, grad/param norm = 7.2471e-02, time/batch = 0.2578s	
2408/5250 (epoch 22.933), train_loss = 0.66607750, grad/param norm = 7.1890e-02, time/batch = 0.2576s	
2409/5250 (epoch 22.943), train_loss = 0.66979524, grad/param norm = 7.2235e-02, time/batch = 0.2579s	
2410/5250 (epoch 22.952), train_loss = 0.68603948, grad/param norm = 7.3603e-02, time/batch = 0.2578s	
2411/5250 (epoch 22.962), train_loss = 0.65443045, grad/param norm = 6.7967e-02, time/batch = 0.2587s	
2412/5250 (epoch 22.971), train_loss = 0.66896164, grad/param norm = 6.7988e-02, time/batch = 0.2576s	
2413/5250 (epoch 22.981), train_loss = 0.66504725, grad/param norm = 7.3469e-02, time/batch = 0.2576s	
2414/5250 (epoch 22.990), train_loss = 0.66773123, grad/param norm = 7.1577e-02, time/batch = 0.2577s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
2415/5250 (epoch 23.000), train_loss = 0.65430197, grad/param norm = 7.6520e-02, time/batch = 0.2576s	
2416/5250 (epoch 23.010), train_loss = 0.85477904, grad/param norm = 8.0967e-02, time/batch = 0.2578s	
2417/5250 (epoch 23.019), train_loss = 0.66612892, grad/param norm = 6.9864e-02, time/batch = 0.2574s	
2418/5250 (epoch 23.029), train_loss = 0.66421779, grad/param norm = 7.3226e-02, time/batch = 0.2579s	
2419/5250 (epoch 23.038), train_loss = 0.66147372, grad/param norm = 6.7861e-02, time/batch = 0.2577s	
2420/5250 (epoch 23.048), train_loss = 0.64047902, grad/param norm = 6.5573e-02, time/batch = 0.2579s	
2421/5250 (epoch 23.057), train_loss = 0.66264679, grad/param norm = 6.9670e-02, time/batch = 0.2588s	
2422/5250 (epoch 23.067), train_loss = 0.65060109, grad/param norm = 6.7602e-02, time/batch = 0.2577s	
2423/5250 (epoch 23.076), train_loss = 0.65473689, grad/param norm = 6.7687e-02, time/batch = 0.2582s	
2424/5250 (epoch 23.086), train_loss = 0.64240060, grad/param norm = 6.6423e-02, time/batch = 0.2578s	
2425/5250 (epoch 23.095), train_loss = 0.65474169, grad/param norm = 7.3920e-02, time/batch = 0.2580s	
2426/5250 (epoch 23.105), train_loss = 0.64949688, grad/param norm = 6.6704e-02, time/batch = 0.2577s	
2427/5250 (epoch 23.114), train_loss = 0.64252441, grad/param norm = 6.5606e-02, time/batch = 0.2578s	
2428/5250 (epoch 23.124), train_loss = 0.65452116, grad/param norm = 6.6098e-02, time/batch = 0.2577s	
2429/5250 (epoch 23.133), train_loss = 0.65335526, grad/param norm = 6.8766e-02, time/batch = 0.2579s	
2430/5250 (epoch 23.143), train_loss = 0.64593952, grad/param norm = 7.4063e-02, time/batch = 0.2579s	
2431/5250 (epoch 23.152), train_loss = 0.64120902, grad/param norm = 6.8469e-02, time/batch = 0.2584s	
2432/5250 (epoch 23.162), train_loss = 0.64528575, grad/param norm = 6.9004e-02, time/batch = 0.2574s	
2433/5250 (epoch 23.171), train_loss = 0.64468121, grad/param norm = 7.0684e-02, time/batch = 0.2579s	
2434/5250 (epoch 23.181), train_loss = 0.65343556, grad/param norm = 7.3072e-02, time/batch = 0.2576s	
2435/5250 (epoch 23.190), train_loss = 0.64638295, grad/param norm = 7.0147e-02, time/batch = 0.2577s	
2436/5250 (epoch 23.200), train_loss = 0.65365085, grad/param norm = 7.3484e-02, time/batch = 0.2580s	
2437/5250 (epoch 23.210), train_loss = 0.65348398, grad/param norm = 7.1406e-02, time/batch = 0.2580s	
2438/5250 (epoch 23.219), train_loss = 0.66268748, grad/param norm = 7.1458e-02, time/batch = 0.2576s	
2439/5250 (epoch 23.229), train_loss = 0.65312481, grad/param norm = 6.9483e-02, time/batch = 0.2576s	
2440/5250 (epoch 23.238), train_loss = 0.64808545, grad/param norm = 6.8545e-02, time/batch = 0.2575s	
2441/5250 (epoch 23.248), train_loss = 0.64923164, grad/param norm = 6.8918e-02, time/batch = 0.2584s	
2442/5250 (epoch 23.257), train_loss = 0.64485426, grad/param norm = 6.7586e-02, time/batch = 0.2576s	
2443/5250 (epoch 23.267), train_loss = 0.64096818, grad/param norm = 6.6360e-02, time/batch = 0.2577s	
2444/5250 (epoch 23.276), train_loss = 0.64335080, grad/param norm = 6.9074e-02, time/batch = 0.2581s	
2445/5250 (epoch 23.286), train_loss = 0.63710190, grad/param norm = 6.7983e-02, time/batch = 0.2579s	
2446/5250 (epoch 23.295), train_loss = 0.63698494, grad/param norm = 6.5292e-02, time/batch = 0.2574s	
2447/5250 (epoch 23.305), train_loss = 0.62067308, grad/param norm = 7.3568e-02, time/batch = 0.2577s	
2448/5250 (epoch 23.314), train_loss = 0.61877879, grad/param norm = 7.0329e-02, time/batch = 0.2576s	
2449/5250 (epoch 23.324), train_loss = 0.65058087, grad/param norm = 7.6636e-02, time/batch = 0.2579s	
2450/5250 (epoch 23.333), train_loss = 0.64385477, grad/param norm = 7.1514e-02, time/batch = 0.2579s	
2451/5250 (epoch 23.343), train_loss = 0.63590426, grad/param norm = 7.0319e-02, time/batch = 0.2586s	
2452/5250 (epoch 23.352), train_loss = 0.63217512, grad/param norm = 6.8610e-02, time/batch = 0.2577s	
2453/5250 (epoch 23.362), train_loss = 0.63980103, grad/param norm = 7.0446e-02, time/batch = 0.2576s	
2454/5250 (epoch 23.371), train_loss = 0.63588647, grad/param norm = 6.9083e-02, time/batch = 0.2576s	
2455/5250 (epoch 23.381), train_loss = 0.64054924, grad/param norm = 6.7621e-02, time/batch = 0.2579s	
2456/5250 (epoch 23.390), train_loss = 0.63959992, grad/param norm = 6.9337e-02, time/batch = 0.2578s	
2457/5250 (epoch 23.400), train_loss = 0.65665113, grad/param norm = 7.4812e-02, time/batch = 0.2579s	
2458/5250 (epoch 23.410), train_loss = 0.65749419, grad/param norm = 8.5178e-02, time/batch = 0.2576s	
2459/5250 (epoch 23.419), train_loss = 0.64751220, grad/param norm = 7.5192e-02, time/batch = 0.2575s	
2460/5250 (epoch 23.429), train_loss = 0.64906763, grad/param norm = 7.3722e-02, time/batch = 0.2576s	
2461/5250 (epoch 23.438), train_loss = 0.65942744, grad/param norm = 7.1556e-02, time/batch = 0.2588s	
2462/5250 (epoch 23.448), train_loss = 0.63595303, grad/param norm = 7.0472e-02, time/batch = 0.2580s	
2463/5250 (epoch 23.457), train_loss = 0.64153039, grad/param norm = 6.9954e-02, time/batch = 0.2583s	
2464/5250 (epoch 23.467), train_loss = 0.63801172, grad/param norm = 7.0441e-02, time/batch = 0.2578s	
2465/5250 (epoch 23.476), train_loss = 0.62979217, grad/param norm = 7.0358e-02, time/batch = 0.2579s	
2466/5250 (epoch 23.486), train_loss = 0.63352579, grad/param norm = 7.3863e-02, time/batch = 0.2580s	
2467/5250 (epoch 23.495), train_loss = 0.65453754, grad/param norm = 7.6771e-02, time/batch = 0.2576s	
2468/5250 (epoch 23.505), train_loss = 0.66648805, grad/param norm = 7.7428e-02, time/batch = 0.2577s	
2469/5250 (epoch 23.514), train_loss = 0.66200103, grad/param norm = 7.4958e-02, time/batch = 0.2580s	
2470/5250 (epoch 23.524), train_loss = 0.65961118, grad/param norm = 7.7433e-02, time/batch = 0.2580s	
2471/5250 (epoch 23.533), train_loss = 0.66032038, grad/param norm = 7.8524e-02, time/batch = 0.2588s	
2472/5250 (epoch 23.543), train_loss = 0.64760852, grad/param norm = 7.2951e-02, time/batch = 0.2577s	
2473/5250 (epoch 23.552), train_loss = 0.63164937, grad/param norm = 6.8990e-02, time/batch = 0.2580s	
2474/5250 (epoch 23.562), train_loss = 0.64146855, grad/param norm = 6.7120e-02, time/batch = 0.2579s	
2475/5250 (epoch 23.571), train_loss = 0.63269106, grad/param norm = 6.7395e-02, time/batch = 0.2580s	
2476/5250 (epoch 23.581), train_loss = 0.63706892, grad/param norm = 6.9649e-02, time/batch = 0.2580s	
2477/5250 (epoch 23.590), train_loss = 0.63248065, grad/param norm = 7.1351e-02, time/batch = 0.2577s	
2478/5250 (epoch 23.600), train_loss = 0.64217589, grad/param norm = 7.0208e-02, time/batch = 0.2577s	
2479/5250 (epoch 23.610), train_loss = 0.64414293, grad/param norm = 7.0821e-02, time/batch = 0.2577s	
2480/5250 (epoch 23.619), train_loss = 0.64863877, grad/param norm = 7.4942e-02, time/batch = 0.2578s	
2481/5250 (epoch 23.629), train_loss = 0.62981349, grad/param norm = 6.8670e-02, time/batch = 0.2584s	
2482/5250 (epoch 23.638), train_loss = 0.62808284, grad/param norm = 7.0183e-02, time/batch = 0.2578s	
2483/5250 (epoch 23.648), train_loss = 0.64100866, grad/param norm = 6.8835e-02, time/batch = 0.2579s	
2484/5250 (epoch 23.657), train_loss = 0.63262314, grad/param norm = 6.9811e-02, time/batch = 0.2578s	
2485/5250 (epoch 23.667), train_loss = 0.63903566, grad/param norm = 7.2289e-02, time/batch = 0.2576s	
2486/5250 (epoch 23.676), train_loss = 0.63139160, grad/param norm = 7.1771e-02, time/batch = 0.2579s	
2487/5250 (epoch 23.686), train_loss = 0.63015079, grad/param norm = 7.3231e-02, time/batch = 0.2576s	
2488/5250 (epoch 23.695), train_loss = 0.63400013, grad/param norm = 7.7820e-02, time/batch = 0.2579s	
2489/5250 (epoch 23.705), train_loss = 0.64036461, grad/param norm = 7.7367e-02, time/batch = 0.2579s	
2490/5250 (epoch 23.714), train_loss = 0.63493436, grad/param norm = 7.3177e-02, time/batch = 0.2577s	
2491/5250 (epoch 23.724), train_loss = 0.63558171, grad/param norm = 7.0635e-02, time/batch = 0.2586s	
2492/5250 (epoch 23.733), train_loss = 0.62435770, grad/param norm = 7.2363e-02, time/batch = 0.2574s	
2493/5250 (epoch 23.743), train_loss = 0.63900664, grad/param norm = 7.1000e-02, time/batch = 0.2576s	
2494/5250 (epoch 23.752), train_loss = 0.62680475, grad/param norm = 6.9779e-02, time/batch = 0.2577s	
2495/5250 (epoch 23.762), train_loss = 0.63283152, grad/param norm = 6.9642e-02, time/batch = 0.2579s	
2496/5250 (epoch 23.771), train_loss = 0.62939921, grad/param norm = 6.9479e-02, time/batch = 0.2576s	
2497/5250 (epoch 23.781), train_loss = 0.63083963, grad/param norm = 6.8872e-02, time/batch = 0.2580s	
2498/5250 (epoch 23.790), train_loss = 0.63742061, grad/param norm = 6.7960e-02, time/batch = 0.2577s	
2499/5250 (epoch 23.800), train_loss = 0.60868945, grad/param norm = 6.6986e-02, time/batch = 0.2574s	
2500/5250 (epoch 23.810), train_loss = 0.62082742, grad/param norm = 6.8365e-02, time/batch = 0.2578s	
2501/5250 (epoch 23.819), train_loss = 0.63840194, grad/param norm = 7.1333e-02, time/batch = 0.2583s	
2502/5250 (epoch 23.829), train_loss = 0.62916095, grad/param norm = 7.2397e-02, time/batch = 0.2576s	
2503/5250 (epoch 23.838), train_loss = 0.62956744, grad/param norm = 8.1607e-02, time/batch = 0.2576s	
2504/5250 (epoch 23.848), train_loss = 0.62966282, grad/param norm = 7.5411e-02, time/batch = 0.2578s	
2505/5250 (epoch 23.857), train_loss = 0.62669686, grad/param norm = 7.4092e-02, time/batch = 0.2576s	
2506/5250 (epoch 23.867), train_loss = 0.62100083, grad/param norm = 7.1742e-02, time/batch = 0.2575s	
2507/5250 (epoch 23.876), train_loss = 0.61969061, grad/param norm = 7.3206e-02, time/batch = 0.2581s	
2508/5250 (epoch 23.886), train_loss = 0.63916965, grad/param norm = 7.3426e-02, time/batch = 0.2577s	
2509/5250 (epoch 23.895), train_loss = 0.63001125, grad/param norm = 7.5353e-02, time/batch = 0.2576s	
2510/5250 (epoch 23.905), train_loss = 0.64068216, grad/param norm = 7.5711e-02, time/batch = 0.2579s	
2511/5250 (epoch 23.914), train_loss = 0.62672664, grad/param norm = 7.2951e-02, time/batch = 0.2588s	
2512/5250 (epoch 23.924), train_loss = 0.62566069, grad/param norm = 7.2545e-02, time/batch = 0.2576s	
2513/5250 (epoch 23.933), train_loss = 0.63886388, grad/param norm = 7.6883e-02, time/batch = 0.2578s	
2514/5250 (epoch 23.943), train_loss = 0.63294440, grad/param norm = 7.1065e-02, time/batch = 0.2579s	
2515/5250 (epoch 23.952), train_loss = 0.66169524, grad/param norm = 7.7944e-02, time/batch = 0.2577s	
2516/5250 (epoch 23.962), train_loss = 0.64427446, grad/param norm = 7.6874e-02, time/batch = 0.2576s	
2517/5250 (epoch 23.971), train_loss = 0.64703614, grad/param norm = 7.0091e-02, time/batch = 0.2576s	
2518/5250 (epoch 23.981), train_loss = 0.63062645, grad/param norm = 7.1490e-02, time/batch = 0.2573s	
2519/5250 (epoch 23.990), train_loss = 0.63018926, grad/param norm = 6.9138e-02, time/batch = 0.2576s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
2520/5250 (epoch 24.000), train_loss = 0.61478305, grad/param norm = 7.1914e-02, time/batch = 0.2579s	
2521/5250 (epoch 24.010), train_loss = 0.81424462, grad/param norm = 7.7543e-02, time/batch = 0.2591s	
2522/5250 (epoch 24.019), train_loss = 0.63942657, grad/param norm = 7.4053e-02, time/batch = 0.2576s	
2523/5250 (epoch 24.029), train_loss = 0.63826997, grad/param norm = 7.4458e-02, time/batch = 0.2578s	
2524/5250 (epoch 24.038), train_loss = 0.63914527, grad/param norm = 7.1552e-02, time/batch = 0.2577s	
2525/5250 (epoch 24.048), train_loss = 0.61678928, grad/param norm = 6.9300e-02, time/batch = 0.2577s	
2526/5250 (epoch 24.057), train_loss = 0.63273397, grad/param norm = 7.0414e-02, time/batch = 0.2575s	
2527/5250 (epoch 24.067), train_loss = 0.62598029, grad/param norm = 7.1039e-02, time/batch = 0.2578s	
2528/5250 (epoch 24.076), train_loss = 0.62218114, grad/param norm = 7.1814e-02, time/batch = 0.2578s	
2529/5250 (epoch 24.086), train_loss = 0.61345343, grad/param norm = 6.8146e-02, time/batch = 0.2576s	
2530/5250 (epoch 24.095), train_loss = 0.61743720, grad/param norm = 7.1943e-02, time/batch = 0.2577s	
2531/5250 (epoch 24.105), train_loss = 0.62812320, grad/param norm = 7.5403e-02, time/batch = 0.2585s	
2532/5250 (epoch 24.114), train_loss = 0.61772550, grad/param norm = 6.9377e-02, time/batch = 0.2578s	
2533/5250 (epoch 24.124), train_loss = 0.62728101, grad/param norm = 6.8069e-02, time/batch = 0.2580s	
2534/5250 (epoch 24.133), train_loss = 0.62103549, grad/param norm = 6.6887e-02, time/batch = 0.2574s	
2535/5250 (epoch 24.143), train_loss = 0.61267030, grad/param norm = 6.8218e-02, time/batch = 0.2577s	
2536/5250 (epoch 24.152), train_loss = 0.60385124, grad/param norm = 6.7194e-02, time/batch = 0.2577s	
2537/5250 (epoch 24.162), train_loss = 0.61465018, grad/param norm = 6.9805e-02, time/batch = 0.2573s	
2538/5250 (epoch 24.171), train_loss = 0.60582395, grad/param norm = 6.8602e-02, time/batch = 0.2580s	
2539/5250 (epoch 24.181), train_loss = 0.61168527, grad/param norm = 6.8008e-02, time/batch = 0.2577s	
2540/5250 (epoch 24.190), train_loss = 0.62188560, grad/param norm = 7.6753e-02, time/batch = 0.2579s	
2541/5250 (epoch 24.200), train_loss = 0.62440388, grad/param norm = 7.4246e-02, time/batch = 0.2588s	
2542/5250 (epoch 24.210), train_loss = 0.62411071, grad/param norm = 7.3290e-02, time/batch = 0.2575s	
2543/5250 (epoch 24.219), train_loss = 0.63387604, grad/param norm = 7.4533e-02, time/batch = 0.2575s	
2544/5250 (epoch 24.229), train_loss = 0.62811170, grad/param norm = 7.4700e-02, time/batch = 0.2576s	
2545/5250 (epoch 24.238), train_loss = 0.62401721, grad/param norm = 7.3919e-02, time/batch = 0.2579s	
2546/5250 (epoch 24.248), train_loss = 0.63107943, grad/param norm = 7.5926e-02, time/batch = 0.2578s	
2547/5250 (epoch 24.257), train_loss = 0.62128771, grad/param norm = 7.2068e-02, time/batch = 0.2580s	
2548/5250 (epoch 24.267), train_loss = 0.61856167, grad/param norm = 6.8388e-02, time/batch = 0.2579s	
2549/5250 (epoch 24.276), train_loss = 0.61631139, grad/param norm = 6.8071e-02, time/batch = 0.2577s	
2550/5250 (epoch 24.286), train_loss = 0.61071193, grad/param norm = 6.9528e-02, time/batch = 0.2574s	
2551/5250 (epoch 24.295), train_loss = 0.61509227, grad/param norm = 7.1690e-02, time/batch = 0.2584s	
2552/5250 (epoch 24.305), train_loss = 0.59327562, grad/param norm = 7.5296e-02, time/batch = 0.2574s	
2553/5250 (epoch 24.314), train_loss = 0.59328489, grad/param norm = 7.4304e-02, time/batch = 0.2578s	
2554/5250 (epoch 24.324), train_loss = 0.61845389, grad/param norm = 7.2092e-02, time/batch = 0.2577s	
2555/5250 (epoch 24.333), train_loss = 0.61162979, grad/param norm = 7.2404e-02, time/batch = 0.2577s	
2556/5250 (epoch 24.343), train_loss = 0.61179643, grad/param norm = 7.1182e-02, time/batch = 0.2576s	
2557/5250 (epoch 24.352), train_loss = 0.59832466, grad/param norm = 7.1007e-02, time/batch = 0.2575s	
2558/5250 (epoch 24.362), train_loss = 0.61329535, grad/param norm = 7.2146e-02, time/batch = 0.2577s	
2559/5250 (epoch 24.371), train_loss = 0.60549607, grad/param norm = 7.1497e-02, time/batch = 0.2576s	
2560/5250 (epoch 24.381), train_loss = 0.61015693, grad/param norm = 6.9998e-02, time/batch = 0.2580s	
2561/5250 (epoch 24.390), train_loss = 0.60221648, grad/param norm = 6.8656e-02, time/batch = 0.2594s	
2562/5250 (epoch 24.400), train_loss = 0.61085959, grad/param norm = 6.8474e-02, time/batch = 0.2578s	
2563/5250 (epoch 24.410), train_loss = 0.60217718, grad/param norm = 7.0642e-02, time/batch = 0.2574s	
2564/5250 (epoch 24.419), train_loss = 0.62466797, grad/param norm = 8.1181e-02, time/batch = 0.2579s	
2565/5250 (epoch 24.429), train_loss = 0.63448389, grad/param norm = 8.6592e-02, time/batch = 0.2577s	
2566/5250 (epoch 24.438), train_loss = 0.63164997, grad/param norm = 7.6525e-02, time/batch = 0.2577s	
2567/5250 (epoch 24.448), train_loss = 0.61422821, grad/param norm = 7.4251e-02, time/batch = 0.2574s	
2568/5250 (epoch 24.457), train_loss = 0.60967979, grad/param norm = 6.7325e-02, time/batch = 0.2577s	
2569/5250 (epoch 24.467), train_loss = 0.60733696, grad/param norm = 7.0197e-02, time/batch = 0.2579s	
2570/5250 (epoch 24.476), train_loss = 0.59551534, grad/param norm = 7.1053e-02, time/batch = 0.2579s	
2571/5250 (epoch 24.486), train_loss = 0.60362076, grad/param norm = 7.0522e-02, time/batch = 0.2584s	
2572/5250 (epoch 24.495), train_loss = 0.62277571, grad/param norm = 7.3976e-02, time/batch = 0.2575s	
2573/5250 (epoch 24.505), train_loss = 0.62179819, grad/param norm = 7.1068e-02, time/batch = 0.2576s	
2574/5250 (epoch 24.514), train_loss = 0.62353073, grad/param norm = 7.4939e-02, time/batch = 0.2581s	
2575/5250 (epoch 24.524), train_loss = 0.62171417, grad/param norm = 7.4063e-02, time/batch = 0.2575s	
2576/5250 (epoch 24.533), train_loss = 0.61012563, grad/param norm = 7.2137e-02, time/batch = 0.2571s	
2577/5250 (epoch 24.543), train_loss = 0.61318151, grad/param norm = 7.6181e-02, time/batch = 0.2580s	
2578/5250 (epoch 24.552), train_loss = 0.60978055, grad/param norm = 7.4985e-02, time/batch = 0.2578s	
2579/5250 (epoch 24.562), train_loss = 0.61574585, grad/param norm = 7.1151e-02, time/batch = 0.2577s	
2580/5250 (epoch 24.571), train_loss = 0.60325850, grad/param norm = 6.8827e-02, time/batch = 0.2579s	
2581/5250 (epoch 24.581), train_loss = 0.61119888, grad/param norm = 7.3236e-02, time/batch = 0.2586s	
2582/5250 (epoch 24.590), train_loss = 0.60327950, grad/param norm = 7.0291e-02, time/batch = 0.2573s	
2583/5250 (epoch 24.600), train_loss = 0.60924437, grad/param norm = 7.2451e-02, time/batch = 0.2578s	
2584/5250 (epoch 24.610), train_loss = 0.61432683, grad/param norm = 7.3412e-02, time/batch = 0.2575s	
2585/5250 (epoch 24.619), train_loss = 0.61983429, grad/param norm = 7.5156e-02, time/batch = 0.2572s	
2586/5250 (epoch 24.629), train_loss = 0.60111500, grad/param norm = 7.1929e-02, time/batch = 0.2580s	
2587/5250 (epoch 24.638), train_loss = 0.59778179, grad/param norm = 6.8532e-02, time/batch = 0.2578s	
2588/5250 (epoch 24.648), train_loss = 0.60060084, grad/param norm = 6.8248e-02, time/batch = 0.2577s	
2589/5250 (epoch 24.657), train_loss = 0.59832063, grad/param norm = 6.8284e-02, time/batch = 0.2577s	
2590/5250 (epoch 24.667), train_loss = 0.61126601, grad/param norm = 7.5698e-02, time/batch = 0.2578s	
2591/5250 (epoch 24.676), train_loss = 0.59489137, grad/param norm = 6.6844e-02, time/batch = 0.2588s	
2592/5250 (epoch 24.686), train_loss = 0.59519653, grad/param norm = 7.3412e-02, time/batch = 0.2579s	
2593/5250 (epoch 24.695), train_loss = 0.60397596, grad/param norm = 7.3902e-02, time/batch = 0.2579s	
2594/5250 (epoch 24.705), train_loss = 0.60007614, grad/param norm = 7.1106e-02, time/batch = 0.2576s	
2595/5250 (epoch 24.714), train_loss = 0.59506831, grad/param norm = 7.1708e-02, time/batch = 0.2578s	
2596/5250 (epoch 24.724), train_loss = 0.60178633, grad/param norm = 7.2678e-02, time/batch = 0.2579s	
2597/5250 (epoch 24.733), train_loss = 0.58448854, grad/param norm = 7.3213e-02, time/batch = 0.2577s	
2598/5250 (epoch 24.743), train_loss = 0.61046208, grad/param norm = 7.4440e-02, time/batch = 0.2579s	
2599/5250 (epoch 24.752), train_loss = 0.59269630, grad/param norm = 7.0591e-02, time/batch = 0.2578s	
2600/5250 (epoch 24.762), train_loss = 0.60982708, grad/param norm = 7.4167e-02, time/batch = 0.2581s	
2601/5250 (epoch 24.771), train_loss = 0.60550397, grad/param norm = 7.7924e-02, time/batch = 0.2587s	
2602/5250 (epoch 24.781), train_loss = 0.60529223, grad/param norm = 7.3202e-02, time/batch = 0.2576s	
2603/5250 (epoch 24.790), train_loss = 0.61247166, grad/param norm = 7.5034e-02, time/batch = 0.2579s	
2604/5250 (epoch 24.800), train_loss = 0.58493598, grad/param norm = 6.8944e-02, time/batch = 0.2576s	
2605/5250 (epoch 24.810), train_loss = 0.59502257, grad/param norm = 6.9379e-02, time/batch = 0.2578s	
2606/5250 (epoch 24.819), train_loss = 0.61068974, grad/param norm = 7.3982e-02, time/batch = 0.2575s	
2607/5250 (epoch 24.829), train_loss = 0.60620058, grad/param norm = 7.7520e-02, time/batch = 0.2574s	
2608/5250 (epoch 24.838), train_loss = 0.59588900, grad/param norm = 7.5632e-02, time/batch = 0.2575s	
2609/5250 (epoch 24.848), train_loss = 0.60392494, grad/param norm = 7.5666e-02, time/batch = 0.2574s	
2610/5250 (epoch 24.857), train_loss = 0.61422121, grad/param norm = 8.4582e-02, time/batch = 0.2578s	
2611/5250 (epoch 24.867), train_loss = 0.60323116, grad/param norm = 7.9728e-02, time/batch = 0.2589s	
2612/5250 (epoch 24.876), train_loss = 0.59567679, grad/param norm = 7.4377e-02, time/batch = 0.2577s	
2613/5250 (epoch 24.886), train_loss = 0.61446500, grad/param norm = 7.6609e-02, time/batch = 0.2573s	
2614/5250 (epoch 24.895), train_loss = 0.59991142, grad/param norm = 7.3432e-02, time/batch = 0.2577s	
2615/5250 (epoch 24.905), train_loss = 0.60607265, grad/param norm = 7.1522e-02, time/batch = 0.2576s	
2616/5250 (epoch 24.914), train_loss = 0.60133360, grad/param norm = 7.5628e-02, time/batch = 0.2579s	
2617/5250 (epoch 24.924), train_loss = 0.60730259, grad/param norm = 7.9118e-02, time/batch = 0.2576s	
2618/5250 (epoch 24.933), train_loss = 0.60570447, grad/param norm = 7.4457e-02, time/batch = 0.2576s	
2619/5250 (epoch 24.943), train_loss = 0.60778205, grad/param norm = 7.2196e-02, time/batch = 0.2575s	
2620/5250 (epoch 24.952), train_loss = 0.62362729, grad/param norm = 7.5608e-02, time/batch = 0.2577s	
2621/5250 (epoch 24.962), train_loss = 0.60468667, grad/param norm = 7.3989e-02, time/batch = 0.2592s	
2622/5250 (epoch 24.971), train_loss = 0.61241819, grad/param norm = 7.1503e-02, time/batch = 0.2580s	
2623/5250 (epoch 24.981), train_loss = 0.61223518, grad/param norm = 8.0105e-02, time/batch = 0.2578s	
2624/5250 (epoch 24.990), train_loss = 0.61469173, grad/param norm = 7.4002e-02, time/batch = 0.2573s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
2625/5250 (epoch 25.000), train_loss = 0.58350786, grad/param norm = 7.1322e-02, time/batch = 0.2577s	
2626/5250 (epoch 25.010), train_loss = 0.78737510, grad/param norm = 7.4117e-02, time/batch = 0.2575s	
2627/5250 (epoch 25.019), train_loss = 0.60344713, grad/param norm = 7.2618e-02, time/batch = 0.2576s	
2628/5250 (epoch 25.029), train_loss = 0.60273716, grad/param norm = 7.0291e-02, time/batch = 0.2578s	
2629/5250 (epoch 25.038), train_loss = 0.60950718, grad/param norm = 7.4277e-02, time/batch = 0.2576s	
2630/5250 (epoch 25.048), train_loss = 0.58509403, grad/param norm = 7.0285e-02, time/batch = 0.2576s	
2631/5250 (epoch 25.057), train_loss = 0.59969307, grad/param norm = 6.9749e-02, time/batch = 0.2587s	
2632/5250 (epoch 25.067), train_loss = 0.59891951, grad/param norm = 7.6599e-02, time/batch = 0.2574s	
2633/5250 (epoch 25.076), train_loss = 0.59712300, grad/param norm = 7.4694e-02, time/batch = 0.2578s	
2634/5250 (epoch 25.086), train_loss = 0.59607774, grad/param norm = 7.5498e-02, time/batch = 0.2576s	
2635/5250 (epoch 25.095), train_loss = 0.58770450, grad/param norm = 7.0815e-02, time/batch = 0.2578s	
2636/5250 (epoch 25.105), train_loss = 0.59380843, grad/param norm = 7.7586e-02, time/batch = 0.2579s	
2637/5250 (epoch 25.114), train_loss = 0.59489697, grad/param norm = 7.4743e-02, time/batch = 0.2575s	
2638/5250 (epoch 25.124), train_loss = 0.61191462, grad/param norm = 7.5145e-02, time/batch = 0.2580s	
2639/5250 (epoch 25.133), train_loss = 0.59981992, grad/param norm = 7.4828e-02, time/batch = 0.2578s	
2640/5250 (epoch 25.143), train_loss = 0.58807430, grad/param norm = 6.9292e-02, time/batch = 0.2578s	
2641/5250 (epoch 25.152), train_loss = 0.57761004, grad/param norm = 6.9863e-02, time/batch = 0.2587s	
2642/5250 (epoch 25.162), train_loss = 0.58773333, grad/param norm = 6.9909e-02, time/batch = 0.2577s	
2643/5250 (epoch 25.171), train_loss = 0.58098202, grad/param norm = 7.0445e-02, time/batch = 0.2579s	
2644/5250 (epoch 25.181), train_loss = 0.58952548, grad/param norm = 7.4833e-02, time/batch = 0.2576s	
2645/5250 (epoch 25.190), train_loss = 0.58004687, grad/param norm = 6.8742e-02, time/batch = 0.2576s	
2646/5250 (epoch 25.200), train_loss = 0.58450934, grad/param norm = 7.2322e-02, time/batch = 0.2574s	
2647/5250 (epoch 25.210), train_loss = 0.60136556, grad/param norm = 8.0441e-02, time/batch = 0.2578s	
2648/5250 (epoch 25.219), train_loss = 0.61712871, grad/param norm = 7.5597e-02, time/batch = 0.2576s	
2649/5250 (epoch 25.229), train_loss = 0.59687863, grad/param norm = 7.3561e-02, time/batch = 0.2577s	
2650/5250 (epoch 25.238), train_loss = 0.59245202, grad/param norm = 7.2728e-02, time/batch = 0.2578s	
2651/5250 (epoch 25.248), train_loss = 0.59178362, grad/param norm = 7.3525e-02, time/batch = 0.2583s	
2652/5250 (epoch 25.257), train_loss = 0.59080102, grad/param norm = 7.2938e-02, time/batch = 0.2578s	
2653/5250 (epoch 25.267), train_loss = 0.59398796, grad/param norm = 7.0464e-02, time/batch = 0.2574s	
2654/5250 (epoch 25.276), train_loss = 0.59423951, grad/param norm = 7.1106e-02, time/batch = 0.2577s	
2655/5250 (epoch 25.286), train_loss = 0.58382090, grad/param norm = 6.9034e-02, time/batch = 0.2578s	
2656/5250 (epoch 25.295), train_loss = 0.57994985, grad/param norm = 6.7164e-02, time/batch = 0.2577s	
2657/5250 (epoch 25.305), train_loss = 0.56245608, grad/param norm = 7.1961e-02, time/batch = 0.2577s	
2658/5250 (epoch 25.314), train_loss = 0.56868649, grad/param norm = 7.8974e-02, time/batch = 0.2579s	
2659/5250 (epoch 25.324), train_loss = 0.58425281, grad/param norm = 7.1815e-02, time/batch = 0.2577s	
2660/5250 (epoch 25.333), train_loss = 0.58346483, grad/param norm = 7.3199e-02, time/batch = 0.2579s	
2661/5250 (epoch 25.343), train_loss = 0.57890915, grad/param norm = 7.0463e-02, time/batch = 0.2591s	
2662/5250 (epoch 25.352), train_loss = 0.57514024, grad/param norm = 6.9664e-02, time/batch = 0.2575s	
2663/5250 (epoch 25.362), train_loss = 0.57969354, grad/param norm = 7.1137e-02, time/batch = 0.2579s	
2664/5250 (epoch 25.371), train_loss = 0.58042450, grad/param norm = 7.3860e-02, time/batch = 0.2579s	
2665/5250 (epoch 25.381), train_loss = 0.58667948, grad/param norm = 7.7052e-02, time/batch = 0.2574s	
2666/5250 (epoch 25.390), train_loss = 0.58425243, grad/param norm = 7.2029e-02, time/batch = 0.2576s	
2667/5250 (epoch 25.400), train_loss = 0.58209804, grad/param norm = 7.1572e-02, time/batch = 0.2580s	
2668/5250 (epoch 25.410), train_loss = 0.57363552, grad/param norm = 7.0216e-02, time/batch = 0.2578s	
2669/5250 (epoch 25.419), train_loss = 0.57950896, grad/param norm = 7.1055e-02, time/batch = 0.2579s	
2670/5250 (epoch 25.429), train_loss = 0.58702964, grad/param norm = 7.6840e-02, time/batch = 0.2581s	
2671/5250 (epoch 25.438), train_loss = 0.59653023, grad/param norm = 7.8635e-02, time/batch = 0.2583s	
2672/5250 (epoch 25.448), train_loss = 0.58008737, grad/param norm = 6.9326e-02, time/batch = 0.2576s	
2673/5250 (epoch 25.457), train_loss = 0.57211605, grad/param norm = 7.0497e-02, time/batch = 0.2581s	
2674/5250 (epoch 25.467), train_loss = 0.58374908, grad/param norm = 7.1775e-02, time/batch = 0.2574s	
2675/5250 (epoch 25.476), train_loss = 0.56656975, grad/param norm = 7.0018e-02, time/batch = 0.2576s	
2676/5250 (epoch 25.486), train_loss = 0.57534695, grad/param norm = 7.1935e-02, time/batch = 0.2581s	
2677/5250 (epoch 25.495), train_loss = 0.58149965, grad/param norm = 6.9120e-02, time/batch = 0.2575s	
2678/5250 (epoch 25.505), train_loss = 0.59334872, grad/param norm = 7.3278e-02, time/batch = 0.2575s	
2679/5250 (epoch 25.514), train_loss = 0.59246988, grad/param norm = 7.7498e-02, time/batch = 0.2580s	
2680/5250 (epoch 25.524), train_loss = 0.58654876, grad/param norm = 7.6516e-02, time/batch = 0.2579s	
2681/5250 (epoch 25.533), train_loss = 0.58474285, grad/param norm = 7.4478e-02, time/batch = 0.2589s	
2682/5250 (epoch 25.543), train_loss = 0.58768088, grad/param norm = 7.4086e-02, time/batch = 0.2578s	
2683/5250 (epoch 25.552), train_loss = 0.57594211, grad/param norm = 7.1320e-02, time/batch = 0.2579s	
2684/5250 (epoch 25.562), train_loss = 0.58420091, grad/param norm = 7.1947e-02, time/batch = 0.2575s	
2685/5250 (epoch 25.571), train_loss = 0.58095343, grad/param norm = 7.5580e-02, time/batch = 0.2577s	
2686/5250 (epoch 25.581), train_loss = 0.58604906, grad/param norm = 7.3478e-02, time/batch = 0.2578s	
2687/5250 (epoch 25.590), train_loss = 0.58324695, grad/param norm = 7.6009e-02, time/batch = 0.2574s	
2688/5250 (epoch 25.600), train_loss = 0.59012410, grad/param norm = 7.6198e-02, time/batch = 0.2576s	
2689/5250 (epoch 25.610), train_loss = 0.58906584, grad/param norm = 7.1748e-02, time/batch = 0.2576s	
2690/5250 (epoch 25.619), train_loss = 0.57785664, grad/param norm = 7.1449e-02, time/batch = 0.2579s	
2691/5250 (epoch 25.629), train_loss = 0.57552337, grad/param norm = 7.8508e-02, time/batch = 0.2591s	
2692/5250 (epoch 25.638), train_loss = 0.58300719, grad/param norm = 7.7346e-02, time/batch = 0.2579s	
2693/5250 (epoch 25.648), train_loss = 0.57708619, grad/param norm = 7.1422e-02, time/batch = 0.2580s	
2694/5250 (epoch 25.657), train_loss = 0.58040323, grad/param norm = 7.5694e-02, time/batch = 0.2572s	
2695/5250 (epoch 25.667), train_loss = 0.57770570, grad/param norm = 7.2611e-02, time/batch = 0.2577s	
2696/5250 (epoch 25.676), train_loss = 0.57049539, grad/param norm = 6.9949e-02, time/batch = 0.2579s	
2697/5250 (epoch 25.686), train_loss = 0.56814072, grad/param norm = 7.1325e-02, time/batch = 0.2577s	
2698/5250 (epoch 25.695), train_loss = 0.57022302, grad/param norm = 7.2124e-02, time/batch = 0.2579s	
2699/5250 (epoch 25.705), train_loss = 0.57429693, grad/param norm = 7.5795e-02, time/batch = 0.2578s	
2700/5250 (epoch 25.714), train_loss = 0.57867770, grad/param norm = 7.7251e-02, time/batch = 0.2575s	
2701/5250 (epoch 25.724), train_loss = 0.56354744, grad/param norm = 7.0737e-02, time/batch = 0.2592s	
2702/5250 (epoch 25.733), train_loss = 0.55968056, grad/param norm = 7.4906e-02, time/batch = 0.2576s	
2703/5250 (epoch 25.743), train_loss = 0.57621046, grad/param norm = 7.0309e-02, time/batch = 0.2579s	
2704/5250 (epoch 25.752), train_loss = 0.58031378, grad/param norm = 7.5287e-02, time/batch = 0.2579s	
2705/5250 (epoch 25.762), train_loss = 0.58397912, grad/param norm = 7.7027e-02, time/batch = 0.2576s	
2706/5250 (epoch 25.771), train_loss = 0.57609851, grad/param norm = 7.5811e-02, time/batch = 0.2575s	
2707/5250 (epoch 25.781), train_loss = 0.57897107, grad/param norm = 7.5680e-02, time/batch = 0.2577s	
2708/5250 (epoch 25.790), train_loss = 0.58288855, grad/param norm = 7.2781e-02, time/batch = 0.2575s	
2709/5250 (epoch 25.800), train_loss = 0.56506333, grad/param norm = 7.5792e-02, time/batch = 0.2575s	
2710/5250 (epoch 25.810), train_loss = 0.57365342, grad/param norm = 7.4990e-02, time/batch = 0.2577s	
2711/5250 (epoch 25.819), train_loss = 0.57602952, grad/param norm = 7.1918e-02, time/batch = 0.2586s	
2712/5250 (epoch 25.829), train_loss = 0.56869164, grad/param norm = 7.0145e-02, time/batch = 0.2574s	
2713/5250 (epoch 25.838), train_loss = 0.56353322, grad/param norm = 7.5788e-02, time/batch = 0.2575s	
2714/5250 (epoch 25.848), train_loss = 0.56855764, grad/param norm = 7.1603e-02, time/batch = 0.2578s	
2715/5250 (epoch 25.857), train_loss = 0.57099052, grad/param norm = 7.3966e-02, time/batch = 0.2577s	
2716/5250 (epoch 25.867), train_loss = 0.56669963, grad/param norm = 7.4191e-02, time/batch = 0.2577s	
2717/5250 (epoch 25.876), train_loss = 0.57330830, grad/param norm = 8.0474e-02, time/batch = 0.2579s	
2718/5250 (epoch 25.886), train_loss = 0.58433753, grad/param norm = 7.8173e-02, time/batch = 0.2578s	
2719/5250 (epoch 25.895), train_loss = 0.58681941, grad/param norm = 8.2326e-02, time/batch = 0.2578s	
2720/5250 (epoch 25.905), train_loss = 0.59279760, grad/param norm = 7.7789e-02, time/batch = 0.2577s	
2721/5250 (epoch 25.914), train_loss = 0.57595454, grad/param norm = 7.9019e-02, time/batch = 0.2583s	
2722/5250 (epoch 25.924), train_loss = 0.57892294, grad/param norm = 7.4927e-02, time/batch = 0.2577s	
2723/5250 (epoch 25.933), train_loss = 0.57433439, grad/param norm = 7.2230e-02, time/batch = 0.2579s	
2724/5250 (epoch 25.943), train_loss = 0.57781135, grad/param norm = 7.2348e-02, time/batch = 0.2580s	
2725/5250 (epoch 25.952), train_loss = 0.59453582, grad/param norm = 7.3364e-02, time/batch = 0.2575s	
2726/5250 (epoch 25.962), train_loss = 0.58290554, grad/param norm = 7.6192e-02, time/batch = 0.2579s	
2727/5250 (epoch 25.971), train_loss = 0.58873105, grad/param norm = 7.4480e-02, time/batch = 0.2575s	
2728/5250 (epoch 25.981), train_loss = 0.57237174, grad/param norm = 7.4326e-02, time/batch = 0.2576s	
2729/5250 (epoch 25.990), train_loss = 0.57495141, grad/param norm = 7.2600e-02, time/batch = 0.2581s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
2730/5250 (epoch 26.000), train_loss = 0.55662556, grad/param norm = 7.5233e-02, time/batch = 0.2575s	
2731/5250 (epoch 26.010), train_loss = 0.76575272, grad/param norm = 8.0022e-02, time/batch = 0.2583s	
2732/5250 (epoch 26.019), train_loss = 0.58025845, grad/param norm = 7.4996e-02, time/batch = 0.2575s	
2733/5250 (epoch 26.029), train_loss = 0.57803171, grad/param norm = 7.7172e-02, time/batch = 0.2580s	
2734/5250 (epoch 26.038), train_loss = 0.58124751, grad/param norm = 7.3745e-02, time/batch = 0.2575s	
2735/5250 (epoch 26.048), train_loss = 0.55646148, grad/param norm = 6.8897e-02, time/batch = 0.2576s	
2736/5250 (epoch 26.057), train_loss = 0.57607979, grad/param norm = 7.1929e-02, time/batch = 0.2576s	
2737/5250 (epoch 26.067), train_loss = 0.56926046, grad/param norm = 7.2329e-02, time/batch = 0.2576s	
2738/5250 (epoch 26.076), train_loss = 0.56651916, grad/param norm = 7.3618e-02, time/batch = 0.2576s	
2739/5250 (epoch 26.086), train_loss = 0.55710157, grad/param norm = 7.5411e-02, time/batch = 0.2578s	
2740/5250 (epoch 26.095), train_loss = 0.57300976, grad/param norm = 7.7717e-02, time/batch = 0.2576s	
2741/5250 (epoch 26.105), train_loss = 0.57792762, grad/param norm = 7.6906e-02, time/batch = 0.2588s	
2742/5250 (epoch 26.114), train_loss = 0.56687301, grad/param norm = 7.0083e-02, time/batch = 0.2574s	
2743/5250 (epoch 26.124), train_loss = 0.57593193, grad/param norm = 7.0097e-02, time/batch = 0.2582s	
2744/5250 (epoch 26.133), train_loss = 0.57252452, grad/param norm = 7.4681e-02, time/batch = 0.2580s	
2745/5250 (epoch 26.143), train_loss = 0.56664853, grad/param norm = 7.4778e-02, time/batch = 0.2578s	
2746/5250 (epoch 26.152), train_loss = 0.56266696, grad/param norm = 7.3906e-02, time/batch = 0.2575s	
2747/5250 (epoch 26.162), train_loss = 0.56578297, grad/param norm = 7.3587e-02, time/batch = 0.2577s	
2748/5250 (epoch 26.171), train_loss = 0.55772223, grad/param norm = 6.9238e-02, time/batch = 0.2574s	
2749/5250 (epoch 26.181), train_loss = 0.56003392, grad/param norm = 7.0399e-02, time/batch = 0.2579s	
2750/5250 (epoch 26.190), train_loss = 0.55844803, grad/param norm = 7.3718e-02, time/batch = 0.2580s	
2751/5250 (epoch 26.200), train_loss = 0.55764822, grad/param norm = 7.0778e-02, time/batch = 0.2583s	
2752/5250 (epoch 26.210), train_loss = 0.56382981, grad/param norm = 7.1513e-02, time/batch = 0.2576s	
2753/5250 (epoch 26.219), train_loss = 0.57873205, grad/param norm = 7.5310e-02, time/batch = 0.2577s	
2754/5250 (epoch 26.229), train_loss = 0.57426488, grad/param norm = 7.7346e-02, time/batch = 0.2576s	
2755/5250 (epoch 26.238), train_loss = 0.56381628, grad/param norm = 7.5155e-02, time/batch = 0.2577s	
2756/5250 (epoch 26.248), train_loss = 0.57139805, grad/param norm = 7.5301e-02, time/batch = 0.2576s	
2757/5250 (epoch 26.257), train_loss = 0.56273047, grad/param norm = 7.5148e-02, time/batch = 0.2577s	
2758/5250 (epoch 26.267), train_loss = 0.55968296, grad/param norm = 6.9910e-02, time/batch = 0.2579s	
2759/5250 (epoch 26.276), train_loss = 0.55971610, grad/param norm = 7.0565e-02, time/batch = 0.2580s	
2760/5250 (epoch 26.286), train_loss = 0.55514674, grad/param norm = 7.0351e-02, time/batch = 0.2579s	
2761/5250 (epoch 26.295), train_loss = 0.56074525, grad/param norm = 7.2417e-02, time/batch = 0.2583s	
2762/5250 (epoch 26.305), train_loss = 0.53908480, grad/param norm = 7.1363e-02, time/batch = 0.2577s	
2763/5250 (epoch 26.314), train_loss = 0.53457184, grad/param norm = 7.3253e-02, time/batch = 0.2579s	
2764/5250 (epoch 26.324), train_loss = 0.55218533, grad/param norm = 7.1549e-02, time/batch = 0.2576s	
2765/5250 (epoch 26.333), train_loss = 0.55833008, grad/param norm = 7.8234e-02, time/batch = 0.2578s	
2766/5250 (epoch 26.343), train_loss = 0.55730549, grad/param norm = 7.6416e-02, time/batch = 0.2575s	
2767/5250 (epoch 26.352), train_loss = 0.55032790, grad/param norm = 7.5459e-02, time/batch = 0.2575s	
2768/5250 (epoch 26.362), train_loss = 0.56140606, grad/param norm = 7.6000e-02, time/batch = 0.2576s	
2769/5250 (epoch 26.371), train_loss = 0.55569930, grad/param norm = 7.2238e-02, time/batch = 0.2577s	
2770/5250 (epoch 26.381), train_loss = 0.55552770, grad/param norm = 7.4123e-02, time/batch = 0.2579s	
2771/5250 (epoch 26.390), train_loss = 0.56334614, grad/param norm = 8.3181e-02, time/batch = 0.2586s	
2772/5250 (epoch 26.400), train_loss = 0.56852246, grad/param norm = 7.4976e-02, time/batch = 0.2575s	
2773/5250 (epoch 26.410), train_loss = 0.54635202, grad/param norm = 7.4836e-02, time/batch = 0.2582s	
2774/5250 (epoch 26.419), train_loss = 0.56245634, grad/param norm = 7.8451e-02, time/batch = 0.2578s	
2775/5250 (epoch 26.429), train_loss = 0.55744399, grad/param norm = 7.5795e-02, time/batch = 0.2575s	
2776/5250 (epoch 26.438), train_loss = 0.57234299, grad/param norm = 7.7936e-02, time/batch = 0.2576s	
2777/5250 (epoch 26.448), train_loss = 0.55851668, grad/param norm = 7.1293e-02, time/batch = 0.2577s	
2778/5250 (epoch 26.457), train_loss = 0.54985911, grad/param norm = 6.8769e-02, time/batch = 0.2573s	
2779/5250 (epoch 26.467), train_loss = 0.55232593, grad/param norm = 7.3351e-02, time/batch = 0.2577s	
2780/5250 (epoch 26.476), train_loss = 0.53572680, grad/param norm = 6.7172e-02, time/batch = 0.2579s	
2781/5250 (epoch 26.486), train_loss = 0.54092240, grad/param norm = 6.8584e-02, time/batch = 0.2585s	
2782/5250 (epoch 26.495), train_loss = 0.55859202, grad/param norm = 7.3364e-02, time/batch = 0.2575s	
2783/5250 (epoch 26.505), train_loss = 0.56771853, grad/param norm = 7.7147e-02, time/batch = 0.2577s	
2784/5250 (epoch 26.514), train_loss = 0.56030668, grad/param norm = 7.3352e-02, time/batch = 0.2578s	
2785/5250 (epoch 26.524), train_loss = 0.55353799, grad/param norm = 7.4829e-02, time/batch = 0.2577s	
2786/5250 (epoch 26.533), train_loss = 0.56043765, grad/param norm = 7.9463e-02, time/batch = 0.2574s	
2787/5250 (epoch 26.543), train_loss = 0.56319811, grad/param norm = 7.8657e-02, time/batch = 0.2575s	
2788/5250 (epoch 26.552), train_loss = 0.55350234, grad/param norm = 7.8276e-02, time/batch = 0.2578s	
2789/5250 (epoch 26.562), train_loss = 0.55885324, grad/param norm = 7.1528e-02, time/batch = 0.2579s	
2790/5250 (epoch 26.571), train_loss = 0.54724068, grad/param norm = 7.1218e-02, time/batch = 0.2578s	
2791/5250 (epoch 26.581), train_loss = 0.55148842, grad/param norm = 7.1121e-02, time/batch = 0.2593s	
2792/5250 (epoch 26.590), train_loss = 0.55023340, grad/param norm = 7.1617e-02, time/batch = 0.2577s	
2793/5250 (epoch 26.600), train_loss = 0.54842225, grad/param norm = 7.2981e-02, time/batch = 0.2575s	
2794/5250 (epoch 26.610), train_loss = 0.56224627, grad/param norm = 7.7589e-02, time/batch = 0.2579s	
2795/5250 (epoch 26.619), train_loss = 0.55706656, grad/param norm = 7.1827e-02, time/batch = 0.2578s	
2796/5250 (epoch 26.629), train_loss = 0.53636748, grad/param norm = 7.3801e-02, time/batch = 0.2579s	
2797/5250 (epoch 26.638), train_loss = 0.54443904, grad/param norm = 7.1995e-02, time/batch = 0.2579s	
2798/5250 (epoch 26.648), train_loss = 0.55603308, grad/param norm = 7.8619e-02, time/batch = 0.2577s	
2799/5250 (epoch 26.657), train_loss = 0.55703848, grad/param norm = 7.9471e-02, time/batch = 0.2577s	
2800/5250 (epoch 26.667), train_loss = 0.56052474, grad/param norm = 7.9006e-02, time/batch = 0.2574s	
2801/5250 (epoch 26.676), train_loss = 0.55920443, grad/param norm = 7.8397e-02, time/batch = 0.2584s	
2802/5250 (epoch 26.686), train_loss = 0.55515254, grad/param norm = 7.7773e-02, time/batch = 0.2575s	
2803/5250 (epoch 26.695), train_loss = 0.54857047, grad/param norm = 7.3105e-02, time/batch = 0.2577s	
2804/5250 (epoch 26.705), train_loss = 0.54073798, grad/param norm = 7.2685e-02, time/batch = 0.2579s	
2805/5250 (epoch 26.714), train_loss = 0.54459214, grad/param norm = 7.3307e-02, time/batch = 0.2574s	
2806/5250 (epoch 26.724), train_loss = 0.55055246, grad/param norm = 7.9014e-02, time/batch = 0.2576s	
2807/5250 (epoch 26.733), train_loss = 0.54406500, grad/param norm = 7.9683e-02, time/batch = 0.2579s	
2808/5250 (epoch 26.743), train_loss = 0.56102632, grad/param norm = 8.1238e-02, time/batch = 0.2574s	
2809/5250 (epoch 26.752), train_loss = 0.55082658, grad/param norm = 7.4003e-02, time/batch = 0.2576s	
2810/5250 (epoch 26.762), train_loss = 0.54714698, grad/param norm = 7.0594e-02, time/batch = 0.2580s	
2811/5250 (epoch 26.771), train_loss = 0.54285085, grad/param norm = 7.6063e-02, time/batch = 0.2585s	
2812/5250 (epoch 26.781), train_loss = 0.54410734, grad/param norm = 7.3830e-02, time/batch = 0.2576s	
2813/5250 (epoch 26.790), train_loss = 0.55366529, grad/param norm = 7.4684e-02, time/batch = 0.2576s	
2814/5250 (epoch 26.800), train_loss = 0.52843168, grad/param norm = 6.9269e-02, time/batch = 0.2574s	
2815/5250 (epoch 26.810), train_loss = 0.53446563, grad/param norm = 7.1564e-02, time/batch = 0.2579s	
2816/5250 (epoch 26.819), train_loss = 0.55664739, grad/param norm = 8.0021e-02, time/batch = 0.2575s	
2817/5250 (epoch 26.829), train_loss = 0.54589626, grad/param norm = 7.6850e-02, time/batch = 0.2577s	
2818/5250 (epoch 26.838), train_loss = 0.53201553, grad/param norm = 7.2355e-02, time/batch = 0.2576s	
2819/5250 (epoch 26.848), train_loss = 0.53675996, grad/param norm = 6.9779e-02, time/batch = 0.2577s	
2820/5250 (epoch 26.857), train_loss = 0.53824517, grad/param norm = 7.5014e-02, time/batch = 0.2579s	
2821/5250 (epoch 26.867), train_loss = 0.53529025, grad/param norm = 7.4039e-02, time/batch = 0.2585s	
2822/5250 (epoch 26.876), train_loss = 0.53028237, grad/param norm = 7.2254e-02, time/batch = 0.2572s	
2823/5250 (epoch 26.886), train_loss = 0.55859474, grad/param norm = 7.7932e-02, time/batch = 0.2579s	
2824/5250 (epoch 26.895), train_loss = 0.55121975, grad/param norm = 7.8675e-02, time/batch = 0.2573s	
2825/5250 (epoch 26.905), train_loss = 0.56359287, grad/param norm = 7.9806e-02, time/batch = 0.2578s	
2826/5250 (epoch 26.914), train_loss = 0.55507706, grad/param norm = 8.3565e-02, time/batch = 0.2578s	
2827/5250 (epoch 26.924), train_loss = 0.55245958, grad/param norm = 8.0534e-02, time/batch = 0.2574s	
2828/5250 (epoch 26.933), train_loss = 0.55636273, grad/param norm = 7.8457e-02, time/batch = 0.2580s	
2829/5250 (epoch 26.943), train_loss = 0.55773188, grad/param norm = 7.4399e-02, time/batch = 0.2578s	
2830/5250 (epoch 26.952), train_loss = 0.56551860, grad/param norm = 7.1007e-02, time/batch = 0.2576s	
2831/5250 (epoch 26.962), train_loss = 0.54882953, grad/param norm = 7.4784e-02, time/batch = 0.2593s	
2832/5250 (epoch 26.971), train_loss = 0.55951718, grad/param norm = 7.5391e-02, time/batch = 0.2575s	
2833/5250 (epoch 26.981), train_loss = 0.55136912, grad/param norm = 7.4070e-02, time/batch = 0.2574s	
2834/5250 (epoch 26.990), train_loss = 0.55182454, grad/param norm = 7.8665e-02, time/batch = 0.2577s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
2835/5250 (epoch 27.000), train_loss = 0.53354228, grad/param norm = 7.6371e-02, time/batch = 0.2579s	
2836/5250 (epoch 27.010), train_loss = 0.73248883, grad/param norm = 8.1627e-02, time/batch = 0.2580s	
2837/5250 (epoch 27.019), train_loss = 0.55426175, grad/param norm = 7.6530e-02, time/batch = 0.2574s	
2838/5250 (epoch 27.029), train_loss = 0.55271599, grad/param norm = 7.4517e-02, time/batch = 0.2578s	
2839/5250 (epoch 27.038), train_loss = 0.55883549, grad/param norm = 7.5599e-02, time/batch = 0.2575s	
2840/5250 (epoch 27.048), train_loss = 0.53292814, grad/param norm = 7.3158e-02, time/batch = 0.2578s	
2841/5250 (epoch 27.057), train_loss = 0.54774104, grad/param norm = 7.2885e-02, time/batch = 0.2589s	
2842/5250 (epoch 27.067), train_loss = 0.54206782, grad/param norm = 7.3980e-02, time/batch = 0.2577s	
2843/5250 (epoch 27.076), train_loss = 0.53930326, grad/param norm = 7.6780e-02, time/batch = 0.2580s	
2844/5250 (epoch 27.086), train_loss = 0.53734296, grad/param norm = 7.5174e-02, time/batch = 0.2572s	
2845/5250 (epoch 27.095), train_loss = 0.53981186, grad/param norm = 7.3952e-02, time/batch = 0.2575s	
2846/5250 (epoch 27.105), train_loss = 0.54431569, grad/param norm = 7.5097e-02, time/batch = 0.2577s	
2847/5250 (epoch 27.114), train_loss = 0.55294353, grad/param norm = 8.0572e-02, time/batch = 0.2577s	
2848/5250 (epoch 27.124), train_loss = 0.56374798, grad/param norm = 7.5432e-02, time/batch = 0.2577s	
2849/5250 (epoch 27.133), train_loss = 0.54415145, grad/param norm = 7.2780e-02, time/batch = 0.2579s	
2850/5250 (epoch 27.143), train_loss = 0.53485253, grad/param norm = 7.1026e-02, time/batch = 0.2579s	
2851/5250 (epoch 27.152), train_loss = 0.52682919, grad/param norm = 6.9067e-02, time/batch = 0.2586s	
2852/5250 (epoch 27.162), train_loss = 0.53586239, grad/param norm = 7.0773e-02, time/batch = 0.2576s	
2853/5250 (epoch 27.171), train_loss = 0.53530306, grad/param norm = 7.4973e-02, time/batch = 0.2577s	
2854/5250 (epoch 27.181), train_loss = 0.54049057, grad/param norm = 7.5498e-02, time/batch = 0.2577s	
2855/5250 (epoch 27.190), train_loss = 0.52845159, grad/param norm = 7.3692e-02, time/batch = 0.2575s	
2856/5250 (epoch 27.200), train_loss = 0.53299916, grad/param norm = 7.0142e-02, time/batch = 0.2576s	
2857/5250 (epoch 27.210), train_loss = 0.53140593, grad/param norm = 7.0957e-02, time/batch = 0.2576s	
2858/5250 (epoch 27.219), train_loss = 0.54579686, grad/param norm = 7.3803e-02, time/batch = 0.2576s	
2859/5250 (epoch 27.229), train_loss = 0.53830532, grad/param norm = 7.0902e-02, time/batch = 0.2576s	
2860/5250 (epoch 27.238), train_loss = 0.53560612, grad/param norm = 7.4072e-02, time/batch = 0.2578s	
2861/5250 (epoch 27.248), train_loss = 0.54369482, grad/param norm = 7.6418e-02, time/batch = 0.2592s	
2862/5250 (epoch 27.257), train_loss = 0.54069732, grad/param norm = 7.5316e-02, time/batch = 0.2579s	
2863/5250 (epoch 27.267), train_loss = 0.53861325, grad/param norm = 7.3547e-02, time/batch = 0.2578s	
2864/5250 (epoch 27.276), train_loss = 0.53987239, grad/param norm = 7.1847e-02, time/batch = 0.2576s	
2865/5250 (epoch 27.286), train_loss = 0.53584109, grad/param norm = 7.3598e-02, time/batch = 0.2575s	
2866/5250 (epoch 27.295), train_loss = 0.53891311, grad/param norm = 7.3353e-02, time/batch = 0.2575s	
2867/5250 (epoch 27.305), train_loss = 0.51535035, grad/param norm = 7.6690e-02, time/batch = 0.2575s	
2868/5250 (epoch 27.314), train_loss = 0.50897267, grad/param norm = 7.3116e-02, time/batch = 0.2577s	
2869/5250 (epoch 27.324), train_loss = 0.52438929, grad/param norm = 7.4152e-02, time/batch = 0.2575s	
2870/5250 (epoch 27.333), train_loss = 0.52616982, grad/param norm = 7.1842e-02, time/batch = 0.2581s	
2871/5250 (epoch 27.343), train_loss = 0.53373917, grad/param norm = 7.7413e-02, time/batch = 0.2586s	
2872/5250 (epoch 27.352), train_loss = 0.53707693, grad/param norm = 7.9568e-02, time/batch = 0.2574s	
2873/5250 (epoch 27.362), train_loss = 0.54367494, grad/param norm = 7.7871e-02, time/batch = 0.2577s	
2874/5250 (epoch 27.371), train_loss = 0.53302392, grad/param norm = 7.7201e-02, time/batch = 0.2576s	
2875/5250 (epoch 27.381), train_loss = 0.53000258, grad/param norm = 7.5637e-02, time/batch = 0.2574s	
2876/5250 (epoch 27.390), train_loss = 0.53704749, grad/param norm = 8.4593e-02, time/batch = 0.2581s	
2877/5250 (epoch 27.400), train_loss = 0.54361593, grad/param norm = 7.6524e-02, time/batch = 0.2578s	
2878/5250 (epoch 27.410), train_loss = 0.52812594, grad/param norm = 7.9223e-02, time/batch = 0.2574s	
2879/5250 (epoch 27.419), train_loss = 0.53531543, grad/param norm = 7.9900e-02, time/batch = 0.2576s	
2880/5250 (epoch 27.429), train_loss = 0.54214028, grad/param norm = 7.9278e-02, time/batch = 0.2578s	
2881/5250 (epoch 27.438), train_loss = 0.54629754, grad/param norm = 8.0831e-02, time/batch = 0.2591s	
2882/5250 (epoch 27.448), train_loss = 0.53381611, grad/param norm = 7.1567e-02, time/batch = 0.2579s	
2883/5250 (epoch 27.457), train_loss = 0.52520619, grad/param norm = 7.2933e-02, time/batch = 0.2576s	
2884/5250 (epoch 27.467), train_loss = 0.52997213, grad/param norm = 7.4421e-02, time/batch = 0.2575s	
2885/5250 (epoch 27.476), train_loss = 0.51754120, grad/param norm = 7.3172e-02, time/batch = 0.2577s	
2886/5250 (epoch 27.486), train_loss = 0.52466147, grad/param norm = 7.3233e-02, time/batch = 0.2576s	
2887/5250 (epoch 27.495), train_loss = 0.53020416, grad/param norm = 7.2978e-02, time/batch = 0.2577s	
2888/5250 (epoch 27.505), train_loss = 0.53964264, grad/param norm = 7.6736e-02, time/batch = 0.2579s	
2889/5250 (epoch 27.514), train_loss = 0.52653992, grad/param norm = 7.1851e-02, time/batch = 0.2577s	
2890/5250 (epoch 27.524), train_loss = 0.52826840, grad/param norm = 7.5557e-02, time/batch = 0.2577s	
2891/5250 (epoch 27.533), train_loss = 0.52238711, grad/param norm = 7.1055e-02, time/batch = 0.2591s	
2892/5250 (epoch 27.543), train_loss = 0.51983815, grad/param norm = 7.1502e-02, time/batch = 0.2577s	
2893/5250 (epoch 27.552), train_loss = 0.51799340, grad/param norm = 7.2303e-02, time/batch = 0.2580s	
2894/5250 (epoch 27.562), train_loss = 0.52248048, grad/param norm = 6.9927e-02, time/batch = 0.2575s	
2895/5250 (epoch 27.571), train_loss = 0.51954388, grad/param norm = 7.8296e-02, time/batch = 0.2575s	
2896/5250 (epoch 27.581), train_loss = 0.52856076, grad/param norm = 7.8281e-02, time/batch = 0.2575s	
2897/5250 (epoch 27.590), train_loss = 0.52974585, grad/param norm = 7.8036e-02, time/batch = 0.2578s	
2898/5250 (epoch 27.600), train_loss = 0.53070145, grad/param norm = 7.6211e-02, time/batch = 0.2580s	
2899/5250 (epoch 27.610), train_loss = 0.52863693, grad/param norm = 7.3233e-02, time/batch = 0.2576s	
2900/5250 (epoch 27.619), train_loss = 0.52877098, grad/param norm = 7.5002e-02, time/batch = 0.2575s	
2901/5250 (epoch 27.629), train_loss = 0.51201291, grad/param norm = 7.2461e-02, time/batch = 0.2586s	
2902/5250 (epoch 27.638), train_loss = 0.51896482, grad/param norm = 7.3496e-02, time/batch = 0.2574s	
2903/5250 (epoch 27.648), train_loss = 0.52865329, grad/param norm = 7.3634e-02, time/batch = 0.2579s	
2904/5250 (epoch 27.657), train_loss = 0.52432254, grad/param norm = 7.5574e-02, time/batch = 0.2574s	
2905/5250 (epoch 27.667), train_loss = 0.53192013, grad/param norm = 8.0476e-02, time/batch = 0.2577s	
2906/5250 (epoch 27.676), train_loss = 0.52104396, grad/param norm = 7.3433e-02, time/batch = 0.2577s	
2907/5250 (epoch 27.686), train_loss = 0.51765317, grad/param norm = 7.6688e-02, time/batch = 0.2576s	
2908/5250 (epoch 27.695), train_loss = 0.52380194, grad/param norm = 7.9080e-02, time/batch = 0.2577s	
2909/5250 (epoch 27.705), train_loss = 0.52367570, grad/param norm = 8.1569e-02, time/batch = 0.2581s	
2910/5250 (epoch 27.714), train_loss = 0.52693189, grad/param norm = 7.7668e-02, time/batch = 0.2574s	
2911/5250 (epoch 27.724), train_loss = 0.51863080, grad/param norm = 7.4498e-02, time/batch = 0.2585s	
2912/5250 (epoch 27.733), train_loss = 0.51550551, grad/param norm = 7.5927e-02, time/batch = 0.2575s	
2913/5250 (epoch 27.743), train_loss = 0.53523036, grad/param norm = 8.0016e-02, time/batch = 0.2576s	
2914/5250 (epoch 27.752), train_loss = 0.52880706, grad/param norm = 8.0378e-02, time/batch = 0.2579s	
2915/5250 (epoch 27.762), train_loss = 0.53953389, grad/param norm = 7.5830e-02, time/batch = 0.2578s	
2916/5250 (epoch 27.771), train_loss = 0.52327684, grad/param norm = 7.9322e-02, time/batch = 0.2578s	
2917/5250 (epoch 27.781), train_loss = 0.52460883, grad/param norm = 7.5660e-02, time/batch = 0.2578s	
2918/5250 (epoch 27.790), train_loss = 0.52644047, grad/param norm = 7.3347e-02, time/batch = 0.2578s	
2919/5250 (epoch 27.800), train_loss = 0.50758659, grad/param norm = 7.1395e-02, time/batch = 0.2579s	
2920/5250 (epoch 27.810), train_loss = 0.50861340, grad/param norm = 7.0321e-02, time/batch = 0.2575s	
2921/5250 (epoch 27.819), train_loss = 0.52624742, grad/param norm = 7.7743e-02, time/batch = 0.2586s	
2922/5250 (epoch 27.829), train_loss = 0.51642405, grad/param norm = 7.4521e-02, time/batch = 0.2576s	
2923/5250 (epoch 27.838), train_loss = 0.50260644, grad/param norm = 7.4438e-02, time/batch = 0.2573s	
2924/5250 (epoch 27.848), train_loss = 0.51619292, grad/param norm = 7.3316e-02, time/batch = 0.2578s	
2925/5250 (epoch 27.857), train_loss = 0.50974809, grad/param norm = 7.3517e-02, time/batch = 0.2580s	
2926/5250 (epoch 27.867), train_loss = 0.50650539, grad/param norm = 7.4734e-02, time/batch = 0.2573s	
2927/5250 (epoch 27.876), train_loss = 0.50337975, grad/param norm = 7.4079e-02, time/batch = 0.2576s	
2928/5250 (epoch 27.886), train_loss = 0.52564343, grad/param norm = 7.5184e-02, time/batch = 0.2579s	
2929/5250 (epoch 27.895), train_loss = 0.52332224, grad/param norm = 7.6870e-02, time/batch = 0.2578s	
2930/5250 (epoch 27.905), train_loss = 0.53450375, grad/param norm = 7.8746e-02, time/batch = 0.2577s	
2931/5250 (epoch 27.914), train_loss = 0.52142959, grad/param norm = 7.6876e-02, time/batch = 0.2587s	
2932/5250 (epoch 27.924), train_loss = 0.52300347, grad/param norm = 7.8199e-02, time/batch = 0.2578s	
2933/5250 (epoch 27.933), train_loss = 0.52932858, grad/param norm = 7.8846e-02, time/batch = 0.2579s	
2934/5250 (epoch 27.943), train_loss = 0.53107540, grad/param norm = 7.5517e-02, time/batch = 0.2576s	
2935/5250 (epoch 27.952), train_loss = 0.54291664, grad/param norm = 7.7115e-02, time/batch = 0.2579s	
2936/5250 (epoch 27.962), train_loss = 0.52362847, grad/param norm = 7.5046e-02, time/batch = 0.2580s	
2937/5250 (epoch 27.971), train_loss = 0.53714958, grad/param norm = 7.5566e-02, time/batch = 0.2580s	
2938/5250 (epoch 27.981), train_loss = 0.52137729, grad/param norm = 7.7700e-02, time/batch = 0.2577s	
2939/5250 (epoch 27.990), train_loss = 0.53074873, grad/param norm = 7.7300e-02, time/batch = 0.2576s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
2940/5250 (epoch 28.000), train_loss = 0.50425566, grad/param norm = 7.4503e-02, time/batch = 0.2577s	
2941/5250 (epoch 28.010), train_loss = 0.71263633, grad/param norm = 8.4216e-02, time/batch = 0.2588s	
2942/5250 (epoch 28.019), train_loss = 0.53091848, grad/param norm = 7.8820e-02, time/batch = 0.2575s	
2943/5250 (epoch 28.029), train_loss = 0.52583443, grad/param norm = 7.8044e-02, time/batch = 0.2576s	
2944/5250 (epoch 28.038), train_loss = 0.52779397, grad/param norm = 7.5089e-02, time/batch = 0.2582s	
2945/5250 (epoch 28.048), train_loss = 0.50805338, grad/param norm = 7.0895e-02, time/batch = 0.2578s	
2946/5250 (epoch 28.057), train_loss = 0.51931683, grad/param norm = 7.1622e-02, time/batch = 0.2573s	
2947/5250 (epoch 28.067), train_loss = 0.51842048, grad/param norm = 7.5686e-02, time/batch = 0.2578s	
2948/5250 (epoch 28.076), train_loss = 0.51163790, grad/param norm = 7.3190e-02, time/batch = 0.2577s	
2949/5250 (epoch 28.086), train_loss = 0.51207791, grad/param norm = 7.5840e-02, time/batch = 0.2577s	
2950/5250 (epoch 28.095), train_loss = 0.51694338, grad/param norm = 7.5867e-02, time/batch = 0.2575s	
2951/5250 (epoch 28.105), train_loss = 0.52079417, grad/param norm = 7.8969e-02, time/batch = 0.2584s	
2952/5250 (epoch 28.114), train_loss = 0.52474351, grad/param norm = 7.4751e-02, time/batch = 0.2575s	
2953/5250 (epoch 28.124), train_loss = 0.53376089, grad/param norm = 7.5178e-02, time/batch = 0.2577s	
2954/5250 (epoch 28.133), train_loss = 0.51671357, grad/param norm = 7.1772e-02, time/batch = 0.2575s	
2955/5250 (epoch 28.143), train_loss = 0.51196144, grad/param norm = 7.4381e-02, time/batch = 0.2578s	
2956/5250 (epoch 28.152), train_loss = 0.50380736, grad/param norm = 6.8569e-02, time/batch = 0.2574s	
2957/5250 (epoch 28.162), train_loss = 0.50976499, grad/param norm = 7.3454e-02, time/batch = 0.2582s	
2958/5250 (epoch 28.171), train_loss = 0.50662510, grad/param norm = 7.2761e-02, time/batch = 0.2577s	
2959/5250 (epoch 28.181), train_loss = 0.50707406, grad/param norm = 7.3852e-02, time/batch = 0.2578s	
2960/5250 (epoch 28.190), train_loss = 0.50505144, grad/param norm = 7.4933e-02, time/batch = 0.2578s	
2961/5250 (epoch 28.200), train_loss = 0.52144085, grad/param norm = 7.7112e-02, time/batch = 0.2585s	
2962/5250 (epoch 28.210), train_loss = 0.51642020, grad/param norm = 7.4784e-02, time/batch = 0.2574s	
2963/5250 (epoch 28.219), train_loss = 0.51681865, grad/param norm = 7.2666e-02, time/batch = 0.2577s	
2964/5250 (epoch 28.229), train_loss = 0.51448612, grad/param norm = 7.3362e-02, time/batch = 0.2576s	
2965/5250 (epoch 28.238), train_loss = 0.51019958, grad/param norm = 7.0661e-02, time/batch = 0.2573s	
2966/5250 (epoch 28.248), train_loss = 0.50333173, grad/param norm = 7.2952e-02, time/batch = 0.2572s	
2967/5250 (epoch 28.257), train_loss = 0.51169077, grad/param norm = 7.3729e-02, time/batch = 0.2578s	
2968/5250 (epoch 28.267), train_loss = 0.50810977, grad/param norm = 7.2744e-02, time/batch = 0.2577s	
2969/5250 (epoch 28.276), train_loss = 0.51328385, grad/param norm = 7.3500e-02, time/batch = 0.2578s	
2970/5250 (epoch 28.286), train_loss = 0.50715385, grad/param norm = 7.1580e-02, time/batch = 0.2581s	
2971/5250 (epoch 28.295), train_loss = 0.51170447, grad/param norm = 7.1163e-02, time/batch = 0.2587s	
2972/5250 (epoch 28.305), train_loss = 0.48923390, grad/param norm = 7.3494e-02, time/batch = 0.2580s	
2973/5250 (epoch 28.314), train_loss = 0.48244138, grad/param norm = 7.3349e-02, time/batch = 0.2577s	
2974/5250 (epoch 28.324), train_loss = 0.50406100, grad/param norm = 7.4548e-02, time/batch = 0.2579s	
2975/5250 (epoch 28.333), train_loss = 0.50877003, grad/param norm = 7.6440e-02, time/batch = 0.2580s	
2976/5250 (epoch 28.343), train_loss = 0.51207229, grad/param norm = 7.7822e-02, time/batch = 0.2579s	
2977/5250 (epoch 28.352), train_loss = 0.49786560, grad/param norm = 7.5165e-02, time/batch = 0.2572s	
2978/5250 (epoch 28.362), train_loss = 0.51493700, grad/param norm = 7.7566e-02, time/batch = 0.2575s	
2979/5250 (epoch 28.371), train_loss = 0.51144057, grad/param norm = 7.7976e-02, time/batch = 0.2577s	
2980/5250 (epoch 28.381), train_loss = 0.50939202, grad/param norm = 7.4685e-02, time/batch = 0.2576s	
2981/5250 (epoch 28.390), train_loss = 0.51023949, grad/param norm = 7.9636e-02, time/batch = 0.2590s	
2982/5250 (epoch 28.400), train_loss = 0.52185803, grad/param norm = 8.0120e-02, time/batch = 0.2578s	
2983/5250 (epoch 28.410), train_loss = 0.50970881, grad/param norm = 8.0389e-02, time/batch = 0.2578s	
2984/5250 (epoch 28.419), train_loss = 0.51532774, grad/param norm = 7.9587e-02, time/batch = 0.2576s	
2985/5250 (epoch 28.429), train_loss = 0.51544141, grad/param norm = 7.8337e-02, time/batch = 0.2579s	
2986/5250 (epoch 28.438), train_loss = 0.51788511, grad/param norm = 7.8190e-02, time/batch = 0.2572s	
2987/5250 (epoch 28.448), train_loss = 0.51184789, grad/param norm = 7.4965e-02, time/batch = 0.2576s	
2988/5250 (epoch 28.457), train_loss = 0.50230599, grad/param norm = 7.0131e-02, time/batch = 0.2574s	
2989/5250 (epoch 28.467), train_loss = 0.50039085, grad/param norm = 7.2809e-02, time/batch = 0.2571s	
2990/5250 (epoch 28.476), train_loss = 0.48650406, grad/param norm = 7.1123e-02, time/batch = 0.2576s	
2991/5250 (epoch 28.486), train_loss = 0.49771063, grad/param norm = 7.0444e-02, time/batch = 0.2584s	
2992/5250 (epoch 28.495), train_loss = 0.50394098, grad/param norm = 7.2305e-02, time/batch = 0.2578s	
2993/5250 (epoch 28.505), train_loss = 0.52086792, grad/param norm = 8.1121e-02, time/batch = 0.2580s	
2994/5250 (epoch 28.514), train_loss = 0.51808085, grad/param norm = 8.0147e-02, time/batch = 0.2579s	
2995/5250 (epoch 28.524), train_loss = 0.50156839, grad/param norm = 7.3938e-02, time/batch = 0.2579s	
2996/5250 (epoch 28.533), train_loss = 0.50507207, grad/param norm = 7.5700e-02, time/batch = 0.2576s	
2997/5250 (epoch 28.543), train_loss = 0.50171967, grad/param norm = 7.6079e-02, time/batch = 0.2577s	
2998/5250 (epoch 28.552), train_loss = 0.49874438, grad/param norm = 7.3610e-02, time/batch = 0.2576s	
2999/5250 (epoch 28.562), train_loss = 0.50240106, grad/param norm = 7.2684e-02, time/batch = 0.2578s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch28.57_2.0517.t7	
3000/5250 (epoch 28.571), train_loss = 0.49370482, grad/param norm = 7.2471e-02, time/batch = 0.2575s	
3001/5250 (epoch 28.581), train_loss = 1.45232662, grad/param norm = 1.2112e-01, time/batch = 0.2592s	
3002/5250 (epoch 28.590), train_loss = 0.57009073, grad/param norm = 8.5679e-02, time/batch = 0.2593s	
3003/5250 (epoch 28.600), train_loss = 0.53073444, grad/param norm = 7.8226e-02, time/batch = 0.2591s	
3004/5250 (epoch 28.610), train_loss = 0.51773566, grad/param norm = 7.4410e-02, time/batch = 0.2599s	
3005/5250 (epoch 28.619), train_loss = 0.51397452, grad/param norm = 7.7706e-02, time/batch = 0.2586s	
3006/5250 (epoch 28.629), train_loss = 0.49769539, grad/param norm = 7.4195e-02, time/batch = 0.2584s	
3007/5250 (epoch 28.638), train_loss = 0.50806188, grad/param norm = 7.5408e-02, time/batch = 0.2584s	
3008/5250 (epoch 28.648), train_loss = 0.51420041, grad/param norm = 7.6197e-02, time/batch = 0.2583s	
3009/5250 (epoch 28.657), train_loss = 0.50493422, grad/param norm = 7.2327e-02, time/batch = 0.2583s	
3010/5250 (epoch 28.667), train_loss = 0.50747631, grad/param norm = 7.6543e-02, time/batch = 0.2580s	
3011/5250 (epoch 28.676), train_loss = 0.49940673, grad/param norm = 7.5714e-02, time/batch = 0.2593s	
3012/5250 (epoch 28.686), train_loss = 0.50154738, grad/param norm = 7.6546e-02, time/batch = 0.2578s	
3013/5250 (epoch 28.695), train_loss = 0.50142728, grad/param norm = 7.6906e-02, time/batch = 0.2580s	
3014/5250 (epoch 28.705), train_loss = 0.50369979, grad/param norm = 7.5345e-02, time/batch = 0.2583s	
3015/5250 (epoch 28.714), train_loss = 0.50624150, grad/param norm = 8.0846e-02, time/batch = 0.2585s	
3016/5250 (epoch 28.724), train_loss = 0.50989184, grad/param norm = 7.9031e-02, time/batch = 0.2578s	
3017/5250 (epoch 28.733), train_loss = 0.49661709, grad/param norm = 7.6996e-02, time/batch = 0.2582s	
3018/5250 (epoch 28.743), train_loss = 0.50758903, grad/param norm = 7.7840e-02, time/batch = 0.2580s	
3019/5250 (epoch 28.752), train_loss = 0.50231344, grad/param norm = 7.9069e-02, time/batch = 0.2582s	
3020/5250 (epoch 28.762), train_loss = 0.51167082, grad/param norm = 7.7263e-02, time/batch = 0.2583s	
3021/5250 (epoch 28.771), train_loss = 0.49401701, grad/param norm = 7.4657e-02, time/batch = 0.2591s	
3022/5250 (epoch 28.781), train_loss = 0.49468358, grad/param norm = 7.6321e-02, time/batch = 0.2580s	
3023/5250 (epoch 28.790), train_loss = 0.51112981, grad/param norm = 7.7510e-02, time/batch = 0.2585s	
3024/5250 (epoch 28.800), train_loss = 0.49706671, grad/param norm = 7.6750e-02, time/batch = 0.2585s	
3025/5250 (epoch 28.810), train_loss = 0.49797114, grad/param norm = 7.5841e-02, time/batch = 0.2583s	
3026/5250 (epoch 28.819), train_loss = 0.50610799, grad/param norm = 7.4467e-02, time/batch = 0.2581s	
3027/5250 (epoch 28.829), train_loss = 0.50319238, grad/param norm = 7.6348e-02, time/batch = 0.2585s	
3028/5250 (epoch 28.838), train_loss = 0.48411851, grad/param norm = 7.2786e-02, time/batch = 0.2582s	
3029/5250 (epoch 28.848), train_loss = 0.48491570, grad/param norm = 7.1432e-02, time/batch = 0.2580s	
3030/5250 (epoch 28.857), train_loss = 0.47730612, grad/param norm = 7.0826e-02, time/batch = 0.2582s	
3031/5250 (epoch 28.867), train_loss = 0.48611921, grad/param norm = 7.6437e-02, time/batch = 0.2588s	
3032/5250 (epoch 28.876), train_loss = 0.48127483, grad/param norm = 7.3203e-02, time/batch = 0.2579s	
3033/5250 (epoch 28.886), train_loss = 0.49975259, grad/param norm = 7.6653e-02, time/batch = 0.2585s	
3034/5250 (epoch 28.895), train_loss = 0.49509541, grad/param norm = 7.6450e-02, time/batch = 0.2582s	
3035/5250 (epoch 28.905), train_loss = 0.50335138, grad/param norm = 7.5358e-02, time/batch = 0.2581s	
3036/5250 (epoch 28.914), train_loss = 0.49270722, grad/param norm = 7.6344e-02, time/batch = 0.2580s	
3037/5250 (epoch 28.924), train_loss = 0.50145863, grad/param norm = 7.9457e-02, time/batch = 0.2581s	
3038/5250 (epoch 28.933), train_loss = 0.50123738, grad/param norm = 7.4718e-02, time/batch = 0.2578s	
3039/5250 (epoch 28.943), train_loss = 0.50275179, grad/param norm = 7.4806e-02, time/batch = 0.2578s	
3040/5250 (epoch 28.952), train_loss = 0.51822573, grad/param norm = 7.6710e-02, time/batch = 0.2583s	
3041/5250 (epoch 28.962), train_loss = 0.50162343, grad/param norm = 7.4882e-02, time/batch = 0.2592s	
3042/5250 (epoch 28.971), train_loss = 0.50704174, grad/param norm = 7.3391e-02, time/batch = 0.2580s	
3043/5250 (epoch 28.981), train_loss = 0.49674863, grad/param norm = 7.6069e-02, time/batch = 0.2582s	
3044/5250 (epoch 28.990), train_loss = 0.49884140, grad/param norm = 7.2695e-02, time/batch = 0.2582s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
3045/5250 (epoch 29.000), train_loss = 0.47998371, grad/param norm = 7.3964e-02, time/batch = 0.2583s	
3046/5250 (epoch 29.010), train_loss = 0.67732595, grad/param norm = 8.2219e-02, time/batch = 0.2581s	
3047/5250 (epoch 29.019), train_loss = 0.50931630, grad/param norm = 7.9660e-02, time/batch = 0.2580s	
3048/5250 (epoch 29.029), train_loss = 0.50992525, grad/param norm = 8.0544e-02, time/batch = 0.2578s	
3049/5250 (epoch 29.038), train_loss = 0.50691518, grad/param norm = 7.4192e-02, time/batch = 0.2580s	
3050/5250 (epoch 29.048), train_loss = 0.48681555, grad/param norm = 7.5551e-02, time/batch = 0.2581s	
3051/5250 (epoch 29.057), train_loss = 0.50114574, grad/param norm = 7.2519e-02, time/batch = 0.2588s	
3052/5250 (epoch 29.067), train_loss = 0.49099549, grad/param norm = 7.4082e-02, time/batch = 0.2582s	
3053/5250 (epoch 29.076), train_loss = 0.48917546, grad/param norm = 7.4896e-02, time/batch = 0.2585s	
3054/5250 (epoch 29.086), train_loss = 0.48722342, grad/param norm = 7.3897e-02, time/batch = 0.2582s	
3055/5250 (epoch 29.095), train_loss = 0.48470482, grad/param norm = 7.3406e-02, time/batch = 0.2581s	
3056/5250 (epoch 29.105), train_loss = 0.49611216, grad/param norm = 7.7225e-02, time/batch = 0.2578s	
3057/5250 (epoch 29.114), train_loss = 0.49840317, grad/param norm = 7.2891e-02, time/batch = 0.2581s	
3058/5250 (epoch 29.124), train_loss = 0.51000493, grad/param norm = 7.4758e-02, time/batch = 0.2583s	
3059/5250 (epoch 29.133), train_loss = 0.49853718, grad/param norm = 7.5774e-02, time/batch = 0.2583s	
3060/5250 (epoch 29.143), train_loss = 0.48665668, grad/param norm = 7.1992e-02, time/batch = 0.2583s	
3061/5250 (epoch 29.152), train_loss = 0.47883430, grad/param norm = 7.1963e-02, time/batch = 0.2590s	
3062/5250 (epoch 29.162), train_loss = 0.48625400, grad/param norm = 7.1545e-02, time/batch = 0.2584s	
3063/5250 (epoch 29.171), train_loss = 0.48137683, grad/param norm = 7.2007e-02, time/batch = 0.2584s	
3064/5250 (epoch 29.181), train_loss = 0.48499861, grad/param norm = 7.3910e-02, time/batch = 0.2582s	
3065/5250 (epoch 29.190), train_loss = 0.48126952, grad/param norm = 7.5254e-02, time/batch = 0.2582s	
3066/5250 (epoch 29.200), train_loss = 0.48308392, grad/param norm = 7.4737e-02, time/batch = 0.2580s	
3067/5250 (epoch 29.210), train_loss = 0.49405215, grad/param norm = 7.7003e-02, time/batch = 0.2579s	
3068/5250 (epoch 29.219), train_loss = 0.50014672, grad/param norm = 7.4575e-02, time/batch = 0.2583s	
3069/5250 (epoch 29.229), train_loss = 0.49326737, grad/param norm = 7.4647e-02, time/batch = 0.2581s	
3070/5250 (epoch 29.238), train_loss = 0.48561850, grad/param norm = 7.3152e-02, time/batch = 0.2585s	
3071/5250 (epoch 29.248), train_loss = 0.48371081, grad/param norm = 7.3691e-02, time/batch = 0.2587s	
3072/5250 (epoch 29.257), train_loss = 0.48356589, grad/param norm = 7.5187e-02, time/batch = 0.2582s	
3073/5250 (epoch 29.267), train_loss = 0.48445621, grad/param norm = 7.2461e-02, time/batch = 0.2580s	
3074/5250 (epoch 29.276), train_loss = 0.48603650, grad/param norm = 7.3708e-02, time/batch = 0.2584s	
3075/5250 (epoch 29.286), train_loss = 0.48490354, grad/param norm = 7.1418e-02, time/batch = 0.2579s	
3076/5250 (epoch 29.295), train_loss = 0.48561105, grad/param norm = 7.3687e-02, time/batch = 0.2583s	
3077/5250 (epoch 29.305), train_loss = 0.46463007, grad/param norm = 7.1853e-02, time/batch = 0.2579s	
3078/5250 (epoch 29.314), train_loss = 0.46238485, grad/param norm = 7.4894e-02, time/batch = 0.2581s	
3079/5250 (epoch 29.324), train_loss = 0.47793380, grad/param norm = 7.5287e-02, time/batch = 0.2581s	
3080/5250 (epoch 29.333), train_loss = 0.49076125, grad/param norm = 7.7785e-02, time/batch = 0.2579s	
3081/5250 (epoch 29.343), train_loss = 0.49219452, grad/param norm = 7.9686e-02, time/batch = 0.2591s	
3082/5250 (epoch 29.352), train_loss = 0.47615853, grad/param norm = 7.6246e-02, time/batch = 0.2583s	
3083/5250 (epoch 29.362), train_loss = 0.48612697, grad/param norm = 7.5596e-02, time/batch = 0.2584s	
3084/5250 (epoch 29.371), train_loss = 0.48703517, grad/param norm = 8.0188e-02, time/batch = 0.2582s	
3085/5250 (epoch 29.381), train_loss = 0.49315615, grad/param norm = 8.0519e-02, time/batch = 0.2580s	
3086/5250 (epoch 29.390), train_loss = 0.48291217, grad/param norm = 7.7031e-02, time/batch = 0.2580s	
3087/5250 (epoch 29.400), train_loss = 0.49989047, grad/param norm = 8.0971e-02, time/batch = 0.2581s	
3088/5250 (epoch 29.410), train_loss = 0.48636681, grad/param norm = 7.6770e-02, time/batch = 0.2579s	
3089/5250 (epoch 29.419), train_loss = 0.48803537, grad/param norm = 7.7745e-02, time/batch = 0.2579s	
3090/5250 (epoch 29.429), train_loss = 0.48772530, grad/param norm = 8.0500e-02, time/batch = 0.2581s	
3091/5250 (epoch 29.438), train_loss = 0.49872790, grad/param norm = 8.1182e-02, time/batch = 0.2591s	
3092/5250 (epoch 29.448), train_loss = 0.48875381, grad/param norm = 7.9796e-02, time/batch = 0.2579s	
3093/5250 (epoch 29.457), train_loss = 0.47792536, grad/param norm = 7.0576e-02, time/batch = 0.2584s	
3094/5250 (epoch 29.467), train_loss = 0.48417462, grad/param norm = 7.6740e-02, time/batch = 0.2581s	
3095/5250 (epoch 29.476), train_loss = 0.46836385, grad/param norm = 7.3300e-02, time/batch = 0.2580s	
3096/5250 (epoch 29.486), train_loss = 0.47878136, grad/param norm = 7.6001e-02, time/batch = 0.2579s	
3097/5250 (epoch 29.495), train_loss = 0.48354253, grad/param norm = 7.2857e-02, time/batch = 0.2581s	
3098/5250 (epoch 29.505), train_loss = 0.49071816, grad/param norm = 7.6433e-02, time/batch = 0.2582s	
3099/5250 (epoch 29.514), train_loss = 0.49221391, grad/param norm = 8.1468e-02, time/batch = 0.2586s	
3100/5250 (epoch 29.524), train_loss = 0.49027493, grad/param norm = 8.4698e-02, time/batch = 0.2580s	
3101/5250 (epoch 29.533), train_loss = 0.49352703, grad/param norm = 8.0582e-02, time/batch = 0.2589s	
3102/5250 (epoch 29.543), train_loss = 0.48729354, grad/param norm = 7.7090e-02, time/batch = 0.2584s	
3103/5250 (epoch 29.552), train_loss = 0.47262026, grad/param norm = 7.5977e-02, time/batch = 0.2583s	
3104/5250 (epoch 29.562), train_loss = 0.47888591, grad/param norm = 7.4198e-02, time/batch = 0.2584s	
3105/5250 (epoch 29.571), train_loss = 0.47330045, grad/param norm = 7.3073e-02, time/batch = 0.2584s	
3106/5250 (epoch 29.581), train_loss = 0.51827123, grad/param norm = 7.7032e-02, time/batch = 0.2580s	
3107/5250 (epoch 29.590), train_loss = 0.48539651, grad/param norm = 7.1286e-02, time/batch = 0.2578s	
3108/5250 (epoch 29.600), train_loss = 0.48306868, grad/param norm = 7.4410e-02, time/batch = 0.2581s	
3109/5250 (epoch 29.610), train_loss = 0.48577518, grad/param norm = 7.8623e-02, time/batch = 0.2582s	
3110/5250 (epoch 29.619), train_loss = 0.48349660, grad/param norm = 7.3853e-02, time/batch = 0.2580s	
3111/5250 (epoch 29.629), train_loss = 0.46700835, grad/param norm = 7.6401e-02, time/batch = 0.2590s	
3112/5250 (epoch 29.638), train_loss = 0.48004005, grad/param norm = 7.6285e-02, time/batch = 0.2582s	
3113/5250 (epoch 29.648), train_loss = 0.47548078, grad/param norm = 7.0691e-02, time/batch = 0.2582s	
3114/5250 (epoch 29.657), train_loss = 0.47660639, grad/param norm = 7.7725e-02, time/batch = 0.2587s	
3115/5250 (epoch 29.667), train_loss = 0.48350107, grad/param norm = 7.6424e-02, time/batch = 0.2584s	
3116/5250 (epoch 29.676), train_loss = 0.47055168, grad/param norm = 7.2181e-02, time/batch = 0.2579s	
3117/5250 (epoch 29.686), train_loss = 0.47144083, grad/param norm = 7.6391e-02, time/batch = 0.2580s	
3118/5250 (epoch 29.695), train_loss = 0.46717277, grad/param norm = 7.3155e-02, time/batch = 0.2581s	
3119/5250 (epoch 29.705), train_loss = 0.47211243, grad/param norm = 7.4834e-02, time/batch = 0.2582s	
3120/5250 (epoch 29.714), train_loss = 0.47357441, grad/param norm = 7.7133e-02, time/batch = 0.2579s	
3121/5250 (epoch 29.724), train_loss = 0.47247691, grad/param norm = 7.1773e-02, time/batch = 0.2590s	
3122/5250 (epoch 29.733), train_loss = 0.46728512, grad/param norm = 7.4958e-02, time/batch = 0.2584s	
3123/5250 (epoch 29.743), train_loss = 0.47915186, grad/param norm = 7.9553e-02, time/batch = 0.2585s	
3124/5250 (epoch 29.752), train_loss = 0.47871837, grad/param norm = 7.4021e-02, time/batch = 0.2582s	
3125/5250 (epoch 29.762), train_loss = 0.48436946, grad/param norm = 7.7352e-02, time/batch = 0.2583s	
3126/5250 (epoch 29.771), train_loss = 0.46668065, grad/param norm = 7.5023e-02, time/batch = 0.2586s	
3127/5250 (epoch 29.781), train_loss = 0.47613067, grad/param norm = 7.8347e-02, time/batch = 0.2581s	
3128/5250 (epoch 29.790), train_loss = 0.48448566, grad/param norm = 7.7852e-02, time/batch = 0.2582s	
3129/5250 (epoch 29.800), train_loss = 0.46317248, grad/param norm = 7.1196e-02, time/batch = 0.2582s	
3130/5250 (epoch 29.810), train_loss = 0.46406461, grad/param norm = 7.3714e-02, time/batch = 0.2581s	
3131/5250 (epoch 29.819), train_loss = 0.47795764, grad/param norm = 7.8135e-02, time/batch = 0.2587s	
3132/5250 (epoch 29.829), train_loss = 0.47130880, grad/param norm = 8.1516e-02, time/batch = 0.2583s	
3133/5250 (epoch 29.838), train_loss = 0.46384486, grad/param norm = 7.5191e-02, time/batch = 0.2581s	
3134/5250 (epoch 29.848), train_loss = 0.46474738, grad/param norm = 7.3345e-02, time/batch = 0.2581s	
3135/5250 (epoch 29.857), train_loss = 0.46617491, grad/param norm = 7.3898e-02, time/batch = 0.2581s	
3136/5250 (epoch 29.867), train_loss = 0.46675999, grad/param norm = 7.5668e-02, time/batch = 0.2581s	
3137/5250 (epoch 29.876), train_loss = 0.45499759, grad/param norm = 7.3794e-02, time/batch = 0.2579s	
3138/5250 (epoch 29.886), train_loss = 0.47606102, grad/param norm = 7.5810e-02, time/batch = 0.2582s	
3139/5250 (epoch 29.895), train_loss = 0.47735918, grad/param norm = 7.8413e-02, time/batch = 0.2583s	
3140/5250 (epoch 29.905), train_loss = 0.48454182, grad/param norm = 7.9846e-02, time/batch = 0.2578s	
3141/5250 (epoch 29.914), train_loss = 0.46269929, grad/param norm = 7.3712e-02, time/batch = 0.2590s	
3142/5250 (epoch 29.924), train_loss = 0.47344315, grad/param norm = 7.7605e-02, time/batch = 0.2580s	
3143/5250 (epoch 29.933), train_loss = 0.47920900, grad/param norm = 7.9254e-02, time/batch = 0.2582s	
3144/5250 (epoch 29.943), train_loss = 0.48344889, grad/param norm = 7.7127e-02, time/batch = 0.2582s	
3145/5250 (epoch 29.952), train_loss = 0.48423048, grad/param norm = 7.2194e-02, time/batch = 0.2584s	
3146/5250 (epoch 29.962), train_loss = 0.47037538, grad/param norm = 7.2237e-02, time/batch = 0.2579s	
3147/5250 (epoch 29.971), train_loss = 0.47930366, grad/param norm = 7.2837e-02, time/batch = 0.2580s	
3148/5250 (epoch 29.981), train_loss = 0.47124730, grad/param norm = 7.3874e-02, time/batch = 0.2582s	
3149/5250 (epoch 29.990), train_loss = 0.47749584, grad/param norm = 7.5695e-02, time/batch = 0.2582s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
3150/5250 (epoch 30.000), train_loss = 0.45460442, grad/param norm = 7.2617e-02, time/batch = 0.2580s	
3151/5250 (epoch 30.010), train_loss = 0.65740049, grad/param norm = 8.0543e-02, time/batch = 0.2593s	
3152/5250 (epoch 30.019), train_loss = 0.48811071, grad/param norm = 8.0189e-02, time/batch = 0.2581s	
3153/5250 (epoch 30.029), train_loss = 0.47796340, grad/param norm = 8.1156e-02, time/batch = 0.2581s	
3154/5250 (epoch 30.038), train_loss = 0.48963752, grad/param norm = 7.8720e-02, time/batch = 0.2582s	
3155/5250 (epoch 30.048), train_loss = 0.46118114, grad/param norm = 7.3418e-02, time/batch = 0.2585s	
3156/5250 (epoch 30.057), train_loss = 0.47549210, grad/param norm = 7.3158e-02, time/batch = 0.2586s	
3157/5250 (epoch 30.067), train_loss = 0.46594193, grad/param norm = 7.3476e-02, time/batch = 0.2582s	
3158/5250 (epoch 30.076), train_loss = 0.47171285, grad/param norm = 8.0737e-02, time/batch = 0.2584s	
3159/5250 (epoch 30.086), train_loss = 0.46468228, grad/param norm = 7.3640e-02, time/batch = 0.2581s	
3160/5250 (epoch 30.095), train_loss = 0.47110372, grad/param norm = 7.6022e-02, time/batch = 0.2578s	
3161/5250 (epoch 30.105), train_loss = 0.47580772, grad/param norm = 7.8927e-02, time/batch = 0.2593s	
3162/5250 (epoch 30.114), train_loss = 0.47919957, grad/param norm = 7.5917e-02, time/batch = 0.2580s	
3163/5250 (epoch 30.124), train_loss = 0.48610458, grad/param norm = 7.4642e-02, time/batch = 0.2583s	
3164/5250 (epoch 30.133), train_loss = 0.47084985, grad/param norm = 7.2323e-02, time/batch = 0.2584s	
3165/5250 (epoch 30.143), train_loss = 0.46611898, grad/param norm = 7.3558e-02, time/batch = 0.2580s	
3166/5250 (epoch 30.152), train_loss = 0.46567445, grad/param norm = 7.5668e-02, time/batch = 0.2581s	
3167/5250 (epoch 30.162), train_loss = 0.46852348, grad/param norm = 7.2375e-02, time/batch = 0.2584s	
3168/5250 (epoch 30.171), train_loss = 0.46275678, grad/param norm = 7.3397e-02, time/batch = 0.2585s	
3169/5250 (epoch 30.181), train_loss = 0.45755888, grad/param norm = 7.2934e-02, time/batch = 0.2580s	
3170/5250 (epoch 30.190), train_loss = 0.45640522, grad/param norm = 7.2948e-02, time/batch = 0.2580s	
3171/5250 (epoch 30.200), train_loss = 0.46163128, grad/param norm = 7.3266e-02, time/batch = 0.2590s	
3172/5250 (epoch 30.210), train_loss = 0.47009641, grad/param norm = 7.5976e-02, time/batch = 0.2580s	
3173/5250 (epoch 30.219), train_loss = 0.47054585, grad/param norm = 7.5296e-02, time/batch = 0.2585s	
3174/5250 (epoch 30.229), train_loss = 0.47638606, grad/param norm = 7.5922e-02, time/batch = 0.2583s	
3175/5250 (epoch 30.238), train_loss = 0.46365763, grad/param norm = 7.3943e-02, time/batch = 0.2583s	
3176/5250 (epoch 30.248), train_loss = 0.46083356, grad/param norm = 7.1842e-02, time/batch = 0.2579s	
3177/5250 (epoch 30.257), train_loss = 0.45975804, grad/param norm = 7.2261e-02, time/batch = 0.2583s	
3178/5250 (epoch 30.267), train_loss = 0.46431234, grad/param norm = 7.4167e-02, time/batch = 0.2581s	
3179/5250 (epoch 30.276), train_loss = 0.45940038, grad/param norm = 7.1953e-02, time/batch = 0.2581s	
3180/5250 (epoch 30.286), train_loss = 0.46044110, grad/param norm = 7.4450e-02, time/batch = 0.2583s	
3181/5250 (epoch 30.295), train_loss = 0.46893609, grad/param norm = 7.2807e-02, time/batch = 0.2589s	
3182/5250 (epoch 30.305), train_loss = 0.44229211, grad/param norm = 7.4145e-02, time/batch = 0.2585s	
3183/5250 (epoch 30.314), train_loss = 0.44670760, grad/param norm = 8.0685e-02, time/batch = 0.2585s	
3184/5250 (epoch 30.324), train_loss = 0.45274466, grad/param norm = 7.2704e-02, time/batch = 0.2581s	
3185/5250 (epoch 30.333), train_loss = 0.45957732, grad/param norm = 7.7092e-02, time/batch = 0.2580s	
3186/5250 (epoch 30.343), train_loss = 0.46577681, grad/param norm = 7.7771e-02, time/batch = 0.2583s	
3187/5250 (epoch 30.352), train_loss = 0.45676642, grad/param norm = 7.8289e-02, time/batch = 0.2583s	
3188/5250 (epoch 30.362), train_loss = 0.47301296, grad/param norm = 7.9778e-02, time/batch = 0.2584s	
3189/5250 (epoch 30.371), train_loss = 0.46074530, grad/param norm = 7.9481e-02, time/batch = 0.2582s	
3190/5250 (epoch 30.381), train_loss = 0.46828863, grad/param norm = 7.8196e-02, time/batch = 0.2580s	
3191/5250 (epoch 30.390), train_loss = 0.46406802, grad/param norm = 8.3077e-02, time/batch = 0.2593s	
3192/5250 (epoch 30.400), train_loss = 0.47214259, grad/param norm = 7.5022e-02, time/batch = 0.2582s	
3193/5250 (epoch 30.410), train_loss = 0.45933256, grad/param norm = 7.7383e-02, time/batch = 0.2585s	
3194/5250 (epoch 30.419), train_loss = 0.47676124, grad/param norm = 8.2284e-02, time/batch = 0.2582s	
3195/5250 (epoch 30.429), train_loss = 0.46233848, grad/param norm = 7.9477e-02, time/batch = 0.2581s	
3196/5250 (epoch 30.438), train_loss = 0.47242521, grad/param norm = 7.9853e-02, time/batch = 0.2582s	
3197/5250 (epoch 30.448), train_loss = 0.46609958, grad/param norm = 7.4858e-02, time/batch = 0.2580s	
3198/5250 (epoch 30.457), train_loss = 0.46619006, grad/param norm = 7.7775e-02, time/batch = 0.2582s	
3199/5250 (epoch 30.467), train_loss = 0.46365250, grad/param norm = 7.8492e-02, time/batch = 0.2580s	
3200/5250 (epoch 30.476), train_loss = 0.44372058, grad/param norm = 7.3191e-02, time/batch = 0.2579s	
3201/5250 (epoch 30.486), train_loss = 0.45602444, grad/param norm = 7.4172e-02, time/batch = 0.2588s	
3202/5250 (epoch 30.495), train_loss = 0.46408842, grad/param norm = 7.5408e-02, time/batch = 0.2581s	
3203/5250 (epoch 30.505), train_loss = 0.47103017, grad/param norm = 7.9930e-02, time/batch = 0.2583s	
3204/5250 (epoch 30.514), train_loss = 0.46505037, grad/param norm = 7.5555e-02, time/batch = 0.2582s	
3205/5250 (epoch 30.524), train_loss = 0.45678429, grad/param norm = 7.5720e-02, time/batch = 0.2586s	
3206/5250 (epoch 30.533), train_loss = 0.46595459, grad/param norm = 8.0797e-02, time/batch = 0.2583s	
3207/5250 (epoch 30.543), train_loss = 0.46281710, grad/param norm = 8.3118e-02, time/batch = 0.2582s	
3208/5250 (epoch 30.552), train_loss = 0.45962632, grad/param norm = 7.8832e-02, time/batch = 0.2581s	
3209/5250 (epoch 30.562), train_loss = 0.45580704, grad/param norm = 7.3957e-02, time/batch = 0.2579s	
3210/5250 (epoch 30.571), train_loss = 0.44806223, grad/param norm = 7.3511e-02, time/batch = 0.2584s	
3211/5250 (epoch 30.581), train_loss = 0.49147800, grad/param norm = 7.9575e-02, time/batch = 0.2592s	
3212/5250 (epoch 30.590), train_loss = 0.45996771, grad/param norm = 7.2880e-02, time/batch = 0.2580s	
3213/5250 (epoch 30.600), train_loss = 0.46431798, grad/param norm = 7.4084e-02, time/batch = 0.2582s	
3214/5250 (epoch 30.610), train_loss = 0.46086095, grad/param norm = 7.4240e-02, time/batch = 0.2584s	
3215/5250 (epoch 30.619), train_loss = 0.45796455, grad/param norm = 7.7616e-02, time/batch = 0.2581s	
3216/5250 (epoch 30.629), train_loss = 0.44877846, grad/param norm = 7.4694e-02, time/batch = 0.2581s	
3217/5250 (epoch 30.638), train_loss = 0.45589909, grad/param norm = 7.3030e-02, time/batch = 0.2587s	
3218/5250 (epoch 30.648), train_loss = 0.45532976, grad/param norm = 7.1451e-02, time/batch = 0.2582s	
3219/5250 (epoch 30.657), train_loss = 0.45603265, grad/param norm = 7.4184e-02, time/batch = 0.2580s	
3220/5250 (epoch 30.667), train_loss = 0.45850540, grad/param norm = 7.4007e-02, time/batch = 0.2580s	
3221/5250 (epoch 30.676), train_loss = 0.45112391, grad/param norm = 7.5834e-02, time/batch = 0.2592s	
3222/5250 (epoch 30.686), train_loss = 0.45787401, grad/param norm = 7.5520e-02, time/batch = 0.2586s	
3223/5250 (epoch 30.695), train_loss = 0.45176384, grad/param norm = 7.7274e-02, time/batch = 0.2586s	
3224/5250 (epoch 30.705), train_loss = 0.45401063, grad/param norm = 7.6820e-02, time/batch = 0.2583s	
3225/5250 (epoch 30.714), train_loss = 0.45141619, grad/param norm = 7.7103e-02, time/batch = 0.2585s	
3226/5250 (epoch 30.724), train_loss = 0.45529802, grad/param norm = 7.7320e-02, time/batch = 0.2583s	
3227/5250 (epoch 30.733), train_loss = 0.44692248, grad/param norm = 7.5545e-02, time/batch = 0.2582s	
3228/5250 (epoch 30.743), train_loss = 0.45312396, grad/param norm = 7.6436e-02, time/batch = 0.2586s	
3229/5250 (epoch 30.752), train_loss = 0.45833494, grad/param norm = 7.9586e-02, time/batch = 0.2584s	
3230/5250 (epoch 30.762), train_loss = 0.46434547, grad/param norm = 7.5987e-02, time/batch = 0.2585s	
3231/5250 (epoch 30.771), train_loss = 0.45025665, grad/param norm = 7.8176e-02, time/batch = 0.2592s	
3232/5250 (epoch 30.781), train_loss = 0.44954132, grad/param norm = 7.5607e-02, time/batch = 0.2580s	
3233/5250 (epoch 30.790), train_loss = 0.46298390, grad/param norm = 8.0875e-02, time/batch = 0.2585s	
3234/5250 (epoch 30.800), train_loss = 0.45423263, grad/param norm = 7.9443e-02, time/batch = 0.2582s	
3235/5250 (epoch 30.810), train_loss = 0.45022335, grad/param norm = 7.6727e-02, time/batch = 0.2583s	
3236/5250 (epoch 30.819), train_loss = 0.46233017, grad/param norm = 7.6439e-02, time/batch = 0.2583s	
3237/5250 (epoch 30.829), train_loss = 0.44615248, grad/param norm = 7.3802e-02, time/batch = 0.2582s	
3238/5250 (epoch 30.838), train_loss = 0.44637253, grad/param norm = 7.8431e-02, time/batch = 0.2585s	
3239/5250 (epoch 30.848), train_loss = 0.44737362, grad/param norm = 7.4372e-02, time/batch = 0.2579s	
3240/5250 (epoch 30.857), train_loss = 0.44488369, grad/param norm = 7.5610e-02, time/batch = 0.2581s	
3241/5250 (epoch 30.867), train_loss = 0.44223041, grad/param norm = 7.4520e-02, time/batch = 0.2592s	
3242/5250 (epoch 30.876), train_loss = 0.43206488, grad/param norm = 7.2648e-02, time/batch = 0.2580s	
3243/5250 (epoch 30.886), train_loss = 0.45129935, grad/param norm = 7.6477e-02, time/batch = 0.2581s	
3244/5250 (epoch 30.895), train_loss = 0.44980818, grad/param norm = 7.7856e-02, time/batch = 0.2582s	
3245/5250 (epoch 30.905), train_loss = 0.46254228, grad/param norm = 7.6333e-02, time/batch = 0.2583s	
3246/5250 (epoch 30.914), train_loss = 0.45136502, grad/param norm = 8.1008e-02, time/batch = 0.2581s	
3247/5250 (epoch 30.924), train_loss = 0.45435489, grad/param norm = 7.8802e-02, time/batch = 0.2583s	
3248/5250 (epoch 30.933), train_loss = 0.45466957, grad/param norm = 7.7556e-02, time/batch = 0.2583s	
3249/5250 (epoch 30.943), train_loss = 0.45451727, grad/param norm = 7.3752e-02, time/batch = 0.2583s	
3250/5250 (epoch 30.952), train_loss = 0.46735092, grad/param norm = 7.8446e-02, time/batch = 0.2583s	
3251/5250 (epoch 30.962), train_loss = 0.45131211, grad/param norm = 7.6289e-02, time/batch = 0.2591s	
3252/5250 (epoch 30.971), train_loss = 0.45725404, grad/param norm = 7.3072e-02, time/batch = 0.2583s	
3253/5250 (epoch 30.981), train_loss = 0.44657374, grad/param norm = 7.6096e-02, time/batch = 0.2583s	
3254/5250 (epoch 30.990), train_loss = 0.45460943, grad/param norm = 7.6391e-02, time/batch = 0.2582s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
3255/5250 (epoch 31.000), train_loss = 0.43244732, grad/param norm = 7.6173e-02, time/batch = 0.2583s	
3256/5250 (epoch 31.010), train_loss = 0.63374595, grad/param norm = 7.9683e-02, time/batch = 0.2582s	
3257/5250 (epoch 31.019), train_loss = 0.46223305, grad/param norm = 8.2820e-02, time/batch = 0.2582s	
3258/5250 (epoch 31.029), train_loss = 0.46651401, grad/param norm = 8.2106e-02, time/batch = 0.2582s	
3259/5250 (epoch 31.038), train_loss = 0.46619199, grad/param norm = 7.9037e-02, time/batch = 0.2579s	
3260/5250 (epoch 31.048), train_loss = 0.44376653, grad/param norm = 7.7975e-02, time/batch = 0.2585s	
3261/5250 (epoch 31.057), train_loss = 0.46047142, grad/param norm = 7.6575e-02, time/batch = 0.2593s	
3262/5250 (epoch 31.067), train_loss = 0.45337466, grad/param norm = 7.6501e-02, time/batch = 0.2582s	
3263/5250 (epoch 31.076), train_loss = 0.44568544, grad/param norm = 7.5468e-02, time/batch = 0.2583s	
3264/5250 (epoch 31.086), train_loss = 0.44774847, grad/param norm = 7.7659e-02, time/batch = 0.2586s	
3265/5250 (epoch 31.095), train_loss = 0.45367394, grad/param norm = 7.7250e-02, time/batch = 0.2583s	
3266/5250 (epoch 31.105), train_loss = 0.45038476, grad/param norm = 7.6198e-02, time/batch = 0.2582s	
3267/5250 (epoch 31.114), train_loss = 0.45661639, grad/param norm = 7.6818e-02, time/batch = 0.2582s	
3268/5250 (epoch 31.124), train_loss = 0.46306434, grad/param norm = 7.3133e-02, time/batch = 0.2583s	
3269/5250 (epoch 31.133), train_loss = 0.45662201, grad/param norm = 7.7250e-02, time/batch = 0.2578s	
3270/5250 (epoch 31.143), train_loss = 0.45227304, grad/param norm = 7.7394e-02, time/batch = 0.2583s	
3271/5250 (epoch 31.152), train_loss = 0.43920293, grad/param norm = 7.1102e-02, time/batch = 0.2594s	
3272/5250 (epoch 31.162), train_loss = 0.44579326, grad/param norm = 7.3853e-02, time/batch = 0.2582s	
3273/5250 (epoch 31.171), train_loss = 0.44098750, grad/param norm = 7.5507e-02, time/batch = 0.2585s	
3274/5250 (epoch 31.181), train_loss = 0.43675648, grad/param norm = 7.4733e-02, time/batch = 0.2582s	
3275/5250 (epoch 31.190), train_loss = 0.43016742, grad/param norm = 7.2974e-02, time/batch = 0.2582s	
3276/5250 (epoch 31.200), train_loss = 0.44117259, grad/param norm = 7.2936e-02, time/batch = 0.2580s	
3277/5250 (epoch 31.210), train_loss = 0.44521398, grad/param norm = 7.4690e-02, time/batch = 0.2581s	
3278/5250 (epoch 31.219), train_loss = 0.45530591, grad/param norm = 7.7989e-02, time/batch = 0.2580s	
3279/5250 (epoch 31.229), train_loss = 0.45635270, grad/param norm = 7.6776e-02, time/batch = 0.2581s	
3280/5250 (epoch 31.238), train_loss = 0.44779392, grad/param norm = 7.6988e-02, time/batch = 0.2581s	
3281/5250 (epoch 31.248), train_loss = 0.44013150, grad/param norm = 7.5860e-02, time/batch = 0.2589s	
3282/5250 (epoch 31.257), train_loss = 0.44487991, grad/param norm = 7.6124e-02, time/batch = 0.2584s	
3283/5250 (epoch 31.267), train_loss = 0.44955087, grad/param norm = 7.6047e-02, time/batch = 0.2582s	
3284/5250 (epoch 31.276), train_loss = 0.44397913, grad/param norm = 7.7810e-02, time/batch = 0.2580s	
3285/5250 (epoch 31.286), train_loss = 0.45156944, grad/param norm = 7.6681e-02, time/batch = 0.2579s	
3286/5250 (epoch 31.295), train_loss = 0.45722620, grad/param norm = 8.1499e-02, time/batch = 0.2580s	
3287/5250 (epoch 31.305), train_loss = 0.42876697, grad/param norm = 7.4160e-02, time/batch = 0.2582s	
3288/5250 (epoch 31.314), train_loss = 0.42362218, grad/param norm = 7.3249e-02, time/batch = 0.2583s	
3289/5250 (epoch 31.324), train_loss = 0.43693446, grad/param norm = 8.0749e-02, time/batch = 0.2580s	
3290/5250 (epoch 31.333), train_loss = 0.44880317, grad/param norm = 7.7340e-02, time/batch = 0.2581s	
3291/5250 (epoch 31.343), train_loss = 0.43987207, grad/param norm = 7.6275e-02, time/batch = 0.2591s	
3292/5250 (epoch 31.352), train_loss = 0.43354294, grad/param norm = 7.5924e-02, time/batch = 0.2583s	
3293/5250 (epoch 31.362), train_loss = 0.44579935, grad/param norm = 7.6958e-02, time/batch = 0.2584s	
3294/5250 (epoch 31.371), train_loss = 0.44065377, grad/param norm = 8.0191e-02, time/batch = 0.2583s	
3295/5250 (epoch 31.381), train_loss = 0.45761867, grad/param norm = 8.6246e-02, time/batch = 0.2583s	
3296/5250 (epoch 31.390), train_loss = 0.45241050, grad/param norm = 8.2037e-02, time/batch = 0.2579s	
3297/5250 (epoch 31.400), train_loss = 0.46214742, grad/param norm = 8.5768e-02, time/batch = 0.2584s	
3298/5250 (epoch 31.410), train_loss = 0.44244056, grad/param norm = 8.1735e-02, time/batch = 0.2576s	
3299/5250 (epoch 31.419), train_loss = 0.44504482, grad/param norm = 7.7742e-02, time/batch = 0.2582s	
3300/5250 (epoch 31.429), train_loss = 0.44697472, grad/param norm = 8.1599e-02, time/batch = 0.2582s	
3301/5250 (epoch 31.438), train_loss = 0.45618751, grad/param norm = 8.4404e-02, time/batch = 0.2589s	
3302/5250 (epoch 31.448), train_loss = 0.45193799, grad/param norm = 7.7824e-02, time/batch = 0.2579s	
3303/5250 (epoch 31.457), train_loss = 0.44186542, grad/param norm = 7.4850e-02, time/batch = 0.2583s	
3304/5250 (epoch 31.467), train_loss = 0.44252787, grad/param norm = 7.4278e-02, time/batch = 0.2586s	
3305/5250 (epoch 31.476), train_loss = 0.42787398, grad/param norm = 7.3402e-02, time/batch = 0.2584s	
3306/5250 (epoch 31.486), train_loss = 0.44356418, grad/param norm = 7.6601e-02, time/batch = 0.2578s	
3307/5250 (epoch 31.495), train_loss = 0.44370270, grad/param norm = 7.5291e-02, time/batch = 0.2581s	
3308/5250 (epoch 31.505), train_loss = 0.44837908, grad/param norm = 7.9401e-02, time/batch = 0.2580s	
3309/5250 (epoch 31.514), train_loss = 0.45486966, grad/param norm = 8.5662e-02, time/batch = 0.2582s	
3310/5250 (epoch 31.524), train_loss = 0.43927260, grad/param norm = 7.5569e-02, time/batch = 0.2582s	
3311/5250 (epoch 31.533), train_loss = 0.43907175, grad/param norm = 7.4123e-02, time/batch = 0.2590s	
3312/5250 (epoch 31.543), train_loss = 0.42997728, grad/param norm = 7.6733e-02, time/batch = 0.2583s	
3313/5250 (epoch 31.552), train_loss = 0.43103725, grad/param norm = 7.6677e-02, time/batch = 0.2582s	
3314/5250 (epoch 31.562), train_loss = 0.44053770, grad/param norm = 7.5298e-02, time/batch = 0.2582s	
3315/5250 (epoch 31.571), train_loss = 0.43024474, grad/param norm = 7.4664e-02, time/batch = 0.2587s	
3316/5250 (epoch 31.581), train_loss = 0.45879060, grad/param norm = 7.6725e-02, time/batch = 0.2584s	
3317/5250 (epoch 31.590), train_loss = 0.43796595, grad/param norm = 7.3256e-02, time/batch = 0.2583s	
3318/5250 (epoch 31.600), train_loss = 0.44000036, grad/param norm = 7.2309e-02, time/batch = 0.2581s	
3319/5250 (epoch 31.610), train_loss = 0.43315461, grad/param norm = 7.3929e-02, time/batch = 0.2583s	
3320/5250 (epoch 31.619), train_loss = 0.43644973, grad/param norm = 7.4680e-02, time/batch = 0.2582s	
3321/5250 (epoch 31.629), train_loss = 0.42182809, grad/param norm = 7.7577e-02, time/batch = 0.2593s	
3322/5250 (epoch 31.638), train_loss = 0.42872225, grad/param norm = 7.2080e-02, time/batch = 0.2584s	
3323/5250 (epoch 31.648), train_loss = 0.43888103, grad/param norm = 7.3929e-02, time/batch = 0.2583s	
3324/5250 (epoch 31.657), train_loss = 0.43805559, grad/param norm = 7.5230e-02, time/batch = 0.2582s	
3325/5250 (epoch 31.667), train_loss = 0.43256672, grad/param norm = 7.3844e-02, time/batch = 0.2583s	
3326/5250 (epoch 31.676), train_loss = 0.42884684, grad/param norm = 7.2575e-02, time/batch = 0.2581s	
3327/5250 (epoch 31.686), train_loss = 0.42978551, grad/param norm = 7.4939e-02, time/batch = 0.2579s	
3328/5250 (epoch 31.695), train_loss = 0.42490569, grad/param norm = 7.5708e-02, time/batch = 0.2580s	
3329/5250 (epoch 31.705), train_loss = 0.43419245, grad/param norm = 7.6819e-02, time/batch = 0.2586s	
3330/5250 (epoch 31.714), train_loss = 0.43190352, grad/param norm = 7.9313e-02, time/batch = 0.2583s	
3331/5250 (epoch 31.724), train_loss = 0.43682835, grad/param norm = 7.9611e-02, time/batch = 0.2591s	
3332/5250 (epoch 31.733), train_loss = 0.42676765, grad/param norm = 7.4414e-02, time/batch = 0.2583s	
3333/5250 (epoch 31.743), train_loss = 0.43795291, grad/param norm = 7.7130e-02, time/batch = 0.2584s	
3334/5250 (epoch 31.752), train_loss = 0.44133436, grad/param norm = 7.9632e-02, time/batch = 0.2583s	
3335/5250 (epoch 31.762), train_loss = 0.43483603, grad/param norm = 7.4452e-02, time/batch = 0.2585s	
3336/5250 (epoch 31.771), train_loss = 0.42730414, grad/param norm = 7.9435e-02, time/batch = 0.2582s	
3337/5250 (epoch 31.781), train_loss = 0.43753255, grad/param norm = 8.1572e-02, time/batch = 0.2580s	
3338/5250 (epoch 31.790), train_loss = 0.44463452, grad/param norm = 7.5743e-02, time/batch = 0.2579s	
3339/5250 (epoch 31.800), train_loss = 0.42938262, grad/param norm = 7.5626e-02, time/batch = 0.2585s	
3340/5250 (epoch 31.810), train_loss = 0.42704770, grad/param norm = 7.3400e-02, time/batch = 0.2582s	
3341/5250 (epoch 31.819), train_loss = 0.43638249, grad/param norm = 7.4771e-02, time/batch = 0.2588s	
3342/5250 (epoch 31.829), train_loss = 0.42685461, grad/param norm = 7.6017e-02, time/batch = 0.2582s	
3343/5250 (epoch 31.838), train_loss = 0.42268672, grad/param norm = 7.6191e-02, time/batch = 0.2585s	
3344/5250 (epoch 31.848), train_loss = 0.42791023, grad/param norm = 7.7258e-02, time/batch = 0.2581s	
3345/5250 (epoch 31.857), train_loss = 0.42462419, grad/param norm = 7.7174e-02, time/batch = 0.2587s	
3346/5250 (epoch 31.867), train_loss = 0.41987530, grad/param norm = 7.3535e-02, time/batch = 0.2580s	
3347/5250 (epoch 31.876), train_loss = 0.41444022, grad/param norm = 7.4666e-02, time/batch = 0.2580s	
3348/5250 (epoch 31.886), train_loss = 0.43248623, grad/param norm = 7.4928e-02, time/batch = 0.2584s	
3349/5250 (epoch 31.895), train_loss = 0.43097651, grad/param norm = 7.7208e-02, time/batch = 0.2579s	
3350/5250 (epoch 31.905), train_loss = 0.44396791, grad/param norm = 8.1491e-02, time/batch = 0.2580s	
3351/5250 (epoch 31.914), train_loss = 0.43018547, grad/param norm = 7.6809e-02, time/batch = 0.2591s	
3352/5250 (epoch 31.924), train_loss = 0.43783409, grad/param norm = 8.2319e-02, time/batch = 0.2583s	
3353/5250 (epoch 31.933), train_loss = 0.43723527, grad/param norm = 7.8415e-02, time/batch = 0.2584s	
3354/5250 (epoch 31.943), train_loss = 0.43600375, grad/param norm = 7.6772e-02, time/batch = 0.2579s	
3355/5250 (epoch 31.952), train_loss = 0.44279807, grad/param norm = 8.2042e-02, time/batch = 0.2583s	
3356/5250 (epoch 31.962), train_loss = 0.43171352, grad/param norm = 7.7493e-02, time/batch = 0.2582s	
3357/5250 (epoch 31.971), train_loss = 0.43805885, grad/param norm = 7.4814e-02, time/batch = 0.2583s	
3358/5250 (epoch 31.981), train_loss = 0.43129841, grad/param norm = 8.0570e-02, time/batch = 0.2581s	
3359/5250 (epoch 31.990), train_loss = 0.44050349, grad/param norm = 7.9957e-02, time/batch = 0.2582s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
3360/5250 (epoch 32.000), train_loss = 0.41526756, grad/param norm = 7.6335e-02, time/batch = 0.2582s	
3361/5250 (epoch 32.010), train_loss = 0.61897878, grad/param norm = 8.5961e-02, time/batch = 0.2593s	
3362/5250 (epoch 32.019), train_loss = 0.44495703, grad/param norm = 7.9778e-02, time/batch = 0.2579s	
3363/5250 (epoch 32.029), train_loss = 0.43513241, grad/param norm = 7.7024e-02, time/batch = 0.2580s	
3364/5250 (epoch 32.038), train_loss = 0.44265401, grad/param norm = 7.7035e-02, time/batch = 0.2582s	
3365/5250 (epoch 32.048), train_loss = 0.41893232, grad/param norm = 7.0599e-02, time/batch = 0.2585s	
3366/5250 (epoch 32.057), train_loss = 0.43429819, grad/param norm = 7.5359e-02, time/batch = 0.2580s	
3367/5250 (epoch 32.067), train_loss = 0.43234925, grad/param norm = 7.5619e-02, time/batch = 0.2581s	
3368/5250 (epoch 32.076), train_loss = 0.42969852, grad/param norm = 7.8213e-02, time/batch = 0.2581s	
3369/5250 (epoch 32.086), train_loss = 0.42231527, grad/param norm = 7.5260e-02, time/batch = 0.2579s	
3370/5250 (epoch 32.095), train_loss = 0.43049534, grad/param norm = 7.6578e-02, time/batch = 0.2584s	
3371/5250 (epoch 32.105), train_loss = 0.43310068, grad/param norm = 7.9722e-02, time/batch = 0.2591s	
3372/5250 (epoch 32.114), train_loss = 0.44056742, grad/param norm = 7.8897e-02, time/batch = 0.2581s	
3373/5250 (epoch 32.124), train_loss = 0.45598540, grad/param norm = 8.2522e-02, time/batch = 0.2581s	
3374/5250 (epoch 32.133), train_loss = 0.43655280, grad/param norm = 7.4839e-02, time/batch = 0.2586s	
3375/5250 (epoch 32.143), train_loss = 0.42360469, grad/param norm = 7.3111e-02, time/batch = 0.2581s	
3376/5250 (epoch 32.152), train_loss = 0.42083527, grad/param norm = 7.2422e-02, time/batch = 0.2582s	
3377/5250 (epoch 32.162), train_loss = 0.42601977, grad/param norm = 7.2628e-02, time/batch = 0.2583s	
3378/5250 (epoch 32.171), train_loss = 0.41498778, grad/param norm = 7.2661e-02, time/batch = 0.2583s	
3379/5250 (epoch 32.181), train_loss = 0.41839760, grad/param norm = 7.3204e-02, time/batch = 0.2581s	
3380/5250 (epoch 32.190), train_loss = 0.41747216, grad/param norm = 7.2376e-02, time/batch = 0.2580s	
3381/5250 (epoch 32.200), train_loss = 0.42940205, grad/param norm = 8.0618e-02, time/batch = 0.2589s	
3382/5250 (epoch 32.210), train_loss = 0.43389979, grad/param norm = 7.8113e-02, time/batch = 0.2580s	
3383/5250 (epoch 32.219), train_loss = 0.43140024, grad/param norm = 7.8133e-02, time/batch = 0.2586s	
3384/5250 (epoch 32.229), train_loss = 0.43202318, grad/param norm = 7.8619e-02, time/batch = 0.2582s	
3385/5250 (epoch 32.238), train_loss = 0.42996489, grad/param norm = 7.4920e-02, time/batch = 0.2581s	
3386/5250 (epoch 32.248), train_loss = 0.43032207, grad/param norm = 8.0319e-02, time/batch = 0.2581s	
3387/5250 (epoch 32.257), train_loss = 0.43273906, grad/param norm = 7.7762e-02, time/batch = 0.2580s	
3388/5250 (epoch 32.267), train_loss = 0.43296866, grad/param norm = 7.7240e-02, time/batch = 0.2579s	
3389/5250 (epoch 32.276), train_loss = 0.42711704, grad/param norm = 7.6793e-02, time/batch = 0.2582s	
3390/5250 (epoch 32.286), train_loss = 0.43149679, grad/param norm = 7.7758e-02, time/batch = 0.2583s	
3391/5250 (epoch 32.295), train_loss = 0.43744989, grad/param norm = 7.5227e-02, time/batch = 0.2590s	
3392/5250 (epoch 32.305), train_loss = 0.40906681, grad/param norm = 7.9756e-02, time/batch = 0.2581s	
3393/5250 (epoch 32.314), train_loss = 0.41270673, grad/param norm = 7.9294e-02, time/batch = 0.2587s	
3394/5250 (epoch 32.324), train_loss = 0.41487288, grad/param norm = 7.5280e-02, time/batch = 0.2583s	
3395/5250 (epoch 32.333), train_loss = 0.42275836, grad/param norm = 7.8895e-02, time/batch = 0.2585s	
3396/5250 (epoch 32.343), train_loss = 0.42969454, grad/param norm = 7.6391e-02, time/batch = 0.2582s	
3397/5250 (epoch 32.352), train_loss = 0.40797697, grad/param norm = 7.5088e-02, time/batch = 0.2582s	
3398/5250 (epoch 32.362), train_loss = 0.42554077, grad/param norm = 7.7123e-02, time/batch = 0.2579s	
3399/5250 (epoch 32.371), train_loss = 0.41928882, grad/param norm = 7.8316e-02, time/batch = 0.2583s	
3400/5250 (epoch 32.381), train_loss = 0.42358070, grad/param norm = 7.7177e-02, time/batch = 0.2581s	
3401/5250 (epoch 32.390), train_loss = 0.42080377, grad/param norm = 7.9569e-02, time/batch = 0.2591s	
3402/5250 (epoch 32.400), train_loss = 0.43190787, grad/param norm = 7.7452e-02, time/batch = 0.2579s	
3403/5250 (epoch 32.410), train_loss = 0.42178791, grad/param norm = 7.9749e-02, time/batch = 0.2583s	
3404/5250 (epoch 32.419), train_loss = 0.43381471, grad/param norm = 8.3689e-02, time/batch = 0.2582s	
3405/5250 (epoch 32.429), train_loss = 0.42140772, grad/param norm = 7.7077e-02, time/batch = 0.2586s	
3406/5250 (epoch 32.438), train_loss = 0.42900788, grad/param norm = 8.2408e-02, time/batch = 0.2583s	
3407/5250 (epoch 32.448), train_loss = 0.43059703, grad/param norm = 8.2098e-02, time/batch = 0.2580s	
3408/5250 (epoch 32.457), train_loss = 0.42699825, grad/param norm = 7.5329e-02, time/batch = 0.2583s	
3409/5250 (epoch 32.467), train_loss = 0.41973884, grad/param norm = 7.6392e-02, time/batch = 0.2579s	
3410/5250 (epoch 32.476), train_loss = 0.40810397, grad/param norm = 7.5197e-02, time/batch = 0.2585s	
3411/5250 (epoch 32.486), train_loss = 0.42406753, grad/param norm = 7.5310e-02, time/batch = 0.2589s	
3412/5250 (epoch 32.495), train_loss = 0.42297226, grad/param norm = 7.3849e-02, time/batch = 0.2580s	
3413/5250 (epoch 32.505), train_loss = 0.42433402, grad/param norm = 7.8862e-02, time/batch = 0.2584s	
3414/5250 (epoch 32.514), train_loss = 0.42684594, grad/param norm = 7.8782e-02, time/batch = 0.2583s	
3415/5250 (epoch 32.524), train_loss = 0.42440359, grad/param norm = 8.2254e-02, time/batch = 0.2579s	
3416/5250 (epoch 32.533), train_loss = 0.42272488, grad/param norm = 7.5859e-02, time/batch = 0.2580s	
3417/5250 (epoch 32.543), train_loss = 0.41179142, grad/param norm = 7.6697e-02, time/batch = 0.2581s	
3418/5250 (epoch 32.552), train_loss = 0.40702734, grad/param norm = 7.4732e-02, time/batch = 0.2581s	
3419/5250 (epoch 32.562), train_loss = 0.41322194, grad/param norm = 7.4112e-02, time/batch = 0.2582s	
3420/5250 (epoch 32.571), train_loss = 0.40753821, grad/param norm = 7.5337e-02, time/batch = 0.2578s	
3421/5250 (epoch 32.581), train_loss = 0.43352694, grad/param norm = 7.5193e-02, time/batch = 0.2587s	
3422/5250 (epoch 32.590), train_loss = 0.42009436, grad/param norm = 7.5252e-02, time/batch = 0.2582s	
3423/5250 (epoch 32.600), train_loss = 0.41348184, grad/param norm = 7.4494e-02, time/batch = 0.2582s	
3424/5250 (epoch 32.610), train_loss = 0.41754481, grad/param norm = 7.3372e-02, time/batch = 0.2580s	
3425/5250 (epoch 32.619), train_loss = 0.41393956, grad/param norm = 7.4928e-02, time/batch = 0.2582s	
3426/5250 (epoch 32.629), train_loss = 0.40366223, grad/param norm = 7.5839e-02, time/batch = 0.2582s	
3427/5250 (epoch 32.638), train_loss = 0.41803128, grad/param norm = 8.0515e-02, time/batch = 0.2582s	
3428/5250 (epoch 32.648), train_loss = 0.42629291, grad/param norm = 7.7882e-02, time/batch = 0.2582s	
3429/5250 (epoch 32.657), train_loss = 0.42047284, grad/param norm = 7.8319e-02, time/batch = 0.2581s	
3430/5250 (epoch 32.667), train_loss = 0.42791906, grad/param norm = 7.8953e-02, time/batch = 0.2584s	
3431/5250 (epoch 32.676), train_loss = 0.41343418, grad/param norm = 7.6205e-02, time/batch = 0.2592s	
3432/5250 (epoch 32.686), train_loss = 0.42003766, grad/param norm = 7.7951e-02, time/batch = 0.2584s	
3433/5250 (epoch 32.695), train_loss = 0.40497637, grad/param norm = 7.1060e-02, time/batch = 0.2581s	
3434/5250 (epoch 32.705), train_loss = 0.40900235, grad/param norm = 7.8584e-02, time/batch = 0.2582s	
3435/5250 (epoch 32.714), train_loss = 0.41160834, grad/param norm = 8.1399e-02, time/batch = 0.2581s	
3436/5250 (epoch 32.724), train_loss = 0.42071089, grad/param norm = 7.8388e-02, time/batch = 0.2581s	
3437/5250 (epoch 32.733), train_loss = 0.41601458, grad/param norm = 8.1970e-02, time/batch = 0.2583s	
3438/5250 (epoch 32.743), train_loss = 0.42327363, grad/param norm = 7.8700e-02, time/batch = 0.2583s	
3439/5250 (epoch 32.752), train_loss = 0.41464441, grad/param norm = 7.7139e-02, time/batch = 0.2582s	
3440/5250 (epoch 32.762), train_loss = 0.42170891, grad/param norm = 7.5893e-02, time/batch = 0.2586s	
3441/5250 (epoch 32.771), train_loss = 0.40384314, grad/param norm = 7.4657e-02, time/batch = 0.2592s	
3442/5250 (epoch 32.781), train_loss = 0.41383201, grad/param norm = 7.9978e-02, time/batch = 0.2581s	
3443/5250 (epoch 32.790), train_loss = 0.42885753, grad/param norm = 8.4170e-02, time/batch = 0.2584s	
3444/5250 (epoch 32.800), train_loss = 0.41379302, grad/param norm = 7.7443e-02, time/batch = 0.2583s	
3445/5250 (epoch 32.810), train_loss = 0.40997735, grad/param norm = 7.6490e-02, time/batch = 0.2582s	
3446/5250 (epoch 32.819), train_loss = 0.41508483, grad/param norm = 7.5352e-02, time/batch = 0.2584s	
3447/5250 (epoch 32.829), train_loss = 0.40282502, grad/param norm = 7.5442e-02, time/batch = 0.2579s	
3448/5250 (epoch 32.838), train_loss = 0.40373167, grad/param norm = 7.7003e-02, time/batch = 0.2581s	
3449/5250 (epoch 32.848), train_loss = 0.40387662, grad/param norm = 7.6582e-02, time/batch = 0.2581s	
3450/5250 (epoch 32.857), train_loss = 0.40289584, grad/param norm = 7.6857e-02, time/batch = 0.2582s	
3451/5250 (epoch 32.867), train_loss = 0.40353004, grad/param norm = 7.7437e-02, time/batch = 0.2594s	
3452/5250 (epoch 32.876), train_loss = 0.38984629, grad/param norm = 7.4471e-02, time/batch = 0.2577s	
3453/5250 (epoch 32.886), train_loss = 0.41401210, grad/param norm = 7.7058e-02, time/batch = 0.2583s	
3454/5250 (epoch 32.895), train_loss = 0.40944422, grad/param norm = 7.8564e-02, time/batch = 0.2583s	
3455/5250 (epoch 32.905), train_loss = 0.41064390, grad/param norm = 7.3959e-02, time/batch = 0.2586s	
3456/5250 (epoch 32.914), train_loss = 0.40238454, grad/param norm = 7.5127e-02, time/batch = 0.2583s	
3457/5250 (epoch 32.924), train_loss = 0.41591906, grad/param norm = 8.0024e-02, time/batch = 0.2585s	
3458/5250 (epoch 32.933), train_loss = 0.41541007, grad/param norm = 7.5396e-02, time/batch = 0.2579s	
3459/5250 (epoch 32.943), train_loss = 0.41004441, grad/param norm = 7.4557e-02, time/batch = 0.2583s	
3460/5250 (epoch 32.952), train_loss = 0.42495818, grad/param norm = 7.8870e-02, time/batch = 0.2577s	
3461/5250 (epoch 32.962), train_loss = 0.41466445, grad/param norm = 7.8889e-02, time/batch = 0.2589s	
3462/5250 (epoch 32.971), train_loss = 0.41920477, grad/param norm = 7.5634e-02, time/batch = 0.2581s	
3463/5250 (epoch 32.981), train_loss = 0.40691811, grad/param norm = 7.7033e-02, time/batch = 0.2585s	
3464/5250 (epoch 32.990), train_loss = 0.41897254, grad/param norm = 7.5472e-02, time/batch = 0.2583s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
3465/5250 (epoch 33.000), train_loss = 0.39714033, grad/param norm = 7.6688e-02, time/batch = 0.2577s	
3466/5250 (epoch 33.010), train_loss = 0.58715523, grad/param norm = 7.9910e-02, time/batch = 0.2577s	
3467/5250 (epoch 33.019), train_loss = 0.42275562, grad/param norm = 7.9786e-02, time/batch = 0.2579s	
3468/5250 (epoch 33.029), train_loss = 0.42461902, grad/param norm = 8.0659e-02, time/batch = 0.2582s	
3469/5250 (epoch 33.038), train_loss = 0.42307289, grad/param norm = 7.7260e-02, time/batch = 0.2584s	
3470/5250 (epoch 33.048), train_loss = 0.40849982, grad/param norm = 7.7903e-02, time/batch = 0.2583s	
3471/5250 (epoch 33.057), train_loss = 0.42306551, grad/param norm = 7.6603e-02, time/batch = 0.2592s	
3472/5250 (epoch 33.067), train_loss = 0.41019360, grad/param norm = 7.9842e-02, time/batch = 0.2582s	
3473/5250 (epoch 33.076), train_loss = 0.41302810, grad/param norm = 7.6643e-02, time/batch = 0.2583s	
3474/5250 (epoch 33.086), train_loss = 0.40819120, grad/param norm = 7.7145e-02, time/batch = 0.2583s	
3475/5250 (epoch 33.095), train_loss = 0.40741664, grad/param norm = 7.6623e-02, time/batch = 0.2581s	
3476/5250 (epoch 33.105), train_loss = 0.41869408, grad/param norm = 8.0256e-02, time/batch = 0.2582s	
3477/5250 (epoch 33.114), train_loss = 0.42041133, grad/param norm = 7.6914e-02, time/batch = 0.2581s	
3478/5250 (epoch 33.124), train_loss = 0.43096184, grad/param norm = 7.4863e-02, time/batch = 0.2581s	
3479/5250 (epoch 33.133), train_loss = 0.42213579, grad/param norm = 7.8056e-02, time/batch = 0.2580s	
3480/5250 (epoch 33.143), train_loss = 0.41291873, grad/param norm = 7.6385e-02, time/batch = 0.2582s	
3481/5250 (epoch 33.152), train_loss = 0.41268513, grad/param norm = 7.6032e-02, time/batch = 0.2590s	
3482/5250 (epoch 33.162), train_loss = 0.40795869, grad/param norm = 7.5495e-02, time/batch = 0.2583s	
3483/5250 (epoch 33.171), train_loss = 0.40043412, grad/param norm = 7.2337e-02, time/batch = 0.2583s	
3484/5250 (epoch 33.181), train_loss = 0.40334428, grad/param norm = 7.5526e-02, time/batch = 0.2580s	
3485/5250 (epoch 33.190), train_loss = 0.39527767, grad/param norm = 7.2991e-02, time/batch = 0.2582s	
3486/5250 (epoch 33.200), train_loss = 0.40211061, grad/param norm = 7.4986e-02, time/batch = 0.2584s	
3487/5250 (epoch 33.210), train_loss = 0.41000690, grad/param norm = 7.6453e-02, time/batch = 0.2584s	
3488/5250 (epoch 33.219), train_loss = 0.41185513, grad/param norm = 7.6519e-02, time/batch = 0.2582s	
3489/5250 (epoch 33.229), train_loss = 0.41861784, grad/param norm = 7.6235e-02, time/batch = 0.2583s	
3490/5250 (epoch 33.238), train_loss = 0.40421159, grad/param norm = 7.5875e-02, time/batch = 0.2580s	
3491/5250 (epoch 33.248), train_loss = 0.39665026, grad/param norm = 7.1842e-02, time/batch = 0.2591s	
3492/5250 (epoch 33.257), train_loss = 0.40914303, grad/param norm = 7.6342e-02, time/batch = 0.2582s	
3493/5250 (epoch 33.267), train_loss = 0.40746506, grad/param norm = 7.5566e-02, time/batch = 0.2584s	
3494/5250 (epoch 33.276), train_loss = 0.40736427, grad/param norm = 7.6016e-02, time/batch = 0.2582s	
3495/5250 (epoch 33.286), train_loss = 0.40734739, grad/param norm = 7.5545e-02, time/batch = 0.2582s	
3496/5250 (epoch 33.295), train_loss = 0.42324906, grad/param norm = 7.8993e-02, time/batch = 0.2578s	
3497/5250 (epoch 33.305), train_loss = 0.39276477, grad/param norm = 7.4283e-02, time/batch = 0.2583s	
3498/5250 (epoch 33.314), train_loss = 0.38330594, grad/param norm = 7.1390e-02, time/batch = 0.2578s	
3499/5250 (epoch 33.324), train_loss = 0.39645202, grad/param norm = 7.4866e-02, time/batch = 0.2584s	
3500/5250 (epoch 33.333), train_loss = 0.39854612, grad/param norm = 7.4326e-02, time/batch = 0.2583s	
3501/5250 (epoch 33.343), train_loss = 0.40505318, grad/param norm = 7.7978e-02, time/batch = 0.2589s	
3502/5250 (epoch 33.352), train_loss = 0.40096614, grad/param norm = 7.7733e-02, time/batch = 0.2583s	
3503/5250 (epoch 33.362), train_loss = 0.40676582, grad/param norm = 7.7136e-02, time/batch = 0.2583s	
3504/5250 (epoch 33.371), train_loss = 0.39824738, grad/param norm = 7.6101e-02, time/batch = 0.2583s	
3505/5250 (epoch 33.381), train_loss = 0.40160099, grad/param norm = 7.7022e-02, time/batch = 0.2584s	
3506/5250 (epoch 33.390), train_loss = 0.39923626, grad/param norm = 7.7587e-02, time/batch = 0.2579s	
3507/5250 (epoch 33.400), train_loss = 0.41158647, grad/param norm = 7.8237e-02, time/batch = 0.2579s	
3508/5250 (epoch 33.410), train_loss = 0.39217707, grad/param norm = 7.4916e-02, time/batch = 0.2583s	
3509/5250 (epoch 33.419), train_loss = 0.39808977, grad/param norm = 7.3994e-02, time/batch = 0.2581s	
3510/5250 (epoch 33.429), train_loss = 0.40766365, grad/param norm = 8.2417e-02, time/batch = 0.2578s	
3511/5250 (epoch 33.438), train_loss = 0.40958316, grad/param norm = 8.0656e-02, time/batch = 0.2592s	
3512/5250 (epoch 33.448), train_loss = 0.40318104, grad/param norm = 7.2930e-02, time/batch = 0.2580s	
3513/5250 (epoch 33.457), train_loss = 0.40488302, grad/param norm = 7.7355e-02, time/batch = 0.2586s	
3514/5250 (epoch 33.467), train_loss = 0.40441332, grad/param norm = 7.7750e-02, time/batch = 0.2582s	
3515/5250 (epoch 33.476), train_loss = 0.38905373, grad/param norm = 7.3305e-02, time/batch = 0.2583s	
3516/5250 (epoch 33.486), train_loss = 0.39726608, grad/param norm = 7.3217e-02, time/batch = 0.2582s	
3517/5250 (epoch 33.495), train_loss = 0.40082303, grad/param norm = 7.2666e-02, time/batch = 0.2580s	
3518/5250 (epoch 33.505), train_loss = 0.40540845, grad/param norm = 7.8603e-02, time/batch = 0.2582s	
3519/5250 (epoch 33.514), train_loss = 0.41103693, grad/param norm = 8.3569e-02, time/batch = 0.2580s	
3520/5250 (epoch 33.524), train_loss = 0.40183172, grad/param norm = 7.6062e-02, time/batch = 0.2580s	
3521/5250 (epoch 33.533), train_loss = 0.40390568, grad/param norm = 7.7516e-02, time/batch = 0.2589s	
3522/5250 (epoch 33.543), train_loss = 0.39442565, grad/param norm = 7.7634e-02, time/batch = 0.2579s	
3523/5250 (epoch 33.552), train_loss = 0.39381010, grad/param norm = 7.6349e-02, time/batch = 0.2584s	
3524/5250 (epoch 33.562), train_loss = 0.40286270, grad/param norm = 7.5316e-02, time/batch = 0.2585s	
3525/5250 (epoch 33.571), train_loss = 0.39328830, grad/param norm = 7.4448e-02, time/batch = 0.2579s	
3526/5250 (epoch 33.581), train_loss = 0.41732812, grad/param norm = 7.7109e-02, time/batch = 0.2574s	
3527/5250 (epoch 33.590), train_loss = 0.39634897, grad/param norm = 7.4064e-02, time/batch = 0.2581s	
3528/5250 (epoch 33.600), train_loss = 0.40334269, grad/param norm = 7.6986e-02, time/batch = 0.2583s	
3529/5250 (epoch 33.610), train_loss = 0.40383972, grad/param norm = 7.6758e-02, time/batch = 0.2580s	
3530/5250 (epoch 33.619), train_loss = 0.39491063, grad/param norm = 7.5651e-02, time/batch = 0.2584s	
3531/5250 (epoch 33.629), train_loss = 0.38149422, grad/param norm = 7.5420e-02, time/batch = 0.2590s	
3532/5250 (epoch 33.638), train_loss = 0.39982996, grad/param norm = 7.6920e-02, time/batch = 0.2582s	
3533/5250 (epoch 33.648), train_loss = 0.40398652, grad/param norm = 7.6780e-02, time/batch = 0.2583s	
3534/5250 (epoch 33.657), train_loss = 0.40003418, grad/param norm = 7.8302e-02, time/batch = 0.2581s	
3535/5250 (epoch 33.667), train_loss = 0.39910165, grad/param norm = 7.5906e-02, time/batch = 0.2580s	
3536/5250 (epoch 33.676), train_loss = 0.39451331, grad/param norm = 7.7244e-02, time/batch = 0.2582s	
3537/5250 (epoch 33.686), train_loss = 0.40011002, grad/param norm = 7.9482e-02, time/batch = 0.2583s	
3538/5250 (epoch 33.695), train_loss = 0.39364945, grad/param norm = 8.0575e-02, time/batch = 0.2580s	
3539/5250 (epoch 33.705), train_loss = 0.39721132, grad/param norm = 7.8346e-02, time/batch = 0.2577s	
3540/5250 (epoch 33.714), train_loss = 0.39663843, grad/param norm = 8.0600e-02, time/batch = 0.2582s	
3541/5250 (epoch 33.724), train_loss = 0.39968615, grad/param norm = 7.5523e-02, time/batch = 0.2591s	
3542/5250 (epoch 33.733), train_loss = 0.40106443, grad/param norm = 7.9444e-02, time/batch = 0.2585s	
3543/5250 (epoch 33.743), train_loss = 0.39295162, grad/param norm = 7.6542e-02, time/batch = 0.2584s	
3544/5250 (epoch 33.752), train_loss = 0.40077118, grad/param norm = 7.8858e-02, time/batch = 0.2581s	
3545/5250 (epoch 33.762), train_loss = 0.40294696, grad/param norm = 7.5698e-02, time/batch = 0.2583s	
3546/5250 (epoch 33.771), train_loss = 0.38848558, grad/param norm = 7.7267e-02, time/batch = 0.2580s	
3547/5250 (epoch 33.781), train_loss = 0.39052260, grad/param norm = 7.8789e-02, time/batch = 0.2584s	
3548/5250 (epoch 33.790), train_loss = 0.40248156, grad/param norm = 7.9056e-02, time/batch = 0.2580s	
3549/5250 (epoch 33.800), train_loss = 0.39638943, grad/param norm = 7.6565e-02, time/batch = 0.2581s	
3550/5250 (epoch 33.810), train_loss = 0.38606767, grad/param norm = 7.2732e-02, time/batch = 0.2581s	
3551/5250 (epoch 33.819), train_loss = 0.39206039, grad/param norm = 7.5805e-02, time/batch = 0.2586s	
3552/5250 (epoch 33.829), train_loss = 0.38951898, grad/param norm = 7.7320e-02, time/batch = 0.2578s	
3553/5250 (epoch 33.838), train_loss = 0.38896398, grad/param norm = 7.4749e-02, time/batch = 0.2583s	
3554/5250 (epoch 33.848), train_loss = 0.39338006, grad/param norm = 7.4223e-02, time/batch = 0.2582s	
3555/5250 (epoch 33.857), train_loss = 0.38082614, grad/param norm = 7.4684e-02, time/batch = 0.2582s	
3556/5250 (epoch 33.867), train_loss = 0.38198176, grad/param norm = 7.5277e-02, time/batch = 0.2584s	
3557/5250 (epoch 33.876), train_loss = 0.37722674, grad/param norm = 7.4956e-02, time/batch = 0.2581s	
3558/5250 (epoch 33.886), train_loss = 0.39507775, grad/param norm = 7.6549e-02, time/batch = 0.2581s	
3559/5250 (epoch 33.895), train_loss = 0.39046842, grad/param norm = 7.7808e-02, time/batch = 0.2582s	
3560/5250 (epoch 33.905), train_loss = 0.39510138, grad/param norm = 7.8717e-02, time/batch = 0.2578s	
3561/5250 (epoch 33.914), train_loss = 0.39183407, grad/param norm = 7.7764e-02, time/batch = 0.2591s	
3562/5250 (epoch 33.924), train_loss = 0.39289747, grad/param norm = 7.5097e-02, time/batch = 0.2580s	
3563/5250 (epoch 33.933), train_loss = 0.38716399, grad/param norm = 7.5149e-02, time/batch = 0.2581s	
3564/5250 (epoch 33.943), train_loss = 0.39356707, grad/param norm = 7.6515e-02, time/batch = 0.2580s	
3565/5250 (epoch 33.952), train_loss = 0.40233060, grad/param norm = 7.8739e-02, time/batch = 0.2583s	
3566/5250 (epoch 33.962), train_loss = 0.38885166, grad/param norm = 7.4909e-02, time/batch = 0.2579s	
3567/5250 (epoch 33.971), train_loss = 0.40792799, grad/param norm = 7.7563e-02, time/batch = 0.2581s	
3568/5250 (epoch 33.981), train_loss = 0.38513285, grad/param norm = 7.4154e-02, time/batch = 0.2582s	
3569/5250 (epoch 33.990), train_loss = 0.38909031, grad/param norm = 7.5071e-02, time/batch = 0.2583s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
3570/5250 (epoch 34.000), train_loss = 0.37484674, grad/param norm = 7.1818e-02, time/batch = 0.2581s	
3571/5250 (epoch 34.010), train_loss = 0.57462439, grad/param norm = 8.4038e-02, time/batch = 0.2590s	
3572/5250 (epoch 34.019), train_loss = 0.40093038, grad/param norm = 7.9343e-02, time/batch = 0.2579s	
3573/5250 (epoch 34.029), train_loss = 0.39985464, grad/param norm = 7.6735e-02, time/batch = 0.2581s	
3574/5250 (epoch 34.038), train_loss = 0.40342672, grad/param norm = 7.7400e-02, time/batch = 0.2579s	
3575/5250 (epoch 34.048), train_loss = 0.38316174, grad/param norm = 7.3084e-02, time/batch = 0.2582s	
3576/5250 (epoch 34.057), train_loss = 0.40046365, grad/param norm = 7.4286e-02, time/batch = 0.2583s	
3577/5250 (epoch 34.067), train_loss = 0.38956347, grad/param norm = 7.5026e-02, time/batch = 0.2579s	
3578/5250 (epoch 34.076), train_loss = 0.39614584, grad/param norm = 7.8281e-02, time/batch = 0.2583s	
3579/5250 (epoch 34.086), train_loss = 0.38643097, grad/param norm = 7.7882e-02, time/batch = 0.2584s	
3580/5250 (epoch 34.095), train_loss = 0.40180056, grad/param norm = 7.9583e-02, time/batch = 0.2579s	
3581/5250 (epoch 34.105), train_loss = 0.40716435, grad/param norm = 8.2879e-02, time/batch = 0.2590s	
3582/5250 (epoch 34.114), train_loss = 0.40699878, grad/param norm = 8.1789e-02, time/batch = 0.2576s	
3583/5250 (epoch 34.124), train_loss = 0.41984378, grad/param norm = 8.5779e-02, time/batch = 0.2584s	
3584/5250 (epoch 34.133), train_loss = 0.41122991, grad/param norm = 8.0537e-02, time/batch = 0.2583s	
3585/5250 (epoch 34.143), train_loss = 0.39952384, grad/param norm = 7.4378e-02, time/batch = 0.2581s	
3586/5250 (epoch 34.152), train_loss = 0.39188509, grad/param norm = 7.5088e-02, time/batch = 0.2582s	
3587/5250 (epoch 34.162), train_loss = 0.39337514, grad/param norm = 7.5657e-02, time/batch = 0.2581s	
3588/5250 (epoch 34.171), train_loss = 0.38812726, grad/param norm = 7.3928e-02, time/batch = 0.2582s	
3589/5250 (epoch 34.181), train_loss = 0.38736256, grad/param norm = 7.7231e-02, time/batch = 0.2584s	
3590/5250 (epoch 34.190), train_loss = 0.38993573, grad/param norm = 7.8822e-02, time/batch = 0.2582s	
3591/5250 (epoch 34.200), train_loss = 0.39639540, grad/param norm = 7.7382e-02, time/batch = 0.2592s	
3592/5250 (epoch 34.210), train_loss = 0.39785777, grad/param norm = 7.8553e-02, time/batch = 0.2579s	
3593/5250 (epoch 34.219), train_loss = 0.39992120, grad/param norm = 7.8330e-02, time/batch = 0.2584s	
3594/5250 (epoch 34.229), train_loss = 0.39144445, grad/param norm = 7.5923e-02, time/batch = 0.2586s	
3595/5250 (epoch 34.238), train_loss = 0.39759151, grad/param norm = 7.9904e-02, time/batch = 0.2584s	
3596/5250 (epoch 34.248), train_loss = 0.38912814, grad/param norm = 7.5218e-02, time/batch = 0.2581s	
3597/5250 (epoch 34.257), train_loss = 0.38654660, grad/param norm = 7.3085e-02, time/batch = 0.2580s	
3598/5250 (epoch 34.267), train_loss = 0.38876070, grad/param norm = 7.5113e-02, time/batch = 0.2583s	
3599/5250 (epoch 34.276), train_loss = 0.38629258, grad/param norm = 7.3888e-02, time/batch = 0.2580s	
3600/5250 (epoch 34.286), train_loss = 0.39701701, grad/param norm = 7.8771e-02, time/batch = 0.2583s	
3601/5250 (epoch 34.295), train_loss = 0.39742619, grad/param norm = 7.4935e-02, time/batch = 0.2588s	
3602/5250 (epoch 34.305), train_loss = 0.37907423, grad/param norm = 7.7625e-02, time/batch = 0.2581s	
3603/5250 (epoch 34.314), train_loss = 0.37642127, grad/param norm = 7.7611e-02, time/batch = 0.2582s	
3604/5250 (epoch 34.324), train_loss = 0.37847714, grad/param norm = 7.3747e-02, time/batch = 0.2583s	
3605/5250 (epoch 34.333), train_loss = 0.38481813, grad/param norm = 7.2937e-02, time/batch = 0.2582s	
3606/5250 (epoch 34.343), train_loss = 0.38961201, grad/param norm = 7.9650e-02, time/batch = 0.2583s	
3607/5250 (epoch 34.352), train_loss = 0.37856159, grad/param norm = 7.5797e-02, time/batch = 0.2582s	
3608/5250 (epoch 34.362), train_loss = 0.39781368, grad/param norm = 7.9838e-02, time/batch = 0.2579s	
3609/5250 (epoch 34.371), train_loss = 0.38709888, grad/param norm = 8.2664e-02, time/batch = 0.2581s	
3610/5250 (epoch 34.381), train_loss = 0.38919314, grad/param norm = 8.0171e-02, time/batch = 0.2581s	
3611/5250 (epoch 34.390), train_loss = 0.38505617, grad/param norm = 8.1226e-02, time/batch = 0.2588s	
3612/5250 (epoch 34.400), train_loss = 0.39318782, grad/param norm = 7.7638e-02, time/batch = 0.2584s	
3613/5250 (epoch 34.410), train_loss = 0.38064561, grad/param norm = 7.6686e-02, time/batch = 0.2588s	
3614/5250 (epoch 34.419), train_loss = 0.38474283, grad/param norm = 7.9037e-02, time/batch = 0.2582s	
3615/5250 (epoch 34.429), train_loss = 0.38548947, grad/param norm = 7.7617e-02, time/batch = 0.2580s	
3616/5250 (epoch 34.438), train_loss = 0.39651670, grad/param norm = 8.7724e-02, time/batch = 0.2585s	
3617/5250 (epoch 34.448), train_loss = 0.39297087, grad/param norm = 7.6030e-02, time/batch = 0.2580s	
3618/5250 (epoch 34.457), train_loss = 0.38497105, grad/param norm = 7.4243e-02, time/batch = 0.2578s	
3619/5250 (epoch 34.467), train_loss = 0.38429786, grad/param norm = 7.3927e-02, time/batch = 0.2582s	
3620/5250 (epoch 34.476), train_loss = 0.37557817, grad/param norm = 7.5030e-02, time/batch = 0.2580s	
3621/5250 (epoch 34.486), train_loss = 0.38256483, grad/param norm = 7.5981e-02, time/batch = 0.2588s	
3622/5250 (epoch 34.495), train_loss = 0.38241770, grad/param norm = 7.4187e-02, time/batch = 0.2581s	
3623/5250 (epoch 34.505), train_loss = 0.39244013, grad/param norm = 7.7428e-02, time/batch = 0.2582s	
3624/5250 (epoch 34.514), train_loss = 0.38785984, grad/param norm = 8.1798e-02, time/batch = 0.2583s	
3625/5250 (epoch 34.524), train_loss = 0.38939145, grad/param norm = 7.8375e-02, time/batch = 0.2581s	
3626/5250 (epoch 34.533), train_loss = 0.38474488, grad/param norm = 7.2560e-02, time/batch = 0.2581s	
3627/5250 (epoch 34.543), train_loss = 0.37260989, grad/param norm = 7.4522e-02, time/batch = 0.2581s	
3628/5250 (epoch 34.552), train_loss = 0.37788848, grad/param norm = 7.6051e-02, time/batch = 0.2581s	
3629/5250 (epoch 34.562), train_loss = 0.38173149, grad/param norm = 7.6295e-02, time/batch = 0.2582s	
3630/5250 (epoch 34.571), train_loss = 0.37395356, grad/param norm = 7.2674e-02, time/batch = 0.2580s	
3631/5250 (epoch 34.581), train_loss = 0.38683989, grad/param norm = 7.3054e-02, time/batch = 0.2590s	
3632/5250 (epoch 34.590), train_loss = 0.37596935, grad/param norm = 7.0834e-02, time/batch = 0.2581s	
3633/5250 (epoch 34.600), train_loss = 0.38197801, grad/param norm = 7.5542e-02, time/batch = 0.2583s	
3634/5250 (epoch 34.610), train_loss = 0.37966271, grad/param norm = 7.3522e-02, time/batch = 0.2582s	
3635/5250 (epoch 34.619), train_loss = 0.36889142, grad/param norm = 7.1620e-02, time/batch = 0.2586s	
3636/5250 (epoch 34.629), train_loss = 0.36140597, grad/param norm = 7.6798e-02, time/batch = 0.2584s	
3637/5250 (epoch 34.638), train_loss = 0.38152642, grad/param norm = 7.8354e-02, time/batch = 0.2582s	
3638/5250 (epoch 34.648), train_loss = 0.38441148, grad/param norm = 7.3034e-02, time/batch = 0.2586s	
3639/5250 (epoch 34.657), train_loss = 0.38169247, grad/param norm = 7.6767e-02, time/batch = 0.2581s	
3640/5250 (epoch 34.667), train_loss = 0.38333559, grad/param norm = 7.5751e-02, time/batch = 0.2578s	
3641/5250 (epoch 34.676), train_loss = 0.37498392, grad/param norm = 7.4872e-02, time/batch = 0.2589s	
3642/5250 (epoch 34.686), train_loss = 0.38689332, grad/param norm = 7.9714e-02, time/batch = 0.2582s	
3643/5250 (epoch 34.695), train_loss = 0.37943846, grad/param norm = 7.4828e-02, time/batch = 0.2585s	
3644/5250 (epoch 34.705), train_loss = 0.38587413, grad/param norm = 8.0377e-02, time/batch = 0.2583s	
3645/5250 (epoch 34.714), train_loss = 0.37377889, grad/param norm = 7.6674e-02, time/batch = 0.2578s	
3646/5250 (epoch 34.724), train_loss = 0.37999092, grad/param norm = 7.2684e-02, time/batch = 0.2581s	
3647/5250 (epoch 34.733), train_loss = 0.37145552, grad/param norm = 7.6251e-02, time/batch = 0.2576s	
3648/5250 (epoch 34.743), train_loss = 0.37696168, grad/param norm = 7.6962e-02, time/batch = 0.2582s	
3649/5250 (epoch 34.752), train_loss = 0.38111913, grad/param norm = 7.7623e-02, time/batch = 0.2581s	
3650/5250 (epoch 34.762), train_loss = 0.38615891, grad/param norm = 7.7030e-02, time/batch = 0.2578s	
3651/5250 (epoch 34.771), train_loss = 0.37152935, grad/param norm = 7.6027e-02, time/batch = 0.2589s	
3652/5250 (epoch 34.781), train_loss = 0.37083605, grad/param norm = 7.5412e-02, time/batch = 0.2584s	
3653/5250 (epoch 34.790), train_loss = 0.38200311, grad/param norm = 7.8571e-02, time/batch = 0.2585s	
3654/5250 (epoch 34.800), train_loss = 0.37530441, grad/param norm = 7.5155e-02, time/batch = 0.2581s	
3655/5250 (epoch 34.810), train_loss = 0.36949561, grad/param norm = 7.1327e-02, time/batch = 0.2581s	
3656/5250 (epoch 34.819), train_loss = 0.37227472, grad/param norm = 7.5258e-02, time/batch = 0.2583s	
3657/5250 (epoch 34.829), train_loss = 0.36887236, grad/param norm = 7.4706e-02, time/batch = 0.2583s	
3658/5250 (epoch 34.838), train_loss = 0.36633397, grad/param norm = 7.2848e-02, time/batch = 0.2580s	
3659/5250 (epoch 34.848), train_loss = 0.37140243, grad/param norm = 7.3123e-02, time/batch = 0.2586s	
3660/5250 (epoch 34.857), train_loss = 0.36296479, grad/param norm = 7.3648e-02, time/batch = 0.2580s	
3661/5250 (epoch 34.867), train_loss = 0.37393095, grad/param norm = 7.8283e-02, time/batch = 0.2591s	
3662/5250 (epoch 34.876), train_loss = 0.36338165, grad/param norm = 7.6466e-02, time/batch = 0.2585s	
3663/5250 (epoch 34.886), train_loss = 0.37549805, grad/param norm = 7.5588e-02, time/batch = 0.2581s	
3664/5250 (epoch 34.895), train_loss = 0.37294660, grad/param norm = 7.7671e-02, time/batch = 0.2581s	
3665/5250 (epoch 34.905), train_loss = 0.37773064, grad/param norm = 7.5826e-02, time/batch = 0.2581s	
3666/5250 (epoch 34.914), train_loss = 0.36920660, grad/param norm = 7.4480e-02, time/batch = 0.2584s	
3667/5250 (epoch 34.924), train_loss = 0.38271070, grad/param norm = 7.8963e-02, time/batch = 0.2580s	
3668/5250 (epoch 34.933), train_loss = 0.38580999, grad/param norm = 8.0442e-02, time/batch = 0.2581s	
3669/5250 (epoch 34.943), train_loss = 0.38126826, grad/param norm = 7.6621e-02, time/batch = 0.2580s	
3670/5250 (epoch 34.952), train_loss = 0.38406672, grad/param norm = 7.5316e-02, time/batch = 0.2582s	
3671/5250 (epoch 34.962), train_loss = 0.37649060, grad/param norm = 7.8512e-02, time/batch = 0.2600s	
3672/5250 (epoch 34.971), train_loss = 0.38901048, grad/param norm = 7.6064e-02, time/batch = 0.2579s	
3673/5250 (epoch 34.981), train_loss = 0.36945079, grad/param norm = 7.5998e-02, time/batch = 0.2582s	
3674/5250 (epoch 34.990), train_loss = 0.37904902, grad/param norm = 7.5516e-02, time/batch = 0.2581s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
3675/5250 (epoch 35.000), train_loss = 0.35947071, grad/param norm = 7.4859e-02, time/batch = 0.2580s	
3676/5250 (epoch 35.010), train_loss = 0.55135833, grad/param norm = 8.2843e-02, time/batch = 0.2580s	
3677/5250 (epoch 35.019), train_loss = 0.38536388, grad/param norm = 7.7965e-02, time/batch = 0.2582s	
3678/5250 (epoch 35.029), train_loss = 0.38458070, grad/param norm = 7.8675e-02, time/batch = 0.2578s	
3679/5250 (epoch 35.038), train_loss = 0.38852344, grad/param norm = 7.7658e-02, time/batch = 0.2584s	
3680/5250 (epoch 35.048), train_loss = 0.37168073, grad/param norm = 8.0672e-02, time/batch = 0.2580s	
3681/5250 (epoch 35.057), train_loss = 0.39307865, grad/param norm = 8.1051e-02, time/batch = 0.2587s	
3682/5250 (epoch 35.067), train_loss = 0.37653724, grad/param norm = 7.4891e-02, time/batch = 0.2579s	
3683/5250 (epoch 35.076), train_loss = 0.37626243, grad/param norm = 7.3733e-02, time/batch = 0.2586s	
3684/5250 (epoch 35.086), train_loss = 0.36617622, grad/param norm = 7.7624e-02, time/batch = 0.2580s	
3685/5250 (epoch 35.095), train_loss = 0.37511711, grad/param norm = 7.7229e-02, time/batch = 0.2582s	
3686/5250 (epoch 35.105), train_loss = 0.38572573, grad/param norm = 7.9153e-02, time/batch = 0.2584s	
3687/5250 (epoch 35.114), train_loss = 0.38888977, grad/param norm = 7.7452e-02, time/batch = 0.2582s	
3688/5250 (epoch 35.124), train_loss = 0.39828766, grad/param norm = 7.6689e-02, time/batch = 0.2584s	
3689/5250 (epoch 35.133), train_loss = 0.39293075, grad/param norm = 7.9116e-02, time/batch = 0.2579s	
3690/5250 (epoch 35.143), train_loss = 0.38517570, grad/param norm = 7.8243e-02, time/batch = 0.2582s	
3691/5250 (epoch 35.152), train_loss = 0.37728418, grad/param norm = 7.4861e-02, time/batch = 0.2586s	
3692/5250 (epoch 35.162), train_loss = 0.37557902, grad/param norm = 7.6717e-02, time/batch = 0.2579s	
3693/5250 (epoch 35.171), train_loss = 0.36255872, grad/param norm = 7.3849e-02, time/batch = 0.2586s	
3694/5250 (epoch 35.181), train_loss = 0.36411745, grad/param norm = 7.2494e-02, time/batch = 0.2585s	
3695/5250 (epoch 35.190), train_loss = 0.36730159, grad/param norm = 7.3229e-02, time/batch = 0.2583s	
3696/5250 (epoch 35.200), train_loss = 0.37632159, grad/param norm = 7.6677e-02, time/batch = 0.2582s	
3697/5250 (epoch 35.210), train_loss = 0.37713495, grad/param norm = 7.8498e-02, time/batch = 0.2583s	
3698/5250 (epoch 35.219), train_loss = 0.37047506, grad/param norm = 7.6206e-02, time/batch = 0.2583s	
3699/5250 (epoch 35.229), train_loss = 0.38191479, grad/param norm = 7.8035e-02, time/batch = 0.2582s	
3700/5250 (epoch 35.238), train_loss = 0.38641799, grad/param norm = 8.2462e-02, time/batch = 0.2581s	
3701/5250 (epoch 35.248), train_loss = 0.36984750, grad/param norm = 7.3769e-02, time/batch = 0.2591s	
3702/5250 (epoch 35.257), train_loss = 0.37214538, grad/param norm = 7.3793e-02, time/batch = 0.2582s	
3703/5250 (epoch 35.267), train_loss = 0.37143758, grad/param norm = 7.3770e-02, time/batch = 0.2581s	
3704/5250 (epoch 35.276), train_loss = 0.36892171, grad/param norm = 7.3144e-02, time/batch = 0.2585s	
3705/5250 (epoch 35.286), train_loss = 0.37282219, grad/param norm = 7.4458e-02, time/batch = 0.2583s	
3706/5250 (epoch 35.295), train_loss = 0.37980828, grad/param norm = 7.4756e-02, time/batch = 0.2583s	
3707/5250 (epoch 35.305), train_loss = 0.35733608, grad/param norm = 7.5271e-02, time/batch = 0.2580s	
3708/5250 (epoch 35.314), train_loss = 0.35993892, grad/param norm = 7.5685e-02, time/batch = 0.2581s	
3709/5250 (epoch 35.324), train_loss = 0.36831872, grad/param norm = 7.5909e-02, time/batch = 0.2581s	
3710/5250 (epoch 35.333), train_loss = 0.36617725, grad/param norm = 7.6490e-02, time/batch = 0.2576s	
3711/5250 (epoch 35.343), train_loss = 0.37077352, grad/param norm = 7.7028e-02, time/batch = 0.2592s	
3712/5250 (epoch 35.352), train_loss = 0.36109543, grad/param norm = 7.3410e-02, time/batch = 0.2582s	
3713/5250 (epoch 35.362), train_loss = 0.36736463, grad/param norm = 7.3089e-02, time/batch = 0.2583s	
3714/5250 (epoch 35.371), train_loss = 0.35791063, grad/param norm = 7.6031e-02, time/batch = 0.2582s	
3715/5250 (epoch 35.381), train_loss = 0.37156055, grad/param norm = 7.8474e-02, time/batch = 0.2581s	
3716/5250 (epoch 35.390), train_loss = 0.36906530, grad/param norm = 7.7472e-02, time/batch = 0.2579s	
3717/5250 (epoch 35.400), train_loss = 0.37101185, grad/param norm = 8.1542e-02, time/batch = 0.2580s	
3718/5250 (epoch 35.410), train_loss = 0.35910023, grad/param norm = 7.7050e-02, time/batch = 0.2583s	
3719/5250 (epoch 35.419), train_loss = 0.37340638, grad/param norm = 7.7762e-02, time/batch = 0.2584s	
3720/5250 (epoch 35.429), train_loss = 0.36689016, grad/param norm = 7.7552e-02, time/batch = 0.2581s	
3721/5250 (epoch 35.438), train_loss = 0.36998008, grad/param norm = 7.8521e-02, time/batch = 0.2595s	
3722/5250 (epoch 35.448), train_loss = 0.37368666, grad/param norm = 7.7070e-02, time/batch = 0.2584s	
3723/5250 (epoch 35.457), train_loss = 0.37801267, grad/param norm = 7.6199e-02, time/batch = 0.2583s	
3724/5250 (epoch 35.467), train_loss = 0.36950815, grad/param norm = 7.8560e-02, time/batch = 0.2587s	
3725/5250 (epoch 35.476), train_loss = 0.35384151, grad/param norm = 7.2621e-02, time/batch = 0.2585s	
3726/5250 (epoch 35.486), train_loss = 0.36411113, grad/param norm = 7.4260e-02, time/batch = 0.2582s	
3727/5250 (epoch 35.495), train_loss = 0.37221930, grad/param norm = 7.3929e-02, time/batch = 0.2581s	
3728/5250 (epoch 35.505), train_loss = 0.36703574, grad/param norm = 7.3701e-02, time/batch = 0.2582s	
3729/5250 (epoch 35.514), train_loss = 0.37345806, grad/param norm = 7.9151e-02, time/batch = 0.2576s	
3730/5250 (epoch 35.524), train_loss = 0.37271016, grad/param norm = 7.5975e-02, time/batch = 0.2577s	
3731/5250 (epoch 35.533), train_loss = 0.36627687, grad/param norm = 7.2381e-02, time/batch = 0.2592s	
3732/5250 (epoch 35.543), train_loss = 0.35456695, grad/param norm = 7.5964e-02, time/batch = 0.2581s	
3733/5250 (epoch 35.552), train_loss = 0.35714352, grad/param norm = 7.5129e-02, time/batch = 0.2584s	
3734/5250 (epoch 35.562), train_loss = 0.36497407, grad/param norm = 7.6659e-02, time/batch = 0.2583s	
3735/5250 (epoch 35.571), train_loss = 0.35969133, grad/param norm = 7.3650e-02, time/batch = 0.2579s	
3736/5250 (epoch 35.581), train_loss = 0.37476420, grad/param norm = 7.2645e-02, time/batch = 0.2579s	
3737/5250 (epoch 35.590), train_loss = 0.36627236, grad/param norm = 7.3605e-02, time/batch = 0.2582s	
3738/5250 (epoch 35.600), train_loss = 0.36136471, grad/param norm = 7.2560e-02, time/batch = 0.2580s	
3739/5250 (epoch 35.610), train_loss = 0.36715042, grad/param norm = 7.4981e-02, time/batch = 0.2584s	
3740/5250 (epoch 35.619), train_loss = 0.35739022, grad/param norm = 7.3579e-02, time/batch = 0.2581s	
3741/5250 (epoch 35.629), train_loss = 0.34259276, grad/param norm = 7.5035e-02, time/batch = 0.2590s	
3742/5250 (epoch 35.638), train_loss = 0.36403928, grad/param norm = 7.5508e-02, time/batch = 0.2585s	
3743/5250 (epoch 35.648), train_loss = 0.37301077, grad/param norm = 7.9559e-02, time/batch = 0.2583s	
3744/5250 (epoch 35.657), train_loss = 0.37021940, grad/param norm = 7.7769e-02, time/batch = 0.2582s	
3745/5250 (epoch 35.667), train_loss = 0.36433782, grad/param norm = 7.4892e-02, time/batch = 0.2580s	
3746/5250 (epoch 35.676), train_loss = 0.35800476, grad/param norm = 7.5388e-02, time/batch = 0.2584s	
3747/5250 (epoch 35.686), train_loss = 0.36808626, grad/param norm = 7.9768e-02, time/batch = 0.2583s	
3748/5250 (epoch 35.695), train_loss = 0.36200011, grad/param norm = 7.6900e-02, time/batch = 0.2583s	
3749/5250 (epoch 35.705), train_loss = 0.35994971, grad/param norm = 7.6738e-02, time/batch = 0.2581s	
3750/5250 (epoch 35.714), train_loss = 0.35412566, grad/param norm = 7.5984e-02, time/batch = 0.2584s	
3751/5250 (epoch 35.724), train_loss = 0.35834922, grad/param norm = 7.4544e-02, time/batch = 0.2588s	
3752/5250 (epoch 35.733), train_loss = 0.35823016, grad/param norm = 7.7094e-02, time/batch = 0.2582s	
3753/5250 (epoch 35.743), train_loss = 0.35903517, grad/param norm = 7.8135e-02, time/batch = 0.2582s	
3754/5250 (epoch 35.752), train_loss = 0.36010071, grad/param norm = 7.5664e-02, time/batch = 0.2581s	
3755/5250 (epoch 35.762), train_loss = 0.36762217, grad/param norm = 7.6335e-02, time/batch = 0.2582s	
3756/5250 (epoch 35.771), train_loss = 0.35132483, grad/param norm = 7.5230e-02, time/batch = 0.2579s	
3757/5250 (epoch 35.781), train_loss = 0.35676835, grad/param norm = 7.7732e-02, time/batch = 0.2584s	
3758/5250 (epoch 35.790), train_loss = 0.37033483, grad/param norm = 7.6811e-02, time/batch = 0.2580s	
3759/5250 (epoch 35.800), train_loss = 0.36660852, grad/param norm = 8.0280e-02, time/batch = 0.2580s	
3760/5250 (epoch 35.810), train_loss = 0.35362517, grad/param norm = 7.2329e-02, time/batch = 0.2582s	
3761/5250 (epoch 35.819), train_loss = 0.35529252, grad/param norm = 7.6333e-02, time/batch = 0.2591s	
3762/5250 (epoch 35.829), train_loss = 0.35114628, grad/param norm = 7.4898e-02, time/batch = 0.2578s	
3763/5250 (epoch 35.838), train_loss = 0.34785330, grad/param norm = 7.3934e-02, time/batch = 0.2582s	
3764/5250 (epoch 35.848), train_loss = 0.35117393, grad/param norm = 7.3200e-02, time/batch = 0.2584s	
3765/5250 (epoch 35.857), train_loss = 0.35303256, grad/param norm = 7.6620e-02, time/batch = 0.2583s	
3766/5250 (epoch 35.867), train_loss = 0.34663344, grad/param norm = 7.4721e-02, time/batch = 0.2580s	
3767/5250 (epoch 35.876), train_loss = 0.34798690, grad/param norm = 7.8623e-02, time/batch = 0.2583s	
3768/5250 (epoch 35.886), train_loss = 0.35588886, grad/param norm = 7.4841e-02, time/batch = 0.2577s	
3769/5250 (epoch 35.895), train_loss = 0.35951294, grad/param norm = 8.0385e-02, time/batch = 0.2580s	
3770/5250 (epoch 35.905), train_loss = 0.36836664, grad/param norm = 7.9382e-02, time/batch = 0.2580s	
3771/5250 (epoch 35.914), train_loss = 0.35629532, grad/param norm = 7.6954e-02, time/batch = 0.2592s	
3772/5250 (epoch 35.924), train_loss = 0.36398194, grad/param norm = 7.7423e-02, time/batch = 0.2582s	
3773/5250 (epoch 35.933), train_loss = 0.36575059, grad/param norm = 7.8478e-02, time/batch = 0.2582s	
3774/5250 (epoch 35.943), train_loss = 0.36002237, grad/param norm = 7.5611e-02, time/batch = 0.2584s	
3775/5250 (epoch 35.952), train_loss = 0.36331838, grad/param norm = 7.6120e-02, time/batch = 0.2580s	
3776/5250 (epoch 35.962), train_loss = 0.35760425, grad/param norm = 7.6880e-02, time/batch = 0.2579s	
3777/5250 (epoch 35.971), train_loss = 0.37472841, grad/param norm = 7.5655e-02, time/batch = 0.2578s	
3778/5250 (epoch 35.981), train_loss = 0.35712405, grad/param norm = 7.5171e-02, time/batch = 0.2582s	
3779/5250 (epoch 35.990), train_loss = 0.36335474, grad/param norm = 7.8491e-02, time/batch = 0.2583s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
3780/5250 (epoch 36.000), train_loss = 0.34408173, grad/param norm = 7.4147e-02, time/batch = 0.2583s	
3781/5250 (epoch 36.010), train_loss = 0.53186080, grad/param norm = 8.2288e-02, time/batch = 0.2593s	
3782/5250 (epoch 36.019), train_loss = 0.36711283, grad/param norm = 8.0517e-02, time/batch = 0.2577s	
3783/5250 (epoch 36.029), train_loss = 0.36896256, grad/param norm = 7.7278e-02, time/batch = 0.2584s	
3784/5250 (epoch 36.038), train_loss = 0.36562343, grad/param norm = 7.7024e-02, time/batch = 0.2584s	
3785/5250 (epoch 36.048), train_loss = 0.35073172, grad/param norm = 7.2873e-02, time/batch = 0.2581s	
3786/5250 (epoch 36.057), train_loss = 0.36382900, grad/param norm = 7.4266e-02, time/batch = 0.2580s	
3787/5250 (epoch 36.067), train_loss = 0.36398374, grad/param norm = 7.5982e-02, time/batch = 0.2582s	
3788/5250 (epoch 36.076), train_loss = 0.35784098, grad/param norm = 7.7613e-02, time/batch = 0.2579s	
3789/5250 (epoch 36.086), train_loss = 0.35775150, grad/param norm = 7.8826e-02, time/batch = 0.2579s	
3790/5250 (epoch 36.095), train_loss = 0.35798323, grad/param norm = 7.6153e-02, time/batch = 0.2584s	
3791/5250 (epoch 36.105), train_loss = 0.36279636, grad/param norm = 7.7900e-02, time/batch = 0.2590s	
3792/5250 (epoch 36.114), train_loss = 0.36353580, grad/param norm = 7.3979e-02, time/batch = 0.2578s	
3793/5250 (epoch 36.124), train_loss = 0.37747806, grad/param norm = 7.7698e-02, time/batch = 0.2582s	
3794/5250 (epoch 36.133), train_loss = 0.36648485, grad/param norm = 7.6038e-02, time/batch = 0.2579s	
3795/5250 (epoch 36.143), train_loss = 0.36161938, grad/param norm = 7.3021e-02, time/batch = 0.2583s	
3796/5250 (epoch 36.152), train_loss = 0.36181839, grad/param norm = 7.5665e-02, time/batch = 0.2581s	
3797/5250 (epoch 36.162), train_loss = 0.36339075, grad/param norm = 7.6370e-02, time/batch = 0.2581s	
3798/5250 (epoch 36.171), train_loss = 0.35664714, grad/param norm = 7.8751e-02, time/batch = 0.2586s	
3799/5250 (epoch 36.181), train_loss = 0.35253481, grad/param norm = 7.6445e-02, time/batch = 0.2580s	
3800/5250 (epoch 36.190), train_loss = 0.35162771, grad/param norm = 7.3752e-02, time/batch = 0.2582s	
3801/5250 (epoch 36.200), train_loss = 0.35277687, grad/param norm = 7.4340e-02, time/batch = 0.2592s	
3802/5250 (epoch 36.210), train_loss = 0.36327408, grad/param norm = 7.7389e-02, time/batch = 0.2581s	
3803/5250 (epoch 36.219), train_loss = 0.35468605, grad/param norm = 7.4867e-02, time/batch = 0.2583s	
