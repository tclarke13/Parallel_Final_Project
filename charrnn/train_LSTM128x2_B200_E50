using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 105, val: 6, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 240321	
cloning rnn	
cloning criterion	
1/5250 (epoch 0.010), train_loss = 4.16697643, grad/param norm = 5.4516e-01, time/batch = 0.4906s	
2/5250 (epoch 0.019), train_loss = 3.85763955, grad/param norm = 1.4228e+00, time/batch = 0.2227s	
3/5250 (epoch 0.029), train_loss = 3.43325003, grad/param norm = 9.7153e-01, time/batch = 0.1839s	
4/5250 (epoch 0.038), train_loss = 3.38173005, grad/param norm = 5.3446e-01, time/batch = 0.1287s	
5/5250 (epoch 0.048), train_loss = 3.41075545, grad/param norm = 4.4750e-01, time/batch = 0.1289s	
6/5250 (epoch 0.057), train_loss = 3.37711637, grad/param norm = 5.0888e-01, time/batch = 0.1263s	
7/5250 (epoch 0.067), train_loss = 3.34780492, grad/param norm = 5.2286e-01, time/batch = 0.1165s	
8/5250 (epoch 0.076), train_loss = 3.31588873, grad/param norm = 4.4461e-01, time/batch = 0.1093s	
9/5250 (epoch 0.086), train_loss = 3.36459684, grad/param norm = 3.4735e-01, time/batch = 0.1096s	
10/5250 (epoch 0.095), train_loss = 3.32368506, grad/param norm = 3.0345e-01, time/batch = 0.1090s	
11/5250 (epoch 0.105), train_loss = 3.30840492, grad/param norm = 2.8891e-01, time/batch = 0.1120s	
12/5250 (epoch 0.114), train_loss = 3.34849497, grad/param norm = 2.7988e-01, time/batch = 0.1069s	
13/5250 (epoch 0.124), train_loss = 3.32240033, grad/param norm = 2.4217e-01, time/batch = 0.1071s	
14/5250 (epoch 0.133), train_loss = 3.34565142, grad/param norm = 2.6543e-01, time/batch = 0.1068s	
15/5250 (epoch 0.143), train_loss = 3.33633297, grad/param norm = 2.4890e-01, time/batch = 0.1074s	
16/5250 (epoch 0.152), train_loss = 3.33963524, grad/param norm = 2.5285e-01, time/batch = 0.0943s	
17/5250 (epoch 0.162), train_loss = 3.32014105, grad/param norm = 2.6853e-01, time/batch = 0.0843s	
18/5250 (epoch 0.171), train_loss = 3.31595628, grad/param norm = 2.4016e-01, time/batch = 0.0843s	
19/5250 (epoch 0.181), train_loss = 3.34865351, grad/param norm = 2.2444e-01, time/batch = 0.0850s	
20/5250 (epoch 0.190), train_loss = 3.32293092, grad/param norm = 2.3475e-01, time/batch = 0.0856s	
21/5250 (epoch 0.200), train_loss = 3.32076894, grad/param norm = 2.2956e-01, time/batch = 0.0897s	
22/5250 (epoch 0.210), train_loss = 3.30468045, grad/param norm = 2.7723e-01, time/batch = 0.0841s	
23/5250 (epoch 0.219), train_loss = 3.29279691, grad/param norm = 3.0192e-01, time/batch = 0.0840s	
24/5250 (epoch 0.229), train_loss = 3.32943855, grad/param norm = 2.4977e-01, time/batch = 0.0843s	
25/5250 (epoch 0.238), train_loss = 3.32524232, grad/param norm = 2.4123e-01, time/batch = 0.0841s	
26/5250 (epoch 0.248), train_loss = 3.29705455, grad/param norm = 2.3695e-01, time/batch = 0.0845s	
27/5250 (epoch 0.257), train_loss = 3.32747990, grad/param norm = 2.4167e-01, time/batch = 0.0843s	
28/5250 (epoch 0.267), train_loss = 3.33280315, grad/param norm = 2.1879e-01, time/batch = 0.0841s	
29/5250 (epoch 0.276), train_loss = 3.32072044, grad/param norm = 2.3111e-01, time/batch = 0.0847s	
30/5250 (epoch 0.286), train_loss = 3.32370416, grad/param norm = 2.4267e-01, time/batch = 0.0847s	
31/5250 (epoch 0.295), train_loss = 3.31692376, grad/param norm = 4.4872e-01, time/batch = 0.0896s	
32/5250 (epoch 0.305), train_loss = 3.35643744, grad/param norm = 6.4545e-01, time/batch = 0.0845s	
33/5250 (epoch 0.314), train_loss = 3.36169892, grad/param norm = 4.4109e-01, time/batch = 0.0840s	
34/5250 (epoch 0.324), train_loss = 3.31526059, grad/param norm = 2.9348e-01, time/batch = 0.0840s	
35/5250 (epoch 0.333), train_loss = 3.29954619, grad/param norm = 2.3619e-01, time/batch = 0.0846s	
36/5250 (epoch 0.343), train_loss = 3.30369310, grad/param norm = 2.0965e-01, time/batch = 0.0844s	
37/5250 (epoch 0.352), train_loss = 3.30288963, grad/param norm = 2.9084e-01, time/batch = 0.0843s	
38/5250 (epoch 0.362), train_loss = 3.32981477, grad/param norm = 3.6719e-01, time/batch = 0.0839s	
39/5250 (epoch 0.371), train_loss = 3.32906734, grad/param norm = 3.5901e-01, time/batch = 0.0847s	
40/5250 (epoch 0.381), train_loss = 3.31286439, grad/param norm = 3.0503e-01, time/batch = 0.0844s	
41/5250 (epoch 0.390), train_loss = 3.30176888, grad/param norm = 2.6300e-01, time/batch = 0.0897s	
42/5250 (epoch 0.400), train_loss = 3.29780092, grad/param norm = 3.5916e-01, time/batch = 0.0840s	
43/5250 (epoch 0.410), train_loss = 3.31651209, grad/param norm = 4.4492e-01, time/batch = 0.0846s	
44/5250 (epoch 0.419), train_loss = 3.29546599, grad/param norm = 4.6735e-01, time/batch = 0.0842s	
45/5250 (epoch 0.429), train_loss = 3.27236458, grad/param norm = 4.7317e-01, time/batch = 0.0843s	
46/5250 (epoch 0.438), train_loss = 3.33249973, grad/param norm = 1.3141e+00, time/batch = 0.0845s	
47/5250 (epoch 0.448), train_loss = 3.34595417, grad/param norm = 5.3588e-01, time/batch = 0.0837s	
48/5250 (epoch 0.457), train_loss = 3.31036534, grad/param norm = 2.7599e-01, time/batch = 0.0840s	
49/5250 (epoch 0.467), train_loss = 3.28867025, grad/param norm = 2.2080e-01, time/batch = 0.0844s	
50/5250 (epoch 0.476), train_loss = 3.28646541, grad/param norm = 2.1017e-01, time/batch = 0.0844s	
51/5250 (epoch 0.486), train_loss = 3.26151728, grad/param norm = 1.8994e-01, time/batch = 0.0896s	
52/5250 (epoch 0.495), train_loss = 3.22630447, grad/param norm = 2.0245e-01, time/batch = 0.0841s	
53/5250 (epoch 0.505), train_loss = 3.22240833, grad/param norm = 2.5481e-01, time/batch = 0.0845s	
54/5250 (epoch 0.514), train_loss = 3.22667289, grad/param norm = 4.9691e-01, time/batch = 0.0844s	
55/5250 (epoch 0.524), train_loss = 3.28545684, grad/param norm = 1.3015e+00, time/batch = 0.0843s	
56/5250 (epoch 0.533), train_loss = 3.31541521, grad/param norm = 5.7571e-01, time/batch = 0.0845s	
57/5250 (epoch 0.543), train_loss = 3.24927508, grad/param norm = 2.9481e-01, time/batch = 0.0839s	
58/5250 (epoch 0.552), train_loss = 3.23966848, grad/param norm = 1.7659e-01, time/batch = 0.0836s	
59/5250 (epoch 0.562), train_loss = 3.21988935, grad/param norm = 1.7496e-01, time/batch = 0.0850s	
60/5250 (epoch 0.571), train_loss = 3.20908114, grad/param norm = 1.9215e-01, time/batch = 0.0845s	
61/5250 (epoch 0.581), train_loss = 3.20248835, grad/param norm = 2.1839e-01, time/batch = 0.0894s	
62/5250 (epoch 0.590), train_loss = 3.20182936, grad/param norm = 2.9013e-01, time/batch = 0.0840s	
63/5250 (epoch 0.600), train_loss = 3.19883908, grad/param norm = 6.3313e-01, time/batch = 0.0839s	
64/5250 (epoch 0.610), train_loss = 3.22484306, grad/param norm = 9.8837e-01, time/batch = 0.0845s	
65/5250 (epoch 0.619), train_loss = 3.22264789, grad/param norm = 1.1253e+00, time/batch = 0.0844s	
66/5250 (epoch 0.629), train_loss = 3.24258830, grad/param norm = 7.0663e-01, time/batch = 0.0843s	
67/5250 (epoch 0.638), train_loss = 3.19015800, grad/param norm = 1.7317e-01, time/batch = 0.0840s	
68/5250 (epoch 0.648), train_loss = 3.15799237, grad/param norm = 1.4664e-01, time/batch = 0.0836s	
69/5250 (epoch 0.657), train_loss = 3.15853512, grad/param norm = 1.3346e-01, time/batch = 0.0843s	
70/5250 (epoch 0.667), train_loss = 3.16378153, grad/param norm = 1.6109e-01, time/batch = 0.0849s	
71/5250 (epoch 0.676), train_loss = 3.14794294, grad/param norm = 1.3106e-01, time/batch = 0.0897s	
72/5250 (epoch 0.686), train_loss = 3.14865024, grad/param norm = 2.0327e-01, time/batch = 0.0840s	
73/5250 (epoch 0.695), train_loss = 3.13412558, grad/param norm = 4.4633e-01, time/batch = 0.0841s	
74/5250 (epoch 0.705), train_loss = 3.15951148, grad/param norm = 9.7554e-01, time/batch = 0.0842s	
75/5250 (epoch 0.714), train_loss = 3.16849339, grad/param norm = 7.8235e-01, time/batch = 0.0843s	
76/5250 (epoch 0.724), train_loss = 3.13872760, grad/param norm = 2.5166e-01, time/batch = 0.0845s	
77/5250 (epoch 0.733), train_loss = 3.11772263, grad/param norm = 1.8276e-01, time/batch = 0.0837s	
78/5250 (epoch 0.743), train_loss = 3.11742516, grad/param norm = 2.1623e-01, time/batch = 0.0839s	
79/5250 (epoch 0.752), train_loss = 3.11864759, grad/param norm = 5.4186e-01, time/batch = 0.0844s	
80/5250 (epoch 0.762), train_loss = 3.23381263, grad/param norm = 1.6646e+00, time/batch = 0.0844s	
81/5250 (epoch 0.771), train_loss = 3.40333605, grad/param norm = 3.1045e+00, time/batch = 0.0899s	
82/5250 (epoch 0.781), train_loss = 3.25228424, grad/param norm = 1.0484e+00, time/batch = 0.0841s	
83/5250 (epoch 0.790), train_loss = 3.14230104, grad/param norm = 2.9227e-01, time/batch = 0.0839s	
84/5250 (epoch 0.800), train_loss = 3.12096419, grad/param norm = 1.7477e-01, time/batch = 0.0840s	
85/5250 (epoch 0.810), train_loss = 3.09836771, grad/param norm = 1.4303e-01, time/batch = 0.0843s	
86/5250 (epoch 0.819), train_loss = 3.09886998, grad/param norm = 1.6501e-01, time/batch = 0.0848s	
87/5250 (epoch 0.829), train_loss = 3.09441682, grad/param norm = 1.3644e-01, time/batch = 0.0839s	
88/5250 (epoch 0.838), train_loss = 3.09042181, grad/param norm = 1.5974e-01, time/batch = 0.0836s	
89/5250 (epoch 0.848), train_loss = 3.08345664, grad/param norm = 1.6746e-01, time/batch = 0.0847s	
90/5250 (epoch 0.857), train_loss = 3.08212962, grad/param norm = 2.2927e-01, time/batch = 0.0844s	
91/5250 (epoch 0.867), train_loss = 3.08719820, grad/param norm = 4.6180e-01, time/batch = 0.0900s	
92/5250 (epoch 0.876), train_loss = 3.09200855, grad/param norm = 7.1392e-01, time/batch = 0.0841s	
93/5250 (epoch 0.886), train_loss = 3.08803860, grad/param norm = 7.1488e-01, time/batch = 0.0840s	
94/5250 (epoch 0.895), train_loss = 3.06306252, grad/param norm = 5.3375e-01, time/batch = 0.0841s	
95/5250 (epoch 0.905), train_loss = 3.05335555, grad/param norm = 4.6879e-01, time/batch = 0.0845s	
96/5250 (epoch 0.914), train_loss = 3.03655466, grad/param norm = 4.2233e-01, time/batch = 0.0844s	
97/5250 (epoch 0.924), train_loss = 3.02940304, grad/param norm = 4.9394e-01, time/batch = 0.0843s	
98/5250 (epoch 0.933), train_loss = 3.02741740, grad/param norm = 5.7301e-01, time/batch = 0.0836s	
99/5250 (epoch 0.943), train_loss = 3.02738541, grad/param norm = 6.9123e-01, time/batch = 0.0844s	
100/5250 (epoch 0.952), train_loss = 3.02872527, grad/param norm = 7.3408e-01, time/batch = 0.0845s	
101/5250 (epoch 0.962), train_loss = 3.02663513, grad/param norm = 8.0537e-01, time/batch = 0.0893s	
102/5250 (epoch 0.971), train_loss = 3.02432025, grad/param norm = 7.4213e-01, time/batch = 0.0847s	
103/5250 (epoch 0.981), train_loss = 3.01194619, grad/param norm = 6.4698e-01, time/batch = 0.0842s	
104/5250 (epoch 0.990), train_loss = 2.97663976, grad/param norm = 5.0008e-01, time/batch = 0.0841s	
105/5250 (epoch 1.000), train_loss = 2.96040657, grad/param norm = 4.5910e-01, time/batch = 0.0842s	
106/5250 (epoch 1.010), train_loss = 2.96980860, grad/param norm = 4.8320e-01, time/batch = 0.0847s	
107/5250 (epoch 1.019), train_loss = 2.97382182, grad/param norm = 6.2092e-01, time/batch = 0.0837s	
108/5250 (epoch 1.029), train_loss = 2.95904355, grad/param norm = 8.7489e-01, time/batch = 0.0842s	
109/5250 (epoch 1.038), train_loss = 2.99963549, grad/param norm = 1.1952e+00, time/batch = 0.0845s	
110/5250 (epoch 1.048), train_loss = 3.06411008, grad/param norm = 1.9020e+00, time/batch = 0.0845s	
111/5250 (epoch 1.057), train_loss = 3.05205564, grad/param norm = 1.3929e+00, time/batch = 0.0896s	
112/5250 (epoch 1.067), train_loss = 2.99199482, grad/param norm = 9.9822e-01, time/batch = 0.0841s	
113/5250 (epoch 1.076), train_loss = 2.94295280, grad/param norm = 7.2814e-01, time/batch = 0.1586s	
114/5250 (epoch 1.086), train_loss = 2.92550479, grad/param norm = 5.6722e-01, time/batch = 0.1702s	
115/5250 (epoch 1.095), train_loss = 2.91521135, grad/param norm = 5.5392e-01, time/batch = 0.1714s	
116/5250 (epoch 1.105), train_loss = 2.89933925, grad/param norm = 4.9755e-01, time/batch = 0.1150s	
117/5250 (epoch 1.114), train_loss = 2.89183092, grad/param norm = 4.8195e-01, time/batch = 0.1026s	
118/5250 (epoch 1.124), train_loss = 2.87724549, grad/param norm = 4.9396e-01, time/batch = 0.1023s	
119/5250 (epoch 1.133), train_loss = 2.86968390, grad/param norm = 5.6621e-01, time/batch = 0.1033s	
120/5250 (epoch 1.143), train_loss = 2.85890944, grad/param norm = 6.6921e-01, time/batch = 0.1028s	
121/5250 (epoch 1.152), train_loss = 2.86514300, grad/param norm = 7.9436e-01, time/batch = 0.0971s	
122/5250 (epoch 1.162), train_loss = 2.86868395, grad/param norm = 8.3021e-01, time/batch = 0.0917s	
123/5250 (epoch 1.171), train_loss = 2.85425446, grad/param norm = 8.0141e-01, time/batch = 0.0916s	
124/5250 (epoch 1.181), train_loss = 2.86120659, grad/param norm = 7.1489e-01, time/batch = 0.0916s	
125/5250 (epoch 1.190), train_loss = 2.83725801, grad/param norm = 5.5258e-01, time/batch = 0.0926s	
126/5250 (epoch 1.200), train_loss = 2.80525541, grad/param norm = 5.2665e-01, time/batch = 0.1681s	
127/5250 (epoch 1.210), train_loss = 2.82286420, grad/param norm = 5.9200e-01, time/batch = 0.1749s	
128/5250 (epoch 1.219), train_loss = 2.83698888, grad/param norm = 8.1870e-01, time/batch = 0.1696s	
129/5250 (epoch 1.229), train_loss = 2.84499786, grad/param norm = 7.7363e-01, time/batch = 0.1535s	
130/5250 (epoch 1.238), train_loss = 2.78883575, grad/param norm = 4.7349e-01, time/batch = 0.1528s	
131/5250 (epoch 1.248), train_loss = 2.76310386, grad/param norm = 3.5174e-01, time/batch = 0.1358s	
132/5250 (epoch 1.257), train_loss = 2.75088558, grad/param norm = 4.1061e-01, time/batch = 0.0983s	
133/5250 (epoch 1.267), train_loss = 2.76980783, grad/param norm = 6.5851e-01, time/batch = 0.0976s	
134/5250 (epoch 1.276), train_loss = 2.79799075, grad/param norm = 1.0920e+00, time/batch = 0.0975s	
135/5250 (epoch 1.286), train_loss = 2.85162191, grad/param norm = 1.4374e+00, time/batch = 0.0973s	
136/5250 (epoch 1.295), train_loss = 2.81490726, grad/param norm = 9.9597e-01, time/batch = 0.0972s	
137/5250 (epoch 1.305), train_loss = 2.77956477, grad/param norm = 5.3347e-01, time/batch = 0.0942s	
138/5250 (epoch 1.314), train_loss = 2.75279040, grad/param norm = 3.2419e-01, time/batch = 0.0940s	
139/5250 (epoch 1.324), train_loss = 2.72670434, grad/param norm = 3.0704e-01, time/batch = 0.0946s	
140/5250 (epoch 1.333), train_loss = 2.73067557, grad/param norm = 2.9202e-01, time/batch = 0.0939s	
141/5250 (epoch 1.343), train_loss = 2.71263926, grad/param norm = 3.1649e-01, time/batch = 0.0971s	
142/5250 (epoch 1.352), train_loss = 2.70162457, grad/param norm = 3.9045e-01, time/batch = 0.0941s	
143/5250 (epoch 1.362), train_loss = 2.71480111, grad/param norm = 5.1243e-01, time/batch = 0.0941s	
144/5250 (epoch 1.371), train_loss = 2.71809235, grad/param norm = 6.7492e-01, time/batch = 0.0937s	
145/5250 (epoch 1.381), train_loss = 2.72312760, grad/param norm = 8.8375e-01, time/batch = 0.0941s	
146/5250 (epoch 1.390), train_loss = 2.76112247, grad/param norm = 9.4317e-01, time/batch = 0.0900s	
147/5250 (epoch 1.400), train_loss = 2.74790989, grad/param norm = 1.0729e+00, time/batch = 0.0783s	
148/5250 (epoch 1.410), train_loss = 2.75053904, grad/param norm = 1.0562e+00, time/batch = 0.0774s	
149/5250 (epoch 1.419), train_loss = 2.70740515, grad/param norm = 8.3151e-01, time/batch = 0.0779s	
150/5250 (epoch 1.429), train_loss = 2.67759059, grad/param norm = 5.9134e-01, time/batch = 0.0770s	
151/5250 (epoch 1.438), train_loss = 2.69046069, grad/param norm = 6.6473e-01, time/batch = 0.0789s	
152/5250 (epoch 1.448), train_loss = 2.70317582, grad/param norm = 8.1875e-01, time/batch = 0.0771s	
153/5250 (epoch 1.457), train_loss = 2.69393418, grad/param norm = 8.5720e-01, time/batch = 0.0774s	
154/5250 (epoch 1.467), train_loss = 2.67984083, grad/param norm = 6.6626e-01, time/batch = 0.0773s	
155/5250 (epoch 1.476), train_loss = 2.66132305, grad/param norm = 4.9084e-01, time/batch = 0.0773s	
156/5250 (epoch 1.486), train_loss = 2.65376309, grad/param norm = 4.3698e-01, time/batch = 0.0779s	
157/5250 (epoch 1.495), train_loss = 2.62397359, grad/param norm = 5.0211e-01, time/batch = 0.0777s	
158/5250 (epoch 1.505), train_loss = 2.63724906, grad/param norm = 6.2848e-01, time/batch = 0.0775s	
159/5250 (epoch 1.514), train_loss = 2.64234472, grad/param norm = 8.0770e-01, time/batch = 0.0780s	
160/5250 (epoch 1.524), train_loss = 2.65437205, grad/param norm = 8.0800e-01, time/batch = 0.0772s	
161/5250 (epoch 1.533), train_loss = 2.63758556, grad/param norm = 7.1937e-01, time/batch = 0.0791s	
162/5250 (epoch 1.543), train_loss = 2.62470060, grad/param norm = 5.5699e-01, time/batch = 0.0771s	
163/5250 (epoch 1.552), train_loss = 2.60945739, grad/param norm = 4.4577e-01, time/batch = 0.0775s	
164/5250 (epoch 1.562), train_loss = 2.61214743, grad/param norm = 4.5110e-01, time/batch = 0.1480s	
165/5250 (epoch 1.571), train_loss = 2.61930020, grad/param norm = 5.9416e-01, time/batch = 0.1794s	
166/5250 (epoch 1.581), train_loss = 2.64930910, grad/param norm = 9.0205e-01, time/batch = 0.1774s	
167/5250 (epoch 1.590), train_loss = 2.67327824, grad/param norm = 9.7341e-01, time/batch = 0.1735s	
168/5250 (epoch 1.600), train_loss = 2.64131103, grad/param norm = 7.8311e-01, time/batch = 0.1738s	
169/5250 (epoch 1.610), train_loss = 2.59169208, grad/param norm = 5.0269e-01, time/batch = 0.1352s	
170/5250 (epoch 1.619), train_loss = 2.56699011, grad/param norm = 4.7126e-01, time/batch = 0.1057s	
171/5250 (epoch 1.629), train_loss = 2.60140982, grad/param norm = 5.1718e-01, time/batch = 0.1080s	
172/5250 (epoch 1.638), train_loss = 2.59966038, grad/param norm = 5.4435e-01, time/batch = 0.1051s	
173/5250 (epoch 1.648), train_loss = 2.58159848, grad/param norm = 5.8086e-01, time/batch = 0.1010s	
174/5250 (epoch 1.657), train_loss = 2.57227248, grad/param norm = 7.5688e-01, time/batch = 0.0940s	
175/5250 (epoch 1.667), train_loss = 2.62142237, grad/param norm = 7.8969e-01, time/batch = 0.0941s	
176/5250 (epoch 1.676), train_loss = 2.58350683, grad/param norm = 6.8360e-01, time/batch = 0.0945s	
177/5250 (epoch 1.686), train_loss = 2.60271479, grad/param norm = 6.4985e-01, time/batch = 0.0939s	
178/5250 (epoch 1.695), train_loss = 2.55191059, grad/param norm = 5.9883e-01, time/batch = 0.0944s	
179/5250 (epoch 1.705), train_loss = 2.56313304, grad/param norm = 5.5789e-01, time/batch = 0.0945s	
180/5250 (epoch 1.714), train_loss = 2.55564620, grad/param norm = 4.9235e-01, time/batch = 0.0939s	
181/5250 (epoch 1.724), train_loss = 2.55084228, grad/param norm = 4.4454e-01, time/batch = 0.0963s	
182/5250 (epoch 1.733), train_loss = 2.53885369, grad/param norm = 5.8520e-01, time/batch = 0.0935s	
183/5250 (epoch 1.743), train_loss = 2.55991934, grad/param norm = 7.0039e-01, time/batch = 0.0942s	
184/5250 (epoch 1.752), train_loss = 2.56489217, grad/param norm = 8.3359e-01, time/batch = 0.0829s	
185/5250 (epoch 1.762), train_loss = 2.58426553, grad/param norm = 8.5086e-01, time/batch = 0.0773s	
186/5250 (epoch 1.771), train_loss = 2.53708701, grad/param norm = 7.9076e-01, time/batch = 0.0778s	
187/5250 (epoch 1.781), train_loss = 2.55004808, grad/param norm = 6.4568e-01, time/batch = 0.0772s	
188/5250 (epoch 1.790), train_loss = 2.54179957, grad/param norm = 8.0478e-01, time/batch = 0.0774s	
189/5250 (epoch 1.800), train_loss = 2.56383107, grad/param norm = 7.6788e-01, time/batch = 0.0784s	
190/5250 (epoch 1.810), train_loss = 2.50713489, grad/param norm = 5.6304e-01, time/batch = 0.0770s	
191/5250 (epoch 1.819), train_loss = 2.50081203, grad/param norm = 3.6979e-01, time/batch = 0.0789s	
192/5250 (epoch 1.829), train_loss = 2.50694269, grad/param norm = 2.4080e-01, time/batch = 0.0770s	
193/5250 (epoch 1.838), train_loss = 2.49461740, grad/param norm = 2.2967e-01, time/batch = 0.0772s	
194/5250 (epoch 1.848), train_loss = 2.48597154, grad/param norm = 2.7099e-01, time/batch = 0.0776s	
195/5250 (epoch 1.857), train_loss = 2.48200737, grad/param norm = 3.2189e-01, time/batch = 0.0776s	
196/5250 (epoch 1.867), train_loss = 2.48776983, grad/param norm = 3.9766e-01, time/batch = 0.0779s	
197/5250 (epoch 1.876), train_loss = 2.50261872, grad/param norm = 5.0578e-01, time/batch = 0.0773s	
198/5250 (epoch 1.886), train_loss = 2.52348542, grad/param norm = 7.0591e-01, time/batch = 0.0773s	
199/5250 (epoch 1.895), train_loss = 2.51608767, grad/param norm = 7.3201e-01, time/batch = 0.0779s	
200/5250 (epoch 1.905), train_loss = 2.51950696, grad/param norm = 7.0271e-01, time/batch = 0.0774s	
201/5250 (epoch 1.914), train_loss = 2.51706928, grad/param norm = 1.0129e+00, time/batch = 0.0791s	
202/5250 (epoch 1.924), train_loss = 2.55794818, grad/param norm = 1.0678e+00, time/batch = 0.0770s	
203/5250 (epoch 1.933), train_loss = 2.51365417, grad/param norm = 7.4217e-01, time/batch = 0.0769s	
204/5250 (epoch 1.943), train_loss = 2.49223881, grad/param norm = 5.2989e-01, time/batch = 0.0771s	
205/5250 (epoch 1.952), train_loss = 2.48389003, grad/param norm = 5.5573e-01, time/batch = 0.0776s	
206/5250 (epoch 1.962), train_loss = 2.49380934, grad/param norm = 5.6687e-01, time/batch = 0.0779s	
207/5250 (epoch 1.971), train_loss = 2.47010067, grad/param norm = 5.1210e-01, time/batch = 0.0773s	
208/5250 (epoch 1.981), train_loss = 2.47131631, grad/param norm = 4.2650e-01, time/batch = 0.0773s	
209/5250 (epoch 1.990), train_loss = 2.44755232, grad/param norm = 3.5882e-01, time/batch = 0.0779s	
210/5250 (epoch 2.000), train_loss = 2.42678175, grad/param norm = 3.3755e-01, time/batch = 0.0770s	
211/5250 (epoch 2.010), train_loss = 2.45397152, grad/param norm = 3.4022e-01, time/batch = 0.0797s	
212/5250 (epoch 2.019), train_loss = 2.45066260, grad/param norm = 4.1338e-01, time/batch = 0.0772s	
213/5250 (epoch 2.029), train_loss = 2.43537533, grad/param norm = 5.8229e-01, time/batch = 0.0772s	
214/5250 (epoch 2.038), train_loss = 2.49258541, grad/param norm = 8.3180e-01, time/batch = 0.0771s	
215/5250 (epoch 2.048), train_loss = 2.48876213, grad/param norm = 8.6902e-01, time/batch = 0.0773s	
216/5250 (epoch 2.057), train_loss = 2.49987244, grad/param norm = 6.5039e-01, time/batch = 0.0779s	
217/5250 (epoch 2.067), train_loss = 2.46826817, grad/param norm = 4.3585e-01, time/batch = 0.0775s	
218/5250 (epoch 2.076), train_loss = 2.42887661, grad/param norm = 3.5854e-01, time/batch = 0.0773s	
219/5250 (epoch 2.086), train_loss = 2.41562685, grad/param norm = 3.6932e-01, time/batch = 0.0779s	
220/5250 (epoch 2.095), train_loss = 2.44123106, grad/param norm = 4.6418e-01, time/batch = 0.0771s	
221/5250 (epoch 2.105), train_loss = 2.46554220, grad/param norm = 6.9322e-01, time/batch = 0.0798s	
222/5250 (epoch 2.114), train_loss = 2.49095848, grad/param norm = 7.4078e-01, time/batch = 0.0777s	
223/5250 (epoch 2.124), train_loss = 2.45873232, grad/param norm = 5.4558e-01, time/batch = 0.0774s	
224/5250 (epoch 2.133), train_loss = 2.42713094, grad/param norm = 3.5050e-01, time/batch = 0.0773s	
225/5250 (epoch 2.143), train_loss = 2.39428951, grad/param norm = 2.6613e-01, time/batch = 0.0772s	
226/5250 (epoch 2.152), train_loss = 2.40056566, grad/param norm = 2.9126e-01, time/batch = 0.0776s	
227/5250 (epoch 2.162), train_loss = 2.41019044, grad/param norm = 3.8742e-01, time/batch = 0.0772s	
228/5250 (epoch 2.171), train_loss = 2.42249504, grad/param norm = 5.8858e-01, time/batch = 0.0776s	
229/5250 (epoch 2.181), train_loss = 2.47605410, grad/param norm = 8.2419e-01, time/batch = 0.0776s	
230/5250 (epoch 2.190), train_loss = 2.46896319, grad/param norm = 7.6561e-01, time/batch = 0.0769s	
231/5250 (epoch 2.200), train_loss = 2.40916200, grad/param norm = 5.0794e-01, time/batch = 0.0789s	
232/5250 (epoch 2.210), train_loss = 2.42625031, grad/param norm = 4.1953e-01, time/batch = 0.0771s	
233/5250 (epoch 2.219), train_loss = 2.41278939, grad/param norm = 3.2445e-01, time/batch = 0.0778s	
234/5250 (epoch 2.229), train_loss = 2.40127862, grad/param norm = 2.7639e-01, time/batch = 0.0771s	
235/5250 (epoch 2.238), train_loss = 2.36937647, grad/param norm = 2.9222e-01, time/batch = 0.0775s	
236/5250 (epoch 2.248), train_loss = 2.37946540, grad/param norm = 3.7432e-01, time/batch = 0.0778s	
237/5250 (epoch 2.257), train_loss = 2.39213221, grad/param norm = 5.7883e-01, time/batch = 0.0772s	
238/5250 (epoch 2.267), train_loss = 2.43817736, grad/param norm = 8.2557e-01, time/batch = 0.0771s	
239/5250 (epoch 2.276), train_loss = 2.47216428, grad/param norm = 8.9946e-01, time/batch = 0.0783s	
240/5250 (epoch 2.286), train_loss = 2.42469049, grad/param norm = 7.0287e-01, time/batch = 0.0772s	
241/5250 (epoch 2.295), train_loss = 2.38960963, grad/param norm = 4.0887e-01, time/batch = 0.0797s	
242/5250 (epoch 2.305), train_loss = 2.39747193, grad/param norm = 4.3164e-01, time/batch = 0.0770s	
243/5250 (epoch 2.314), train_loss = 2.39481791, grad/param norm = 5.7850e-01, time/batch = 0.0770s	
244/5250 (epoch 2.324), train_loss = 2.39122198, grad/param norm = 6.6260e-01, time/batch = 0.0778s	
245/5250 (epoch 2.333), train_loss = 2.41613220, grad/param norm = 7.0043e-01, time/batch = 0.0773s	
246/5250 (epoch 2.343), train_loss = 2.42117568, grad/param norm = 6.0504e-01, time/batch = 0.0779s	
247/5250 (epoch 2.352), train_loss = 2.37525304, grad/param norm = 4.5483e-01, time/batch = 0.0772s	
248/5250 (epoch 2.362), train_loss = 2.37233897, grad/param norm = 3.0141e-01, time/batch = 0.0772s	
249/5250 (epoch 2.371), train_loss = 2.35470136, grad/param norm = 1.9578e-01, time/batch = 0.0777s	
250/5250 (epoch 2.381), train_loss = 2.33610554, grad/param norm = 1.7338e-01, time/batch = 0.0777s	
251/5250 (epoch 2.390), train_loss = 2.36557324, grad/param norm = 2.1945e-01, time/batch = 0.0791s	
252/5250 (epoch 2.400), train_loss = 2.34539785, grad/param norm = 3.4207e-01, time/batch = 0.0771s	
253/5250 (epoch 2.410), train_loss = 2.36191656, grad/param norm = 7.0588e-01, time/batch = 0.0773s	
254/5250 (epoch 2.419), train_loss = 2.41574880, grad/param norm = 8.8645e-01, time/batch = 0.0772s	
255/5250 (epoch 2.429), train_loss = 2.41136716, grad/param norm = 7.3626e-01, time/batch = 0.0777s	
256/5250 (epoch 2.438), train_loss = 2.39576576, grad/param norm = 4.5104e-01, time/batch = 0.0778s	
257/5250 (epoch 2.448), train_loss = 2.34948266, grad/param norm = 3.2433e-01, time/batch = 0.0773s	
258/5250 (epoch 2.457), train_loss = 2.33162832, grad/param norm = 2.6306e-01, time/batch = 0.0771s	
259/5250 (epoch 2.467), train_loss = 2.32511035, grad/param norm = 2.4663e-01, time/batch = 0.0775s	
260/5250 (epoch 2.476), train_loss = 2.33400224, grad/param norm = 2.8779e-01, time/batch = 0.0769s	
261/5250 (epoch 2.486), train_loss = 2.35309574, grad/param norm = 3.6985e-01, time/batch = 0.0790s	
262/5250 (epoch 2.495), train_loss = 2.33238499, grad/param norm = 5.9851e-01, time/batch = 0.0770s	
263/5250 (epoch 2.505), train_loss = 2.38336146, grad/param norm = 7.8362e-01, time/batch = 0.0773s	
264/5250 (epoch 2.514), train_loss = 2.38185682, grad/param norm = 6.5235e-01, time/batch = 0.0769s	
265/5250 (epoch 2.524), train_loss = 2.36289010, grad/param norm = 5.2795e-01, time/batch = 0.0773s	
266/5250 (epoch 2.533), train_loss = 2.34339531, grad/param norm = 4.9675e-01, time/batch = 0.0782s	
267/5250 (epoch 2.543), train_loss = 2.34338785, grad/param norm = 5.0463e-01, time/batch = 0.0773s	
268/5250 (epoch 2.552), train_loss = 2.32912797, grad/param norm = 4.8924e-01, time/batch = 0.0773s	
269/5250 (epoch 2.562), train_loss = 2.34274387, grad/param norm = 4.2624e-01, time/batch = 0.0778s	
270/5250 (epoch 2.571), train_loss = 2.32644789, grad/param norm = 3.6413e-01, time/batch = 0.0771s	
271/5250 (epoch 2.581), train_loss = 2.32659365, grad/param norm = 3.9314e-01, time/batch = 0.0792s	
272/5250 (epoch 2.590), train_loss = 2.31864535, grad/param norm = 4.0933e-01, time/batch = 0.0778s	
273/5250 (epoch 2.600), train_loss = 2.33442190, grad/param norm = 4.0875e-01, time/batch = 0.0771s	
274/5250 (epoch 2.610), train_loss = 2.31118483, grad/param norm = 4.5162e-01, time/batch = 0.0770s	
275/5250 (epoch 2.619), train_loss = 2.30257550, grad/param norm = 4.4909e-01, time/batch = 0.0770s	
276/5250 (epoch 2.629), train_loss = 2.33830533, grad/param norm = 3.9079e-01, time/batch = 0.0775s	
277/5250 (epoch 2.638), train_loss = 2.32130139, grad/param norm = 3.7992e-01, time/batch = 0.0778s	
278/5250 (epoch 2.648), train_loss = 2.30829564, grad/param norm = 4.1087e-01, time/batch = 0.0773s	
279/5250 (epoch 2.657), train_loss = 2.28566490, grad/param norm = 3.6899e-01, time/batch = 0.0779s	
280/5250 (epoch 2.667), train_loss = 2.31940978, grad/param norm = 3.4649e-01, time/batch = 0.0773s	
281/5250 (epoch 2.676), train_loss = 2.29792201, grad/param norm = 3.5628e-01, time/batch = 0.0792s	
282/5250 (epoch 2.686), train_loss = 2.32411542, grad/param norm = 3.5161e-01, time/batch = 0.0771s	
283/5250 (epoch 2.695), train_loss = 2.28221095, grad/param norm = 3.7777e-01, time/batch = 0.0776s	
284/5250 (epoch 2.705), train_loss = 2.29958994, grad/param norm = 5.0269e-01, time/batch = 0.0772s	
285/5250 (epoch 2.714), train_loss = 2.33182564, grad/param norm = 6.3454e-01, time/batch = 0.0772s	
286/5250 (epoch 2.724), train_loss = 2.33226299, grad/param norm = 6.4185e-01, time/batch = 0.0776s	
287/5250 (epoch 2.733), train_loss = 2.31024655, grad/param norm = 6.2534e-01, time/batch = 0.0773s	
288/5250 (epoch 2.743), train_loss = 2.30187377, grad/param norm = 4.8058e-01, time/batch = 0.0773s	
289/5250 (epoch 2.752), train_loss = 2.28682365, grad/param norm = 3.8351e-01, time/batch = 0.0777s	
290/5250 (epoch 2.762), train_loss = 2.29010923, grad/param norm = 3.6437e-01, time/batch = 0.0771s	
291/5250 (epoch 2.771), train_loss = 2.24356311, grad/param norm = 3.4724e-01, time/batch = 0.0790s	
292/5250 (epoch 2.781), train_loss = 2.28610615, grad/param norm = 3.6924e-01, time/batch = 0.0770s	
293/5250 (epoch 2.790), train_loss = 2.27967307, grad/param norm = 4.0226e-01, time/batch = 0.0771s	
294/5250 (epoch 2.800), train_loss = 2.28518323, grad/param norm = 4.2498e-01, time/batch = 0.0776s	
295/5250 (epoch 2.810), train_loss = 2.26148989, grad/param norm = 4.6425e-01, time/batch = 0.0775s	
296/5250 (epoch 2.819), train_loss = 2.27044125, grad/param norm = 4.4121e-01, time/batch = 0.0778s	
297/5250 (epoch 2.829), train_loss = 2.28187615, grad/param norm = 3.5328e-01, time/batch = 0.0774s	
298/5250 (epoch 2.838), train_loss = 2.26860022, grad/param norm = 3.0952e-01, time/batch = 0.0774s	
299/5250 (epoch 2.848), train_loss = 2.25609149, grad/param norm = 3.8027e-01, time/batch = 0.0781s	
300/5250 (epoch 2.857), train_loss = 2.27241203, grad/param norm = 4.3616e-01, time/batch = 0.0775s	
301/5250 (epoch 2.867), train_loss = 2.27653047, grad/param norm = 4.9271e-01, time/batch = 0.0791s	
302/5250 (epoch 2.876), train_loss = 2.30171443, grad/param norm = 6.5906e-01, time/batch = 0.0770s	
303/5250 (epoch 2.886), train_loss = 2.31111400, grad/param norm = 6.2302e-01, time/batch = 0.0769s	
304/5250 (epoch 2.895), train_loss = 2.27065291, grad/param norm = 4.5157e-01, time/batch = 0.0772s	
305/5250 (epoch 2.905), train_loss = 2.26142819, grad/param norm = 3.7178e-01, time/batch = 0.0776s	
306/5250 (epoch 2.914), train_loss = 2.23383994, grad/param norm = 3.4793e-01, time/batch = 0.0779s	
307/5250 (epoch 2.924), train_loss = 2.23723489, grad/param norm = 3.1146e-01, time/batch = 0.0772s	
308/5250 (epoch 2.933), train_loss = 2.23886268, grad/param norm = 2.9693e-01, time/batch = 0.0772s	
309/5250 (epoch 2.943), train_loss = 2.23868485, grad/param norm = 3.0375e-01, time/batch = 0.0777s	
310/5250 (epoch 2.952), train_loss = 2.25789820, grad/param norm = 4.2338e-01, time/batch = 0.0770s	
311/5250 (epoch 2.962), train_loss = 2.25701400, grad/param norm = 4.5856e-01, time/batch = 0.0789s	
312/5250 (epoch 2.971), train_loss = 2.23814990, grad/param norm = 3.7664e-01, time/batch = 0.0771s	
313/5250 (epoch 2.981), train_loss = 2.25048111, grad/param norm = 3.5120e-01, time/batch = 0.0772s	
314/5250 (epoch 2.990), train_loss = 2.23408770, grad/param norm = 4.2251e-01, time/batch = 0.0768s	
315/5250 (epoch 3.000), train_loss = 2.22337858, grad/param norm = 5.3782e-01, time/batch = 0.0773s	
316/5250 (epoch 3.010), train_loss = 2.29167630, grad/param norm = 4.6096e-01, time/batch = 0.0782s	
317/5250 (epoch 3.019), train_loss = 2.24920810, grad/param norm = 3.5777e-01, time/batch = 0.0773s	
318/5250 (epoch 3.029), train_loss = 2.22389358, grad/param norm = 3.4436e-01, time/batch = 0.0772s	
319/5250 (epoch 3.038), train_loss = 2.25404989, grad/param norm = 2.6929e-01, time/batch = 0.0778s	
320/5250 (epoch 3.048), train_loss = 2.21256805, grad/param norm = 2.1537e-01, time/batch = 0.0769s	
321/5250 (epoch 3.057), train_loss = 2.22725508, grad/param norm = 2.2747e-01, time/batch = 0.0789s	
322/5250 (epoch 3.067), train_loss = 2.23610805, grad/param norm = 2.9449e-01, time/batch = 0.0770s	
323/5250 (epoch 3.076), train_loss = 2.22866172, grad/param norm = 5.3751e-01, time/batch = 0.0771s	
324/5250 (epoch 3.086), train_loss = 2.29495535, grad/param norm = 9.6949e-01, time/batch = 0.0772s	
325/5250 (epoch 3.095), train_loss = 2.37183796, grad/param norm = 1.0176e+00, time/batch = 0.0770s	
326/5250 (epoch 3.105), train_loss = 2.28863873, grad/param norm = 5.0927e-01, time/batch = 0.0776s	
327/5250 (epoch 3.114), train_loss = 2.24259395, grad/param norm = 3.2668e-01, time/batch = 0.0777s	
328/5250 (epoch 3.124), train_loss = 2.21853969, grad/param norm = 2.4185e-01, time/batch = 0.0774s	
329/5250 (epoch 3.133), train_loss = 2.20272826, grad/param norm = 1.8537e-01, time/batch = 0.0778s	
330/5250 (epoch 3.143), train_loss = 2.17586494, grad/param norm = 1.6478e-01, time/batch = 0.0770s	
331/5250 (epoch 3.152), train_loss = 2.18135373, grad/param norm = 1.7793e-01, time/batch = 0.0799s	
332/5250 (epoch 3.162), train_loss = 2.18897728, grad/param norm = 2.2024e-01, time/batch = 0.0771s	
333/5250 (epoch 3.171), train_loss = 2.21321464, grad/param norm = 3.2054e-01, time/batch = 0.0776s	
334/5250 (epoch 3.181), train_loss = 2.24496396, grad/param norm = 3.9215e-01, time/batch = 0.0772s	
335/5250 (epoch 3.190), train_loss = 2.22956740, grad/param norm = 5.0129e-01, time/batch = 0.0772s	
336/5250 (epoch 3.200), train_loss = 2.22724510, grad/param norm = 6.0051e-01, time/batch = 0.0777s	
337/5250 (epoch 3.210), train_loss = 2.25777149, grad/param norm = 6.7957e-01, time/batch = 0.0775s	
338/5250 (epoch 3.219), train_loss = 2.25841175, grad/param norm = 5.7823e-01, time/batch = 0.0777s	
339/5250 (epoch 3.229), train_loss = 2.22337162, grad/param norm = 4.1589e-01, time/batch = 0.0779s	
340/5250 (epoch 3.238), train_loss = 2.17589402, grad/param norm = 2.9239e-01, time/batch = 0.0771s	
341/5250 (epoch 3.248), train_loss = 2.17635088, grad/param norm = 2.2271e-01, time/batch = 0.0789s	
342/5250 (epoch 3.257), train_loss = 2.16380876, grad/param norm = 2.0798e-01, time/batch = 0.0770s	
343/5250 (epoch 3.267), train_loss = 2.16314072, grad/param norm = 2.2189e-01, time/batch = 0.0771s	
344/5250 (epoch 3.276), train_loss = 2.17597978, grad/param norm = 2.2897e-01, time/batch = 0.0778s	
345/5250 (epoch 3.286), train_loss = 2.14737937, grad/param norm = 2.2175e-01, time/batch = 0.0770s	
346/5250 (epoch 3.295), train_loss = 2.17388072, grad/param norm = 2.2183e-01, time/batch = 0.0778s	
347/5250 (epoch 3.305), train_loss = 2.19446484, grad/param norm = 2.4629e-01, time/batch = 0.0771s	
348/5250 (epoch 3.314), train_loss = 2.17230042, grad/param norm = 3.2970e-01, time/batch = 0.0772s	
349/5250 (epoch 3.324), train_loss = 2.18687578, grad/param norm = 3.7395e-01, time/batch = 0.0774s	
350/5250 (epoch 3.333), train_loss = 2.19787785, grad/param norm = 3.9676e-01, time/batch = 0.0771s	
351/5250 (epoch 3.343), train_loss = 2.19653841, grad/param norm = 4.2864e-01, time/batch = 0.0790s	
352/5250 (epoch 3.352), train_loss = 2.17730415, grad/param norm = 5.4738e-01, time/batch = 0.0769s	
353/5250 (epoch 3.362), train_loss = 2.21541011, grad/param norm = 6.9380e-01, time/batch = 0.0772s	
354/5250 (epoch 3.371), train_loss = 2.20847287, grad/param norm = 5.0970e-01, time/batch = 0.0774s	
355/5250 (epoch 3.381), train_loss = 2.16680530, grad/param norm = 3.4989e-01, time/batch = 0.0776s	
356/5250 (epoch 3.390), train_loss = 2.19149134, grad/param norm = 3.1302e-01, time/batch = 0.0778s	
357/5250 (epoch 3.400), train_loss = 2.14987583, grad/param norm = 2.5199e-01, time/batch = 0.0774s	
358/5250 (epoch 3.410), train_loss = 2.15642028, grad/param norm = 2.8707e-01, time/batch = 0.0773s	
359/5250 (epoch 3.419), train_loss = 2.16822278, grad/param norm = 2.8996e-01, time/batch = 0.0778s	
360/5250 (epoch 3.429), train_loss = 2.15297722, grad/param norm = 2.8123e-01, time/batch = 0.0771s	
361/5250 (epoch 3.438), train_loss = 2.18641437, grad/param norm = 3.0055e-01, time/batch = 0.0791s	
362/5250 (epoch 3.448), train_loss = 2.15722694, grad/param norm = 3.1882e-01, time/batch = 0.0769s	
363/5250 (epoch 3.457), train_loss = 2.14340231, grad/param norm = 3.3557e-01, time/batch = 0.0770s	
364/5250 (epoch 3.467), train_loss = 2.14066847, grad/param norm = 2.9821e-01, time/batch = 0.0773s	
365/5250 (epoch 3.476), train_loss = 2.14656167, grad/param norm = 2.7985e-01, time/batch = 0.0772s	
366/5250 (epoch 3.486), train_loss = 2.16645886, grad/param norm = 3.0491e-01, time/batch = 0.0782s	
367/5250 (epoch 3.495), train_loss = 2.14503675, grad/param norm = 3.5384e-01, time/batch = 0.0773s	
368/5250 (epoch 3.505), train_loss = 2.15089358, grad/param norm = 3.5011e-01, time/batch = 0.0772s	
369/5250 (epoch 3.514), train_loss = 2.15041490, grad/param norm = 3.2887e-01, time/batch = 0.0776s	
370/5250 (epoch 3.524), train_loss = 2.13515393, grad/param norm = 4.0222e-01, time/batch = 0.0771s	
371/5250 (epoch 3.533), train_loss = 2.15747096, grad/param norm = 4.8610e-01, time/batch = 0.0794s	
372/5250 (epoch 3.543), train_loss = 2.15928890, grad/param norm = 4.4843e-01, time/batch = 0.0770s	
373/5250 (epoch 3.552), train_loss = 2.14173044, grad/param norm = 3.5974e-01, time/batch = 0.0773s	
374/5250 (epoch 3.562), train_loss = 2.16775276, grad/param norm = 4.0904e-01, time/batch = 0.0789s	
375/5250 (epoch 3.571), train_loss = 2.16698907, grad/param norm = 4.3085e-01, time/batch = 0.0782s	
376/5250 (epoch 3.581), train_loss = 2.16805079, grad/param norm = 4.4023e-01, time/batch = 0.0776s	
377/5250 (epoch 3.590), train_loss = 2.15599079, grad/param norm = 3.7707e-01, time/batch = 0.0776s	
378/5250 (epoch 3.600), train_loss = 2.15219524, grad/param norm = 2.6428e-01, time/batch = 0.0771s	
379/5250 (epoch 3.610), train_loss = 2.11234557, grad/param norm = 1.8780e-01, time/batch = 0.0779s	
380/5250 (epoch 3.619), train_loss = 2.10125398, grad/param norm = 1.8969e-01, time/batch = 0.0770s	
381/5250 (epoch 3.629), train_loss = 2.15049423, grad/param norm = 2.1730e-01, time/batch = 0.0843s	
382/5250 (epoch 3.638), train_loss = 2.12848530, grad/param norm = 2.4856e-01, time/batch = 0.0784s	
383/5250 (epoch 3.648), train_loss = 2.12696587, grad/param norm = 2.8941e-01, time/batch = 0.0770s	
384/5250 (epoch 3.657), train_loss = 2.10404153, grad/param norm = 3.7085e-01, time/batch = 0.0774s	
385/5250 (epoch 3.667), train_loss = 2.15629225, grad/param norm = 3.7136e-01, time/batch = 0.0774s	
386/5250 (epoch 3.676), train_loss = 2.12736340, grad/param norm = 3.5627e-01, time/batch = 0.0777s	
387/5250 (epoch 3.686), train_loss = 2.15296459, grad/param norm = 3.0157e-01, time/batch = 0.0772s	
388/5250 (epoch 3.695), train_loss = 2.09858598, grad/param norm = 2.2018e-01, time/batch = 0.0775s	
389/5250 (epoch 3.705), train_loss = 2.08758094, grad/param norm = 2.3902e-01, time/batch = 0.0777s	
390/5250 (epoch 3.714), train_loss = 2.12502107, grad/param norm = 3.4004e-01, time/batch = 0.0771s	
391/5250 (epoch 3.724), train_loss = 2.12578843, grad/param norm = 4.7173e-01, time/batch = 0.0790s	
392/5250 (epoch 3.733), train_loss = 2.14539444, grad/param norm = 4.6434e-01, time/batch = 0.0769s	
393/5250 (epoch 3.743), train_loss = 2.11032054, grad/param norm = 3.1334e-01, time/batch = 0.0771s	
394/5250 (epoch 3.752), train_loss = 2.10498034, grad/param norm = 2.3431e-01, time/batch = 0.0777s	
395/5250 (epoch 3.762), train_loss = 2.10632474, grad/param norm = 2.3727e-01, time/batch = 0.0773s	
396/5250 (epoch 3.771), train_loss = 2.06970765, grad/param norm = 2.7835e-01, time/batch = 0.0777s	
397/5250 (epoch 3.781), train_loss = 2.11475556, grad/param norm = 3.4513e-01, time/batch = 0.0771s	
398/5250 (epoch 3.790), train_loss = 2.12842385, grad/param norm = 3.9842e-01, time/batch = 0.0772s	
399/5250 (epoch 3.800), train_loss = 2.12665540, grad/param norm = 3.6655e-01, time/batch = 0.0782s	
400/5250 (epoch 3.810), train_loss = 2.08875853, grad/param norm = 3.2718e-01, time/batch = 0.0774s	
401/5250 (epoch 3.819), train_loss = 2.09627265, grad/param norm = 3.1417e-01, time/batch = 0.0793s	
402/5250 (epoch 3.829), train_loss = 2.11534949, grad/param norm = 3.8013e-01, time/batch = 0.0771s	
403/5250 (epoch 3.838), train_loss = 2.11577551, grad/param norm = 3.7626e-01, time/batch = 0.0772s	
404/5250 (epoch 3.848), train_loss = 2.09300139, grad/param norm = 3.5800e-01, time/batch = 0.0770s	
405/5250 (epoch 3.857), train_loss = 2.10531583, grad/param norm = 3.4778e-01, time/batch = 0.0774s	
406/5250 (epoch 3.867), train_loss = 2.09007080, grad/param norm = 2.7116e-01, time/batch = 0.0777s	
407/5250 (epoch 3.876), train_loss = 2.10165517, grad/param norm = 1.9625e-01, time/batch = 0.0772s	
408/5250 (epoch 3.886), train_loss = 2.09124253, grad/param norm = 2.0558e-01, time/batch = 0.0772s	
409/5250 (epoch 3.895), train_loss = 2.09020783, grad/param norm = 2.1776e-01, time/batch = 0.0777s	
410/5250 (epoch 3.905), train_loss = 2.09394042, grad/param norm = 2.3360e-01, time/batch = 0.0775s	
411/5250 (epoch 3.914), train_loss = 2.07929758, grad/param norm = 2.8774e-01, time/batch = 0.0789s	
412/5250 (epoch 3.924), train_loss = 2.09243937, grad/param norm = 2.9907e-01, time/batch = 0.0770s	
413/5250 (epoch 3.933), train_loss = 2.09344088, grad/param norm = 2.9974e-01, time/batch = 0.0771s	
414/5250 (epoch 3.943), train_loss = 2.09646017, grad/param norm = 2.7908e-01, time/batch = 0.0771s	
415/5250 (epoch 3.952), train_loss = 2.10346196, grad/param norm = 3.5960e-01, time/batch = 0.0774s	
416/5250 (epoch 3.962), train_loss = 2.10411833, grad/param norm = 4.2086e-01, time/batch = 0.0784s	
417/5250 (epoch 3.971), train_loss = 2.09004395, grad/param norm = 3.8586e-01, time/batch = 0.0774s	
418/5250 (epoch 3.981), train_loss = 2.11134224, grad/param norm = 3.9976e-01, time/batch = 0.0772s	
419/5250 (epoch 3.990), train_loss = 2.09984446, grad/param norm = 4.4497e-01, time/batch = 0.0778s	
420/5250 (epoch 4.000), train_loss = 2.06493512, grad/param norm = 3.5392e-01, time/batch = 0.0770s	
421/5250 (epoch 4.010), train_loss = 2.13732334, grad/param norm = 2.5333e-01, time/batch = 0.0793s	
422/5250 (epoch 4.019), train_loss = 2.07666374, grad/param norm = 2.3511e-01, time/batch = 0.0770s	
423/5250 (epoch 4.029), train_loss = 2.06355613, grad/param norm = 2.6967e-01, time/batch = 0.0779s	
424/5250 (epoch 4.038), train_loss = 2.10895439, grad/param norm = 3.2424e-01, time/batch = 0.0792s	
425/5250 (epoch 4.048), train_loss = 2.07767786, grad/param norm = 3.2145e-01, time/batch = 0.0772s	
426/5250 (epoch 4.057), train_loss = 2.08759995, grad/param norm = 2.7056e-01, time/batch = 0.0777s	
427/5250 (epoch 4.067), train_loss = 2.08928090, grad/param norm = 3.0222e-01, time/batch = 0.0779s	
428/5250 (epoch 4.076), train_loss = 2.07841590, grad/param norm = 3.1560e-01, time/batch = 0.0773s	
429/5250 (epoch 4.086), train_loss = 2.04667431, grad/param norm = 2.8465e-01, time/batch = 0.0777s	
430/5250 (epoch 4.095), train_loss = 2.08600259, grad/param norm = 2.8178e-01, time/batch = 0.0771s	
431/5250 (epoch 4.105), train_loss = 2.08398545, grad/param norm = 3.1497e-01, time/batch = 0.0788s	
432/5250 (epoch 4.114), train_loss = 2.07513605, grad/param norm = 3.1161e-01, time/batch = 0.0774s	
433/5250 (epoch 4.124), train_loss = 2.06659302, grad/param norm = 2.6564e-01, time/batch = 0.0771s	
434/5250 (epoch 4.133), train_loss = 2.04860255, grad/param norm = 2.0277e-01, time/batch = 0.0768s	
435/5250 (epoch 4.143), train_loss = 2.01694209, grad/param norm = 1.6407e-01, time/batch = 0.0776s	
436/5250 (epoch 4.152), train_loss = 2.02260799, grad/param norm = 1.8652e-01, time/batch = 0.0779s	
437/5250 (epoch 4.162), train_loss = 2.04419811, grad/param norm = 2.3500e-01, time/batch = 0.0771s	
438/5250 (epoch 4.171), train_loss = 2.07434025, grad/param norm = 2.6998e-01, time/batch = 0.0776s	
439/5250 (epoch 4.181), train_loss = 2.08483260, grad/param norm = 2.7125e-01, time/batch = 0.0780s	
440/5250 (epoch 4.190), train_loss = 2.06901414, grad/param norm = 2.6405e-01, time/batch = 0.0770s	
441/5250 (epoch 4.200), train_loss = 2.05162866, grad/param norm = 2.4752e-01, time/batch = 0.0799s	
442/5250 (epoch 4.210), train_loss = 2.06050758, grad/param norm = 2.4100e-01, time/batch = 0.0770s	
443/5250 (epoch 4.219), train_loss = 2.07591578, grad/param norm = 2.3162e-01, time/batch = 0.0776s	
444/5250 (epoch 4.229), train_loss = 2.06646167, grad/param norm = 2.8098e-01, time/batch = 0.0774s	
445/5250 (epoch 4.238), train_loss = 2.03879815, grad/param norm = 3.2777e-01, time/batch = 0.0773s	
446/5250 (epoch 4.248), train_loss = 2.05192176, grad/param norm = 2.9319e-01, time/batch = 0.0778s	
447/5250 (epoch 4.257), train_loss = 2.03066008, grad/param norm = 2.7294e-01, time/batch = 0.0773s	
448/5250 (epoch 4.267), train_loss = 2.02917150, grad/param norm = 2.9218e-01, time/batch = 0.0772s	
449/5250 (epoch 4.276), train_loss = 2.04817330, grad/param norm = 3.8193e-01, time/batch = 0.0781s	
450/5250 (epoch 4.286), train_loss = 2.04095413, grad/param norm = 4.7219e-01, time/batch = 0.0771s	
451/5250 (epoch 4.295), train_loss = 2.07934327, grad/param norm = 4.7841e-01, time/batch = 0.0790s	
452/5250 (epoch 4.305), train_loss = 2.08198535, grad/param norm = 4.1887e-01, time/batch = 0.0770s	
453/5250 (epoch 4.314), train_loss = 2.02826108, grad/param norm = 2.8786e-01, time/batch = 0.0771s	
454/5250 (epoch 4.324), train_loss = 2.02424513, grad/param norm = 1.7827e-01, time/batch = 0.0768s	
455/5250 (epoch 4.333), train_loss = 2.03857399, grad/param norm = 1.8601e-01, time/batch = 0.0771s	
456/5250 (epoch 4.343), train_loss = 2.03241969, grad/param norm = 1.8462e-01, time/batch = 0.0778s	
457/5250 (epoch 4.352), train_loss = 2.01692761, grad/param norm = 2.1275e-01, time/batch = 0.0774s	
458/5250 (epoch 4.362), train_loss = 2.01420596, grad/param norm = 1.8225e-01, time/batch = 0.0772s	
459/5250 (epoch 4.371), train_loss = 2.00644839, grad/param norm = 1.5634e-01, time/batch = 0.0779s	
460/5250 (epoch 4.381), train_loss = 1.99769016, grad/param norm = 1.7811e-01, time/batch = 0.0775s	
461/5250 (epoch 4.390), train_loss = 2.04012847, grad/param norm = 2.5331e-01, time/batch = 0.0790s	
462/5250 (epoch 4.400), train_loss = 2.01671134, grad/param norm = 3.2088e-01, time/batch = 0.0769s	
463/5250 (epoch 4.410), train_loss = 2.04094345, grad/param norm = 3.8718e-01, time/batch = 0.0770s	
464/5250 (epoch 4.419), train_loss = 2.05297724, grad/param norm = 4.0059e-01, time/batch = 0.0772s	
465/5250 (epoch 4.429), train_loss = 2.04946327, grad/param norm = 3.6634e-01, time/batch = 0.0775s	
466/5250 (epoch 4.438), train_loss = 2.06239289, grad/param norm = 3.2816e-01, time/batch = 0.0783s	
467/5250 (epoch 4.448), train_loss = 2.03266861, grad/param norm = 3.1732e-01, time/batch = 0.0772s	
468/5250 (epoch 4.457), train_loss = 2.00721752, grad/param norm = 2.7771e-01, time/batch = 0.0771s	
469/5250 (epoch 4.467), train_loss = 1.99124957, grad/param norm = 1.9167e-01, time/batch = 0.0777s	
470/5250 (epoch 4.476), train_loss = 1.99190651, grad/param norm = 1.6296e-01, time/batch = 0.0769s	
471/5250 (epoch 4.486), train_loss = 2.01280154, grad/param norm = 1.8281e-01, time/batch = 0.0791s	
472/5250 (epoch 4.495), train_loss = 1.99663260, grad/param norm = 2.3344e-01, time/batch = 0.0770s	
473/5250 (epoch 4.505), train_loss = 2.01363965, grad/param norm = 3.1850e-01, time/batch = 0.0773s	
474/5250 (epoch 4.514), train_loss = 2.03526582, grad/param norm = 4.0264e-01, time/batch = 0.0771s	
475/5250 (epoch 4.524), train_loss = 2.01406187, grad/param norm = 3.1200e-01, time/batch = 0.0775s	
476/5250 (epoch 4.533), train_loss = 2.00249220, grad/param norm = 2.2168e-01, time/batch = 0.0787s	
477/5250 (epoch 4.543), train_loss = 1.98623493, grad/param norm = 1.7873e-01, time/batch = 0.0779s	
478/5250 (epoch 4.552), train_loss = 1.98025395, grad/param norm = 1.9303e-01, time/batch = 0.0773s	
479/5250 (epoch 4.562), train_loss = 2.01280130, grad/param norm = 2.6234e-01, time/batch = 0.0773s	
480/5250 (epoch 4.571), train_loss = 2.01341800, grad/param norm = 3.1751e-01, time/batch = 0.0770s	
481/5250 (epoch 4.581), train_loss = 2.02270788, grad/param norm = 3.2017e-01, time/batch = 0.0788s	
482/5250 (epoch 4.590), train_loss = 2.01185147, grad/param norm = 2.8790e-01, time/batch = 0.0773s	
483/5250 (epoch 4.600), train_loss = 2.02222449, grad/param norm = 2.5516e-01, time/batch = 0.0772s	
484/5250 (epoch 4.610), train_loss = 1.98742552, grad/param norm = 2.0520e-01, time/batch = 0.0773s	
485/5250 (epoch 4.619), train_loss = 1.97045078, grad/param norm = 1.9172e-01, time/batch = 0.0771s	
486/5250 (epoch 4.629), train_loss = 2.02379399, grad/param norm = 2.0158e-01, time/batch = 0.0778s	
487/5250 (epoch 4.638), train_loss = 1.99984278, grad/param norm = 2.3467e-01, time/batch = 0.0774s	
488/5250 (epoch 4.648), train_loss = 2.00389454, grad/param norm = 2.6840e-01, time/batch = 0.0777s	
489/5250 (epoch 4.657), train_loss = 1.97904705, grad/param norm = 3.0162e-01, time/batch = 0.0778s	
490/5250 (epoch 4.667), train_loss = 2.02386775, grad/param norm = 3.2982e-01, time/batch = 0.0770s	
491/5250 (epoch 4.676), train_loss = 2.00453605, grad/param norm = 3.7515e-01, time/batch = 0.0791s	
492/5250 (epoch 4.686), train_loss = 2.04212174, grad/param norm = 3.1785e-01, time/batch = 0.0797s	
493/5250 (epoch 4.695), train_loss = 1.98037377, grad/param norm = 2.4971e-01, time/batch = 0.0780s	
494/5250 (epoch 4.705), train_loss = 1.96796292, grad/param norm = 2.5841e-01, time/batch = 0.0771s	
495/5250 (epoch 4.714), train_loss = 1.99537805, grad/param norm = 2.4398e-01, time/batch = 0.0772s	
496/5250 (epoch 4.724), train_loss = 1.96846374, grad/param norm = 2.4855e-01, time/batch = 0.0777s	
497/5250 (epoch 4.733), train_loss = 1.97531889, grad/param norm = 2.3216e-01, time/batch = 0.0773s	
498/5250 (epoch 4.743), train_loss = 1.95799808, grad/param norm = 1.7213e-01, time/batch = 0.0773s	
499/5250 (epoch 4.752), train_loss = 1.96916661, grad/param norm = 1.5525e-01, time/batch = 0.0782s	
500/5250 (epoch 4.762), train_loss = 1.97417119, grad/param norm = 1.8329e-01, time/batch = 0.0771s	
501/5250 (epoch 4.771), train_loss = 1.93737988, grad/param norm = 2.2090e-01, time/batch = 0.0791s	
502/5250 (epoch 4.781), train_loss = 1.98106497, grad/param norm = 2.6541e-01, time/batch = 0.0770s	
503/5250 (epoch 4.790), train_loss = 1.99800336, grad/param norm = 2.9819e-01, time/batch = 0.0772s	
504/5250 (epoch 4.800), train_loss = 1.98934088, grad/param norm = 2.7500e-01, time/batch = 0.0775s	
505/5250 (epoch 4.810), train_loss = 1.96173711, grad/param norm = 2.8200e-01, time/batch = 0.0773s	
506/5250 (epoch 4.819), train_loss = 1.98086267, grad/param norm = 2.9772e-01, time/batch = 0.0779s	
507/5250 (epoch 4.829), train_loss = 1.99250025, grad/param norm = 2.8131e-01, time/batch = 0.0772s	
508/5250 (epoch 4.838), train_loss = 1.96798916, grad/param norm = 2.2608e-01, time/batch = 0.0771s	
509/5250 (epoch 4.848), train_loss = 1.94453517, grad/param norm = 1.6859e-01, time/batch = 0.0778s	
510/5250 (epoch 4.857), train_loss = 1.95986964, grad/param norm = 1.9656e-01, time/batch = 0.0775s	
511/5250 (epoch 4.867), train_loss = 1.96358270, grad/param norm = 2.1036e-01, time/batch = 0.0789s	
512/5250 (epoch 4.876), train_loss = 1.98176955, grad/param norm = 2.0076e-01, time/batch = 0.0771s	
513/5250 (epoch 4.886), train_loss = 1.97408720, grad/param norm = 2.6065e-01, time/batch = 0.0771s	
514/5250 (epoch 4.895), train_loss = 1.99138169, grad/param norm = 3.0230e-01, time/batch = 0.0771s	
515/5250 (epoch 4.905), train_loss = 1.99455789, grad/param norm = 3.3759e-01, time/batch = 0.0770s	
516/5250 (epoch 4.914), train_loss = 1.98080041, grad/param norm = 3.1051e-01, time/batch = 0.0778s	
517/5250 (epoch 4.924), train_loss = 1.96554327, grad/param norm = 2.2650e-01, time/batch = 0.0775s	
518/5250 (epoch 4.933), train_loss = 1.96379440, grad/param norm = 2.3148e-01, time/batch = 0.0774s	
519/5250 (epoch 4.943), train_loss = 1.97584842, grad/param norm = 2.3477e-01, time/batch = 0.0779s	
520/5250 (epoch 4.952), train_loss = 1.98066915, grad/param norm = 2.8625e-01, time/batch = 0.0772s	
521/5250 (epoch 4.962), train_loss = 1.97168117, grad/param norm = 3.1053e-01, time/batch = 0.0796s	
522/5250 (epoch 4.971), train_loss = 1.96257816, grad/param norm = 2.8416e-01, time/batch = 0.0770s	
523/5250 (epoch 4.981), train_loss = 1.98543079, grad/param norm = 2.7087e-01, time/batch = 0.0768s	
524/5250 (epoch 4.990), train_loss = 1.96691426, grad/param norm = 2.5948e-01, time/batch = 0.0772s	
525/5250 (epoch 5.000), train_loss = 1.93209077, grad/param norm = 2.5246e-01, time/batch = 0.0772s	
526/5250 (epoch 5.010), train_loss = 2.03894457, grad/param norm = 2.1320e-01, time/batch = 0.0777s	
527/5250 (epoch 5.019), train_loss = 1.95746474, grad/param norm = 1.7851e-01, time/batch = 0.0779s	
528/5250 (epoch 5.029), train_loss = 1.94245812, grad/param norm = 2.1702e-01, time/batch = 0.0773s	
529/5250 (epoch 5.038), train_loss = 1.98744407, grad/param norm = 2.7671e-01, time/batch = 0.0776s	
530/5250 (epoch 5.048), train_loss = 1.95402167, grad/param norm = 3.2357e-01, time/batch = 0.0770s	
531/5250 (epoch 5.057), train_loss = 1.97699209, grad/param norm = 2.7871e-01, time/batch = 0.0790s	
532/5250 (epoch 5.067), train_loss = 1.95933273, grad/param norm = 2.1500e-01, time/batch = 0.0775s	
533/5250 (epoch 5.076), train_loss = 1.93544356, grad/param norm = 1.7276e-01, time/batch = 0.0770s	
534/5250 (epoch 5.086), train_loss = 1.89865348, grad/param norm = 1.5241e-01, time/batch = 0.0772s	
535/5250 (epoch 5.095), train_loss = 1.94600484, grad/param norm = 1.6991e-01, time/batch = 0.0773s	
536/5250 (epoch 5.105), train_loss = 1.95519228, grad/param norm = 2.1386e-01, time/batch = 0.0776s	
537/5250 (epoch 5.114), train_loss = 1.95011231, grad/param norm = 2.6221e-01, time/batch = 0.0771s	
538/5250 (epoch 5.124), train_loss = 1.96285640, grad/param norm = 2.6778e-01, time/batch = 0.0778s	
539/5250 (epoch 5.133), train_loss = 1.94306135, grad/param norm = 2.3327e-01, time/batch = 0.0778s	
540/5250 (epoch 5.143), train_loss = 1.91225671, grad/param norm = 2.0804e-01, time/batch = 0.0769s	
541/5250 (epoch 5.152), train_loss = 1.91447130, grad/param norm = 1.8273e-01, time/batch = 0.0789s	
542/5250 (epoch 5.162), train_loss = 1.92736095, grad/param norm = 1.7007e-01, time/batch = 0.0771s	
543/5250 (epoch 5.171), train_loss = 1.94807971, grad/param norm = 1.6813e-01, time/batch = 0.0774s	
544/5250 (epoch 5.181), train_loss = 1.94793909, grad/param norm = 1.9633e-01, time/batch = 0.0774s	
545/5250 (epoch 5.190), train_loss = 1.94443358, grad/param norm = 2.5467e-01, time/batch = 0.0772s	
546/5250 (epoch 5.200), train_loss = 1.93668403, grad/param norm = 2.7235e-01, time/batch = 0.0778s	
547/5250 (epoch 5.210), train_loss = 1.94605031, grad/param norm = 2.9017e-01, time/batch = 0.0773s	
548/5250 (epoch 5.219), train_loss = 1.97322230, grad/param norm = 2.7852e-01, time/batch = 0.0772s	
549/5250 (epoch 5.229), train_loss = 1.95424739, grad/param norm = 2.7333e-01, time/batch = 0.0783s	
550/5250 (epoch 5.238), train_loss = 1.91929698, grad/param norm = 2.5968e-01, time/batch = 0.0770s	
551/5250 (epoch 5.248), train_loss = 1.93420487, grad/param norm = 2.5196e-01, time/batch = 0.0788s	
552/5250 (epoch 5.257), train_loss = 1.92662464, grad/param norm = 2.2841e-01, time/batch = 0.0769s	
553/5250 (epoch 5.267), train_loss = 1.91002636, grad/param norm = 2.0849e-01, time/batch = 0.0774s	
554/5250 (epoch 5.276), train_loss = 1.93310184, grad/param norm = 2.6297e-01, time/batch = 0.0774s	
555/5250 (epoch 5.286), train_loss = 1.90640813, grad/param norm = 2.5837e-01, time/batch = 0.0774s	
556/5250 (epoch 5.295), train_loss = 1.92712772, grad/param norm = 1.9849e-01, time/batch = 0.0778s	
557/5250 (epoch 5.305), train_loss = 1.94061924, grad/param norm = 1.8859e-01, time/batch = 0.0773s	
558/5250 (epoch 5.314), train_loss = 1.89434460, grad/param norm = 1.9001e-01, time/batch = 0.0771s	
559/5250 (epoch 5.324), train_loss = 1.92108093, grad/param norm = 2.0916e-01, time/batch = 0.0778s	
560/5250 (epoch 5.333), train_loss = 1.93505934, grad/param norm = 2.4666e-01, time/batch = 0.0773s	
561/5250 (epoch 5.343), train_loss = 1.94020037, grad/param norm = 2.7476e-01, time/batch = 0.0790s	
562/5250 (epoch 5.352), train_loss = 1.92554588, grad/param norm = 3.1662e-01, time/batch = 0.0770s	
563/5250 (epoch 5.362), train_loss = 1.92186052, grad/param norm = 3.1405e-01, time/batch = 0.0770s	
564/5250 (epoch 5.371), train_loss = 1.91341042, grad/param norm = 2.7197e-01, time/batch = 0.0770s	
565/5250 (epoch 5.381), train_loss = 1.89477766, grad/param norm = 2.4235e-01, time/batch = 0.0779s	
566/5250 (epoch 5.390), train_loss = 1.93005877, grad/param norm = 1.9888e-01, time/batch = 0.0777s	
567/5250 (epoch 5.400), train_loss = 1.88226467, grad/param norm = 1.5915e-01, time/batch = 0.0772s	
568/5250 (epoch 5.410), train_loss = 1.90992927, grad/param norm = 1.9797e-01, time/batch = 0.0772s	
569/5250 (epoch 5.419), train_loss = 1.91987242, grad/param norm = 2.2263e-01, time/batch = 0.0777s	
570/5250 (epoch 5.429), train_loss = 1.91903904, grad/param norm = 2.0721e-01, time/batch = 0.0773s	
571/5250 (epoch 5.438), train_loss = 1.93729278, grad/param norm = 2.1407e-01, time/batch = 0.0805s	
572/5250 (epoch 5.448), train_loss = 1.90937877, grad/param norm = 2.2898e-01, time/batch = 0.0773s	
573/5250 (epoch 5.457), train_loss = 1.89301794, grad/param norm = 2.6467e-01, time/batch = 0.0773s	
574/5250 (epoch 5.467), train_loss = 1.88916975, grad/param norm = 2.0273e-01, time/batch = 0.0769s	
575/5250 (epoch 5.476), train_loss = 1.88534276, grad/param norm = 1.4150e-01, time/batch = 0.0772s	
576/5250 (epoch 5.486), train_loss = 1.90281455, grad/param norm = 1.3719e-01, time/batch = 0.0778s	
577/5250 (epoch 5.495), train_loss = 1.88181285, grad/param norm = 1.3165e-01, time/batch = 0.0772s	
578/5250 (epoch 5.505), train_loss = 1.89164691, grad/param norm = 1.3464e-01, time/batch = 0.0771s	
579/5250 (epoch 5.514), train_loss = 1.90118182, grad/param norm = 1.8122e-01, time/batch = 0.0779s	
580/5250 (epoch 5.524), train_loss = 1.88807018, grad/param norm = 2.2864e-01, time/batch = 0.0769s	
581/5250 (epoch 5.533), train_loss = 1.90551229, grad/param norm = 2.6058e-01, time/batch = 0.0797s	
582/5250 (epoch 5.543), train_loss = 1.89472857, grad/param norm = 2.2668e-01, time/batch = 0.0774s	
583/5250 (epoch 5.552), train_loss = 1.88207052, grad/param norm = 2.0900e-01, time/batch = 0.0772s	
584/5250 (epoch 5.562), train_loss = 1.91137679, grad/param norm = 2.1855e-01, time/batch = 0.0771s	
585/5250 (epoch 5.571), train_loss = 1.90358948, grad/param norm = 2.1771e-01, time/batch = 0.0772s	
586/5250 (epoch 5.581), train_loss = 1.90768412, grad/param norm = 2.2681e-01, time/batch = 0.0775s	
587/5250 (epoch 5.590), train_loss = 1.90372456, grad/param norm = 2.5831e-01, time/batch = 0.0773s	
588/5250 (epoch 5.600), train_loss = 1.91680788, grad/param norm = 2.8116e-01, time/batch = 0.0777s	
589/5250 (epoch 5.610), train_loss = 1.89995591, grad/param norm = 2.7054e-01, time/batch = 0.0777s	
590/5250 (epoch 5.619), train_loss = 1.88071520, grad/param norm = 2.8176e-01, time/batch = 0.0771s	
591/5250 (epoch 5.629), train_loss = 1.94062458, grad/param norm = 2.7579e-01, time/batch = 0.0798s	
592/5250 (epoch 5.638), train_loss = 1.89816694, grad/param norm = 2.7160e-01, time/batch = 0.0770s	
593/5250 (epoch 5.648), train_loss = 1.90403575, grad/param norm = 2.4390e-01, time/batch = 0.0778s	
594/5250 (epoch 5.657), train_loss = 1.86577904, grad/param norm = 1.9381e-01, time/batch = 0.0772s	
595/5250 (epoch 5.667), train_loss = 1.89075942, grad/param norm = 1.6700e-01, time/batch = 0.0773s	
596/5250 (epoch 5.676), train_loss = 1.86424708, grad/param norm = 1.5609e-01, time/batch = 0.0778s	
597/5250 (epoch 5.686), train_loss = 1.89843134, grad/param norm = 1.5904e-01, time/batch = 0.0773s	
598/5250 (epoch 5.695), train_loss = 1.87268182, grad/param norm = 2.4258e-01, time/batch = 0.0774s	
599/5250 (epoch 5.705), train_loss = 1.87609499, grad/param norm = 2.1025e-01, time/batch = 0.0780s	
600/5250 (epoch 5.714), train_loss = 1.89633791, grad/param norm = 1.7129e-01, time/batch = 0.0771s	
601/5250 (epoch 5.724), train_loss = 1.85728004, grad/param norm = 1.5359e-01, time/batch = 0.0790s	
602/5250 (epoch 5.733), train_loss = 1.86872678, grad/param norm = 1.5152e-01, time/batch = 0.0769s	
603/5250 (epoch 5.743), train_loss = 1.86023875, grad/param norm = 1.8722e-01, time/batch = 0.0812s	
604/5250 (epoch 5.752), train_loss = 1.88228941, grad/param norm = 2.0965e-01, time/batch = 0.0777s	
605/5250 (epoch 5.762), train_loss = 1.87567606, grad/param norm = 2.3522e-01, time/batch = 0.0774s	
606/5250 (epoch 5.771), train_loss = 1.84457198, grad/param norm = 2.3669e-01, time/batch = 0.0777s	
607/5250 (epoch 5.781), train_loss = 1.87334086, grad/param norm = 2.2581e-01, time/batch = 0.0773s	
608/5250 (epoch 5.790), train_loss = 1.89455092, grad/param norm = 2.6240e-01, time/batch = 0.0771s	
609/5250 (epoch 5.800), train_loss = 1.89290192, grad/param norm = 2.4580e-01, time/batch = 0.0779s	
610/5250 (epoch 5.810), train_loss = 1.86008589, grad/param norm = 1.8564e-01, time/batch = 0.0778s	
611/5250 (epoch 5.819), train_loss = 1.86827553, grad/param norm = 2.0063e-01, time/batch = 0.0792s	
612/5250 (epoch 5.829), train_loss = 1.88164678, grad/param norm = 2.0662e-01, time/batch = 0.0771s	
613/5250 (epoch 5.838), train_loss = 1.86158287, grad/param norm = 1.8306e-01, time/batch = 0.0770s	
614/5250 (epoch 5.848), train_loss = 1.85181855, grad/param norm = 1.8222e-01, time/batch = 0.0772s	
615/5250 (epoch 5.857), train_loss = 1.86596288, grad/param norm = 1.8434e-01, time/batch = 0.0774s	
616/5250 (epoch 5.867), train_loss = 1.85837656, grad/param norm = 2.2135e-01, time/batch = 0.0777s	
617/5250 (epoch 5.876), train_loss = 1.89329877, grad/param norm = 2.0155e-01, time/batch = 0.0773s	
618/5250 (epoch 5.886), train_loss = 1.86360612, grad/param norm = 1.5420e-01, time/batch = 0.0772s	
619/5250 (epoch 5.895), train_loss = 1.87494640, grad/param norm = 1.7263e-01, time/batch = 0.0778s	
620/5250 (epoch 5.905), train_loss = 1.87485358, grad/param norm = 2.1651e-01, time/batch = 0.0771s	
621/5250 (epoch 5.914), train_loss = 1.86708420, grad/param norm = 2.5018e-01, time/batch = 0.0790s	
622/5250 (epoch 5.924), train_loss = 1.87700268, grad/param norm = 2.2945e-01, time/batch = 0.0769s	
623/5250 (epoch 5.933), train_loss = 1.87143390, grad/param norm = 2.1269e-01, time/batch = 0.0770s	
624/5250 (epoch 5.943), train_loss = 1.88596372, grad/param norm = 1.9609e-01, time/batch = 0.0769s	
625/5250 (epoch 5.952), train_loss = 1.87474194, grad/param norm = 1.7099e-01, time/batch = 0.0768s	
626/5250 (epoch 5.962), train_loss = 1.85458975, grad/param norm = 1.7373e-01, time/batch = 0.0781s	
627/5250 (epoch 5.971), train_loss = 1.84823508, grad/param norm = 1.9347e-01, time/batch = 0.0772s	
628/5250 (epoch 5.981), train_loss = 1.89238148, grad/param norm = 2.5392e-01, time/batch = 0.0771s	
629/5250 (epoch 5.990), train_loss = 1.88835002, grad/param norm = 2.7105e-01, time/batch = 0.0778s	
630/5250 (epoch 6.000), train_loss = 1.84946910, grad/param norm = 2.4789e-01, time/batch = 0.0771s	
631/5250 (epoch 6.010), train_loss = 1.96860824, grad/param norm = 2.4652e-01, time/batch = 0.0792s	
632/5250 (epoch 6.019), train_loss = 1.87858788, grad/param norm = 2.6265e-01, time/batch = 0.0778s	
633/5250 (epoch 6.029), train_loss = 1.86468759, grad/param norm = 2.9461e-01, time/batch = 0.0773s	
634/5250 (epoch 6.038), train_loss = 1.90499053, grad/param norm = 3.0912e-01, time/batch = 0.0771s	
635/5250 (epoch 6.048), train_loss = 1.85701758, grad/param norm = 2.7423e-01, time/batch = 0.0774s	
636/5250 (epoch 6.057), train_loss = 1.86546927, grad/param norm = 2.1611e-01, time/batch = 0.0776s	
637/5250 (epoch 6.067), train_loss = 1.85093851, grad/param norm = 1.6764e-01, time/batch = 0.0773s	
638/5250 (epoch 6.076), train_loss = 1.83421017, grad/param norm = 1.4411e-01, time/batch = 0.0773s	
639/5250 (epoch 6.086), train_loss = 1.79163060, grad/param norm = 1.3012e-01, time/batch = 0.0779s	
640/5250 (epoch 6.095), train_loss = 1.84023827, grad/param norm = 1.2427e-01, time/batch = 0.0772s	
641/5250 (epoch 6.105), train_loss = 1.85187706, grad/param norm = 1.4773e-01, time/batch = 0.0790s	
642/5250 (epoch 6.114), train_loss = 1.83626945, grad/param norm = 1.6571e-01, time/batch = 0.0771s	
643/5250 (epoch 6.124), train_loss = 1.84981099, grad/param norm = 1.8994e-01, time/batch = 0.0776s	
644/5250 (epoch 6.133), train_loss = 1.84551941, grad/param norm = 2.0158e-01, time/batch = 0.0771s	
645/5250 (epoch 6.143), train_loss = 1.82238877, grad/param norm = 2.0867e-01, time/batch = 0.0771s	
646/5250 (epoch 6.152), train_loss = 1.82695907, grad/param norm = 2.0327e-01, time/batch = 0.0773s	
647/5250 (epoch 6.162), train_loss = 1.84587067, grad/param norm = 2.0835e-01, time/batch = 0.0772s	
648/5250 (epoch 6.171), train_loss = 1.86863371, grad/param norm = 2.2673e-01, time/batch = 0.0771s	
649/5250 (epoch 6.181), train_loss = 1.86607794, grad/param norm = 2.2589e-01, time/batch = 0.0784s	
650/5250 (epoch 6.190), train_loss = 1.85052509, grad/param norm = 1.9780e-01, time/batch = 0.0771s	
651/5250 (epoch 6.200), train_loss = 1.83705159, grad/param norm = 1.6726e-01, time/batch = 0.0790s	
652/5250 (epoch 6.210), train_loss = 1.83963837, grad/param norm = 1.5516e-01, time/batch = 0.0770s	
653/5250 (epoch 6.219), train_loss = 1.86602117, grad/param norm = 1.5258e-01, time/batch = 0.0776s	
654/5250 (epoch 6.229), train_loss = 1.85169547, grad/param norm = 1.7497e-01, time/batch = 0.0782s	
655/5250 (epoch 6.238), train_loss = 1.82581391, grad/param norm = 2.4398e-01, time/batch = 0.0774s	
656/5250 (epoch 6.248), train_loss = 1.85491938, grad/param norm = 2.6418e-01, time/batch = 0.0778s	
657/5250 (epoch 6.257), train_loss = 1.83075504, grad/param norm = 2.6070e-01, time/batch = 0.0771s	
658/5250 (epoch 6.267), train_loss = 1.82108900, grad/param norm = 2.3868e-01, time/batch = 0.0772s	
659/5250 (epoch 6.276), train_loss = 1.83395036, grad/param norm = 1.9203e-01, time/batch = 0.0778s	
660/5250 (epoch 6.286), train_loss = 1.78516465, grad/param norm = 1.5066e-01, time/batch = 0.0776s	
661/5250 (epoch 6.295), train_loss = 1.82279359, grad/param norm = 1.5610e-01, time/batch = 0.0790s	
662/5250 (epoch 6.305), train_loss = 1.84788190, grad/param norm = 1.7351e-01, time/batch = 0.0769s	
663/5250 (epoch 6.314), train_loss = 1.80684822, grad/param norm = 2.3931e-01, time/batch = 0.0771s	
664/5250 (epoch 6.324), train_loss = 1.84392006, grad/param norm = 2.0472e-01, time/batch = 0.0770s	
665/5250 (epoch 6.333), train_loss = 1.84466841, grad/param norm = 2.1399e-01, time/batch = 0.0776s	
666/5250 (epoch 6.343), train_loss = 1.84549391, grad/param norm = 2.0323e-01, time/batch = 0.0778s	
667/5250 (epoch 6.352), train_loss = 1.82722569, grad/param norm = 2.1008e-01, time/batch = 0.0773s	
668/5250 (epoch 6.362), train_loss = 1.81885249, grad/param norm = 1.9920e-01, time/batch = 0.0772s	
669/5250 (epoch 6.371), train_loss = 1.81219770, grad/param norm = 2.0415e-01, time/batch = 0.0777s	
670/5250 (epoch 6.381), train_loss = 1.81328915, grad/param norm = 2.1021e-01, time/batch = 0.0769s	
671/5250 (epoch 6.390), train_loss = 1.84657088, grad/param norm = 2.0256e-01, time/batch = 0.0789s	
672/5250 (epoch 6.400), train_loss = 1.80320543, grad/param norm = 1.8808e-01, time/batch = 0.0770s	
673/5250 (epoch 6.410), train_loss = 1.83030836, grad/param norm = 1.8570e-01, time/batch = 0.0771s	
674/5250 (epoch 6.419), train_loss = 1.82217230, grad/param norm = 1.6280e-01, time/batch = 0.0770s	
675/5250 (epoch 6.429), train_loss = 1.81969494, grad/param norm = 1.2792e-01, time/batch = 0.0773s	
676/5250 (epoch 6.438), train_loss = 1.83263523, grad/param norm = 1.2038e-01, time/batch = 0.0783s	
677/5250 (epoch 6.448), train_loss = 1.80420479, grad/param norm = 1.2637e-01, time/batch = 0.0774s	
678/5250 (epoch 6.457), train_loss = 1.79218301, grad/param norm = 1.8966e-01, time/batch = 0.0772s	
679/5250 (epoch 6.467), train_loss = 1.80622502, grad/param norm = 2.3338e-01, time/batch = 0.0778s	
680/5250 (epoch 6.476), train_loss = 1.81582096, grad/param norm = 2.2913e-01, time/batch = 0.0770s	
681/5250 (epoch 6.486), train_loss = 1.82790396, grad/param norm = 2.0827e-01, time/batch = 0.0789s	
682/5250 (epoch 6.495), train_loss = 1.80839417, grad/param norm = 2.0150e-01, time/batch = 0.0770s	
683/5250 (epoch 6.505), train_loss = 1.82373627, grad/param norm = 2.1119e-01, time/batch = 0.0769s	
684/5250 (epoch 6.514), train_loss = 1.82952785, grad/param norm = 2.2348e-01, time/batch = 0.0771s	
685/5250 (epoch 6.524), train_loss = 1.79855051, grad/param norm = 2.1275e-01, time/batch = 0.0770s	
686/5250 (epoch 6.533), train_loss = 1.81071172, grad/param norm = 1.9647e-01, time/batch = 0.0778s	
687/5250 (epoch 6.543), train_loss = 1.79611653, grad/param norm = 1.6702e-01, time/batch = 0.0779s	
688/5250 (epoch 6.552), train_loss = 1.79247623, grad/param norm = 1.5780e-01, time/batch = 0.0772s	
689/5250 (epoch 6.562), train_loss = 1.80926074, grad/param norm = 1.5660e-01, time/batch = 0.0777s	
690/5250 (epoch 6.571), train_loss = 1.80606258, grad/param norm = 1.4726e-01, time/batch = 0.0771s	
691/5250 (epoch 6.581), train_loss = 1.81114503, grad/param norm = 1.3554e-01, time/batch = 0.0790s	
692/5250 (epoch 6.590), train_loss = 1.79776374, grad/param norm = 1.4967e-01, time/batch = 0.0771s	
693/5250 (epoch 6.600), train_loss = 1.81482480, grad/param norm = 1.6318e-01, time/batch = 0.0776s	
694/5250 (epoch 6.610), train_loss = 1.80471947, grad/param norm = 1.6684e-01, time/batch = 0.0770s	
695/5250 (epoch 6.619), train_loss = 1.78356227, grad/param norm = 1.7643e-01, time/batch = 0.0771s	
696/5250 (epoch 6.629), train_loss = 1.83987210, grad/param norm = 1.7174e-01, time/batch = 0.0779s	
697/5250 (epoch 6.638), train_loss = 1.79480764, grad/param norm = 1.6624e-01, time/batch = 0.0773s	
698/5250 (epoch 6.648), train_loss = 1.80834119, grad/param norm = 1.8550e-01, time/batch = 0.0778s	
699/5250 (epoch 6.657), train_loss = 1.79874838, grad/param norm = 2.7624e-01, time/batch = 0.0779s	
700/5250 (epoch 6.667), train_loss = 1.85269211, grad/param norm = 3.1306e-01, time/batch = 0.0772s	
701/5250 (epoch 6.676), train_loss = 1.80831053, grad/param norm = 2.4259e-01, time/batch = 0.0789s	
702/5250 (epoch 6.686), train_loss = 1.83680781, grad/param norm = 2.0956e-01, time/batch = 0.0769s	
703/5250 (epoch 6.695), train_loss = 1.80006786, grad/param norm = 1.9518e-01, time/batch = 0.0772s	
704/5250 (epoch 6.705), train_loss = 1.78307706, grad/param norm = 1.9741e-01, time/batch = 0.0779s	
705/5250 (epoch 6.714), train_loss = 1.80407505, grad/param norm = 1.4937e-01, time/batch = 0.0773s	
706/5250 (epoch 6.724), train_loss = 1.76920411, grad/param norm = 1.3519e-01, time/batch = 0.0776s	
707/5250 (epoch 6.733), train_loss = 1.77656502, grad/param norm = 1.4422e-01, time/batch = 0.0772s	
708/5250 (epoch 6.743), train_loss = 1.77085131, grad/param norm = 1.3605e-01, time/batch = 0.0772s	
709/5250 (epoch 6.752), train_loss = 1.78855374, grad/param norm = 1.3797e-01, time/batch = 0.0777s	
710/5250 (epoch 6.762), train_loss = 1.78574184, grad/param norm = 1.8683e-01, time/batch = 0.0776s	
711/5250 (epoch 6.771), train_loss = 1.76350590, grad/param norm = 1.8943e-01, time/batch = 0.0790s	
712/5250 (epoch 6.781), train_loss = 1.78324294, grad/param norm = 1.5780e-01, time/batch = 0.0770s	
713/5250 (epoch 6.790), train_loss = 1.80790743, grad/param norm = 1.7039e-01, time/batch = 0.0770s	
714/5250 (epoch 6.800), train_loss = 1.79681451, grad/param norm = 1.6473e-01, time/batch = 0.0816s	
715/5250 (epoch 6.810), train_loss = 1.77862830, grad/param norm = 1.5160e-01, time/batch = 0.0778s	
716/5250 (epoch 6.819), train_loss = 1.78315185, grad/param norm = 1.5985e-01, time/batch = 0.0778s	
717/5250 (epoch 6.829), train_loss = 1.79604573, grad/param norm = 1.8547e-01, time/batch = 0.0772s	
718/5250 (epoch 6.838), train_loss = 1.78469669, grad/param norm = 2.2665e-01, time/batch = 0.0771s	
719/5250 (epoch 6.848), train_loss = 1.78073571, grad/param norm = 2.4075e-01, time/batch = 0.0778s	
720/5250 (epoch 6.857), train_loss = 1.80207374, grad/param norm = 2.4469e-01, time/batch = 0.0774s	
721/5250 (epoch 6.867), train_loss = 1.78433538, grad/param norm = 2.3354e-01, time/batch = 0.0793s	
722/5250 (epoch 6.876), train_loss = 1.80752838, grad/param norm = 1.7956e-01, time/batch = 0.0770s	
723/5250 (epoch 6.886), train_loss = 1.78022849, grad/param norm = 1.5847e-01, time/batch = 0.0769s	
724/5250 (epoch 6.895), train_loss = 1.80017589, grad/param norm = 1.5750e-01, time/batch = 0.0770s	
725/5250 (epoch 6.905), train_loss = 1.78509292, grad/param norm = 1.4922e-01, time/batch = 0.0775s	
726/5250 (epoch 6.914), train_loss = 1.78413571, grad/param norm = 1.5204e-01, time/batch = 0.0783s	
727/5250 (epoch 6.924), train_loss = 1.78894049, grad/param norm = 1.5971e-01, time/batch = 0.0774s	
728/5250 (epoch 6.933), train_loss = 1.79616437, grad/param norm = 2.0611e-01, time/batch = 0.0772s	
729/5250 (epoch 6.943), train_loss = 1.81751871, grad/param norm = 1.8925e-01, time/batch = 0.0777s	
730/5250 (epoch 6.952), train_loss = 1.80520836, grad/param norm = 1.4623e-01, time/batch = 0.0769s	
731/5250 (epoch 6.962), train_loss = 1.77522064, grad/param norm = 1.2250e-01, time/batch = 0.0795s	
732/5250 (epoch 6.971), train_loss = 1.75737003, grad/param norm = 1.1325e-01, time/batch = 0.0771s	
733/5250 (epoch 6.981), train_loss = 1.79216677, grad/param norm = 1.1569e-01, time/batch = 0.0773s	
734/5250 (epoch 6.990), train_loss = 1.78462423, grad/param norm = 1.2365e-01, time/batch = 0.0771s	
735/5250 (epoch 7.000), train_loss = 1.76297303, grad/param norm = 1.5471e-01, time/batch = 0.0774s	
736/5250 (epoch 7.010), train_loss = 1.90082517, grad/param norm = 1.8349e-01, time/batch = 0.0779s	
737/5250 (epoch 7.019), train_loss = 1.79568310, grad/param norm = 1.9044e-01, time/batch = 0.0777s	
738/5250 (epoch 7.029), train_loss = 1.77468822, grad/param norm = 1.6617e-01, time/batch = 0.0772s	
739/5250 (epoch 7.038), train_loss = 1.78426096, grad/param norm = 1.4740e-01, time/batch = 0.0774s	
740/5250 (epoch 7.048), train_loss = 1.76245993, grad/param norm = 1.6924e-01, time/batch = 0.0770s	
741/5250 (epoch 7.057), train_loss = 1.77957454, grad/param norm = 1.8737e-01, time/batch = 0.0789s	
742/5250 (epoch 7.067), train_loss = 1.78550053, grad/param norm = 2.2266e-01, time/batch = 0.0772s	
743/5250 (epoch 7.076), train_loss = 1.77798377, grad/param norm = 2.2249e-01, time/batch = 0.0773s	
744/5250 (epoch 7.086), train_loss = 1.72273346, grad/param norm = 2.0236e-01, time/batch = 0.0771s	
745/5250 (epoch 7.095), train_loss = 1.77692978, grad/param norm = 2.0079e-01, time/batch = 0.0773s	
746/5250 (epoch 7.105), train_loss = 1.78922259, grad/param norm = 2.2226e-01, time/batch = 0.0776s	
747/5250 (epoch 7.114), train_loss = 1.76505754, grad/param norm = 1.9194e-01, time/batch = 0.0772s	
748/5250 (epoch 7.124), train_loss = 1.76881378, grad/param norm = 1.7272e-01, time/batch = 0.0774s	
749/5250 (epoch 7.133), train_loss = 1.75668924, grad/param norm = 1.5137e-01, time/batch = 0.0779s	
750/5250 (epoch 7.143), train_loss = 1.73008991, grad/param norm = 1.4234e-01, time/batch = 0.0771s	
751/5250 (epoch 7.152), train_loss = 1.73443037, grad/param norm = 1.4911e-01, time/batch = 0.0790s	
752/5250 (epoch 7.162), train_loss = 1.75936635, grad/param norm = 1.5170e-01, time/batch = 0.0769s	
753/5250 (epoch 7.171), train_loss = 1.78124299, grad/param norm = 1.6024e-01, time/batch = 0.0772s	
754/5250 (epoch 7.181), train_loss = 1.77333267, grad/param norm = 1.6485e-01, time/batch = 0.0775s	
755/5250 (epoch 7.190), train_loss = 1.77220320, grad/param norm = 2.2145e-01, time/batch = 0.0769s	
756/5250 (epoch 7.200), train_loss = 1.78014700, grad/param norm = 2.0797e-01, time/batch = 0.0777s	
757/5250 (epoch 7.210), train_loss = 1.77384235, grad/param norm = 1.7929e-01, time/batch = 0.0773s	
758/5250 (epoch 7.219), train_loss = 1.80112917, grad/param norm = 1.7133e-01, time/batch = 0.0770s	
759/5250 (epoch 7.229), train_loss = 1.77990204, grad/param norm = 1.8913e-01, time/batch = 0.0783s	
760/5250 (epoch 7.238), train_loss = 1.75687994, grad/param norm = 2.0500e-01, time/batch = 0.0774s	
761/5250 (epoch 7.248), train_loss = 1.76803874, grad/param norm = 1.8717e-01, time/batch = 0.0792s	
762/5250 (epoch 7.257), train_loss = 1.74863243, grad/param norm = 1.7424e-01, time/batch = 0.0770s	
763/5250 (epoch 7.267), train_loss = 1.73890387, grad/param norm = 1.7209e-01, time/batch = 0.0771s	
764/5250 (epoch 7.276), train_loss = 1.75841336, grad/param norm = 1.7306e-01, time/batch = 0.0772s	
765/5250 (epoch 7.286), train_loss = 1.71512048, grad/param norm = 1.5896e-01, time/batch = 0.0777s	
766/5250 (epoch 7.295), train_loss = 1.74661675, grad/param norm = 1.2053e-01, time/batch = 0.0775s	
767/5250 (epoch 7.305), train_loss = 1.76027180, grad/param norm = 1.0466e-01, time/batch = 0.0771s	
768/5250 (epoch 7.314), train_loss = 1.71074197, grad/param norm = 9.2981e-02, time/batch = 0.0771s	
769/5250 (epoch 7.324), train_loss = 1.74721324, grad/param norm = 1.1472e-01, time/batch = 0.0778s	
770/5250 (epoch 7.333), train_loss = 1.75800444, grad/param norm = 1.5095e-01, time/batch = 0.0770s	
771/5250 (epoch 7.343), train_loss = 1.76646501, grad/param norm = 1.7788e-01, time/batch = 0.0800s	
772/5250 (epoch 7.352), train_loss = 1.76518413, grad/param norm = 2.3301e-01, time/batch = 0.0772s	
773/5250 (epoch 7.362), train_loss = 1.76650421, grad/param norm = 2.4731e-01, time/batch = 0.0770s	
774/5250 (epoch 7.371), train_loss = 1.74710181, grad/param norm = 2.2968e-01, time/batch = 0.0772s	
775/5250 (epoch 7.381), train_loss = 1.74939636, grad/param norm = 2.0411e-01, time/batch = 0.0772s	
776/5250 (epoch 7.390), train_loss = 1.76652936, grad/param norm = 1.6797e-01, time/batch = 0.0786s	
777/5250 (epoch 7.400), train_loss = 1.72444555, grad/param norm = 1.3341e-01, time/batch = 0.0774s	
778/5250 (epoch 7.410), train_loss = 1.75094684, grad/param norm = 1.2473e-01, time/batch = 0.0773s	
779/5250 (epoch 7.419), train_loss = 1.74237484, grad/param norm = 1.2354e-01, time/batch = 0.0775s	
780/5250 (epoch 7.429), train_loss = 1.74605502, grad/param norm = 1.2180e-01, time/batch = 0.0770s	
781/5250 (epoch 7.438), train_loss = 1.76398001, grad/param norm = 1.2421e-01, time/batch = 0.0792s	
782/5250 (epoch 7.448), train_loss = 1.73219799, grad/param norm = 1.2352e-01, time/batch = 0.0771s	
783/5250 (epoch 7.457), train_loss = 1.71899797, grad/param norm = 1.4005e-01, time/batch = 0.0772s	
784/5250 (epoch 7.467), train_loss = 1.72370544, grad/param norm = 1.6267e-01, time/batch = 0.0770s	
785/5250 (epoch 7.476), train_loss = 1.73889174, grad/param norm = 1.9361e-01, time/batch = 0.0771s	
786/5250 (epoch 7.486), train_loss = 1.76142371, grad/param norm = 2.1317e-01, time/batch = 0.0778s	
787/5250 (epoch 7.495), train_loss = 1.74849559, grad/param norm = 2.1348e-01, time/batch = 0.0778s	
788/5250 (epoch 7.505), train_loss = 1.76230438, grad/param norm = 1.9652e-01, time/batch = 0.0773s	
789/5250 (epoch 7.514), train_loss = 1.75593733, grad/param norm = 1.6985e-01, time/batch = 0.0778s	
790/5250 (epoch 7.524), train_loss = 1.72190885, grad/param norm = 1.8618e-01, time/batch = 0.0771s	
791/5250 (epoch 7.533), train_loss = 1.74362818, grad/param norm = 1.9426e-01, time/batch = 0.0789s	
792/5250 (epoch 7.543), train_loss = 1.72757084, grad/param norm = 1.8437e-01, time/batch = 0.0775s	
793/5250 (epoch 7.552), train_loss = 1.73207082, grad/param norm = 1.6432e-01, time/batch = 0.0774s	
794/5250 (epoch 7.562), train_loss = 1.74005668, grad/param norm = 1.4782e-01, time/batch = 0.0770s	
795/5250 (epoch 7.571), train_loss = 1.73511898, grad/param norm = 1.4773e-01, time/batch = 0.0774s	
796/5250 (epoch 7.581), train_loss = 1.74777695, grad/param norm = 1.2612e-01, time/batch = 0.0779s	
797/5250 (epoch 7.590), train_loss = 1.72881474, grad/param norm = 1.2111e-01, time/batch = 0.0775s	
798/5250 (epoch 7.600), train_loss = 1.74145222, grad/param norm = 1.2484e-01, time/batch = 0.0780s	
799/5250 (epoch 7.610), train_loss = 1.73692446, grad/param norm = 1.3077e-01, time/batch = 0.0777s	
800/5250 (epoch 7.619), train_loss = 1.71769380, grad/param norm = 1.5113e-01, time/batch = 0.0769s	
801/5250 (epoch 7.629), train_loss = 1.76977719, grad/param norm = 1.5320e-01, time/batch = 0.0797s	
802/5250 (epoch 7.638), train_loss = 1.72529835, grad/param norm = 1.4012e-01, time/batch = 0.0770s	
803/5250 (epoch 7.648), train_loss = 1.73559736, grad/param norm = 1.3964e-01, time/batch = 0.0776s	
804/5250 (epoch 7.657), train_loss = 1.71242077, grad/param norm = 1.6983e-01, time/batch = 0.0770s	
805/5250 (epoch 7.667), train_loss = 1.74856620, grad/param norm = 1.9351e-01, time/batch = 0.0771s	
806/5250 (epoch 7.676), train_loss = 1.73616295, grad/param norm = 1.9340e-01, time/batch = 0.0776s	
807/5250 (epoch 7.686), train_loss = 1.76839272, grad/param norm = 1.9218e-01, time/batch = 0.0770s	
808/5250 (epoch 7.695), train_loss = 1.73714149, grad/param norm = 1.7134e-01, time/batch = 0.0772s	
809/5250 (epoch 7.705), train_loss = 1.71192585, grad/param norm = 1.3713e-01, time/batch = 0.0783s	
810/5250 (epoch 7.714), train_loss = 1.73223389, grad/param norm = 1.0400e-01, time/batch = 0.0773s	
811/5250 (epoch 7.724), train_loss = 1.70153951, grad/param norm = 1.0266e-01, time/batch = 0.0788s	
812/5250 (epoch 7.733), train_loss = 1.70383423, grad/param norm = 1.0952e-01, time/batch = 0.0770s	
813/5250 (epoch 7.743), train_loss = 1.70535145, grad/param norm = 1.1651e-01, time/batch = 0.0770s	
814/5250 (epoch 7.752), train_loss = 1.72587466, grad/param norm = 1.4479e-01, time/batch = 0.0771s	
815/5250 (epoch 7.762), train_loss = 1.72070447, grad/param norm = 1.3243e-01, time/batch = 0.0777s	
816/5250 (epoch 7.771), train_loss = 1.69424745, grad/param norm = 1.4123e-01, time/batch = 0.0779s	
817/5250 (epoch 7.781), train_loss = 1.71752635, grad/param norm = 1.3834e-01, time/batch = 0.0772s	
818/5250 (epoch 7.790), train_loss = 1.74002710, grad/param norm = 1.2825e-01, time/batch = 0.0771s	
819/5250 (epoch 7.800), train_loss = 1.72989810, grad/param norm = 1.4663e-01, time/batch = 0.0774s	
820/5250 (epoch 7.810), train_loss = 1.72135359, grad/param norm = 1.7377e-01, time/batch = 0.0776s	
821/5250 (epoch 7.819), train_loss = 1.73235190, grad/param norm = 2.2056e-01, time/batch = 0.0789s	
822/5250 (epoch 7.829), train_loss = 1.75381538, grad/param norm = 2.5062e-01, time/batch = 0.0770s	
823/5250 (epoch 7.838), train_loss = 1.72846031, grad/param norm = 2.2568e-01, time/batch = 0.0771s	
824/5250 (epoch 7.848), train_loss = 1.71556806, grad/param norm = 2.0587e-01, time/batch = 0.0772s	
825/5250 (epoch 7.857), train_loss = 1.72149219, grad/param norm = 1.7642e-01, time/batch = 0.0823s	
826/5250 (epoch 7.867), train_loss = 1.70622874, grad/param norm = 1.6232e-01, time/batch = 0.0782s	
827/5250 (epoch 7.876), train_loss = 1.73690490, grad/param norm = 1.5591e-01, time/batch = 0.0773s	
828/5250 (epoch 7.886), train_loss = 1.70601414, grad/param norm = 1.1836e-01, time/batch = 0.0772s	
829/5250 (epoch 7.895), train_loss = 1.72671255, grad/param norm = 1.0731e-01, time/batch = 0.0779s	
830/5250 (epoch 7.905), train_loss = 1.71615967, grad/param norm = 1.2645e-01, time/batch = 0.0775s	
831/5250 (epoch 7.914), train_loss = 1.73131334, grad/param norm = 1.6816e-01, time/batch = 0.0798s	
832/5250 (epoch 7.924), train_loss = 1.73568312, grad/param norm = 1.6866e-01, time/batch = 0.0771s	
833/5250 (epoch 7.933), train_loss = 1.75043110, grad/param norm = 3.1104e-01, time/batch = 0.0770s	
834/5250 (epoch 7.943), train_loss = 1.76842534, grad/param norm = 1.5552e-01, time/batch = 0.0771s	
835/5250 (epoch 7.952), train_loss = 1.75808707, grad/param norm = 1.6226e-01, time/batch = 0.0772s	
836/5250 (epoch 7.962), train_loss = 1.72942139, grad/param norm = 1.8354e-01, time/batch = 0.0776s	
837/5250 (epoch 7.971), train_loss = 1.71653566, grad/param norm = 1.6289e-01, time/batch = 0.0777s	
838/5250 (epoch 7.981), train_loss = 1.74810393, grad/param norm = 1.7770e-01, time/batch = 0.0772s	
839/5250 (epoch 7.990), train_loss = 1.74286358, grad/param norm = 1.6612e-01, time/batch = 0.0778s	
840/5250 (epoch 8.000), train_loss = 1.70484100, grad/param norm = 1.3600e-01, time/batch = 0.0769s	
841/5250 (epoch 8.010), train_loss = 1.83594839, grad/param norm = 1.2217e-01, time/batch = 0.0788s	
842/5250 (epoch 8.019), train_loss = 1.71711031, grad/param norm = 1.2532e-01, time/batch = 0.0774s	
843/5250 (epoch 8.029), train_loss = 1.70393248, grad/param norm = 1.2334e-01, time/batch = 0.0772s	
844/5250 (epoch 8.038), train_loss = 1.71290377, grad/param norm = 1.3205e-01, time/batch = 0.0773s	
845/5250 (epoch 8.048), train_loss = 1.69900257, grad/param norm = 1.6124e-01, time/batch = 0.0767s	
846/5250 (epoch 8.057), train_loss = 1.71365110, grad/param norm = 1.6370e-01, time/batch = 0.0778s	
847/5250 (epoch 8.067), train_loss = 1.71165980, grad/param norm = 1.5327e-01, time/batch = 0.0772s	
848/5250 (epoch 8.076), train_loss = 1.69134349, grad/param norm = 1.2000e-01, time/batch = 0.0777s	
849/5250 (epoch 8.086), train_loss = 1.64206234, grad/param norm = 1.1820e-01, time/batch = 0.0778s	
850/5250 (epoch 8.095), train_loss = 1.70531308, grad/param norm = 1.3970e-01, time/batch = 0.0771s	
851/5250 (epoch 8.105), train_loss = 1.71729676, grad/param norm = 1.5693e-01, time/batch = 0.0790s	
852/5250 (epoch 8.114), train_loss = 1.69647806, grad/param norm = 1.5956e-01, time/batch = 0.0771s	
853/5250 (epoch 8.124), train_loss = 1.71110136, grad/param norm = 1.6546e-01, time/batch = 0.0778s	
854/5250 (epoch 8.133), train_loss = 1.70342693, grad/param norm = 1.6614e-01, time/batch = 0.0772s	
855/5250 (epoch 8.143), train_loss = 1.68083009, grad/param norm = 1.5806e-01, time/batch = 0.0773s	
856/5250 (epoch 8.152), train_loss = 1.68465593, grad/param norm = 1.5439e-01, time/batch = 0.0777s	
857/5250 (epoch 8.162), train_loss = 1.70714216, grad/param norm = 1.4628e-01, time/batch = 0.0772s	
858/5250 (epoch 8.171), train_loss = 1.71982917, grad/param norm = 1.4826e-01, time/batch = 0.0771s	
859/5250 (epoch 8.181), train_loss = 1.71255806, grad/param norm = 1.6088e-01, time/batch = 0.0777s	
860/5250 (epoch 8.190), train_loss = 1.70298812, grad/param norm = 1.6067e-01, time/batch = 0.0771s	
861/5250 (epoch 8.200), train_loss = 1.69785101, grad/param norm = 1.4926e-01, time/batch = 0.0789s	
862/5250 (epoch 8.210), train_loss = 1.69518339, grad/param norm = 1.3850e-01, time/batch = 0.0769s	
863/5250 (epoch 8.219), train_loss = 1.73498032, grad/param norm = 1.4276e-01, time/batch = 0.0771s	
864/5250 (epoch 8.229), train_loss = 1.71134835, grad/param norm = 1.5151e-01, time/batch = 0.0776s	
865/5250 (epoch 8.238), train_loss = 1.69416079, grad/param norm = 1.8070e-01, time/batch = 0.0773s	
866/5250 (epoch 8.248), train_loss = 1.71285589, grad/param norm = 1.8363e-01, time/batch = 0.0777s	
867/5250 (epoch 8.257), train_loss = 1.68482955, grad/param norm = 1.7391e-01, time/batch = 0.0772s	
868/5250 (epoch 8.267), train_loss = 1.68019661, grad/param norm = 1.6622e-01, time/batch = 0.0771s	
869/5250 (epoch 8.276), train_loss = 1.69202566, grad/param norm = 1.5647e-01, time/batch = 0.0778s	
870/5250 (epoch 8.286), train_loss = 1.64993006, grad/param norm = 1.3515e-01, time/batch = 0.0775s	
871/5250 (epoch 8.295), train_loss = 1.68628100, grad/param norm = 1.2418e-01, time/batch = 0.0790s	
872/5250 (epoch 8.305), train_loss = 1.70404978, grad/param norm = 1.3128e-01, time/batch = 0.0770s	
873/5250 (epoch 8.314), train_loss = 1.66427062, grad/param norm = 1.5435e-01, time/batch = 0.0770s	
874/5250 (epoch 8.324), train_loss = 1.70528990, grad/param norm = 1.6744e-01, time/batch = 0.0771s	
875/5250 (epoch 8.333), train_loss = 1.70366510, grad/param norm = 1.4910e-01, time/batch = 0.0770s	
876/5250 (epoch 8.343), train_loss = 1.69998360, grad/param norm = 1.3214e-01, time/batch = 0.0778s	
877/5250 (epoch 8.352), train_loss = 1.69614965, grad/param norm = 1.3642e-01, time/batch = 0.0773s	
878/5250 (epoch 8.362), train_loss = 1.68798356, grad/param norm = 1.2881e-01, time/batch = 0.0772s	
879/5250 (epoch 8.371), train_loss = 1.67144395, grad/param norm = 1.3051e-01, time/batch = 0.0778s	
880/5250 (epoch 8.381), train_loss = 1.68409973, grad/param norm = 1.4567e-01, time/batch = 0.0771s	
881/5250 (epoch 8.390), train_loss = 1.71396497, grad/param norm = 1.6497e-01, time/batch = 0.0798s	
882/5250 (epoch 8.400), train_loss = 1.67984680, grad/param norm = 1.6220e-01, time/batch = 0.0771s	
883/5250 (epoch 8.410), train_loss = 1.70569996, grad/param norm = 1.5007e-01, time/batch = 0.0768s	
884/5250 (epoch 8.419), train_loss = 1.68903404, grad/param norm = 1.3388e-01, time/batch = 0.0772s	
885/5250 (epoch 8.429), train_loss = 1.68988408, grad/param norm = 1.2453e-01, time/batch = 0.0771s	
886/5250 (epoch 8.438), train_loss = 1.70549425, grad/param norm = 1.2103e-01, time/batch = 0.0776s	
887/5250 (epoch 8.448), train_loss = 1.67118610, grad/param norm = 1.2419e-01, time/batch = 0.0779s	
888/5250 (epoch 8.457), train_loss = 1.66330384, grad/param norm = 1.5202e-01, time/batch = 0.0772s	
889/5250 (epoch 8.467), train_loss = 1.67156656, grad/param norm = 1.7809e-01, time/batch = 0.0777s	
890/5250 (epoch 8.476), train_loss = 1.68471654, grad/param norm = 1.9526e-01, time/batch = 0.0773s	
891/5250 (epoch 8.486), train_loss = 1.70019544, grad/param norm = 1.9662e-01, time/batch = 0.0791s	
892/5250 (epoch 8.495), train_loss = 1.69346521, grad/param norm = 1.9606e-01, time/batch = 0.0774s	
893/5250 (epoch 8.505), train_loss = 1.70309199, grad/param norm = 1.6505e-01, time/batch = 0.0773s	
894/5250 (epoch 8.514), train_loss = 1.69037563, grad/param norm = 1.1862e-01, time/batch = 0.0770s	
895/5250 (epoch 8.524), train_loss = 1.65676084, grad/param norm = 1.1628e-01, time/batch = 0.0771s	
896/5250 (epoch 8.533), train_loss = 1.67183332, grad/param norm = 1.2261e-01, time/batch = 0.0777s	
897/5250 (epoch 8.543), train_loss = 1.66021775, grad/param norm = 1.2933e-01, time/batch = 0.0772s	
898/5250 (epoch 8.552), train_loss = 1.67009357, grad/param norm = 1.3459e-01, time/batch = 0.0779s	
899/5250 (epoch 8.562), train_loss = 1.68282659, grad/param norm = 1.3690e-01, time/batch = 0.0773s	
900/5250 (epoch 8.571), train_loss = 1.68137993, grad/param norm = 1.2400e-01, time/batch = 0.0769s	
901/5250 (epoch 8.581), train_loss = 1.69150464, grad/param norm = 1.0641e-01, time/batch = 0.0789s	
902/5250 (epoch 8.590), train_loss = 1.67145228, grad/param norm = 1.0646e-01, time/batch = 0.0768s	
903/5250 (epoch 8.600), train_loss = 1.68832834, grad/param norm = 1.2330e-01, time/batch = 0.0774s	
904/5250 (epoch 8.610), train_loss = 1.68668111, grad/param norm = 1.3693e-01, time/batch = 0.0771s	
905/5250 (epoch 8.619), train_loss = 1.66646971, grad/param norm = 1.3848e-01, time/batch = 0.0774s	
906/5250 (epoch 8.629), train_loss = 1.71174950, grad/param norm = 1.4225e-01, time/batch = 0.0778s	
907/5250 (epoch 8.638), train_loss = 1.67084982, grad/param norm = 1.2927e-01, time/batch = 0.0771s	
908/5250 (epoch 8.648), train_loss = 1.67590073, grad/param norm = 1.1641e-01, time/batch = 0.0774s	
909/5250 (epoch 8.657), train_loss = 1.65203549, grad/param norm = 1.3096e-01, time/batch = 0.0787s	
910/5250 (epoch 8.667), train_loss = 1.68441448, grad/param norm = 1.6003e-01, time/batch = 0.0772s	
911/5250 (epoch 8.676), train_loss = 1.67978580, grad/param norm = 1.9177e-01, time/batch = 0.0790s	
912/5250 (epoch 8.686), train_loss = 1.71202085, grad/param norm = 1.7469e-01, time/batch = 0.0769s	
913/5250 (epoch 8.695), train_loss = 1.68537094, grad/param norm = 1.5177e-01, time/batch = 0.0771s	
914/5250 (epoch 8.705), train_loss = 1.65966677, grad/param norm = 1.4045e-01, time/batch = 0.0775s	
915/5250 (epoch 8.714), train_loss = 1.69119938, grad/param norm = 1.4130e-01, time/batch = 0.0772s	
916/5250 (epoch 8.724), train_loss = 1.65922186, grad/param norm = 1.4331e-01, time/batch = 0.0778s	
917/5250 (epoch 8.733), train_loss = 1.66169456, grad/param norm = 1.4619e-01, time/batch = 0.0772s	
918/5250 (epoch 8.743), train_loss = 1.66667151, grad/param norm = 1.7639e-01, time/batch = 0.0771s	
919/5250 (epoch 8.752), train_loss = 1.69295442, grad/param norm = 1.8029e-01, time/batch = 0.0775s	
920/5250 (epoch 8.762), train_loss = 1.67112127, grad/param norm = 1.7325e-01, time/batch = 0.0781s	
921/5250 (epoch 8.771), train_loss = 1.64977715, grad/param norm = 1.5128e-01, time/batch = 0.0790s	
922/5250 (epoch 8.781), train_loss = 1.66353853, grad/param norm = 1.2309e-01, time/batch = 0.0769s	
923/5250 (epoch 8.790), train_loss = 1.68806007, grad/param norm = 1.1670e-01, time/batch = 0.0772s	
924/5250 (epoch 8.800), train_loss = 1.67519518, grad/param norm = 1.1148e-01, time/batch = 0.0772s	
925/5250 (epoch 8.810), train_loss = 1.66313385, grad/param norm = 9.8553e-02, time/batch = 0.0774s	
926/5250 (epoch 8.819), train_loss = 1.66460516, grad/param norm = 1.2229e-01, time/batch = 0.0777s	
927/5250 (epoch 8.829), train_loss = 1.67645241, grad/param norm = 1.4377e-01, time/batch = 0.0772s	
928/5250 (epoch 8.838), train_loss = 1.66195228, grad/param norm = 1.6742e-01, time/batch = 0.0772s	
929/5250 (epoch 8.848), train_loss = 1.66033092, grad/param norm = 1.6262e-01, time/batch = 0.0778s	
930/5250 (epoch 8.857), train_loss = 1.66790244, grad/param norm = 1.3324e-01, time/batch = 0.0771s	
931/5250 (epoch 8.867), train_loss = 1.65098012, grad/param norm = 1.1930e-01, time/batch = 0.0796s	
932/5250 (epoch 8.876), train_loss = 1.67556077, grad/param norm = 9.5192e-02, time/batch = 0.0773s	
933/5250 (epoch 8.886), train_loss = 1.64968489, grad/param norm = 1.0053e-01, time/batch = 0.0770s	
934/5250 (epoch 8.895), train_loss = 1.68029521, grad/param norm = 1.1647e-01, time/batch = 0.0772s	
935/5250 (epoch 8.905), train_loss = 1.66760564, grad/param norm = 1.2614e-01, time/batch = 0.0784s	
936/5250 (epoch 8.914), train_loss = 1.68545898, grad/param norm = 1.5016e-01, time/batch = 0.0807s	
937/5250 (epoch 8.924), train_loss = 1.68887160, grad/param norm = 1.7239e-01, time/batch = 0.0774s	
938/5250 (epoch 8.933), train_loss = 1.69138567, grad/param norm = 1.9222e-01, time/batch = 0.0772s	
939/5250 (epoch 8.943), train_loss = 1.71022536, grad/param norm = 1.7435e-01, time/batch = 0.0773s	
940/5250 (epoch 8.952), train_loss = 1.69105342, grad/param norm = 1.2474e-01, time/batch = 0.0769s	
941/5250 (epoch 8.962), train_loss = 1.66369732, grad/param norm = 1.1564e-01, time/batch = 0.0790s	
942/5250 (epoch 8.971), train_loss = 1.65085316, grad/param norm = 1.3155e-01, time/batch = 0.0776s	
943/5250 (epoch 8.981), train_loss = 1.69257834, grad/param norm = 1.6021e-01, time/batch = 0.0772s	
944/5250 (epoch 8.990), train_loss = 1.69576519, grad/param norm = 1.6859e-01, time/batch = 0.0770s	
945/5250 (epoch 9.000), train_loss = 1.66293246, grad/param norm = 1.6294e-01, time/batch = 0.0770s	
946/5250 (epoch 9.010), train_loss = 1.80626890, grad/param norm = 1.5810e-01, time/batch = 0.0777s	
947/5250 (epoch 9.019), train_loss = 1.66767943, grad/param norm = 1.3547e-01, time/batch = 0.0772s	
948/5250 (epoch 9.029), train_loss = 1.65063109, grad/param norm = 9.7623e-02, time/batch = 0.0777s	
949/5250 (epoch 9.038), train_loss = 1.65056867, grad/param norm = 8.7953e-02, time/batch = 0.0777s	
950/5250 (epoch 9.048), train_loss = 1.64145298, grad/param norm = 1.1148e-01, time/batch = 0.0771s	
951/5250 (epoch 9.057), train_loss = 1.65435903, grad/param norm = 1.2534e-01, time/batch = 0.0790s	
952/5250 (epoch 9.067), train_loss = 1.65857608, grad/param norm = 1.3329e-01, time/batch = 0.0768s	
953/5250 (epoch 9.076), train_loss = 1.64338791, grad/param norm = 1.2279e-01, time/batch = 0.0774s	
954/5250 (epoch 9.086), train_loss = 1.59204258, grad/param norm = 1.1669e-01, time/batch = 0.0772s	
955/5250 (epoch 9.095), train_loss = 1.64999989, grad/param norm = 1.2202e-01, time/batch = 0.0774s	
956/5250 (epoch 9.105), train_loss = 1.65782328, grad/param norm = 1.1801e-01, time/batch = 0.0777s	
957/5250 (epoch 9.114), train_loss = 1.63341701, grad/param norm = 1.2629e-01, time/batch = 0.0772s	
958/5250 (epoch 9.124), train_loss = 1.65351552, grad/param norm = 1.5279e-01, time/batch = 0.0771s	
959/5250 (epoch 9.133), train_loss = 1.64927214, grad/param norm = 1.6512e-01, time/batch = 0.0783s	
960/5250 (epoch 9.143), train_loss = 1.62841895, grad/param norm = 1.6310e-01, time/batch = 0.0768s	
961/5250 (epoch 9.152), train_loss = 1.62346593, grad/param norm = 1.4037e-01, time/batch = 0.0788s	
962/5250 (epoch 9.162), train_loss = 1.65210932, grad/param norm = 1.2928e-01, time/batch = 0.0770s	
963/5250 (epoch 9.171), train_loss = 1.66645596, grad/param norm = 1.1576e-01, time/batch = 0.0770s	
964/5250 (epoch 9.181), train_loss = 1.65898473, grad/param norm = 1.0790e-01, time/batch = 0.0778s	
965/5250 (epoch 9.190), train_loss = 1.64895565, grad/param norm = 1.1567e-01, time/batch = 0.0770s	
966/5250 (epoch 9.200), train_loss = 1.64452843, grad/param norm = 1.1390e-01, time/batch = 0.0777s	
967/5250 (epoch 9.210), train_loss = 1.63946053, grad/param norm = 1.2041e-01, time/batch = 0.0771s	
968/5250 (epoch 9.219), train_loss = 1.68501137, grad/param norm = 1.3307e-01, time/batch = 0.0771s	
969/5250 (epoch 9.229), train_loss = 1.65795040, grad/param norm = 1.5573e-01, time/batch = 0.0777s	
970/5250 (epoch 9.238), train_loss = 1.64806175, grad/param norm = 1.7210e-01, time/batch = 0.0775s	
971/5250 (epoch 9.248), train_loss = 1.65743800, grad/param norm = 1.5659e-01, time/batch = 0.0788s	
972/5250 (epoch 9.257), train_loss = 1.62956249, grad/param norm = 1.3019e-01, time/batch = 0.0770s	
973/5250 (epoch 9.267), train_loss = 1.62297962, grad/param norm = 1.2071e-01, time/batch = 0.0770s	
974/5250 (epoch 9.276), train_loss = 1.63759610, grad/param norm = 1.1875e-01, time/batch = 0.0770s	
975/5250 (epoch 9.286), train_loss = 1.60155344, grad/param norm = 1.1856e-01, time/batch = 0.0774s	
976/5250 (epoch 9.295), train_loss = 1.63936207, grad/param norm = 1.1639e-01, time/batch = 0.0778s	
977/5250 (epoch 9.305), train_loss = 1.65103962, grad/param norm = 1.1598e-01, time/batch = 0.0772s	
978/5250 (epoch 9.314), train_loss = 1.60967405, grad/param norm = 1.2034e-01, time/batch = 0.0771s	
979/5250 (epoch 9.324), train_loss = 1.64672870, grad/param norm = 1.3741e-01, time/batch = 0.0774s	
980/5250 (epoch 9.333), train_loss = 1.65398126, grad/param norm = 1.5400e-01, time/batch = 0.0768s	
981/5250 (epoch 9.343), train_loss = 1.65620081, grad/param norm = 1.5725e-01, time/batch = 0.0794s	
982/5250 (epoch 9.352), train_loss = 1.65708644, grad/param norm = 1.5041e-01, time/batch = 0.0769s	
983/5250 (epoch 9.362), train_loss = 1.64733499, grad/param norm = 1.2780e-01, time/batch = 0.0772s	
984/5250 (epoch 9.371), train_loss = 1.62220150, grad/param norm = 1.2011e-01, time/batch = 0.0769s	
985/5250 (epoch 9.381), train_loss = 1.63355319, grad/param norm = 1.2947e-01, time/batch = 0.0768s	
986/5250 (epoch 9.390), train_loss = 1.66696845, grad/param norm = 1.7517e-01, time/batch = 0.0782s	
987/5250 (epoch 9.400), train_loss = 1.63928286, grad/param norm = 1.4387e-01, time/batch = 0.0772s	
988/5250 (epoch 9.410), train_loss = 1.66183048, grad/param norm = 1.4433e-01, time/batch = 0.0771s	
989/5250 (epoch 9.419), train_loss = 1.64549886, grad/param norm = 1.3789e-01, time/batch = 0.0778s	
990/5250 (epoch 9.429), train_loss = 1.64823597, grad/param norm = 1.2642e-01, time/batch = 0.0770s	
991/5250 (epoch 9.438), train_loss = 1.65968319, grad/param norm = 1.1103e-01, time/batch = 0.0797s	
992/5250 (epoch 9.448), train_loss = 1.62032795, grad/param norm = 1.1176e-01, time/batch = 0.0776s	
993/5250 (epoch 9.457), train_loss = 1.61393328, grad/param norm = 1.4253e-01, time/batch = 0.0770s	
994/5250 (epoch 9.467), train_loss = 1.62520264, grad/param norm = 1.6934e-01, time/batch = 0.0769s	
995/5250 (epoch 9.476), train_loss = 1.63721423, grad/param norm = 1.6604e-01, time/batch = 0.0772s	
996/5250 (epoch 9.486), train_loss = 1.64103637, grad/param norm = 1.5069e-01, time/batch = 0.0777s	
997/5250 (epoch 9.495), train_loss = 1.63805816, grad/param norm = 1.3548e-01, time/batch = 0.0772s	
998/5250 (epoch 9.505), train_loss = 1.64176196, grad/param norm = 1.1462e-01, time/batch = 0.0772s	
999/5250 (epoch 9.514), train_loss = 1.63979548, grad/param norm = 1.0516e-01, time/batch = 0.0780s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch9.52_1.6784.t7	
1000/5250 (epoch 9.524), train_loss = 1.60924073, grad/param norm = 1.1115e-01, time/batch = 0.0771s	
1001/5250 (epoch 9.533), train_loss = 1.75884995, grad/param norm = 1.1954e-01, time/batch = 0.0796s	
1002/5250 (epoch 9.543), train_loss = 1.61587281, grad/param norm = 1.2266e-01, time/batch = 0.0773s	
1003/5250 (epoch 9.552), train_loss = 1.62473844, grad/param norm = 1.2530e-01, time/batch = 0.0771s	
1004/5250 (epoch 9.562), train_loss = 1.63299247, grad/param norm = 1.2114e-01, time/batch = 0.0776s	
1005/5250 (epoch 9.571), train_loss = 1.63038850, grad/param norm = 1.0439e-01, time/batch = 0.0784s	
1006/5250 (epoch 9.581), train_loss = 1.64789379, grad/param norm = 1.0576e-01, time/batch = 0.0783s	
1007/5250 (epoch 9.590), train_loss = 1.62661885, grad/param norm = 1.0494e-01, time/batch = 0.0773s	
1008/5250 (epoch 9.600), train_loss = 1.64211972, grad/param norm = 1.0252e-01, time/batch = 0.0773s	
1009/5250 (epoch 9.610), train_loss = 1.63763854, grad/param norm = 1.1583e-01, time/batch = 0.0776s	
1010/5250 (epoch 9.619), train_loss = 1.62191352, grad/param norm = 1.2598e-01, time/batch = 0.0775s	
1011/5250 (epoch 9.629), train_loss = 1.65951205, grad/param norm = 1.2491e-01, time/batch = 0.0795s	
1012/5250 (epoch 9.638), train_loss = 1.62191253, grad/param norm = 1.1908e-01, time/batch = 0.0770s	
1013/5250 (epoch 9.648), train_loss = 1.62867979, grad/param norm = 1.0486e-01, time/batch = 0.0768s	
1014/5250 (epoch 9.657), train_loss = 1.60264814, grad/param norm = 9.7473e-02, time/batch = 0.0773s	
1015/5250 (epoch 9.667), train_loss = 1.62561237, grad/param norm = 1.1641e-01, time/batch = 0.0771s	
1016/5250 (epoch 9.676), train_loss = 1.62533233, grad/param norm = 1.4284e-01, time/batch = 0.0774s	
1017/5250 (epoch 9.686), train_loss = 1.66282197, grad/param norm = 1.6130e-01, time/batch = 0.0774s	
1018/5250 (epoch 9.695), train_loss = 1.65050618, grad/param norm = 1.9676e-01, time/batch = 0.0771s	
1019/5250 (epoch 9.705), train_loss = 1.62407915, grad/param norm = 1.4372e-01, time/batch = 0.0775s	
1020/5250 (epoch 9.714), train_loss = 1.64840361, grad/param norm = 1.2738e-01, time/batch = 0.0768s	
1021/5250 (epoch 9.724), train_loss = 1.62322745, grad/param norm = 1.6409e-01, time/batch = 0.0789s	
1022/5250 (epoch 9.733), train_loss = 1.62860470, grad/param norm = 1.5144e-01, time/batch = 0.0776s	
1023/5250 (epoch 9.743), train_loss = 1.62435847, grad/param norm = 1.6140e-01, time/batch = 0.0767s	
1024/5250 (epoch 9.752), train_loss = 1.64283753, grad/param norm = 1.5193e-01, time/batch = 0.0773s	
1025/5250 (epoch 9.762), train_loss = 1.61646585, grad/param norm = 1.3365e-01, time/batch = 0.0771s	
1026/5250 (epoch 9.771), train_loss = 1.60126557, grad/param norm = 1.2676e-01, time/batch = 0.0771s	
1027/5250 (epoch 9.781), train_loss = 1.61823441, grad/param norm = 1.1565e-01, time/batch = 0.0764s	
1028/5250 (epoch 9.790), train_loss = 1.64516173, grad/param norm = 1.0945e-01, time/batch = 0.0774s	
1029/5250 (epoch 9.800), train_loss = 1.63293067, grad/param norm = 1.1403e-01, time/batch = 0.0773s	
1030/5250 (epoch 9.810), train_loss = 1.62779514, grad/param norm = 1.2643e-01, time/batch = 0.0773s	
1031/5250 (epoch 9.819), train_loss = 1.62431344, grad/param norm = 1.3162e-01, time/batch = 0.0792s	
1032/5250 (epoch 9.829), train_loss = 1.63253104, grad/param norm = 1.3403e-01, time/batch = 0.0772s	
1033/5250 (epoch 9.838), train_loss = 1.61991663, grad/param norm = 1.3630e-01, time/batch = 0.0776s	
1034/5250 (epoch 9.848), train_loss = 1.61264789, grad/param norm = 1.3836e-01, time/batch = 0.0771s	
1035/5250 (epoch 9.857), train_loss = 1.63071958, grad/param norm = 1.4350e-01, time/batch = 0.0769s	
1036/5250 (epoch 9.867), train_loss = 1.61246129, grad/param norm = 1.5465e-01, time/batch = 0.0801s	
1037/5250 (epoch 9.876), train_loss = 1.64283226, grad/param norm = 1.2114e-01, time/batch = 0.0774s	
1038/5250 (epoch 9.886), train_loss = 1.60769323, grad/param norm = 9.6653e-02, time/batch = 0.0768s	
1039/5250 (epoch 9.895), train_loss = 1.63499131, grad/param norm = 9.8847e-02, time/batch = 0.0778s	
1040/5250 (epoch 9.905), train_loss = 1.62160565, grad/param norm = 1.0187e-01, time/batch = 0.0769s	
1041/5250 (epoch 9.914), train_loss = 1.63456531, grad/param norm = 1.0178e-01, time/batch = 0.0790s	
1042/5250 (epoch 9.924), train_loss = 1.63265522, grad/param norm = 1.0163e-01, time/batch = 0.0769s	
1043/5250 (epoch 9.933), train_loss = 1.62361098, grad/param norm = 9.9889e-02, time/batch = 0.0816s	
1044/5250 (epoch 9.943), train_loss = 1.65186877, grad/param norm = 1.1259e-01, time/batch = 0.0800s	
1045/5250 (epoch 9.952), train_loss = 1.64607578, grad/param norm = 1.1748e-01, time/batch = 0.0772s	
1046/5250 (epoch 9.962), train_loss = 1.62896371, grad/param norm = 1.3012e-01, time/batch = 0.0777s	
1047/5250 (epoch 9.971), train_loss = 1.62015130, grad/param norm = 1.4796e-01, time/batch = 0.0769s	
1048/5250 (epoch 9.981), train_loss = 1.65292835, grad/param norm = 1.3628e-01, time/batch = 0.0768s	
1049/5250 (epoch 9.990), train_loss = 1.64282883, grad/param norm = 1.1192e-01, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.00194	
1050/5250 (epoch 10.000), train_loss = 1.61311647, grad/param norm = 1.1096e-01, time/batch = 0.0777s	
1051/5250 (epoch 10.010), train_loss = 1.76287639, grad/param norm = 1.2718e-01, time/batch = 0.0800s	
1052/5250 (epoch 10.019), train_loss = 1.62070941, grad/param norm = 1.2984e-01, time/batch = 0.0771s	
1053/5250 (epoch 10.029), train_loss = 1.61374160, grad/param norm = 1.1906e-01, time/batch = 0.0770s	
1054/5250 (epoch 10.038), train_loss = 1.61548561, grad/param norm = 1.3075e-01, time/batch = 0.0766s	
1055/5250 (epoch 10.048), train_loss = 1.61458208, grad/param norm = 1.7155e-01, time/batch = 0.0773s	
1056/5250 (epoch 10.057), train_loss = 1.62863986, grad/param norm = 1.8019e-01, time/batch = 0.0776s	
1057/5250 (epoch 10.067), train_loss = 1.62383029, grad/param norm = 1.6086e-01, time/batch = 0.0770s	
1058/5250 (epoch 10.076), train_loss = 1.60227706, grad/param norm = 1.1860e-01, time/batch = 0.0767s	
1059/5250 (epoch 10.086), train_loss = 1.54769119, grad/param norm = 1.0014e-01, time/batch = 0.0772s	
1060/5250 (epoch 10.095), train_loss = 1.60467822, grad/param norm = 1.0551e-01, time/batch = 0.0769s	
1061/5250 (epoch 10.105), train_loss = 1.61358687, grad/param norm = 1.0824e-01, time/batch = 0.0795s	
1062/5250 (epoch 10.114), train_loss = 1.59297685, grad/param norm = 1.1219e-01, time/batch = 0.0773s	
1063/5250 (epoch 10.124), train_loss = 1.60791275, grad/param norm = 1.2208e-01, time/batch = 0.0770s	
1064/5250 (epoch 10.133), train_loss = 1.59948093, grad/param norm = 1.2221e-01, time/batch = 0.0772s	
1065/5250 (epoch 10.143), train_loss = 1.57443070, grad/param norm = 1.1329e-01, time/batch = 0.0770s	
1066/5250 (epoch 10.152), train_loss = 1.57462911, grad/param norm = 1.1349e-01, time/batch = 0.0772s	
1067/5250 (epoch 10.162), train_loss = 1.60702685, grad/param norm = 1.2140e-01, time/batch = 0.0767s	
1068/5250 (epoch 10.171), train_loss = 1.62223357, grad/param norm = 1.2112e-01, time/batch = 0.0764s	
1069/5250 (epoch 10.181), train_loss = 1.61487813, grad/param norm = 1.1593e-01, time/batch = 0.0772s	
1070/5250 (epoch 10.190), train_loss = 1.60218224, grad/param norm = 1.0411e-01, time/batch = 0.0770s	
1071/5250 (epoch 10.200), train_loss = 1.59578416, grad/param norm = 8.9938e-02, time/batch = 0.0789s	
1072/5250 (epoch 10.210), train_loss = 1.59067975, grad/param norm = 8.2692e-02, time/batch = 0.0778s	
1073/5250 (epoch 10.219), train_loss = 1.63805905, grad/param norm = 9.3939e-02, time/batch = 0.0772s	
1074/5250 (epoch 10.229), train_loss = 1.60968231, grad/param norm = 1.2184e-01, time/batch = 0.0771s	
1075/5250 (epoch 10.238), train_loss = 1.60710780, grad/param norm = 1.4853e-01, time/batch = 0.0768s	
1076/5250 (epoch 10.248), train_loss = 1.61247943, grad/param norm = 1.2172e-01, time/batch = 0.0773s	
1077/5250 (epoch 10.257), train_loss = 1.58908701, grad/param norm = 1.2068e-01, time/batch = 0.0764s	
1078/5250 (epoch 10.267), train_loss = 1.58481629, grad/param norm = 1.1851e-01, time/batch = 0.0775s	
1079/5250 (epoch 10.276), train_loss = 1.59221813, grad/param norm = 1.2152e-01, time/batch = 0.0772s	
1080/5250 (epoch 10.286), train_loss = 1.56216032, grad/param norm = 1.2439e-01, time/batch = 0.0769s	
1081/5250 (epoch 10.295), train_loss = 1.59934106, grad/param norm = 1.3356e-01, time/batch = 0.0790s	
1082/5250 (epoch 10.305), train_loss = 1.61271037, grad/param norm = 1.3448e-01, time/batch = 0.0772s	
1083/5250 (epoch 10.314), train_loss = 1.57199488, grad/param norm = 1.3085e-01, time/batch = 0.0777s	
1084/5250 (epoch 10.324), train_loss = 1.60750107, grad/param norm = 1.3258e-01, time/batch = 0.0771s	
1085/5250 (epoch 10.333), train_loss = 1.60822263, grad/param norm = 1.3225e-01, time/batch = 0.0766s	
1086/5250 (epoch 10.343), train_loss = 1.60647965, grad/param norm = 1.3109e-01, time/batch = 0.0774s	
1087/5250 (epoch 10.352), train_loss = 1.61240271, grad/param norm = 1.3806e-01, time/batch = 0.0767s	
1088/5250 (epoch 10.362), train_loss = 1.60382903, grad/param norm = 1.2330e-01, time/batch = 0.0767s	
1089/5250 (epoch 10.371), train_loss = 1.57657314, grad/param norm = 1.0515e-01, time/batch = 0.0777s	
1090/5250 (epoch 10.381), train_loss = 1.58950086, grad/param norm = 1.1427e-01, time/batch = 0.0774s	
1091/5250 (epoch 10.390), train_loss = 1.61172632, grad/param norm = 1.3523e-01, time/batch = 0.0790s	
1092/5250 (epoch 10.400), train_loss = 1.59053968, grad/param norm = 1.4309e-01, time/batch = 0.0771s	
1093/5250 (epoch 10.410), train_loss = 1.61580325, grad/param norm = 1.1518e-01, time/batch = 0.0771s	
1094/5250 (epoch 10.419), train_loss = 1.60152688, grad/param norm = 1.1801e-01, time/batch = 0.0773s	
1095/5250 (epoch 10.429), train_loss = 1.60808766, grad/param norm = 1.3599e-01, time/batch = 0.0770s	
1096/5250 (epoch 10.438), train_loss = 1.62755495, grad/param norm = 1.2545e-01, time/batch = 0.0775s	
1097/5250 (epoch 10.448), train_loss = 1.58320771, grad/param norm = 1.2354e-01, time/batch = 0.0769s	
1098/5250 (epoch 10.457), train_loss = 1.57583395, grad/param norm = 1.2536e-01, time/batch = 0.0767s	
1099/5250 (epoch 10.467), train_loss = 1.57991199, grad/param norm = 1.1165e-01, time/batch = 0.0769s	
1100/5250 (epoch 10.476), train_loss = 1.58061369, grad/param norm = 9.8907e-02, time/batch = 0.0775s	
1101/5250 (epoch 10.486), train_loss = 1.59228022, grad/param norm = 9.6038e-02, time/batch = 0.0790s	
1102/5250 (epoch 10.495), train_loss = 1.59360809, grad/param norm = 1.0220e-01, time/batch = 0.0770s	
1103/5250 (epoch 10.505), train_loss = 1.60444016, grad/param norm = 9.8791e-02, time/batch = 0.0770s	
1104/5250 (epoch 10.514), train_loss = 1.60131475, grad/param norm = 9.6393e-02, time/batch = 0.0771s	
1105/5250 (epoch 10.524), train_loss = 1.57413645, grad/param norm = 9.9145e-02, time/batch = 0.0777s	
1106/5250 (epoch 10.533), train_loss = 1.58517277, grad/param norm = 9.8602e-02, time/batch = 0.0772s	
1107/5250 (epoch 10.543), train_loss = 1.57118703, grad/param norm = 9.7669e-02, time/batch = 0.0768s	
1108/5250 (epoch 10.552), train_loss = 1.58144724, grad/param norm = 1.0568e-01, time/batch = 0.0768s	
1109/5250 (epoch 10.562), train_loss = 1.59499702, grad/param norm = 1.2926e-01, time/batch = 0.0772s	
1110/5250 (epoch 10.571), train_loss = 1.59895991, grad/param norm = 1.3310e-01, time/batch = 0.0768s	
1111/5250 (epoch 10.581), train_loss = 1.62077912, grad/param norm = 1.3760e-01, time/batch = 0.0801s	
1112/5250 (epoch 10.590), train_loss = 1.60562826, grad/param norm = 1.4815e-01, time/batch = 0.0770s	
1113/5250 (epoch 10.600), train_loss = 1.61659518, grad/param norm = 1.4124e-01, time/batch = 0.0770s	
1114/5250 (epoch 10.610), train_loss = 1.60267800, grad/param norm = 1.1768e-01, time/batch = 0.0771s	
1115/5250 (epoch 10.619), train_loss = 1.57680870, grad/param norm = 1.0631e-01, time/batch = 0.0770s	
1116/5250 (epoch 10.629), train_loss = 1.61364861, grad/param norm = 9.4422e-02, time/batch = 0.0775s	
1117/5250 (epoch 10.638), train_loss = 1.57531067, grad/param norm = 8.9121e-02, time/batch = 0.0769s	
1118/5250 (epoch 10.648), train_loss = 1.59033761, grad/param norm = 9.5963e-02, time/batch = 0.0768s	
1119/5250 (epoch 10.657), train_loss = 1.57318441, grad/param norm = 1.2591e-01, time/batch = 0.0772s	
1120/5250 (epoch 10.667), train_loss = 1.60054510, grad/param norm = 1.4722e-01, time/batch = 0.0769s	
1121/5250 (epoch 10.676), train_loss = 1.59717660, grad/param norm = 1.5113e-01, time/batch = 0.0789s	
1122/5250 (epoch 10.686), train_loss = 1.62657413, grad/param norm = 1.4578e-01, time/batch = 0.0776s	
1123/5250 (epoch 10.695), train_loss = 1.59371958, grad/param norm = 1.1893e-01, time/batch = 0.0770s	
1124/5250 (epoch 10.705), train_loss = 1.56837482, grad/param norm = 9.1203e-02, time/batch = 0.0768s	
1125/5250 (epoch 10.714), train_loss = 1.59502105, grad/param norm = 8.4116e-02, time/batch = 0.0770s	
1126/5250 (epoch 10.724), train_loss = 1.56909201, grad/param norm = 7.8558e-02, time/batch = 0.0774s	
1127/5250 (epoch 10.733), train_loss = 1.56487222, grad/param norm = 7.9339e-02, time/batch = 0.0772s	
1128/5250 (epoch 10.743), train_loss = 1.57066526, grad/param norm = 8.3569e-02, time/batch = 0.0774s	
1129/5250 (epoch 10.752), train_loss = 1.58485789, grad/param norm = 8.5796e-02, time/batch = 0.0774s	
1130/5250 (epoch 10.762), train_loss = 1.56805904, grad/param norm = 9.1731e-02, time/batch = 0.0770s	
1131/5250 (epoch 10.771), train_loss = 1.56220688, grad/param norm = 9.9333e-02, time/batch = 0.0789s	
1132/5250 (epoch 10.781), train_loss = 1.58307452, grad/param norm = 1.2085e-01, time/batch = 0.0771s	
1133/5250 (epoch 10.790), train_loss = 1.61774969, grad/param norm = 1.4514e-01, time/batch = 0.0774s	
1134/5250 (epoch 10.800), train_loss = 1.61245276, grad/param norm = 1.5799e-01, time/batch = 0.0768s	
1135/5250 (epoch 10.810), train_loss = 1.60198942, grad/param norm = 1.5976e-01, time/batch = 0.0770s	
1136/5250 (epoch 10.819), train_loss = 1.60151108, grad/param norm = 1.3570e-01, time/batch = 0.0774s	
1137/5250 (epoch 10.829), train_loss = 1.60811649, grad/param norm = 1.4467e-01, time/batch = 0.0767s	
1138/5250 (epoch 10.838), train_loss = 1.57910563, grad/param norm = 1.2957e-01, time/batch = 0.0764s	
1139/5250 (epoch 10.848), train_loss = 1.56625737, grad/param norm = 1.0402e-01, time/batch = 0.0781s	
1140/5250 (epoch 10.857), train_loss = 1.57838794, grad/param norm = 8.8365e-02, time/batch = 0.0770s	
1141/5250 (epoch 10.867), train_loss = 1.56205452, grad/param norm = 8.5711e-02, time/batch = 0.0790s	
1142/5250 (epoch 10.876), train_loss = 1.59191518, grad/param norm = 8.0796e-02, time/batch = 0.0770s	
1143/5250 (epoch 10.886), train_loss = 1.56603206, grad/param norm = 8.3551e-02, time/batch = 0.0767s	
1144/5250 (epoch 10.895), train_loss = 1.59903872, grad/param norm = 9.4072e-02, time/batch = 0.0773s	
1145/5250 (epoch 10.905), train_loss = 1.58723590, grad/param norm = 1.1088e-01, time/batch = 0.0773s	
1146/5250 (epoch 10.914), train_loss = 1.61305658, grad/param norm = 1.3907e-01, time/batch = 0.0773s	
1147/5250 (epoch 10.924), train_loss = 1.61761826, grad/param norm = 1.7278e-01, time/batch = 0.0768s	
1148/5250 (epoch 10.933), train_loss = 1.61477822, grad/param norm = 1.9136e-01, time/batch = 0.0767s	
1149/5250 (epoch 10.943), train_loss = 1.63484117, grad/param norm = 1.7590e-01, time/batch = 0.0775s	
1150/5250 (epoch 10.952), train_loss = 1.61773436, grad/param norm = 1.3311e-01, time/batch = 0.0781s	
1151/5250 (epoch 10.962), train_loss = 1.58912946, grad/param norm = 1.1468e-01, time/batch = 0.0788s	
1152/5250 (epoch 10.971), train_loss = 1.57523840, grad/param norm = 1.1725e-01, time/batch = 0.0769s	
1153/5250 (epoch 10.981), train_loss = 1.60925073, grad/param norm = 1.1275e-01, time/batch = 0.0770s	
1154/5250 (epoch 10.990), train_loss = 1.60437629, grad/param norm = 1.0532e-01, time/batch = 0.0771s	
decayed learning rate by a factor 0.97 to 0.0018818	
1155/5250 (epoch 11.000), train_loss = 1.57543895, grad/param norm = 9.7789e-02, time/batch = 0.0804s	
1156/5250 (epoch 11.010), train_loss = 1.72544801, grad/param norm = 9.7827e-02, time/batch = 0.0777s	
1157/5250 (epoch 11.019), train_loss = 1.57584896, grad/param norm = 1.0091e-01, time/batch = 0.0771s	
1158/5250 (epoch 11.029), train_loss = 1.57586663, grad/param norm = 9.5733e-02, time/batch = 0.0766s	
1159/5250 (epoch 11.038), train_loss = 1.56869048, grad/param norm = 8.9682e-02, time/batch = 0.0775s	
1160/5250 (epoch 11.048), train_loss = 1.56011947, grad/param norm = 9.7872e-02, time/batch = 0.0772s	
1161/5250 (epoch 11.057), train_loss = 1.56882628, grad/param norm = 9.1244e-02, time/batch = 0.0797s	
1162/5250 (epoch 11.067), train_loss = 1.56847202, grad/param norm = 8.1051e-02, time/batch = 0.0773s	
1163/5250 (epoch 11.076), train_loss = 1.55631942, grad/param norm = 7.1715e-02, time/batch = 0.0772s	
1164/5250 (epoch 11.086), train_loss = 1.50725075, grad/param norm = 7.3027e-02, time/batch = 0.0770s	
1165/5250 (epoch 11.095), train_loss = 1.56474036, grad/param norm = 8.6488e-02, time/batch = 0.0768s	
1166/5250 (epoch 11.105), train_loss = 1.57579681, grad/param norm = 9.2405e-02, time/batch = 0.0778s	
1167/5250 (epoch 11.114), train_loss = 1.55459058, grad/param norm = 1.0180e-01, time/batch = 0.0767s	
1168/5250 (epoch 11.124), train_loss = 1.56896641, grad/param norm = 1.0808e-01, time/batch = 0.0769s	
1169/5250 (epoch 11.133), train_loss = 1.56066802, grad/param norm = 1.0361e-01, time/batch = 0.0773s	
1170/5250 (epoch 11.143), train_loss = 1.53831118, grad/param norm = 1.0586e-01, time/batch = 0.0769s	
1171/5250 (epoch 11.152), train_loss = 1.53862311, grad/param norm = 1.0289e-01, time/batch = 0.0789s	
1172/5250 (epoch 11.162), train_loss = 1.57233093, grad/param norm = 1.1174e-01, time/batch = 0.0777s	
1173/5250 (epoch 11.171), train_loss = 1.58728390, grad/param norm = 1.1660e-01, time/batch = 0.0771s	
1174/5250 (epoch 11.181), train_loss = 1.58348217, grad/param norm = 1.1228e-01, time/batch = 0.0771s	
1175/5250 (epoch 11.190), train_loss = 1.57128057, grad/param norm = 9.8358e-02, time/batch = 0.0767s	
1176/5250 (epoch 11.200), train_loss = 1.56293526, grad/param norm = 8.5649e-02, time/batch = 0.0775s	
1177/5250 (epoch 11.210), train_loss = 1.55286577, grad/param norm = 8.0255e-02, time/batch = 0.0769s	
1178/5250 (epoch 11.219), train_loss = 1.60326605, grad/param norm = 8.7826e-02, time/batch = 0.0772s	
1179/5250 (epoch 11.229), train_loss = 1.56635188, grad/param norm = 9.6267e-02, time/batch = 0.0771s	
1180/5250 (epoch 11.238), train_loss = 1.56178944, grad/param norm = 1.0880e-01, time/batch = 0.0769s	
1181/5250 (epoch 11.248), train_loss = 1.57446401, grad/param norm = 1.1810e-01, time/batch = 0.0789s	
1182/5250 (epoch 11.257), train_loss = 1.55191451, grad/param norm = 1.1396e-01, time/batch = 0.0769s	
1183/5250 (epoch 11.267), train_loss = 1.54783277, grad/param norm = 1.1272e-01, time/batch = 0.0777s	
1184/5250 (epoch 11.276), train_loss = 1.55678403, grad/param norm = 1.1997e-01, time/batch = 0.0771s	
1185/5250 (epoch 11.286), train_loss = 1.53000760, grad/param norm = 1.2880e-01, time/batch = 0.0770s	
1186/5250 (epoch 11.295), train_loss = 1.56783702, grad/param norm = 1.3318e-01, time/batch = 0.0776s	
1187/5250 (epoch 11.305), train_loss = 1.57861200, grad/param norm = 1.4888e-01, time/batch = 0.0770s	
1188/5250 (epoch 11.314), train_loss = 1.54591006, grad/param norm = 1.5934e-01, time/batch = 0.0766s	
1189/5250 (epoch 11.324), train_loss = 1.57196965, grad/param norm = 1.3868e-01, time/batch = 0.0779s	
1190/5250 (epoch 11.333), train_loss = 1.56897224, grad/param norm = 1.1289e-01, time/batch = 0.0771s	
1191/5250 (epoch 11.343), train_loss = 1.56672360, grad/param norm = 1.0834e-01, time/batch = 0.0788s	
1192/5250 (epoch 11.352), train_loss = 1.57576759, grad/param norm = 1.0560e-01, time/batch = 0.0770s	
1193/5250 (epoch 11.362), train_loss = 1.56962831, grad/param norm = 1.0842e-01, time/batch = 0.0770s	
1194/5250 (epoch 11.371), train_loss = 1.54854016, grad/param norm = 1.1790e-01, time/batch = 0.0771s	
1195/5250 (epoch 11.381), train_loss = 1.55966268, grad/param norm = 1.2936e-01, time/batch = 0.0773s	
1196/5250 (epoch 11.390), train_loss = 1.58752006, grad/param norm = 1.4505e-01, time/batch = 0.0773s	
1197/5250 (epoch 11.400), train_loss = 1.56247721, grad/param norm = 1.4448e-01, time/batch = 0.0769s	
1198/5250 (epoch 11.410), train_loss = 1.58875517, grad/param norm = 1.3913e-01, time/batch = 0.0767s	
1199/5250 (epoch 11.419), train_loss = 1.57125768, grad/param norm = 1.2417e-01, time/batch = 0.0777s	
1200/5250 (epoch 11.429), train_loss = 1.56705678, grad/param norm = 9.6243e-02, time/batch = 0.0773s	
1201/5250 (epoch 11.438), train_loss = 1.58298931, grad/param norm = 7.6723e-02, time/batch = 0.0791s	
1202/5250 (epoch 11.448), train_loss = 1.53890031, grad/param norm = 7.5291e-02, time/batch = 0.0770s	
1203/5250 (epoch 11.457), train_loss = 1.53225047, grad/param norm = 9.4076e-02, time/batch = 0.0769s	
1204/5250 (epoch 11.467), train_loss = 1.54265289, grad/param norm = 8.9519e-02, time/batch = 0.0769s	
1205/5250 (epoch 11.476), train_loss = 1.54745344, grad/param norm = 8.9868e-02, time/batch = 0.0776s	
1206/5250 (epoch 11.486), train_loss = 1.56042272, grad/param norm = 1.0023e-01, time/batch = 0.0775s	
1207/5250 (epoch 11.495), train_loss = 1.56238188, grad/param norm = 9.9783e-02, time/batch = 0.0768s	
1208/5250 (epoch 11.505), train_loss = 1.57171657, grad/param norm = 9.7371e-02, time/batch = 0.0767s	
1209/5250 (epoch 11.514), train_loss = 1.56820040, grad/param norm = 1.0195e-01, time/batch = 0.0768s	
1210/5250 (epoch 11.524), train_loss = 1.54080462, grad/param norm = 1.1204e-01, time/batch = 0.0770s	
1211/5250 (epoch 11.533), train_loss = 1.55393897, grad/param norm = 1.1288e-01, time/batch = 0.0795s	
1212/5250 (epoch 11.543), train_loss = 1.54241657, grad/param norm = 1.1020e-01, time/batch = 0.0772s	
1213/5250 (epoch 11.552), train_loss = 1.54634722, grad/param norm = 1.0309e-01, time/batch = 0.0771s	
1214/5250 (epoch 11.562), train_loss = 1.55229286, grad/param norm = 9.0730e-02, time/batch = 0.0771s	
1215/5250 (epoch 11.571), train_loss = 1.55484309, grad/param norm = 1.0885e-01, time/batch = 0.0770s	
1216/5250 (epoch 11.581), train_loss = 1.58607059, grad/param norm = 1.0733e-01, time/batch = 0.0781s	
1217/5250 (epoch 11.590), train_loss = 1.56332926, grad/param norm = 1.1209e-01, time/batch = 0.0771s	
1218/5250 (epoch 11.600), train_loss = 1.58076821, grad/param norm = 1.1829e-01, time/batch = 0.0768s	
1219/5250 (epoch 11.610), train_loss = 1.58135460, grad/param norm = 1.3654e-01, time/batch = 0.0774s	
1220/5250 (epoch 11.619), train_loss = 1.56185880, grad/param norm = 1.3924e-01, time/batch = 0.0766s	
1221/5250 (epoch 11.629), train_loss = 1.59028965, grad/param norm = 1.2682e-01, time/batch = 0.0788s	
1222/5250 (epoch 11.638), train_loss = 1.55132541, grad/param norm = 1.1504e-01, time/batch = 0.0775s	
1223/5250 (epoch 11.648), train_loss = 1.55960969, grad/param norm = 1.1178e-01, time/batch = 0.0771s	
1224/5250 (epoch 11.657), train_loss = 1.53683951, grad/param norm = 1.0338e-01, time/batch = 0.0771s	
1225/5250 (epoch 11.667), train_loss = 1.55457062, grad/param norm = 1.0621e-01, time/batch = 0.0769s	
1226/5250 (epoch 11.676), train_loss = 1.55278445, grad/param norm = 1.1053e-01, time/batch = 0.0774s	
1227/5250 (epoch 11.686), train_loss = 1.57968811, grad/param norm = 1.0113e-01, time/batch = 0.0769s	
1228/5250 (epoch 11.695), train_loss = 1.55556690, grad/param norm = 8.8765e-02, time/batch = 0.0770s	
1229/5250 (epoch 11.705), train_loss = 1.53199515, grad/param norm = 7.6006e-02, time/batch = 0.0773s	
1230/5250 (epoch 11.714), train_loss = 1.56297995, grad/param norm = 8.2827e-02, time/batch = 0.0769s	
1231/5250 (epoch 11.724), train_loss = 1.54132098, grad/param norm = 8.5810e-02, time/batch = 0.0790s	
1232/5250 (epoch 11.733), train_loss = 1.53236235, grad/param norm = 8.3134e-02, time/batch = 0.0770s	
1233/5250 (epoch 11.743), train_loss = 1.54609815, grad/param norm = 1.1385e-01, time/batch = 0.0775s	
1234/5250 (epoch 11.752), train_loss = 1.56175352, grad/param norm = 1.3165e-01, time/batch = 0.0769s	
1235/5250 (epoch 11.762), train_loss = 1.54770013, grad/param norm = 1.1449e-01, time/batch = 0.0767s	
1236/5250 (epoch 11.771), train_loss = 1.53667255, grad/param norm = 1.1250e-01, time/batch = 0.0775s	
1237/5250 (epoch 11.781), train_loss = 1.55277807, grad/param norm = 1.1214e-01, time/batch = 0.0768s	
1238/5250 (epoch 11.790), train_loss = 1.57739936, grad/param norm = 1.0957e-01, time/batch = 0.0769s	
1239/5250 (epoch 11.800), train_loss = 1.56418874, grad/param norm = 9.8952e-02, time/batch = 0.0780s	
1240/5250 (epoch 11.810), train_loss = 1.55762024, grad/param norm = 1.0495e-01, time/batch = 0.0769s	
1241/5250 (epoch 11.819), train_loss = 1.55429685, grad/param norm = 1.0656e-01, time/batch = 0.0789s	
1242/5250 (epoch 11.829), train_loss = 1.55639739, grad/param norm = 1.1273e-01, time/batch = 0.0770s	
1243/5250 (epoch 11.838), train_loss = 1.54729951, grad/param norm = 1.2337e-01, time/batch = 0.0768s	
1244/5250 (epoch 11.848), train_loss = 1.53565403, grad/param norm = 1.1928e-01, time/batch = 0.0772s	
1245/5250 (epoch 11.857), train_loss = 1.55708683, grad/param norm = 1.1351e-01, time/batch = 0.0771s	
1246/5250 (epoch 11.867), train_loss = 1.53450270, grad/param norm = 1.0007e-01, time/batch = 0.0774s	
1247/5250 (epoch 11.876), train_loss = 1.56200594, grad/param norm = 8.2993e-02, time/batch = 0.0770s	
1248/5250 (epoch 11.886), train_loss = 1.53467798, grad/param norm = 9.2205e-02, time/batch = 0.0765s	
1249/5250 (epoch 11.895), train_loss = 1.57256934, grad/param norm = 1.0949e-01, time/batch = 0.0770s	
1250/5250 (epoch 11.905), train_loss = 1.55916649, grad/param norm = 1.1029e-01, time/batch = 0.0777s	
1251/5250 (epoch 11.914), train_loss = 1.57875840, grad/param norm = 1.1926e-01, time/batch = 0.0790s	
1252/5250 (epoch 11.924), train_loss = 1.57393754, grad/param norm = 1.1386e-01, time/batch = 0.0772s	
1253/5250 (epoch 11.933), train_loss = 1.55637261, grad/param norm = 1.0128e-01, time/batch = 0.0769s	
1254/5250 (epoch 11.943), train_loss = 1.58870893, grad/param norm = 1.1574e-01, time/batch = 0.0771s	
1255/5250 (epoch 11.952), train_loss = 1.58308353, grad/param norm = 1.2067e-01, time/batch = 0.0774s	
1256/5250 (epoch 11.962), train_loss = 1.56715137, grad/param norm = 1.2366e-01, time/batch = 0.0775s	
1257/5250 (epoch 11.971), train_loss = 1.54825194, grad/param norm = 1.2415e-01, time/batch = 0.0767s	
1258/5250 (epoch 11.981), train_loss = 1.57898308, grad/param norm = 1.0659e-01, time/batch = 0.0768s	
1259/5250 (epoch 11.990), train_loss = 1.57703686, grad/param norm = 1.1151e-01, time/batch = 0.0773s	
decayed learning rate by a factor 0.97 to 0.001825346	
1260/5250 (epoch 12.000), train_loss = 1.55280249, grad/param norm = 1.2490e-01, time/batch = 0.0766s	
1261/5250 (epoch 12.010), train_loss = 1.70867308, grad/param norm = 1.3099e-01, time/batch = 0.0801s	
1262/5250 (epoch 12.019), train_loss = 1.54978708, grad/param norm = 1.2777e-01, time/batch = 0.0771s	
1263/5250 (epoch 12.029), train_loss = 1.55303091, grad/param norm = 1.2462e-01, time/batch = 0.0769s	
1264/5250 (epoch 12.038), train_loss = 1.54780704, grad/param norm = 1.1981e-01, time/batch = 0.0768s	
1265/5250 (epoch 12.048), train_loss = 1.53437797, grad/param norm = 1.2096e-01, time/batch = 0.0770s	
1266/5250 (epoch 12.057), train_loss = 1.54541692, grad/param norm = 1.0925e-01, time/batch = 0.0807s	
1267/5250 (epoch 12.067), train_loss = 1.53999512, grad/param norm = 9.1716e-02, time/batch = 0.0773s	
1268/5250 (epoch 12.076), train_loss = 1.52800067, grad/param norm = 7.4904e-02, time/batch = 0.0767s	
1269/5250 (epoch 12.086), train_loss = 1.47887750, grad/param norm = 7.9343e-02, time/batch = 0.0773s	
1270/5250 (epoch 12.095), train_loss = 1.53601182, grad/param norm = 9.3493e-02, time/batch = 0.0770s	
1271/5250 (epoch 12.105), train_loss = 1.54500081, grad/param norm = 8.9763e-02, time/batch = 0.0798s	
1272/5250 (epoch 12.114), train_loss = 1.52363726, grad/param norm = 9.3865e-02, time/batch = 0.0778s	
1273/5250 (epoch 12.124), train_loss = 1.53693133, grad/param norm = 9.2884e-02, time/batch = 0.0770s	
1274/5250 (epoch 12.133), train_loss = 1.52691275, grad/param norm = 8.4962e-02, time/batch = 0.0769s	
1275/5250 (epoch 12.143), train_loss = 1.50264605, grad/param norm = 8.3371e-02, time/batch = 0.0773s	
1276/5250 (epoch 12.152), train_loss = 1.50448612, grad/param norm = 8.4204e-02, time/batch = 0.0772s	
1277/5250 (epoch 12.162), train_loss = 1.53967219, grad/param norm = 1.0271e-01, time/batch = 0.0768s	
1278/5250 (epoch 12.171), train_loss = 1.55637747, grad/param norm = 1.0679e-01, time/batch = 0.0771s	
1279/5250 (epoch 12.181), train_loss = 1.55300100, grad/param norm = 1.0767e-01, time/batch = 0.0775s	
1280/5250 (epoch 12.190), train_loss = 1.53939297, grad/param norm = 9.5703e-02, time/batch = 0.0771s	
1281/5250 (epoch 12.200), train_loss = 1.52992201, grad/param norm = 8.2557e-02, time/batch = 0.0800s	
1282/5250 (epoch 12.210), train_loss = 1.52429503, grad/param norm = 8.3810e-02, time/batch = 0.0771s	
1283/5250 (epoch 12.219), train_loss = 1.57497868, grad/param norm = 8.9202e-02, time/batch = 0.0776s	
1284/5250 (epoch 12.229), train_loss = 1.53579450, grad/param norm = 9.5371e-02, time/batch = 0.0771s	
1285/5250 (epoch 12.238), train_loss = 1.53490880, grad/param norm = 1.1483e-01, time/batch = 0.0771s	
1286/5250 (epoch 12.248), train_loss = 1.54737448, grad/param norm = 1.2142e-01, time/batch = 0.0773s	
1287/5250 (epoch 12.257), train_loss = 1.52086533, grad/param norm = 1.1316e-01, time/batch = 0.0763s	
1288/5250 (epoch 12.267), train_loss = 1.52016766, grad/param norm = 1.0702e-01, time/batch = 0.0765s	
1289/5250 (epoch 12.276), train_loss = 1.52357742, grad/param norm = 1.0228e-01, time/batch = 0.0778s	
1290/5250 (epoch 12.286), train_loss = 1.49394558, grad/param norm = 9.2201e-02, time/batch = 0.0770s	
1291/5250 (epoch 12.295), train_loss = 1.52971525, grad/param norm = 9.2792e-02, time/batch = 0.0790s	
1292/5250 (epoch 12.305), train_loss = 1.53462117, grad/param norm = 9.8344e-02, time/batch = 0.0771s	
1293/5250 (epoch 12.314), train_loss = 1.50528157, grad/param norm = 1.0621e-01, time/batch = 0.0768s	
1294/5250 (epoch 12.324), train_loss = 1.54175333, grad/param norm = 1.2485e-01, time/batch = 0.0775s	
1295/5250 (epoch 12.333), train_loss = 1.54500287, grad/param norm = 1.3530e-01, time/batch = 0.0773s	
1296/5250 (epoch 12.343), train_loss = 1.54746005, grad/param norm = 1.2887e-01, time/batch = 0.0776s	
1297/5250 (epoch 12.352), train_loss = 1.55271161, grad/param norm = 1.3413e-01, time/batch = 0.0772s	
1298/5250 (epoch 12.362), train_loss = 1.54604703, grad/param norm = 1.2067e-01, time/batch = 0.0766s	
1299/5250 (epoch 12.371), train_loss = 1.51676183, grad/param norm = 1.0817e-01, time/batch = 0.0771s	
1300/5250 (epoch 12.381), train_loss = 1.53198138, grad/param norm = 1.2459e-01, time/batch = 0.0773s	
1301/5250 (epoch 12.390), train_loss = 1.55203360, grad/param norm = 1.3723e-01, time/batch = 0.0789s	
1302/5250 (epoch 12.400), train_loss = 1.52773196, grad/param norm = 1.2068e-01, time/batch = 0.0769s	
1303/5250 (epoch 12.410), train_loss = 1.55342101, grad/param norm = 1.0050e-01, time/batch = 0.0767s	
1304/5250 (epoch 12.419), train_loss = 1.54233086, grad/param norm = 1.1314e-01, time/batch = 0.0771s	
1305/5250 (epoch 12.429), train_loss = 1.53971052, grad/param norm = 1.0033e-01, time/batch = 0.0777s	
1306/5250 (epoch 12.438), train_loss = 1.55537437, grad/param norm = 8.0212e-02, time/batch = 0.0773s	
1307/5250 (epoch 12.448), train_loss = 1.50927569, grad/param norm = 7.4105e-02, time/batch = 0.0768s	
1308/5250 (epoch 12.457), train_loss = 1.50376083, grad/param norm = 8.5023e-02, time/batch = 0.0766s	
1309/5250 (epoch 12.467), train_loss = 1.51357145, grad/param norm = 7.7800e-02, time/batch = 0.0771s	
1310/5250 (epoch 12.476), train_loss = 1.51668450, grad/param norm = 7.6945e-02, time/batch = 0.0770s	
1311/5250 (epoch 12.486), train_loss = 1.53005137, grad/param norm = 8.5924e-02, time/batch = 0.0795s	
1312/5250 (epoch 12.495), train_loss = 1.53309149, grad/param norm = 8.7479e-02, time/batch = 0.0771s	
1313/5250 (epoch 12.505), train_loss = 1.54163244, grad/param norm = 8.1436e-02, time/batch = 0.0770s	
1314/5250 (epoch 12.514), train_loss = 1.53626945, grad/param norm = 8.0083e-02, time/batch = 0.0770s	
1315/5250 (epoch 12.524), train_loss = 1.50783574, grad/param norm = 7.8180e-02, time/batch = 0.0768s	
1316/5250 (epoch 12.533), train_loss = 1.51728326, grad/param norm = 7.8072e-02, time/batch = 0.0779s	
1317/5250 (epoch 12.543), train_loss = 1.50386532, grad/param norm = 7.4522e-02, time/batch = 0.0769s	
1318/5250 (epoch 12.552), train_loss = 1.51224781, grad/param norm = 7.8296e-02, time/batch = 0.0770s	
1319/5250 (epoch 12.562), train_loss = 1.52594285, grad/param norm = 9.6904e-02, time/batch = 0.0775s	
1320/5250 (epoch 12.571), train_loss = 1.52986684, grad/param norm = 9.9843e-02, time/batch = 0.0770s	
1321/5250 (epoch 12.581), train_loss = 1.55580344, grad/param norm = 9.6066e-02, time/batch = 0.0789s	
1322/5250 (epoch 12.590), train_loss = 1.53288906, grad/param norm = 9.4246e-02, time/batch = 0.0776s	
1323/5250 (epoch 12.600), train_loss = 1.54693049, grad/param norm = 9.3051e-02, time/batch = 0.0771s	
1324/5250 (epoch 12.610), train_loss = 1.54026628, grad/param norm = 9.6786e-02, time/batch = 0.0769s	
1325/5250 (epoch 12.619), train_loss = 1.52035271, grad/param norm = 1.0013e-01, time/batch = 0.0769s	
1326/5250 (epoch 12.629), train_loss = 1.55387552, grad/param norm = 1.0351e-01, time/batch = 0.0771s	
1327/5250 (epoch 12.638), train_loss = 1.51961770, grad/param norm = 1.0171e-01, time/batch = 0.0765s	
1328/5250 (epoch 12.648), train_loss = 1.53246100, grad/param norm = 1.0208e-01, time/batch = 0.0768s	
1329/5250 (epoch 12.657), train_loss = 1.51421406, grad/param norm = 1.1382e-01, time/batch = 0.0772s	
1330/5250 (epoch 12.667), train_loss = 1.53436842, grad/param norm = 1.2197e-01, time/batch = 0.0772s	
1331/5250 (epoch 12.676), train_loss = 1.52967988, grad/param norm = 1.2401e-01, time/batch = 0.0789s	
1332/5250 (epoch 12.686), train_loss = 1.56239872, grad/param norm = 1.2661e-01, time/batch = 0.0771s	
1333/5250 (epoch 12.695), train_loss = 1.54059686, grad/param norm = 1.3947e-01, time/batch = 0.0776s	
1334/5250 (epoch 12.705), train_loss = 1.52871389, grad/param norm = 1.3929e-01, time/batch = 0.0771s	
1335/5250 (epoch 12.714), train_loss = 1.54619044, grad/param norm = 1.2277e-01, time/batch = 0.0768s	
1336/5250 (epoch 12.724), train_loss = 1.52170984, grad/param norm = 9.7879e-02, time/batch = 0.0775s	
1337/5250 (epoch 12.733), train_loss = 1.50411199, grad/param norm = 8.3105e-02, time/batch = 0.0770s	
1338/5250 (epoch 12.743), train_loss = 1.51353484, grad/param norm = 8.5030e-02, time/batch = 0.0768s	
1339/5250 (epoch 12.752), train_loss = 1.51977806, grad/param norm = 7.9438e-02, time/batch = 0.0780s	
1340/5250 (epoch 12.762), train_loss = 1.50773820, grad/param norm = 8.8113e-02, time/batch = 0.0771s	
1341/5250 (epoch 12.771), train_loss = 1.50663345, grad/param norm = 9.7359e-02, time/batch = 0.0798s	
1342/5250 (epoch 12.781), train_loss = 1.52180512, grad/param norm = 9.1556e-02, time/batch = 0.0769s	
1343/5250 (epoch 12.790), train_loss = 1.54302289, grad/param norm = 8.5102e-02, time/batch = 0.0769s	
1344/5250 (epoch 12.800), train_loss = 1.53147407, grad/param norm = 7.9585e-02, time/batch = 0.0774s	
1345/5250 (epoch 12.810), train_loss = 1.52596135, grad/param norm = 8.5288e-02, time/batch = 0.0770s	
1346/5250 (epoch 12.819), train_loss = 1.52573981, grad/param norm = 9.0490e-02, time/batch = 0.0774s	
1347/5250 (epoch 12.829), train_loss = 1.52770134, grad/param norm = 1.0378e-01, time/batch = 0.0762s	
1348/5250 (epoch 12.838), train_loss = 1.51696146, grad/param norm = 1.0470e-01, time/batch = 0.0766s	
1349/5250 (epoch 12.848), train_loss = 1.50697999, grad/param norm = 1.0507e-01, time/batch = 0.0775s	
1350/5250 (epoch 12.857), train_loss = 1.52950755, grad/param norm = 1.1601e-01, time/batch = 0.0779s	
1351/5250 (epoch 12.867), train_loss = 1.51253182, grad/param norm = 1.1449e-01, time/batch = 0.0790s	
1352/5250 (epoch 12.876), train_loss = 1.54077256, grad/param norm = 1.0855e-01, time/batch = 0.0770s	
1353/5250 (epoch 12.886), train_loss = 1.50918667, grad/param norm = 9.8186e-02, time/batch = 0.0769s	
1354/5250 (epoch 12.895), train_loss = 1.54336709, grad/param norm = 9.4319e-02, time/batch = 0.0767s	
1355/5250 (epoch 12.905), train_loss = 1.53046082, grad/param norm = 9.2613e-02, time/batch = 0.0772s	
1356/5250 (epoch 12.914), train_loss = 1.54977553, grad/param norm = 1.1079e-01, time/batch = 0.0775s	
1357/5250 (epoch 12.924), train_loss = 1.55127980, grad/param norm = 1.1599e-01, time/batch = 0.0769s	
1358/5250 (epoch 12.933), train_loss = 1.52637531, grad/param norm = 1.0491e-01, time/batch = 0.0768s	
1359/5250 (epoch 12.943), train_loss = 1.55907822, grad/param norm = 1.0383e-01, time/batch = 0.0772s	
1360/5250 (epoch 12.952), train_loss = 1.55489502, grad/param norm = 1.1371e-01, time/batch = 0.0768s	
1361/5250 (epoch 12.962), train_loss = 1.53723695, grad/param norm = 1.1273e-01, time/batch = 0.0795s	
1362/5250 (epoch 12.971), train_loss = 1.51780067, grad/param norm = 1.0612e-01, time/batch = 0.0771s	
1363/5250 (epoch 12.981), train_loss = 1.55084626, grad/param norm = 1.0294e-01, time/batch = 0.0768s	
1364/5250 (epoch 12.990), train_loss = 1.54790073, grad/param norm = 9.6936e-02, time/batch = 0.0770s	
decayed learning rate by a factor 0.97 to 0.00177058562	
1365/5250 (epoch 13.000), train_loss = 1.52071430, grad/param norm = 9.2420e-02, time/batch = 0.0771s	
1366/5250 (epoch 13.010), train_loss = 1.67737066, grad/param norm = 8.7426e-02, time/batch = 0.0779s	
1367/5250 (epoch 13.019), train_loss = 1.51582836, grad/param norm = 9.0578e-02, time/batch = 0.0771s	
1368/5250 (epoch 13.029), train_loss = 1.51989800, grad/param norm = 9.0204e-02, time/batch = 0.0769s	
1369/5250 (epoch 13.038), train_loss = 1.51385421, grad/param norm = 1.0343e-01, time/batch = 0.0771s	
1370/5250 (epoch 13.048), train_loss = 1.50385063, grad/param norm = 9.5307e-02, time/batch = 0.0771s	
1371/5250 (epoch 13.057), train_loss = 1.51265963, grad/param norm = 8.3441e-02, time/batch = 0.0789s	
1372/5250 (epoch 13.067), train_loss = 1.51027612, grad/param norm = 7.9322e-02, time/batch = 0.0778s	
1373/5250 (epoch 13.076), train_loss = 1.50151401, grad/param norm = 7.3555e-02, time/batch = 0.0770s	
1374/5250 (epoch 13.086), train_loss = 1.45291405, grad/param norm = 7.0747e-02, time/batch = 0.0770s	
1375/5250 (epoch 13.095), train_loss = 1.50737732, grad/param norm = 8.7380e-02, time/batch = 0.0769s	
1376/5250 (epoch 13.105), train_loss = 1.52023647, grad/param norm = 9.5445e-02, time/batch = 0.0775s	
1377/5250 (epoch 13.114), train_loss = 1.50064846, grad/param norm = 1.0646e-01, time/batch = 0.0814s	
1378/5250 (epoch 13.124), train_loss = 1.51200756, grad/param norm = 9.8067e-02, time/batch = 0.0776s	
1379/5250 (epoch 13.133), train_loss = 1.50082107, grad/param norm = 7.9651e-02, time/batch = 0.0775s	
1380/5250 (epoch 13.143), train_loss = 1.47638210, grad/param norm = 7.8496e-02, time/batch = 0.0771s	
1381/5250 (epoch 13.152), train_loss = 1.47802819, grad/param norm = 7.4434e-02, time/batch = 0.0798s	
1382/5250 (epoch 13.162), train_loss = 1.51029562, grad/param norm = 8.1845e-02, time/batch = 0.0769s	
1383/5250 (epoch 13.171), train_loss = 1.52315098, grad/param norm = 8.6128e-02, time/batch = 0.0777s	
1384/5250 (epoch 13.181), train_loss = 1.52596217, grad/param norm = 9.9460e-02, time/batch = 0.0769s	
1385/5250 (epoch 13.190), train_loss = 1.51672788, grad/param norm = 1.0234e-01, time/batch = 0.0769s	
1386/5250 (epoch 13.200), train_loss = 1.50825297, grad/param norm = 9.3809e-02, time/batch = 0.0771s	
1387/5250 (epoch 13.210), train_loss = 1.50124829, grad/param norm = 9.3236e-02, time/batch = 0.0767s	
1388/5250 (epoch 13.219), train_loss = 1.55227767, grad/param norm = 9.7980e-02, time/batch = 0.0765s	
1389/5250 (epoch 13.229), train_loss = 1.51017825, grad/param norm = 9.8832e-02, time/batch = 0.0779s	
1390/5250 (epoch 13.238), train_loss = 1.50804947, grad/param norm = 1.0231e-01, time/batch = 0.0773s	
1391/5250 (epoch 13.248), train_loss = 1.51847027, grad/param norm = 1.0215e-01, time/batch = 0.0790s	
1392/5250 (epoch 13.257), train_loss = 1.49300166, grad/param norm = 9.7664e-02, time/batch = 0.0772s	
1393/5250 (epoch 13.267), train_loss = 1.49185412, grad/param norm = 9.2743e-02, time/batch = 0.0769s	
1394/5250 (epoch 13.276), train_loss = 1.49531980, grad/param norm = 9.3649e-02, time/batch = 0.0776s	
1395/5250 (epoch 13.286), train_loss = 1.47187218, grad/param norm = 1.0170e-01, time/batch = 0.0771s	
1396/5250 (epoch 13.295), train_loss = 1.50820536, grad/param norm = 1.1258e-01, time/batch = 0.0772s	
1397/5250 (epoch 13.305), train_loss = 1.51156821, grad/param norm = 1.1648e-01, time/batch = 0.0766s	
1398/5250 (epoch 13.314), train_loss = 1.48220753, grad/param norm = 1.1004e-01, time/batch = 0.0769s	
1399/5250 (epoch 13.324), train_loss = 1.50947499, grad/param norm = 1.0680e-01, time/batch = 0.0773s	
1400/5250 (epoch 13.333), train_loss = 1.50869780, grad/param norm = 1.0723e-01, time/batch = 0.0775s	
1401/5250 (epoch 13.343), train_loss = 1.51126588, grad/param norm = 1.0732e-01, time/batch = 0.0790s	
1402/5250 (epoch 13.352), train_loss = 1.52119435, grad/param norm = 1.1466e-01, time/batch = 0.0770s	
1403/5250 (epoch 13.362), train_loss = 1.51542396, grad/param norm = 1.0321e-01, time/batch = 0.0771s	
1404/5250 (epoch 13.371), train_loss = 1.48798017, grad/param norm = 9.6735e-02, time/batch = 0.0765s	
1405/5250 (epoch 13.381), train_loss = 1.50121774, grad/param norm = 1.0150e-01, time/batch = 0.0774s	
1406/5250 (epoch 13.390), train_loss = 1.51850321, grad/param norm = 1.1556e-01, time/batch = 0.0776s	
1407/5250 (epoch 13.400), train_loss = 1.50002836, grad/param norm = 1.0764e-01, time/batch = 0.0768s	
1408/5250 (epoch 13.410), train_loss = 1.52560697, grad/param norm = 1.0122e-01, time/batch = 0.0764s	
1409/5250 (epoch 13.419), train_loss = 1.51192049, grad/param norm = 1.0079e-01, time/batch = 0.0772s	
1410/5250 (epoch 13.429), train_loss = 1.51302759, grad/param norm = 9.7594e-02, time/batch = 0.0770s	
1411/5250 (epoch 13.438), train_loss = 1.53254428, grad/param norm = 8.8739e-02, time/batch = 0.0803s	
1412/5250 (epoch 13.448), train_loss = 1.48778951, grad/param norm = 8.9166e-02, time/batch = 0.0771s	
1413/5250 (epoch 13.457), train_loss = 1.48119486, grad/param norm = 7.7499e-02, time/batch = 0.0769s	
1414/5250 (epoch 13.467), train_loss = 1.49066578, grad/param norm = 7.0406e-02, time/batch = 0.0769s	
1415/5250 (epoch 13.476), train_loss = 1.49118587, grad/param norm = 6.9517e-02, time/batch = 0.0769s	
1416/5250 (epoch 13.486), train_loss = 1.50452329, grad/param norm = 7.8236e-02, time/batch = 0.0779s	
1417/5250 (epoch 13.495), train_loss = 1.50878782, grad/param norm = 8.7401e-02, time/batch = 0.0789s	
1418/5250 (epoch 13.505), train_loss = 1.52009352, grad/param norm = 8.8477e-02, time/batch = 0.0774s	
1419/5250 (epoch 13.514), train_loss = 1.51617126, grad/param norm = 9.2463e-02, time/batch = 0.0774s	
1420/5250 (epoch 13.524), train_loss = 1.48855278, grad/param norm = 8.3731e-02, time/batch = 0.0771s	
1421/5250 (epoch 13.533), train_loss = 1.49536381, grad/param norm = 7.8474e-02, time/batch = 0.0788s	
1422/5250 (epoch 13.543), train_loss = 1.47972221, grad/param norm = 7.5635e-02, time/batch = 0.0776s	
1423/5250 (epoch 13.552), train_loss = 1.48875896, grad/param norm = 8.1314e-02, time/batch = 0.0772s	
1424/5250 (epoch 13.562), train_loss = 1.50206284, grad/param norm = 9.8687e-02, time/batch = 0.0770s	
1425/5250 (epoch 13.571), train_loss = 1.50591223, grad/param norm = 1.0392e-01, time/batch = 0.0771s	
1426/5250 (epoch 13.581), train_loss = 1.53364994, grad/param norm = 1.0406e-01, time/batch = 0.0774s	
1427/5250 (epoch 13.590), train_loss = 1.50988302, grad/param norm = 1.0636e-01, time/batch = 0.0769s	
1428/5250 (epoch 13.600), train_loss = 1.53043252, grad/param norm = 1.0546e-01, time/batch = 0.0768s	
1429/5250 (epoch 13.610), train_loss = 1.52214356, grad/param norm = 1.1514e-01, time/batch = 0.0777s	
1430/5250 (epoch 13.619), train_loss = 1.50571533, grad/param norm = 1.0774e-01, time/batch = 0.0769s	
1431/5250 (epoch 13.629), train_loss = 1.52742664, grad/param norm = 9.7371e-02, time/batch = 0.0790s	
1432/5250 (epoch 13.638), train_loss = 1.49498128, grad/param norm = 9.7293e-02, time/batch = 0.0769s	
1433/5250 (epoch 13.648), train_loss = 1.50912581, grad/param norm = 1.0816e-01, time/batch = 0.0777s	
1434/5250 (epoch 13.657), train_loss = 1.49638314, grad/param norm = 1.2512e-01, time/batch = 0.0773s	
1435/5250 (epoch 13.667), train_loss = 1.51891302, grad/param norm = 1.3750e-01, time/batch = 0.0772s	
1436/5250 (epoch 13.676), train_loss = 1.51888576, grad/param norm = 1.3802e-01, time/batch = 0.0772s	
1437/5250 (epoch 13.686), train_loss = 1.53804158, grad/param norm = 1.1780e-01, time/batch = 0.0768s	
1438/5250 (epoch 13.695), train_loss = 1.50679125, grad/param norm = 9.7299e-02, time/batch = 0.0764s	
1439/5250 (epoch 13.705), train_loss = 1.48529605, grad/param norm = 8.2097e-02, time/batch = 0.0777s	
1440/5250 (epoch 13.714), train_loss = 1.51430840, grad/param norm = 7.2713e-02, time/batch = 0.0772s	
1441/5250 (epoch 13.724), train_loss = 1.49319726, grad/param norm = 6.6603e-02, time/batch = 0.0790s	
1442/5250 (epoch 13.733), train_loss = 1.47954379, grad/param norm = 7.3171e-02, time/batch = 0.0772s	
1443/5250 (epoch 13.743), train_loss = 1.48998233, grad/param norm = 8.4669e-02, time/batch = 0.0771s	
1444/5250 (epoch 13.752), train_loss = 1.49665742, grad/param norm = 7.4402e-02, time/batch = 0.0773s	
1445/5250 (epoch 13.762), train_loss = 1.48298742, grad/param norm = 7.7030e-02, time/batch = 0.0771s	
1446/5250 (epoch 13.771), train_loss = 1.48172670, grad/param norm = 8.5493e-02, time/batch = 0.0774s	
1447/5250 (epoch 13.781), train_loss = 1.49833472, grad/param norm = 8.3721e-02, time/batch = 0.0767s	
1448/5250 (epoch 13.790), train_loss = 1.51880852, grad/param norm = 7.8358e-02, time/batch = 0.0765s	
1449/5250 (epoch 13.800), train_loss = 1.50901474, grad/param norm = 8.0596e-02, time/batch = 0.0772s	
1450/5250 (epoch 13.810), train_loss = 1.50183989, grad/param norm = 7.7094e-02, time/batch = 0.0773s	
1451/5250 (epoch 13.819), train_loss = 1.50144451, grad/param norm = 7.3813e-02, time/batch = 0.0788s	
1452/5250 (epoch 13.829), train_loss = 1.49974945, grad/param norm = 7.7001e-02, time/batch = 0.0770s	
1453/5250 (epoch 13.838), train_loss = 1.48497883, grad/param norm = 7.8207e-02, time/batch = 0.0770s	
1454/5250 (epoch 13.848), train_loss = 1.47455671, grad/param norm = 7.3359e-02, time/batch = 0.0771s	
1455/5250 (epoch 13.857), train_loss = 1.49545577, grad/param norm = 7.2331e-02, time/batch = 0.0773s	
1456/5250 (epoch 13.867), train_loss = 1.47950309, grad/param norm = 6.7594e-02, time/batch = 0.0777s	
1457/5250 (epoch 13.876), train_loss = 1.50794755, grad/param norm = 7.0218e-02, time/batch = 0.0767s	
1458/5250 (epoch 13.886), train_loss = 1.48113380, grad/param norm = 7.1875e-02, time/batch = 0.0767s	
1459/5250 (epoch 13.895), train_loss = 1.51769840, grad/param norm = 8.0299e-02, time/batch = 0.0771s	
1460/5250 (epoch 13.905), train_loss = 1.50845202, grad/param norm = 1.0044e-01, time/batch = 0.0770s	
1461/5250 (epoch 13.914), train_loss = 1.53835407, grad/param norm = 1.3988e-01, time/batch = 0.0797s	
1462/5250 (epoch 13.924), train_loss = 1.54613812, grad/param norm = 1.5384e-01, time/batch = 0.0773s	
1463/5250 (epoch 13.933), train_loss = 1.51125814, grad/param norm = 1.1733e-01, time/batch = 0.0771s	
1464/5250 (epoch 13.943), train_loss = 1.54334796, grad/param norm = 1.1570e-01, time/batch = 0.0768s	
1465/5250 (epoch 13.952), train_loss = 1.53874638, grad/param norm = 1.2694e-01, time/batch = 0.0767s	
1466/5250 (epoch 13.962), train_loss = 1.51713393, grad/param norm = 1.1422e-01, time/batch = 0.0778s	
1467/5250 (epoch 13.971), train_loss = 1.49191505, grad/param norm = 9.0934e-02, time/batch = 0.0768s	
1468/5250 (epoch 13.981), train_loss = 1.52160113, grad/param norm = 7.8531e-02, time/batch = 0.0766s	
1469/5250 (epoch 13.990), train_loss = 1.52214965, grad/param norm = 8.3796e-02, time/batch = 0.0771s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
1470/5250 (epoch 14.000), train_loss = 1.49670753, grad/param norm = 9.0944e-02, time/batch = 0.0770s	
1471/5250 (epoch 14.010), train_loss = 1.65865290, grad/param norm = 9.2897e-02, time/batch = 0.0794s	
1472/5250 (epoch 14.019), train_loss = 1.49113150, grad/param norm = 9.0994e-02, time/batch = 0.0777s	
1473/5250 (epoch 14.029), train_loss = 1.49793913, grad/param norm = 9.2319e-02, time/batch = 0.0771s	
1474/5250 (epoch 14.038), train_loss = 1.49281865, grad/param norm = 9.6679e-02, time/batch = 0.0769s	
1475/5250 (epoch 14.048), train_loss = 1.48003941, grad/param norm = 1.0575e-01, time/batch = 0.0768s	
1476/5250 (epoch 14.057), train_loss = 1.49276581, grad/param norm = 9.8503e-02, time/batch = 0.0772s	
1477/5250 (epoch 14.067), train_loss = 1.49047904, grad/param norm = 9.1264e-02, time/batch = 0.0770s	
1478/5250 (epoch 14.076), train_loss = 1.48259657, grad/param norm = 8.3338e-02, time/batch = 0.0770s	
1479/5250 (epoch 14.086), train_loss = 1.43416970, grad/param norm = 8.6885e-02, time/batch = 0.0775s	
1480/5250 (epoch 14.095), train_loss = 1.48869887, grad/param norm = 9.7955e-02, time/batch = 0.0770s	
1481/5250 (epoch 14.105), train_loss = 1.49796200, grad/param norm = 9.0665e-02, time/batch = 0.0789s	
1482/5250 (epoch 14.114), train_loss = 1.47465423, grad/param norm = 8.5698e-02, time/batch = 0.0769s	
1483/5250 (epoch 14.124), train_loss = 1.48465379, grad/param norm = 7.4773e-02, time/batch = 0.0775s	
1484/5250 (epoch 14.133), train_loss = 1.47701568, grad/param norm = 7.4381e-02, time/batch = 0.0769s	
1485/5250 (epoch 14.143), train_loss = 1.45521812, grad/param norm = 8.8281e-02, time/batch = 0.0767s	
1486/5250 (epoch 14.152), train_loss = 1.46059239, grad/param norm = 9.6469e-02, time/batch = 0.0774s	
1487/5250 (epoch 14.162), train_loss = 1.49401100, grad/param norm = 1.1304e-01, time/batch = 0.0767s	
1488/5250 (epoch 14.171), train_loss = 1.50911190, grad/param norm = 1.1051e-01, time/batch = 0.0782s	
1489/5250 (epoch 14.181), train_loss = 1.50322614, grad/param norm = 9.7432e-02, time/batch = 0.0788s	
1490/5250 (epoch 14.190), train_loss = 1.48734115, grad/param norm = 7.9616e-02, time/batch = 0.0773s	
1491/5250 (epoch 14.200), train_loss = 1.48129467, grad/param norm = 8.0400e-02, time/batch = 0.0791s	
1492/5250 (epoch 14.210), train_loss = 1.47799779, grad/param norm = 9.1553e-02, time/batch = 0.0770s	
1493/5250 (epoch 14.219), train_loss = 1.52984745, grad/param norm = 9.8668e-02, time/batch = 0.0770s	
1494/5250 (epoch 14.229), train_loss = 1.48640666, grad/param norm = 9.8153e-02, time/batch = 0.0772s	
1495/5250 (epoch 14.238), train_loss = 1.48795726, grad/param norm = 1.0702e-01, time/batch = 0.0772s	
1496/5250 (epoch 14.248), train_loss = 1.49645068, grad/param norm = 1.0588e-01, time/batch = 0.0775s	
1497/5250 (epoch 14.257), train_loss = 1.46949564, grad/param norm = 8.7235e-02, time/batch = 0.0767s	
1498/5250 (epoch 14.267), train_loss = 1.46568356, grad/param norm = 7.3911e-02, time/batch = 0.0766s	
1499/5250 (epoch 14.276), train_loss = 1.46751002, grad/param norm = 6.8386e-02, time/batch = 0.0772s	
1500/5250 (epoch 14.286), train_loss = 1.44396337, grad/param norm = 7.1327e-02, time/batch = 0.0775s	
1501/5250 (epoch 14.295), train_loss = 1.47974853, grad/param norm = 7.8151e-02, time/batch = 0.0790s	
1502/5250 (epoch 14.305), train_loss = 1.48002724, grad/param norm = 8.2236e-02, time/batch = 0.0769s	
1503/5250 (epoch 14.314), train_loss = 1.45403860, grad/param norm = 7.5745e-02, time/batch = 0.0767s	
1504/5250 (epoch 14.324), train_loss = 1.47802687, grad/param norm = 7.4804e-02, time/batch = 0.0771s	
1505/5250 (epoch 14.333), train_loss = 1.48006157, grad/param norm = 7.4385e-02, time/batch = 0.0774s	
1506/5250 (epoch 14.343), train_loss = 1.48403974, grad/param norm = 8.2292e-02, time/batch = 0.0774s	
1507/5250 (epoch 14.352), train_loss = 1.49731418, grad/param norm = 1.0370e-01, time/batch = 0.0768s	
1508/5250 (epoch 14.362), train_loss = 1.49679181, grad/param norm = 1.0381e-01, time/batch = 0.0767s	
1509/5250 (epoch 14.371), train_loss = 1.46970221, grad/param norm = 1.0429e-01, time/batch = 0.0773s	
1510/5250 (epoch 14.381), train_loss = 1.48377681, grad/param norm = 1.1364e-01, time/batch = 0.0770s	
1511/5250 (epoch 14.390), train_loss = 1.49988970, grad/param norm = 1.2774e-01, time/batch = 0.0803s	
1512/5250 (epoch 14.400), train_loss = 1.48208390, grad/param norm = 1.1541e-01, time/batch = 0.0771s	
1513/5250 (epoch 14.410), train_loss = 1.50259824, grad/param norm = 9.2615e-02, time/batch = 0.0770s	
1514/5250 (epoch 14.419), train_loss = 1.48973984, grad/param norm = 9.2752e-02, time/batch = 0.0770s	
1515/5250 (epoch 14.429), train_loss = 1.49049037, grad/param norm = 9.4235e-02, time/batch = 0.0770s	
1516/5250 (epoch 14.438), train_loss = 1.50923402, grad/param norm = 8.1756e-02, time/batch = 0.0777s	
1517/5250 (epoch 14.448), train_loss = 1.46351137, grad/param norm = 7.3759e-02, time/batch = 0.0771s	
1518/5250 (epoch 14.457), train_loss = 1.45853112, grad/param norm = 7.8531e-02, time/batch = 0.0768s	
1519/5250 (epoch 14.467), train_loss = 1.47070018, grad/param norm = 7.8192e-02, time/batch = 0.0771s	
1520/5250 (epoch 14.476), train_loss = 1.47277686, grad/param norm = 7.7931e-02, time/batch = 0.0769s	
1521/5250 (epoch 14.486), train_loss = 1.48713049, grad/param norm = 8.6317e-02, time/batch = 0.0789s	
1522/5250 (epoch 14.495), train_loss = 1.48928992, grad/param norm = 8.6726e-02, time/batch = 0.0777s	
1523/5250 (epoch 14.505), train_loss = 1.49889805, grad/param norm = 7.8775e-02, time/batch = 0.0771s	
1524/5250 (epoch 14.514), train_loss = 1.49304633, grad/param norm = 7.9498e-02, time/batch = 0.0769s	
1525/5250 (epoch 14.524), train_loss = 1.46453809, grad/param norm = 7.5158e-02, time/batch = 0.0772s	
1526/5250 (epoch 14.533), train_loss = 1.47297873, grad/param norm = 7.6888e-02, time/batch = 0.0772s	
1527/5250 (epoch 14.543), train_loss = 1.45946874, grad/param norm = 8.0210e-02, time/batch = 0.0767s	
1528/5250 (epoch 14.552), train_loss = 1.46818081, grad/param norm = 8.2593e-02, time/batch = 0.0767s	
1529/5250 (epoch 14.562), train_loss = 1.47754385, grad/param norm = 9.0776e-02, time/batch = 0.0773s	
1530/5250 (epoch 14.571), train_loss = 1.48328142, grad/param norm = 9.9227e-02, time/batch = 0.0770s	
1531/5250 (epoch 14.581), train_loss = 1.51403160, grad/param norm = 9.8620e-02, time/batch = 0.0789s	
1532/5250 (epoch 14.590), train_loss = 1.48830013, grad/param norm = 9.4068e-02, time/batch = 0.0769s	
1533/5250 (epoch 14.600), train_loss = 1.50769891, grad/param norm = 8.9637e-02, time/batch = 0.0772s	
1534/5250 (epoch 14.610), train_loss = 1.49831960, grad/param norm = 9.5960e-02, time/batch = 0.0771s	
1535/5250 (epoch 14.619), train_loss = 1.48282497, grad/param norm = 9.6435e-02, time/batch = 0.0771s	
1536/5250 (epoch 14.629), train_loss = 1.50581898, grad/param norm = 9.8099e-02, time/batch = 0.0773s	
1537/5250 (epoch 14.638), train_loss = 1.47721922, grad/param norm = 1.0540e-01, time/batch = 0.0766s	
1538/5250 (epoch 14.648), train_loss = 1.49061466, grad/param norm = 1.1781e-01, time/batch = 0.0766s	
1539/5250 (epoch 14.657), train_loss = 1.47657505, grad/param norm = 1.1447e-01, time/batch = 0.0780s	
1540/5250 (epoch 14.667), train_loss = 1.48623932, grad/param norm = 1.0093e-01, time/batch = 0.0771s	
1541/5250 (epoch 14.676), train_loss = 1.48193547, grad/param norm = 9.1161e-02, time/batch = 0.0796s	
1542/5250 (epoch 14.686), train_loss = 1.50625504, grad/param norm = 8.4380e-02, time/batch = 0.0769s	
1543/5250 (epoch 14.695), train_loss = 1.48314669, grad/param norm = 8.9589e-02, time/batch = 0.0768s	
1544/5250 (epoch 14.705), train_loss = 1.46585271, grad/param norm = 8.5574e-02, time/batch = 0.0773s	
1545/5250 (epoch 14.714), train_loss = 1.49610525, grad/param norm = 8.4610e-02, time/batch = 0.0773s	
1546/5250 (epoch 14.724), train_loss = 1.47600331, grad/param norm = 7.0090e-02, time/batch = 0.0773s	
1547/5250 (epoch 14.733), train_loss = 1.45993529, grad/param norm = 7.2709e-02, time/batch = 0.0767s	
1548/5250 (epoch 14.743), train_loss = 1.47143960, grad/param norm = 8.7469e-02, time/batch = 0.0767s	
1549/5250 (epoch 14.752), train_loss = 1.47712286, grad/param norm = 7.9951e-02, time/batch = 0.0773s	
1550/5250 (epoch 14.762), train_loss = 1.46356280, grad/param norm = 7.8032e-02, time/batch = 0.0775s	
1551/5250 (epoch 14.771), train_loss = 1.46200251, grad/param norm = 8.5882e-02, time/batch = 0.0790s	
1552/5250 (epoch 14.781), train_loss = 1.48003471, grad/param norm = 8.5954e-02, time/batch = 0.0769s	
1553/5250 (epoch 14.790), train_loss = 1.50016018, grad/param norm = 8.8889e-02, time/batch = 0.0771s	
1554/5250 (epoch 14.800), train_loss = 1.48966178, grad/param norm = 8.5295e-02, time/batch = 0.0768s	
1555/5250 (epoch 14.810), train_loss = 1.48506570, grad/param norm = 8.4922e-02, time/batch = 0.0773s	
1556/5250 (epoch 14.819), train_loss = 1.48448315, grad/param norm = 8.5860e-02, time/batch = 0.0774s	
1557/5250 (epoch 14.829), train_loss = 1.48080898, grad/param norm = 8.7708e-02, time/batch = 0.0766s	
1558/5250 (epoch 14.838), train_loss = 1.46851112, grad/param norm = 9.4308e-02, time/batch = 0.0766s	
1559/5250 (epoch 14.848), train_loss = 1.45749196, grad/param norm = 7.7792e-02, time/batch = 0.0774s	
1560/5250 (epoch 14.857), train_loss = 1.47870729, grad/param norm = 7.4525e-02, time/batch = 0.0771s	
1561/5250 (epoch 14.867), train_loss = 1.46126532, grad/param norm = 7.5038e-02, time/batch = 0.0795s	
1562/5250 (epoch 14.876), train_loss = 1.48745663, grad/param norm = 7.0513e-02, time/batch = 0.0773s	
1563/5250 (epoch 14.886), train_loss = 1.46100074, grad/param norm = 7.5120e-02, time/batch = 0.0771s	
1564/5250 (epoch 14.895), train_loss = 1.50160937, grad/param norm = 9.5718e-02, time/batch = 0.0771s	
1565/5250 (epoch 14.905), train_loss = 1.49177457, grad/param norm = 1.0251e-01, time/batch = 0.0771s	
1566/5250 (epoch 14.914), train_loss = 1.51348427, grad/param norm = 1.0952e-01, time/batch = 0.0779s	
1567/5250 (epoch 14.924), train_loss = 1.50675880, grad/param norm = 9.7442e-02, time/batch = 0.0767s	
1568/5250 (epoch 14.933), train_loss = 1.48502521, grad/param norm = 1.1003e-01, time/batch = 0.0765s	
1569/5250 (epoch 14.943), train_loss = 1.51806341, grad/param norm = 9.5719e-02, time/batch = 0.0770s	
1570/5250 (epoch 14.952), train_loss = 1.50882380, grad/param norm = 7.5428e-02, time/batch = 0.0770s	
1571/5250 (epoch 14.962), train_loss = 1.48634501, grad/param norm = 7.8473e-02, time/batch = 0.0796s	
1572/5250 (epoch 14.971), train_loss = 1.47019105, grad/param norm = 8.3796e-02, time/batch = 0.0778s	
1573/5250 (epoch 14.981), train_loss = 1.50601682, grad/param norm = 9.2678e-02, time/batch = 0.0772s	
1574/5250 (epoch 14.990), train_loss = 1.50823126, grad/param norm = 9.9783e-02, time/batch = 0.0771s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
1575/5250 (epoch 15.000), train_loss = 1.48136531, grad/param norm = 1.0142e-01, time/batch = 0.0772s	
1576/5250 (epoch 15.010), train_loss = 1.64554566, grad/param norm = 9.9091e-02, time/batch = 0.0775s	
1577/5250 (epoch 15.019), train_loss = 1.47336485, grad/param norm = 9.8382e-02, time/batch = 0.0767s	
1578/5250 (epoch 15.029), train_loss = 1.47987369, grad/param norm = 9.6595e-02, time/batch = 0.0766s	
1579/5250 (epoch 15.038), train_loss = 1.47463044, grad/param norm = 1.0215e-01, time/batch = 0.0772s	
1580/5250 (epoch 15.048), train_loss = 1.46030608, grad/param norm = 1.0317e-01, time/batch = 0.0770s	
1581/5250 (epoch 15.057), train_loss = 1.47154060, grad/param norm = 8.9750e-02, time/batch = 0.0797s	
1582/5250 (epoch 15.067), train_loss = 1.46728213, grad/param norm = 7.9653e-02, time/batch = 0.0770s	
1583/5250 (epoch 15.076), train_loss = 1.46110077, grad/param norm = 6.9219e-02, time/batch = 0.0775s	
1584/5250 (epoch 15.086), train_loss = 1.41126417, grad/param norm = 7.0432e-02, time/batch = 0.0768s	
1585/5250 (epoch 15.095), train_loss = 1.46452012, grad/param norm = 8.2297e-02, time/batch = 0.0771s	
1586/5250 (epoch 15.105), train_loss = 1.47643779, grad/param norm = 8.2443e-02, time/batch = 0.0775s	
1587/5250 (epoch 15.114), train_loss = 1.45520279, grad/param norm = 8.4469e-02, time/batch = 0.0767s	
1588/5250 (epoch 15.124), train_loss = 1.46703868, grad/param norm = 8.0600e-02, time/batch = 0.0762s	
1589/5250 (epoch 15.133), train_loss = 1.45959747, grad/param norm = 7.8896e-02, time/batch = 0.0780s	
1590/5250 (epoch 15.143), train_loss = 1.43587956, grad/param norm = 8.2616e-02, time/batch = 0.0773s	
1591/5250 (epoch 15.152), train_loss = 1.43900496, grad/param norm = 8.4734e-02, time/batch = 0.0790s	
1592/5250 (epoch 15.162), train_loss = 1.47072551, grad/param norm = 9.5695e-02, time/batch = 0.0771s	
1593/5250 (epoch 15.171), train_loss = 1.48491203, grad/param norm = 9.6292e-02, time/batch = 0.0769s	
1594/5250 (epoch 15.181), train_loss = 1.48220683, grad/param norm = 9.2902e-02, time/batch = 0.0772s	
1595/5250 (epoch 15.190), train_loss = 1.46841070, grad/param norm = 8.0286e-02, time/batch = 0.0768s	
1596/5250 (epoch 15.200), train_loss = 1.46058304, grad/param norm = 7.6199e-02, time/batch = 0.0774s	
1597/5250 (epoch 15.210), train_loss = 1.45606571, grad/param norm = 7.9782e-02, time/batch = 0.0766s	
1598/5250 (epoch 15.219), train_loss = 1.50545919, grad/param norm = 8.3293e-02, time/batch = 0.0766s	
1599/5250 (epoch 15.229), train_loss = 1.46286697, grad/param norm = 8.5180e-02, time/batch = 0.0781s	
1600/5250 (epoch 15.238), train_loss = 1.46570866, grad/param norm = 9.5870e-02, time/batch = 0.0797s	
1601/5250 (epoch 15.248), train_loss = 1.47674008, grad/param norm = 1.0605e-01, time/batch = 0.0796s	
1602/5250 (epoch 15.257), train_loss = 1.45289231, grad/param norm = 9.0447e-02, time/batch = 0.0769s	
1603/5250 (epoch 15.267), train_loss = 1.44596440, grad/param norm = 6.7738e-02, time/batch = 0.0767s	
1604/5250 (epoch 15.276), train_loss = 1.44674132, grad/param norm = 6.0384e-02, time/batch = 0.0770s	
1605/5250 (epoch 15.286), train_loss = 1.42365655, grad/param norm = 6.0329e-02, time/batch = 0.0776s	
1606/5250 (epoch 15.295), train_loss = 1.45929248, grad/param norm = 7.1956e-02, time/batch = 0.0777s	
1607/5250 (epoch 15.305), train_loss = 1.45936643, grad/param norm = 8.1526e-02, time/batch = 0.0772s	
1608/5250 (epoch 15.314), train_loss = 1.43684306, grad/param norm = 7.7766e-02, time/batch = 0.0768s	
1609/5250 (epoch 15.324), train_loss = 1.45865714, grad/param norm = 7.6029e-02, time/batch = 0.0771s	
1610/5250 (epoch 15.333), train_loss = 1.46151150, grad/param norm = 8.0699e-02, time/batch = 0.0765s	
1611/5250 (epoch 15.343), train_loss = 1.46748613, grad/param norm = 9.2211e-02, time/batch = 0.0794s	
1612/5250 (epoch 15.352), train_loss = 1.47972233, grad/param norm = 1.1541e-01, time/batch = 0.0770s	
1613/5250 (epoch 15.362), train_loss = 1.48076491, grad/param norm = 1.1631e-01, time/batch = 0.0769s	
1614/5250 (epoch 15.371), train_loss = 1.45152793, grad/param norm = 1.0637e-01, time/batch = 0.0772s	
1615/5250 (epoch 15.381), train_loss = 1.46419013, grad/param norm = 1.1337e-01, time/batch = 0.0769s	
1616/5250 (epoch 15.390), train_loss = 1.47911724, grad/param norm = 1.1968e-01, time/batch = 0.0781s	
1617/5250 (epoch 15.400), train_loss = 1.46072270, grad/param norm = 1.0141e-01, time/batch = 0.0770s	
1618/5250 (epoch 15.410), train_loss = 1.48168520, grad/param norm = 8.3792e-02, time/batch = 0.0769s	
1619/5250 (epoch 15.419), train_loss = 1.46999226, grad/param norm = 8.9535e-02, time/batch = 0.0776s	
1620/5250 (epoch 15.429), train_loss = 1.47087814, grad/param norm = 8.8946e-02, time/batch = 0.0771s	
1621/5250 (epoch 15.438), train_loss = 1.48820099, grad/param norm = 7.3674e-02, time/batch = 0.0789s	
1622/5250 (epoch 15.448), train_loss = 1.44269986, grad/param norm = 6.4025e-02, time/batch = 0.0776s	
1623/5250 (epoch 15.457), train_loss = 1.43824761, grad/param norm = 6.8421e-02, time/batch = 0.0769s	
1624/5250 (epoch 15.467), train_loss = 1.45084124, grad/param norm = 6.6023e-02, time/batch = 0.0766s	
1625/5250 (epoch 15.476), train_loss = 1.45303847, grad/param norm = 6.6119e-02, time/batch = 0.0769s	
1626/5250 (epoch 15.486), train_loss = 1.46773475, grad/param norm = 7.5492e-02, time/batch = 0.0772s	
1627/5250 (epoch 15.495), train_loss = 1.47008644, grad/param norm = 7.5361e-02, time/batch = 0.0766s	
1628/5250 (epoch 15.505), train_loss = 1.47970204, grad/param norm = 7.1719e-02, time/batch = 0.0765s	
1629/5250 (epoch 15.514), train_loss = 1.47687765, grad/param norm = 8.1509e-02, time/batch = 0.0773s	
1630/5250 (epoch 15.524), train_loss = 1.44727151, grad/param norm = 8.2038e-02, time/batch = 0.0771s	
1631/5250 (epoch 15.533), train_loss = 1.45560422, grad/param norm = 8.3379e-02, time/batch = 0.0789s	
1632/5250 (epoch 15.543), train_loss = 1.44359670, grad/param norm = 8.3203e-02, time/batch = 0.0770s	
1633/5250 (epoch 15.552), train_loss = 1.45173758, grad/param norm = 8.6065e-02, time/batch = 0.0776s	
1634/5250 (epoch 15.562), train_loss = 1.46039154, grad/param norm = 9.1430e-02, time/batch = 0.0769s	
1635/5250 (epoch 15.571), train_loss = 1.46418831, grad/param norm = 9.9446e-02, time/batch = 0.0773s	
1636/5250 (epoch 15.581), train_loss = 1.49619053, grad/param norm = 1.0216e-01, time/batch = 0.0774s	
1637/5250 (epoch 15.590), train_loss = 1.46941047, grad/param norm = 9.5786e-02, time/batch = 0.0768s	
1638/5250 (epoch 15.600), train_loss = 1.48612053, grad/param norm = 8.7008e-02, time/batch = 0.0765s	
1639/5250 (epoch 15.610), train_loss = 1.47616480, grad/param norm = 8.7655e-02, time/batch = 0.0776s	
1640/5250 (epoch 15.619), train_loss = 1.46097984, grad/param norm = 8.5518e-02, time/batch = 0.0768s	
1641/5250 (epoch 15.629), train_loss = 1.48141516, grad/param norm = 7.9169e-02, time/batch = 0.0787s	
1642/5250 (epoch 15.638), train_loss = 1.45191181, grad/param norm = 7.7307e-02, time/batch = 0.0770s	
1643/5250 (epoch 15.648), train_loss = 1.46284495, grad/param norm = 7.6050e-02, time/batch = 0.0770s	
1644/5250 (epoch 15.657), train_loss = 1.44728546, grad/param norm = 6.8804e-02, time/batch = 0.0772s	
1645/5250 (epoch 15.667), train_loss = 1.45871518, grad/param norm = 6.9690e-02, time/batch = 0.0772s	
1646/5250 (epoch 15.676), train_loss = 1.46082903, grad/param norm = 7.8085e-02, time/batch = 0.0774s	
1647/5250 (epoch 15.686), train_loss = 1.48592297, grad/param norm = 7.3644e-02, time/batch = 0.0769s	
1648/5250 (epoch 15.695), train_loss = 1.46398801, grad/param norm = 7.2732e-02, time/batch = 0.0766s	
1649/5250 (epoch 15.705), train_loss = 1.45013462, grad/param norm = 8.3173e-02, time/batch = 0.0771s	
1650/5250 (epoch 15.714), train_loss = 1.48236064, grad/param norm = 9.5027e-02, time/batch = 0.0776s	
1651/5250 (epoch 15.724), train_loss = 1.46723748, grad/param norm = 9.9004e-02, time/batch = 0.0796s	
1652/5250 (epoch 15.733), train_loss = 1.44942322, grad/param norm = 9.8788e-02, time/batch = 0.0771s	
1653/5250 (epoch 15.743), train_loss = 1.46405619, grad/param norm = 1.2186e-01, time/batch = 0.0769s	
1654/5250 (epoch 15.752), train_loss = 1.47230895, grad/param norm = 1.1781e-01, time/batch = 0.0770s	
1655/5250 (epoch 15.762), train_loss = 1.45337855, grad/param norm = 9.7889e-02, time/batch = 0.0772s	
1656/5250 (epoch 15.771), train_loss = 1.44448670, grad/param norm = 8.3914e-02, time/batch = 0.0776s	
1657/5250 (epoch 15.781), train_loss = 1.46127623, grad/param norm = 7.8122e-02, time/batch = 0.0767s	
1658/5250 (epoch 15.790), train_loss = 1.48089172, grad/param norm = 7.6556e-02, time/batch = 0.0764s	
1659/5250 (epoch 15.800), train_loss = 1.47103301, grad/param norm = 8.0777e-02, time/batch = 0.0775s	
1660/5250 (epoch 15.810), train_loss = 1.46664034, grad/param norm = 8.1858e-02, time/batch = 0.0769s	
1661/5250 (epoch 15.819), train_loss = 1.46643501, grad/param norm = 8.3296e-02, time/batch = 0.0800s	
1662/5250 (epoch 15.829), train_loss = 1.46349257, grad/param norm = 8.6131e-02, time/batch = 0.0771s	
1663/5250 (epoch 15.838), train_loss = 1.44651654, grad/param norm = 7.5406e-02, time/batch = 0.0772s	
1664/5250 (epoch 15.848), train_loss = 1.43912028, grad/param norm = 8.6372e-02, time/batch = 0.0767s	
1665/5250 (epoch 15.857), train_loss = 1.46452235, grad/param norm = 1.0102e-01, time/batch = 0.0769s	
1666/5250 (epoch 15.867), train_loss = 1.45226639, grad/param norm = 1.1677e-01, time/batch = 0.0775s	
1667/5250 (epoch 15.876), train_loss = 1.47921509, grad/param norm = 8.4948e-02, time/batch = 0.0769s	
1668/5250 (epoch 15.886), train_loss = 1.44557802, grad/param norm = 7.3487e-02, time/batch = 0.0767s	
1669/5250 (epoch 15.895), train_loss = 1.48174968, grad/param norm = 8.1239e-02, time/batch = 0.0773s	
1670/5250 (epoch 15.905), train_loss = 1.47276687, grad/param norm = 8.9817e-02, time/batch = 0.0771s	
1671/5250 (epoch 15.914), train_loss = 1.49324969, grad/param norm = 1.0337e-01, time/batch = 0.0789s	
1672/5250 (epoch 15.924), train_loss = 1.49005306, grad/param norm = 9.4440e-02, time/batch = 0.0776s	
1673/5250 (epoch 15.933), train_loss = 1.46173473, grad/param norm = 9.0441e-02, time/batch = 0.0769s	
1674/5250 (epoch 15.943), train_loss = 1.49545113, grad/param norm = 8.1080e-02, time/batch = 0.0766s	
1675/5250 (epoch 15.952), train_loss = 1.49437808, grad/param norm = 9.6127e-02, time/batch = 0.0771s	
1676/5250 (epoch 15.962), train_loss = 1.47203071, grad/param norm = 9.6123e-02, time/batch = 0.0772s	
1677/5250 (epoch 15.971), train_loss = 1.45397472, grad/param norm = 8.6902e-02, time/batch = 0.0765s	
1678/5250 (epoch 15.981), train_loss = 1.48714615, grad/param norm = 9.0531e-02, time/batch = 0.0770s	
1679/5250 (epoch 15.990), train_loss = 1.48648741, grad/param norm = 8.8904e-02, time/batch = 0.0775s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
1680/5250 (epoch 16.000), train_loss = 1.45709431, grad/param norm = 8.0034e-02, time/batch = 0.0770s	
1681/5250 (epoch 16.010), train_loss = 1.62645017, grad/param norm = 8.2095e-02, time/batch = 0.0795s	
1682/5250 (epoch 16.019), train_loss = 1.45168921, grad/param norm = 7.9948e-02, time/batch = 0.0771s	
1683/5250 (epoch 16.029), train_loss = 1.45761464, grad/param norm = 7.2051e-02, time/batch = 0.0776s	
1684/5250 (epoch 16.038), train_loss = 1.45158560, grad/param norm = 7.6687e-02, time/batch = 0.0772s	
1685/5250 (epoch 16.048), train_loss = 1.43627471, grad/param norm = 8.2026e-02, time/batch = 0.0770s	
1686/5250 (epoch 16.057), train_loss = 1.44979485, grad/param norm = 7.6869e-02, time/batch = 0.0772s	
1687/5250 (epoch 16.067), train_loss = 1.44833424, grad/param norm = 7.0818e-02, time/batch = 0.0766s	
1688/5250 (epoch 16.076), train_loss = 1.44349066, grad/param norm = 6.4974e-02, time/batch = 0.0765s	
1689/5250 (epoch 16.086), train_loss = 1.39417097, grad/param norm = 6.8332e-02, time/batch = 0.0779s	
1690/5250 (epoch 16.095), train_loss = 1.44637614, grad/param norm = 8.0819e-02, time/batch = 0.0769s	
1691/5250 (epoch 16.105), train_loss = 1.45888105, grad/param norm = 8.1724e-02, time/batch = 0.0789s	
1692/5250 (epoch 16.114), train_loss = 1.43825181, grad/param norm = 8.3823e-02, time/batch = 0.0770s	
1693/5250 (epoch 16.124), train_loss = 1.44899792, grad/param norm = 7.6865e-02, time/batch = 0.0768s	
1694/5250 (epoch 16.133), train_loss = 1.44147229, grad/param norm = 7.0631e-02, time/batch = 0.0778s	
1695/5250 (epoch 16.143), train_loss = 1.41780737, grad/param norm = 7.4953e-02, time/batch = 0.0769s	
1696/5250 (epoch 16.152), train_loss = 1.42047434, grad/param norm = 7.8858e-02, time/batch = 0.0772s	
1697/5250 (epoch 16.162), train_loss = 1.45379967, grad/param norm = 9.3331e-02, time/batch = 0.0767s	
1698/5250 (epoch 16.171), train_loss = 1.46905395, grad/param norm = 1.0025e-01, time/batch = 0.0770s	
1699/5250 (epoch 16.181), train_loss = 1.46751041, grad/param norm = 9.9921e-02, time/batch = 0.0773s	
1700/5250 (epoch 16.190), train_loss = 1.45382872, grad/param norm = 8.4554e-02, time/batch = 0.0774s	
1701/5250 (epoch 16.200), train_loss = 1.44365920, grad/param norm = 7.5118e-02, time/batch = 0.0789s	
1702/5250 (epoch 16.210), train_loss = 1.43822194, grad/param norm = 7.5128e-02, time/batch = 0.0791s	
1703/5250 (epoch 16.219), train_loss = 1.48622678, grad/param norm = 7.7408e-02, time/batch = 0.0781s	
1704/5250 (epoch 16.229), train_loss = 1.44349201, grad/param norm = 7.6900e-02, time/batch = 0.0773s	
1705/5250 (epoch 16.238), train_loss = 1.44632721, grad/param norm = 8.5705e-02, time/batch = 0.0774s	
1706/5250 (epoch 16.248), train_loss = 1.45646354, grad/param norm = 9.1709e-02, time/batch = 0.0775s	
1707/5250 (epoch 16.257), train_loss = 1.43430528, grad/param norm = 8.3705e-02, time/batch = 0.0769s	
1708/5250 (epoch 16.267), train_loss = 1.42827728, grad/param norm = 6.8360e-02, time/batch = 0.0768s	
1709/5250 (epoch 16.276), train_loss = 1.42988851, grad/param norm = 6.0404e-02, time/batch = 0.0774s	
1710/5250 (epoch 16.286), train_loss = 1.40749748, grad/param norm = 5.8368e-02, time/batch = 0.0770s	
1711/5250 (epoch 16.295), train_loss = 1.44077332, grad/param norm = 6.6188e-02, time/batch = 0.0791s	
1712/5250 (epoch 16.305), train_loss = 1.44089011, grad/param norm = 7.9120e-02, time/batch = 0.0771s	
1713/5250 (epoch 16.314), train_loss = 1.42101199, grad/param norm = 7.8861e-02, time/batch = 0.0771s	
1714/5250 (epoch 16.324), train_loss = 1.44181039, grad/param norm = 7.7278e-02, time/batch = 0.0771s	
1715/5250 (epoch 16.333), train_loss = 1.44461042, grad/param norm = 8.1179e-02, time/batch = 0.0767s	
1716/5250 (epoch 16.343), train_loss = 1.45061156, grad/param norm = 8.8673e-02, time/batch = 0.0779s	
1717/5250 (epoch 16.352), train_loss = 1.46003549, grad/param norm = 1.0311e-01, time/batch = 0.0765s	
1718/5250 (epoch 16.362), train_loss = 1.45952907, grad/param norm = 1.0089e-01, time/batch = 0.0766s	
1719/5250 (epoch 16.371), train_loss = 1.43234180, grad/param norm = 9.4476e-02, time/batch = 0.0772s	
1720/5250 (epoch 16.381), train_loss = 1.44363932, grad/param norm = 1.0472e-01, time/batch = 0.0771s	
1721/5250 (epoch 16.390), train_loss = 1.46047854, grad/param norm = 1.1447e-01, time/batch = 0.0791s	
1722/5250 (epoch 16.400), train_loss = 1.44391092, grad/param norm = 9.7886e-02, time/batch = 0.0777s	
1723/5250 (epoch 16.410), train_loss = 1.46303828, grad/param norm = 8.0440e-02, time/batch = 0.0773s	
1724/5250 (epoch 16.419), train_loss = 1.45181740, grad/param norm = 8.5100e-02, time/batch = 0.0772s	
1725/5250 (epoch 16.429), train_loss = 1.45345175, grad/param norm = 8.4691e-02, time/batch = 0.0769s	
1726/5250 (epoch 16.438), train_loss = 1.47069016, grad/param norm = 7.1657e-02, time/batch = 0.0771s	
1727/5250 (epoch 16.448), train_loss = 1.42582183, grad/param norm = 6.3360e-02, time/batch = 0.0768s	
1728/5250 (epoch 16.457), train_loss = 1.42194613, grad/param norm = 6.7935e-02, time/batch = 0.0767s	
1729/5250 (epoch 16.467), train_loss = 1.43520482, grad/param norm = 6.5924e-02, time/batch = 0.0773s	
1730/5250 (epoch 16.476), train_loss = 1.43733650, grad/param norm = 6.5520e-02, time/batch = 0.0768s	
1731/5250 (epoch 16.486), train_loss = 1.45211902, grad/param norm = 7.4007e-02, time/batch = 0.0795s	
1732/5250 (epoch 16.495), train_loss = 1.45477147, grad/param norm = 7.5713e-02, time/batch = 0.0769s	
1733/5250 (epoch 16.505), train_loss = 1.46461650, grad/param norm = 7.2745e-02, time/batch = 0.0774s	
1734/5250 (epoch 16.514), train_loss = 1.46211125, grad/param norm = 8.2956e-02, time/batch = 0.0769s	
1735/5250 (epoch 16.524), train_loss = 1.43263805, grad/param norm = 8.3700e-02, time/batch = 0.0771s	
1736/5250 (epoch 16.533), train_loss = 1.44004776, grad/param norm = 8.6212e-02, time/batch = 0.0776s	
1737/5250 (epoch 16.543), train_loss = 1.42951999, grad/param norm = 8.6820e-02, time/batch = 0.0765s	
1738/5250 (epoch 16.552), train_loss = 1.43679687, grad/param norm = 8.7657e-02, time/batch = 0.0767s	
1739/5250 (epoch 16.562), train_loss = 1.44401489, grad/param norm = 9.3631e-02, time/batch = 0.0781s	
1740/5250 (epoch 16.571), train_loss = 1.44969174, grad/param norm = 1.0066e-01, time/batch = 0.0767s	
1741/5250 (epoch 16.581), train_loss = 1.47972372, grad/param norm = 1.0099e-01, time/batch = 0.0788s	
1742/5250 (epoch 16.590), train_loss = 1.45148276, grad/param norm = 8.1168e-02, time/batch = 0.0770s	
1743/5250 (epoch 16.600), train_loss = 1.46820449, grad/param norm = 7.5760e-02, time/batch = 0.0766s	
1744/5250 (epoch 16.610), train_loss = 1.45926064, grad/param norm = 8.3513e-02, time/batch = 0.0771s	
1745/5250 (epoch 16.619), train_loss = 1.44466208, grad/param norm = 8.0093e-02, time/batch = 0.0771s	
1746/5250 (epoch 16.629), train_loss = 1.46463094, grad/param norm = 7.7814e-02, time/batch = 0.0774s	
1747/5250 (epoch 16.638), train_loss = 1.43541989, grad/param norm = 7.6889e-02, time/batch = 0.0767s	
1748/5250 (epoch 16.648), train_loss = 1.44584833, grad/param norm = 7.3312e-02, time/batch = 0.0769s	
1749/5250 (epoch 16.657), train_loss = 1.43191465, grad/param norm = 6.5694e-02, time/batch = 0.0772s	
1750/5250 (epoch 16.667), train_loss = 1.44112574, grad/param norm = 6.1900e-02, time/batch = 0.0776s	
1751/5250 (epoch 16.676), train_loss = 1.44278524, grad/param norm = 6.7899e-02, time/batch = 0.0794s	
1752/5250 (epoch 16.686), train_loss = 1.46783626, grad/param norm = 6.6236e-02, time/batch = 0.0770s	
1753/5250 (epoch 16.695), train_loss = 1.44746971, grad/param norm = 7.9107e-02, time/batch = 0.0770s	
1754/5250 (epoch 16.705), train_loss = 1.43442021, grad/param norm = 8.7871e-02, time/batch = 0.0767s	
1755/5250 (epoch 16.714), train_loss = 1.46680408, grad/param norm = 8.9633e-02, time/batch = 0.0773s	
1756/5250 (epoch 16.724), train_loss = 1.44789130, grad/param norm = 7.3553e-02, time/batch = 0.0775s	
1757/5250 (epoch 16.733), train_loss = 1.42946126, grad/param norm = 7.7627e-02, time/batch = 0.0769s	
1758/5250 (epoch 16.743), train_loss = 1.44157827, grad/param norm = 9.7893e-02, time/batch = 0.0767s	
1759/5250 (epoch 16.752), train_loss = 1.44928335, grad/param norm = 9.0420e-02, time/batch = 0.0772s	
1760/5250 (epoch 16.762), train_loss = 1.43294772, grad/param norm = 8.5958e-02, time/batch = 0.0768s	
1761/5250 (epoch 16.771), train_loss = 1.42951595, grad/param norm = 8.2529e-02, time/batch = 0.0789s	
1762/5250 (epoch 16.781), train_loss = 1.44677758, grad/param norm = 7.8230e-02, time/batch = 0.0768s	
1763/5250 (epoch 16.790), train_loss = 1.46479505, grad/param norm = 7.8059e-02, time/batch = 0.0769s	
1764/5250 (epoch 16.800), train_loss = 1.45569104, grad/param norm = 8.4576e-02, time/batch = 0.0768s	
1765/5250 (epoch 16.810), train_loss = 1.45072305, grad/param norm = 7.9224e-02, time/batch = 0.0770s	
1766/5250 (epoch 16.819), train_loss = 1.45163713, grad/param norm = 8.1262e-02, time/batch = 0.0779s	
1767/5250 (epoch 16.829), train_loss = 1.44825756, grad/param norm = 8.4844e-02, time/batch = 0.0770s	
1768/5250 (epoch 16.838), train_loss = 1.42983451, grad/param norm = 7.3414e-02, time/batch = 0.0766s	
1769/5250 (epoch 16.848), train_loss = 1.42271580, grad/param norm = 7.9697e-02, time/batch = 0.0775s	
1770/5250 (epoch 16.857), train_loss = 1.44668652, grad/param norm = 8.9620e-02, time/batch = 0.0771s	
1771/5250 (epoch 16.867), train_loss = 1.43245019, grad/param norm = 9.4509e-02, time/batch = 0.0788s	
1772/5250 (epoch 16.876), train_loss = 1.45881244, grad/param norm = 9.3350e-02, time/batch = 0.0777s	
1773/5250 (epoch 16.886), train_loss = 1.43179776, grad/param norm = 8.2573e-02, time/batch = 0.0771s	
1774/5250 (epoch 16.895), train_loss = 1.47012340, grad/param norm = 9.1076e-02, time/batch = 0.0769s	
1775/5250 (epoch 16.905), train_loss = 1.45917995, grad/param norm = 9.5372e-02, time/batch = 0.0770s	
1776/5250 (epoch 16.914), train_loss = 1.47761953, grad/param norm = 1.0078e-01, time/batch = 0.0773s	
1777/5250 (epoch 16.924), train_loss = 1.47144134, grad/param norm = 8.3174e-02, time/batch = 0.0766s	
1778/5250 (epoch 16.933), train_loss = 1.44150017, grad/param norm = 7.6656e-02, time/batch = 0.0769s	
1779/5250 (epoch 16.943), train_loss = 1.47693108, grad/param norm = 6.7809e-02, time/batch = 0.0773s	
1780/5250 (epoch 16.952), train_loss = 1.47389783, grad/param norm = 7.4465e-02, time/batch = 0.0769s	
1781/5250 (epoch 16.962), train_loss = 1.45246570, grad/param norm = 8.0675e-02, time/batch = 0.0788s	
1782/5250 (epoch 16.971), train_loss = 1.43877468, grad/param norm = 8.4721e-02, time/batch = 0.0769s	
1783/5250 (epoch 16.981), train_loss = 1.47616993, grad/param norm = 1.0205e-01, time/batch = 0.0776s	
1784/5250 (epoch 16.990), train_loss = 1.47696581, grad/param norm = 1.0278e-01, time/batch = 0.0768s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
1785/5250 (epoch 17.000), train_loss = 1.44588617, grad/param norm = 8.8572e-02, time/batch = 0.0771s	
1786/5250 (epoch 17.010), train_loss = 1.61427719, grad/param norm = 7.9446e-02, time/batch = 0.0773s	
1787/5250 (epoch 17.019), train_loss = 1.43530144, grad/param norm = 7.2280e-02, time/batch = 0.0768s	
1788/5250 (epoch 17.029), train_loss = 1.44168007, grad/param norm = 6.6189e-02, time/batch = 0.0763s	
1789/5250 (epoch 17.038), train_loss = 1.43491660, grad/param norm = 7.2179e-02, time/batch = 0.0780s	
1790/5250 (epoch 17.048), train_loss = 1.41932263, grad/param norm = 7.5716e-02, time/batch = 0.0772s	
1791/5250 (epoch 17.057), train_loss = 1.43240808, grad/param norm = 6.8095e-02, time/batch = 0.0797s	
1792/5250 (epoch 17.067), train_loss = 1.43141941, grad/param norm = 6.3111e-02, time/batch = 0.0770s	
1793/5250 (epoch 17.076), train_loss = 1.42950989, grad/param norm = 6.7773e-02, time/batch = 0.0771s	
1794/5250 (epoch 17.086), train_loss = 1.38135047, grad/param norm = 7.8158e-02, time/batch = 0.0775s	
1795/5250 (epoch 17.095), train_loss = 1.43429882, grad/param norm = 9.7294e-02, time/batch = 0.0771s	
1796/5250 (epoch 17.105), train_loss = 1.44720922, grad/param norm = 9.1672e-02, time/batch = 0.0773s	
1797/5250 (epoch 17.114), train_loss = 1.42213921, grad/param norm = 8.1225e-02, time/batch = 0.0767s	
1798/5250 (epoch 17.124), train_loss = 1.43234461, grad/param norm = 7.1126e-02, time/batch = 0.0768s	
1799/5250 (epoch 17.133), train_loss = 1.42475326, grad/param norm = 6.5382e-02, time/batch = 0.0770s	
1800/5250 (epoch 17.143), train_loss = 1.40179654, grad/param norm = 6.7561e-02, time/batch = 0.0773s	
1801/5250 (epoch 17.152), train_loss = 1.40143765, grad/param norm = 6.6093e-02, time/batch = 0.0790s	
1802/5250 (epoch 17.162), train_loss = 1.43486674, grad/param norm = 7.3653e-02, time/batch = 0.0769s	
1803/5250 (epoch 17.171), train_loss = 1.44711139, grad/param norm = 7.7476e-02, time/batch = 0.0769s	
1804/5250 (epoch 17.181), train_loss = 1.44696746, grad/param norm = 7.9467e-02, time/batch = 0.0769s	
1805/5250 (epoch 17.190), train_loss = 1.43682480, grad/param norm = 7.2699e-02, time/batch = 0.0774s	
1806/5250 (epoch 17.200), train_loss = 1.42856329, grad/param norm = 7.2321e-02, time/batch = 0.0776s	
1807/5250 (epoch 17.210), train_loss = 1.42402368, grad/param norm = 7.6839e-02, time/batch = 0.0767s	
1808/5250 (epoch 17.219), train_loss = 1.47224877, grad/param norm = 8.2116e-02, time/batch = 0.0767s	
1809/5250 (epoch 17.229), train_loss = 1.42993609, grad/param norm = 8.0065e-02, time/batch = 0.0772s	
1810/5250 (epoch 17.238), train_loss = 1.43218884, grad/param norm = 8.6391e-02, time/batch = 0.0769s	
1811/5250 (epoch 17.248), train_loss = 1.44261535, grad/param norm = 9.6588e-02, time/batch = 0.0806s	
1812/5250 (epoch 17.257), train_loss = 1.42140752, grad/param norm = 8.5023e-02, time/batch = 0.0774s	
1813/5250 (epoch 17.267), train_loss = 1.41290943, grad/param norm = 6.1859e-02, time/batch = 0.0770s	
1814/5250 (epoch 17.276), train_loss = 1.41352235, grad/param norm = 5.4895e-02, time/batch = 0.0771s	
1815/5250 (epoch 17.286), train_loss = 1.39290631, grad/param norm = 5.8459e-02, time/batch = 0.0768s	
1816/5250 (epoch 17.295), train_loss = 1.42596077, grad/param norm = 6.9657e-02, time/batch = 0.0780s	
1817/5250 (epoch 17.305), train_loss = 1.42459360, grad/param norm = 7.5717e-02, time/batch = 0.0769s	
1818/5250 (epoch 17.314), train_loss = 1.40475420, grad/param norm = 6.6870e-02, time/batch = 0.0767s	
1819/5250 (epoch 17.324), train_loss = 1.42320756, grad/param norm = 6.9137e-02, time/batch = 0.0771s	
1820/5250 (epoch 17.333), train_loss = 1.42713232, grad/param norm = 7.6553e-02, time/batch = 0.0770s	
1821/5250 (epoch 17.343), train_loss = 1.43486129, grad/param norm = 8.4412e-02, time/batch = 0.0795s	
1822/5250 (epoch 17.352), train_loss = 1.44441654, grad/param norm = 9.9226e-02, time/batch = 0.0797s	
1823/5250 (epoch 17.362), train_loss = 1.44453861, grad/param norm = 9.7091e-02, time/batch = 0.0773s	
1824/5250 (epoch 17.371), train_loss = 1.41780173, grad/param norm = 9.1245e-02, time/batch = 0.0771s	
1825/5250 (epoch 17.381), train_loss = 1.42710016, grad/param norm = 9.9276e-02, time/batch = 0.0765s	
1826/5250 (epoch 17.390), train_loss = 1.44325178, grad/param norm = 1.0815e-01, time/batch = 0.0773s	
1827/5250 (epoch 17.400), train_loss = 1.42803389, grad/param norm = 9.1220e-02, time/batch = 0.0769s	
1828/5250 (epoch 17.410), train_loss = 1.44497799, grad/param norm = 7.5128e-02, time/batch = 0.0767s	
1829/5250 (epoch 17.419), train_loss = 1.43339617, grad/param norm = 7.5879e-02, time/batch = 0.0772s	
1830/5250 (epoch 17.429), train_loss = 1.43571393, grad/param norm = 7.4850e-02, time/batch = 0.0769s	
1831/5250 (epoch 17.438), train_loss = 1.45350023, grad/param norm = 6.6739e-02, time/batch = 0.0789s	
1832/5250 (epoch 17.448), train_loss = 1.41054805, grad/param norm = 6.2384e-02, time/batch = 0.0770s	
1833/5250 (epoch 17.457), train_loss = 1.40701972, grad/param norm = 6.6222e-02, time/batch = 0.0776s	
1834/5250 (epoch 17.467), train_loss = 1.42088996, grad/param norm = 6.6659e-02, time/batch = 0.0771s	
1835/5250 (epoch 17.476), train_loss = 1.42344630, grad/param norm = 6.7060e-02, time/batch = 0.0770s	
1836/5250 (epoch 17.486), train_loss = 1.43883328, grad/param norm = 7.6294e-02, time/batch = 0.0775s	
1837/5250 (epoch 17.495), train_loss = 1.44164519, grad/param norm = 7.6986e-02, time/batch = 0.0765s	
1838/5250 (epoch 17.505), train_loss = 1.45029787, grad/param norm = 7.2446e-02, time/batch = 0.0766s	
1839/5250 (epoch 17.514), train_loss = 1.44793630, grad/param norm = 8.3410e-02, time/batch = 0.0778s	
1840/5250 (epoch 17.524), train_loss = 1.41842433, grad/param norm = 7.2818e-02, time/batch = 0.0768s	
1841/5250 (epoch 17.533), train_loss = 1.42367961, grad/param norm = 6.8833e-02, time/batch = 0.0789s	
1842/5250 (epoch 17.543), train_loss = 1.41049346, grad/param norm = 6.9643e-02, time/batch = 0.0770s	
1843/5250 (epoch 17.552), train_loss = 1.41943820, grad/param norm = 7.1361e-02, time/batch = 0.0769s	
1844/5250 (epoch 17.562), train_loss = 1.42582668, grad/param norm = 8.0802e-02, time/batch = 0.0772s	
1845/5250 (epoch 17.571), train_loss = 1.43114239, grad/param norm = 8.4341e-02, time/batch = 0.0769s	
1846/5250 (epoch 17.581), train_loss = 1.46104125, grad/param norm = 7.8340e-02, time/batch = 0.0773s	
1847/5250 (epoch 17.590), train_loss = 1.43446748, grad/param norm = 7.3993e-02, time/batch = 0.0769s	
1848/5250 (epoch 17.600), train_loss = 1.45191776, grad/param norm = 7.1414e-02, time/batch = 0.0765s	
1849/5250 (epoch 17.610), train_loss = 1.44345646, grad/param norm = 7.6974e-02, time/batch = 0.0771s	
1850/5250 (epoch 17.619), train_loss = 1.43102201, grad/param norm = 8.0226e-02, time/batch = 0.0776s	
1851/5250 (epoch 17.629), train_loss = 1.45165591, grad/param norm = 8.6915e-02, time/batch = 0.0788s	
1852/5250 (epoch 17.638), train_loss = 1.42623957, grad/param norm = 9.5088e-02, time/batch = 0.0770s	
1853/5250 (epoch 17.648), train_loss = 1.44148423, grad/param norm = 1.1249e-01, time/batch = 0.0768s	
1854/5250 (epoch 17.657), train_loss = 1.43402557, grad/param norm = 1.1078e-01, time/batch = 0.0769s	
1855/5250 (epoch 17.667), train_loss = 1.43862051, grad/param norm = 9.8537e-02, time/batch = 0.0773s	
1856/5250 (epoch 17.676), train_loss = 1.44021961, grad/param norm = 9.5987e-02, time/batch = 0.0776s	
1857/5250 (epoch 17.686), train_loss = 1.45978851, grad/param norm = 8.5469e-02, time/batch = 0.0770s	
1858/5250 (epoch 17.695), train_loss = 1.43558519, grad/param norm = 8.8155e-02, time/batch = 0.0765s	
1859/5250 (epoch 17.705), train_loss = 1.41862827, grad/param norm = 7.8613e-02, time/batch = 0.0772s	
1860/5250 (epoch 17.714), train_loss = 1.44928837, grad/param norm = 7.0391e-02, time/batch = 0.0770s	
1861/5250 (epoch 17.724), train_loss = 1.43051219, grad/param norm = 6.8203e-02, time/batch = 0.0790s	
1862/5250 (epoch 17.733), train_loss = 1.41258867, grad/param norm = 7.4281e-02, time/batch = 0.0770s	
1863/5250 (epoch 17.743), train_loss = 1.42117171, grad/param norm = 7.8263e-02, time/batch = 0.0768s	
1864/5250 (epoch 17.752), train_loss = 1.42550355, grad/param norm = 6.3925e-02, time/batch = 0.0771s	
1865/5250 (epoch 17.762), train_loss = 1.41256451, grad/param norm = 6.2147e-02, time/batch = 0.0769s	
1866/5250 (epoch 17.771), train_loss = 1.41076481, grad/param norm = 6.6632e-02, time/batch = 0.0775s	
1867/5250 (epoch 17.781), train_loss = 1.43021677, grad/param norm = 6.6206e-02, time/batch = 0.0766s	
1868/5250 (epoch 17.790), train_loss = 1.44740866, grad/param norm = 6.4439e-02, time/batch = 0.0767s	
1869/5250 (epoch 17.800), train_loss = 1.43462434, grad/param norm = 6.0455e-02, time/batch = 0.0773s	
1870/5250 (epoch 17.810), train_loss = 1.43223342, grad/param norm = 6.1247e-02, time/batch = 0.0768s	
1871/5250 (epoch 17.819), train_loss = 1.43349232, grad/param norm = 6.3785e-02, time/batch = 0.0787s	
1872/5250 (epoch 17.829), train_loss = 1.42823665, grad/param norm = 6.4331e-02, time/batch = 0.0777s	
1873/5250 (epoch 17.838), train_loss = 1.41375918, grad/param norm = 7.0716e-02, time/batch = 0.0770s	
1874/5250 (epoch 17.848), train_loss = 1.40791419, grad/param norm = 6.5978e-02, time/batch = 0.0771s	
1875/5250 (epoch 17.857), train_loss = 1.42926773, grad/param norm = 6.5707e-02, time/batch = 0.0771s	
1876/5250 (epoch 17.867), train_loss = 1.41615009, grad/param norm = 6.8119e-02, time/batch = 0.0774s	
1877/5250 (epoch 17.876), train_loss = 1.43798154, grad/param norm = 6.4927e-02, time/batch = 0.0767s	
1878/5250 (epoch 17.886), train_loss = 1.41591826, grad/param norm = 7.0618e-02, time/batch = 0.0767s	
1879/5250 (epoch 17.895), train_loss = 1.45683528, grad/param norm = 8.9498e-02, time/batch = 0.0774s	
1880/5250 (epoch 17.905), train_loss = 1.44292794, grad/param norm = 8.6056e-02, time/batch = 0.0770s	
1881/5250 (epoch 17.914), train_loss = 1.46169872, grad/param norm = 8.4672e-02, time/batch = 0.0790s	
1882/5250 (epoch 17.924), train_loss = 1.45636303, grad/param norm = 8.2849e-02, time/batch = 0.0770s	
1883/5250 (epoch 17.933), train_loss = 1.43157868, grad/param norm = 8.5215e-02, time/batch = 0.0777s	
1884/5250 (epoch 17.943), train_loss = 1.47054404, grad/param norm = 9.9884e-02, time/batch = 0.0770s	
1885/5250 (epoch 17.952), train_loss = 1.46690096, grad/param norm = 9.6641e-02, time/batch = 0.0767s	
1886/5250 (epoch 17.962), train_loss = 1.44439198, grad/param norm = 9.5714e-02, time/batch = 0.0772s	
1887/5250 (epoch 17.971), train_loss = 1.42951159, grad/param norm = 9.5302e-02, time/batch = 0.0765s	
1888/5250 (epoch 17.981), train_loss = 1.45874576, grad/param norm = 8.0225e-02, time/batch = 0.0769s	
1889/5250 (epoch 17.990), train_loss = 1.45601877, grad/param norm = 7.2806e-02, time/batch = 0.0778s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
1890/5250 (epoch 18.000), train_loss = 1.42980667, grad/param norm = 7.8639e-02, time/batch = 0.0771s	
1891/5250 (epoch 18.010), train_loss = 1.60403372, grad/param norm = 7.6646e-02, time/batch = 0.0790s	
1892/5250 (epoch 18.019), train_loss = 1.42167776, grad/param norm = 7.2108e-02, time/batch = 0.0772s	
1893/5250 (epoch 18.029), train_loss = 1.42728999, grad/param norm = 5.8508e-02, time/batch = 0.0770s	
1894/5250 (epoch 18.038), train_loss = 1.41742113, grad/param norm = 5.9172e-02, time/batch = 0.0774s	
1895/5250 (epoch 18.048), train_loss = 1.40195399, grad/param norm = 6.5648e-02, time/batch = 0.0768s	
1896/5250 (epoch 18.057), train_loss = 1.41571326, grad/param norm = 6.5699e-02, time/batch = 0.0772s	
1897/5250 (epoch 18.067), train_loss = 1.41821889, grad/param norm = 6.6868e-02, time/batch = 0.0768s	
1898/5250 (epoch 18.076), train_loss = 1.41893238, grad/param norm = 7.5632e-02, time/batch = 0.0767s	
1899/5250 (epoch 18.086), train_loss = 1.37026673, grad/param norm = 8.1574e-02, time/batch = 0.0774s	
1900/5250 (epoch 18.095), train_loss = 1.41681410, grad/param norm = 8.9854e-02, time/batch = 0.0775s	
1901/5250 (epoch 18.105), train_loss = 1.42900888, grad/param norm = 8.0652e-02, time/batch = 0.0790s	
1902/5250 (epoch 18.114), train_loss = 1.40603627, grad/param norm = 7.4403e-02, time/batch = 0.0770s	
1903/5250 (epoch 18.124), train_loss = 1.41911518, grad/param norm = 7.3948e-02, time/batch = 0.0771s	
1904/5250 (epoch 18.133), train_loss = 1.41138360, grad/param norm = 6.3818e-02, time/batch = 0.0771s	
1905/5250 (epoch 18.143), train_loss = 1.38827643, grad/param norm = 5.9073e-02, time/batch = 0.0775s	
1906/5250 (epoch 18.152), train_loss = 1.38536007, grad/param norm = 5.6271e-02, time/batch = 0.0777s	
1907/5250 (epoch 18.162), train_loss = 1.41844158, grad/param norm = 5.9594e-02, time/batch = 0.0769s	
1908/5250 (epoch 18.171), train_loss = 1.42914408, grad/param norm = 6.1406e-02, time/batch = 0.0763s	
1909/5250 (epoch 18.181), train_loss = 1.43059997, grad/param norm = 7.0146e-02, time/batch = 0.0772s	
1910/5250 (epoch 18.190), train_loss = 1.42545231, grad/param norm = 7.7064e-02, time/batch = 0.0769s	
1911/5250 (epoch 18.200), train_loss = 1.41735325, grad/param norm = 7.7463e-02, time/batch = 0.0790s	
1912/5250 (epoch 18.210), train_loss = 1.41156587, grad/param norm = 8.1053e-02, time/batch = 0.0770s	
1913/5250 (epoch 18.219), train_loss = 1.46068887, grad/param norm = 8.6972e-02, time/batch = 0.0768s	
1914/5250 (epoch 18.229), train_loss = 1.41754541, grad/param norm = 8.1351e-02, time/batch = 0.0771s	
1915/5250 (epoch 18.238), train_loss = 1.41733427, grad/param norm = 7.8555e-02, time/batch = 0.0771s	
1916/5250 (epoch 18.248), train_loss = 1.42361163, grad/param norm = 7.6689e-02, time/batch = 0.0781s	
1917/5250 (epoch 18.257), train_loss = 1.40470164, grad/param norm = 7.1511e-02, time/batch = 0.0789s	
1918/5250 (epoch 18.267), train_loss = 1.39899388, grad/param norm = 6.3770e-02, time/batch = 0.0771s	
1919/5250 (epoch 18.276), train_loss = 1.40127106, grad/param norm = 5.9513e-02, time/batch = 0.0777s	
1920/5250 (epoch 18.286), train_loss = 1.38106824, grad/param norm = 6.5377e-02, time/batch = 0.0768s	
1921/5250 (epoch 18.295), train_loss = 1.41429469, grad/param norm = 7.6195e-02, time/batch = 0.0796s	
1922/5250 (epoch 18.305), train_loss = 1.41345576, grad/param norm = 8.1135e-02, time/batch = 0.0775s	
1923/5250 (epoch 18.314), train_loss = 1.39301075, grad/param norm = 7.0218e-02, time/batch = 0.0772s	
1924/5250 (epoch 18.324), train_loss = 1.40901698, grad/param norm = 7.1351e-02, time/batch = 0.0767s	
1925/5250 (epoch 18.333), train_loss = 1.41260121, grad/param norm = 7.0118e-02, time/batch = 0.0772s	
1926/5250 (epoch 18.343), train_loss = 1.41882929, grad/param norm = 7.2426e-02, time/batch = 0.0782s	
1927/5250 (epoch 18.352), train_loss = 1.42898351, grad/param norm = 8.2307e-02, time/batch = 0.0768s	
1928/5250 (epoch 18.362), train_loss = 1.42717129, grad/param norm = 8.1137e-02, time/batch = 0.0769s	
1929/5250 (epoch 18.371), train_loss = 1.40307985, grad/param norm = 7.8119e-02, time/batch = 0.0775s	
1930/5250 (epoch 18.381), train_loss = 1.41088696, grad/param norm = 8.6791e-02, time/batch = 0.0770s	
1931/5250 (epoch 18.390), train_loss = 1.43184202, grad/param norm = 1.0282e-01, time/batch = 0.0788s	
1932/5250 (epoch 18.400), train_loss = 1.42052414, grad/param norm = 1.0544e-01, time/batch = 0.0769s	
1933/5250 (epoch 18.410), train_loss = 1.43707767, grad/param norm = 9.5506e-02, time/batch = 0.0805s	
1934/5250 (epoch 18.419), train_loss = 1.42163110, grad/param norm = 8.3418e-02, time/batch = 0.0776s	
1935/5250 (epoch 18.429), train_loss = 1.42131802, grad/param norm = 7.0723e-02, time/batch = 0.0773s	
1936/5250 (epoch 18.438), train_loss = 1.43848767, grad/param norm = 6.5091e-02, time/batch = 0.0774s	
1937/5250 (epoch 18.448), train_loss = 1.39894207, grad/param norm = 6.9628e-02, time/batch = 0.0768s	
1938/5250 (epoch 18.457), train_loss = 1.39667443, grad/param norm = 8.3287e-02, time/batch = 0.0768s	
1939/5250 (epoch 18.467), train_loss = 1.41304907, grad/param norm = 7.4821e-02, time/batch = 0.0777s	
1940/5250 (epoch 18.476), train_loss = 1.41559600, grad/param norm = 8.2041e-02, time/batch = 0.0770s	
1941/5250 (epoch 18.486), train_loss = 1.42990353, grad/param norm = 8.9815e-02, time/batch = 0.0790s	
1942/5250 (epoch 18.495), train_loss = 1.43156804, grad/param norm = 8.5346e-02, time/batch = 0.0770s	
1943/5250 (epoch 18.505), train_loss = 1.44070112, grad/param norm = 8.2283e-02, time/batch = 0.0770s	
1944/5250 (epoch 18.514), train_loss = 1.43835802, grad/param norm = 8.8674e-02, time/batch = 0.0776s	
1945/5250 (epoch 18.524), train_loss = 1.40664484, grad/param norm = 8.4983e-02, time/batch = 0.0769s	
1946/5250 (epoch 18.533), train_loss = 1.41197310, grad/param norm = 8.1533e-02, time/batch = 0.0775s	
1947/5250 (epoch 18.543), train_loss = 1.40066677, grad/param norm = 7.5837e-02, time/batch = 0.0767s	
1948/5250 (epoch 18.552), train_loss = 1.40683016, grad/param norm = 7.0385e-02, time/batch = 0.0763s	
1949/5250 (epoch 18.562), train_loss = 1.40891562, grad/param norm = 6.4967e-02, time/batch = 0.0771s	
1950/5250 (epoch 18.571), train_loss = 1.41190382, grad/param norm = 6.9485e-02, time/batch = 0.0773s	
1951/5250 (epoch 18.581), train_loss = 1.44761831, grad/param norm = 7.4843e-02, time/batch = 0.0788s	
1952/5250 (epoch 18.590), train_loss = 1.42044494, grad/param norm = 7.1457e-02, time/batch = 0.0770s	
1953/5250 (epoch 18.600), train_loss = 1.43537573, grad/param norm = 6.2365e-02, time/batch = 0.0766s	
1954/5250 (epoch 18.610), train_loss = 1.42666730, grad/param norm = 6.5818e-02, time/batch = 0.0770s	
1955/5250 (epoch 18.619), train_loss = 1.41481337, grad/param norm = 7.1519e-02, time/batch = 0.0772s	
1956/5250 (epoch 18.629), train_loss = 1.43355030, grad/param norm = 7.1805e-02, time/batch = 0.0774s	
1957/5250 (epoch 18.638), train_loss = 1.40657202, grad/param norm = 7.1322e-02, time/batch = 0.0771s	
1958/5250 (epoch 18.648), train_loss = 1.41826572, grad/param norm = 7.6482e-02, time/batch = 0.0768s	
1959/5250 (epoch 18.657), train_loss = 1.40866470, grad/param norm = 6.8861e-02, time/batch = 0.0774s	
1960/5250 (epoch 18.667), train_loss = 1.41422679, grad/param norm = 6.2052e-02, time/batch = 0.0768s	
1961/5250 (epoch 18.676), train_loss = 1.41954501, grad/param norm = 6.9385e-02, time/batch = 0.0791s	
1962/5250 (epoch 18.686), train_loss = 1.44324744, grad/param norm = 7.2757e-02, time/batch = 0.0770s	
1963/5250 (epoch 18.695), train_loss = 1.42130043, grad/param norm = 7.7847e-02, time/batch = 0.0767s	
1964/5250 (epoch 18.705), train_loss = 1.40548459, grad/param norm = 7.6515e-02, time/batch = 0.0767s	
1965/5250 (epoch 18.714), train_loss = 1.43942100, grad/param norm = 8.0977e-02, time/batch = 0.0769s	
1966/5250 (epoch 18.724), train_loss = 1.42111881, grad/param norm = 7.1798e-02, time/batch = 0.0779s	
1967/5250 (epoch 18.733), train_loss = 1.40043078, grad/param norm = 6.9156e-02, time/batch = 0.0771s	
1968/5250 (epoch 18.743), train_loss = 1.40931442, grad/param norm = 7.7757e-02, time/batch = 0.0766s	
1969/5250 (epoch 18.752), train_loss = 1.41399895, grad/param norm = 6.8921e-02, time/batch = 0.0772s	
1970/5250 (epoch 18.762), train_loss = 1.40110401, grad/param norm = 6.5591e-02, time/batch = 0.0770s	
1971/5250 (epoch 18.771), train_loss = 1.39797744, grad/param norm = 6.7018e-02, time/batch = 0.0788s	
1972/5250 (epoch 18.781), train_loss = 1.41912455, grad/param norm = 7.2601e-02, time/batch = 0.0776s	
1973/5250 (epoch 18.790), train_loss = 1.44006188, grad/param norm = 8.7212e-02, time/batch = 0.0771s	
1974/5250 (epoch 18.800), train_loss = 1.42896322, grad/param norm = 8.2593e-02, time/batch = 0.0770s	
1975/5250 (epoch 18.810), train_loss = 1.42463503, grad/param norm = 7.2274e-02, time/batch = 0.0772s	
1976/5250 (epoch 18.819), train_loss = 1.42501605, grad/param norm = 7.6010e-02, time/batch = 0.0776s	
1977/5250 (epoch 18.829), train_loss = 1.42114981, grad/param norm = 8.0550e-02, time/batch = 0.0772s	
1978/5250 (epoch 18.838), train_loss = 1.40238855, grad/param norm = 7.4704e-02, time/batch = 0.0766s	
1979/5250 (epoch 18.848), train_loss = 1.39954115, grad/param norm = 8.1752e-02, time/batch = 0.0773s	
1980/5250 (epoch 18.857), train_loss = 1.42133465, grad/param norm = 9.2810e-02, time/batch = 0.0769s	
1981/5250 (epoch 18.867), train_loss = 1.40782316, grad/param norm = 8.8495e-02, time/batch = 0.0795s	
1982/5250 (epoch 18.876), train_loss = 1.42869487, grad/param norm = 8.7290e-02, time/batch = 0.0770s	
1983/5250 (epoch 18.886), train_loss = 1.40532333, grad/param norm = 7.9980e-02, time/batch = 0.0774s	
1984/5250 (epoch 18.895), train_loss = 1.44336265, grad/param norm = 8.1257e-02, time/batch = 0.0769s	
1985/5250 (epoch 18.905), train_loss = 1.43021714, grad/param norm = 8.2103e-02, time/batch = 0.0771s	
1986/5250 (epoch 18.914), train_loss = 1.44926288, grad/param norm = 8.8666e-02, time/batch = 0.0777s	
1987/5250 (epoch 18.924), train_loss = 1.44294792, grad/param norm = 7.6754e-02, time/batch = 0.0766s	
1988/5250 (epoch 18.933), train_loss = 1.41405082, grad/param norm = 7.1259e-02, time/batch = 0.0762s	
1989/5250 (epoch 18.943), train_loss = 1.45038056, grad/param norm = 7.0566e-02, time/batch = 0.0778s	
1990/5250 (epoch 18.952), train_loss = 1.45020226, grad/param norm = 8.3886e-02, time/batch = 0.0771s	
1991/5250 (epoch 18.962), train_loss = 1.42798899, grad/param norm = 8.3960e-02, time/batch = 0.0789s	
1992/5250 (epoch 18.971), train_loss = 1.41303371, grad/param norm = 7.9984e-02, time/batch = 0.0770s	
1993/5250 (epoch 18.981), train_loss = 1.44565368, grad/param norm = 8.2568e-02, time/batch = 0.0768s	
1994/5250 (epoch 18.990), train_loss = 1.44336914, grad/param norm = 8.0547e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1995/5250 (epoch 19.000), train_loss = 1.41622095, grad/param norm = 7.5188e-02, time/batch = 0.0772s	
1996/5250 (epoch 19.010), train_loss = 1.59240430, grad/param norm = 7.2435e-02, time/batch = 0.0775s	
1997/5250 (epoch 19.019), train_loss = 1.40792922, grad/param norm = 7.1418e-02, time/batch = 0.0768s	
1998/5250 (epoch 19.029), train_loss = 1.41617810, grad/param norm = 6.6403e-02, time/batch = 0.0766s	
1999/5250 (epoch 19.038), train_loss = 1.40871783, grad/param norm = 7.2086e-02, time/batch = 0.0773s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch19.05_1.4933.t7	
2000/5250 (epoch 19.048), train_loss = 1.39188761, grad/param norm = 7.5405e-02, time/batch = 0.0771s	
2001/5250 (epoch 19.057), train_loss = 1.60753126, grad/param norm = 7.0538e-02, time/batch = 0.0795s	
2002/5250 (epoch 19.067), train_loss = 1.40694575, grad/param norm = 6.3053e-02, time/batch = 0.0775s	
2003/5250 (epoch 19.076), train_loss = 1.40628707, grad/param norm = 6.5370e-02, time/batch = 0.0771s	
2004/5250 (epoch 19.086), train_loss = 1.35618797, grad/param norm = 7.0764e-02, time/batch = 0.0780s	
2005/5250 (epoch 19.095), train_loss = 1.40280996, grad/param norm = 8.0668e-02, time/batch = 0.0778s	
2006/5250 (epoch 19.105), train_loss = 1.41626040, grad/param norm = 7.7117e-02, time/batch = 0.0781s	
2007/5250 (epoch 19.114), train_loss = 1.39421725, grad/param norm = 7.3936e-02, time/batch = 0.0773s	
2008/5250 (epoch 19.124), train_loss = 1.40650704, grad/param norm = 6.5781e-02, time/batch = 0.0781s	
2009/5250 (epoch 19.133), train_loss = 1.39795924, grad/param norm = 6.3354e-02, time/batch = 0.0778s	
2010/5250 (epoch 19.143), train_loss = 1.37864242, grad/param norm = 7.1833e-02, time/batch = 0.0779s	
2011/5250 (epoch 19.152), train_loss = 1.37862656, grad/param norm = 7.6242e-02, time/batch = 0.0792s	
2012/5250 (epoch 19.162), train_loss = 1.41053133, grad/param norm = 8.0893e-02, time/batch = 0.0771s	
2013/5250 (epoch 19.171), train_loss = 1.42121482, grad/param norm = 7.9111e-02, time/batch = 0.0772s	
2014/5250 (epoch 19.181), train_loss = 1.41978485, grad/param norm = 7.6059e-02, time/batch = 0.0774s	
2015/5250 (epoch 19.190), train_loss = 1.41032430, grad/param norm = 6.5004e-02, time/batch = 0.0771s	
2016/5250 (epoch 19.200), train_loss = 1.40019904, grad/param norm = 6.1259e-02, time/batch = 0.0772s	
2017/5250 (epoch 19.210), train_loss = 1.39479509, grad/param norm = 6.3330e-02, time/batch = 0.0767s	
2018/5250 (epoch 19.219), train_loss = 1.44292356, grad/param norm = 7.0858e-02, time/batch = 0.0768s	
2019/5250 (epoch 19.229), train_loss = 1.40235145, grad/param norm = 7.0119e-02, time/batch = 0.0775s	
2020/5250 (epoch 19.238), train_loss = 1.40445248, grad/param norm = 7.4328e-02, time/batch = 0.0773s	
2021/5250 (epoch 19.248), train_loss = 1.41161786, grad/param norm = 7.4563e-02, time/batch = 0.0791s	
2022/5250 (epoch 19.257), train_loss = 1.39366728, grad/param norm = 7.1273e-02, time/batch = 0.0769s	
2023/5250 (epoch 19.267), train_loss = 1.38689607, grad/param norm = 6.1433e-02, time/batch = 0.0769s	
2024/5250 (epoch 19.276), train_loss = 1.38831007, grad/param norm = 5.5537e-02, time/batch = 0.0773s	
2025/5250 (epoch 19.286), train_loss = 1.36766307, grad/param norm = 5.6882e-02, time/batch = 0.0769s	
2026/5250 (epoch 19.295), train_loss = 1.39649072, grad/param norm = 5.4136e-02, time/batch = 0.0773s	
2027/5250 (epoch 19.305), train_loss = 1.39353602, grad/param norm = 5.8194e-02, time/batch = 0.0766s	
2028/5250 (epoch 19.314), train_loss = 1.37865657, grad/param norm = 6.3386e-02, time/batch = 0.0766s	
2029/5250 (epoch 19.324), train_loss = 1.39627419, grad/param norm = 7.1047e-02, time/batch = 0.0771s	
2030/5250 (epoch 19.333), train_loss = 1.40271245, grad/param norm = 7.7743e-02, time/batch = 0.0773s	
2031/5250 (epoch 19.343), train_loss = 1.40856577, grad/param norm = 7.7289e-02, time/batch = 0.0789s	
2032/5250 (epoch 19.352), train_loss = 1.41755284, grad/param norm = 8.6492e-02, time/batch = 0.0770s	
2033/5250 (epoch 19.362), train_loss = 1.41517927, grad/param norm = 8.3255e-02, time/batch = 0.0767s	
2034/5250 (epoch 19.371), train_loss = 1.39077575, grad/param norm = 7.8758e-02, time/batch = 0.0767s	
2035/5250 (epoch 19.381), train_loss = 1.39858865, grad/param norm = 8.9806e-02, time/batch = 0.0777s	
2036/5250 (epoch 19.390), train_loss = 1.41571059, grad/param norm = 1.0270e-01, time/batch = 0.0771s	
2037/5250 (epoch 19.400), train_loss = 1.40409820, grad/param norm = 8.8928e-02, time/batch = 0.0770s	
2038/5250 (epoch 19.410), train_loss = 1.41770009, grad/param norm = 7.1883e-02, time/batch = 0.0767s	
2039/5250 (epoch 19.419), train_loss = 1.40636096, grad/param norm = 7.2568e-02, time/batch = 0.0772s	
2040/5250 (epoch 19.429), train_loss = 1.41050208, grad/param norm = 7.3644e-02, time/batch = 0.0767s	
2041/5250 (epoch 19.438), train_loss = 1.42757334, grad/param norm = 6.7284e-02, time/batch = 0.0812s	
2042/5250 (epoch 19.448), train_loss = 1.38654538, grad/param norm = 6.5701e-02, time/batch = 0.0769s	
2043/5250 (epoch 19.457), train_loss = 1.38387551, grad/param norm = 7.0495e-02, time/batch = 0.0768s	
2044/5250 (epoch 19.467), train_loss = 1.39789900, grad/param norm = 7.3828e-02, time/batch = 0.0770s	
2045/5250 (epoch 19.476), train_loss = 1.39981272, grad/param norm = 7.1947e-02, time/batch = 0.0770s	
2046/5250 (epoch 19.486), train_loss = 1.41666989, grad/param norm = 8.3011e-02, time/batch = 0.0772s	
2047/5250 (epoch 19.495), train_loss = 1.42084679, grad/param norm = 9.0669e-02, time/batch = 0.0768s	
2048/5250 (epoch 19.505), train_loss = 1.43059999, grad/param norm = 8.4800e-02, time/batch = 0.0769s	
2049/5250 (epoch 19.514), train_loss = 1.42389264, grad/param norm = 7.1907e-02, time/batch = 0.0773s	
2050/5250 (epoch 19.524), train_loss = 1.39251552, grad/param norm = 6.6201e-02, time/batch = 0.0771s	
2051/5250 (epoch 19.533), train_loss = 1.40021228, grad/param norm = 6.9878e-02, time/batch = 0.0791s	
2052/5250 (epoch 19.543), train_loss = 1.38681651, grad/param norm = 6.6408e-02, time/batch = 0.0777s	
2053/5250 (epoch 19.552), train_loss = 1.39964301, grad/param norm = 7.5820e-02, time/batch = 0.0771s	
2054/5250 (epoch 19.562), train_loss = 1.40550111, grad/param norm = 9.0895e-02, time/batch = 0.0769s	
2055/5250 (epoch 19.571), train_loss = 1.40907070, grad/param norm = 8.9621e-02, time/batch = 0.0772s	
2056/5250 (epoch 19.581), train_loss = 1.43992509, grad/param norm = 8.7730e-02, time/batch = 0.0776s	
2057/5250 (epoch 19.590), train_loss = 1.41461722, grad/param norm = 8.7965e-02, time/batch = 0.0765s	
2058/5250 (epoch 19.600), train_loss = 1.42744814, grad/param norm = 7.8249e-02, time/batch = 0.0769s	
2059/5250 (epoch 19.610), train_loss = 1.41651981, grad/param norm = 7.0998e-02, time/batch = 0.0774s	
2060/5250 (epoch 19.619), train_loss = 1.40355959, grad/param norm = 6.9046e-02, time/batch = 0.0770s	
2061/5250 (epoch 19.629), train_loss = 1.41993539, grad/param norm = 6.3264e-02, time/batch = 0.0790s	
2062/5250 (epoch 19.638), train_loss = 1.39194987, grad/param norm = 5.9161e-02, time/batch = 0.0769s	
2063/5250 (epoch 19.648), train_loss = 1.40368682, grad/param norm = 5.9496e-02, time/batch = 0.0772s	
2064/5250 (epoch 19.657), train_loss = 1.39518023, grad/param norm = 5.7152e-02, time/batch = 0.0768s	
2065/5250 (epoch 19.667), train_loss = 1.40182384, grad/param norm = 6.0366e-02, time/batch = 0.0771s	
2066/5250 (epoch 19.676), train_loss = 1.40833314, grad/param norm = 7.3432e-02, time/batch = 0.0774s	
2067/5250 (epoch 19.686), train_loss = 1.43234701, grad/param norm = 7.9414e-02, time/batch = 0.0765s	
2068/5250 (epoch 19.695), train_loss = 1.41094519, grad/param norm = 7.8165e-02, time/batch = 0.0764s	
2069/5250 (epoch 19.705), train_loss = 1.39623806, grad/param norm = 7.7489e-02, time/batch = 0.0777s	
2070/5250 (epoch 19.714), train_loss = 1.42666151, grad/param norm = 7.3277e-02, time/batch = 0.0771s	
2071/5250 (epoch 19.724), train_loss = 1.40732577, grad/param norm = 6.8558e-02, time/batch = 0.0787s	
2072/5250 (epoch 19.733), train_loss = 1.38679886, grad/param norm = 7.1309e-02, time/batch = 0.0769s	
2073/5250 (epoch 19.743), train_loss = 1.39392975, grad/param norm = 6.7093e-02, time/batch = 0.0769s	
2074/5250 (epoch 19.752), train_loss = 1.39934674, grad/param norm = 5.6581e-02, time/batch = 0.0774s	
2075/5250 (epoch 19.762), train_loss = 1.38815478, grad/param norm = 5.8506e-02, time/batch = 0.0772s	
2076/5250 (epoch 19.771), train_loss = 1.38594293, grad/param norm = 6.4170e-02, time/batch = 0.0774s	
2077/5250 (epoch 19.781), train_loss = 1.40847557, grad/param norm = 6.8583e-02, time/batch = 0.0769s	
2078/5250 (epoch 19.790), train_loss = 1.42630228, grad/param norm = 7.3359e-02, time/batch = 0.0765s	
2079/5250 (epoch 19.800), train_loss = 1.41156384, grad/param norm = 6.3018e-02, time/batch = 0.0771s	
2080/5250 (epoch 19.810), train_loss = 1.40962010, grad/param norm = 6.0764e-02, time/batch = 0.0771s	
2081/5250 (epoch 19.819), train_loss = 1.41168933, grad/param norm = 7.3044e-02, time/batch = 0.0789s	
2082/5250 (epoch 19.829), train_loss = 1.40904118, grad/param norm = 7.6849e-02, time/batch = 0.0769s	
2083/5250 (epoch 19.838), train_loss = 1.39257997, grad/param norm = 8.2118e-02, time/batch = 0.0768s	
2084/5250 (epoch 19.848), train_loss = 1.38946968, grad/param norm = 7.3917e-02, time/batch = 0.0770s	
2085/5250 (epoch 19.857), train_loss = 1.40721855, grad/param norm = 7.3054e-02, time/batch = 0.0773s	
2086/5250 (epoch 19.867), train_loss = 1.39571905, grad/param norm = 7.1575e-02, time/batch = 0.0777s	
2087/5250 (epoch 19.876), train_loss = 1.41558501, grad/param norm = 7.3700e-02, time/batch = 0.0768s	
2088/5250 (epoch 19.886), train_loss = 1.39463948, grad/param norm = 7.7670e-02, time/batch = 0.0764s	
2089/5250 (epoch 19.895), train_loss = 1.43382582, grad/param norm = 8.3383e-02, time/batch = 0.0772s	
2090/5250 (epoch 19.905), train_loss = 1.41946905, grad/param norm = 8.3161e-02, time/batch = 0.0772s	
2091/5250 (epoch 19.914), train_loss = 1.43999436, grad/param norm = 8.6494e-02, time/batch = 0.0804s	
2092/5250 (epoch 19.924), train_loss = 1.43332566, grad/param norm = 8.1434e-02, time/batch = 0.0771s	
2093/5250 (epoch 19.933), train_loss = 1.40759483, grad/param norm = 8.5147e-02, time/batch = 0.0770s	
2094/5250 (epoch 19.943), train_loss = 1.44300404, grad/param norm = 8.7164e-02, time/batch = 0.0767s	
2095/5250 (epoch 19.952), train_loss = 1.43869757, grad/param norm = 7.8790e-02, time/batch = 0.0771s	
2096/5250 (epoch 19.962), train_loss = 1.41243422, grad/param norm = 7.0336e-02, time/batch = 0.0774s	
2097/5250 (epoch 19.971), train_loss = 1.40013671, grad/param norm = 7.1818e-02, time/batch = 0.0768s	
2098/5250 (epoch 19.981), train_loss = 1.43120032, grad/param norm = 7.1508e-02, time/batch = 0.0766s	
2099/5250 (epoch 19.990), train_loss = 1.42856977, grad/param norm = 6.6779e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
2100/5250 (epoch 20.000), train_loss = 1.40348372, grad/param norm = 6.7612e-02, time/batch = 0.0771s	
2101/5250 (epoch 20.010), train_loss = 1.58231990, grad/param norm = 6.4331e-02, time/batch = 0.0789s	
2102/5250 (epoch 20.019), train_loss = 1.39542438, grad/param norm = 6.4166e-02, time/batch = 0.0775s	
2103/5250 (epoch 20.029), train_loss = 1.40364393, grad/param norm = 5.7819e-02, time/batch = 0.0772s	
2104/5250 (epoch 20.038), train_loss = 1.39486508, grad/param norm = 6.3423e-02, time/batch = 0.0767s	
2105/5250 (epoch 20.048), train_loss = 1.37828333, grad/param norm = 6.6805e-02, time/batch = 0.0771s	
2106/5250 (epoch 20.057), train_loss = 1.39155793, grad/param norm = 5.9211e-02, time/batch = 0.0773s	
2107/5250 (epoch 20.067), train_loss = 1.39333128, grad/param norm = 5.6690e-02, time/batch = 0.0764s	
2108/5250 (epoch 20.076), train_loss = 1.39408871, grad/param norm = 6.1913e-02, time/batch = 0.0770s	
2109/5250 (epoch 20.086), train_loss = 1.34285706, grad/param norm = 6.5411e-02, time/batch = 0.0773s	
2110/5250 (epoch 20.095), train_loss = 1.38883690, grad/param norm = 7.4253e-02, time/batch = 0.0769s	
2111/5250 (epoch 20.105), train_loss = 1.40310281, grad/param norm = 7.1429e-02, time/batch = 0.0787s	
2112/5250 (epoch 20.114), train_loss = 1.38126675, grad/param norm = 6.8883e-02, time/batch = 0.0769s	
2113/5250 (epoch 20.124), train_loss = 1.39534486, grad/param norm = 6.2669e-02, time/batch = 0.0773s	
2114/5250 (epoch 20.133), train_loss = 1.38526127, grad/param norm = 5.6741e-02, time/batch = 0.0770s	
2115/5250 (epoch 20.143), train_loss = 1.36600938, grad/param norm = 5.8337e-02, time/batch = 0.0770s	
2116/5250 (epoch 20.152), train_loss = 1.36385533, grad/param norm = 6.0352e-02, time/batch = 0.0773s	
2117/5250 (epoch 20.162), train_loss = 1.39674655, grad/param norm = 6.6258e-02, time/batch = 0.0768s	
2118/5250 (epoch 20.171), train_loss = 1.40711575, grad/param norm = 6.8688e-02, time/batch = 0.0764s	
2119/5250 (epoch 20.181), train_loss = 1.40866897, grad/param norm = 7.6960e-02, time/batch = 0.0778s	
2120/5250 (epoch 20.190), train_loss = 1.40138038, grad/param norm = 7.1886e-02, time/batch = 0.0771s	
2121/5250 (epoch 20.200), train_loss = 1.39112473, grad/param norm = 7.0274e-02, time/batch = 0.0788s	
2122/5250 (epoch 20.210), train_loss = 1.38610744, grad/param norm = 7.1639e-02, time/batch = 0.0769s	
2123/5250 (epoch 20.219), train_loss = 1.43360538, grad/param norm = 7.6857e-02, time/batch = 0.0770s	
2124/5250 (epoch 20.229), train_loss = 1.39159534, grad/param norm = 7.4450e-02, time/batch = 0.0771s	
2125/5250 (epoch 20.238), train_loss = 1.39505970, grad/param norm = 7.9830e-02, time/batch = 0.0775s	
2126/5250 (epoch 20.248), train_loss = 1.40330551, grad/param norm = 8.8079e-02, time/batch = 0.0775s	
2127/5250 (epoch 20.257), train_loss = 1.38641161, grad/param norm = 8.0749e-02, time/batch = 0.0765s	
2128/5250 (epoch 20.267), train_loss = 1.37646708, grad/param norm = 6.1042e-02, time/batch = 0.0766s	
2129/5250 (epoch 20.276), train_loss = 1.37678074, grad/param norm = 5.4282e-02, time/batch = 0.0772s	
2130/5250 (epoch 20.286), train_loss = 1.35710225, grad/param norm = 5.5200e-02, time/batch = 0.0776s	
2131/5250 (epoch 20.295), train_loss = 1.38654529, grad/param norm = 6.0958e-02, time/batch = 0.0789s	
2132/5250 (epoch 20.305), train_loss = 1.38535582, grad/param norm = 6.8139e-02, time/batch = 0.0766s	
2133/5250 (epoch 20.314), train_loss = 1.36883520, grad/param norm = 6.0744e-02, time/batch = 0.0767s	
2134/5250 (epoch 20.324), train_loss = 1.38292435, grad/param norm = 6.2412e-02, time/batch = 0.0769s	
2135/5250 (epoch 20.333), train_loss = 1.38852156, grad/param norm = 6.8484e-02, time/batch = 0.0776s	
2136/5250 (epoch 20.343), train_loss = 1.39599639, grad/param norm = 7.5659e-02, time/batch = 0.0770s	
2137/5250 (epoch 20.352), train_loss = 1.40551586, grad/param norm = 8.4957e-02, time/batch = 0.0768s	
2138/5250 (epoch 20.362), train_loss = 1.40442931, grad/param norm = 8.4307e-02, time/batch = 0.0767s	
2139/5250 (epoch 20.371), train_loss = 1.38209880, grad/param norm = 8.0995e-02, time/batch = 0.0773s	
2140/5250 (epoch 20.381), train_loss = 1.38940974, grad/param norm = 9.3161e-02, time/batch = 0.0769s	
2141/5250 (epoch 20.390), train_loss = 1.40486526, grad/param norm = 9.8284e-02, time/batch = 0.0794s	
2142/5250 (epoch 20.400), train_loss = 1.39210169, grad/param norm = 7.9972e-02, time/batch = 0.0770s	
2143/5250 (epoch 20.410), train_loss = 1.40505088, grad/param norm = 6.7229e-02, time/batch = 0.0770s	
2144/5250 (epoch 20.419), train_loss = 1.39356771, grad/param norm = 6.9779e-02, time/batch = 0.0767s	
2145/5250 (epoch 20.429), train_loss = 1.39897069, grad/param norm = 7.1661e-02, time/batch = 0.0768s	
2146/5250 (epoch 20.438), train_loss = 1.41558585, grad/param norm = 6.3549e-02, time/batch = 0.0772s	
2147/5250 (epoch 20.448), train_loss = 1.37432765, grad/param norm = 5.9199e-02, time/batch = 0.0768s	
2148/5250 (epoch 20.457), train_loss = 1.37154511, grad/param norm = 5.9630e-02, time/batch = 0.0778s	
2149/5250 (epoch 20.467), train_loss = 1.38482941, grad/param norm = 6.2695e-02, time/batch = 0.0776s	
2150/5250 (epoch 20.476), train_loss = 1.38730968, grad/param norm = 6.1922e-02, time/batch = 0.0773s	
2151/5250 (epoch 20.486), train_loss = 1.40248141, grad/param norm = 6.7670e-02, time/batch = 0.0788s	
2152/5250 (epoch 20.495), train_loss = 1.40510229, grad/param norm = 6.7945e-02, time/batch = 0.0803s	
2153/5250 (epoch 20.505), train_loss = 1.41331667, grad/param norm = 6.4760e-02, time/batch = 0.0769s	
2154/5250 (epoch 20.514), train_loss = 1.41196780, grad/param norm = 7.3598e-02, time/batch = 0.0769s	
2155/5250 (epoch 20.524), train_loss = 1.38356604, grad/param norm = 6.8974e-02, time/batch = 0.0767s	
2156/5250 (epoch 20.533), train_loss = 1.39151802, grad/param norm = 7.4875e-02, time/batch = 0.0773s	
2157/5250 (epoch 20.543), train_loss = 1.38048947, grad/param norm = 7.9388e-02, time/batch = 0.0767s	
2158/5250 (epoch 20.552), train_loss = 1.39329811, grad/param norm = 8.6060e-02, time/batch = 0.0772s	
2159/5250 (epoch 20.562), train_loss = 1.39373205, grad/param norm = 8.6347e-02, time/batch = 0.0774s	
2160/5250 (epoch 20.571), train_loss = 1.39511304, grad/param norm = 7.6226e-02, time/batch = 0.0772s	
2161/5250 (epoch 20.581), train_loss = 1.42340161, grad/param norm = 6.8132e-02, time/batch = 0.0792s	
2162/5250 (epoch 20.590), train_loss = 1.39839206, grad/param norm = 6.8906e-02, time/batch = 0.0770s	
2163/5250 (epoch 20.600), train_loss = 1.41416661, grad/param norm = 6.5555e-02, time/batch = 0.0777s	
2164/5250 (epoch 20.610), train_loss = 1.40427017, grad/param norm = 6.4226e-02, time/batch = 0.0770s	
2165/5250 (epoch 20.619), train_loss = 1.39191834, grad/param norm = 6.5829e-02, time/batch = 0.0768s	
2166/5250 (epoch 20.629), train_loss = 1.40774176, grad/param norm = 6.1977e-02, time/batch = 0.0772s	
2167/5250 (epoch 20.638), train_loss = 1.38107824, grad/param norm = 5.8626e-02, time/batch = 0.0767s	
2168/5250 (epoch 20.648), train_loss = 1.39263658, grad/param norm = 6.0879e-02, time/batch = 0.0767s	
2169/5250 (epoch 20.657), train_loss = 1.38564204, grad/param norm = 5.6588e-02, time/batch = 0.0776s	
2170/5250 (epoch 20.667), train_loss = 1.38998399, grad/param norm = 5.3869e-02, time/batch = 0.0769s	
2171/5250 (epoch 20.676), train_loss = 1.39564742, grad/param norm = 6.2095e-02, time/batch = 0.0789s	
2172/5250 (epoch 20.686), train_loss = 1.41804373, grad/param norm = 6.1783e-02, time/batch = 0.0768s	
2173/5250 (epoch 20.695), train_loss = 1.39755706, grad/param norm = 6.7549e-02, time/batch = 0.0769s	
2174/5250 (epoch 20.705), train_loss = 1.38279040, grad/param norm = 7.2072e-02, time/batch = 0.0774s	
2175/5250 (epoch 20.714), train_loss = 1.41926672, grad/param norm = 7.6898e-02, time/batch = 0.0773s	
2176/5250 (epoch 20.724), train_loss = 1.40220859, grad/param norm = 7.7383e-02, time/batch = 0.0773s	
2177/5250 (epoch 20.733), train_loss = 1.38294874, grad/param norm = 8.4913e-02, time/batch = 0.0765s	
2178/5250 (epoch 20.743), train_loss = 1.39540470, grad/param norm = 1.0950e-01, time/batch = 0.0768s	
2179/5250 (epoch 20.752), train_loss = 1.40469024, grad/param norm = 9.9551e-02, time/batch = 0.0773s	
2180/5250 (epoch 20.762), train_loss = 1.38630875, grad/param norm = 8.8787e-02, time/batch = 0.0773s	
2181/5250 (epoch 20.771), train_loss = 1.37954552, grad/param norm = 8.0826e-02, time/batch = 0.0789s	
2182/5250 (epoch 20.781), train_loss = 1.39979796, grad/param norm = 7.6473e-02, time/batch = 0.0768s	
2183/5250 (epoch 20.790), train_loss = 1.41541841, grad/param norm = 7.5346e-02, time/batch = 0.0768s	
2184/5250 (epoch 20.800), train_loss = 1.40104194, grad/param norm = 7.0835e-02, time/batch = 0.0768s	
2185/5250 (epoch 20.810), train_loss = 1.39888010, grad/param norm = 6.2987e-02, time/batch = 0.0773s	
2186/5250 (epoch 20.819), train_loss = 1.39934057, grad/param norm = 6.2797e-02, time/batch = 0.0774s	
2187/5250 (epoch 20.829), train_loss = 1.39529773, grad/param norm = 6.6553e-02, time/batch = 0.0769s	
2188/5250 (epoch 20.838), train_loss = 1.37738938, grad/param norm = 6.0378e-02, time/batch = 0.0768s	
2189/5250 (epoch 20.848), train_loss = 1.37493093, grad/param norm = 6.6025e-02, time/batch = 0.0771s	
2190/5250 (epoch 20.857), train_loss = 1.39326136, grad/param norm = 6.9834e-02, time/batch = 0.0771s	
2191/5250 (epoch 20.867), train_loss = 1.38502240, grad/param norm = 6.9435e-02, time/batch = 0.0794s	
2192/5250 (epoch 20.876), train_loss = 1.40250737, grad/param norm = 6.7885e-02, time/batch = 0.0769s	
2193/5250 (epoch 20.886), train_loss = 1.38059089, grad/param norm = 6.6504e-02, time/batch = 0.0767s	
2194/5250 (epoch 20.895), train_loss = 1.42023365, grad/param norm = 6.8977e-02, time/batch = 0.0767s	
2195/5250 (epoch 20.905), train_loss = 1.40546828, grad/param norm = 6.6608e-02, time/batch = 0.0769s	
2196/5250 (epoch 20.914), train_loss = 1.42560688, grad/param norm = 7.4119e-02, time/batch = 0.0779s	
2197/5250 (epoch 20.924), train_loss = 1.41913540, grad/param norm = 7.0217e-02, time/batch = 0.0768s	
2198/5250 (epoch 20.933), train_loss = 1.39087615, grad/param norm = 6.4278e-02, time/batch = 0.0768s	
2199/5250 (epoch 20.943), train_loss = 1.42800757, grad/param norm = 7.2101e-02, time/batch = 0.0773s	
2200/5250 (epoch 20.952), train_loss = 1.42713979, grad/param norm = 7.7490e-02, time/batch = 0.0770s	
2201/5250 (epoch 20.962), train_loss = 1.40337964, grad/param norm = 7.3022e-02, time/batch = 0.0788s	
2202/5250 (epoch 20.971), train_loss = 1.39014815, grad/param norm = 7.1489e-02, time/batch = 0.0774s	
2203/5250 (epoch 20.981), train_loss = 1.42016164, grad/param norm = 6.4295e-02, time/batch = 0.0772s	
2204/5250 (epoch 20.990), train_loss = 1.41736999, grad/param norm = 5.9924e-02, time/batch = 0.0770s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
2205/5250 (epoch 21.000), train_loss = 1.39452753, grad/param norm = 6.7295e-02, time/batch = 0.0772s	
2206/5250 (epoch 21.010), train_loss = 1.57815091, grad/param norm = 7.9791e-02, time/batch = 0.0775s	
2207/5250 (epoch 21.019), train_loss = 1.39022306, grad/param norm = 8.8030e-02, time/batch = 0.0766s	
2208/5250 (epoch 21.029), train_loss = 1.39912085, grad/param norm = 8.0873e-02, time/batch = 0.0772s	
2209/5250 (epoch 21.038), train_loss = 1.39045698, grad/param norm = 8.1910e-02, time/batch = 0.0774s	
2210/5250 (epoch 21.048), train_loss = 1.37099121, grad/param norm = 7.7268e-02, time/batch = 0.0770s	
2211/5250 (epoch 21.057), train_loss = 1.38269761, grad/param norm = 6.4629e-02, time/batch = 0.0788s	
2212/5250 (epoch 21.067), train_loss = 1.38396863, grad/param norm = 6.0937e-02, time/batch = 0.0768s	
2213/5250 (epoch 21.076), train_loss = 1.38560091, grad/param norm = 6.3774e-02, time/batch = 0.0775s	
2214/5250 (epoch 21.086), train_loss = 1.33386398, grad/param norm = 6.5949e-02, time/batch = 0.0768s	
2215/5250 (epoch 21.095), train_loss = 1.37807525, grad/param norm = 7.2291e-02, time/batch = 0.0773s	
2216/5250 (epoch 21.105), train_loss = 1.39309602, grad/param norm = 7.1858e-02, time/batch = 0.0770s	
2217/5250 (epoch 21.114), train_loss = 1.37227766, grad/param norm = 7.2049e-02, time/batch = 0.0768s	
2218/5250 (epoch 21.124), train_loss = 1.38601336, grad/param norm = 6.5622e-02, time/batch = 0.0767s	
2219/5250 (epoch 21.133), train_loss = 1.37601545, grad/param norm = 6.3061e-02, time/batch = 0.0777s	
2220/5250 (epoch 21.143), train_loss = 1.35874789, grad/param norm = 7.0349e-02, time/batch = 0.0773s	
2221/5250 (epoch 21.152), train_loss = 1.35707840, grad/param norm = 7.1011e-02, time/batch = 0.0789s	
2222/5250 (epoch 21.162), train_loss = 1.38800208, grad/param norm = 7.1213e-02, time/batch = 0.0767s	
2223/5250 (epoch 21.171), train_loss = 1.39705803, grad/param norm = 6.8636e-02, time/batch = 0.0767s	
2224/5250 (epoch 21.181), train_loss = 1.39654225, grad/param norm = 6.8635e-02, time/batch = 0.0773s	
2225/5250 (epoch 21.190), train_loss = 1.38922566, grad/param norm = 6.0931e-02, time/batch = 0.0769s	
2226/5250 (epoch 21.200), train_loss = 1.37886481, grad/param norm = 5.9491e-02, time/batch = 0.0776s	
2227/5250 (epoch 21.210), train_loss = 1.37374044, grad/param norm = 6.1370e-02, time/batch = 0.0767s	
2228/5250 (epoch 21.219), train_loss = 1.42203341, grad/param norm = 6.9793e-02, time/batch = 0.0768s	
2229/5250 (epoch 21.229), train_loss = 1.38089703, grad/param norm = 6.7677e-02, time/batch = 0.0772s	
2230/5250 (epoch 21.238), train_loss = 1.38281417, grad/param norm = 6.8002e-02, time/batch = 0.0775s	
2231/5250 (epoch 21.248), train_loss = 1.38717556, grad/param norm = 6.6270e-02, time/batch = 0.0790s	
2232/5250 (epoch 21.257), train_loss = 1.37232208, grad/param norm = 6.3582e-02, time/batch = 0.0769s	
2233/5250 (epoch 21.267), train_loss = 1.36493920, grad/param norm = 5.8128e-02, time/batch = 0.0766s	
2234/5250 (epoch 21.276), train_loss = 1.36699167, grad/param norm = 5.5104e-02, time/batch = 0.0766s	
2235/5250 (epoch 21.286), train_loss = 1.34820960, grad/param norm = 5.8454e-02, time/batch = 0.0774s	
2236/5250 (epoch 21.295), train_loss = 1.37713387, grad/param norm = 6.3293e-02, time/batch = 0.0774s	
2237/5250 (epoch 21.305), train_loss = 1.37560899, grad/param norm = 6.6625e-02, time/batch = 0.0767s	
2238/5250 (epoch 21.314), train_loss = 1.35880170, grad/param norm = 5.8697e-02, time/batch = 0.0767s	
2239/5250 (epoch 21.324), train_loss = 1.37201029, grad/param norm = 6.0018e-02, time/batch = 0.0774s	
2240/5250 (epoch 21.333), train_loss = 1.37707516, grad/param norm = 6.1271e-02, time/batch = 0.0771s	
2241/5250 (epoch 21.343), train_loss = 1.38397615, grad/param norm = 6.4449e-02, time/batch = 0.0793s	
2242/5250 (epoch 21.352), train_loss = 1.39422636, grad/param norm = 7.5038e-02, time/batch = 0.0769s	
2243/5250 (epoch 21.362), train_loss = 1.39300105, grad/param norm = 7.5798e-02, time/batch = 0.0769s	
2244/5250 (epoch 21.371), train_loss = 1.37032587, grad/param norm = 7.2232e-02, time/batch = 0.0770s	
2245/5250 (epoch 21.381), train_loss = 1.37450404, grad/param norm = 7.6506e-02, time/batch = 0.0768s	
2246/5250 (epoch 21.390), train_loss = 1.39251579, grad/param norm = 9.0152e-02, time/batch = 0.0778s	
2247/5250 (epoch 21.400), train_loss = 1.38577968, grad/param norm = 8.9155e-02, time/batch = 0.0769s	
2248/5250 (epoch 21.410), train_loss = 1.39741090, grad/param norm = 7.9161e-02, time/batch = 0.0770s	
2249/5250 (epoch 21.419), train_loss = 1.38424265, grad/param norm = 7.3269e-02, time/batch = 0.0772s	
2250/5250 (epoch 21.429), train_loss = 1.38822566, grad/param norm = 6.5132e-02, time/batch = 0.0767s	
2251/5250 (epoch 21.438), train_loss = 1.40391010, grad/param norm = 6.1068e-02, time/batch = 0.0786s	
2252/5250 (epoch 21.448), train_loss = 1.36610513, grad/param norm = 6.6094e-02, time/batch = 0.0774s	
2253/5250 (epoch 21.457), train_loss = 1.36521131, grad/param norm = 8.0509e-02, time/batch = 0.0769s	
2254/5250 (epoch 21.467), train_loss = 1.37904438, grad/param norm = 6.7105e-02, time/batch = 0.0769s	
2255/5250 (epoch 21.476), train_loss = 1.38103907, grad/param norm = 7.0612e-02, time/batch = 0.0768s	
2256/5250 (epoch 21.486), train_loss = 1.39526258, grad/param norm = 7.6356e-02, time/batch = 0.0773s	
2257/5250 (epoch 21.495), train_loss = 1.39674115, grad/param norm = 7.0190e-02, time/batch = 0.0768s	
2258/5250 (epoch 21.505), train_loss = 1.40471807, grad/param norm = 6.6765e-02, time/batch = 0.0768s	
2259/5250 (epoch 21.514), train_loss = 1.40304521, grad/param norm = 7.4641e-02, time/batch = 0.0772s	
2260/5250 (epoch 21.524), train_loss = 1.37271618, grad/param norm = 7.4831e-02, time/batch = 0.0773s	
2261/5250 (epoch 21.533), train_loss = 1.37975526, grad/param norm = 7.4964e-02, time/batch = 0.0788s	
2262/5250 (epoch 21.543), train_loss = 1.37047242, grad/param norm = 7.1024e-02, time/batch = 0.0768s	
2263/5250 (epoch 21.552), train_loss = 1.37842492, grad/param norm = 6.9810e-02, time/batch = 0.0808s	
2264/5250 (epoch 21.562), train_loss = 1.37682143, grad/param norm = 6.3399e-02, time/batch = 0.0775s	
2265/5250 (epoch 21.571), train_loss = 1.38053471, grad/param norm = 6.8801e-02, time/batch = 0.0770s	
2266/5250 (epoch 21.581), train_loss = 1.41537375, grad/param norm = 7.3912e-02, time/batch = 0.0774s	
2267/5250 (epoch 21.590), train_loss = 1.38953715, grad/param norm = 6.7178e-02, time/batch = 0.0767s	
2268/5250 (epoch 21.600), train_loss = 1.40355641, grad/param norm = 6.0292e-02, time/batch = 0.0769s	
2269/5250 (epoch 21.610), train_loss = 1.39526930, grad/param norm = 6.8543e-02, time/batch = 0.0775s	
2270/5250 (epoch 21.619), train_loss = 1.38451815, grad/param norm = 7.3444e-02, time/batch = 0.0773s	
2271/5250 (epoch 21.629), train_loss = 1.39857100, grad/param norm = 6.9009e-02, time/batch = 0.0790s	
2272/5250 (epoch 21.638), train_loss = 1.37361022, grad/param norm = 6.9119e-02, time/batch = 0.0770s	
2273/5250 (epoch 21.648), train_loss = 1.38575948, grad/param norm = 7.6827e-02, time/batch = 0.0773s	
2274/5250 (epoch 21.657), train_loss = 1.38007831, grad/param norm = 6.9761e-02, time/batch = 0.0773s	
2275/5250 (epoch 21.667), train_loss = 1.38403064, grad/param norm = 6.8366e-02, time/batch = 0.0773s	
2276/5250 (epoch 21.676), train_loss = 1.39146834, grad/param norm = 7.9837e-02, time/batch = 0.0773s	
2277/5250 (epoch 21.686), train_loss = 1.41326014, grad/param norm = 7.8793e-02, time/batch = 0.0767s	
2278/5250 (epoch 21.695), train_loss = 1.39439770, grad/param norm = 9.3312e-02, time/batch = 0.0765s	
2279/5250 (epoch 21.705), train_loss = 1.37804465, grad/param norm = 8.1246e-02, time/batch = 0.0773s	
2280/5250 (epoch 21.714), train_loss = 1.40912320, grad/param norm = 6.4629e-02, time/batch = 0.0775s	
2281/5250 (epoch 21.724), train_loss = 1.38796762, grad/param norm = 6.4066e-02, time/batch = 0.0789s	
2282/5250 (epoch 21.733), train_loss = 1.36687572, grad/param norm = 6.6212e-02, time/batch = 0.0770s	
2283/5250 (epoch 21.743), train_loss = 1.37429824, grad/param norm = 6.8227e-02, time/batch = 0.0769s	
2284/5250 (epoch 21.752), train_loss = 1.38098360, grad/param norm = 5.6621e-02, time/batch = 0.0767s	
2285/5250 (epoch 21.762), train_loss = 1.36892303, grad/param norm = 5.8984e-02, time/batch = 0.0773s	
2286/5250 (epoch 21.771), train_loss = 1.36468425, grad/param norm = 5.9279e-02, time/batch = 0.0774s	
2287/5250 (epoch 21.781), train_loss = 1.38734305, grad/param norm = 6.2294e-02, time/batch = 0.0766s	
2288/5250 (epoch 21.790), train_loss = 1.40351994, grad/param norm = 6.6402e-02, time/batch = 0.0765s	
2289/5250 (epoch 21.800), train_loss = 1.38939929, grad/param norm = 6.3888e-02, time/batch = 0.0774s	
2290/5250 (epoch 21.810), train_loss = 1.38864722, grad/param norm = 6.0880e-02, time/batch = 0.0770s	
2291/5250 (epoch 21.819), train_loss = 1.39074646, grad/param norm = 6.3656e-02, time/batch = 0.0795s	
2292/5250 (epoch 21.829), train_loss = 1.38679311, grad/param norm = 6.7665e-02, time/batch = 0.0772s	
2293/5250 (epoch 21.838), train_loss = 1.36826509, grad/param norm = 6.1099e-02, time/batch = 0.0769s	
2294/5250 (epoch 21.848), train_loss = 1.36640183, grad/param norm = 6.7798e-02, time/batch = 0.0769s	
2295/5250 (epoch 21.857), train_loss = 1.38434418, grad/param norm = 7.4631e-02, time/batch = 0.0771s	
2296/5250 (epoch 21.867), train_loss = 1.37672918, grad/param norm = 7.3571e-02, time/batch = 0.0778s	
2297/5250 (epoch 21.876), train_loss = 1.39277311, grad/param norm = 7.0251e-02, time/batch = 0.0771s	
2298/5250 (epoch 21.886), train_loss = 1.37133815, grad/param norm = 6.7204e-02, time/batch = 0.0767s	
2299/5250 (epoch 21.895), train_loss = 1.41123372, grad/param norm = 7.2068e-02, time/batch = 0.0771s	
2300/5250 (epoch 21.905), train_loss = 1.39810985, grad/param norm = 7.4671e-02, time/batch = 0.0767s	
2301/5250 (epoch 21.914), train_loss = 1.41819148, grad/param norm = 8.4258e-02, time/batch = 0.0787s	
2302/5250 (epoch 21.924), train_loss = 1.41094275, grad/param norm = 7.4150e-02, time/batch = 0.0780s	
2303/5250 (epoch 21.933), train_loss = 1.37977309, grad/param norm = 6.1957e-02, time/batch = 0.0770s	
2304/5250 (epoch 21.943), train_loss = 1.41601287, grad/param norm = 6.2737e-02, time/batch = 0.0770s	
2305/5250 (epoch 21.952), train_loss = 1.41493275, grad/param norm = 7.0268e-02, time/batch = 0.0772s	
2306/5250 (epoch 21.962), train_loss = 1.39225033, grad/param norm = 7.0858e-02, time/batch = 0.0775s	
2307/5250 (epoch 21.971), train_loss = 1.38263937, grad/param norm = 7.3995e-02, time/batch = 0.0768s	
2308/5250 (epoch 21.981), train_loss = 1.41572998, grad/param norm = 8.4062e-02, time/batch = 0.0767s	
2309/5250 (epoch 21.990), train_loss = 1.41410578, grad/param norm = 8.7065e-02, time/batch = 0.0773s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
2310/5250 (epoch 22.000), train_loss = 1.38904793, grad/param norm = 8.1188e-02, time/batch = 0.0771s	
2311/5250 (epoch 22.010), train_loss = 1.56965953, grad/param norm = 7.8158e-02, time/batch = 0.0789s	
2312/5250 (epoch 22.019), train_loss = 1.37794082, grad/param norm = 7.6289e-02, time/batch = 0.0768s	
2313/5250 (epoch 22.029), train_loss = 1.38821827, grad/param norm = 7.3259e-02, time/batch = 0.0775s	
2314/5250 (epoch 22.038), train_loss = 1.37994230, grad/param norm = 7.4592e-02, time/batch = 0.0768s	
2315/5250 (epoch 22.048), train_loss = 1.35949122, grad/param norm = 7.0094e-02, time/batch = 0.0772s	
2316/5250 (epoch 22.057), train_loss = 1.37127349, grad/param norm = 6.0825e-02, time/batch = 0.0771s	
2317/5250 (epoch 22.067), train_loss = 1.37436683, grad/param norm = 5.7394e-02, time/batch = 0.0765s	
2318/5250 (epoch 22.076), train_loss = 1.37678159, grad/param norm = 6.3511e-02, time/batch = 0.0764s	
2319/5250 (epoch 22.086), train_loss = 1.32602649, grad/param norm = 6.9693e-02, time/batch = 0.0778s	
2320/5250 (epoch 22.095), train_loss = 1.36820152, grad/param norm = 7.2936e-02, time/batch = 0.0771s	
2321/5250 (epoch 22.105), train_loss = 1.38217445, grad/param norm = 6.7208e-02, time/batch = 0.0789s	
2322/5250 (epoch 22.114), train_loss = 1.36108151, grad/param norm = 6.3422e-02, time/batch = 0.0768s	
2323/5250 (epoch 22.124), train_loss = 1.37578685, grad/param norm = 5.9224e-02, time/batch = 0.0766s	
2324/5250 (epoch 22.133), train_loss = 1.36566420, grad/param norm = 5.8132e-02, time/batch = 0.0775s	
2325/5250 (epoch 22.143), train_loss = 1.34847347, grad/param norm = 6.2777e-02, time/batch = 0.0770s	
2326/5250 (epoch 22.152), train_loss = 1.34571052, grad/param norm = 6.0632e-02, time/batch = 0.0775s	
2327/5250 (epoch 22.162), train_loss = 1.37688075, grad/param norm = 6.0577e-02, time/batch = 0.0768s	
2328/5250 (epoch 22.171), train_loss = 1.38546101, grad/param norm = 5.8525e-02, time/batch = 0.0768s	
2329/5250 (epoch 22.181), train_loss = 1.38529948, grad/param norm = 6.0041e-02, time/batch = 0.0768s	
2330/5250 (epoch 22.190), train_loss = 1.37918803, grad/param norm = 5.5888e-02, time/batch = 0.0774s	
2331/5250 (epoch 22.200), train_loss = 1.36933791, grad/param norm = 5.8498e-02, time/batch = 0.0788s	
2332/5250 (epoch 22.210), train_loss = 1.36538396, grad/param norm = 6.3126e-02, time/batch = 0.0769s	
2333/5250 (epoch 22.219), train_loss = 1.41389414, grad/param norm = 7.2612e-02, time/batch = 0.0769s	
2334/5250 (epoch 22.229), train_loss = 1.37244572, grad/param norm = 6.9795e-02, time/batch = 0.0769s	
2335/5250 (epoch 22.238), train_loss = 1.37423715, grad/param norm = 6.8567e-02, time/batch = 0.0778s	
2336/5250 (epoch 22.248), train_loss = 1.37753562, grad/param norm = 6.5125e-02, time/batch = 0.0775s	
2337/5250 (epoch 22.257), train_loss = 1.36334350, grad/param norm = 6.1739e-02, time/batch = 0.0770s	
2338/5250 (epoch 22.267), train_loss = 1.35538336, grad/param norm = 5.6523e-02, time/batch = 0.0765s	
2339/5250 (epoch 22.276), train_loss = 1.35771357, grad/param norm = 5.3690e-02, time/batch = 0.0770s	
2340/5250 (epoch 22.286), train_loss = 1.33916492, grad/param norm = 5.7133e-02, time/batch = 0.0768s	
2341/5250 (epoch 22.295), train_loss = 1.36764666, grad/param norm = 6.1936e-02, time/batch = 0.0788s	
2342/5250 (epoch 22.305), train_loss = 1.36639838, grad/param norm = 6.6898e-02, time/batch = 0.0770s	
2343/5250 (epoch 22.314), train_loss = 1.35002811, grad/param norm = 5.7680e-02, time/batch = 0.0769s	
2344/5250 (epoch 22.324), train_loss = 1.36223226, grad/param norm = 5.8254e-02, time/batch = 0.0769s	
2345/5250 (epoch 22.333), train_loss = 1.36768537, grad/param norm = 5.9438e-02, time/batch = 0.0771s	
2346/5250 (epoch 22.343), train_loss = 1.37425701, grad/param norm = 6.2640e-02, time/batch = 0.0779s	
2347/5250 (epoch 22.352), train_loss = 1.38482699, grad/param norm = 7.2811e-02, time/batch = 0.0767s	
2348/5250 (epoch 22.362), train_loss = 1.38274867, grad/param norm = 7.2967e-02, time/batch = 0.0768s	
2349/5250 (epoch 22.371), train_loss = 1.36068491, grad/param norm = 6.7516e-02, time/batch = 0.0773s	
2350/5250 (epoch 22.381), train_loss = 1.36357444, grad/param norm = 7.1404e-02, time/batch = 0.0771s	
2351/5250 (epoch 22.390), train_loss = 1.38020800, grad/param norm = 8.3461e-02, time/batch = 0.0787s	
2352/5250 (epoch 22.400), train_loss = 1.37467842, grad/param norm = 8.0157e-02, time/batch = 0.0774s	
2353/5250 (epoch 22.410), train_loss = 1.38519796, grad/param norm = 7.1248e-02, time/batch = 0.0770s	
2354/5250 (epoch 22.419), train_loss = 1.37351824, grad/param norm = 6.9277e-02, time/batch = 0.0768s	
2355/5250 (epoch 22.429), train_loss = 1.37886718, grad/param norm = 6.3074e-02, time/batch = 0.0771s	
2356/5250 (epoch 22.438), train_loss = 1.39431521, grad/param norm = 5.7772e-02, time/batch = 0.0774s	
2357/5250 (epoch 22.448), train_loss = 1.35605070, grad/param norm = 6.0772e-02, time/batch = 0.0769s	
2358/5250 (epoch 22.457), train_loss = 1.35609742, grad/param norm = 7.9579e-02, time/batch = 0.0765s	
2359/5250 (epoch 22.467), train_loss = 1.36977717, grad/param norm = 6.4961e-02, time/batch = 0.0772s	
2360/5250 (epoch 22.476), train_loss = 1.37088422, grad/param norm = 6.4616e-02, time/batch = 0.0770s	
2361/5250 (epoch 22.486), train_loss = 1.38559769, grad/param norm = 7.1676e-02, time/batch = 0.0788s	
2362/5250 (epoch 22.495), train_loss = 1.38661192, grad/param norm = 6.4234e-02, time/batch = 0.0768s	
2363/5250 (epoch 22.505), train_loss = 1.39392586, grad/param norm = 5.9213e-02, time/batch = 0.0774s	
2364/5250 (epoch 22.514), train_loss = 1.39211651, grad/param norm = 6.6532e-02, time/batch = 0.0767s	
2365/5250 (epoch 22.524), train_loss = 1.36253269, grad/param norm = 6.8397e-02, time/batch = 0.0771s	
2366/5250 (epoch 22.533), train_loss = 1.37030757, grad/param norm = 7.1023e-02, time/batch = 0.0799s	
2367/5250 (epoch 22.543), train_loss = 1.36193594, grad/param norm = 6.9368e-02, time/batch = 0.0772s	
2368/5250 (epoch 22.552), train_loss = 1.37098914, grad/param norm = 7.2047e-02, time/batch = 0.0766s	
2369/5250 (epoch 22.562), train_loss = 1.36884057, grad/param norm = 6.7610e-02, time/batch = 0.0778s	
2370/5250 (epoch 22.571), train_loss = 1.37298567, grad/param norm = 7.2646e-02, time/batch = 0.0773s	
2371/5250 (epoch 22.581), train_loss = 1.40676054, grad/param norm = 7.4687e-02, time/batch = 0.0788s	
2372/5250 (epoch 22.590), train_loss = 1.37942064, grad/param norm = 6.7424e-02, time/batch = 0.0770s	
2373/5250 (epoch 22.600), train_loss = 1.39487488, grad/param norm = 6.1000e-02, time/batch = 0.0769s	
2374/5250 (epoch 22.610), train_loss = 1.38617485, grad/param norm = 6.4999e-02, time/batch = 0.0798s	
2375/5250 (epoch 22.619), train_loss = 1.37452103, grad/param norm = 6.6794e-02, time/batch = 0.0789s	
2376/5250 (epoch 22.629), train_loss = 1.38783036, grad/param norm = 6.3691e-02, time/batch = 0.0777s	
2377/5250 (epoch 22.638), train_loss = 1.36386019, grad/param norm = 6.6904e-02, time/batch = 0.0769s	
2378/5250 (epoch 22.648), train_loss = 1.37579147, grad/param norm = 7.1102e-02, time/batch = 0.0770s	
2379/5250 (epoch 22.657), train_loss = 1.37029458, grad/param norm = 6.1865e-02, time/batch = 0.0775s	
2380/5250 (epoch 22.667), train_loss = 1.37365326, grad/param norm = 6.2369e-02, time/batch = 0.0778s	
2381/5250 (epoch 22.676), train_loss = 1.38088786, grad/param norm = 7.4011e-02, time/batch = 0.0790s	
2382/5250 (epoch 22.686), train_loss = 1.40186799, grad/param norm = 6.9987e-02, time/batch = 0.0769s	
2383/5250 (epoch 22.695), train_loss = 1.38301666, grad/param norm = 7.6795e-02, time/batch = 0.0769s	
2384/5250 (epoch 22.705), train_loss = 1.36737228, grad/param norm = 7.7693e-02, time/batch = 0.0769s	
2385/5250 (epoch 22.714), train_loss = 1.40133413, grad/param norm = 7.1734e-02, time/batch = 0.0774s	
2386/5250 (epoch 22.724), train_loss = 1.38122889, grad/param norm = 6.5170e-02, time/batch = 0.0772s	
2387/5250 (epoch 22.733), train_loss = 1.35907059, grad/param norm = 6.6865e-02, time/batch = 0.0765s	
2388/5250 (epoch 22.743), train_loss = 1.36720031, grad/param norm = 7.5141e-02, time/batch = 0.0766s	
2389/5250 (epoch 22.752), train_loss = 1.37481832, grad/param norm = 6.6085e-02, time/batch = 0.0772s	
2390/5250 (epoch 22.762), train_loss = 1.36232251, grad/param norm = 6.7050e-02, time/batch = 0.0769s	
2391/5250 (epoch 22.771), train_loss = 1.35719856, grad/param norm = 6.5294e-02, time/batch = 0.0789s	
2392/5250 (epoch 22.781), train_loss = 1.37937131, grad/param norm = 6.6769e-02, time/batch = 0.0770s	
2393/5250 (epoch 22.790), train_loss = 1.39537520, grad/param norm = 7.2470e-02, time/batch = 0.0770s	
2394/5250 (epoch 22.800), train_loss = 1.38277128, grad/param norm = 7.2319e-02, time/batch = 0.0769s	
2395/5250 (epoch 22.810), train_loss = 1.38102364, grad/param norm = 6.4481e-02, time/batch = 0.0771s	
2396/5250 (epoch 22.819), train_loss = 1.38259584, grad/param norm = 6.4684e-02, time/batch = 0.0778s	
2397/5250 (epoch 22.829), train_loss = 1.37821176, grad/param norm = 6.7668e-02, time/batch = 0.0768s	
2398/5250 (epoch 22.838), train_loss = 1.35908137, grad/param norm = 5.8711e-02, time/batch = 0.0767s	
2399/5250 (epoch 22.848), train_loss = 1.35745147, grad/param norm = 6.5020e-02, time/batch = 0.0774s	
2400/5250 (epoch 22.857), train_loss = 1.37413692, grad/param norm = 6.8779e-02, time/batch = 0.0768s	
2401/5250 (epoch 22.867), train_loss = 1.36745985, grad/param norm = 6.8337e-02, time/batch = 0.0788s	
2402/5250 (epoch 22.876), train_loss = 1.38255300, grad/param norm = 6.4219e-02, time/batch = 0.0776s	
2403/5250 (epoch 22.886), train_loss = 1.36155793, grad/param norm = 6.1976e-02, time/batch = 0.0771s	
2404/5250 (epoch 22.895), train_loss = 1.40179738, grad/param norm = 6.6966e-02, time/batch = 0.0768s	
2405/5250 (epoch 22.905), train_loss = 1.38751921, grad/param norm = 6.5008e-02, time/batch = 0.0769s	
2406/5250 (epoch 22.914), train_loss = 1.40625253, grad/param norm = 7.1337e-02, time/batch = 0.0771s	
2407/5250 (epoch 22.924), train_loss = 1.39915992, grad/param norm = 6.3699e-02, time/batch = 0.0774s	
2408/5250 (epoch 22.933), train_loss = 1.36952009, grad/param norm = 5.5895e-02, time/batch = 0.0769s	
2409/5250 (epoch 22.943), train_loss = 1.40632060, grad/param norm = 6.1746e-02, time/batch = 0.0774s	
2410/5250 (epoch 22.952), train_loss = 1.40499732, grad/param norm = 6.3817e-02, time/batch = 0.0769s	
2411/5250 (epoch 22.962), train_loss = 1.38230457, grad/param norm = 6.1959e-02, time/batch = 0.0787s	
2412/5250 (epoch 22.971), train_loss = 1.37281353, grad/param norm = 6.6847e-02, time/batch = 0.0770s	
2413/5250 (epoch 22.981), train_loss = 1.40264374, grad/param norm = 6.6530e-02, time/batch = 0.0787s	
2414/5250 (epoch 22.990), train_loss = 1.40007803, grad/param norm = 6.3438e-02, time/batch = 0.0786s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
2415/5250 (epoch 23.000), train_loss = 1.37806336, grad/param norm = 6.8134e-02, time/batch = 0.0773s	
2416/5250 (epoch 23.010), train_loss = 1.56436856, grad/param norm = 7.8541e-02, time/batch = 0.0774s	
2417/5250 (epoch 23.019), train_loss = 1.37179544, grad/param norm = 8.5161e-02, time/batch = 0.0765s	
2418/5250 (epoch 23.029), train_loss = 1.38219432, grad/param norm = 8.1790e-02, time/batch = 0.0767s	
2419/5250 (epoch 23.038), train_loss = 1.37397604, grad/param norm = 8.5398e-02, time/batch = 0.0780s	
2420/5250 (epoch 23.048), train_loss = 1.35339695, grad/param norm = 7.7527e-02, time/batch = 0.0771s	
2421/5250 (epoch 23.057), train_loss = 1.36336503, grad/param norm = 6.2518e-02, time/batch = 0.0789s	
2422/5250 (epoch 23.067), train_loss = 1.36624918, grad/param norm = 5.9143e-02, time/batch = 0.0769s	
2423/5250 (epoch 23.076), train_loss = 1.36955841, grad/param norm = 6.5267e-02, time/batch = 0.0769s	
2424/5250 (epoch 23.086), train_loss = 1.31803718, grad/param norm = 6.8307e-02, time/batch = 0.0771s	
2425/5250 (epoch 23.095), train_loss = 1.35896208, grad/param norm = 7.1262e-02, time/batch = 0.0773s	
2426/5250 (epoch 23.105), train_loss = 1.37344958, grad/param norm = 6.6961e-02, time/batch = 0.0771s	
2427/5250 (epoch 23.114), train_loss = 1.35290641, grad/param norm = 6.4011e-02, time/batch = 0.0765s	
2428/5250 (epoch 23.124), train_loss = 1.36743220, grad/param norm = 6.0142e-02, time/batch = 0.0767s	
2429/5250 (epoch 23.133), train_loss = 1.35727957, grad/param norm = 5.9052e-02, time/batch = 0.0774s	
2430/5250 (epoch 23.143), train_loss = 1.34097806, grad/param norm = 6.4769e-02, time/batch = 0.0779s	
2431/5250 (epoch 23.152), train_loss = 1.33881238, grad/param norm = 6.3188e-02, time/batch = 0.0789s	
2432/5250 (epoch 23.162), train_loss = 1.36924406, grad/param norm = 6.2526e-02, time/batch = 0.0768s	
2433/5250 (epoch 23.171), train_loss = 1.37697407, grad/param norm = 5.9715e-02, time/batch = 0.0768s	
2434/5250 (epoch 23.181), train_loss = 1.37745271, grad/param norm = 6.1927e-02, time/batch = 0.0766s	
2435/5250 (epoch 23.190), train_loss = 1.37115364, grad/param norm = 5.7142e-02, time/batch = 0.0774s	
2436/5250 (epoch 23.200), train_loss = 1.36081313, grad/param norm = 5.9502e-02, time/batch = 0.0776s	
2437/5250 (epoch 23.210), train_loss = 1.35730135, grad/param norm = 6.2648e-02, time/batch = 0.0770s	
2438/5250 (epoch 23.219), train_loss = 1.40558870, grad/param norm = 7.1062e-02, time/batch = 0.0766s	
2439/5250 (epoch 23.229), train_loss = 1.36350642, grad/param norm = 6.6401e-02, time/batch = 0.0771s	
2440/5250 (epoch 23.238), train_loss = 1.36491688, grad/param norm = 6.3984e-02, time/batch = 0.0771s	
2441/5250 (epoch 23.248), train_loss = 1.36825253, grad/param norm = 6.2121e-02, time/batch = 0.0789s	
2442/5250 (epoch 23.257), train_loss = 1.35498302, grad/param norm = 5.8924e-02, time/batch = 0.0769s	
2443/5250 (epoch 23.267), train_loss = 1.34640101, grad/param norm = 5.3864e-02, time/batch = 0.0768s	
2444/5250 (epoch 23.276), train_loss = 1.34890736, grad/param norm = 5.1364e-02, time/batch = 0.0766s	
2445/5250 (epoch 23.286), train_loss = 1.33063600, grad/param norm = 5.5117e-02, time/batch = 0.0769s	
2446/5250 (epoch 23.295), train_loss = 1.35857529, grad/param norm = 5.8849e-02, time/batch = 0.0778s	
2447/5250 (epoch 23.305), train_loss = 1.35677680, grad/param norm = 6.3246e-02, time/batch = 0.0768s	
2448/5250 (epoch 23.314), train_loss = 1.34151430, grad/param norm = 5.5285e-02, time/batch = 0.0769s	
2449/5250 (epoch 23.324), train_loss = 1.35340125, grad/param norm = 5.6262e-02, time/batch = 0.0771s	
2450/5250 (epoch 23.333), train_loss = 1.35892776, grad/param norm = 5.7984e-02, time/batch = 0.0772s	
2451/5250 (epoch 23.343), train_loss = 1.36499923, grad/param norm = 6.0477e-02, time/batch = 0.0790s	
2452/5250 (epoch 23.352), train_loss = 1.37521318, grad/param norm = 6.8838e-02, time/batch = 0.0776s	
2453/5250 (epoch 23.362), train_loss = 1.37299311, grad/param norm = 6.9207e-02, time/batch = 0.0770s	
2454/5250 (epoch 23.371), train_loss = 1.35207530, grad/param norm = 6.5434e-02, time/batch = 0.0767s	
2455/5250 (epoch 23.381), train_loss = 1.35513137, grad/param norm = 7.3906e-02, time/batch = 0.0771s	
2456/5250 (epoch 23.390), train_loss = 1.37089154, grad/param norm = 8.5569e-02, time/batch = 0.0772s	
2457/5250 (epoch 23.400), train_loss = 1.36546474, grad/param norm = 7.4366e-02, time/batch = 0.0772s	
2458/5250 (epoch 23.410), train_loss = 1.37398815, grad/param norm = 6.2613e-02, time/batch = 0.0767s	
2459/5250 (epoch 23.419), train_loss = 1.36318147, grad/param norm = 6.3183e-02, time/batch = 0.0775s	
2460/5250 (epoch 23.429), train_loss = 1.37024284, grad/param norm = 6.2053e-02, time/batch = 0.0769s	
2461/5250 (epoch 23.438), train_loss = 1.38648399, grad/param norm = 6.1814e-02, time/batch = 0.0787s	
2462/5250 (epoch 23.448), train_loss = 1.35094932, grad/param norm = 7.3057e-02, time/batch = 0.0770s	
2463/5250 (epoch 23.457), train_loss = 1.35309577, grad/param norm = 9.2183e-02, time/batch = 0.0774s	
2464/5250 (epoch 23.467), train_loss = 1.36377347, grad/param norm = 7.6988e-02, time/batch = 0.0768s	
2465/5250 (epoch 23.476), train_loss = 1.36307271, grad/param norm = 6.8118e-02, time/batch = 0.0772s	
2466/5250 (epoch 23.486), train_loss = 1.37755651, grad/param norm = 7.2225e-02, time/batch = 0.0774s	
2467/5250 (epoch 23.495), train_loss = 1.37911293, grad/param norm = 6.5058e-02, time/batch = 0.0768s	
2468/5250 (epoch 23.505), train_loss = 1.38572025, grad/param norm = 6.1391e-02, time/batch = 0.0766s	
2469/5250 (epoch 23.514), train_loss = 1.38340417, grad/param norm = 6.6158e-02, time/batch = 0.0773s	
2470/5250 (epoch 23.524), train_loss = 1.35415637, grad/param norm = 6.8858e-02, time/batch = 0.0772s	
2471/5250 (epoch 23.533), train_loss = 1.36306569, grad/param norm = 6.9640e-02, time/batch = 0.0789s	
2472/5250 (epoch 23.543), train_loss = 1.35318161, grad/param norm = 6.9475e-02, time/batch = 0.0770s	
2473/5250 (epoch 23.552), train_loss = 1.36580745, grad/param norm = 7.7998e-02, time/batch = 0.0770s	
2474/5250 (epoch 23.562), train_loss = 1.36676225, grad/param norm = 8.7245e-02, time/batch = 0.0774s	
2475/5250 (epoch 23.571), train_loss = 1.36983094, grad/param norm = 8.1101e-02, time/batch = 0.0772s	
2476/5250 (epoch 23.581), train_loss = 1.39917397, grad/param norm = 7.5363e-02, time/batch = 0.0772s	
2477/5250 (epoch 23.590), train_loss = 1.37266002, grad/param norm = 6.9397e-02, time/batch = 0.0765s	
2478/5250 (epoch 23.600), train_loss = 1.38678044, grad/param norm = 6.3575e-02, time/batch = 0.0766s	
2479/5250 (epoch 23.610), train_loss = 1.37776618, grad/param norm = 6.4722e-02, time/batch = 0.0772s	
2480/5250 (epoch 23.619), train_loss = 1.36555649, grad/param norm = 6.4350e-02, time/batch = 0.0775s	
2481/5250 (epoch 23.629), train_loss = 1.37891671, grad/param norm = 6.1926e-02, time/batch = 0.0789s	
2482/5250 (epoch 23.638), train_loss = 1.35408956, grad/param norm = 6.1360e-02, time/batch = 0.0770s	
2483/5250 (epoch 23.648), train_loss = 1.36468769, grad/param norm = 5.5503e-02, time/batch = 0.0770s	
2484/5250 (epoch 23.657), train_loss = 1.36045445, grad/param norm = 5.3576e-02, time/batch = 0.0765s	
2485/5250 (epoch 23.667), train_loss = 1.36458001, grad/param norm = 5.7973e-02, time/batch = 0.0786s	
2486/5250 (epoch 23.676), train_loss = 1.36989014, grad/param norm = 6.7535e-02, time/batch = 0.0792s	
2487/5250 (epoch 23.686), train_loss = 1.39222793, grad/param norm = 6.5618e-02, time/batch = 0.0771s	
2488/5250 (epoch 23.695), train_loss = 1.37282216, grad/param norm = 6.7478e-02, time/batch = 0.0767s	
2489/5250 (epoch 23.705), train_loss = 1.35672788, grad/param norm = 6.6777e-02, time/batch = 0.0772s	
2490/5250 (epoch 23.714), train_loss = 1.39013270, grad/param norm = 6.4357e-02, time/batch = 0.0769s	
2491/5250 (epoch 23.724), train_loss = 1.37100667, grad/param norm = 6.4571e-02, time/batch = 0.0789s	
2492/5250 (epoch 23.733), train_loss = 1.35024377, grad/param norm = 6.8376e-02, time/batch = 0.0770s	
2493/5250 (epoch 23.743), train_loss = 1.35641906, grad/param norm = 6.9114e-02, time/batch = 0.0772s	
2494/5250 (epoch 23.752), train_loss = 1.36471533, grad/param norm = 5.3344e-02, time/batch = 0.0766s	
2495/5250 (epoch 23.762), train_loss = 1.35283226, grad/param norm = 5.6873e-02, time/batch = 0.0772s	
2496/5250 (epoch 23.771), train_loss = 1.34851134, grad/param norm = 6.2242e-02, time/batch = 0.0776s	
2497/5250 (epoch 23.781), train_loss = 1.37364729, grad/param norm = 6.9667e-02, time/batch = 0.0771s	
2498/5250 (epoch 23.790), train_loss = 1.38910698, grad/param norm = 7.5110e-02, time/batch = 0.0765s	
2499/5250 (epoch 23.800), train_loss = 1.37218101, grad/param norm = 6.4744e-02, time/batch = 0.0773s	
2500/5250 (epoch 23.810), train_loss = 1.37114685, grad/param norm = 5.9175e-02, time/batch = 0.0770s	
2501/5250 (epoch 23.819), train_loss = 1.37409284, grad/param norm = 6.2090e-02, time/batch = 0.0789s	
2502/5250 (epoch 23.829), train_loss = 1.37018409, grad/param norm = 6.5642e-02, time/batch = 0.0770s	
2503/5250 (epoch 23.838), train_loss = 1.35109625, grad/param norm = 5.8861e-02, time/batch = 0.0771s	
2504/5250 (epoch 23.848), train_loss = 1.34997753, grad/param norm = 6.2668e-02, time/batch = 0.0769s	
2505/5250 (epoch 23.857), train_loss = 1.36548171, grad/param norm = 6.4044e-02, time/batch = 0.0770s	
2506/5250 (epoch 23.867), train_loss = 1.35875408, grad/param norm = 5.9689e-02, time/batch = 0.0773s	
2507/5250 (epoch 23.876), train_loss = 1.37246894, grad/param norm = 5.6656e-02, time/batch = 0.0774s	
2508/5250 (epoch 23.886), train_loss = 1.35263282, grad/param norm = 5.6085e-02, time/batch = 0.0765s	
2509/5250 (epoch 23.895), train_loss = 1.39299470, grad/param norm = 6.2882e-02, time/batch = 0.0774s	
2510/5250 (epoch 23.905), train_loss = 1.37822896, grad/param norm = 6.0389e-02, time/batch = 0.0771s	
2511/5250 (epoch 23.914), train_loss = 1.39793582, grad/param norm = 6.8602e-02, time/batch = 0.0790s	
2512/5250 (epoch 23.924), train_loss = 1.39183122, grad/param norm = 6.6977e-02, time/batch = 0.0769s	
2513/5250 (epoch 23.933), train_loss = 1.36294286, grad/param norm = 6.0127e-02, time/batch = 0.0775s	
2514/5250 (epoch 23.943), train_loss = 1.40112624, grad/param norm = 7.4267e-02, time/batch = 0.0771s	
2515/5250 (epoch 23.952), train_loss = 1.40171621, grad/param norm = 7.9428e-02, time/batch = 0.0772s	
2516/5250 (epoch 23.962), train_loss = 1.37891813, grad/param norm = 7.6943e-02, time/batch = 0.0774s	
2517/5250 (epoch 23.971), train_loss = 1.37074982, grad/param norm = 8.7844e-02, time/batch = 0.0767s	
2518/5250 (epoch 23.981), train_loss = 1.39779141, grad/param norm = 7.3419e-02, time/batch = 0.0764s	
2519/5250 (epoch 23.990), train_loss = 1.39276337, grad/param norm = 5.9073e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
2520/5250 (epoch 24.000), train_loss = 1.37043891, grad/param norm = 6.3998e-02, time/batch = 0.0772s	
2521/5250 (epoch 24.010), train_loss = 1.55554916, grad/param norm = 6.7262e-02, time/batch = 0.0789s	
2522/5250 (epoch 24.019), train_loss = 1.36079712, grad/param norm = 7.1179e-02, time/batch = 0.0770s	
2523/5250 (epoch 24.029), train_loss = 1.36912380, grad/param norm = 5.7247e-02, time/batch = 0.0769s	
2524/5250 (epoch 24.038), train_loss = 1.35800519, grad/param norm = 5.6394e-02, time/batch = 0.0772s	
2525/5250 (epoch 24.048), train_loss = 1.33907221, grad/param norm = 5.6267e-02, time/batch = 0.0774s	
2526/5250 (epoch 24.057), train_loss = 1.35150921, grad/param norm = 5.3292e-02, time/batch = 0.0773s	
2527/5250 (epoch 24.067), train_loss = 1.35787633, grad/param norm = 5.4653e-02, time/batch = 0.0765s	
2528/5250 (epoch 24.076), train_loss = 1.36150126, grad/param norm = 6.2193e-02, time/batch = 0.0765s	
2529/5250 (epoch 24.086), train_loss = 1.31072058, grad/param norm = 6.6693e-02, time/batch = 0.0774s	
2530/5250 (epoch 24.095), train_loss = 1.34947387, grad/param norm = 6.9280e-02, time/batch = 0.0776s	
2531/5250 (epoch 24.105), train_loss = 1.36354368, grad/param norm = 6.1928e-02, time/batch = 0.0788s	
2532/5250 (epoch 24.114), train_loss = 1.34320603, grad/param norm = 5.7127e-02, time/batch = 0.0769s	
2533/5250 (epoch 24.124), train_loss = 1.36017290, grad/param norm = 6.3149e-02, time/batch = 0.0772s	
2534/5250 (epoch 24.133), train_loss = 1.34967888, grad/param norm = 5.7815e-02, time/batch = 0.0767s	
2535/5250 (epoch 24.143), train_loss = 1.33264307, grad/param norm = 5.8278e-02, time/batch = 0.0775s	
2536/5250 (epoch 24.152), train_loss = 1.33008714, grad/param norm = 5.5019e-02, time/batch = 0.0777s	
2537/5250 (epoch 24.162), train_loss = 1.36046339, grad/param norm = 5.5334e-02, time/batch = 0.0768s	
2538/5250 (epoch 24.171), train_loss = 1.36757589, grad/param norm = 5.3032e-02, time/batch = 0.0765s	
2539/5250 (epoch 24.181), train_loss = 1.36885025, grad/param norm = 5.6468e-02, time/batch = 0.0772s	
2540/5250 (epoch 24.190), train_loss = 1.36276047, grad/param norm = 5.3817e-02, time/batch = 0.0768s	
2541/5250 (epoch 24.200), train_loss = 1.35242399, grad/param norm = 5.7094e-02, time/batch = 0.0789s	
2542/5250 (epoch 24.210), train_loss = 1.34965030, grad/param norm = 6.2074e-02, time/batch = 0.0770s	
2543/5250 (epoch 24.219), train_loss = 1.39884873, grad/param norm = 7.2994e-02, time/batch = 0.0770s	
2544/5250 (epoch 24.229), train_loss = 1.35679193, grad/param norm = 7.0278e-02, time/batch = 0.0769s	
2545/5250 (epoch 24.238), train_loss = 1.35808408, grad/param norm = 6.7289e-02, time/batch = 0.0770s	
2546/5250 (epoch 24.248), train_loss = 1.36029598, grad/param norm = 6.3561e-02, time/batch = 0.0779s	
2547/5250 (epoch 24.257), train_loss = 1.34855713, grad/param norm = 6.2016e-02, time/batch = 0.0768s	
2548/5250 (epoch 24.267), train_loss = 1.34008323, grad/param norm = 6.1969e-02, time/batch = 0.0766s	
2549/5250 (epoch 24.276), train_loss = 1.34351277, grad/param norm = 6.1427e-02, time/batch = 0.0770s	
2550/5250 (epoch 24.286), train_loss = 1.32569711, grad/param norm = 6.4663e-02, time/batch = 0.0770s	
2551/5250 (epoch 24.295), train_loss = 1.35325104, grad/param norm = 6.7233e-02, time/batch = 0.0788s	
2552/5250 (epoch 24.305), train_loss = 1.35084061, grad/param norm = 6.9956e-02, time/batch = 0.0769s	
2553/5250 (epoch 24.314), train_loss = 1.33500044, grad/param norm = 5.7242e-02, time/batch = 0.0772s	
2554/5250 (epoch 24.324), train_loss = 1.34553446, grad/param norm = 5.5849e-02, time/batch = 0.0767s	
2555/5250 (epoch 24.333), train_loss = 1.35077435, grad/param norm = 5.5577e-02, time/batch = 0.0770s	
2556/5250 (epoch 24.343), train_loss = 1.35743236, grad/param norm = 6.0726e-02, time/batch = 0.0774s	
2557/5250 (epoch 24.352), train_loss = 1.36838709, grad/param norm = 6.9249e-02, time/batch = 0.0773s	
2558/5250 (epoch 24.362), train_loss = 1.36515733, grad/param norm = 7.1138e-02, time/batch = 0.0767s	
2559/5250 (epoch 24.371), train_loss = 1.34487452, grad/param norm = 6.5281e-02, time/batch = 0.0772s	
2560/5250 (epoch 24.381), train_loss = 1.34594476, grad/param norm = 7.0162e-02, time/batch = 0.0772s	
2561/5250 (epoch 24.390), train_loss = 1.36214576, grad/param norm = 8.1425e-02, time/batch = 0.0788s	
2562/5250 (epoch 24.400), train_loss = 1.36053453, grad/param norm = 8.3695e-02, time/batch = 0.0770s	
2563/5250 (epoch 24.410), train_loss = 1.36902668, grad/param norm = 7.6028e-02, time/batch = 0.0774s	
2564/5250 (epoch 24.419), train_loss = 1.35690344, grad/param norm = 7.1464e-02, time/batch = 0.0770s	
2565/5250 (epoch 24.429), train_loss = 1.36265625, grad/param norm = 6.4194e-02, time/batch = 0.0770s	
2566/5250 (epoch 24.438), train_loss = 1.37822835, grad/param norm = 5.9313e-02, time/batch = 0.0772s	
2567/5250 (epoch 24.448), train_loss = 1.34030304, grad/param norm = 6.0513e-02, time/batch = 0.0766s	
2568/5250 (epoch 24.457), train_loss = 1.34014970, grad/param norm = 6.8249e-02, time/batch = 0.0767s	
2569/5250 (epoch 24.467), train_loss = 1.35178848, grad/param norm = 5.9649e-02, time/batch = 0.0771s	
2570/5250 (epoch 24.476), train_loss = 1.35229663, grad/param norm = 5.9853e-02, time/batch = 0.0775s	
2571/5250 (epoch 24.486), train_loss = 1.36870176, grad/param norm = 6.5965e-02, time/batch = 0.0790s	
2572/5250 (epoch 24.495), train_loss = 1.36964387, grad/param norm = 5.9276e-02, time/batch = 0.0769s	
2573/5250 (epoch 24.505), train_loss = 1.37645405, grad/param norm = 5.3742e-02, time/batch = 0.0769s	
2574/5250 (epoch 24.514), train_loss = 1.37398007, grad/param norm = 5.7500e-02, time/batch = 0.0776s	
2575/5250 (epoch 24.524), train_loss = 1.34431111, grad/param norm = 5.6203e-02, time/batch = 0.0773s	
2576/5250 (epoch 24.533), train_loss = 1.35326725, grad/param norm = 6.1108e-02, time/batch = 0.0774s	
2577/5250 (epoch 24.543), train_loss = 1.34551050, grad/param norm = 6.3020e-02, time/batch = 0.0767s	
2578/5250 (epoch 24.552), train_loss = 1.35575372, grad/param norm = 6.9550e-02, time/batch = 0.0766s	
2579/5250 (epoch 24.562), train_loss = 1.35520338, grad/param norm = 7.6580e-02, time/batch = 0.0770s	
2580/5250 (epoch 24.571), train_loss = 1.36172788, grad/param norm = 7.8951e-02, time/batch = 0.0772s	
2581/5250 (epoch 24.581), train_loss = 1.39102935, grad/param norm = 7.3823e-02, time/batch = 0.0787s	
2582/5250 (epoch 24.590), train_loss = 1.36333605, grad/param norm = 6.2758e-02, time/batch = 0.0769s	
2583/5250 (epoch 24.600), train_loss = 1.37883009, grad/param norm = 5.7882e-02, time/batch = 0.0766s	
2584/5250 (epoch 24.610), train_loss = 1.36960985, grad/param norm = 6.0909e-02, time/batch = 0.0768s	
2585/5250 (epoch 24.619), train_loss = 1.35661713, grad/param norm = 5.9840e-02, time/batch = 0.0773s	
2586/5250 (epoch 24.629), train_loss = 1.36982551, grad/param norm = 5.7378e-02, time/batch = 0.0776s	
2587/5250 (epoch 24.638), train_loss = 1.34570853, grad/param norm = 5.7746e-02, time/batch = 0.0765s	
2588/5250 (epoch 24.648), train_loss = 1.35698811, grad/param norm = 5.5633e-02, time/batch = 0.0764s	
2589/5250 (epoch 24.657), train_loss = 1.35316927, grad/param norm = 5.1337e-02, time/batch = 0.0773s	
2590/5250 (epoch 24.667), train_loss = 1.35659550, grad/param norm = 5.3694e-02, time/batch = 0.0772s	
2591/5250 (epoch 24.676), train_loss = 1.36171199, grad/param norm = 6.2966e-02, time/batch = 0.0788s	
2592/5250 (epoch 24.686), train_loss = 1.38386781, grad/param norm = 5.9916e-02, time/batch = 0.0771s	
2593/5250 (epoch 24.695), train_loss = 1.36584630, grad/param norm = 6.8946e-02, time/batch = 0.0770s	
2594/5250 (epoch 24.705), train_loss = 1.34905295, grad/param norm = 6.6007e-02, time/batch = 0.0765s	
2595/5250 (epoch 24.714), train_loss = 1.38296272, grad/param norm = 5.9263e-02, time/batch = 0.0770s	
2596/5250 (epoch 24.724), train_loss = 1.36346752, grad/param norm = 5.8711e-02, time/batch = 0.0792s	
2597/5250 (epoch 24.733), train_loss = 1.34201100, grad/param norm = 6.2557e-02, time/batch = 0.0804s	
2598/5250 (epoch 24.743), train_loss = 1.34865719, grad/param norm = 6.3832e-02, time/batch = 0.0773s	
2599/5250 (epoch 24.752), train_loss = 1.35678792, grad/param norm = 5.5229e-02, time/batch = 0.0774s	
2600/5250 (epoch 24.762), train_loss = 1.34460510, grad/param norm = 5.7922e-02, time/batch = 0.0772s	
2601/5250 (epoch 24.771), train_loss = 1.33966837, grad/param norm = 5.6939e-02, time/batch = 0.0798s	
2602/5250 (epoch 24.781), train_loss = 1.36385034, grad/param norm = 5.9992e-02, time/batch = 0.0771s	
2603/5250 (epoch 24.790), train_loss = 1.37873900, grad/param norm = 6.3557e-02, time/batch = 0.0767s	
2604/5250 (epoch 24.800), train_loss = 1.36398395, grad/param norm = 6.5510e-02, time/batch = 0.0767s	
2605/5250 (epoch 24.810), train_loss = 1.36448704, grad/param norm = 6.6110e-02, time/batch = 0.0772s	
2606/5250 (epoch 24.819), train_loss = 1.36904903, grad/param norm = 7.0885e-02, time/batch = 0.0774s	
2607/5250 (epoch 24.829), train_loss = 1.36590537, grad/param norm = 7.7704e-02, time/batch = 0.0770s	
2608/5250 (epoch 24.838), train_loss = 1.34603835, grad/param norm = 6.9098e-02, time/batch = 0.0766s	
2609/5250 (epoch 24.848), train_loss = 1.34640999, grad/param norm = 8.2208e-02, time/batch = 0.0772s	
2610/5250 (epoch 24.857), train_loss = 1.36368581, grad/param norm = 8.3980e-02, time/batch = 0.0770s	
2611/5250 (epoch 24.867), train_loss = 1.35444867, grad/param norm = 7.1834e-02, time/batch = 0.0790s	
2612/5250 (epoch 24.876), train_loss = 1.36636818, grad/param norm = 6.2588e-02, time/batch = 0.0771s	
2613/5250 (epoch 24.886), train_loss = 1.34602612, grad/param norm = 6.0205e-02, time/batch = 0.0771s	
2614/5250 (epoch 24.895), train_loss = 1.38648442, grad/param norm = 6.8661e-02, time/batch = 0.0769s	
2615/5250 (epoch 24.905), train_loss = 1.37213318, grad/param norm = 6.6312e-02, time/batch = 0.0772s	
2616/5250 (epoch 24.914), train_loss = 1.38924197, grad/param norm = 6.9270e-02, time/batch = 0.0771s	
2617/5250 (epoch 24.924), train_loss = 1.38222310, grad/param norm = 5.9538e-02, time/batch = 0.0767s	
2618/5250 (epoch 24.933), train_loss = 1.35176254, grad/param norm = 4.9727e-02, time/batch = 0.0773s	
2619/5250 (epoch 24.943), train_loss = 1.38839250, grad/param norm = 5.4470e-02, time/batch = 0.0773s	
2620/5250 (epoch 24.952), train_loss = 1.38689867, grad/param norm = 5.5047e-02, time/batch = 0.0768s	
2621/5250 (epoch 24.962), train_loss = 1.36438490, grad/param norm = 5.3538e-02, time/batch = 0.0787s	
2622/5250 (epoch 24.971), train_loss = 1.35738580, grad/param norm = 6.1392e-02, time/batch = 0.0769s	
2623/5250 (epoch 24.981), train_loss = 1.38752558, grad/param norm = 6.7771e-02, time/batch = 0.0768s	
2624/5250 (epoch 24.990), train_loss = 1.38631373, grad/param norm = 7.1131e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
2625/5250 (epoch 25.000), train_loss = 1.36492341, grad/param norm = 7.2237e-02, time/batch = 0.0774s	
2626/5250 (epoch 25.010), train_loss = 1.55097464, grad/param norm = 7.3996e-02, time/batch = 0.0771s	
2627/5250 (epoch 25.019), train_loss = 1.35389394, grad/param norm = 7.7036e-02, time/batch = 0.0767s	
2628/5250 (epoch 25.029), train_loss = 1.36517628, grad/param norm = 7.2980e-02, time/batch = 0.0768s	
2629/5250 (epoch 25.038), train_loss = 1.35602835, grad/param norm = 7.4156e-02, time/batch = 0.0773s	
2630/5250 (epoch 25.048), train_loss = 1.33477207, grad/param norm = 6.7587e-02, time/batch = 0.0770s	
2631/5250 (epoch 25.057), train_loss = 1.34578286, grad/param norm = 5.7803e-02, time/batch = 0.0795s	
2632/5250 (epoch 25.067), train_loss = 1.35092061, grad/param norm = 5.6277e-02, time/batch = 0.0768s	
2633/5250 (epoch 25.076), train_loss = 1.35485142, grad/param norm = 6.3781e-02, time/batch = 0.0768s	
2634/5250 (epoch 25.086), train_loss = 1.30404363, grad/param norm = 6.7962e-02, time/batch = 0.0769s	
2635/5250 (epoch 25.095), train_loss = 1.34170449, grad/param norm = 6.7406e-02, time/batch = 0.0775s	
2636/5250 (epoch 25.105), train_loss = 1.35634036, grad/param norm = 6.1760e-02, time/batch = 0.0775s	
2637/5250 (epoch 25.114), train_loss = 1.33668561, grad/param norm = 5.9496e-02, time/batch = 0.0770s	
2638/5250 (epoch 25.124), train_loss = 1.35331063, grad/param norm = 5.9266e-02, time/batch = 0.0766s	
2639/5250 (epoch 25.133), train_loss = 1.34248037, grad/param norm = 6.0079e-02, time/batch = 0.0773s	
2640/5250 (epoch 25.143), train_loss = 1.32680809, grad/param norm = 6.4785e-02, time/batch = 0.0770s	
2641/5250 (epoch 25.152), train_loss = 1.32491578, grad/param norm = 6.1085e-02, time/batch = 0.0787s	
2642/5250 (epoch 25.162), train_loss = 1.35456308, grad/param norm = 6.0126e-02, time/batch = 0.0768s	
2643/5250 (epoch 25.171), train_loss = 1.36075485, grad/param norm = 5.6686e-02, time/batch = 0.0768s	
2644/5250 (epoch 25.181), train_loss = 1.36240253, grad/param norm = 5.9331e-02, time/batch = 0.0770s	
2645/5250 (epoch 25.190), train_loss = 1.35545739, grad/param norm = 5.3673e-02, time/batch = 0.0767s	
2646/5250 (epoch 25.200), train_loss = 1.34486189, grad/param norm = 5.7471e-02, time/batch = 0.0776s	
2647/5250 (epoch 25.210), train_loss = 1.34252907, grad/param norm = 6.0603e-02, time/batch = 0.0775s	
2648/5250 (epoch 25.219), train_loss = 1.39070683, grad/param norm = 6.7773e-02, time/batch = 0.0773s	
2649/5250 (epoch 25.229), train_loss = 1.34742817, grad/param norm = 6.2736e-02, time/batch = 0.0773s	
2650/5250 (epoch 25.238), train_loss = 1.34916786, grad/param norm = 6.1722e-02, time/batch = 0.0771s	
2651/5250 (epoch 25.248), train_loss = 1.35266646, grad/param norm = 6.0300e-02, time/batch = 0.0793s	
2652/5250 (epoch 25.257), train_loss = 1.34077928, grad/param norm = 5.6657e-02, time/batch = 0.0771s	
2653/5250 (epoch 25.267), train_loss = 1.33085612, grad/param norm = 5.1228e-02, time/batch = 0.0769s	
2654/5250 (epoch 25.276), train_loss = 1.33377274, grad/param norm = 4.9702e-02, time/batch = 0.0768s	
2655/5250 (epoch 25.286), train_loss = 1.31606666, grad/param norm = 5.3620e-02, time/batch = 0.0771s	
2656/5250 (epoch 25.295), train_loss = 1.34270591, grad/param norm = 5.3932e-02, time/batch = 0.0775s	
2657/5250 (epoch 25.305), train_loss = 1.33995433, grad/param norm = 5.8661e-02, time/batch = 0.0772s	
2658/5250 (epoch 25.314), train_loss = 1.32688062, grad/param norm = 5.3236e-02, time/batch = 0.0767s	
2659/5250 (epoch 25.324), train_loss = 1.33846904, grad/param norm = 5.7178e-02, time/batch = 0.0776s	
2660/5250 (epoch 25.333), train_loss = 1.34531713, grad/param norm = 6.3984e-02, time/batch = 0.0771s	
2661/5250 (epoch 25.343), train_loss = 1.35175918, grad/param norm = 7.0905e-02, time/batch = 0.0787s	
2662/5250 (epoch 25.352), train_loss = 1.36213206, grad/param norm = 7.5266e-02, time/batch = 0.0769s	
2663/5250 (epoch 25.362), train_loss = 1.35982653, grad/param norm = 7.4831e-02, time/batch = 0.0767s	
2664/5250 (epoch 25.371), train_loss = 1.34017311, grad/param norm = 7.4338e-02, time/batch = 0.0768s	
2665/5250 (epoch 25.381), train_loss = 1.34222402, grad/param norm = 8.1205e-02, time/batch = 0.0769s	
2666/5250 (epoch 25.390), train_loss = 1.35355144, grad/param norm = 8.1973e-02, time/batch = 0.0775s	
2667/5250 (epoch 25.400), train_loss = 1.34964876, grad/param norm = 6.6326e-02, time/batch = 0.0763s	
2668/5250 (epoch 25.410), train_loss = 1.35792062, grad/param norm = 5.8137e-02, time/batch = 0.0769s	
2669/5250 (epoch 25.419), train_loss = 1.34778879, grad/param norm = 6.1331e-02, time/batch = 0.0775s	
2670/5250 (epoch 25.429), train_loss = 1.35512310, grad/param norm = 5.9963e-02, time/batch = 0.0773s	
2671/5250 (epoch 25.438), train_loss = 1.37059292, grad/param norm = 5.5329e-02, time/batch = 0.0790s	
2672/5250 (epoch 25.448), train_loss = 1.33278088, grad/param norm = 6.0443e-02, time/batch = 0.0768s	
2673/5250 (epoch 25.457), train_loss = 1.33562418, grad/param norm = 7.7382e-02, time/batch = 0.0768s	
2674/5250 (epoch 25.467), train_loss = 1.34627894, grad/param norm = 6.8025e-02, time/batch = 0.0775s	
2675/5250 (epoch 25.476), train_loss = 1.34528261, grad/param norm = 6.0434e-02, time/batch = 0.0772s	
2676/5250 (epoch 25.486), train_loss = 1.36154467, grad/param norm = 6.5755e-02, time/batch = 0.0774s	
2677/5250 (epoch 25.495), train_loss = 1.36279701, grad/param norm = 5.8033e-02, time/batch = 0.0769s	
2678/5250 (epoch 25.505), train_loss = 1.36930964, grad/param norm = 5.4669e-02, time/batch = 0.0766s	
2679/5250 (epoch 25.514), train_loss = 1.36705863, grad/param norm = 6.0838e-02, time/batch = 0.0773s	
2680/5250 (epoch 25.524), train_loss = 1.33833537, grad/param norm = 6.1712e-02, time/batch = 0.0769s	
2681/5250 (epoch 25.533), train_loss = 1.34768942, grad/param norm = 6.2814e-02, time/batch = 0.0790s	
2682/5250 (epoch 25.543), train_loss = 1.33874839, grad/param norm = 6.3124e-02, time/batch = 0.0769s	
2683/5250 (epoch 25.552), train_loss = 1.35023587, grad/param norm = 7.1980e-02, time/batch = 0.0766s	
2684/5250 (epoch 25.562), train_loss = 1.34941113, grad/param norm = 7.9203e-02, time/batch = 0.0767s	
2685/5250 (epoch 25.571), train_loss = 1.35411582, grad/param norm = 7.5180e-02, time/batch = 0.0778s	
2686/5250 (epoch 25.581), train_loss = 1.38368507, grad/param norm = 6.9865e-02, time/batch = 0.0772s	
2687/5250 (epoch 25.590), train_loss = 1.35708652, grad/param norm = 6.6974e-02, time/batch = 0.0765s	
2688/5250 (epoch 25.600), train_loss = 1.37298167, grad/param norm = 6.5502e-02, time/batch = 0.0764s	
2689/5250 (epoch 25.610), train_loss = 1.36332465, grad/param norm = 6.5090e-02, time/batch = 0.0773s	
2690/5250 (epoch 25.619), train_loss = 1.34950557, grad/param norm = 6.0979e-02, time/batch = 0.0774s	
2691/5250 (epoch 25.629), train_loss = 1.36304316, grad/param norm = 5.7735e-02, time/batch = 0.0791s	
2692/5250 (epoch 25.638), train_loss = 1.33806526, grad/param norm = 5.4877e-02, time/batch = 0.0772s	
2693/5250 (epoch 25.648), train_loss = 1.34889279, grad/param norm = 5.1415e-02, time/batch = 0.0768s	
2694/5250 (epoch 25.657), train_loss = 1.34658832, grad/param norm = 5.2852e-02, time/batch = 0.0768s	
2695/5250 (epoch 25.667), train_loss = 1.35059125, grad/param norm = 5.6380e-02, time/batch = 0.0769s	
2696/5250 (epoch 25.676), train_loss = 1.35469732, grad/param norm = 6.5047e-02, time/batch = 0.0777s	
2697/5250 (epoch 25.686), train_loss = 1.37798047, grad/param norm = 6.4929e-02, time/batch = 0.0771s	
2698/5250 (epoch 25.695), train_loss = 1.35909003, grad/param norm = 6.9739e-02, time/batch = 0.0766s	
2699/5250 (epoch 25.705), train_loss = 1.34205138, grad/param norm = 6.5600e-02, time/batch = 0.0772s	
2700/5250 (epoch 25.714), train_loss = 1.37571950, grad/param norm = 6.2438e-02, time/batch = 0.0770s	
2701/5250 (epoch 25.724), train_loss = 1.35705771, grad/param norm = 6.5512e-02, time/batch = 0.0792s	
2702/5250 (epoch 25.733), train_loss = 1.33593849, grad/param norm = 6.6872e-02, time/batch = 0.0770s	
2703/5250 (epoch 25.743), train_loss = 1.34060840, grad/param norm = 6.1627e-02, time/batch = 0.0772s	
2704/5250 (epoch 25.752), train_loss = 1.34980020, grad/param norm = 5.0952e-02, time/batch = 0.0768s	
2705/5250 (epoch 25.762), train_loss = 1.33763456, grad/param norm = 5.5166e-02, time/batch = 0.0771s	
2706/5250 (epoch 25.771), train_loss = 1.33323952, grad/param norm = 5.8224e-02, time/batch = 0.0774s	
2707/5250 (epoch 25.781), train_loss = 1.35830790, grad/param norm = 6.3794e-02, time/batch = 0.0785s	
2708/5250 (epoch 25.790), train_loss = 1.37285315, grad/param norm = 6.7262e-02, time/batch = 0.0801s	
2709/5250 (epoch 25.800), train_loss = 1.35504539, grad/param norm = 5.9821e-02, time/batch = 0.0775s	
2710/5250 (epoch 25.810), train_loss = 1.35493008, grad/param norm = 5.5976e-02, time/batch = 0.0773s	
2711/5250 (epoch 25.819), train_loss = 1.35938359, grad/param norm = 5.9272e-02, time/batch = 0.0790s	
2712/5250 (epoch 25.829), train_loss = 1.35517419, grad/param norm = 6.3017e-02, time/batch = 0.0769s	
2713/5250 (epoch 25.838), train_loss = 1.33758305, grad/param norm = 6.3583e-02, time/batch = 0.0770s	
2714/5250 (epoch 25.848), train_loss = 1.33715215, grad/param norm = 6.2143e-02, time/batch = 0.0772s	
2715/5250 (epoch 25.857), train_loss = 1.35152435, grad/param norm = 6.0179e-02, time/batch = 0.0773s	
2716/5250 (epoch 25.867), train_loss = 1.34582588, grad/param norm = 5.9636e-02, time/batch = 0.0772s	
2717/5250 (epoch 25.876), train_loss = 1.35769165, grad/param norm = 5.6125e-02, time/batch = 0.0768s	
2718/5250 (epoch 25.886), train_loss = 1.33860383, grad/param norm = 5.7165e-02, time/batch = 0.0770s	
2719/5250 (epoch 25.895), train_loss = 1.38000984, grad/param norm = 6.5653e-02, time/batch = 0.0773s	
2720/5250 (epoch 25.905), train_loss = 1.36540402, grad/param norm = 6.1577e-02, time/batch = 0.0771s	
2721/5250 (epoch 25.914), train_loss = 1.38359154, grad/param norm = 6.5403e-02, time/batch = 0.0788s	
2722/5250 (epoch 25.924), train_loss = 1.37753982, grad/param norm = 7.0223e-02, time/batch = 0.0770s	
2723/5250 (epoch 25.933), train_loss = 1.35307272, grad/param norm = 8.0070e-02, time/batch = 0.0770s	
2724/5250 (epoch 25.943), train_loss = 1.39333667, grad/param norm = 9.5898e-02, time/batch = 0.0775s	
2725/5250 (epoch 25.952), train_loss = 1.38834337, grad/param norm = 8.2408e-02, time/batch = 0.0770s	
2726/5250 (epoch 25.962), train_loss = 1.36351851, grad/param norm = 7.0985e-02, time/batch = 0.0773s	
2727/5250 (epoch 25.971), train_loss = 1.35349305, grad/param norm = 7.3354e-02, time/batch = 0.0769s	
2728/5250 (epoch 25.981), train_loss = 1.37882257, grad/param norm = 5.8780e-02, time/batch = 0.0765s	
2729/5250 (epoch 25.990), train_loss = 1.37713755, grad/param norm = 5.4150e-02, time/batch = 0.0773s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
2730/5250 (epoch 26.000), train_loss = 1.35578494, grad/param norm = 5.8651e-02, time/batch = 0.0772s	
2731/5250 (epoch 26.010), train_loss = 1.54340698, grad/param norm = 6.5338e-02, time/batch = 0.0789s	
2732/5250 (epoch 26.019), train_loss = 1.34523961, grad/param norm = 7.0181e-02, time/batch = 0.0770s	
2733/5250 (epoch 26.029), train_loss = 1.35530019, grad/param norm = 5.8876e-02, time/batch = 0.0772s	
2734/5250 (epoch 26.038), train_loss = 1.34451519, grad/param norm = 5.8182e-02, time/batch = 0.0769s	
2735/5250 (epoch 26.048), train_loss = 1.32424801, grad/param norm = 5.5170e-02, time/batch = 0.0776s	
2736/5250 (epoch 26.057), train_loss = 1.33684705, grad/param norm = 5.1707e-02, time/batch = 0.0774s	
2737/5250 (epoch 26.067), train_loss = 1.34374590, grad/param norm = 5.2990e-02, time/batch = 0.0768s	
2738/5250 (epoch 26.076), train_loss = 1.34743224, grad/param norm = 5.8315e-02, time/batch = 0.0766s	
2739/5250 (epoch 26.086), train_loss = 1.29644650, grad/param norm = 6.1337e-02, time/batch = 0.0772s	
2740/5250 (epoch 26.095), train_loss = 1.33266043, grad/param norm = 6.1201e-02, time/batch = 0.0771s	
2741/5250 (epoch 26.105), train_loss = 1.34788973, grad/param norm = 5.7386e-02, time/batch = 0.0790s	
2742/5250 (epoch 26.114), train_loss = 1.32943065, grad/param norm = 5.7730e-02, time/batch = 0.0771s	
2743/5250 (epoch 26.124), train_loss = 1.34663521, grad/param norm = 5.9015e-02, time/batch = 0.0771s	
2744/5250 (epoch 26.133), train_loss = 1.33556606, grad/param norm = 5.8487e-02, time/batch = 0.0769s	
2745/5250 (epoch 26.143), train_loss = 1.32001824, grad/param norm = 6.2594e-02, time/batch = 0.0768s	
2746/5250 (epoch 26.152), train_loss = 1.31835653, grad/param norm = 5.9834e-02, time/batch = 0.0777s	
2747/5250 (epoch 26.162), train_loss = 1.34792748, grad/param norm = 5.9329e-02, time/batch = 0.0765s	
2748/5250 (epoch 26.171), train_loss = 1.35364774, grad/param norm = 5.5881e-02, time/batch = 0.0768s	
2749/5250 (epoch 26.181), train_loss = 1.35619939, grad/param norm = 5.9503e-02, time/batch = 0.0771s	
2750/5250 (epoch 26.190), train_loss = 1.34898864, grad/param norm = 5.4219e-02, time/batch = 0.0770s	
2751/5250 (epoch 26.200), train_loss = 1.33785907, grad/param norm = 5.7342e-02, time/batch = 0.0790s	
2752/5250 (epoch 26.210), train_loss = 1.33571342, grad/param norm = 5.8246e-02, time/batch = 0.0770s	
2753/5250 (epoch 26.219), train_loss = 1.38371051, grad/param norm = 6.4367e-02, time/batch = 0.0768s	
2754/5250 (epoch 26.229), train_loss = 1.33982416, grad/param norm = 5.9396e-02, time/batch = 0.0771s	
2755/5250 (epoch 26.238), train_loss = 1.34185401, grad/param norm = 5.9644e-02, time/batch = 0.0768s	
2756/5250 (epoch 26.248), train_loss = 1.34564090, grad/param norm = 5.9832e-02, time/batch = 0.0772s	
2757/5250 (epoch 26.257), train_loss = 1.33439754, grad/param norm = 5.5691e-02, time/batch = 0.0773s	
2758/5250 (epoch 26.267), train_loss = 1.32423208, grad/param norm = 5.1136e-02, time/batch = 0.0769s	
2759/5250 (epoch 26.276), train_loss = 1.32729184, grad/param norm = 5.0442e-02, time/batch = 0.0771s	
2760/5250 (epoch 26.286), train_loss = 1.30995168, grad/param norm = 5.4396e-02, time/batch = 0.0768s	
2761/5250 (epoch 26.295), train_loss = 1.33634736, grad/param norm = 5.4945e-02, time/batch = 0.0788s	
2762/5250 (epoch 26.305), train_loss = 1.33337405, grad/param norm = 5.9512e-02, time/batch = 0.0774s	
2763/5250 (epoch 26.314), train_loss = 1.32062390, grad/param norm = 5.2395e-02, time/batch = 0.0771s	
2764/5250 (epoch 26.324), train_loss = 1.33178290, grad/param norm = 5.5012e-02, time/batch = 0.0770s	
2765/5250 (epoch 26.333), train_loss = 1.33765717, grad/param norm = 5.9518e-02, time/batch = 0.0768s	
2766/5250 (epoch 26.343), train_loss = 1.34348823, grad/param norm = 6.4238e-02, time/batch = 0.0774s	
2767/5250 (epoch 26.352), train_loss = 1.35417202, grad/param norm = 6.8596e-02, time/batch = 0.0767s	
2768/5250 (epoch 26.362), train_loss = 1.35191869, grad/param norm = 6.9345e-02, time/batch = 0.0769s	
2769/5250 (epoch 26.371), train_loss = 1.33206510, grad/param norm = 6.7293e-02, time/batch = 0.0773s	
2770/5250 (epoch 26.381), train_loss = 1.33342428, grad/param norm = 7.4116e-02, time/batch = 0.0770s	
2771/5250 (epoch 26.390), train_loss = 1.34595764, grad/param norm = 8.0061e-02, time/batch = 0.0787s	
2772/5250 (epoch 26.400), train_loss = 1.34384623, grad/param norm = 6.6941e-02, time/batch = 0.0770s	
2773/5250 (epoch 26.410), train_loss = 1.35052868, grad/param norm = 5.7018e-02, time/batch = 0.0768s	
2774/5250 (epoch 26.419), train_loss = 1.34017108, grad/param norm = 5.9125e-02, time/batch = 0.0774s	
2775/5250 (epoch 26.429), train_loss = 1.34789912, grad/param norm = 5.7863e-02, time/batch = 0.0772s	
2776/5250 (epoch 26.438), train_loss = 1.36382151, grad/param norm = 5.6269e-02, time/batch = 0.0774s	
2777/5250 (epoch 26.448), train_loss = 1.32738685, grad/param norm = 6.4090e-02, time/batch = 0.0766s	
2778/5250 (epoch 26.457), train_loss = 1.33080459, grad/param norm = 8.0588e-02, time/batch = 0.0766s	
2779/5250 (epoch 26.467), train_loss = 1.34016565, grad/param norm = 6.6246e-02, time/batch = 0.0777s	
2780/5250 (epoch 26.476), train_loss = 1.33872872, grad/param norm = 6.1249e-02, time/batch = 0.0772s	
2781/5250 (epoch 26.486), train_loss = 1.35491109, grad/param norm = 6.4372e-02, time/batch = 0.0789s	
2782/5250 (epoch 26.495), train_loss = 1.35580570, grad/param norm = 5.5616e-02, time/batch = 0.0768s	
2783/5250 (epoch 26.505), train_loss = 1.36237929, grad/param norm = 5.3903e-02, time/batch = 0.0766s	
2784/5250 (epoch 26.514), train_loss = 1.36002078, grad/param norm = 6.0267e-02, time/batch = 0.0769s	
2785/5250 (epoch 26.524), train_loss = 1.33129586, grad/param norm = 5.7832e-02, time/batch = 0.0775s	
2786/5250 (epoch 26.533), train_loss = 1.34052614, grad/param norm = 5.8916e-02, time/batch = 0.0774s	
2787/5250 (epoch 26.543), train_loss = 1.33185357, grad/param norm = 5.9363e-02, time/batch = 0.0767s	
2788/5250 (epoch 26.552), train_loss = 1.34265246, grad/param norm = 6.7530e-02, time/batch = 0.0766s	
2789/5250 (epoch 26.562), train_loss = 1.34086802, grad/param norm = 7.1724e-02, time/batch = 0.0773s	
2790/5250 (epoch 26.571), train_loss = 1.34563103, grad/param norm = 6.8788e-02, time/batch = 0.0770s	
2791/5250 (epoch 26.581), train_loss = 1.37585852, grad/param norm = 6.4632e-02, time/batch = 0.0787s	
2792/5250 (epoch 26.590), train_loss = 1.34877315, grad/param norm = 6.2075e-02, time/batch = 0.0774s	
2793/5250 (epoch 26.600), train_loss = 1.36551092, grad/param norm = 6.0776e-02, time/batch = 0.0770s	
2794/5250 (epoch 26.610), train_loss = 1.35587937, grad/param norm = 5.9913e-02, time/batch = 0.0768s	
2795/5250 (epoch 26.619), train_loss = 1.34161598, grad/param norm = 5.6101e-02, time/batch = 0.0770s	
2796/5250 (epoch 26.629), train_loss = 1.35499529, grad/param norm = 5.3575e-02, time/batch = 0.0778s	
2797/5250 (epoch 26.638), train_loss = 1.33116117, grad/param norm = 5.0991e-02, time/batch = 0.0765s	
2798/5250 (epoch 26.648), train_loss = 1.34248267, grad/param norm = 5.1873e-02, time/batch = 0.0767s	
2799/5250 (epoch 26.657), train_loss = 1.34092307, grad/param norm = 5.4486e-02, time/batch = 0.0773s	
2800/5250 (epoch 26.667), train_loss = 1.34540541, grad/param norm = 5.8452e-02, time/batch = 0.0771s	
2801/5250 (epoch 26.676), train_loss = 1.34920221, grad/param norm = 6.7201e-02, time/batch = 0.0791s	
2802/5250 (epoch 26.686), train_loss = 1.37260608, grad/param norm = 6.5929e-02, time/batch = 0.0769s	
2803/5250 (epoch 26.695), train_loss = 1.35387201, grad/param norm = 7.5050e-02, time/batch = 0.0773s	
2804/5250 (epoch 26.705), train_loss = 1.33660698, grad/param norm = 6.6762e-02, time/batch = 0.0769s	
2805/5250 (epoch 26.714), train_loss = 1.36996508, grad/param norm = 6.0759e-02, time/batch = 0.0770s	
2806/5250 (epoch 26.724), train_loss = 1.35079924, grad/param norm = 6.3736e-02, time/batch = 0.0772s	
2807/5250 (epoch 26.733), train_loss = 1.32901533, grad/param norm = 6.4404e-02, time/batch = 0.0770s	
2808/5250 (epoch 26.743), train_loss = 1.33346313, grad/param norm = 5.8596e-02, time/batch = 0.0768s	
2809/5250 (epoch 26.752), train_loss = 1.34270507, grad/param norm = 5.0815e-02, time/batch = 0.0775s	
2810/5250 (epoch 26.762), train_loss = 1.33049373, grad/param norm = 5.4315e-02, time/batch = 0.0772s	
2811/5250 (epoch 26.771), train_loss = 1.32579705, grad/param norm = 5.4760e-02, time/batch = 0.0787s	
2812/5250 (epoch 26.781), train_loss = 1.35072293, grad/param norm = 5.8994e-02, time/batch = 0.0773s	
2813/5250 (epoch 26.790), train_loss = 1.36509226, grad/param norm = 6.1891e-02, time/batch = 0.0770s	
2814/5250 (epoch 26.800), train_loss = 1.34755148, grad/param norm = 5.6704e-02, time/batch = 0.0768s	
2815/5250 (epoch 26.810), train_loss = 1.34800112, grad/param norm = 5.5869e-02, time/batch = 0.0769s	
2816/5250 (epoch 26.819), train_loss = 1.35249010, grad/param norm = 5.7404e-02, time/batch = 0.0770s	
2817/5250 (epoch 26.829), train_loss = 1.34813928, grad/param norm = 5.9824e-02, time/batch = 0.0766s	
2818/5250 (epoch 26.838), train_loss = 1.33054224, grad/param norm = 5.4546e-02, time/batch = 0.0771s	
2819/5250 (epoch 26.848), train_loss = 1.33013373, grad/param norm = 6.4271e-02, time/batch = 0.0823s	
2820/5250 (epoch 26.857), train_loss = 1.34600186, grad/param norm = 6.5200e-02, time/batch = 0.0775s	
2821/5250 (epoch 26.867), train_loss = 1.34078595, grad/param norm = 6.2655e-02, time/batch = 0.0795s	
2822/5250 (epoch 26.876), train_loss = 1.35165284, grad/param norm = 5.7339e-02, time/batch = 0.0772s	
2823/5250 (epoch 26.886), train_loss = 1.33313125, grad/param norm = 6.0357e-02, time/batch = 0.0778s	
2824/5250 (epoch 26.895), train_loss = 1.37436571, grad/param norm = 6.7680e-02, time/batch = 0.0769s	
2825/5250 (epoch 26.905), train_loss = 1.35934942, grad/param norm = 6.2878e-02, time/batch = 0.0770s	
2826/5250 (epoch 26.914), train_loss = 1.37587071, grad/param norm = 6.7061e-02, time/batch = 0.0775s	
2827/5250 (epoch 26.924), train_loss = 1.37168776, grad/param norm = 7.1937e-02, time/batch = 0.0766s	
2828/5250 (epoch 26.933), train_loss = 1.34577539, grad/param norm = 8.1987e-02, time/batch = 0.0768s	
2829/5250 (epoch 26.943), train_loss = 1.38417133, grad/param norm = 8.5442e-02, time/batch = 0.0777s	
2830/5250 (epoch 26.952), train_loss = 1.37847685, grad/param norm = 6.7960e-02, time/batch = 0.0770s	
2831/5250 (epoch 26.962), train_loss = 1.35350168, grad/param norm = 5.9828e-02, time/batch = 0.0789s	
2832/5250 (epoch 26.971), train_loss = 1.34471277, grad/param norm = 6.0116e-02, time/batch = 0.0768s	
2833/5250 (epoch 26.981), train_loss = 1.37196732, grad/param norm = 5.9529e-02, time/batch = 0.0768s	
2834/5250 (epoch 26.990), train_loss = 1.37097323, grad/param norm = 5.9835e-02, time/batch = 0.0769s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
2835/5250 (epoch 27.000), train_loss = 1.35004797, grad/param norm = 5.8500e-02, time/batch = 0.0774s	
2836/5250 (epoch 27.010), train_loss = 1.53734757, grad/param norm = 6.2370e-02, time/batch = 0.0774s	
2837/5250 (epoch 27.019), train_loss = 1.33787879, grad/param norm = 6.7358e-02, time/batch = 0.0765s	
2838/5250 (epoch 27.029), train_loss = 1.34907888, grad/param norm = 5.9260e-02, time/batch = 0.0767s	
2839/5250 (epoch 27.038), train_loss = 1.33862204, grad/param norm = 6.0199e-02, time/batch = 0.0771s	
2840/5250 (epoch 27.048), train_loss = 1.31802119, grad/param norm = 5.6737e-02, time/batch = 0.0775s	
2841/5250 (epoch 27.057), train_loss = 1.33040777, grad/param norm = 5.1320e-02, time/batch = 0.0788s	
2842/5250 (epoch 27.067), train_loss = 1.33761036, grad/param norm = 5.2079e-02, time/batch = 0.0770s	
2843/5250 (epoch 27.076), train_loss = 1.34166438, grad/param norm = 5.9222e-02, time/batch = 0.0770s	
2844/5250 (epoch 27.086), train_loss = 1.29109477, grad/param norm = 6.3107e-02, time/batch = 0.0767s	
2845/5250 (epoch 27.095), train_loss = 1.32608827, grad/param norm = 6.1611e-02, time/batch = 0.0771s	
2846/5250 (epoch 27.105), train_loss = 1.34195361, grad/param norm = 5.8710e-02, time/batch = 0.0782s	
2847/5250 (epoch 27.114), train_loss = 1.32357333, grad/param norm = 5.9586e-02, time/batch = 0.0769s	
2848/5250 (epoch 27.124), train_loss = 1.34111940, grad/param norm = 6.0141e-02, time/batch = 0.0769s	
2849/5250 (epoch 27.133), train_loss = 1.32930863, grad/param norm = 5.9225e-02, time/batch = 0.0772s	
2850/5250 (epoch 27.143), train_loss = 1.31411005, grad/param norm = 6.2664e-02, time/batch = 0.0767s	
2851/5250 (epoch 27.152), train_loss = 1.31271412, grad/param norm = 5.8597e-02, time/batch = 0.0789s	
2852/5250 (epoch 27.162), train_loss = 1.34162883, grad/param norm = 5.8013e-02, time/batch = 0.0768s	
2853/5250 (epoch 27.171), train_loss = 1.34678130, grad/param norm = 5.4636e-02, time/batch = 0.0767s	
2854/5250 (epoch 27.181), train_loss = 1.34989395, grad/param norm = 5.8240e-02, time/batch = 0.0766s	
2855/5250 (epoch 27.190), train_loss = 1.34256531, grad/param norm = 5.2968e-02, time/batch = 0.0772s	
2856/5250 (epoch 27.200), train_loss = 1.33129987, grad/param norm = 5.6933e-02, time/batch = 0.0771s	
2857/5250 (epoch 27.210), train_loss = 1.32974812, grad/param norm = 5.8093e-02, time/batch = 0.0771s	
2858/5250 (epoch 27.219), train_loss = 1.37760368, grad/param norm = 6.3387e-02, time/batch = 0.0766s	
2859/5250 (epoch 27.229), train_loss = 1.33323967, grad/param norm = 5.8326e-02, time/batch = 0.0772s	
2860/5250 (epoch 27.238), train_loss = 1.33537874, grad/param norm = 5.8708e-02, time/batch = 0.0772s	
2861/5250 (epoch 27.248), train_loss = 1.33910356, grad/param norm = 5.7468e-02, time/batch = 0.0787s	
2862/5250 (epoch 27.257), train_loss = 1.32824376, grad/param norm = 5.4361e-02, time/batch = 0.0774s	
2863/5250 (epoch 27.267), train_loss = 1.31783369, grad/param norm = 5.1795e-02, time/batch = 0.0768s	
2864/5250 (epoch 27.276), train_loss = 1.32110078, grad/param norm = 5.1076e-02, time/batch = 0.0766s	
2865/5250 (epoch 27.286), train_loss = 1.30414906, grad/param norm = 5.4925e-02, time/batch = 0.0772s	
2866/5250 (epoch 27.295), train_loss = 1.33026731, grad/param norm = 5.5947e-02, time/batch = 0.0776s	
2867/5250 (epoch 27.305), train_loss = 1.32742284, grad/param norm = 6.0251e-02, time/batch = 0.0768s	
2868/5250 (epoch 27.314), train_loss = 1.31476039, grad/param norm = 5.1884e-02, time/batch = 0.0770s	
2869/5250 (epoch 27.324), train_loss = 1.32567519, grad/param norm = 5.4096e-02, time/batch = 0.0772s	
2870/5250 (epoch 27.333), train_loss = 1.33082099, grad/param norm = 5.6669e-02, time/batch = 0.0771s	
2871/5250 (epoch 27.343), train_loss = 1.33614829, grad/param norm = 5.9532e-02, time/batch = 0.0789s	
2872/5250 (epoch 27.352), train_loss = 1.34693981, grad/param norm = 6.3366e-02, time/batch = 0.0768s	
2873/5250 (epoch 27.362), train_loss = 1.34456460, grad/param norm = 6.4130e-02, time/batch = 0.0770s	
2874/5250 (epoch 27.371), train_loss = 1.32451995, grad/param norm = 6.0423e-02, time/batch = 0.0771s	
2875/5250 (epoch 27.381), train_loss = 1.32472451, grad/param norm = 6.4425e-02, time/batch = 0.0773s	
2876/5250 (epoch 27.390), train_loss = 1.33716999, grad/param norm = 7.1558e-02, time/batch = 0.0772s	
2877/5250 (epoch 27.400), train_loss = 1.33713701, grad/param norm = 6.3208e-02, time/batch = 0.0767s	
2878/5250 (epoch 27.410), train_loss = 1.34322798, grad/param norm = 5.5487e-02, time/batch = 0.0768s	
2879/5250 (epoch 27.419), train_loss = 1.33321332, grad/param norm = 5.7823e-02, time/batch = 0.0776s	
2880/5250 (epoch 27.429), train_loss = 1.34126139, grad/param norm = 5.5615e-02, time/batch = 0.0770s	
2881/5250 (epoch 27.438), train_loss = 1.35770914, grad/param norm = 5.6823e-02, time/batch = 0.0789s	
2882/5250 (epoch 27.448), train_loss = 1.32184731, grad/param norm = 6.4655e-02, time/batch = 0.0768s	
2883/5250 (epoch 27.457), train_loss = 1.32475070, grad/param norm = 7.5824e-02, time/batch = 0.0767s	
2884/5250 (epoch 27.467), train_loss = 1.33363218, grad/param norm = 6.2021e-02, time/batch = 0.0766s	
2885/5250 (epoch 27.476), train_loss = 1.33216188, grad/param norm = 6.0616e-02, time/batch = 0.0776s	
2886/5250 (epoch 27.486), train_loss = 1.34839131, grad/param norm = 6.2455e-02, time/batch = 0.0772s	
2887/5250 (epoch 27.495), train_loss = 1.34966789, grad/param norm = 5.5002e-02, time/batch = 0.0766s	
2888/5250 (epoch 27.505), train_loss = 1.35641797, grad/param norm = 5.4815e-02, time/batch = 0.0765s	
2889/5250 (epoch 27.514), train_loss = 1.35375167, grad/param norm = 6.2330e-02, time/batch = 0.0773s	
2890/5250 (epoch 27.524), train_loss = 1.32537868, grad/param norm = 5.6469e-02, time/batch = 0.0773s	
2891/5250 (epoch 27.533), train_loss = 1.33470574, grad/param norm = 5.8141e-02, time/batch = 0.0787s	
2892/5250 (epoch 27.543), train_loss = 1.32618849, grad/param norm = 5.9367e-02, time/batch = 0.0769s	
2893/5250 (epoch 27.552), train_loss = 1.33675167, grad/param norm = 6.7270e-02, time/batch = 0.0765s	
2894/5250 (epoch 27.562), train_loss = 1.33388186, grad/param norm = 6.8270e-02, time/batch = 0.0766s	
2895/5250 (epoch 27.571), train_loss = 1.33867316, grad/param norm = 6.6154e-02, time/batch = 0.0770s	
2896/5250 (epoch 27.581), train_loss = 1.36913930, grad/param norm = 6.2127e-02, time/batch = 0.0780s	
2897/5250 (epoch 27.590), train_loss = 1.34130216, grad/param norm = 5.7782e-02, time/batch = 0.0768s	
2898/5250 (epoch 27.600), train_loss = 1.35896021, grad/param norm = 5.6478e-02, time/batch = 0.0767s	
2899/5250 (epoch 27.610), train_loss = 1.34982016, grad/param norm = 5.9423e-02, time/batch = 0.0774s	
2900/5250 (epoch 27.619), train_loss = 1.33647640, grad/param norm = 5.9880e-02, time/batch = 0.0771s	
2901/5250 (epoch 27.629), train_loss = 1.34946063, grad/param norm = 5.9038e-02, time/batch = 0.0791s	
2902/5250 (epoch 27.638), train_loss = 1.32709805, grad/param norm = 5.9677e-02, time/batch = 0.0766s	
2903/5250 (epoch 27.648), train_loss = 1.34038892, grad/param norm = 7.1044e-02, time/batch = 0.0770s	
2904/5250 (epoch 27.657), train_loss = 1.33943524, grad/param norm = 7.0537e-02, time/batch = 0.0766s	
2905/5250 (epoch 27.667), train_loss = 1.34364376, grad/param norm = 7.1870e-02, time/batch = 0.0771s	
2906/5250 (epoch 27.676), train_loss = 1.34692354, grad/param norm = 7.8907e-02, time/batch = 0.0773s	
2907/5250 (epoch 27.686), train_loss = 1.36751004, grad/param norm = 6.7598e-02, time/batch = 0.0773s	
2908/5250 (epoch 27.695), train_loss = 1.34724601, grad/param norm = 7.1031e-02, time/batch = 0.0767s	
2909/5250 (epoch 27.705), train_loss = 1.32795287, grad/param norm = 5.8102e-02, time/batch = 0.0774s	
2910/5250 (epoch 27.714), train_loss = 1.36307589, grad/param norm = 5.7130e-02, time/batch = 0.0771s	
2911/5250 (epoch 27.724), train_loss = 1.34371188, grad/param norm = 5.9012e-02, time/batch = 0.0788s	
2912/5250 (epoch 27.733), train_loss = 1.32239762, grad/param norm = 5.9812e-02, time/batch = 0.0777s	
2913/5250 (epoch 27.743), train_loss = 1.32927129, grad/param norm = 6.7585e-02, time/batch = 0.0793s	
2914/5250 (epoch 27.752), train_loss = 1.33976061, grad/param norm = 6.5906e-02, time/batch = 0.0777s	
2915/5250 (epoch 27.762), train_loss = 1.32629735, grad/param norm = 6.4099e-02, time/batch = 0.0773s	
2916/5250 (epoch 27.771), train_loss = 1.31970148, grad/param norm = 5.6798e-02, time/batch = 0.0774s	
2917/5250 (epoch 27.781), train_loss = 1.34443487, grad/param norm = 6.0640e-02, time/batch = 0.0766s	
2918/5250 (epoch 27.790), train_loss = 1.35826324, grad/param norm = 5.9878e-02, time/batch = 0.0770s	
2919/5250 (epoch 27.800), train_loss = 1.34132260, grad/param norm = 5.8525e-02, time/batch = 0.0775s	
2920/5250 (epoch 27.810), train_loss = 1.34200691, grad/param norm = 5.7722e-02, time/batch = 0.0771s	
2921/5250 (epoch 27.819), train_loss = 1.34697889, grad/param norm = 5.9056e-02, time/batch = 0.0789s	
2922/5250 (epoch 27.829), train_loss = 1.34269131, grad/param norm = 6.3793e-02, time/batch = 0.0769s	
2923/5250 (epoch 27.838), train_loss = 1.32445970, grad/param norm = 5.5991e-02, time/batch = 0.0774s	
2924/5250 (epoch 27.848), train_loss = 1.32275789, grad/param norm = 5.9436e-02, time/batch = 0.0768s	
2925/5250 (epoch 27.857), train_loss = 1.33815969, grad/param norm = 5.8432e-02, time/batch = 0.0770s	
2926/5250 (epoch 27.867), train_loss = 1.33257117, grad/param norm = 5.5674e-02, time/batch = 0.0774s	
2927/5250 (epoch 27.876), train_loss = 1.34301414, grad/param norm = 5.2470e-02, time/batch = 0.0764s	
2928/5250 (epoch 27.886), train_loss = 1.32445834, grad/param norm = 5.2172e-02, time/batch = 0.0765s	
2929/5250 (epoch 27.895), train_loss = 1.36609130, grad/param norm = 5.9402e-02, time/batch = 0.0775s	
2930/5250 (epoch 27.905), train_loss = 1.35191664, grad/param norm = 5.7512e-02, time/batch = 0.0822s	
2931/5250 (epoch 27.914), train_loss = 1.36930591, grad/param norm = 6.3872e-02, time/batch = 0.0794s	
2932/5250 (epoch 27.924), train_loss = 1.36222231, grad/param norm = 6.1096e-02, time/batch = 0.0772s	
2933/5250 (epoch 27.933), train_loss = 1.33215142, grad/param norm = 5.0194e-02, time/batch = 0.0771s	
2934/5250 (epoch 27.943), train_loss = 1.36931467, grad/param norm = 5.6018e-02, time/batch = 0.0774s	
2935/5250 (epoch 27.952), train_loss = 1.36866109, grad/param norm = 5.7685e-02, time/batch = 0.0770s	
2936/5250 (epoch 27.962), train_loss = 1.34606104, grad/param norm = 5.3607e-02, time/batch = 0.0773s	
2937/5250 (epoch 27.971), train_loss = 1.33953631, grad/param norm = 6.4047e-02, time/batch = 0.0765s	
2938/5250 (epoch 27.981), train_loss = 1.36683686, grad/param norm = 6.2241e-02, time/batch = 0.0764s	
2939/5250 (epoch 27.990), train_loss = 1.36596134, grad/param norm = 6.1512e-02, time/batch = 0.0771s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
2940/5250 (epoch 28.000), train_loss = 1.34784509, grad/param norm = 6.7699e-02, time/batch = 0.0774s	
2941/5250 (epoch 28.010), train_loss = 1.53886947, grad/param norm = 8.1112e-02, time/batch = 0.0787s	
2942/5250 (epoch 28.019), train_loss = 1.33679295, grad/param norm = 8.3301e-02, time/batch = 0.0769s	
2943/5250 (epoch 28.029), train_loss = 1.34669382, grad/param norm = 7.2246e-02, time/batch = 0.0770s	
2944/5250 (epoch 28.038), train_loss = 1.33606343, grad/param norm = 7.0747e-02, time/batch = 0.0768s	
2945/5250 (epoch 28.048), train_loss = 1.31389805, grad/param norm = 6.3090e-02, time/batch = 0.0771s	
2946/5250 (epoch 28.057), train_loss = 1.32555310, grad/param norm = 5.4909e-02, time/batch = 0.0779s	
2947/5250 (epoch 28.067), train_loss = 1.33216416, grad/param norm = 5.4319e-02, time/batch = 0.0769s	
2948/5250 (epoch 28.076), train_loss = 1.33651132, grad/param norm = 6.0559e-02, time/batch = 0.0767s	
2949/5250 (epoch 28.086), train_loss = 1.28541868, grad/param norm = 6.1423e-02, time/batch = 0.0773s	
2950/5250 (epoch 28.095), train_loss = 1.31926374, grad/param norm = 5.8365e-02, time/batch = 0.0771s	
2951/5250 (epoch 28.105), train_loss = 1.33521736, grad/param norm = 5.6965e-02, time/batch = 0.0793s	
2952/5250 (epoch 28.114), train_loss = 1.31754267, grad/param norm = 5.8282e-02, time/batch = 0.0768s	
2953/5250 (epoch 28.124), train_loss = 1.33511825, grad/param norm = 6.0132e-02, time/batch = 0.0770s	
2954/5250 (epoch 28.133), train_loss = 1.32348462, grad/param norm = 5.9012e-02, time/batch = 0.0769s	
2955/5250 (epoch 28.143), train_loss = 1.30804044, grad/param norm = 6.0610e-02, time/batch = 0.0773s	
2956/5250 (epoch 28.152), train_loss = 1.30666723, grad/param norm = 5.6317e-02, time/batch = 0.0773s	
2957/5250 (epoch 28.162), train_loss = 1.33563022, grad/param norm = 5.6199e-02, time/batch = 0.0771s	
2958/5250 (epoch 28.171), train_loss = 1.34034013, grad/param norm = 5.2975e-02, time/batch = 0.0770s	
2959/5250 (epoch 28.181), train_loss = 1.34419246, grad/param norm = 5.7410e-02, time/batch = 0.0774s	
2960/5250 (epoch 28.190), train_loss = 1.33691360, grad/param norm = 5.3663e-02, time/batch = 0.0771s	
2961/5250 (epoch 28.200), train_loss = 1.32515581, grad/param norm = 5.7698e-02, time/batch = 0.0787s	
2962/5250 (epoch 28.210), train_loss = 1.32399974, grad/param norm = 5.7988e-02, time/batch = 0.0774s	
2963/5250 (epoch 28.219), train_loss = 1.37185677, grad/param norm = 6.2236e-02, time/batch = 0.0773s	
2964/5250 (epoch 28.229), train_loss = 1.32694621, grad/param norm = 5.6381e-02, time/batch = 0.0769s	
2965/5250 (epoch 28.238), train_loss = 1.32907381, grad/param norm = 5.6614e-02, time/batch = 0.0769s	
2966/5250 (epoch 28.248), train_loss = 1.33316563, grad/param norm = 5.6478e-02, time/batch = 0.0773s	
2967/5250 (epoch 28.257), train_loss = 1.32259359, grad/param norm = 5.3329e-02, time/batch = 0.0767s	
2968/5250 (epoch 28.267), train_loss = 1.31205731, grad/param norm = 5.1737e-02, time/batch = 0.0770s	
2969/5250 (epoch 28.276), train_loss = 1.31513592, grad/param norm = 5.1064e-02, time/batch = 0.0770s	
2970/5250 (epoch 28.286), train_loss = 1.29859599, grad/param norm = 5.4936e-02, time/batch = 0.0770s	
2971/5250 (epoch 28.295), train_loss = 1.32443887, grad/param norm = 5.4778e-02, time/batch = 0.0788s	
2972/5250 (epoch 28.305), train_loss = 1.32078471, grad/param norm = 5.8579e-02, time/batch = 0.0769s	
2973/5250 (epoch 28.314), train_loss = 1.30907149, grad/param norm = 5.1695e-02, time/batch = 0.0774s	
2974/5250 (epoch 28.324), train_loss = 1.32024312, grad/param norm = 5.3896e-02, time/batch = 0.0768s	
2975/5250 (epoch 28.333), train_loss = 1.32484332, grad/param norm = 5.5490e-02, time/batch = 0.0769s	
2976/5250 (epoch 28.343), train_loss = 1.32954467, grad/param norm = 5.7047e-02, time/batch = 0.0771s	
2977/5250 (epoch 28.352), train_loss = 1.34057151, grad/param norm = 6.0776e-02, time/batch = 0.0765s	
2978/5250 (epoch 28.362), train_loss = 1.33819497, grad/param norm = 6.1551e-02, time/batch = 0.0763s	
2979/5250 (epoch 28.371), train_loss = 1.31813608, grad/param norm = 5.7427e-02, time/batch = 0.0776s	
2980/5250 (epoch 28.381), train_loss = 1.31783545, grad/param norm = 5.9418e-02, time/batch = 0.0772s	
2981/5250 (epoch 28.390), train_loss = 1.32970590, grad/param norm = 6.6282e-02, time/batch = 0.0788s	
2982/5250 (epoch 28.400), train_loss = 1.33114762, grad/param norm = 6.1423e-02, time/batch = 0.0769s	
2983/5250 (epoch 28.410), train_loss = 1.33701996, grad/param norm = 5.6269e-02, time/batch = 0.0770s	
2984/5250 (epoch 28.419), train_loss = 1.32744752, grad/param norm = 5.9000e-02, time/batch = 0.0772s	
2985/5250 (epoch 28.429), train_loss = 1.33561124, grad/param norm = 5.5922e-02, time/batch = 0.0773s	
2986/5250 (epoch 28.438), train_loss = 1.35236678, grad/param norm = 5.7790e-02, time/batch = 0.0774s	
2987/5250 (epoch 28.448), train_loss = 1.31591984, grad/param norm = 6.2878e-02, time/batch = 0.0767s	
2988/5250 (epoch 28.457), train_loss = 1.31820834, grad/param norm = 7.0883e-02, time/batch = 0.0768s	
2989/5250 (epoch 28.467), train_loss = 1.32727445, grad/param norm = 5.8291e-02, time/batch = 0.0772s	
2990/5250 (epoch 28.476), train_loss = 1.32538926, grad/param norm = 5.9346e-02, time/batch = 0.0774s	
2991/5250 (epoch 28.486), train_loss = 1.34261881, grad/param norm = 6.1646e-02, time/batch = 0.0788s	
2992/5250 (epoch 28.495), train_loss = 1.34381382, grad/param norm = 5.5631e-02, time/batch = 0.0768s	
2993/5250 (epoch 28.505), train_loss = 1.35124194, grad/param norm = 5.7040e-02, time/batch = 0.0768s	
2994/5250 (epoch 28.514), train_loss = 1.34799430, grad/param norm = 6.4711e-02, time/batch = 0.0770s	
2995/5250 (epoch 28.524), train_loss = 1.32000376, grad/param norm = 5.6410e-02, time/batch = 0.0769s	
2996/5250 (epoch 28.533), train_loss = 1.32956753, grad/param norm = 6.0427e-02, time/batch = 0.0775s	
2997/5250 (epoch 28.543), train_loss = 1.32159807, grad/param norm = 6.2982e-02, time/batch = 0.0767s	
2998/5250 (epoch 28.552), train_loss = 1.33124660, grad/param norm = 6.8589e-02, time/batch = 0.0766s	
2999/5250 (epoch 28.562), train_loss = 1.32735659, grad/param norm = 6.5952e-02, time/batch = 0.0771s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch28.57_1.4469.t7	
3000/5250 (epoch 28.571), train_loss = 1.33235580, grad/param norm = 6.4432e-02, time/batch = 0.0767s	
3001/5250 (epoch 28.581), train_loss = 1.60079475, grad/param norm = 7.0638e-02, time/batch = 0.0792s	
3002/5250 (epoch 28.590), train_loss = 1.33922611, grad/param norm = 6.0871e-02, time/batch = 0.0771s	
3003/5250 (epoch 28.600), train_loss = 1.35478074, grad/param norm = 5.6702e-02, time/batch = 0.0768s	
3004/5250 (epoch 28.610), train_loss = 1.34391710, grad/param norm = 5.8943e-02, time/batch = 0.0776s	
3005/5250 (epoch 28.619), train_loss = 1.32981858, grad/param norm = 5.8059e-02, time/batch = 0.0781s	
3006/5250 (epoch 28.629), train_loss = 1.34309307, grad/param norm = 5.7581e-02, time/batch = 0.0782s	
3007/5250 (epoch 28.638), train_loss = 1.32109756, grad/param norm = 5.6522e-02, time/batch = 0.0774s	
3008/5250 (epoch 28.648), train_loss = 1.33292677, grad/param norm = 6.1620e-02, time/batch = 0.0774s	
3009/5250 (epoch 28.657), train_loss = 1.33136585, grad/param norm = 5.9265e-02, time/batch = 0.0783s	
3010/5250 (epoch 28.667), train_loss = 1.33541672, grad/param norm = 6.2004e-02, time/batch = 0.0777s	
3011/5250 (epoch 28.676), train_loss = 1.33797324, grad/param norm = 6.9305e-02, time/batch = 0.0791s	
3012/5250 (epoch 28.686), train_loss = 1.36072432, grad/param norm = 6.0999e-02, time/batch = 0.0769s	
3013/5250 (epoch 28.695), train_loss = 1.34073475, grad/param norm = 6.5901e-02, time/batch = 0.0768s	
3014/5250 (epoch 28.705), train_loss = 1.32186583, grad/param norm = 5.5716e-02, time/batch = 0.0768s	
3015/5250 (epoch 28.714), train_loss = 1.35693603, grad/param norm = 5.5216e-02, time/batch = 0.0773s	
3016/5250 (epoch 28.724), train_loss = 1.33746030, grad/param norm = 5.6496e-02, time/batch = 0.0772s	
3017/5250 (epoch 28.733), train_loss = 1.31616627, grad/param norm = 5.7044e-02, time/batch = 0.0766s	
3018/5250 (epoch 28.743), train_loss = 1.32262990, grad/param norm = 6.3461e-02, time/batch = 0.0765s	
3019/5250 (epoch 28.752), train_loss = 1.33338784, grad/param norm = 6.2424e-02, time/batch = 0.0771s	
3020/5250 (epoch 28.762), train_loss = 1.32031231, grad/param norm = 6.1502e-02, time/batch = 0.0774s	
3021/5250 (epoch 28.771), train_loss = 1.31339453, grad/param norm = 5.5129e-02, time/batch = 0.0799s	
3022/5250 (epoch 28.781), train_loss = 1.33876425, grad/param norm = 5.7486e-02, time/batch = 0.0770s	
3023/5250 (epoch 28.790), train_loss = 1.35219056, grad/param norm = 5.8045e-02, time/batch = 0.0770s	
3024/5250 (epoch 28.800), train_loss = 1.33461922, grad/param norm = 5.6984e-02, time/batch = 0.0770s	
3025/5250 (epoch 28.810), train_loss = 1.33585489, grad/param norm = 5.6086e-02, time/batch = 0.0767s	
3026/5250 (epoch 28.819), train_loss = 1.34143710, grad/param norm = 5.7725e-02, time/batch = 0.0779s	
3027/5250 (epoch 28.829), train_loss = 1.33683520, grad/param norm = 6.0532e-02, time/batch = 0.0769s	
3028/5250 (epoch 28.838), train_loss = 1.31894169, grad/param norm = 5.3499e-02, time/batch = 0.0769s	
3029/5250 (epoch 28.848), train_loss = 1.31765622, grad/param norm = 5.7688e-02, time/batch = 0.0795s	
3030/5250 (epoch 28.857), train_loss = 1.33285981, grad/param norm = 5.8986e-02, time/batch = 0.0771s	
3031/5250 (epoch 28.867), train_loss = 1.32741792, grad/param norm = 5.6281e-02, time/batch = 0.0792s	
3032/5250 (epoch 28.876), train_loss = 1.33679160, grad/param norm = 5.2858e-02, time/batch = 0.0770s	
3033/5250 (epoch 28.886), train_loss = 1.31882464, grad/param norm = 5.3498e-02, time/batch = 0.0771s	
3034/5250 (epoch 28.895), train_loss = 1.36141062, grad/param norm = 6.2938e-02, time/batch = 0.0772s	
3035/5250 (epoch 28.905), train_loss = 1.34762006, grad/param norm = 6.0889e-02, time/batch = 0.0768s	
3036/5250 (epoch 28.914), train_loss = 1.36474989, grad/param norm = 6.4620e-02, time/batch = 0.0774s	
3037/5250 (epoch 28.924), train_loss = 1.35602310, grad/param norm = 5.7857e-02, time/batch = 0.0770s	
3038/5250 (epoch 28.933), train_loss = 1.32566998, grad/param norm = 4.9636e-02, time/batch = 0.0797s	
3039/5250 (epoch 28.943), train_loss = 1.36313337, grad/param norm = 5.4928e-02, time/batch = 0.0776s	
3040/5250 (epoch 28.952), train_loss = 1.36224681, grad/param norm = 5.5754e-02, time/batch = 0.0771s	
3041/5250 (epoch 28.962), train_loss = 1.33979816, grad/param norm = 5.2345e-02, time/batch = 0.0791s	
3042/5250 (epoch 28.971), train_loss = 1.33315405, grad/param norm = 5.9880e-02, time/batch = 0.0774s	
3043/5250 (epoch 28.981), train_loss = 1.36005167, grad/param norm = 5.9656e-02, time/batch = 0.0770s	
3044/5250 (epoch 28.990), train_loss = 1.36025470, grad/param norm = 6.2654e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
3045/5250 (epoch 29.000), train_loss = 1.34264619, grad/param norm = 6.7549e-02, time/batch = 0.0770s	
3046/5250 (epoch 29.010), train_loss = 1.53266288, grad/param norm = 7.7524e-02, time/batch = 0.0774s	
3047/5250 (epoch 29.019), train_loss = 1.32938950, grad/param norm = 7.8524e-02, time/batch = 0.0770s	
3048/5250 (epoch 29.029), train_loss = 1.34079511, grad/param norm = 6.9923e-02, time/batch = 0.0770s	
3049/5250 (epoch 29.038), train_loss = 1.33025187, grad/param norm = 6.9182e-02, time/batch = 0.0772s	
3050/5250 (epoch 29.048), train_loss = 1.30792894, grad/param norm = 6.1462e-02, time/batch = 0.0771s	
3051/5250 (epoch 29.057), train_loss = 1.31965915, grad/param norm = 5.3634e-02, time/batch = 0.0790s	
3052/5250 (epoch 29.067), train_loss = 1.32692719, grad/param norm = 5.3576e-02, time/batch = 0.0769s	
3053/5250 (epoch 29.076), train_loss = 1.33104946, grad/param norm = 5.9023e-02, time/batch = 0.0775s	
3054/5250 (epoch 29.086), train_loss = 1.28023938, grad/param norm = 6.0126e-02, time/batch = 0.0770s	
3055/5250 (epoch 29.095), train_loss = 1.31337136, grad/param norm = 5.7694e-02, time/batch = 0.0771s	
3056/5250 (epoch 29.105), train_loss = 1.32950704, grad/param norm = 5.6920e-02, time/batch = 0.0774s	
3057/5250 (epoch 29.114), train_loss = 1.31232648, grad/param norm = 5.8932e-02, time/batch = 0.0767s	
3058/5250 (epoch 29.124), train_loss = 1.32991798, grad/param norm = 6.0065e-02, time/batch = 0.0765s	
3059/5250 (epoch 29.133), train_loss = 1.31763076, grad/param norm = 5.7448e-02, time/batch = 0.0773s	
3060/5250 (epoch 29.143), train_loss = 1.30255817, grad/param norm = 5.8438e-02, time/batch = 0.0768s	
3061/5250 (epoch 29.152), train_loss = 1.30124821, grad/param norm = 5.4612e-02, time/batch = 0.0789s	
3062/5250 (epoch 29.162), train_loss = 1.33008849, grad/param norm = 5.4363e-02, time/batch = 0.0770s	
3063/5250 (epoch 29.171), train_loss = 1.33434597, grad/param norm = 5.1585e-02, time/batch = 0.0770s	
3064/5250 (epoch 29.181), train_loss = 1.33895656, grad/param norm = 5.6970e-02, time/batch = 0.0770s	
3065/5250 (epoch 29.190), train_loss = 1.33151587, grad/param norm = 5.3647e-02, time/batch = 0.0777s	
3066/5250 (epoch 29.200), train_loss = 1.31946841, grad/param norm = 5.7560e-02, time/batch = 0.0776s	
3067/5250 (epoch 29.210), train_loss = 1.31877932, grad/param norm = 5.7366e-02, time/batch = 0.0769s	
3068/5250 (epoch 29.219), train_loss = 1.36642253, grad/param norm = 6.0822e-02, time/batch = 0.0766s	
3069/5250 (epoch 29.229), train_loss = 1.32123482, grad/param norm = 5.4907e-02, time/batch = 0.0768s	
3070/5250 (epoch 29.238), train_loss = 1.32343588, grad/param norm = 5.5842e-02, time/batch = 0.0770s	
3071/5250 (epoch 29.248), train_loss = 1.32775522, grad/param norm = 5.5961e-02, time/batch = 0.0788s	
3072/5250 (epoch 29.257), train_loss = 1.31744148, grad/param norm = 5.2690e-02, time/batch = 0.0769s	
3073/5250 (epoch 29.267), train_loss = 1.30665749, grad/param norm = 5.1566e-02, time/batch = 0.0771s	
3074/5250 (epoch 29.276), train_loss = 1.30959681, grad/param norm = 5.0943e-02, time/batch = 0.0770s	
3075/5250 (epoch 29.286), train_loss = 1.29337285, grad/param norm = 5.4768e-02, time/batch = 0.0770s	
3076/5250 (epoch 29.295), train_loss = 1.31899416, grad/param norm = 5.3811e-02, time/batch = 0.0777s	
3077/5250 (epoch 29.305), train_loss = 1.31500565, grad/param norm = 5.7911e-02, time/batch = 0.0767s	
3078/5250 (epoch 29.314), train_loss = 1.30380071, grad/param norm = 5.1605e-02, time/batch = 0.0765s	
3079/5250 (epoch 29.324), train_loss = 1.31509064, grad/param norm = 5.3049e-02, time/batch = 0.0774s	
3080/5250 (epoch 29.333), train_loss = 1.31937961, grad/param norm = 5.4347e-02, time/batch = 0.0768s	
3081/5250 (epoch 29.343), train_loss = 1.32356460, grad/param norm = 5.5661e-02, time/batch = 0.0790s	
3082/5250 (epoch 29.352), train_loss = 1.33490631, grad/param norm = 5.9499e-02, time/batch = 0.0769s	
3083/5250 (epoch 29.362), train_loss = 1.33270960, grad/param norm = 6.0563e-02, time/batch = 0.0768s	
3084/5250 (epoch 29.371), train_loss = 1.31266832, grad/param norm = 5.6509e-02, time/batch = 0.0770s	
3085/5250 (epoch 29.381), train_loss = 1.31220334, grad/param norm = 5.7853e-02, time/batch = 0.0768s	
3086/5250 (epoch 29.390), train_loss = 1.32347270, grad/param norm = 6.3973e-02, time/batch = 0.0771s	
3087/5250 (epoch 29.400), train_loss = 1.32559601, grad/param norm = 5.9393e-02, time/batch = 0.0772s	
3088/5250 (epoch 29.410), train_loss = 1.33088857, grad/param norm = 5.4535e-02, time/batch = 0.0768s	
3089/5250 (epoch 29.419), train_loss = 1.32146150, grad/param norm = 5.6904e-02, time/batch = 0.0771s	
3090/5250 (epoch 29.429), train_loss = 1.32993825, grad/param norm = 5.4283e-02, time/batch = 0.0769s	
3091/5250 (epoch 29.438), train_loss = 1.34708951, grad/param norm = 5.8741e-02, time/batch = 0.0787s	
3092/5250 (epoch 29.448), train_loss = 1.31104429, grad/param norm = 6.3424e-02, time/batch = 0.0774s	
3093/5250 (epoch 29.457), train_loss = 1.31304859, grad/param norm = 6.8042e-02, time/batch = 0.0772s	
3094/5250 (epoch 29.467), train_loss = 1.32151706, grad/param norm = 5.7143e-02, time/batch = 0.0771s	
3095/5250 (epoch 29.476), train_loss = 1.31900070, grad/param norm = 5.8408e-02, time/batch = 0.0768s	
3096/5250 (epoch 29.486), train_loss = 1.33700141, grad/param norm = 6.0038e-02, time/batch = 0.0774s	
3097/5250 (epoch 29.495), train_loss = 1.33846900, grad/param norm = 5.4991e-02, time/batch = 0.0768s	
3098/5250 (epoch 29.505), train_loss = 1.34604428, grad/param norm = 5.9010e-02, time/batch = 0.0771s	
3099/5250 (epoch 29.514), train_loss = 1.34238698, grad/param norm = 6.6904e-02, time/batch = 0.0772s	
3100/5250 (epoch 29.524), train_loss = 1.31475327, grad/param norm = 5.4495e-02, time/batch = 0.0769s	
3101/5250 (epoch 29.533), train_loss = 1.32407995, grad/param norm = 5.6815e-02, time/batch = 0.0788s	
3102/5250 (epoch 29.543), train_loss = 1.31504414, grad/param norm = 5.8060e-02, time/batch = 0.0769s	
3103/5250 (epoch 29.552), train_loss = 1.32507845, grad/param norm = 6.4109e-02, time/batch = 0.0769s	
3104/5250 (epoch 29.562), train_loss = 1.32148521, grad/param norm = 6.1367e-02, time/batch = 0.0770s	
3105/5250 (epoch 29.571), train_loss = 1.32600870, grad/param norm = 5.9997e-02, time/batch = 0.0769s	
3106/5250 (epoch 29.581), train_loss = 1.35889481, grad/param norm = 6.0685e-02, time/batch = 0.0774s	
3107/5250 (epoch 29.590), train_loss = 1.33002017, grad/param norm = 5.7993e-02, time/batch = 0.0763s	
3108/5250 (epoch 29.600), train_loss = 1.34845657, grad/param norm = 5.6189e-02, time/batch = 0.0766s	
3109/5250 (epoch 29.610), train_loss = 1.33813159, grad/param norm = 5.7335e-02, time/batch = 0.0775s	
3110/5250 (epoch 29.619), train_loss = 1.32494104, grad/param norm = 5.7442e-02, time/batch = 0.0767s	
3111/5250 (epoch 29.629), train_loss = 1.33715528, grad/param norm = 5.5734e-02, time/batch = 0.0788s	
3112/5250 (epoch 29.638), train_loss = 1.31549523, grad/param norm = 5.3597e-02, time/batch = 0.0768s	
3113/5250 (epoch 29.648), train_loss = 1.32696414, grad/param norm = 5.9615e-02, time/batch = 0.0768s	
3114/5250 (epoch 29.657), train_loss = 1.32614640, grad/param norm = 5.8533e-02, time/batch = 0.0769s	
3115/5250 (epoch 29.667), train_loss = 1.33034221, grad/param norm = 6.0664e-02, time/batch = 0.0776s	
3116/5250 (epoch 29.676), train_loss = 1.33197997, grad/param norm = 6.7379e-02, time/batch = 0.0773s	
3117/5250 (epoch 29.686), train_loss = 1.35527044, grad/param norm = 6.0208e-02, time/batch = 0.0768s	
3118/5250 (epoch 29.695), train_loss = 1.33565105, grad/param norm = 6.6712e-02, time/batch = 0.0765s	
3119/5250 (epoch 29.705), train_loss = 1.31681040, grad/param norm = 5.5710e-02, time/batch = 0.0774s	
3120/5250 (epoch 29.714), train_loss = 1.35165732, grad/param norm = 5.4793e-02, time/batch = 0.0772s	
3121/5250 (epoch 29.724), train_loss = 1.33178184, grad/param norm = 5.4631e-02, time/batch = 0.0789s	
3122/5250 (epoch 29.733), train_loss = 1.31029793, grad/param norm = 5.5198e-02, time/batch = 0.0773s	
3123/5250 (epoch 29.743), train_loss = 1.31714298, grad/param norm = 6.3407e-02, time/batch = 0.0769s	
3124/5250 (epoch 29.752), train_loss = 1.32806098, grad/param norm = 6.4136e-02, time/batch = 0.0769s	
3125/5250 (epoch 29.762), train_loss = 1.31516370, grad/param norm = 6.1802e-02, time/batch = 0.0770s	
3126/5250 (epoch 29.771), train_loss = 1.30835690, grad/param norm = 5.5710e-02, time/batch = 0.0779s	
3127/5250 (epoch 29.781), train_loss = 1.33386332, grad/param norm = 5.9366e-02, time/batch = 0.0769s	
3128/5250 (epoch 29.790), train_loss = 1.34696794, grad/param norm = 5.8197e-02, time/batch = 0.0764s	
3129/5250 (epoch 29.800), train_loss = 1.32907160, grad/param norm = 5.6574e-02, time/batch = 0.0771s	
3130/5250 (epoch 29.810), train_loss = 1.33048822, grad/param norm = 5.5947e-02, time/batch = 0.0768s	
3131/5250 (epoch 29.819), train_loss = 1.33617530, grad/param norm = 5.7327e-02, time/batch = 0.0792s	
3132/5250 (epoch 29.829), train_loss = 1.33157269, grad/param norm = 6.0208e-02, time/batch = 0.0769s	
3133/5250 (epoch 29.838), train_loss = 1.31395140, grad/param norm = 5.3580e-02, time/batch = 0.0773s	
3134/5250 (epoch 29.848), train_loss = 1.31310443, grad/param norm = 6.1835e-02, time/batch = 0.0770s	
3135/5250 (epoch 29.857), train_loss = 1.32860916, grad/param norm = 5.6881e-02, time/batch = 0.0767s	
3136/5250 (epoch 29.867), train_loss = 1.32250996, grad/param norm = 5.3801e-02, time/batch = 0.0774s	
3137/5250 (epoch 29.876), train_loss = 1.33198834, grad/param norm = 5.6733e-02, time/batch = 0.0775s	
3138/5250 (epoch 29.886), train_loss = 1.31465905, grad/param norm = 5.6542e-02, time/batch = 0.0766s	
3139/5250 (epoch 29.895), train_loss = 1.35620169, grad/param norm = 5.9956e-02, time/batch = 0.0771s	
3140/5250 (epoch 29.905), train_loss = 1.34140299, grad/param norm = 5.5170e-02, time/batch = 0.0769s	
3141/5250 (epoch 29.914), train_loss = 1.35663945, grad/param norm = 6.1593e-02, time/batch = 0.0789s	
3142/5250 (epoch 29.924), train_loss = 1.35046689, grad/param norm = 5.7945e-02, time/batch = 0.0771s	
3143/5250 (epoch 29.933), train_loss = 1.31998802, grad/param norm = 4.9838e-02, time/batch = 0.0770s	
3144/5250 (epoch 29.943), train_loss = 1.35777241, grad/param norm = 5.4868e-02, time/batch = 0.0780s	
3145/5250 (epoch 29.952), train_loss = 1.35710753, grad/param norm = 5.6149e-02, time/batch = 0.0773s	
3146/5250 (epoch 29.962), train_loss = 1.33440089, grad/param norm = 5.2101e-02, time/batch = 0.0773s	
3147/5250 (epoch 29.971), train_loss = 1.32819820, grad/param norm = 5.9537e-02, time/batch = 0.0768s	
3148/5250 (epoch 29.981), train_loss = 1.35393471, grad/param norm = 5.7071e-02, time/batch = 0.0769s	
3149/5250 (epoch 29.990), train_loss = 1.35386763, grad/param norm = 5.7989e-02, time/batch = 0.0798s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
3150/5250 (epoch 30.000), train_loss = 1.33677791, grad/param norm = 6.1579e-02, time/batch = 0.0772s	
3151/5250 (epoch 30.010), train_loss = 1.52726518, grad/param norm = 7.0118e-02, time/batch = 0.0789s	
3152/5250 (epoch 30.019), train_loss = 1.32270172, grad/param norm = 7.2810e-02, time/batch = 0.0767s	
3153/5250 (epoch 30.029), train_loss = 1.33424195, grad/param norm = 6.4476e-02, time/batch = 0.0770s	
3154/5250 (epoch 30.038), train_loss = 1.32383682, grad/param norm = 6.5251e-02, time/batch = 0.0770s	
3155/5250 (epoch 30.048), train_loss = 1.30195091, grad/param norm = 5.9827e-02, time/batch = 0.0771s	
3156/5250 (epoch 30.057), train_loss = 1.31434975, grad/param norm = 5.3339e-02, time/batch = 0.0775s	
3157/5250 (epoch 30.067), train_loss = 1.32206105, grad/param norm = 5.3437e-02, time/batch = 0.0769s	
3158/5250 (epoch 30.076), train_loss = 1.32622359, grad/param norm = 5.9194e-02, time/batch = 0.0766s	
3159/5250 (epoch 30.086), train_loss = 1.27594482, grad/param norm = 6.1653e-02, time/batch = 0.0774s	
3160/5250 (epoch 30.095), train_loss = 1.30796118, grad/param norm = 5.8252e-02, time/batch = 0.0770s	
3161/5250 (epoch 30.105), train_loss = 1.32471696, grad/param norm = 5.7755e-02, time/batch = 0.0789s	
3162/5250 (epoch 30.114), train_loss = 1.30752664, grad/param norm = 6.0055e-02, time/batch = 0.0768s	
3163/5250 (epoch 30.124), train_loss = 1.32527213, grad/param norm = 6.0184e-02, time/batch = 0.0769s	
3164/5250 (epoch 30.133), train_loss = 1.31257598, grad/param norm = 5.7426e-02, time/batch = 0.0770s	
3165/5250 (epoch 30.143), train_loss = 1.29782188, grad/param norm = 5.9121e-02, time/batch = 0.0773s	
3166/5250 (epoch 30.152), train_loss = 1.29683471, grad/param norm = 5.4185e-02, time/batch = 0.0772s	
3167/5250 (epoch 30.162), train_loss = 1.32525890, grad/param norm = 5.4075e-02, time/batch = 0.0765s	
3168/5250 (epoch 30.171), train_loss = 1.32882434, grad/param norm = 5.1667e-02, time/batch = 0.0766s	
3169/5250 (epoch 30.181), train_loss = 1.33398271, grad/param norm = 5.6830e-02, time/batch = 0.0769s	
3170/5250 (epoch 30.190), train_loss = 1.32615605, grad/param norm = 5.2212e-02, time/batch = 0.0773s	
3171/5250 (epoch 30.200), train_loss = 1.31386529, grad/param norm = 5.6419e-02, time/batch = 0.0788s	
3172/5250 (epoch 30.210), train_loss = 1.31351928, grad/param norm = 5.5928e-02, time/batch = 0.0770s	
3173/5250 (epoch 30.219), train_loss = 1.36106290, grad/param norm = 5.8770e-02, time/batch = 0.0767s	
3174/5250 (epoch 30.229), train_loss = 1.31534637, grad/param norm = 5.2814e-02, time/batch = 0.0771s	
3175/5250 (epoch 30.238), train_loss = 1.31826310, grad/param norm = 5.5079e-02, time/batch = 0.0772s	
3176/5250 (epoch 30.248), train_loss = 1.32264116, grad/param norm = 5.5000e-02, time/batch = 0.0789s	
3177/5250 (epoch 30.257), train_loss = 1.31260767, grad/param norm = 5.1859e-02, time/batch = 0.0771s	
3178/5250 (epoch 30.267), train_loss = 1.30156394, grad/param norm = 5.2142e-02, time/batch = 0.0772s	
3179/5250 (epoch 30.276), train_loss = 1.30446503, grad/param norm = 5.1606e-02, time/batch = 0.0773s	
3180/5250 (epoch 30.286), train_loss = 1.28854444, grad/param norm = 5.4985e-02, time/batch = 0.0767s	
3181/5250 (epoch 30.295), train_loss = 1.31411075, grad/param norm = 5.4164e-02, time/batch = 0.0791s	
3182/5250 (epoch 30.305), train_loss = 1.30981152, grad/param norm = 5.7940e-02, time/batch = 0.0771s	
3183/5250 (epoch 30.314), train_loss = 1.29895266, grad/param norm = 5.1360e-02, time/batch = 0.0770s	
3184/5250 (epoch 30.324), train_loss = 1.31040286, grad/param norm = 5.3031e-02, time/batch = 0.0771s	
3185/5250 (epoch 30.333), train_loss = 1.31430494, grad/param norm = 5.3934e-02, time/batch = 0.0766s	
3186/5250 (epoch 30.343), train_loss = 1.31810114, grad/param norm = 5.4943e-02, time/batch = 0.0775s	
3187/5250 (epoch 30.352), train_loss = 1.32955156, grad/param norm = 5.8352e-02, time/batch = 0.0771s	
3188/5250 (epoch 30.362), train_loss = 1.32748745, grad/param norm = 5.9335e-02, time/batch = 0.0766s	
3189/5250 (epoch 30.371), train_loss = 1.30757664, grad/param norm = 5.5489e-02, time/batch = 0.0773s	
3190/5250 (epoch 30.381), train_loss = 1.30665226, grad/param norm = 5.6259e-02, time/batch = 0.0770s	
3191/5250 (epoch 30.390), train_loss = 1.31748843, grad/param norm = 6.2027e-02, time/batch = 0.0789s	
3192/5250 (epoch 30.400), train_loss = 1.32030188, grad/param norm = 5.7960e-02, time/batch = 0.0772s	
3193/5250 (epoch 30.410), train_loss = 1.32536077, grad/param norm = 5.4106e-02, time/batch = 0.0769s	
3194/5250 (epoch 30.419), train_loss = 1.31617108, grad/param norm = 5.6472e-02, time/batch = 0.0770s	
3195/5250 (epoch 30.429), train_loss = 1.32476182, grad/param norm = 5.3649e-02, time/batch = 0.0771s	
3196/5250 (epoch 30.438), train_loss = 1.34212875, grad/param norm = 5.8351e-02, time/batch = 0.0773s	
3197/5250 (epoch 30.448), train_loss = 1.30555378, grad/param norm = 6.1333e-02, time/batch = 0.0771s	
3198/5250 (epoch 30.457), train_loss = 1.30764923, grad/param norm = 6.4412e-02, time/batch = 0.0767s	
3199/5250 (epoch 30.467), train_loss = 1.31603794, grad/param norm = 5.5992e-02, time/batch = 0.0770s	
3200/5250 (epoch 30.476), train_loss = 1.31294559, grad/param norm = 5.6950e-02, time/batch = 0.0770s	
3201/5250 (epoch 30.486), train_loss = 1.33164773, grad/param norm = 5.9325e-02, time/batch = 0.0788s	
3202/5250 (epoch 30.495), train_loss = 1.33328135, grad/param norm = 5.4707e-02, time/batch = 0.0768s	
3203/5250 (epoch 30.505), train_loss = 1.34086642, grad/param norm = 5.9572e-02, time/batch = 0.0770s	
3204/5250 (epoch 30.514), train_loss = 1.33694767, grad/param norm = 6.7022e-02, time/batch = 0.0768s	
3205/5250 (epoch 30.524), train_loss = 1.30991483, grad/param norm = 5.4324e-02, time/batch = 0.0769s	
3206/5250 (epoch 30.533), train_loss = 1.31939049, grad/param norm = 5.6541e-02, time/batch = 0.0774s	
3207/5250 (epoch 30.543), train_loss = 1.30987105, grad/param norm = 5.7201e-02, time/batch = 0.0767s	
3208/5250 (epoch 30.552), train_loss = 1.31987351, grad/param norm = 6.2977e-02, time/batch = 0.0766s	
3209/5250 (epoch 30.562), train_loss = 1.31631959, grad/param norm = 6.0332e-02, time/batch = 0.0775s	
3210/5250 (epoch 30.571), train_loss = 1.32086204, grad/param norm = 5.8758e-02, time/batch = 0.0767s	
3211/5250 (epoch 30.581), train_loss = 1.35349387, grad/param norm = 6.0801e-02, time/batch = 0.0789s	
3212/5250 (epoch 30.590), train_loss = 1.32482041, grad/param norm = 5.9056e-02, time/batch = 0.0767s	
3213/5250 (epoch 30.600), train_loss = 1.34382900, grad/param norm = 5.6918e-02, time/batch = 0.0770s	
3214/5250 (epoch 30.610), train_loss = 1.33279202, grad/param norm = 5.6164e-02, time/batch = 0.0769s	
3215/5250 (epoch 30.619), train_loss = 1.31955412, grad/param norm = 5.4986e-02, time/batch = 0.0773s	
3216/5250 (epoch 30.629), train_loss = 1.33137578, grad/param norm = 5.3380e-02, time/batch = 0.0775s	
3217/5250 (epoch 30.638), train_loss = 1.30986351, grad/param norm = 5.0454e-02, time/batch = 0.0768s	
3218/5250 (epoch 30.648), train_loss = 1.32049395, grad/param norm = 5.3321e-02, time/batch = 0.0767s	
3219/5250 (epoch 30.657), train_loss = 1.32025409, grad/param norm = 5.3954e-02, time/batch = 0.0773s	
3220/5250 (epoch 30.667), train_loss = 1.32462223, grad/param norm = 5.6824e-02, time/batch = 0.0773s	
3221/5250 (epoch 30.676), train_loss = 1.32520050, grad/param norm = 6.2330e-02, time/batch = 0.0789s	
3222/5250 (epoch 30.686), train_loss = 1.34940161, grad/param norm = 5.6474e-02, time/batch = 0.0771s	
3223/5250 (epoch 30.695), train_loss = 1.33024463, grad/param norm = 6.4093e-02, time/batch = 0.0768s	
3224/5250 (epoch 30.705), train_loss = 1.31199674, grad/param norm = 5.5963e-02, time/batch = 0.0766s	
3225/5250 (epoch 30.714), train_loss = 1.34660143, grad/param norm = 5.4955e-02, time/batch = 0.0768s	
3226/5250 (epoch 30.724), train_loss = 1.32606868, grad/param norm = 5.3549e-02, time/batch = 0.0782s	
3227/5250 (epoch 30.733), train_loss = 1.30449377, grad/param norm = 5.2875e-02, time/batch = 0.0769s	
3228/5250 (epoch 30.743), train_loss = 1.30986063, grad/param norm = 5.3962e-02, time/batch = 0.0767s	
3229/5250 (epoch 30.752), train_loss = 1.32053302, grad/param norm = 5.4056e-02, time/batch = 0.0774s	
3230/5250 (epoch 30.762), train_loss = 1.30873784, grad/param norm = 5.4096e-02, time/batch = 0.0771s	
3231/5250 (epoch 30.771), train_loss = 1.30335432, grad/param norm = 5.4323e-02, time/batch = 0.0793s	
3232/5250 (epoch 30.781), train_loss = 1.33011617, grad/param norm = 6.2689e-02, time/batch = 0.0767s	
3233/5250 (epoch 30.790), train_loss = 1.34316916, grad/param norm = 6.2396e-02, time/batch = 0.0774s	
3234/5250 (epoch 30.800), train_loss = 1.32405355, grad/param norm = 5.6900e-02, time/batch = 0.0770s	
3235/5250 (epoch 30.810), train_loss = 1.32556180, grad/param norm = 5.6138e-02, time/batch = 0.0768s	
3236/5250 (epoch 30.819), train_loss = 1.33111593, grad/param norm = 5.6144e-02, time/batch = 0.0772s	
3237/5250 (epoch 30.829), train_loss = 1.32606243, grad/param norm = 5.6250e-02, time/batch = 0.0774s	
3238/5250 (epoch 30.838), train_loss = 1.30908250, grad/param norm = 5.3670e-02, time/batch = 0.0764s	
3239/5250 (epoch 30.848), train_loss = 1.30738452, grad/param norm = 5.5850e-02, time/batch = 0.0772s	
3240/5250 (epoch 30.857), train_loss = 1.32210856, grad/param norm = 5.4055e-02, time/batch = 0.0770s	
3241/5250 (epoch 30.867), train_loss = 1.31823561, grad/param norm = 5.6064e-02, time/batch = 0.0788s	
3242/5250 (epoch 30.876), train_loss = 1.32690480, grad/param norm = 5.7186e-02, time/batch = 0.0775s	
3243/5250 (epoch 30.886), train_loss = 1.31061955, grad/param norm = 6.0953e-02, time/batch = 0.0770s	
3244/5250 (epoch 30.895), train_loss = 1.35255076, grad/param norm = 6.5575e-02, time/batch = 0.0769s	
3245/5250 (epoch 30.905), train_loss = 1.33724059, grad/param norm = 5.6092e-02, time/batch = 0.0771s	
3246/5250 (epoch 30.914), train_loss = 1.35132175, grad/param norm = 5.7972e-02, time/batch = 0.0770s	
3247/5250 (epoch 30.924), train_loss = 1.34609970, grad/param norm = 6.1574e-02, time/batch = 0.0768s	
3248/5250 (epoch 30.933), train_loss = 1.31853787, grad/param norm = 6.6845e-02, time/batch = 0.0769s	
3249/5250 (epoch 30.943), train_loss = 1.35817400, grad/param norm = 7.6800e-02, time/batch = 0.0771s	
3250/5250 (epoch 30.952), train_loss = 1.35474370, grad/param norm = 6.6304e-02, time/batch = 0.0768s	
3251/5250 (epoch 30.962), train_loss = 1.33074351, grad/param norm = 5.9543e-02, time/batch = 0.0787s	
3252/5250 (epoch 30.971), train_loss = 1.32477704, grad/param norm = 6.6533e-02, time/batch = 0.0769s	
3253/5250 (epoch 30.981), train_loss = 1.34860977, grad/param norm = 5.6781e-02, time/batch = 0.0770s	
3254/5250 (epoch 30.990), train_loss = 1.34883041, grad/param norm = 5.3717e-02, time/batch = 0.0768s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
3255/5250 (epoch 31.000), train_loss = 1.33131353, grad/param norm = 5.6868e-02, time/batch = 0.0772s	
3256/5250 (epoch 31.010), train_loss = 1.52213119, grad/param norm = 6.4802e-02, time/batch = 0.0773s	
3257/5250 (epoch 31.019), train_loss = 1.31576389, grad/param norm = 6.6780e-02, time/batch = 0.0766s	
3258/5250 (epoch 31.029), train_loss = 1.32714485, grad/param norm = 5.5000e-02, time/batch = 0.0765s	
3259/5250 (epoch 31.038), train_loss = 1.31602090, grad/param norm = 5.5009e-02, time/batch = 0.0776s	
3260/5250 (epoch 31.048), train_loss = 1.29490524, grad/param norm = 5.2817e-02, time/batch = 0.0790s	
3261/5250 (epoch 31.057), train_loss = 1.30832365, grad/param norm = 4.9803e-02, time/batch = 0.0788s	
3262/5250 (epoch 31.067), train_loss = 1.31671746, grad/param norm = 5.0448e-02, time/batch = 0.0768s	
3263/5250 (epoch 31.076), train_loss = 1.32112915, grad/param norm = 5.6573e-02, time/batch = 0.0768s	
3264/5250 (epoch 31.086), train_loss = 1.27107291, grad/param norm = 5.9731e-02, time/batch = 0.0771s	
3265/5250 (epoch 31.095), train_loss = 1.30213778, grad/param norm = 5.6223e-02, time/batch = 0.0776s	
3266/5250 (epoch 31.105), train_loss = 1.31886691, grad/param norm = 5.4315e-02, time/batch = 0.0771s	
3267/5250 (epoch 31.114), train_loss = 1.30177561, grad/param norm = 5.7090e-02, time/batch = 0.0765s	
3268/5250 (epoch 31.124), train_loss = 1.32034327, grad/param norm = 5.8958e-02, time/batch = 0.0767s	
3269/5250 (epoch 31.133), train_loss = 1.30739275, grad/param norm = 5.6232e-02, time/batch = 0.0773s	
3270/5250 (epoch 31.143), train_loss = 1.29277440, grad/param norm = 5.7339e-02, time/batch = 0.0770s	
3271/5250 (epoch 31.152), train_loss = 1.29205822, grad/param norm = 5.3025e-02, time/batch = 0.0790s	
3272/5250 (epoch 31.162), train_loss = 1.32040247, grad/param norm = 5.3416e-02, time/batch = 0.0768s	
3273/5250 (epoch 31.171), train_loss = 1.32342653, grad/param norm = 5.0827e-02, time/batch = 0.0770s	
3274/5250 (epoch 31.181), train_loss = 1.32915869, grad/param norm = 5.6339e-02, time/batch = 0.0770s	
3275/5250 (epoch 31.190), train_loss = 1.32131106, grad/param norm = 5.1790e-02, time/batch = 0.0770s	
3276/5250 (epoch 31.200), train_loss = 1.30860057, grad/param norm = 5.5685e-02, time/batch = 0.0780s	
3277/5250 (epoch 31.210), train_loss = 1.30857234, grad/param norm = 5.5241e-02, time/batch = 0.0766s	
3278/5250 (epoch 31.219), train_loss = 1.35629590, grad/param norm = 5.8044e-02, time/batch = 0.0765s	
3279/5250 (epoch 31.229), train_loss = 1.31049388, grad/param norm = 5.2690e-02, time/batch = 0.0772s	
3280/5250 (epoch 31.238), train_loss = 1.31338124, grad/param norm = 5.4999e-02, time/batch = 0.0768s	
3281/5250 (epoch 31.248), train_loss = 1.31772937, grad/param norm = 5.4406e-02, time/batch = 0.0792s	
3282/5250 (epoch 31.257), train_loss = 1.30828043, grad/param norm = 5.1820e-02, time/batch = 0.0770s	
3283/5250 (epoch 31.267), train_loss = 1.29692719, grad/param norm = 5.3002e-02, time/batch = 0.0770s	
3284/5250 (epoch 31.276), train_loss = 1.29968652, grad/param norm = 5.2146e-02, time/batch = 0.0768s	
3285/5250 (epoch 31.286), train_loss = 1.28400449, grad/param norm = 5.4949e-02, time/batch = 0.0771s	
3286/5250 (epoch 31.295), train_loss = 1.30946904, grad/param norm = 5.3889e-02, time/batch = 0.0772s	
3287/5250 (epoch 31.305), train_loss = 1.30474152, grad/param norm = 5.7895e-02, time/batch = 0.0775s	
3288/5250 (epoch 31.314), train_loss = 1.29436181, grad/param norm = 5.1399e-02, time/batch = 0.0767s	
3289/5250 (epoch 31.324), train_loss = 1.30588555, grad/param norm = 5.2643e-02, time/batch = 0.0774s	
3290/5250 (epoch 31.333), train_loss = 1.30935078, grad/param norm = 5.3320e-02, time/batch = 0.0770s	
3291/5250 (epoch 31.343), train_loss = 1.31294596, grad/param norm = 5.4206e-02, time/batch = 0.0788s	
3292/5250 (epoch 31.352), train_loss = 1.32460063, grad/param norm = 5.7770e-02, time/batch = 0.0775s	
3293/5250 (epoch 31.362), train_loss = 1.32277501, grad/param norm = 5.8970e-02, time/batch = 0.0771s	
3294/5250 (epoch 31.371), train_loss = 1.30294944, grad/param norm = 5.4907e-02, time/batch = 0.0767s	
3295/5250 (epoch 31.381), train_loss = 1.30159615, grad/param norm = 5.5404e-02, time/batch = 0.0771s	
3296/5250 (epoch 31.390), train_loss = 1.31211858, grad/param norm = 6.0732e-02, time/batch = 0.0774s	
3297/5250 (epoch 31.400), train_loss = 1.31543404, grad/param norm = 5.6334e-02, time/batch = 0.0764s	
3298/5250 (epoch 31.410), train_loss = 1.32010027, grad/param norm = 5.2832e-02, time/batch = 0.0769s	
3299/5250 (epoch 31.419), train_loss = 1.31089368, grad/param norm = 5.5210e-02, time/batch = 0.0773s	
3300/5250 (epoch 31.429), train_loss = 1.31966502, grad/param norm = 5.2432e-02, time/batch = 0.0770s	
3301/5250 (epoch 31.438), train_loss = 1.33716571, grad/param norm = 5.7012e-02, time/batch = 0.0789s	
3302/5250 (epoch 31.448), train_loss = 1.30032017, grad/param norm = 5.9612e-02, time/batch = 0.0770s	
3303/5250 (epoch 31.457), train_loss = 1.30302067, grad/param norm = 6.4342e-02, time/batch = 0.0768s	
3304/5250 (epoch 31.467), train_loss = 1.31126696, grad/param norm = 5.6539e-02, time/batch = 0.0770s	
3305/5250 (epoch 31.476), train_loss = 1.30768044, grad/param norm = 5.6673e-02, time/batch = 0.0770s	
3306/5250 (epoch 31.486), train_loss = 1.32684828, grad/param norm = 5.9172e-02, time/batch = 0.0772s	
3307/5250 (epoch 31.495), train_loss = 1.32846329, grad/param norm = 5.4318e-02, time/batch = 0.0768s	
3308/5250 (epoch 31.505), train_loss = 1.33588025, grad/param norm = 5.9959e-02, time/batch = 0.0767s	
3309/5250 (epoch 31.514), train_loss = 1.33173681, grad/param norm = 6.7023e-02, time/batch = 0.0777s	
3310/5250 (epoch 31.524), train_loss = 1.30543314, grad/param norm = 5.5079e-02, time/batch = 0.0771s	
3311/5250 (epoch 31.533), train_loss = 1.31507989, grad/param norm = 5.6987e-02, time/batch = 0.0797s	
3312/5250 (epoch 31.543), train_loss = 1.30512342, grad/param norm = 5.7005e-02, time/batch = 0.0768s	
3313/5250 (epoch 31.552), train_loss = 1.31500667, grad/param norm = 6.2407e-02, time/batch = 0.0769s	
3314/5250 (epoch 31.562), train_loss = 1.31156452, grad/param norm = 5.9815e-02, time/batch = 0.0770s	
3315/5250 (epoch 31.571), train_loss = 1.31593457, grad/param norm = 5.8149e-02, time/batch = 0.0777s	
3316/5250 (epoch 31.581), train_loss = 1.34867754, grad/param norm = 6.1406e-02, time/batch = 0.0774s	
3317/5250 (epoch 31.590), train_loss = 1.32000792, grad/param norm = 6.0054e-02, time/batch = 0.0766s	
3318/5250 (epoch 31.600), train_loss = 1.33938743, grad/param norm = 5.7109e-02, time/batch = 0.0766s	
3319/5250 (epoch 31.610), train_loss = 1.32796324, grad/param norm = 5.5607e-02, time/batch = 0.0769s	
3320/5250 (epoch 31.619), train_loss = 1.31477547, grad/param norm = 5.4412e-02, time/batch = 0.0769s	
3321/5250 (epoch 31.629), train_loss = 1.32636455, grad/param norm = 5.3041e-02, time/batch = 0.0789s	
3322/5250 (epoch 31.638), train_loss = 1.30505978, grad/param norm = 4.9881e-02, time/batch = 0.0771s	
3323/5250 (epoch 31.648), train_loss = 1.31547135, grad/param norm = 5.2098e-02, time/batch = 0.0770s	
3324/5250 (epoch 31.657), train_loss = 1.31535393, grad/param norm = 5.3132e-02, time/batch = 0.0771s	
3325/5250 (epoch 31.667), train_loss = 1.31985343, grad/param norm = 5.5947e-02, time/batch = 0.0767s	
3326/5250 (epoch 31.676), train_loss = 1.31954395, grad/param norm = 6.0562e-02, time/batch = 0.0779s	
3327/5250 (epoch 31.686), train_loss = 1.34427991, grad/param norm = 5.4431e-02, time/batch = 0.0769s	
3328/5250 (epoch 31.695), train_loss = 1.32501158, grad/param norm = 6.1601e-02, time/batch = 0.0766s	
3329/5250 (epoch 31.705), train_loss = 1.30715186, grad/param norm = 5.5370e-02, time/batch = 0.0769s	
3330/5250 (epoch 31.714), train_loss = 1.34187293, grad/param norm = 5.5868e-02, time/batch = 0.0769s	
3331/5250 (epoch 31.724), train_loss = 1.32102137, grad/param norm = 5.3768e-02, time/batch = 0.0789s	
3332/5250 (epoch 31.733), train_loss = 1.29946673, grad/param norm = 5.2561e-02, time/batch = 0.0769s	
3333/5250 (epoch 31.743), train_loss = 1.30498255, grad/param norm = 5.3778e-02, time/batch = 0.0771s	
3334/5250 (epoch 31.752), train_loss = 1.31555421, grad/param norm = 5.4449e-02, time/batch = 0.0770s	
3335/5250 (epoch 31.762), train_loss = 1.30393598, grad/param norm = 5.4190e-02, time/batch = 0.0768s	
3336/5250 (epoch 31.771), train_loss = 1.29866155, grad/param norm = 5.4746e-02, time/batch = 0.0777s	
3337/5250 (epoch 31.781), train_loss = 1.32563631, grad/param norm = 6.1568e-02, time/batch = 0.0769s	
3338/5250 (epoch 31.790), train_loss = 1.33792195, grad/param norm = 6.0281e-02, time/batch = 0.0770s	
3339/5250 (epoch 31.800), train_loss = 1.31847069, grad/param norm = 5.5331e-02, time/batch = 0.0772s	
3340/5250 (epoch 31.810), train_loss = 1.32022359, grad/param norm = 5.4088e-02, time/batch = 0.0766s	
3341/5250 (epoch 31.819), train_loss = 1.32608785, grad/param norm = 5.4643e-02, time/batch = 0.0789s	
3342/5250 (epoch 31.829), train_loss = 1.32114541, grad/param norm = 5.4707e-02, time/batch = 0.0773s	
3343/5250 (epoch 31.838), train_loss = 1.30449301, grad/param norm = 5.1981e-02, time/batch = 0.0769s	
3344/5250 (epoch 31.848), train_loss = 1.30310864, grad/param norm = 5.5078e-02, time/batch = 0.0769s	
3345/5250 (epoch 31.857), train_loss = 1.31748980, grad/param norm = 5.3108e-02, time/batch = 0.0770s	
3346/5250 (epoch 31.867), train_loss = 1.31395897, grad/param norm = 5.5865e-02, time/batch = 0.0774s	
3347/5250 (epoch 31.876), train_loss = 1.32192496, grad/param norm = 5.7864e-02, time/batch = 0.0768s	
3348/5250 (epoch 31.886), train_loss = 1.30563457, grad/param norm = 5.8241e-02, time/batch = 0.0773s	
3349/5250 (epoch 31.895), train_loss = 1.34717602, grad/param norm = 6.1547e-02, time/batch = 0.0774s	
3350/5250 (epoch 31.905), train_loss = 1.33190181, grad/param norm = 5.3520e-02, time/batch = 0.0771s	
3351/5250 (epoch 31.914), train_loss = 1.34651283, grad/param norm = 5.6577e-02, time/batch = 0.0789s	
3352/5250 (epoch 31.924), train_loss = 1.34001829, grad/param norm = 5.7522e-02, time/batch = 0.0769s	
3353/5250 (epoch 31.933), train_loss = 1.31179649, grad/param norm = 5.8128e-02, time/batch = 0.0769s	
3354/5250 (epoch 31.943), train_loss = 1.35134829, grad/param norm = 6.8909e-02, time/batch = 0.0770s	
3355/5250 (epoch 31.952), train_loss = 1.34925021, grad/param norm = 6.3799e-02, time/batch = 0.0768s	
3356/5250 (epoch 31.962), train_loss = 1.32605699, grad/param norm = 5.9263e-02, time/batch = 0.0771s	
3357/5250 (epoch 31.971), train_loss = 1.32064976, grad/param norm = 6.7176e-02, time/batch = 0.0765s	
3358/5250 (epoch 31.981), train_loss = 1.34343662, grad/param norm = 5.5745e-02, time/batch = 0.0766s	
3359/5250 (epoch 31.990), train_loss = 1.34407415, grad/param norm = 5.3700e-02, time/batch = 0.0776s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
3360/5250 (epoch 32.000), train_loss = 1.32712673, grad/param norm = 5.6294e-02, time/batch = 0.0774s	
3361/5250 (epoch 32.010), train_loss = 1.51836648, grad/param norm = 6.3438e-02, time/batch = 0.0790s	
3362/5250 (epoch 32.019), train_loss = 1.31074337, grad/param norm = 6.5421e-02, time/batch = 0.0769s	
3363/5250 (epoch 32.029), train_loss = 1.32247226, grad/param norm = 5.4105e-02, time/batch = 0.0769s	
3364/5250 (epoch 32.038), train_loss = 1.31137680, grad/param norm = 5.4871e-02, time/batch = 0.0769s	
3365/5250 (epoch 32.048), train_loss = 1.29020376, grad/param norm = 5.2892e-02, time/batch = 0.0775s	
3366/5250 (epoch 32.057), train_loss = 1.30380906, grad/param norm = 5.0057e-02, time/batch = 0.0770s	
3367/5250 (epoch 32.067), train_loss = 1.31235557, grad/param norm = 5.0106e-02, time/batch = 0.0768s	
3368/5250 (epoch 32.076), train_loss = 1.31675034, grad/param norm = 5.6878e-02, time/batch = 0.0764s	
3369/5250 (epoch 32.086), train_loss = 1.26709853, grad/param norm = 6.0265e-02, time/batch = 0.0773s	
3370/5250 (epoch 32.095), train_loss = 1.29714805, grad/param norm = 5.5201e-02, time/batch = 0.0769s	
3371/5250 (epoch 32.105), train_loss = 1.31419186, grad/param norm = 5.3626e-02, time/batch = 0.0839s	
3372/5250 (epoch 32.114), train_loss = 1.29699749, grad/param norm = 5.6823e-02, time/batch = 0.0779s	
3373/5250 (epoch 32.124), train_loss = 1.31631031, grad/param norm = 5.9881e-02, time/batch = 0.0772s	
3374/5250 (epoch 32.133), train_loss = 1.30305698, grad/param norm = 5.7101e-02, time/batch = 0.0772s	
3375/5250 (epoch 32.143), train_loss = 1.28839785, grad/param norm = 5.7130e-02, time/batch = 0.0771s	
3376/5250 (epoch 32.152), train_loss = 1.28810872, grad/param norm = 5.4133e-02, time/batch = 0.0777s	
3377/5250 (epoch 32.162), train_loss = 1.31620440, grad/param norm = 5.4953e-02, time/batch = 0.0765s	
3378/5250 (epoch 32.171), train_loss = 1.31870335, grad/param norm = 5.1341e-02, time/batch = 0.0767s	
3379/5250 (epoch 32.181), train_loss = 1.32482915, grad/param norm = 5.6573e-02, time/batch = 0.0771s	
3380/5250 (epoch 32.190), train_loss = 1.31668814, grad/param norm = 5.1214e-02, time/batch = 0.0767s	
3381/5250 (epoch 32.200), train_loss = 1.30371764, grad/param norm = 5.5119e-02, time/batch = 0.0792s	
3382/5250 (epoch 32.210), train_loss = 1.30394846, grad/param norm = 5.4244e-02, time/batch = 0.0772s	
3383/5250 (epoch 32.219), train_loss = 1.35148866, grad/param norm = 5.6749e-02, time/batch = 0.0770s	
3384/5250 (epoch 32.229), train_loss = 1.30563464, grad/param norm = 5.1553e-02, time/batch = 0.0769s	
3385/5250 (epoch 32.238), train_loss = 1.30872257, grad/param norm = 5.4241e-02, time/batch = 0.0771s	
3386/5250 (epoch 32.248), train_loss = 1.31319279, grad/param norm = 5.3988e-02, time/batch = 0.0771s	
3387/5250 (epoch 32.257), train_loss = 1.30399215, grad/param norm = 5.1180e-02, time/batch = 0.0771s	
3388/5250 (epoch 32.267), train_loss = 1.29250647, grad/param norm = 5.3437e-02, time/batch = 0.0767s	
3389/5250 (epoch 32.276), train_loss = 1.29500542, grad/param norm = 5.1749e-02, time/batch = 0.0774s	
3390/5250 (epoch 32.286), train_loss = 1.27961497, grad/param norm = 5.4352e-02, time/batch = 0.0768s	
3391/5250 (epoch 32.295), train_loss = 1.30499909, grad/param norm = 5.2826e-02, time/batch = 0.0788s	
3392/5250 (epoch 32.305), train_loss = 1.29962295, grad/param norm = 5.6726e-02, time/batch = 0.0774s	
3393/5250 (epoch 32.314), train_loss = 1.28993848, grad/param norm = 5.1339e-02, time/batch = 0.0770s	
3394/5250 (epoch 32.324), train_loss = 1.30159410, grad/param norm = 5.2438e-02, time/batch = 0.0769s	
3395/5250 (epoch 32.333), train_loss = 1.30472880, grad/param norm = 5.2677e-02, time/batch = 0.0768s	
3396/5250 (epoch 32.343), train_loss = 1.30808120, grad/param norm = 5.3454e-02, time/batch = 0.0772s	
3397/5250 (epoch 32.352), train_loss = 1.32000601, grad/param norm = 5.7430e-02, time/batch = 0.0764s	
3398/5250 (epoch 32.362), train_loss = 1.31837830, grad/param norm = 5.8887e-02, time/batch = 0.0771s	
3399/5250 (epoch 32.371), train_loss = 1.29847275, grad/param norm = 5.3985e-02, time/batch = 0.0775s	
3400/5250 (epoch 32.381), train_loss = 1.29676767, grad/param norm = 5.4480e-02, time/batch = 0.0772s	
3401/5250 (epoch 32.390), train_loss = 1.30710586, grad/param norm = 5.9852e-02, time/batch = 0.0791s	
3402/5250 (epoch 32.400), train_loss = 1.31097869, grad/param norm = 5.5500e-02, time/batch = 0.0767s	
3403/5250 (epoch 32.410), train_loss = 1.31538609, grad/param norm = 5.2719e-02, time/batch = 0.0769s	
3404/5250 (epoch 32.419), train_loss = 1.30626555, grad/param norm = 5.5172e-02, time/batch = 0.0768s	
3405/5250 (epoch 32.429), train_loss = 1.31506681, grad/param norm = 5.1917e-02, time/batch = 0.0771s	
3406/5250 (epoch 32.438), train_loss = 1.33259393, grad/param norm = 5.5873e-02, time/batch = 0.0775s	
3407/5250 (epoch 32.448), train_loss = 1.29523034, grad/param norm = 5.6965e-02, time/batch = 0.0768s	
3408/5250 (epoch 32.457), train_loss = 1.29803438, grad/param norm = 6.0846e-02, time/batch = 0.0766s	
3409/5250 (epoch 32.467), train_loss = 1.30629516, grad/param norm = 5.5214e-02, time/batch = 0.0778s	
3410/5250 (epoch 32.476), train_loss = 1.30232406, grad/param norm = 5.5312e-02, time/batch = 0.0772s	
3411/5250 (epoch 32.486), train_loss = 1.32230097, grad/param norm = 5.8427e-02, time/batch = 0.0790s	
3412/5250 (epoch 32.495), train_loss = 1.32384696, grad/param norm = 5.3982e-02, time/batch = 0.0792s	
3413/5250 (epoch 32.505), train_loss = 1.33111519, grad/param norm = 6.0075e-02, time/batch = 0.0773s	
3414/5250 (epoch 32.514), train_loss = 1.32685255, grad/param norm = 6.7166e-02, time/batch = 0.0769s	
3415/5250 (epoch 32.524), train_loss = 1.30110434, grad/param norm = 5.4860e-02, time/batch = 0.0775s	
3416/5250 (epoch 32.533), train_loss = 1.31109051, grad/param norm = 5.7451e-02, time/batch = 0.0775s	
3417/5250 (epoch 32.543), train_loss = 1.30070854, grad/param norm = 5.7009e-02, time/batch = 0.0765s	
3418/5250 (epoch 32.552), train_loss = 1.31018818, grad/param norm = 6.1200e-02, time/batch = 0.0765s	
3419/5250 (epoch 32.562), train_loss = 1.30662883, grad/param norm = 5.7667e-02, time/batch = 0.0771s	
3420/5250 (epoch 32.571), train_loss = 1.31105255, grad/param norm = 5.6474e-02, time/batch = 0.0769s	
3421/5250 (epoch 32.581), train_loss = 1.34364002, grad/param norm = 5.9553e-02, time/batch = 0.0788s	
3422/5250 (epoch 32.590), train_loss = 1.31469146, grad/param norm = 5.7662e-02, time/batch = 0.0770s	
3423/5250 (epoch 32.600), train_loss = 1.33491241, grad/param norm = 5.5287e-02, time/batch = 0.0771s	
3424/5250 (epoch 32.610), train_loss = 1.32352809, grad/param norm = 5.5913e-02, time/batch = 0.0770s	
3425/5250 (epoch 32.619), train_loss = 1.31087303, grad/param norm = 5.6075e-02, time/batch = 0.0771s	
3426/5250 (epoch 32.629), train_loss = 1.32200391, grad/param norm = 5.4260e-02, time/batch = 0.0780s	
3427/5250 (epoch 32.638), train_loss = 1.30099808, grad/param norm = 5.1283e-02, time/batch = 0.0769s	
3428/5250 (epoch 32.648), train_loss = 1.31164878, grad/param norm = 5.5773e-02, time/batch = 0.0770s	
3429/5250 (epoch 32.657), train_loss = 1.31140233, grad/param norm = 5.4932e-02, time/batch = 0.0769s	
3430/5250 (epoch 32.667), train_loss = 1.31584660, grad/param norm = 5.6804e-02, time/batch = 0.0770s	
3431/5250 (epoch 32.676), train_loss = 1.31516747, grad/param norm = 6.1322e-02, time/batch = 0.0791s	
3432/5250 (epoch 32.686), train_loss = 1.33969407, grad/param norm = 5.3632e-02, time/batch = 0.0768s	
3433/5250 (epoch 32.695), train_loss = 1.32013146, grad/param norm = 6.0378e-02, time/batch = 0.0770s	
3434/5250 (epoch 32.705), train_loss = 1.30205570, grad/param norm = 5.2973e-02, time/batch = 0.0769s	
3435/5250 (epoch 32.714), train_loss = 1.33711533, grad/param norm = 5.4917e-02, time/batch = 0.0772s	
3436/5250 (epoch 32.724), train_loss = 1.31604263, grad/param norm = 5.2375e-02, time/batch = 0.0771s	
3437/5250 (epoch 32.733), train_loss = 1.29481762, grad/param norm = 5.2077e-02, time/batch = 0.0770s	
3438/5250 (epoch 32.743), train_loss = 1.30190787, grad/param norm = 6.0491e-02, time/batch = 0.0765s	
3439/5250 (epoch 32.752), train_loss = 1.31262521, grad/param norm = 6.3485e-02, time/batch = 0.0773s	
3440/5250 (epoch 32.762), train_loss = 1.30022617, grad/param norm = 5.8534e-02, time/batch = 0.0767s	
3441/5250 (epoch 32.771), train_loss = 1.29383922, grad/param norm = 5.4019e-02, time/batch = 0.0787s	
3442/5250 (epoch 32.781), train_loss = 1.32046396, grad/param norm = 5.9937e-02, time/batch = 0.0771s	
3443/5250 (epoch 32.790), train_loss = 1.33238937, grad/param norm = 5.5989e-02, time/batch = 0.0770s	
3444/5250 (epoch 32.800), train_loss = 1.31351439, grad/param norm = 5.4307e-02, time/batch = 0.0769s	
3445/5250 (epoch 32.810), train_loss = 1.31534062, grad/param norm = 5.3773e-02, time/batch = 0.0771s	
3446/5250 (epoch 32.819), train_loss = 1.32182627, grad/param norm = 5.5039e-02, time/batch = 0.0770s	
3447/5250 (epoch 32.829), train_loss = 1.31723968, grad/param norm = 5.6414e-02, time/batch = 0.0766s	
3448/5250 (epoch 32.838), train_loss = 1.29999871, grad/param norm = 5.1060e-02, time/batch = 0.0769s	
3449/5250 (epoch 32.848), train_loss = 1.29838431, grad/param norm = 5.4392e-02, time/batch = 0.0775s	
3450/5250 (epoch 32.857), train_loss = 1.31298965, grad/param norm = 5.3059e-02, time/batch = 0.0768s	
3451/5250 (epoch 32.867), train_loss = 1.30862784, grad/param norm = 5.2510e-02, time/batch = 0.0788s	
3452/5250 (epoch 32.876), train_loss = 1.31564900, grad/param norm = 5.2968e-02, time/batch = 0.0768s	
3453/5250 (epoch 32.886), train_loss = 1.29954088, grad/param norm = 5.3000e-02, time/batch = 0.0769s	
3454/5250 (epoch 32.895), train_loss = 1.34245440, grad/param norm = 6.2410e-02, time/batch = 0.0768s	
3455/5250 (epoch 32.905), train_loss = 1.32945372, grad/param norm = 6.5999e-02, time/batch = 0.0769s	
3456/5250 (epoch 32.914), train_loss = 1.34599955, grad/param norm = 6.7732e-02, time/batch = 0.0775s	
3457/5250 (epoch 32.924), train_loss = 1.33560674, grad/param norm = 5.6340e-02, time/batch = 0.0768s	
3458/5250 (epoch 32.933), train_loss = 1.30514240, grad/param norm = 4.9148e-02, time/batch = 0.0767s	
3459/5250 (epoch 32.943), train_loss = 1.34311659, grad/param norm = 5.2860e-02, time/batch = 0.0777s	
3460/5250 (epoch 32.952), train_loss = 1.34191558, grad/param norm = 5.3408e-02, time/batch = 0.0769s	
3461/5250 (epoch 32.962), train_loss = 1.31923841, grad/param norm = 4.9704e-02, time/batch = 0.0787s	
3462/5250 (epoch 32.971), train_loss = 1.31394606, grad/param norm = 5.5606e-02, time/batch = 0.0768s	
3463/5250 (epoch 32.981), train_loss = 1.33916250, grad/param norm = 5.8432e-02, time/batch = 0.0769s	
3464/5250 (epoch 32.990), train_loss = 1.34178700, grad/param norm = 6.8859e-02, time/batch = 0.0768s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
3465/5250 (epoch 33.000), train_loss = 1.32599571, grad/param norm = 6.8966e-02, time/batch = 0.0775s	
3466/5250 (epoch 33.010), train_loss = 1.51714835, grad/param norm = 7.3784e-02, time/batch = 0.0772s	
3467/5250 (epoch 33.019), train_loss = 1.30685913, grad/param norm = 6.9668e-02, time/batch = 0.0768s	
3468/5250 (epoch 33.029), train_loss = 1.31909074, grad/param norm = 5.8864e-02, time/batch = 0.0771s	
3469/5250 (epoch 33.038), train_loss = 1.30793863, grad/param norm = 5.7721e-02, time/batch = 0.0771s	
3470/5250 (epoch 33.048), train_loss = 1.28596164, grad/param norm = 5.3271e-02, time/batch = 0.0770s	
3471/5250 (epoch 33.057), train_loss = 1.29944329, grad/param norm = 5.0926e-02, time/batch = 0.0790s	
3472/5250 (epoch 33.067), train_loss = 1.30831321, grad/param norm = 5.0724e-02, time/batch = 0.0768s	
3473/5250 (epoch 33.076), train_loss = 1.31266646, grad/param norm = 5.7335e-02, time/batch = 0.0767s	
3474/5250 (epoch 33.086), train_loss = 1.26303664, grad/param norm = 6.0056e-02, time/batch = 0.0768s	
3475/5250 (epoch 33.095), train_loss = 1.29201109, grad/param norm = 5.3737e-02, time/batch = 0.0770s	
3476/5250 (epoch 33.105), train_loss = 1.30977421, grad/param norm = 5.3806e-02, time/batch = 0.0777s	
3477/5250 (epoch 33.114), train_loss = 1.29253966, grad/param norm = 5.6662e-02, time/batch = 0.0768s	
3478/5250 (epoch 33.124), train_loss = 1.31201190, grad/param norm = 5.8892e-02, time/batch = 0.0764s	
3479/5250 (epoch 33.133), train_loss = 1.29833441, grad/param norm = 5.5217e-02, time/batch = 0.0772s	
3480/5250 (epoch 33.143), train_loss = 1.28366063, grad/param norm = 5.4380e-02, time/batch = 0.0769s	
3481/5250 (epoch 33.152), train_loss = 1.28358727, grad/param norm = 5.2651e-02, time/batch = 0.0792s	
3482/5250 (epoch 33.162), train_loss = 1.31172160, grad/param norm = 5.3445e-02, time/batch = 0.0792s	
3483/5250 (epoch 33.171), train_loss = 1.31376255, grad/param norm = 5.0074e-02, time/batch = 0.0792s	
3484/5250 (epoch 33.181), train_loss = 1.32031682, grad/param norm = 5.5812e-02, time/batch = 0.0774s	
3485/5250 (epoch 33.190), train_loss = 1.31258324, grad/param norm = 5.1916e-02, time/batch = 0.0771s	
3486/5250 (epoch 33.200), train_loss = 1.29922908, grad/param norm = 5.5445e-02, time/batch = 0.0774s	
3487/5250 (epoch 33.210), train_loss = 1.29967360, grad/param norm = 5.3635e-02, time/batch = 0.0772s	
3488/5250 (epoch 33.219), train_loss = 1.34690043, grad/param norm = 5.5578e-02, time/batch = 0.0767s	
3489/5250 (epoch 33.229), train_loss = 1.30105031, grad/param norm = 5.0744e-02, time/batch = 0.0771s	
3490/5250 (epoch 33.238), train_loss = 1.30429917, grad/param norm = 5.3590e-02, time/batch = 0.0769s	
3491/5250 (epoch 33.248), train_loss = 1.30890887, grad/param norm = 5.3348e-02, time/batch = 0.0788s	
3492/5250 (epoch 33.257), train_loss = 1.29985784, grad/param norm = 5.0957e-02, time/batch = 0.0773s	
3493/5250 (epoch 33.267), train_loss = 1.28835765, grad/param norm = 5.3636e-02, time/batch = 0.0770s	
3494/5250 (epoch 33.276), train_loss = 1.29042132, grad/param norm = 5.0752e-02, time/batch = 0.0769s	
3495/5250 (epoch 33.286), train_loss = 1.27529212, grad/param norm = 5.3650e-02, time/batch = 0.0767s	
3496/5250 (epoch 33.295), train_loss = 1.30076525, grad/param norm = 5.2238e-02, time/batch = 0.0774s	
3497/5250 (epoch 33.305), train_loss = 1.29497991, grad/param norm = 5.5974e-02, time/batch = 0.0766s	
3498/5250 (epoch 33.314), train_loss = 1.28585954, grad/param norm = 5.1472e-02, time/batch = 0.0769s	
3499/5250 (epoch 33.324), train_loss = 1.29750337, grad/param norm = 5.2587e-02, time/batch = 0.0773s	
3500/5250 (epoch 33.333), train_loss = 1.30039565, grad/param norm = 5.2327e-02, time/batch = 0.0768s	
3501/5250 (epoch 33.343), train_loss = 1.30349197, grad/param norm = 5.2620e-02, time/batch = 0.0789s	
3502/5250 (epoch 33.352), train_loss = 1.31546338, grad/param norm = 5.6366e-02, time/batch = 0.0768s	
3503/5250 (epoch 33.362), train_loss = 1.31387867, grad/param norm = 5.7709e-02, time/batch = 0.0769s	
3504/5250 (epoch 33.371), train_loss = 1.29404696, grad/param norm = 5.2850e-02, time/batch = 0.0768s	
3505/5250 (epoch 33.381), train_loss = 1.29212210, grad/param norm = 5.3422e-02, time/batch = 0.0768s	
3506/5250 (epoch 33.390), train_loss = 1.30240840, grad/param norm = 5.9150e-02, time/batch = 0.0773s	
3507/5250 (epoch 33.400), train_loss = 1.30677166, grad/param norm = 5.5440e-02, time/batch = 0.0768s	
3508/5250 (epoch 33.410), train_loss = 1.31099245, grad/param norm = 5.3758e-02, time/batch = 0.0765s	
3509/5250 (epoch 33.419), train_loss = 1.30215155, grad/param norm = 5.5903e-02, time/batch = 0.0778s	
3510/5250 (epoch 33.429), train_loss = 1.31081466, grad/param norm = 5.1818e-02, time/batch = 0.0769s	
3511/5250 (epoch 33.438), train_loss = 1.32856112, grad/param norm = 5.5641e-02, time/batch = 0.0790s	
3512/5250 (epoch 33.448), train_loss = 1.29071271, grad/param norm = 5.5614e-02, time/batch = 0.0771s	
3513/5250 (epoch 33.457), train_loss = 1.29344084, grad/param norm = 5.8520e-02, time/batch = 0.0771s	
3514/5250 (epoch 33.467), train_loss = 1.30159560, grad/param norm = 5.3237e-02, time/batch = 0.0768s	
3515/5250 (epoch 33.476), train_loss = 1.29746241, grad/param norm = 5.4274e-02, time/batch = 0.0774s	
3516/5250 (epoch 33.486), train_loss = 1.31804508, grad/param norm = 5.7792e-02, time/batch = 0.0773s	
3517/5250 (epoch 33.495), train_loss = 1.31928160, grad/param norm = 5.3238e-02, time/batch = 0.0768s	
3518/5250 (epoch 33.505), train_loss = 1.32645972, grad/param norm = 5.9018e-02, time/batch = 0.0765s	
3519/5250 (epoch 33.514), train_loss = 1.32180089, grad/param norm = 6.4351e-02, time/batch = 0.0771s	
3520/5250 (epoch 33.524), train_loss = 1.29649705, grad/param norm = 5.3599e-02, time/batch = 0.0771s	
3521/5250 (epoch 33.533), train_loss = 1.30691321, grad/param norm = 5.7639e-02, time/batch = 0.0794s	
3522/5250 (epoch 33.543), train_loss = 1.29653858, grad/param norm = 5.6979e-02, time/batch = 0.0770s	
3523/5250 (epoch 33.552), train_loss = 1.30540311, grad/param norm = 5.9887e-02, time/batch = 0.0772s	
3524/5250 (epoch 33.562), train_loss = 1.30190754, grad/param norm = 5.5736e-02, time/batch = 0.0769s	
3525/5250 (epoch 33.571), train_loss = 1.30657380, grad/param norm = 5.5221e-02, time/batch = 0.0772s	
3526/5250 (epoch 33.581), train_loss = 1.33891807, grad/param norm = 5.7946e-02, time/batch = 0.0780s	
3527/5250 (epoch 33.590), train_loss = 1.30970754, grad/param norm = 5.5704e-02, time/batch = 0.0768s	
3528/5250 (epoch 33.600), train_loss = 1.33084643, grad/param norm = 5.4330e-02, time/batch = 0.0768s	
3529/5250 (epoch 33.610), train_loss = 1.31947435, grad/param norm = 5.7427e-02, time/batch = 0.0772s	
3530/5250 (epoch 33.619), train_loss = 1.30747158, grad/param norm = 5.8932e-02, time/batch = 0.0767s	
3531/5250 (epoch 33.629), train_loss = 1.31813163, grad/param norm = 5.6308e-02, time/batch = 0.0790s	
3532/5250 (epoch 33.638), train_loss = 1.29737121, grad/param norm = 5.3197e-02, time/batch = 0.0771s	
3533/5250 (epoch 33.648), train_loss = 1.30787550, grad/param norm = 5.8207e-02, time/batch = 0.0769s	
3534/5250 (epoch 33.657), train_loss = 1.30745802, grad/param norm = 5.5498e-02, time/batch = 0.0771s	
3535/5250 (epoch 33.667), train_loss = 1.31187714, grad/param norm = 5.6784e-02, time/batch = 0.0771s	
3536/5250 (epoch 33.676), train_loss = 1.31050159, grad/param norm = 6.0713e-02, time/batch = 0.0772s	
3537/5250 (epoch 33.686), train_loss = 1.33528276, grad/param norm = 5.2597e-02, time/batch = 0.0772s	
3538/5250 (epoch 33.695), train_loss = 1.31551434, grad/param norm = 5.8944e-02, time/batch = 0.0764s	
3539/5250 (epoch 33.705), train_loss = 1.29775957, grad/param norm = 5.2619e-02, time/batch = 0.0769s	
3540/5250 (epoch 33.714), train_loss = 1.33275198, grad/param norm = 5.5358e-02, time/batch = 0.0766s	
3541/5250 (epoch 33.724), train_loss = 1.31148423, grad/param norm = 5.1890e-02, time/batch = 0.0787s	
3542/5250 (epoch 33.733), train_loss = 1.29030723, grad/param norm = 5.1271e-02, time/batch = 0.0773s	
3543/5250 (epoch 33.743), train_loss = 1.29726951, grad/param norm = 5.8477e-02, time/batch = 0.0771s	
3544/5250 (epoch 33.752), train_loss = 1.30745110, grad/param norm = 6.0232e-02, time/batch = 0.0769s	
3545/5250 (epoch 33.762), train_loss = 1.29531668, grad/param norm = 5.4981e-02, time/batch = 0.0770s	
3546/5250 (epoch 33.771), train_loss = 1.28941430, grad/param norm = 5.3394e-02, time/batch = 0.0773s	
3547/5250 (epoch 33.781), train_loss = 1.31654475, grad/param norm = 6.1392e-02, time/batch = 0.0768s	
3548/5250 (epoch 33.790), train_loss = 1.32820028, grad/param norm = 5.6239e-02, time/batch = 0.0770s	
3549/5250 (epoch 33.800), train_loss = 1.30906541, grad/param norm = 5.3458e-02, time/batch = 0.0772s	
3550/5250 (epoch 33.810), train_loss = 1.31093156, grad/param norm = 5.3262e-02, time/batch = 0.0767s	
3551/5250 (epoch 33.819), train_loss = 1.31727881, grad/param norm = 5.3670e-02, time/batch = 0.0786s	
3552/5250 (epoch 33.829), train_loss = 1.31273651, grad/param norm = 5.4048e-02, time/batch = 0.0768s	
3553/5250 (epoch 33.838), train_loss = 1.29575098, grad/param norm = 5.0091e-02, time/batch = 0.0769s	
3554/5250 (epoch 33.848), train_loss = 1.29403862, grad/param norm = 5.3026e-02, time/batch = 0.0774s	
3555/5250 (epoch 33.857), train_loss = 1.30855333, grad/param norm = 5.1387e-02, time/batch = 0.0770s	
3556/5250 (epoch 33.867), train_loss = 1.30481749, grad/param norm = 5.2396e-02, time/batch = 0.0772s	
3557/5250 (epoch 33.876), train_loss = 1.31102857, grad/param norm = 5.2460e-02, time/batch = 0.0768s	
3558/5250 (epoch 33.886), train_loss = 1.29527886, grad/param norm = 5.1841e-02, time/batch = 0.0769s	
3559/5250 (epoch 33.895), train_loss = 1.33759508, grad/param norm = 5.8427e-02, time/batch = 0.0775s	
3560/5250 (epoch 33.905), train_loss = 1.32372638, grad/param norm = 5.6807e-02, time/batch = 0.0772s	
3561/5250 (epoch 33.914), train_loss = 1.33928443, grad/param norm = 5.9881e-02, time/batch = 0.0789s	
3562/5250 (epoch 33.924), train_loss = 1.33043805, grad/param norm = 5.3820e-02, time/batch = 0.0769s	
3563/5250 (epoch 33.933), train_loss = 1.30085015, grad/param norm = 5.0163e-02, time/batch = 0.0767s	
3564/5250 (epoch 33.943), train_loss = 1.33967533, grad/param norm = 5.6651e-02, time/batch = 0.0770s	
3565/5250 (epoch 33.952), train_loss = 1.33819354, grad/param norm = 5.5420e-02, time/batch = 0.0774s	
3566/5250 (epoch 33.962), train_loss = 1.31526650, grad/param norm = 5.0790e-02, time/batch = 0.0771s	
3567/5250 (epoch 33.971), train_loss = 1.30994025, grad/param norm = 5.5872e-02, time/batch = 0.0769s	
3568/5250 (epoch 33.981), train_loss = 1.33338521, grad/param norm = 5.1893e-02, time/batch = 0.0771s	
3569/5250 (epoch 33.990), train_loss = 1.33521280, grad/param norm = 5.7316e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
3570/5250 (epoch 34.000), train_loss = 1.32001287, grad/param norm = 5.8957e-02, time/batch = 0.0769s	
3571/5250 (epoch 34.010), train_loss = 1.51296873, grad/param norm = 6.7434e-02, time/batch = 0.0788s	
3572/5250 (epoch 34.019), train_loss = 1.30243175, grad/param norm = 6.7577e-02, time/batch = 0.0770s	
3573/5250 (epoch 34.029), train_loss = 1.31462974, grad/param norm = 5.7736e-02, time/batch = 0.0770s	
3574/5250 (epoch 34.038), train_loss = 1.30378396, grad/param norm = 5.8168e-02, time/batch = 0.0769s	
3575/5250 (epoch 34.048), train_loss = 1.28195872, grad/param norm = 5.4654e-02, time/batch = 0.0768s	
3576/5250 (epoch 34.057), train_loss = 1.29540763, grad/param norm = 5.0546e-02, time/batch = 0.0779s	
3577/5250 (epoch 34.067), train_loss = 1.30435112, grad/param norm = 5.0734e-02, time/batch = 0.0768s	
3578/5250 (epoch 34.076), train_loss = 1.30907323, grad/param norm = 5.8719e-02, time/batch = 0.0767s	
3579/5250 (epoch 34.086), train_loss = 1.25944578, grad/param norm = 6.0251e-02, time/batch = 0.0771s	
3580/5250 (epoch 34.095), train_loss = 1.28761550, grad/param norm = 5.2855e-02, time/batch = 0.0769s	
3581/5250 (epoch 34.105), train_loss = 1.30564308, grad/param norm = 5.3146e-02, time/batch = 0.0793s	
3582/5250 (epoch 34.114), train_loss = 1.28840191, grad/param norm = 5.6785e-02, time/batch = 0.0772s	
3583/5250 (epoch 34.124), train_loss = 1.30835513, grad/param norm = 5.9925e-02, time/batch = 0.0772s	
3584/5250 (epoch 34.133), train_loss = 1.29454226, grad/param norm = 5.5516e-02, time/batch = 0.0767s	
3585/5250 (epoch 34.143), train_loss = 1.27983280, grad/param norm = 5.4291e-02, time/batch = 0.0767s	
3586/5250 (epoch 34.152), train_loss = 1.28007290, grad/param norm = 5.3583e-02, time/batch = 0.0773s	
3587/5250 (epoch 34.162), train_loss = 1.30805032, grad/param norm = 5.4222e-02, time/batch = 0.0769s	
3588/5250 (epoch 34.171), train_loss = 1.30941357, grad/param norm = 5.0263e-02, time/batch = 0.0764s	
3589/5250 (epoch 34.181), train_loss = 1.31629675, grad/param norm = 5.5848e-02, time/batch = 0.0772s	
3590/5250 (epoch 34.190), train_loss = 1.30854239, grad/param norm = 5.1183e-02, time/batch = 0.0769s	
3591/5250 (epoch 34.200), train_loss = 1.29495419, grad/param norm = 5.4987e-02, time/batch = 0.0788s	
3592/5250 (epoch 34.210), train_loss = 1.29569934, grad/param norm = 5.3004e-02, time/batch = 0.0772s	
3593/5250 (epoch 34.219), train_loss = 1.34274881, grad/param norm = 5.4707e-02, time/batch = 0.0770s	
3594/5250 (epoch 34.229), train_loss = 1.29679927, grad/param norm = 5.0200e-02, time/batch = 0.0796s	
3595/5250 (epoch 34.238), train_loss = 1.30022223, grad/param norm = 5.3309e-02, time/batch = 0.0770s	
3596/5250 (epoch 34.248), train_loss = 1.30498538, grad/param norm = 5.3063e-02, time/batch = 0.0773s	
3597/5250 (epoch 34.257), train_loss = 1.29613376, grad/param norm = 5.0694e-02, time/batch = 0.0770s	
3598/5250 (epoch 34.267), train_loss = 1.28440994, grad/param norm = 5.3556e-02, time/batch = 0.0770s	
3599/5250 (epoch 34.276), train_loss = 1.28631095, grad/param norm = 5.0521e-02, time/batch = 0.0774s	
3600/5250 (epoch 34.286), train_loss = 1.27142100, grad/param norm = 5.3341e-02, time/batch = 0.0769s	
3601/5250 (epoch 34.295), train_loss = 1.29691899, grad/param norm = 5.1842e-02, time/batch = 0.0787s	
3602/5250 (epoch 34.305), train_loss = 1.29069410, grad/param norm = 5.5626e-02, time/batch = 0.0769s	
3603/5250 (epoch 34.314), train_loss = 1.28200236, grad/param norm = 5.1374e-02, time/batch = 0.0768s	
3604/5250 (epoch 34.324), train_loss = 1.29367566, grad/param norm = 5.2370e-02, time/batch = 0.0775s	
3605/5250 (epoch 34.333), train_loss = 1.29637455, grad/param norm = 5.2088e-02, time/batch = 0.0770s	
3606/5250 (epoch 34.343), train_loss = 1.29921917, grad/param norm = 5.2221e-02, time/batch = 0.0770s	
3607/5250 (epoch 34.352), train_loss = 1.31127058, grad/param norm = 5.5698e-02, time/batch = 0.0769s	
3608/5250 (epoch 34.362), train_loss = 1.30986317, grad/param norm = 5.7013e-02, time/batch = 0.0764s	
3609/5250 (epoch 34.371), train_loss = 1.29010438, grad/param norm = 5.2376e-02, time/batch = 0.0777s	
3610/5250 (epoch 34.381), train_loss = 1.28783068, grad/param norm = 5.2797e-02, time/batch = 0.0771s	
3611/5250 (epoch 34.390), train_loss = 1.29799746, grad/param norm = 5.8442e-02, time/batch = 0.0789s	
3612/5250 (epoch 34.400), train_loss = 1.30254547, grad/param norm = 5.4084e-02, time/batch = 0.0769s	
3613/5250 (epoch 34.410), train_loss = 1.30659715, grad/param norm = 5.2952e-02, time/batch = 0.0769s	
3614/5250 (epoch 34.419), train_loss = 1.29787323, grad/param norm = 5.4774e-02, time/batch = 0.0770s	
3615/5250 (epoch 34.429), train_loss = 1.30661166, grad/param norm = 5.1000e-02, time/batch = 0.0772s	
3616/5250 (epoch 34.438), train_loss = 1.32474761, grad/param norm = 5.6027e-02, time/batch = 0.0773s	
3617/5250 (epoch 34.448), train_loss = 1.28678015, grad/param norm = 5.5765e-02, time/batch = 0.0765s	
3618/5250 (epoch 34.457), train_loss = 1.28973606, grad/param norm = 5.8608e-02, time/batch = 0.0764s	
3619/5250 (epoch 34.467), train_loss = 1.29758933, grad/param norm = 5.3533e-02, time/batch = 0.0770s	
3620/5250 (epoch 34.476), train_loss = 1.29318550, grad/param norm = 5.4333e-02, time/batch = 0.0770s	
3621/5250 (epoch 34.486), train_loss = 1.31409632, grad/param norm = 5.7473e-02, time/batch = 0.0790s	
3622/5250 (epoch 34.495), train_loss = 1.31523125, grad/param norm = 5.3141e-02, time/batch = 0.0771s	
3623/5250 (epoch 34.505), train_loss = 1.32231584, grad/param norm = 5.9817e-02, time/batch = 0.0771s	
3624/5250 (epoch 34.514), train_loss = 1.31739032, grad/param norm = 6.3361e-02, time/batch = 0.0772s	
3625/5250 (epoch 34.524), train_loss = 1.29259402, grad/param norm = 5.3686e-02, time/batch = 0.0768s	
3626/5250 (epoch 34.533), train_loss = 1.30323965, grad/param norm = 5.7961e-02, time/batch = 0.0776s	
3627/5250 (epoch 34.543), train_loss = 1.29240832, grad/param norm = 5.6238e-02, time/batch = 0.0768s	
3628/5250 (epoch 34.552), train_loss = 1.30096946, grad/param norm = 5.8533e-02, time/batch = 0.0765s	
3629/5250 (epoch 34.562), train_loss = 1.29770092, grad/param norm = 5.4373e-02, time/batch = 0.0771s	
3630/5250 (epoch 34.571), train_loss = 1.30245847, grad/param norm = 5.4598e-02, time/batch = 0.0765s	
3631/5250 (epoch 34.581), train_loss = 1.33491177, grad/param norm = 5.8287e-02, time/batch = 0.0790s	
3632/5250 (epoch 34.590), train_loss = 1.30551025, grad/param norm = 5.5728e-02, time/batch = 0.0769s	
3633/5250 (epoch 34.600), train_loss = 1.32707983, grad/param norm = 5.4134e-02, time/batch = 0.0770s	
3634/5250 (epoch 34.610), train_loss = 1.31526352, grad/param norm = 5.6972e-02, time/batch = 0.0769s	
3635/5250 (epoch 34.619), train_loss = 1.30354953, grad/param norm = 5.8208e-02, time/batch = 0.0771s	
3636/5250 (epoch 34.629), train_loss = 1.31375807, grad/param norm = 5.4985e-02, time/batch = 0.0772s	
3637/5250 (epoch 34.638), train_loss = 1.29323019, grad/param norm = 5.1356e-02, time/batch = 0.0771s	
3638/5250 (epoch 34.648), train_loss = 1.30325294, grad/param norm = 5.5195e-02, time/batch = 0.0766s	
3639/5250 (epoch 34.657), train_loss = 1.30300708, grad/param norm = 5.3079e-02, time/batch = 0.0771s	
3640/5250 (epoch 34.667), train_loss = 1.30775408, grad/param norm = 5.5157e-02, time/batch = 0.0769s	
3641/5250 (epoch 34.676), train_loss = 1.30577301, grad/param norm = 5.8766e-02, time/batch = 0.0787s	
3642/5250 (epoch 34.686), train_loss = 1.33109653, grad/param norm = 5.1258e-02, time/batch = 0.0772s	
3643/5250 (epoch 34.695), train_loss = 1.31139714, grad/param norm = 5.8177e-02, time/batch = 0.0774s	
3644/5250 (epoch 34.705), train_loss = 1.29396559, grad/param norm = 5.3408e-02, time/batch = 0.0774s	
3645/5250 (epoch 34.714), train_loss = 1.32872110, grad/param norm = 5.5948e-02, time/batch = 0.0771s	
3646/5250 (epoch 34.724), train_loss = 1.30715822, grad/param norm = 5.1413e-02, time/batch = 0.0773s	
3647/5250 (epoch 34.733), train_loss = 1.28601278, grad/param norm = 5.0471e-02, time/batch = 0.0767s	
3648/5250 (epoch 34.743), train_loss = 1.29276191, grad/param norm = 5.6159e-02, time/batch = 0.0773s	
3649/5250 (epoch 34.752), train_loss = 1.30277498, grad/param norm = 5.7920e-02, time/batch = 0.0774s	
3650/5250 (epoch 34.762), train_loss = 1.29106421, grad/param norm = 5.3263e-02, time/batch = 0.0770s	
3651/5250 (epoch 34.771), train_loss = 1.28554464, grad/param norm = 5.3808e-02, time/batch = 0.0788s	
3652/5250 (epoch 34.781), train_loss = 1.31302364, grad/param norm = 6.2013e-02, time/batch = 0.0770s	
3653/5250 (epoch 34.790), train_loss = 1.32425171, grad/param norm = 5.6413e-02, time/batch = 0.0769s	
3654/5250 (epoch 34.800), train_loss = 1.30501360, grad/param norm = 5.4021e-02, time/batch = 0.0776s	
3655/5250 (epoch 34.810), train_loss = 1.30685399, grad/param norm = 5.3107e-02, time/batch = 0.0771s	
3656/5250 (epoch 34.819), train_loss = 1.31328418, grad/param norm = 5.2967e-02, time/batch = 0.0772s	
3657/5250 (epoch 34.829), train_loss = 1.30863320, grad/param norm = 5.2646e-02, time/batch = 0.0766s	
3658/5250 (epoch 34.838), train_loss = 1.29200151, grad/param norm = 5.0131e-02, time/batch = 0.0765s	
3659/5250 (epoch 34.848), train_loss = 1.29013199, grad/param norm = 5.2488e-02, time/batch = 0.0778s	
3660/5250 (epoch 34.857), train_loss = 1.30445947, grad/param norm = 5.1403e-02, time/batch = 0.0771s	
3661/5250 (epoch 34.867), train_loss = 1.30132308, grad/param norm = 5.3254e-02, time/batch = 0.0789s	
3662/5250 (epoch 34.876), train_loss = 1.30672771, grad/param norm = 5.2137e-02, time/batch = 0.0768s	
3663/5250 (epoch 34.886), train_loss = 1.29130194, grad/param norm = 5.1619e-02, time/batch = 0.0770s	
3664/5250 (epoch 34.895), train_loss = 1.33366955, grad/param norm = 5.8380e-02, time/batch = 0.0769s	
3665/5250 (epoch 34.905), train_loss = 1.31964953, grad/param norm = 5.5930e-02, time/batch = 0.0777s	
3666/5250 (epoch 34.914), train_loss = 1.33494228, grad/param norm = 5.7555e-02, time/batch = 0.0771s	
3667/5250 (epoch 34.924), train_loss = 1.32598217, grad/param norm = 5.2482e-02, time/batch = 0.0765s	
3668/5250 (epoch 34.933), train_loss = 1.29696579, grad/param norm = 5.2685e-02, time/batch = 0.0765s	
3669/5250 (epoch 34.943), train_loss = 1.33637611, grad/param norm = 5.9925e-02, time/batch = 0.0769s	
3670/5250 (epoch 34.952), train_loss = 1.33435932, grad/param norm = 5.6671e-02, time/batch = 0.0771s	
3671/5250 (epoch 34.962), train_loss = 1.31141643, grad/param norm = 5.1807e-02, time/batch = 0.0790s	
3672/5250 (epoch 34.971), train_loss = 1.30615948, grad/param norm = 5.5712e-02, time/batch = 0.0769s	
3673/5250 (epoch 34.981), train_loss = 1.32889139, grad/param norm = 5.1042e-02, time/batch = 0.0771s	
3674/5250 (epoch 34.990), train_loss = 1.33075357, grad/param norm = 5.6222e-02, time/batch = 0.0769s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
3675/5250 (epoch 35.000), train_loss = 1.31594595, grad/param norm = 5.6875e-02, time/batch = 0.0766s	
3676/5250 (epoch 35.010), train_loss = 1.50932760, grad/param norm = 6.4883e-02, time/batch = 0.0777s	
3677/5250 (epoch 35.019), train_loss = 1.29780000, grad/param norm = 6.4789e-02, time/batch = 0.0768s	
3678/5250 (epoch 35.029), train_loss = 1.31006104, grad/param norm = 5.5239e-02, time/batch = 0.0766s	
3679/5250 (epoch 35.038), train_loss = 1.29925091, grad/param norm = 5.6128e-02, time/batch = 0.0770s	
3680/5250 (epoch 35.048), train_loss = 1.27766049, grad/param norm = 5.3564e-02, time/batch = 0.0769s	
3681/5250 (epoch 35.057), train_loss = 1.29125085, grad/param norm = 4.9781e-02, time/batch = 0.0791s	
3682/5250 (epoch 35.067), train_loss = 1.30053445, grad/param norm = 4.9892e-02, time/batch = 0.0769s	
3683/5250 (epoch 35.076), train_loss = 1.30526732, grad/param norm = 5.8245e-02, time/batch = 0.0769s	
3684/5250 (epoch 35.086), train_loss = 1.25581834, grad/param norm = 5.9799e-02, time/batch = 0.0770s	
3685/5250 (epoch 35.095), train_loss = 1.28329471, grad/param norm = 5.2005e-02, time/batch = 0.0770s	
3686/5250 (epoch 35.105), train_loss = 1.30162788, grad/param norm = 5.2339e-02, time/batch = 0.0774s	
3687/5250 (epoch 35.114), train_loss = 1.28427517, grad/param norm = 5.6220e-02, time/batch = 0.0768s	
3688/5250 (epoch 35.124), train_loss = 1.30458477, grad/param norm = 6.0233e-02, time/batch = 0.0768s	
3689/5250 (epoch 35.133), train_loss = 1.29059651, grad/param norm = 5.4447e-02, time/batch = 0.0772s	
3690/5250 (epoch 35.143), train_loss = 1.27594815, grad/param norm = 5.3173e-02, time/batch = 0.0769s	
3691/5250 (epoch 35.152), train_loss = 1.27635358, grad/param norm = 5.2208e-02, time/batch = 0.0787s	
3692/5250 (epoch 35.162), train_loss = 1.30399015, grad/param norm = 5.3048e-02, time/batch = 0.0767s	
3693/5250 (epoch 35.171), train_loss = 1.30495979, grad/param norm = 4.9600e-02, time/batch = 0.0771s	
3694/5250 (epoch 35.181), train_loss = 1.31222580, grad/param norm = 5.5169e-02, time/batch = 0.0770s	
3695/5250 (epoch 35.190), train_loss = 1.30479930, grad/param norm = 5.0859e-02, time/batch = 0.0787s	
3696/5250 (epoch 35.200), train_loss = 1.29097701, grad/param norm = 5.4823e-02, time/batch = 0.0785s	
3697/5250 (epoch 35.210), train_loss = 1.29187891, grad/param norm = 5.2547e-02, time/batch = 0.0768s	
3698/5250 (epoch 35.219), train_loss = 1.33873214, grad/param norm = 5.3975e-02, time/batch = 0.0769s	
3699/5250 (epoch 35.229), train_loss = 1.29275269, grad/param norm = 4.9867e-02, time/batch = 0.0774s	
3700/5250 (epoch 35.238), train_loss = 1.29643836, grad/param norm = 5.3255e-02, time/batch = 0.0771s	
3701/5250 (epoch 35.248), train_loss = 1.30125125, grad/param norm = 5.2784e-02, time/batch = 0.0789s	
3702/5250 (epoch 35.257), train_loss = 1.29263836, grad/param norm = 5.0574e-02, time/batch = 0.0768s	
3703/5250 (epoch 35.267), train_loss = 1.28058311, grad/param norm = 5.3446e-02, time/batch = 0.0770s	
3704/5250 (epoch 35.276), train_loss = 1.28242294, grad/param norm = 5.0327e-02, time/batch = 0.0775s	
3705/5250 (epoch 35.286), train_loss = 1.26772965, grad/param norm = 5.3033e-02, time/batch = 0.0824s	
3706/5250 (epoch 35.295), train_loss = 1.29328590, grad/param norm = 5.1757e-02, time/batch = 0.0780s	
3707/5250 (epoch 35.305), train_loss = 1.28672767, grad/param norm = 5.5451e-02, time/batch = 0.0772s	
3708/5250 (epoch 35.314), train_loss = 1.27838705, grad/param norm = 5.1288e-02, time/batch = 0.0768s	
3709/5250 (epoch 35.324), train_loss = 1.29004099, grad/param norm = 5.2416e-02, time/batch = 0.0778s	
3710/5250 (epoch 35.333), train_loss = 1.29253602, grad/param norm = 5.1967e-02, time/batch = 0.0767s	
3711/5250 (epoch 35.343), train_loss = 1.29524884, grad/param norm = 5.1855e-02, time/batch = 0.0788s	
3712/5250 (epoch 35.352), train_loss = 1.30728513, grad/param norm = 5.4972e-02, time/batch = 0.0768s	
3713/5250 (epoch 35.362), train_loss = 1.30596420, grad/param norm = 5.6249e-02, time/batch = 0.0768s	
3714/5250 (epoch 35.371), train_loss = 1.28634057, grad/param norm = 5.1882e-02, time/batch = 0.0767s	
3715/5250 (epoch 35.381), train_loss = 1.28375538, grad/param norm = 5.2190e-02, time/batch = 0.0774s	
3716/5250 (epoch 35.390), train_loss = 1.29388408, grad/param norm = 5.7822e-02, time/batch = 0.0772s	
3717/5250 (epoch 35.400), train_loss = 1.29857588, grad/param norm = 5.3194e-02, time/batch = 0.0767s	
3718/5250 (epoch 35.410), train_loss = 1.30251027, grad/param norm = 5.2823e-02, time/batch = 0.0766s	
3719/5250 (epoch 35.419), train_loss = 1.29392419, grad/param norm = 5.4132e-02, time/batch = 0.0769s	
3720/5250 (epoch 35.429), train_loss = 1.30265371, grad/param norm = 5.0430e-02, time/batch = 0.0766s	
3721/5250 (epoch 35.438), train_loss = 1.32103344, grad/param norm = 5.6298e-02, time/batch = 0.0789s	
3722/5250 (epoch 35.448), train_loss = 1.28295551, grad/param norm = 5.5567e-02, time/batch = 0.0768s	
3723/5250 (epoch 35.457), train_loss = 1.28606118, grad/param norm = 5.7886e-02, time/batch = 0.0770s	
3724/5250 (epoch 35.467), train_loss = 1.29366869, grad/param norm = 5.3219e-02, time/batch = 0.0768s	
3725/5250 (epoch 35.476), train_loss = 1.28908570, grad/param norm = 5.4170e-02, time/batch = 0.0769s	
3726/5250 (epoch 35.486), train_loss = 1.31037196, grad/param norm = 5.7105e-02, time/batch = 0.0777s	
3727/5250 (epoch 35.495), train_loss = 1.31137346, grad/param norm = 5.2949e-02, time/batch = 0.0767s	
3728/5250 (epoch 35.505), train_loss = 1.31836591, grad/param norm = 6.0160e-02, time/batch = 0.0767s	
3729/5250 (epoch 35.514), train_loss = 1.31318014, grad/param norm = 6.2223e-02, time/batch = 0.0772s	
3730/5250 (epoch 35.524), train_loss = 1.28892710, grad/param norm = 5.3790e-02, time/batch = 0.0768s	
3731/5250 (epoch 35.533), train_loss = 1.29978789, grad/param norm = 5.8442e-02, time/batch = 0.0792s	
3732/5250 (epoch 35.543), train_loss = 1.28858494, grad/param norm = 5.5686e-02, time/batch = 0.0767s	
3733/5250 (epoch 35.552), train_loss = 1.29674928, grad/param norm = 5.7229e-02, time/batch = 0.0771s	
3734/5250 (epoch 35.562), train_loss = 1.29367581, grad/param norm = 5.3049e-02, time/batch = 0.0770s	
3735/5250 (epoch 35.571), train_loss = 1.29857205, grad/param norm = 5.4096e-02, time/batch = 0.0769s	
3736/5250 (epoch 35.581), train_loss = 1.33096654, grad/param norm = 5.7830e-02, time/batch = 0.0773s	
3737/5250 (epoch 35.590), train_loss = 1.30129922, grad/param norm = 5.4815e-02, time/batch = 0.0771s	
3738/5250 (epoch 35.600), train_loss = 1.32345297, grad/param norm = 5.3940e-02, time/batch = 0.0767s	
3739/5250 (epoch 35.610), train_loss = 1.31148252, grad/param norm = 5.7519e-02, time/batch = 0.0772s	
3740/5250 (epoch 35.619), train_loss = 1.30003995, grad/param norm = 5.8614e-02, time/batch = 0.0769s	
3741/5250 (epoch 35.629), train_loss = 1.30982052, grad/param norm = 5.4695e-02, time/batch = 0.0786s	
3742/5250 (epoch 35.638), train_loss = 1.28951969, grad/param norm = 5.0776e-02, time/batch = 0.0772s	
3743/5250 (epoch 35.648), train_loss = 1.29921626, grad/param norm = 5.4141e-02, time/batch = 0.0768s	
3744/5250 (epoch 35.657), train_loss = 1.29903488, grad/param norm = 5.2082e-02, time/batch = 0.0768s	
3745/5250 (epoch 35.667), train_loss = 1.30409183, grad/param norm = 5.4508e-02, time/batch = 0.0767s	
3746/5250 (epoch 35.676), train_loss = 1.30152575, grad/param norm = 5.7754e-02, time/batch = 0.0772s	
3747/5250 (epoch 35.686), train_loss = 1.32715961, grad/param norm = 5.0541e-02, time/batch = 0.0766s	
3748/5250 (epoch 35.695), train_loss = 1.30755987, grad/param norm = 5.7744e-02, time/batch = 0.0771s	
3749/5250 (epoch 35.705), train_loss = 1.29028276, grad/param norm = 5.3821e-02, time/batch = 0.0772s	
3750/5250 (epoch 35.714), train_loss = 1.32484874, grad/param norm = 5.6361e-02, time/batch = 0.0769s	
3751/5250 (epoch 35.724), train_loss = 1.30303350, grad/param norm = 5.1178e-02, time/batch = 0.0788s	
3752/5250 (epoch 35.733), train_loss = 1.28200296, grad/param norm = 5.0271e-02, time/batch = 0.0768s	
3753/5250 (epoch 35.743), train_loss = 1.28888558, grad/param norm = 5.5708e-02, time/batch = 0.0768s	
3754/5250 (epoch 35.752), train_loss = 1.29865283, grad/param norm = 5.7113e-02, time/batch = 0.0774s	
3755/5250 (epoch 35.762), train_loss = 1.28701295, grad/param norm = 5.2222e-02, time/batch = 0.0772s	
3756/5250 (epoch 35.771), train_loss = 1.28184398, grad/param norm = 5.4143e-02, time/batch = 0.0773s	
3757/5250 (epoch 35.781), train_loss = 1.30939914, grad/param norm = 6.1537e-02, time/batch = 0.0767s	
3758/5250 (epoch 35.790), train_loss = 1.32026180, grad/param norm = 5.5785e-02, time/batch = 0.0764s	
3759/5250 (epoch 35.800), train_loss = 1.30105131, grad/param norm = 5.4566e-02, time/batch = 0.0776s	
3760/5250 (epoch 35.810), train_loss = 1.30294413, grad/param norm = 5.2803e-02, time/batch = 0.0772s	
3761/5250 (epoch 35.819), train_loss = 1.30942247, grad/param norm = 5.2567e-02, time/batch = 0.0788s	
3762/5250 (epoch 35.829), train_loss = 1.30488202, grad/param norm = 5.2220e-02, time/batch = 0.0768s	
3763/5250 (epoch 35.838), train_loss = 1.28850168, grad/param norm = 5.0497e-02, time/batch = 0.0769s	
3764/5250 (epoch 35.848), train_loss = 1.28652915, grad/param norm = 5.2381e-02, time/batch = 0.0770s	
3765/5250 (epoch 35.857), train_loss = 1.30062709, grad/param norm = 5.1470e-02, time/batch = 0.0772s	
3766/5250 (epoch 35.867), train_loss = 1.29774827, grad/param norm = 5.3164e-02, time/batch = 0.0774s	
3767/5250 (epoch 35.876), train_loss = 1.30244011, grad/param norm = 5.0896e-02, time/batch = 0.0764s	
3768/5250 (epoch 35.886), train_loss = 1.28734650, grad/param norm = 5.0995e-02, time/batch = 0.0764s	
3769/5250 (epoch 35.895), train_loss = 1.32999932, grad/param norm = 5.8961e-02, time/batch = 0.0770s	
3770/5250 (epoch 35.905), train_loss = 1.31605761, grad/param norm = 5.6774e-02, time/batch = 0.0770s	
3771/5250 (epoch 35.914), train_loss = 1.33126500, grad/param norm = 5.6709e-02, time/batch = 0.0789s	
3772/5250 (epoch 35.924), train_loss = 1.32193644, grad/param norm = 5.1952e-02, time/batch = 0.0767s	
3773/5250 (epoch 35.933), train_loss = 1.29304504, grad/param norm = 5.3526e-02, time/batch = 0.0769s	
3774/5250 (epoch 35.943), train_loss = 1.33247307, grad/param norm = 5.9380e-02, time/batch = 0.0770s	
3775/5250 (epoch 35.952), train_loss = 1.33016796, grad/param norm = 5.5641e-02, time/batch = 0.0768s	
3776/5250 (epoch 35.962), train_loss = 1.30738460, grad/param norm = 5.0868e-02, time/batch = 0.0778s	
3777/5250 (epoch 35.971), train_loss = 1.30235482, grad/param norm = 5.4422e-02, time/batch = 0.0769s	
3778/5250 (epoch 35.981), train_loss = 1.32501739, grad/param norm = 5.1839e-02, time/batch = 0.0766s	
3779/5250 (epoch 35.990), train_loss = 1.32714675, grad/param norm = 5.8384e-02, time/batch = 0.0770s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
3780/5250 (epoch 36.000), train_loss = 1.31275520, grad/param norm = 5.7919e-02, time/batch = 0.0768s	
3781/5250 (epoch 36.010), train_loss = 1.50665423, grad/param norm = 6.6092e-02, time/batch = 0.0791s	
3782/5250 (epoch 36.019), train_loss = 1.29397560, grad/param norm = 6.4475e-02, time/batch = 0.0770s	
3783/5250 (epoch 36.029), train_loss = 1.30619397, grad/param norm = 5.5004e-02, time/batch = 0.0771s	
3784/5250 (epoch 36.038), train_loss = 1.29536595, grad/param norm = 5.5414e-02, time/batch = 0.0769s	
3785/5250 (epoch 36.048), train_loss = 1.27371388, grad/param norm = 5.2876e-02, time/batch = 0.0767s	
3786/5250 (epoch 36.057), train_loss = 1.28740474, grad/param norm = 4.9454e-02, time/batch = 0.0773s	
3787/5250 (epoch 36.067), train_loss = 1.29698343, grad/param norm = 4.9487e-02, time/batch = 0.0767s	
3788/5250 (epoch 36.076), train_loss = 1.30161643, grad/param norm = 5.7854e-02, time/batch = 0.0766s	
3789/5250 (epoch 36.086), train_loss = 1.25219923, grad/param norm = 5.8953e-02, time/batch = 0.0772s	
3790/5250 (epoch 36.095), train_loss = 1.27908689, grad/param norm = 5.0998e-02, time/batch = 0.1125s	
3791/5250 (epoch 36.105), train_loss = 1.29786603, grad/param norm = 5.1971e-02, time/batch = 0.2082s	
3792/5250 (epoch 36.114), train_loss = 1.28036140, grad/param norm = 5.5789e-02, time/batch = 0.2014s	
3793/5250 (epoch 36.124), train_loss = 1.30103313, grad/param norm = 5.8901e-02, time/batch = 0.1949s	
3794/5250 (epoch 36.133), train_loss = 1.28684749, grad/param norm = 5.3899e-02, time/batch = 0.1220s	
3795/5250 (epoch 36.143), train_loss = 1.27223192, grad/param norm = 5.2508e-02, time/batch = 0.1201s	
3796/5250 (epoch 36.152), train_loss = 1.27279944, grad/param norm = 5.2292e-02, time/batch = 0.1204s	
3797/5250 (epoch 36.162), train_loss = 1.30038258, grad/param norm = 5.2738e-02, time/batch = 0.1194s	
3798/5250 (epoch 36.171), train_loss = 1.30078005, grad/param norm = 4.9311e-02, time/batch = 0.1073s	
3799/5250 (epoch 36.181), train_loss = 1.30839672, grad/param norm = 5.4895e-02, time/batch = 0.1063s	
3800/5250 (epoch 36.190), train_loss = 1.30132205, grad/param norm = 5.0960e-02, time/batch = 0.1063s	
3801/5250 (epoch 36.200), train_loss = 1.28719204, grad/param norm = 5.4733e-02, time/batch = 0.1111s	
3802/5250 (epoch 36.210), train_loss = 1.28827319, grad/param norm = 5.1933e-02, time/batch = 0.1063s	
3803/5250 (epoch 36.219), train_loss = 1.33491335, grad/param norm = 5.3175e-02, time/batch = 0.1060s	
3804/5250 (epoch 36.229), train_loss = 1.28898841, grad/param norm = 4.9673e-02, time/batch = 0.1061s	
3805/5250 (epoch 36.238), train_loss = 1.29276962, grad/param norm = 5.3030e-02, time/batch = 0.1061s	
3806/5250 (epoch 36.248), train_loss = 1.29755171, grad/param norm = 5.2503e-02, time/batch = 0.1059s	
3807/5250 (epoch 36.257), train_loss = 1.28917725, grad/param norm = 5.0361e-02, time/batch = 0.0856s	
3808/5250 (epoch 36.267), train_loss = 1.27702665, grad/param norm = 5.3255e-02, time/batch = 0.0879s	
3809/5250 (epoch 36.276), train_loss = 1.27862480, grad/param norm = 4.9602e-02, time/batch = 0.0839s	
3810/5250 (epoch 36.286), train_loss = 1.26410357, grad/param norm = 5.2445e-02, time/batch = 0.0831s	
3811/5250 (epoch 36.295), train_loss = 1.28981780, grad/param norm = 5.1399e-02, time/batch = 0.0901s	
3812/5250 (epoch 36.305), train_loss = 1.28280902, grad/param norm = 5.4747e-02, time/batch = 0.0834s	
3813/5250 (epoch 36.314), train_loss = 1.27485722, grad/param norm = 5.1270e-02, time/batch = 0.0833s	
3814/5250 (epoch 36.324), train_loss = 1.28665037, grad/param norm = 5.2799e-02, time/batch = 0.0836s	
3815/5250 (epoch 36.333), train_loss = 1.28885296, grad/param norm = 5.1698e-02, time/batch = 0.0837s	
3816/5250 (epoch 36.343), train_loss = 1.29154360, grad/param norm = 5.1532e-02, time/batch = 0.0840s	
3817/5250 (epoch 36.352), train_loss = 1.30362960, grad/param norm = 5.4588e-02, time/batch = 0.0843s	
3818/5250 (epoch 36.362), train_loss = 1.30224359, grad/param norm = 5.5887e-02, time/batch = 0.0837s	
3819/5250 (epoch 36.371), train_loss = 1.28273407, grad/param norm = 5.1333e-02, time/batch = 0.0839s	
3820/5250 (epoch 36.381), train_loss = 1.27986912, grad/param norm = 5.1722e-02, time/batch = 0.0834s	
3821/5250 (epoch 36.390), train_loss = 1.28995824, grad/param norm = 5.7288e-02, time/batch = 0.0885s	
3822/5250 (epoch 36.400), train_loss = 1.29487688, grad/param norm = 5.2590e-02, time/batch = 0.0838s	
3823/5250 (epoch 36.410), train_loss = 1.29877753, grad/param norm = 5.3188e-02, time/batch = 0.0835s	
3824/5250 (epoch 36.419), train_loss = 1.29026533, grad/param norm = 5.3830e-02, time/batch = 0.0835s	
3825/5250 (epoch 36.429), train_loss = 1.29894051, grad/param norm = 5.0057e-02, time/batch = 0.0835s	
3826/5250 (epoch 36.438), train_loss = 1.31753619, grad/param norm = 5.6428e-02, time/batch = 0.0840s	
3827/5250 (epoch 36.448), train_loss = 1.27925266, grad/param norm = 5.4785e-02, time/batch = 0.0833s	
3828/5250 (epoch 36.457), train_loss = 1.28239734, grad/param norm = 5.6445e-02, time/batch = 0.0838s	
3829/5250 (epoch 36.467), train_loss = 1.28985903, grad/param norm = 5.2420e-02, time/batch = 0.0842s	
3830/5250 (epoch 36.476), train_loss = 1.28518082, grad/param norm = 5.3840e-02, time/batch = 0.0835s	
3831/5250 (epoch 36.486), train_loss = 1.30678912, grad/param norm = 5.6510e-02, time/batch = 0.0893s	
3832/5250 (epoch 36.495), train_loss = 1.30787558, grad/param norm = 5.3542e-02, time/batch = 0.0835s	
3833/5250 (epoch 36.505), train_loss = 1.31486066, grad/param norm = 6.1499e-02, time/batch = 0.0838s	
3834/5250 (epoch 36.514), train_loss = 1.30925656, grad/param norm = 6.1585e-02, time/batch = 0.0846s	
3835/5250 (epoch 36.524), train_loss = 1.28553122, grad/param norm = 5.3961e-02, time/batch = 0.1615s	
3836/5250 (epoch 36.533), train_loss = 1.29651026, grad/param norm = 5.8978e-02, time/batch = 0.1697s	
3837/5250 (epoch 36.543), train_loss = 1.28491018, grad/param norm = 5.5054e-02, time/batch = 0.1700s	
3838/5250 (epoch 36.552), train_loss = 1.29273540, grad/param norm = 5.6022e-02, time/batch = 0.1694s	
3839/5250 (epoch 36.562), train_loss = 1.28984092, grad/param norm = 5.1990e-02, time/batch = 0.1715s	
3840/5250 (epoch 36.571), train_loss = 1.29487279, grad/param norm = 5.3721e-02, time/batch = 0.1211s	
3841/5250 (epoch 36.581), train_loss = 1.32719333, grad/param norm = 5.7305e-02, time/batch = 0.1066s	
3842/5250 (epoch 36.590), train_loss = 1.29729792, grad/param norm = 5.3899e-02, time/batch = 0.1019s	
3843/5250 (epoch 36.600), train_loss = 1.32003235, grad/param norm = 5.3917e-02, time/batch = 0.1019s	
3844/5250 (epoch 36.610), train_loss = 1.30789719, grad/param norm = 5.8109e-02, time/batch = 0.0979s	
3845/5250 (epoch 36.619), train_loss = 1.29668512, grad/param norm = 5.8671e-02, time/batch = 0.0914s	
3846/5250 (epoch 36.629), train_loss = 1.30593708, grad/param norm = 5.4162e-02, time/batch = 0.1541s	
3847/5250 (epoch 36.638), train_loss = 1.28600431, grad/param norm = 5.0125e-02, time/batch = 0.1730s	
3848/5250 (epoch 36.648), train_loss = 1.29540593, grad/param norm = 5.3001e-02, time/batch = 0.1725s	
3849/5250 (epoch 36.657), train_loss = 1.29532514, grad/param norm = 5.1331e-02, time/batch = 0.1730s	
3850/5250 (epoch 36.667), train_loss = 1.30063557, grad/param norm = 5.4015e-02, time/batch = 0.1728s	
3851/5250 (epoch 36.676), train_loss = 1.29739962, grad/param norm = 5.6696e-02, time/batch = 0.1086s	
3852/5250 (epoch 36.686), train_loss = 1.32346160, grad/param norm = 5.0085e-02, time/batch = 0.1043s	
3853/5250 (epoch 36.695), train_loss = 1.30402114, grad/param norm = 5.8094e-02, time/batch = 0.1047s	
3854/5250 (epoch 36.705), train_loss = 1.28683089, grad/param norm = 5.4404e-02, time/batch = 0.1047s	
3855/5250 (epoch 36.714), train_loss = 1.32113524, grad/param norm = 5.6586e-02, time/batch = 0.0978s	
3856/5250 (epoch 36.724), train_loss = 1.29912694, grad/param norm = 5.0782e-02, time/batch = 0.0937s	
3857/5250 (epoch 36.733), train_loss = 1.27823287, grad/param norm = 4.9986e-02, time/batch = 0.0932s	
3858/5250 (epoch 36.743), train_loss = 1.28522820, grad/param norm = 5.5325e-02, time/batch = 0.0930s	
3859/5250 (epoch 36.752), train_loss = 1.29479966, grad/param norm = 5.6404e-02, time/batch = 0.0937s	
3860/5250 (epoch 36.762), train_loss = 1.28326410, grad/param norm = 5.1432e-02, time/batch = 0.0938s	
3861/5250 (epoch 36.771), train_loss = 1.27840902, grad/param norm = 5.4516e-02, time/batch = 0.0959s	
3862/5250 (epoch 36.781), train_loss = 1.30585180, grad/param norm = 6.0341e-02, time/batch = 0.0931s	
3863/5250 (epoch 36.790), train_loss = 1.31641725, grad/param norm = 5.5277e-02, time/batch = 0.0932s	
3864/5250 (epoch 36.800), train_loss = 1.29710039, grad/param norm = 5.4741e-02, time/batch = 0.0933s	
3865/5250 (epoch 36.810), train_loss = 1.29919257, grad/param norm = 5.2239e-02, time/batch = 0.0867s	
3866/5250 (epoch 36.819), train_loss = 1.30579574, grad/param norm = 5.2512e-02, time/batch = 0.0773s	
3867/5250 (epoch 36.829), train_loss = 1.30154600, grad/param norm = 5.2493e-02, time/batch = 0.0763s	
3868/5250 (epoch 36.838), train_loss = 1.28524854, grad/param norm = 5.1048e-02, time/batch = 0.0762s	
3869/5250 (epoch 36.848), train_loss = 1.28309707, grad/param norm = 5.2069e-02, time/batch = 0.0769s	
3870/5250 (epoch 36.857), train_loss = 1.29685906, grad/param norm = 5.0958e-02, time/batch = 0.0767s	
3871/5250 (epoch 36.867), train_loss = 1.29406950, grad/param norm = 5.2102e-02, time/batch = 0.0789s	
3872/5250 (epoch 36.876), train_loss = 1.29830683, grad/param norm = 4.9482e-02, time/batch = 0.0766s	
3873/5250 (epoch 36.886), train_loss = 1.28356595, grad/param norm = 5.0660e-02, time/batch = 0.0767s	
3874/5250 (epoch 36.895), train_loss = 1.32660839, grad/param norm = 5.9676e-02, time/batch = 0.0765s	
3875/5250 (epoch 36.905), train_loss = 1.31260326, grad/param norm = 5.6648e-02, time/batch = 0.0768s	
3876/5250 (epoch 36.914), train_loss = 1.32757334, grad/param norm = 5.5647e-02, time/batch = 0.0776s	
3877/5250 (epoch 36.924), train_loss = 1.31814072, grad/param norm = 5.1853e-02, time/batch = 0.0766s	
3878/5250 (epoch 36.933), train_loss = 1.28930787, grad/param norm = 5.3821e-02, time/batch = 0.0765s	
3879/5250 (epoch 36.943), train_loss = 1.32867003, grad/param norm = 5.8296e-02, time/batch = 0.0772s	
3880/5250 (epoch 36.952), train_loss = 1.32617624, grad/param norm = 5.4760e-02, time/batch = 0.0767s	
3881/5250 (epoch 36.962), train_loss = 1.30368833, grad/param norm = 5.0444e-02, time/batch = 0.0787s	
3882/5250 (epoch 36.971), train_loss = 1.29895254, grad/param norm = 5.4068e-02, time/batch = 0.0766s	
3883/5250 (epoch 36.981), train_loss = 1.32141260, grad/param norm = 5.2748e-02, time/batch = 0.0767s	
3884/5250 (epoch 36.990), train_loss = 1.32363611, grad/param norm = 5.9558e-02, time/batch = 0.0766s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
3885/5250 (epoch 37.000), train_loss = 1.30959478, grad/param norm = 5.8327e-02, time/batch = 0.0768s	
3886/5250 (epoch 37.010), train_loss = 1.50419294, grad/param norm = 6.6664e-02, time/batch = 0.0772s	
3887/5250 (epoch 37.019), train_loss = 1.29034183, grad/param norm = 6.3727e-02, time/batch = 0.0769s	
3888/5250 (epoch 37.029), train_loss = 1.30249638, grad/param norm = 5.4301e-02, time/batch = 0.0762s	
3889/5250 (epoch 37.038), train_loss = 1.29160630, grad/param norm = 5.4529e-02, time/batch = 0.0785s	
3890/5250 (epoch 37.048), train_loss = 1.27004173, grad/param norm = 5.2426e-02, time/batch = 0.0778s	
3891/5250 (epoch 37.057), train_loss = 1.28378175, grad/param norm = 4.9133e-02, time/batch = 0.0786s	
3892/5250 (epoch 37.067), train_loss = 1.29361031, grad/param norm = 4.9126e-02, time/batch = 0.0765s	
3893/5250 (epoch 37.076), train_loss = 1.29814415, grad/param norm = 5.7301e-02, time/batch = 0.0772s	
3894/5250 (epoch 37.086), train_loss = 1.24869515, grad/param norm = 5.8001e-02, time/batch = 0.0766s	
3895/5250 (epoch 37.095), train_loss = 1.27514835, grad/param norm = 5.0256e-02, time/batch = 0.0766s	
3896/5250 (epoch 37.105), train_loss = 1.29433155, grad/param norm = 5.1718e-02, time/batch = 0.0771s	
3897/5250 (epoch 37.114), train_loss = 1.27670957, grad/param norm = 5.5452e-02, time/batch = 0.0765s	
3898/5250 (epoch 37.124), train_loss = 1.29755929, grad/param norm = 5.8264e-02, time/batch = 0.0765s	
3899/5250 (epoch 37.133), train_loss = 1.28319022, grad/param norm = 5.2970e-02, time/batch = 0.0768s	
3900/5250 (epoch 37.143), train_loss = 1.26872269, grad/param norm = 5.1816e-02, time/batch = 0.0769s	
3901/5250 (epoch 37.152), train_loss = 1.26943039, grad/param norm = 5.1761e-02, time/batch = 0.0788s	
3902/5250 (epoch 37.162), train_loss = 1.29686426, grad/param norm = 5.2170e-02, time/batch = 0.0764s	
3903/5250 (epoch 37.171), train_loss = 1.29678849, grad/param norm = 4.8980e-02, time/batch = 0.0768s	
3904/5250 (epoch 37.181), train_loss = 1.30471295, grad/param norm = 5.4474e-02, time/batch = 0.0770s	
3905/5250 (epoch 37.190), train_loss = 1.29799045, grad/param norm = 5.0930e-02, time/batch = 0.0804s	
3906/5250 (epoch 37.200), train_loss = 1.28362199, grad/param norm = 5.4607e-02, time/batch = 0.0784s	
3907/5250 (epoch 37.210), train_loss = 1.28485880, grad/param norm = 5.1478e-02, time/batch = 0.0764s	
3908/5250 (epoch 37.219), train_loss = 1.33122977, grad/param norm = 5.2543e-02, time/batch = 0.0765s	
3909/5250 (epoch 37.229), train_loss = 1.28540336, grad/param norm = 4.9517e-02, time/batch = 0.0773s	
3910/5250 (epoch 37.238), train_loss = 1.28935946, grad/param norm = 5.2897e-02, time/batch = 0.0774s	
3911/5250 (epoch 37.248), train_loss = 1.29407364, grad/param norm = 5.2222e-02, time/batch = 0.0789s	
3912/5250 (epoch 37.257), train_loss = 1.28593506, grad/param norm = 5.0163e-02, time/batch = 0.0765s	
3913/5250 (epoch 37.267), train_loss = 1.27361128, grad/param norm = 5.3076e-02, time/batch = 0.0765s	
3914/5250 (epoch 37.276), train_loss = 1.27505260, grad/param norm = 4.9105e-02, time/batch = 0.0766s	
3915/5250 (epoch 37.286), train_loss = 1.26066005, grad/param norm = 5.2031e-02, time/batch = 0.0771s	
3916/5250 (epoch 37.295), train_loss = 1.28656704, grad/param norm = 5.1276e-02, time/batch = 0.0772s	
3917/5250 (epoch 37.305), train_loss = 1.27917457, grad/param norm = 5.4323e-02, time/batch = 0.0764s	
3918/5250 (epoch 37.314), train_loss = 1.27147123, grad/param norm = 5.1322e-02, time/batch = 0.0761s	
3919/5250 (epoch 37.324), train_loss = 1.28340665, grad/param norm = 5.3209e-02, time/batch = 0.0770s	
3920/5250 (epoch 37.333), train_loss = 1.28535378, grad/param norm = 5.1409e-02, time/batch = 0.0765s	
3921/5250 (epoch 37.343), train_loss = 1.28804560, grad/param norm = 5.1298e-02, time/batch = 0.0786s	
3922/5250 (epoch 37.352), train_loss = 1.30017970, grad/param norm = 5.4373e-02, time/batch = 0.0764s	
3923/5250 (epoch 37.362), train_loss = 1.29877943, grad/param norm = 5.5619e-02, time/batch = 0.0767s	
3924/5250 (epoch 37.371), train_loss = 1.27934466, grad/param norm = 5.0853e-02, time/batch = 0.0768s	
3925/5250 (epoch 37.381), train_loss = 1.27625666, grad/param norm = 5.1431e-02, time/batch = 0.0766s	
3926/5250 (epoch 37.390), train_loss = 1.28627440, grad/param norm = 5.6831e-02, time/batch = 0.0770s	
3927/5250 (epoch 37.400), train_loss = 1.29133217, grad/param norm = 5.1961e-02, time/batch = 0.0764s	
3928/5250 (epoch 37.410), train_loss = 1.29506510, grad/param norm = 5.3269e-02, time/batch = 0.0764s	
3929/5250 (epoch 37.419), train_loss = 1.28677335, grad/param norm = 5.3335e-02, time/batch = 0.0768s	
3930/5250 (epoch 37.429), train_loss = 1.29545967, grad/param norm = 4.9826e-02, time/batch = 0.0765s	
3931/5250 (epoch 37.438), train_loss = 1.31425510, grad/param norm = 5.6890e-02, time/batch = 0.0785s	
3932/5250 (epoch 37.448), train_loss = 1.27578207, grad/param norm = 5.4224e-02, time/batch = 0.0765s	
3933/5250 (epoch 37.457), train_loss = 1.27895100, grad/param norm = 5.5336e-02, time/batch = 0.0765s	
3934/5250 (epoch 37.467), train_loss = 1.28630687, grad/param norm = 5.1852e-02, time/batch = 0.0770s	
3935/5250 (epoch 37.476), train_loss = 1.28156765, grad/param norm = 5.3780e-02, time/batch = 0.0766s	
3936/5250 (epoch 37.486), train_loss = 1.30340251, grad/param norm = 5.6051e-02, time/batch = 0.0767s	
3937/5250 (epoch 37.495), train_loss = 1.30466728, grad/param norm = 5.4636e-02, time/batch = 0.0770s	
3938/5250 (epoch 37.505), train_loss = 1.31162420, grad/param norm = 6.2870e-02, time/batch = 0.0767s	
3939/5250 (epoch 37.514), train_loss = 1.30541326, grad/param norm = 5.9499e-02, time/batch = 0.0771s	
3940/5250 (epoch 37.524), train_loss = 1.28225986, grad/param norm = 5.4446e-02, time/batch = 0.0768s	
3941/5250 (epoch 37.533), train_loss = 1.29330803, grad/param norm = 5.9373e-02, time/batch = 0.0786s	
3942/5250 (epoch 37.543), train_loss = 1.28141467, grad/param norm = 5.4325e-02, time/batch = 0.0763s	
3943/5250 (epoch 37.552), train_loss = 1.28891042, grad/param norm = 5.5009e-02, time/batch = 0.0771s	
3944/5250 (epoch 37.562), train_loss = 1.28625064, grad/param norm = 5.1353e-02, time/batch = 0.0765s	
3945/5250 (epoch 37.571), train_loss = 1.29138435, grad/param norm = 5.3426e-02, time/batch = 0.0767s	
3946/5250 (epoch 37.581), train_loss = 1.32360544, grad/param norm = 5.6681e-02, time/batch = 0.0768s	
3947/5250 (epoch 37.590), train_loss = 1.29348425, grad/param norm = 5.3118e-02, time/batch = 0.0766s	
3948/5250 (epoch 37.600), train_loss = 1.31674263, grad/param norm = 5.3976e-02, time/batch = 0.0765s	
3949/5250 (epoch 37.610), train_loss = 1.30437806, grad/param norm = 5.8151e-02, time/batch = 0.0774s	
3950/5250 (epoch 37.619), train_loss = 1.29332106, grad/param norm = 5.8040e-02, time/batch = 0.0770s	
3951/5250 (epoch 37.629), train_loss = 1.30218702, grad/param norm = 5.3455e-02, time/batch = 0.0787s	
3952/5250 (epoch 37.638), train_loss = 1.28264633, grad/param norm = 4.9427e-02, time/batch = 0.0765s	
3953/5250 (epoch 37.648), train_loss = 1.29183012, grad/param norm = 5.1995e-02, time/batch = 0.0766s	
3954/5250 (epoch 37.657), train_loss = 1.29170501, grad/param norm = 5.0800e-02, time/batch = 0.0772s	
3955/5250 (epoch 37.667), train_loss = 1.29744223, grad/param norm = 5.3813e-02, time/batch = 0.0768s	
3956/5250 (epoch 37.676), train_loss = 1.29361894, grad/param norm = 5.6128e-02, time/batch = 0.0767s	
3957/5250 (epoch 37.686), train_loss = 1.32000246, grad/param norm = 4.9804e-02, time/batch = 0.0765s	
3958/5250 (epoch 37.695), train_loss = 1.30060250, grad/param norm = 5.7948e-02, time/batch = 0.0760s	
3959/5250 (epoch 37.705), train_loss = 1.28348790, grad/param norm = 5.4696e-02, time/batch = 0.0769s	
3960/5250 (epoch 37.714), train_loss = 1.31755253, grad/param norm = 5.6709e-02, time/batch = 0.0774s	
3961/5250 (epoch 37.724), train_loss = 1.29545099, grad/param norm = 5.0396e-02, time/batch = 0.0787s	
3962/5250 (epoch 37.733), train_loss = 1.27474036, grad/param norm = 4.9969e-02, time/batch = 0.0766s	
3963/5250 (epoch 37.743), train_loss = 1.28186545, grad/param norm = 5.5446e-02, time/batch = 0.0767s	
3964/5250 (epoch 37.752), train_loss = 1.29124113, grad/param norm = 5.6093e-02, time/batch = 0.0768s	
3965/5250 (epoch 37.762), train_loss = 1.27973675, grad/param norm = 5.0892e-02, time/batch = 0.0772s	
3966/5250 (epoch 37.771), train_loss = 1.27513112, grad/param norm = 5.4515e-02, time/batch = 0.0767s	
3967/5250 (epoch 37.781), train_loss = 1.30240997, grad/param norm = 5.8613e-02, time/batch = 0.0766s	
3968/5250 (epoch 37.790), train_loss = 1.31280401, grad/param norm = 5.6079e-02, time/batch = 0.0764s	
3969/5250 (epoch 37.800), train_loss = 1.29368817, grad/param norm = 5.6206e-02, time/batch = 0.0767s	
3970/5250 (epoch 37.810), train_loss = 1.29588251, grad/param norm = 5.1750e-02, time/batch = 0.0763s	
3971/5250 (epoch 37.819), train_loss = 1.30241983, grad/param norm = 5.2928e-02, time/batch = 0.0785s	
3972/5250 (epoch 37.829), train_loss = 1.29829630, grad/param norm = 5.2823e-02, time/batch = 0.0764s	
3973/5250 (epoch 37.838), train_loss = 1.28225941, grad/param norm = 5.1654e-02, time/batch = 0.0765s	
3974/5250 (epoch 37.848), train_loss = 1.27985325, grad/param norm = 5.2144e-02, time/batch = 0.0767s	
3975/5250 (epoch 37.857), train_loss = 1.29341921, grad/param norm = 5.0709e-02, time/batch = 0.0768s	
3976/5250 (epoch 37.867), train_loss = 1.29078253, grad/param norm = 5.1796e-02, time/batch = 0.0774s	
3977/5250 (epoch 37.876), train_loss = 1.29459134, grad/param norm = 4.8865e-02, time/batch = 0.0766s	
3978/5250 (epoch 37.886), train_loss = 1.28011127, grad/param norm = 5.0731e-02, time/batch = 0.0759s	
3979/5250 (epoch 37.895), train_loss = 1.32327752, grad/param norm = 5.9637e-02, time/batch = 0.0771s	
3980/5250 (epoch 37.905), train_loss = 1.30906151, grad/param norm = 5.4555e-02, time/batch = 0.0765s	
3981/5250 (epoch 37.914), train_loss = 1.32366960, grad/param norm = 5.4145e-02, time/batch = 0.0786s	
3982/5250 (epoch 37.924), train_loss = 1.31458681, grad/param norm = 5.1894e-02, time/batch = 0.0768s	
3983/5250 (epoch 37.933), train_loss = 1.28571211, grad/param norm = 5.3696e-02, time/batch = 0.0766s	
3984/5250 (epoch 37.943), train_loss = 1.32507432, grad/param norm = 5.7610e-02, time/batch = 0.0764s	
3985/5250 (epoch 37.952), train_loss = 1.32244623, grad/param norm = 5.4322e-02, time/batch = 0.0766s	
3986/5250 (epoch 37.962), train_loss = 1.30025779, grad/param norm = 5.0278e-02, time/batch = 0.0772s	
3987/5250 (epoch 37.971), train_loss = 1.29575762, grad/param norm = 5.3897e-02, time/batch = 0.0770s	
3988/5250 (epoch 37.981), train_loss = 1.31784142, grad/param norm = 5.2900e-02, time/batch = 0.0766s	
3989/5250 (epoch 37.990), train_loss = 1.32008807, grad/param norm = 5.9578e-02, time/batch = 0.0768s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
3990/5250 (epoch 38.000), train_loss = 1.30641126, grad/param norm = 5.8002e-02, time/batch = 0.0773s	
3991/5250 (epoch 38.010), train_loss = 1.50176854, grad/param norm = 6.6523e-02, time/batch = 0.0788s	
3992/5250 (epoch 38.019), train_loss = 1.28683132, grad/param norm = 6.2704e-02, time/batch = 0.0763s	
3993/5250 (epoch 38.029), train_loss = 1.29897552, grad/param norm = 5.3397e-02, time/batch = 0.0770s	
3994/5250 (epoch 38.038), train_loss = 1.28801030, grad/param norm = 5.3662e-02, time/batch = 0.0767s	
3995/5250 (epoch 38.048), train_loss = 1.26656505, grad/param norm = 5.2025e-02, time/batch = 0.0764s	
3996/5250 (epoch 38.057), train_loss = 1.28037635, grad/param norm = 4.8887e-02, time/batch = 0.0771s	
3997/5250 (epoch 38.067), train_loss = 1.29041496, grad/param norm = 4.8804e-02, time/batch = 0.0764s	
3998/5250 (epoch 38.076), train_loss = 1.29479026, grad/param norm = 5.6496e-02, time/batch = 0.0761s	
3999/5250 (epoch 38.086), train_loss = 1.24536169, grad/param norm = 5.7098e-02, time/batch = 0.0775s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch38.10_1.4211.t7	
4000/5250 (epoch 38.095), train_loss = 1.27148709, grad/param norm = 4.9743e-02, time/batch = 0.0764s	
4001/5250 (epoch 38.105), train_loss = 1.56285810, grad/param norm = 7.1117e-02, time/batch = 0.1765s	
4002/5250 (epoch 38.114), train_loss = 1.28223170, grad/param norm = 7.4383e-02, time/batch = 0.1727s	
4003/5250 (epoch 38.124), train_loss = 1.29651648, grad/param norm = 6.4219e-02, time/batch = 0.1362s	
4004/5250 (epoch 38.133), train_loss = 1.28071117, grad/param norm = 5.1356e-02, time/batch = 0.1060s	
4005/5250 (epoch 38.143), train_loss = 1.26629500, grad/param norm = 5.1525e-02, time/batch = 0.1069s	
4006/5250 (epoch 38.152), train_loss = 1.26595469, grad/param norm = 5.0509e-02, time/batch = 0.1065s	
4007/5250 (epoch 38.162), train_loss = 1.29328647, grad/param norm = 5.1078e-02, time/batch = 0.1057s	
4008/5250 (epoch 38.171), train_loss = 1.29306390, grad/param norm = 4.8489e-02, time/batch = 0.0959s	
4009/5250 (epoch 38.181), train_loss = 1.30093053, grad/param norm = 5.3151e-02, time/batch = 0.1009s	
4010/5250 (epoch 38.190), train_loss = 1.29469167, grad/param norm = 5.0224e-02, time/batch = 0.0952s	
4011/5250 (epoch 38.200), train_loss = 1.28022555, grad/param norm = 5.3826e-02, time/batch = 0.0966s	
4012/5250 (epoch 38.210), train_loss = 1.28151735, grad/param norm = 5.0409e-02, time/batch = 0.0939s	
4013/5250 (epoch 38.219), train_loss = 1.32748122, grad/param norm = 5.1659e-02, time/batch = 0.0933s	
4014/5250 (epoch 38.229), train_loss = 1.28204566, grad/param norm = 4.9335e-02, time/batch = 0.0935s	
4015/5250 (epoch 38.238), train_loss = 1.28611410, grad/param norm = 5.2403e-02, time/batch = 0.0936s	
4016/5250 (epoch 38.248), train_loss = 1.29075660, grad/param norm = 5.1972e-02, time/batch = 0.0939s	
4017/5250 (epoch 38.257), train_loss = 1.28263340, grad/param norm = 4.9802e-02, time/batch = 0.0936s	
4018/5250 (epoch 38.267), train_loss = 1.27076253, grad/param norm = 5.3497e-02, time/batch = 0.0837s	
4019/5250 (epoch 38.276), train_loss = 1.27161655, grad/param norm = 4.7833e-02, time/batch = 0.0772s	
4020/5250 (epoch 38.286), train_loss = 1.25742992, grad/param norm = 5.1796e-02, time/batch = 0.0766s	
4021/5250 (epoch 38.295), train_loss = 1.28338107, grad/param norm = 5.0598e-02, time/batch = 0.0787s	
4022/5250 (epoch 38.305), train_loss = 1.27537465, grad/param norm = 5.2342e-02, time/batch = 0.0768s	
4023/5250 (epoch 38.314), train_loss = 1.26802629, grad/param norm = 5.1272e-02, time/batch = 0.0771s	
4024/5250 (epoch 38.324), train_loss = 1.28023648, grad/param norm = 5.3427e-02, time/batch = 0.0768s	
4025/5250 (epoch 38.333), train_loss = 1.28187790, grad/param norm = 5.0239e-02, time/batch = 0.0768s	
4026/5250 (epoch 38.343), train_loss = 1.28501746, grad/param norm = 5.1341e-02, time/batch = 0.0769s	
4027/5250 (epoch 38.352), train_loss = 1.29696731, grad/param norm = 5.4565e-02, time/batch = 0.0765s	
4028/5250 (epoch 38.362), train_loss = 1.29533886, grad/param norm = 5.5064e-02, time/batch = 0.0764s	
4029/5250 (epoch 38.371), train_loss = 1.27609211, grad/param norm = 5.0003e-02, time/batch = 0.0774s	
4030/5250 (epoch 38.381), train_loss = 1.27281920, grad/param norm = 5.1191e-02, time/batch = 0.0770s	
4031/5250 (epoch 38.390), train_loss = 1.28274436, grad/param norm = 5.6083e-02, time/batch = 0.0787s	
4032/5250 (epoch 38.400), train_loss = 1.28798861, grad/param norm = 5.1413e-02, time/batch = 0.0769s	
4033/5250 (epoch 38.410), train_loss = 1.29157077, grad/param norm = 5.3801e-02, time/batch = 0.0767s	
4034/5250 (epoch 38.419), train_loss = 1.28353065, grad/param norm = 5.2794e-02, time/batch = 0.0775s	
4035/5250 (epoch 38.429), train_loss = 1.29242889, grad/param norm = 4.9797e-02, time/batch = 0.0767s	
4036/5250 (epoch 38.438), train_loss = 1.31105237, grad/param norm = 5.7546e-02, time/batch = 0.0770s	
4037/5250 (epoch 38.448), train_loss = 1.27229904, grad/param norm = 5.3030e-02, time/batch = 0.0769s	
4038/5250 (epoch 38.457), train_loss = 1.27555921, grad/param norm = 5.3713e-02, time/batch = 0.0766s	
4039/5250 (epoch 38.467), train_loss = 1.28292679, grad/param norm = 5.1144e-02, time/batch = 0.0770s	
4040/5250 (epoch 38.476), train_loss = 1.27811080, grad/param norm = 5.3577e-02, time/batch = 0.0776s	
4041/5250 (epoch 38.486), train_loss = 1.30010341, grad/param norm = 5.5437e-02, time/batch = 0.0787s	
4042/5250 (epoch 38.495), train_loss = 1.30163640, grad/param norm = 5.6097e-02, time/batch = 0.0769s	
4043/5250 (epoch 38.505), train_loss = 1.30841520, grad/param norm = 6.3196e-02, time/batch = 0.0766s	
4044/5250 (epoch 38.514), train_loss = 1.30146356, grad/param norm = 5.5470e-02, time/batch = 0.0768s	
4045/5250 (epoch 38.524), train_loss = 1.27912633, grad/param norm = 5.5933e-02, time/batch = 0.0771s	
4046/5250 (epoch 38.533), train_loss = 1.29002959, grad/param norm = 5.9486e-02, time/batch = 0.0771s	
4047/5250 (epoch 38.543), train_loss = 1.27814167, grad/param norm = 5.3573e-02, time/batch = 0.0760s	
4048/5250 (epoch 38.552), train_loss = 1.28520042, grad/param norm = 5.4113e-02, time/batch = 0.0765s	
4049/5250 (epoch 38.562), train_loss = 1.28288493, grad/param norm = 5.0815e-02, time/batch = 0.0770s	
4050/5250 (epoch 38.571), train_loss = 1.28787996, grad/param norm = 5.3113e-02, time/batch = 0.0766s	
4051/5250 (epoch 38.581), train_loss = 1.32017176, grad/param norm = 5.5945e-02, time/batch = 0.0787s	
4052/5250 (epoch 38.590), train_loss = 1.28988866, grad/param norm = 5.2302e-02, time/batch = 0.0768s	
4053/5250 (epoch 38.600), train_loss = 1.31359771, grad/param norm = 5.4134e-02, time/batch = 0.0767s	
4054/5250 (epoch 38.610), train_loss = 1.30088598, grad/param norm = 5.7848e-02, time/batch = 0.0767s	
4055/5250 (epoch 38.619), train_loss = 1.29001827, grad/param norm = 5.6812e-02, time/batch = 0.0767s	
4056/5250 (epoch 38.629), train_loss = 1.29863539, grad/param norm = 5.2676e-02, time/batch = 0.0778s	
4057/5250 (epoch 38.638), train_loss = 1.27945126, grad/param norm = 4.8809e-02, time/batch = 0.0766s	
4058/5250 (epoch 38.648), train_loss = 1.28844653, grad/param norm = 5.0966e-02, time/batch = 0.0765s	
4059/5250 (epoch 38.657), train_loss = 1.28835642, grad/param norm = 5.0239e-02, time/batch = 0.0767s	
4060/5250 (epoch 38.667), train_loss = 1.29440910, grad/param norm = 5.3926e-02, time/batch = 0.0765s	
4061/5250 (epoch 38.676), train_loss = 1.29006808, grad/param norm = 5.5906e-02, time/batch = 0.0785s	
4062/5250 (epoch 38.686), train_loss = 1.31673611, grad/param norm = 4.9670e-02, time/batch = 0.0774s	
4063/5250 (epoch 38.695), train_loss = 1.29733133, grad/param norm = 5.7840e-02, time/batch = 0.0769s	
4064/5250 (epoch 38.705), train_loss = 1.28034811, grad/param norm = 5.4830e-02, time/batch = 0.0766s	
4065/5250 (epoch 38.714), train_loss = 1.31410750, grad/param norm = 5.6576e-02, time/batch = 0.0769s	
4066/5250 (epoch 38.724), train_loss = 1.29188706, grad/param norm = 4.9920e-02, time/batch = 0.0771s	
4067/5250 (epoch 38.733), train_loss = 1.27152560, grad/param norm = 5.0025e-02, time/batch = 0.0764s	
4068/5250 (epoch 38.743), train_loss = 1.27871171, grad/param norm = 5.5751e-02, time/batch = 0.0764s	
4069/5250 (epoch 38.752), train_loss = 1.28781892, grad/param norm = 5.5656e-02, time/batch = 0.0769s	
4070/5250 (epoch 38.762), train_loss = 1.27640829, grad/param norm = 5.0409e-02, time/batch = 0.0768s	
4071/5250 (epoch 38.771), train_loss = 1.27212856, grad/param norm = 5.4859e-02, time/batch = 0.0786s	
4072/5250 (epoch 38.781), train_loss = 1.29898253, grad/param norm = 5.7263e-02, time/batch = 0.0767s	
4073/5250 (epoch 38.790), train_loss = 1.30934610, grad/param norm = 5.5320e-02, time/batch = 0.0772s	
4074/5250 (epoch 38.800), train_loss = 1.28994336, grad/param norm = 5.5330e-02, time/batch = 0.0764s	
4075/5250 (epoch 38.810), train_loss = 1.29235240, grad/param norm = 5.1206e-02, time/batch = 0.0770s	
4076/5250 (epoch 38.819), train_loss = 1.29922857, grad/param norm = 5.3837e-02, time/batch = 0.0772s	
4077/5250 (epoch 38.829), train_loss = 1.29551853, grad/param norm = 5.3945e-02, time/batch = 0.0764s	
4078/5250 (epoch 38.838), train_loss = 1.27917305, grad/param norm = 5.1339e-02, time/batch = 0.0766s	
4079/5250 (epoch 38.848), train_loss = 1.27650657, grad/param norm = 5.0966e-02, time/batch = 0.0773s	
4080/5250 (epoch 38.857), train_loss = 1.28986964, grad/param norm = 5.0020e-02, time/batch = 0.0768s	
4081/5250 (epoch 38.867), train_loss = 1.28739501, grad/param norm = 5.0519e-02, time/batch = 0.0787s	
4082/5250 (epoch 38.876), train_loss = 1.29099245, grad/param norm = 4.8053e-02, time/batch = 0.0766s	
4083/5250 (epoch 38.886), train_loss = 1.27683742, grad/param norm = 5.1302e-02, time/batch = 0.0766s	
4084/5250 (epoch 38.895), train_loss = 1.32022686, grad/param norm = 6.0242e-02, time/batch = 0.0771s	
4085/5250 (epoch 38.905), train_loss = 1.30595350, grad/param norm = 5.3565e-02, time/batch = 0.0769s	
4086/5250 (epoch 38.914), train_loss = 1.32016551, grad/param norm = 5.3743e-02, time/batch = 0.0774s	
4087/5250 (epoch 38.924), train_loss = 1.31121011, grad/param norm = 5.1954e-02, time/batch = 0.0763s	
4088/5250 (epoch 38.933), train_loss = 1.28224110, grad/param norm = 5.3177e-02, time/batch = 0.0764s	
4089/5250 (epoch 38.943), train_loss = 1.32155913, grad/param norm = 5.6108e-02, time/batch = 0.0770s	
4090/5250 (epoch 38.952), train_loss = 1.31896042, grad/param norm = 5.3905e-02, time/batch = 0.0772s	
4091/5250 (epoch 38.962), train_loss = 1.29703780, grad/param norm = 5.0390e-02, time/batch = 0.0796s	
4092/5250 (epoch 38.971), train_loss = 1.29277239, grad/param norm = 5.3815e-02, time/batch = 0.0771s	
4093/5250 (epoch 38.981), train_loss = 1.31456944, grad/param norm = 5.3321e-02, time/batch = 0.0768s	
4094/5250 (epoch 38.990), train_loss = 1.31671125, grad/param norm = 5.9576e-02, time/batch = 0.0766s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
4095/5250 (epoch 39.000), train_loss = 1.30340068, grad/param norm = 5.7720e-02, time/batch = 0.0773s	
4096/5250 (epoch 39.010), train_loss = 1.49874997, grad/param norm = 6.6094e-02, time/batch = 0.0770s	
4097/5250 (epoch 39.019), train_loss = 1.28342175, grad/param norm = 6.1635e-02, time/batch = 0.0764s	
4098/5250 (epoch 39.029), train_loss = 1.29561594, grad/param norm = 5.2606e-02, time/batch = 0.0762s	
4099/5250 (epoch 39.038), train_loss = 1.28469757, grad/param norm = 5.2950e-02, time/batch = 0.0778s	
4100/5250 (epoch 39.048), train_loss = 1.26328938, grad/param norm = 5.1740e-02, time/batch = 0.0770s	
4101/5250 (epoch 39.057), train_loss = 1.27713531, grad/param norm = 4.8670e-02, time/batch = 0.0789s	
4102/5250 (epoch 39.067), train_loss = 1.28738652, grad/param norm = 4.8521e-02, time/batch = 0.0767s	
4103/5250 (epoch 39.076), train_loss = 1.29164084, grad/param norm = 5.5907e-02, time/batch = 0.0768s	
4104/5250 (epoch 39.086), train_loss = 1.24219238, grad/param norm = 5.6334e-02, time/batch = 0.0764s	
4105/5250 (epoch 39.095), train_loss = 1.26807280, grad/param norm = 4.9272e-02, time/batch = 0.0769s	
4106/5250 (epoch 39.105), train_loss = 1.28906984, grad/param norm = 5.1451e-02, time/batch = 0.0777s	
4107/5250 (epoch 39.114), train_loss = 1.27030340, grad/param norm = 5.4680e-02, time/batch = 0.0767s	
4108/5250 (epoch 39.124), train_loss = 1.29139404, grad/param norm = 5.7320e-02, time/batch = 0.0762s	
4109/5250 (epoch 39.133), train_loss = 1.27679184, grad/param norm = 5.2167e-02, time/batch = 0.0770s	
4110/5250 (epoch 39.143), train_loss = 1.26241403, grad/param norm = 5.1263e-02, time/batch = 0.0775s	
4111/5250 (epoch 39.152), train_loss = 1.26328723, grad/param norm = 5.0966e-02, time/batch = 0.0787s	
4112/5250 (epoch 39.162), train_loss = 1.29056482, grad/param norm = 5.1630e-02, time/batch = 0.0774s	
4113/5250 (epoch 39.171), train_loss = 1.28955916, grad/param norm = 4.8382e-02, time/batch = 0.0768s	
4114/5250 (epoch 39.181), train_loss = 1.29795975, grad/param norm = 5.3617e-02, time/batch = 0.0763s	
4115/5250 (epoch 39.190), train_loss = 1.29177496, grad/param norm = 5.0547e-02, time/batch = 0.0768s	
4116/5250 (epoch 39.200), train_loss = 1.27701947, grad/param norm = 5.3921e-02, time/batch = 0.0773s	
4117/5250 (epoch 39.210), train_loss = 1.27852041, grad/param norm = 5.0654e-02, time/batch = 0.0764s	
4118/5250 (epoch 39.219), train_loss = 1.32448884, grad/param norm = 5.1588e-02, time/batch = 0.0762s	
4119/5250 (epoch 39.229), train_loss = 1.27902334, grad/param norm = 4.9663e-02, time/batch = 0.0828s	
4120/5250 (epoch 39.238), train_loss = 1.28311209, grad/param norm = 5.2752e-02, time/batch = 0.0776s	
4121/5250 (epoch 39.248), train_loss = 1.28768809, grad/param norm = 5.1610e-02, time/batch = 0.0789s	
4122/5250 (epoch 39.257), train_loss = 1.28002273, grad/param norm = 4.9993e-02, time/batch = 0.0767s	
4123/5250 (epoch 39.267), train_loss = 1.26745627, grad/param norm = 5.2921e-02, time/batch = 0.0773s	
4124/5250 (epoch 39.276), train_loss = 1.26861654, grad/param norm = 4.8335e-02, time/batch = 0.0767s	
4125/5250 (epoch 39.286), train_loss = 1.25435156, grad/param norm = 5.1367e-02, time/batch = 0.0767s	
4126/5250 (epoch 39.295), train_loss = 1.28057771, grad/param norm = 5.1154e-02, time/batch = 0.0773s	
4127/5250 (epoch 39.305), train_loss = 1.27248287, grad/param norm = 5.3633e-02, time/batch = 0.0767s	
4128/5250 (epoch 39.314), train_loss = 1.26511552, grad/param norm = 5.0865e-02, time/batch = 0.0764s	
4129/5250 (epoch 39.324), train_loss = 1.27698671, grad/param norm = 5.2159e-02, time/batch = 0.0773s	
4130/5250 (epoch 39.333), train_loss = 1.27882927, grad/param norm = 5.0872e-02, time/batch = 0.0767s	
4131/5250 (epoch 39.343), train_loss = 1.28158392, grad/param norm = 5.0920e-02, time/batch = 0.0787s	
4132/5250 (epoch 39.352), train_loss = 1.29361808, grad/param norm = 5.3084e-02, time/batch = 0.0766s	
4133/5250 (epoch 39.362), train_loss = 1.29213983, grad/param norm = 5.3857e-02, time/batch = 0.0765s	
4134/5250 (epoch 39.371), train_loss = 1.27322637, grad/param norm = 5.0039e-02, time/batch = 0.0774s	
4135/5250 (epoch 39.381), train_loss = 1.26953646, grad/param norm = 5.0342e-02, time/batch = 0.0767s	
4136/5250 (epoch 39.390), train_loss = 1.27943717, grad/param norm = 5.5548e-02, time/batch = 0.0772s	
4137/5250 (epoch 39.400), train_loss = 1.28483429, grad/param norm = 5.0812e-02, time/batch = 0.0766s	
4138/5250 (epoch 39.410), train_loss = 1.28810004, grad/param norm = 5.3533e-02, time/batch = 0.0765s	
4139/5250 (epoch 39.419), train_loss = 1.28045149, grad/param norm = 5.2707e-02, time/batch = 0.0767s	
4140/5250 (epoch 39.429), train_loss = 1.28928263, grad/param norm = 4.9558e-02, time/batch = 0.0771s	
4141/5250 (epoch 39.438), train_loss = 1.30809599, grad/param norm = 5.7605e-02, time/batch = 0.0785s	
4142/5250 (epoch 39.448), train_loss = 1.26937063, grad/param norm = 5.3470e-02, time/batch = 0.0765s	
4143/5250 (epoch 39.457), train_loss = 1.27268743, grad/param norm = 5.4109e-02, time/batch = 0.0765s	
4144/5250 (epoch 39.467), train_loss = 1.27981616, grad/param norm = 5.0879e-02, time/batch = 0.0767s	
4145/5250 (epoch 39.476), train_loss = 1.27487331, grad/param norm = 5.2944e-02, time/batch = 0.0772s	
4146/5250 (epoch 39.486), train_loss = 1.29701599, grad/param norm = 5.4992e-02, time/batch = 0.0770s	
4147/5250 (epoch 39.495), train_loss = 1.29811282, grad/param norm = 5.4674e-02, time/batch = 0.0766s	
4148/5250 (epoch 39.505), train_loss = 1.30484396, grad/param norm = 6.1569e-02, time/batch = 0.0765s	
4149/5250 (epoch 39.514), train_loss = 1.29805632, grad/param norm = 5.4298e-02, time/batch = 0.0771s	
4150/5250 (epoch 39.524), train_loss = 1.27609742, grad/param norm = 5.6521e-02, time/batch = 0.0769s	
4151/5250 (epoch 39.533), train_loss = 1.28708558, grad/param norm = 5.9319e-02, time/batch = 0.0787s	
4152/5250 (epoch 39.543), train_loss = 1.27503381, grad/param norm = 5.3311e-02, time/batch = 0.0767s	
4153/5250 (epoch 39.552), train_loss = 1.28197815, grad/param norm = 5.3665e-02, time/batch = 0.0765s	
4154/5250 (epoch 39.562), train_loss = 1.27984728, grad/param norm = 5.0776e-02, time/batch = 0.0767s	
4155/5250 (epoch 39.571), train_loss = 1.28478552, grad/param norm = 5.2778e-02, time/batch = 0.0766s	
4156/5250 (epoch 39.581), train_loss = 1.31689029, grad/param norm = 5.5501e-02, time/batch = 0.0774s	
4157/5250 (epoch 39.590), train_loss = 1.28658204, grad/param norm = 5.2179e-02, time/batch = 0.0765s	
4158/5250 (epoch 39.600), train_loss = 1.31065259, grad/param norm = 5.3849e-02, time/batch = 0.0763s	
4159/5250 (epoch 39.610), train_loss = 1.29766397, grad/param norm = 5.7230e-02, time/batch = 0.0769s	
4160/5250 (epoch 39.619), train_loss = 1.28697535, grad/param norm = 5.6412e-02, time/batch = 0.0771s	
4161/5250 (epoch 39.629), train_loss = 1.29529724, grad/param norm = 5.2475e-02, time/batch = 0.0787s	
4162/5250 (epoch 39.638), train_loss = 1.27648611, grad/param norm = 4.8621e-02, time/batch = 0.0773s	
4163/5250 (epoch 39.648), train_loss = 1.28542453, grad/param norm = 5.1167e-02, time/batch = 0.0770s	
4164/5250 (epoch 39.657), train_loss = 1.28533630, grad/param norm = 5.0622e-02, time/batch = 0.0764s	
4165/5250 (epoch 39.667), train_loss = 1.29152629, grad/param norm = 5.3706e-02, time/batch = 0.0767s	
4166/5250 (epoch 39.676), train_loss = 1.28665917, grad/param norm = 5.5383e-02, time/batch = 0.0773s	
4167/5250 (epoch 39.686), train_loss = 1.31364012, grad/param norm = 4.9464e-02, time/batch = 0.0768s	
4168/5250 (epoch 39.695), train_loss = 1.29424881, grad/param norm = 5.7687e-02, time/batch = 0.0764s	
4169/5250 (epoch 39.705), train_loss = 1.27715406, grad/param norm = 5.4614e-02, time/batch = 0.0769s	
4170/5250 (epoch 39.714), train_loss = 1.31077260, grad/param norm = 5.6319e-02, time/batch = 0.0771s	
4171/5250 (epoch 39.724), train_loss = 1.28859506, grad/param norm = 4.9791e-02, time/batch = 0.0787s	
4172/5250 (epoch 39.733), train_loss = 1.26835667, grad/param norm = 4.9873e-02, time/batch = 0.0768s	
4173/5250 (epoch 39.743), train_loss = 1.27555283, grad/param norm = 5.5588e-02, time/batch = 0.0777s	
4174/5250 (epoch 39.752), train_loss = 1.28464181, grad/param norm = 5.5375e-02, time/batch = 0.0768s	
4175/5250 (epoch 39.762), train_loss = 1.27325412, grad/param norm = 5.0315e-02, time/batch = 0.0767s	
4176/5250 (epoch 39.771), train_loss = 1.26920301, grad/param norm = 5.4664e-02, time/batch = 0.0770s	
4177/5250 (epoch 39.781), train_loss = 1.29594212, grad/param norm = 5.5810e-02, time/batch = 0.0763s	
4178/5250 (epoch 39.790), train_loss = 1.30641681, grad/param norm = 6.0688e-02, time/batch = 0.0763s	
4179/5250 (epoch 39.800), train_loss = 1.28759591, grad/param norm = 5.7927e-02, time/batch = 0.0774s	
4180/5250 (epoch 39.810), train_loss = 1.28993116, grad/param norm = 5.1368e-02, time/batch = 0.0765s	
4181/5250 (epoch 39.819), train_loss = 1.29627934, grad/param norm = 5.4600e-02, time/batch = 0.0786s	
4182/5250 (epoch 39.829), train_loss = 1.29213948, grad/param norm = 5.2916e-02, time/batch = 0.0768s	
4183/5250 (epoch 39.838), train_loss = 1.27635020, grad/param norm = 5.1610e-02, time/batch = 0.0769s	
4184/5250 (epoch 39.848), train_loss = 1.27361328, grad/param norm = 5.1838e-02, time/batch = 0.0775s	
4185/5250 (epoch 39.857), train_loss = 1.28711730, grad/param norm = 5.0103e-02, time/batch = 0.0770s	
4186/5250 (epoch 39.867), train_loss = 1.28472530, grad/param norm = 5.1302e-02, time/batch = 0.0770s	
4187/5250 (epoch 39.876), train_loss = 1.28781708, grad/param norm = 4.8235e-02, time/batch = 0.0767s	
4188/5250 (epoch 39.886), train_loss = 1.27375411, grad/param norm = 5.0736e-02, time/batch = 0.0765s	
4189/5250 (epoch 39.895), train_loss = 1.31678690, grad/param norm = 5.8610e-02, time/batch = 0.0768s	
4190/5250 (epoch 39.905), train_loss = 1.30250146, grad/param norm = 5.1518e-02, time/batch = 0.0771s	
4191/5250 (epoch 39.914), train_loss = 1.31661795, grad/param norm = 5.2788e-02, time/batch = 0.0786s	
4192/5250 (epoch 39.924), train_loss = 1.30802822, grad/param norm = 5.1590e-02, time/batch = 0.0766s	
4193/5250 (epoch 39.933), train_loss = 1.27888815, grad/param norm = 5.2637e-02, time/batch = 0.0765s	
4194/5250 (epoch 39.943), train_loss = 1.31835106, grad/param norm = 5.6231e-02, time/batch = 0.0767s	
4195/5250 (epoch 39.952), train_loss = 1.31560887, grad/param norm = 5.3520e-02, time/batch = 0.0771s	
4196/5250 (epoch 39.962), train_loss = 1.29383612, grad/param norm = 4.9545e-02, time/batch = 0.0772s	
4197/5250 (epoch 39.971), train_loss = 1.28972889, grad/param norm = 5.3193e-02, time/batch = 0.0765s	
4198/5250 (epoch 39.981), train_loss = 1.31112994, grad/param norm = 5.2614e-02, time/batch = 0.0765s	
4199/5250 (epoch 39.990), train_loss = 1.31343239, grad/param norm = 5.8888e-02, time/batch = 0.0774s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
4200/5250 (epoch 40.000), train_loss = 1.30036457, grad/param norm = 5.6745e-02, time/batch = 0.0767s	
4201/5250 (epoch 40.010), train_loss = 1.49659491, grad/param norm = 6.5521e-02, time/batch = 0.0787s	
4202/5250 (epoch 40.019), train_loss = 1.28017657, grad/param norm = 6.0649e-02, time/batch = 0.0765s	
4203/5250 (epoch 40.029), train_loss = 1.29251735, grad/param norm = 5.1780e-02, time/batch = 0.0768s	
4204/5250 (epoch 40.038), train_loss = 1.28154380, grad/param norm = 5.2231e-02, time/batch = 0.0767s	
4205/5250 (epoch 40.048), train_loss = 1.26015500, grad/param norm = 5.1379e-02, time/batch = 0.0768s	
4206/5250 (epoch 40.057), train_loss = 1.27410633, grad/param norm = 4.8610e-02, time/batch = 0.0778s	
4207/5250 (epoch 40.067), train_loss = 1.28445818, grad/param norm = 4.8320e-02, time/batch = 0.0765s	
4208/5250 (epoch 40.076), train_loss = 1.28870174, grad/param norm = 5.5618e-02, time/batch = 0.0767s	
4209/5250 (epoch 40.086), train_loss = 1.23927643, grad/param norm = 5.5956e-02, time/batch = 0.0769s	
4210/5250 (epoch 40.095), train_loss = 1.26484819, grad/param norm = 4.8930e-02, time/batch = 0.0767s	
4211/5250 (epoch 40.105), train_loss = 1.28590153, grad/param norm = 5.1392e-02, time/batch = 0.0787s	
4212/5250 (epoch 40.114), train_loss = 1.26721864, grad/param norm = 5.4487e-02, time/batch = 0.0771s	
4213/5250 (epoch 40.124), train_loss = 1.28830753, grad/param norm = 5.6642e-02, time/batch = 0.0764s	
4214/5250 (epoch 40.133), train_loss = 1.27370658, grad/param norm = 5.1449e-02, time/batch = 0.0768s	
4215/5250 (epoch 40.143), train_loss = 1.25941463, grad/param norm = 5.1194e-02, time/batch = 0.0769s	
4216/5250 (epoch 40.152), train_loss = 1.26036794, grad/param norm = 5.0606e-02, time/batch = 0.0771s	
4217/5250 (epoch 40.162), train_loss = 1.28750699, grad/param norm = 5.1192e-02, time/batch = 0.0764s	
4218/5250 (epoch 40.171), train_loss = 1.28614541, grad/param norm = 4.8194e-02, time/batch = 0.0766s	
4219/5250 (epoch 40.181), train_loss = 1.29472804, grad/param norm = 5.3344e-02, time/batch = 0.0773s	
4220/5250 (epoch 40.190), train_loss = 1.28889111, grad/param norm = 5.0682e-02, time/batch = 0.0769s	
4221/5250 (epoch 40.200), train_loss = 1.27400320, grad/param norm = 5.3806e-02, time/batch = 0.0787s	
4222/5250 (epoch 40.210), train_loss = 1.27554987, grad/param norm = 5.0364e-02, time/batch = 0.0768s	
4223/5250 (epoch 40.219), train_loss = 1.32136659, grad/param norm = 5.1168e-02, time/batch = 0.0770s	
4224/5250 (epoch 40.229), train_loss = 1.27591051, grad/param norm = 4.9651e-02, time/batch = 0.0769s	
4225/5250 (epoch 40.238), train_loss = 1.28016471, grad/param norm = 5.2621e-02, time/batch = 0.0768s	
4226/5250 (epoch 40.248), train_loss = 1.28467729, grad/param norm = 5.1527e-02, time/batch = 0.0770s	
4227/5250 (epoch 40.257), train_loss = 1.27726498, grad/param norm = 4.9920e-02, time/batch = 0.0764s	
4228/5250 (epoch 40.267), train_loss = 1.26450109, grad/param norm = 5.2869e-02, time/batch = 0.0762s	
4229/5250 (epoch 40.276), train_loss = 1.26558213, grad/param norm = 4.8038e-02, time/batch = 0.0776s	
4230/5250 (epoch 40.286), train_loss = 1.25138559, grad/param norm = 5.1181e-02, time/batch = 0.0815s	
4231/5250 (epoch 40.295), train_loss = 1.27775435, grad/param norm = 5.1096e-02, time/batch = 0.0797s	
4232/5250 (epoch 40.305), train_loss = 1.26933043, grad/param norm = 5.3101e-02, time/batch = 0.0771s	
4233/5250 (epoch 40.314), train_loss = 1.26218673, grad/param norm = 5.0819e-02, time/batch = 0.0771s	
4234/5250 (epoch 40.324), train_loss = 1.27418172, grad/param norm = 5.2219e-02, time/batch = 0.0773s	
4235/5250 (epoch 40.333), train_loss = 1.27577737, grad/param norm = 5.0642e-02, time/batch = 0.0768s	
4236/5250 (epoch 40.343), train_loss = 1.27860731, grad/param norm = 5.0912e-02, time/batch = 0.0772s	
4237/5250 (epoch 40.352), train_loss = 1.29067937, grad/param norm = 5.2987e-02, time/batch = 0.0764s	
4238/5250 (epoch 40.362), train_loss = 1.28913999, grad/param norm = 5.3724e-02, time/batch = 0.0762s	
4239/5250 (epoch 40.371), train_loss = 1.27032741, grad/param norm = 4.9745e-02, time/batch = 0.0766s	
4240/5250 (epoch 40.381), train_loss = 1.26650310, grad/param norm = 5.0090e-02, time/batch = 0.0773s	
4241/5250 (epoch 40.390), train_loss = 1.27625616, grad/param norm = 5.5035e-02, time/batch = 0.0786s	
4242/5250 (epoch 40.400), train_loss = 1.28179798, grad/param norm = 5.0462e-02, time/batch = 0.0769s	
4243/5250 (epoch 40.410), train_loss = 1.28486673, grad/param norm = 5.3737e-02, time/batch = 0.0771s	
4244/5250 (epoch 40.419), train_loss = 1.27752025, grad/param norm = 5.2292e-02, time/batch = 0.0768s	
4245/5250 (epoch 40.429), train_loss = 1.28637701, grad/param norm = 4.9653e-02, time/batch = 0.0772s	
4246/5250 (epoch 40.438), train_loss = 1.30521887, grad/param norm = 5.8064e-02, time/batch = 0.0772s	
4247/5250 (epoch 40.448), train_loss = 1.26631164, grad/param norm = 5.2778e-02, time/batch = 0.0767s	
4248/5250 (epoch 40.457), train_loss = 1.26970231, grad/param norm = 5.3355e-02, time/batch = 0.0764s	
4249/5250 (epoch 40.467), train_loss = 1.27680050, grad/param norm = 5.0505e-02, time/batch = 0.0767s	
4250/5250 (epoch 40.476), train_loss = 1.27183563, grad/param norm = 5.2803e-02, time/batch = 0.0768s	
4251/5250 (epoch 40.486), train_loss = 1.29409400, grad/param norm = 5.4701e-02, time/batch = 0.0788s	
4252/5250 (epoch 40.495), train_loss = 1.29518898, grad/param norm = 5.5189e-02, time/batch = 0.0769s	
4253/5250 (epoch 40.505), train_loss = 1.30180310, grad/param norm = 6.1382e-02, time/batch = 0.0767s	
4254/5250 (epoch 40.514), train_loss = 1.29475998, grad/param norm = 5.2530e-02, time/batch = 0.0768s	
4255/5250 (epoch 40.524), train_loss = 1.27337003, grad/param norm = 5.8223e-02, time/batch = 0.0769s	
4256/5250 (epoch 40.533), train_loss = 1.28410696, grad/param norm = 5.9124e-02, time/batch = 0.0775s	
4257/5250 (epoch 40.543), train_loss = 1.27215240, grad/param norm = 5.3083e-02, time/batch = 0.0763s	
4258/5250 (epoch 40.552), train_loss = 1.27877170, grad/param norm = 5.3229e-02, time/batch = 0.0764s	
4259/5250 (epoch 40.562), train_loss = 1.27693263, grad/param norm = 5.0733e-02, time/batch = 0.0770s	
4260/5250 (epoch 40.571), train_loss = 1.28172877, grad/param norm = 5.2471e-02, time/batch = 0.0766s	
4261/5250 (epoch 40.581), train_loss = 1.31371963, grad/param norm = 5.5049e-02, time/batch = 0.0786s	
4262/5250 (epoch 40.590), train_loss = 1.28344304, grad/param norm = 5.1726e-02, time/batch = 0.0768s	
4263/5250 (epoch 40.600), train_loss = 1.30780714, grad/param norm = 5.3898e-02, time/batch = 0.0767s	
4264/5250 (epoch 40.610), train_loss = 1.29449717, grad/param norm = 5.6781e-02, time/batch = 0.0769s	
4265/5250 (epoch 40.619), train_loss = 1.28405149, grad/param norm = 5.5546e-02, time/batch = 0.0769s	
4266/5250 (epoch 40.629), train_loss = 1.29207372, grad/param norm = 5.2087e-02, time/batch = 0.0772s	
4267/5250 (epoch 40.638), train_loss = 1.27361459, grad/param norm = 4.8363e-02, time/batch = 0.0770s	
4268/5250 (epoch 40.648), train_loss = 1.28248925, grad/param norm = 5.0859e-02, time/batch = 0.0768s	
4269/5250 (epoch 40.657), train_loss = 1.28236686, grad/param norm = 5.0488e-02, time/batch = 0.0769s	
4270/5250 (epoch 40.667), train_loss = 1.28880610, grad/param norm = 5.3753e-02, time/batch = 0.0765s	
4271/5250 (epoch 40.676), train_loss = 1.28343301, grad/param norm = 5.5096e-02, time/batch = 0.0786s	
4272/5250 (epoch 40.686), train_loss = 1.31070218, grad/param norm = 4.9320e-02, time/batch = 0.0767s	
4273/5250 (epoch 40.695), train_loss = 1.29132145, grad/param norm = 5.7521e-02, time/batch = 0.0769s	
4274/5250 (epoch 40.705), train_loss = 1.27411409, grad/param norm = 5.4372e-02, time/batch = 0.0768s	
4275/5250 (epoch 40.714), train_loss = 1.30764491, grad/param norm = 5.6260e-02, time/batch = 0.0767s	
4276/5250 (epoch 40.724), train_loss = 1.28541954, grad/param norm = 4.9672e-02, time/batch = 0.0767s	
4277/5250 (epoch 40.733), train_loss = 1.26545983, grad/param norm = 4.9987e-02, time/batch = 0.0767s	
4278/5250 (epoch 40.743), train_loss = 1.27265938, grad/param norm = 5.5588e-02, time/batch = 0.0766s	
4279/5250 (epoch 40.752), train_loss = 1.28158138, grad/param norm = 5.4859e-02, time/batch = 0.0771s	
4280/5250 (epoch 40.762), train_loss = 1.27025151, grad/param norm = 5.0379e-02, time/batch = 0.0766s	
4281/5250 (epoch 40.771), train_loss = 1.26651207, grad/param norm = 5.4998e-02, time/batch = 0.0786s	
4282/5250 (epoch 40.781), train_loss = 1.29297944, grad/param norm = 5.4733e-02, time/batch = 0.0766s	
4283/5250 (epoch 40.790), train_loss = 1.30361111, grad/param norm = 5.9743e-02, time/batch = 0.0765s	
4284/5250 (epoch 40.800), train_loss = 1.28409401, grad/param norm = 5.6094e-02, time/batch = 0.0771s	
4285/5250 (epoch 40.810), train_loss = 1.28647515, grad/param norm = 5.1057e-02, time/batch = 0.0768s	
4286/5250 (epoch 40.819), train_loss = 1.29322670, grad/param norm = 5.4547e-02, time/batch = 0.0772s	
4287/5250 (epoch 40.829), train_loss = 1.28943334, grad/param norm = 5.2955e-02, time/batch = 0.0764s	
4288/5250 (epoch 40.838), train_loss = 1.27349625, grad/param norm = 5.1525e-02, time/batch = 0.0765s	
4289/5250 (epoch 40.848), train_loss = 1.27050246, grad/param norm = 5.0226e-02, time/batch = 0.0770s	
4290/5250 (epoch 40.857), train_loss = 1.28369100, grad/param norm = 4.9656e-02, time/batch = 0.0776s	
4291/5250 (epoch 40.867), train_loss = 1.28154635, grad/param norm = 5.0201e-02, time/batch = 0.0787s	
4292/5250 (epoch 40.876), train_loss = 1.28465199, grad/param norm = 4.7693e-02, time/batch = 0.0768s	
4293/5250 (epoch 40.886), train_loss = 1.27087658, grad/param norm = 5.1312e-02, time/batch = 0.0769s	
4294/5250 (epoch 40.895), train_loss = 1.31402508, grad/param norm = 5.9019e-02, time/batch = 0.0768s	
4295/5250 (epoch 40.905), train_loss = 1.29968511, grad/param norm = 5.1438e-02, time/batch = 0.0773s	
4296/5250 (epoch 40.914), train_loss = 1.31366955, grad/param norm = 5.2769e-02, time/batch = 0.0771s	
4297/5250 (epoch 40.924), train_loss = 1.30495217, grad/param norm = 5.1625e-02, time/batch = 0.0764s	
4298/5250 (epoch 40.933), train_loss = 1.27592478, grad/param norm = 5.2579e-02, time/batch = 0.0764s	
4299/5250 (epoch 40.943), train_loss = 1.31531080, grad/param norm = 5.5292e-02, time/batch = 0.0770s	
4300/5250 (epoch 40.952), train_loss = 1.31255640, grad/param norm = 5.3550e-02, time/batch = 0.0767s	
4301/5250 (epoch 40.962), train_loss = 1.29094444, grad/param norm = 4.9904e-02, time/batch = 0.0786s	
4302/5250 (epoch 40.971), train_loss = 1.28711656, grad/param norm = 5.3304e-02, time/batch = 0.0768s	
4303/5250 (epoch 40.981), train_loss = 1.30836656, grad/param norm = 5.3164e-02, time/batch = 0.0769s	
4304/5250 (epoch 40.990), train_loss = 1.31040892, grad/param norm = 5.8977e-02, time/batch = 0.0767s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
4305/5250 (epoch 41.000), train_loss = 1.29753357, grad/param norm = 5.6327e-02, time/batch = 0.0771s	
4306/5250 (epoch 41.010), train_loss = 1.49445035, grad/param norm = 6.5177e-02, time/batch = 0.0774s	
4307/5250 (epoch 41.019), train_loss = 1.27709671, grad/param norm = 5.9958e-02, time/batch = 0.0763s	
4308/5250 (epoch 41.029), train_loss = 1.28950143, grad/param norm = 5.1240e-02, time/batch = 0.0765s	
4309/5250 (epoch 41.038), train_loss = 1.27854848, grad/param norm = 5.1760e-02, time/batch = 0.0768s	
4310/5250 (epoch 41.048), train_loss = 1.25725813, grad/param norm = 5.1245e-02, time/batch = 0.0766s	
4311/5250 (epoch 41.057), train_loss = 1.27122986, grad/param norm = 4.8539e-02, time/batch = 0.0785s	
4312/5250 (epoch 41.067), train_loss = 1.28165942, grad/param norm = 4.8209e-02, time/batch = 0.0769s	
4313/5250 (epoch 41.076), train_loss = 1.28585545, grad/param norm = 5.5346e-02, time/batch = 0.0766s	
4314/5250 (epoch 41.086), train_loss = 1.23638363, grad/param norm = 5.5330e-02, time/batch = 0.0770s	
4315/5250 (epoch 41.095), train_loss = 1.26179093, grad/param norm = 4.8571e-02, time/batch = 0.0770s	
4316/5250 (epoch 41.105), train_loss = 1.28299748, grad/param norm = 5.1324e-02, time/batch = 0.0772s	
4317/5250 (epoch 41.114), train_loss = 1.26422626, grad/param norm = 5.4304e-02, time/batch = 0.0770s	
4318/5250 (epoch 41.124), train_loss = 1.28555373, grad/param norm = 5.6413e-02, time/batch = 0.0766s	
4319/5250 (epoch 41.133), train_loss = 1.27080142, grad/param norm = 5.0987e-02, time/batch = 0.0768s	
4320/5250 (epoch 41.143), train_loss = 1.25654079, grad/param norm = 5.0981e-02, time/batch = 0.0763s	
4321/5250 (epoch 41.152), train_loss = 1.25758381, grad/param norm = 5.0624e-02, time/batch = 0.0785s	
4322/5250 (epoch 41.162), train_loss = 1.28467045, grad/param norm = 5.1043e-02, time/batch = 0.0768s	
4323/5250 (epoch 41.171), train_loss = 1.28289156, grad/param norm = 4.8094e-02, time/batch = 0.0771s	
4324/5250 (epoch 41.181), train_loss = 1.29168534, grad/param norm = 5.3126e-02, time/batch = 0.0768s	
4325/5250 (epoch 41.190), train_loss = 1.28617843, grad/param norm = 5.0819e-02, time/batch = 0.0767s	
4326/5250 (epoch 41.200), train_loss = 1.27107843, grad/param norm = 5.3601e-02, time/batch = 0.0772s	
4327/5250 (epoch 41.210), train_loss = 1.27264122, grad/param norm = 5.0075e-02, time/batch = 0.0763s	
4328/5250 (epoch 41.219), train_loss = 1.31834196, grad/param norm = 5.0812e-02, time/batch = 0.0762s	
4329/5250 (epoch 41.229), train_loss = 1.27302598, grad/param norm = 4.9852e-02, time/batch = 0.0774s	
4330/5250 (epoch 41.238), train_loss = 1.27732385, grad/param norm = 5.2489e-02, time/batch = 0.0771s	
4331/5250 (epoch 41.248), train_loss = 1.28173908, grad/param norm = 5.1397e-02, time/batch = 0.0802s	
4332/5250 (epoch 41.257), train_loss = 1.27461852, grad/param norm = 4.9857e-02, time/batch = 0.0772s	
4333/5250 (epoch 41.267), train_loss = 1.26173368, grad/param norm = 5.2875e-02, time/batch = 0.0768s	
4334/5250 (epoch 41.276), train_loss = 1.26270727, grad/param norm = 4.7636e-02, time/batch = 0.0771s	
4335/5250 (epoch 41.286), train_loss = 1.24853341, grad/param norm = 5.1057e-02, time/batch = 0.0769s	
4336/5250 (epoch 41.295), train_loss = 1.27505365, grad/param norm = 5.0992e-02, time/batch = 0.0771s	
4337/5250 (epoch 41.305), train_loss = 1.26628722, grad/param norm = 5.2589e-02, time/batch = 0.0765s	
4338/5250 (epoch 41.314), train_loss = 1.25930429, grad/param norm = 5.0653e-02, time/batch = 0.0764s	
4339/5250 (epoch 41.324), train_loss = 1.27126234, grad/param norm = 5.1590e-02, time/batch = 0.0770s	
4340/5250 (epoch 41.333), train_loss = 1.27289394, grad/param norm = 5.0464e-02, time/batch = 0.0772s	
4341/5250 (epoch 41.343), train_loss = 1.27568739, grad/param norm = 5.0823e-02, time/batch = 0.0803s	
4342/5250 (epoch 41.352), train_loss = 1.28783187, grad/param norm = 5.2567e-02, time/batch = 0.0772s	
4343/5250 (epoch 41.362), train_loss = 1.28612531, grad/param norm = 5.3089e-02, time/batch = 0.0768s	
4344/5250 (epoch 41.371), train_loss = 1.26762624, grad/param norm = 4.9533e-02, time/batch = 0.0770s	
4345/5250 (epoch 41.381), train_loss = 1.26359495, grad/param norm = 4.9710e-02, time/batch = 0.0769s	
4346/5250 (epoch 41.390), train_loss = 1.27317321, grad/param norm = 5.4475e-02, time/batch = 0.0773s	
4347/5250 (epoch 41.400), train_loss = 1.27891871, grad/param norm = 5.0173e-02, time/batch = 0.0762s	
4348/5250 (epoch 41.410), train_loss = 1.28182137, grad/param norm = 5.4066e-02, time/batch = 0.0764s	
4349/5250 (epoch 41.419), train_loss = 1.27474610, grad/param norm = 5.2043e-02, time/batch = 0.0769s	
4350/5250 (epoch 41.429), train_loss = 1.28361656, grad/param norm = 4.9661e-02, time/batch = 0.0768s	
4351/5250 (epoch 41.438), train_loss = 1.30242872, grad/param norm = 5.8264e-02, time/batch = 0.0788s	
4352/5250 (epoch 41.448), train_loss = 1.26341889, grad/param norm = 5.2275e-02, time/batch = 0.0769s	
4353/5250 (epoch 41.457), train_loss = 1.26686649, grad/param norm = 5.2877e-02, time/batch = 0.0765s	
4354/5250 (epoch 41.467), train_loss = 1.27392980, grad/param norm = 5.0015e-02, time/batch = 0.0769s	
4355/5250 (epoch 41.476), train_loss = 1.26889688, grad/param norm = 5.2460e-02, time/batch = 0.0767s	
4356/5250 (epoch 41.486), train_loss = 1.29128028, grad/param norm = 5.4323e-02, time/batch = 0.0777s	
4357/5250 (epoch 41.495), train_loss = 1.29224337, grad/param norm = 5.4833e-02, time/batch = 0.0764s	
4358/5250 (epoch 41.505), train_loss = 1.29871112, grad/param norm = 6.0230e-02, time/batch = 0.0765s	
4359/5250 (epoch 41.514), train_loss = 1.29160937, grad/param norm = 5.1250e-02, time/batch = 0.0770s	
4360/5250 (epoch 41.524), train_loss = 1.27075006, grad/param norm = 5.9676e-02, time/batch = 0.0767s	
4361/5250 (epoch 41.533), train_loss = 1.28119244, grad/param norm = 5.8637e-02, time/batch = 0.0786s	
4362/5250 (epoch 41.543), train_loss = 1.26939096, grad/param norm = 5.3004e-02, time/batch = 0.0767s	
4363/5250 (epoch 41.552), train_loss = 1.27576073, grad/param norm = 5.2842e-02, time/batch = 0.0766s	
4364/5250 (epoch 41.562), train_loss = 1.27419136, grad/param norm = 5.0824e-02, time/batch = 0.0769s	
4365/5250 (epoch 41.571), train_loss = 1.27884278, grad/param norm = 5.2183e-02, time/batch = 0.0770s	
4366/5250 (epoch 41.581), train_loss = 1.31077714, grad/param norm = 5.4616e-02, time/batch = 0.0770s	
4367/5250 (epoch 41.590), train_loss = 1.28046013, grad/param norm = 5.1473e-02, time/batch = 0.0770s	
4368/5250 (epoch 41.600), train_loss = 1.30505829, grad/param norm = 5.3711e-02, time/batch = 0.0764s	
4369/5250 (epoch 41.610), train_loss = 1.29146410, grad/param norm = 5.6089e-02, time/batch = 0.0769s	
4370/5250 (epoch 41.619), train_loss = 1.28126166, grad/param norm = 5.4876e-02, time/batch = 0.0768s	
4371/5250 (epoch 41.629), train_loss = 1.28902887, grad/param norm = 5.1848e-02, time/batch = 0.0787s	
4372/5250 (epoch 41.638), train_loss = 1.27091590, grad/param norm = 4.8268e-02, time/batch = 0.0768s	
4373/5250 (epoch 41.648), train_loss = 1.27974139, grad/param norm = 5.0807e-02, time/batch = 0.0771s	
4374/5250 (epoch 41.657), train_loss = 1.27955593, grad/param norm = 5.0421e-02, time/batch = 0.0770s	
4375/5250 (epoch 41.667), train_loss = 1.28617929, grad/param norm = 5.3767e-02, time/batch = 0.0767s	
4376/5250 (epoch 41.676), train_loss = 1.28030838, grad/param norm = 5.4881e-02, time/batch = 0.0770s	
4377/5250 (epoch 41.686), train_loss = 1.30793019, grad/param norm = 4.9272e-02, time/batch = 0.0768s	
4378/5250 (epoch 41.695), train_loss = 1.28852630, grad/param norm = 5.7467e-02, time/batch = 0.0788s	
4379/5250 (epoch 41.705), train_loss = 1.27120064, grad/param norm = 5.4133e-02, time/batch = 0.0775s	
4380/5250 (epoch 41.714), train_loss = 1.30458192, grad/param norm = 5.6003e-02, time/batch = 0.0770s	
4381/5250 (epoch 41.724), train_loss = 1.28236693, grad/param norm = 4.9503e-02, time/batch = 0.0786s	
4382/5250 (epoch 41.733), train_loss = 1.26268839, grad/param norm = 4.9969e-02, time/batch = 0.0767s	
4383/5250 (epoch 41.743), train_loss = 1.26984726, grad/param norm = 5.5581e-02, time/batch = 0.0767s	
4384/5250 (epoch 41.752), train_loss = 1.27866819, grad/param norm = 5.4668e-02, time/batch = 0.0773s	
4385/5250 (epoch 41.762), train_loss = 1.26739062, grad/param norm = 5.0116e-02, time/batch = 0.0769s	
4386/5250 (epoch 41.771), train_loss = 1.26363405, grad/param norm = 5.4005e-02, time/batch = 0.0767s	
4387/5250 (epoch 41.781), train_loss = 1.29023745, grad/param norm = 5.4062e-02, time/batch = 0.0765s	
4388/5250 (epoch 41.790), train_loss = 1.30056280, grad/param norm = 6.0062e-02, time/batch = 0.0763s	
4389/5250 (epoch 41.800), train_loss = 1.28115741, grad/param norm = 5.5586e-02, time/batch = 0.0770s	
4390/5250 (epoch 41.810), train_loss = 1.28365304, grad/param norm = 5.1143e-02, time/batch = 0.0776s	
4391/5250 (epoch 41.819), train_loss = 1.29039607, grad/param norm = 5.4529e-02, time/batch = 0.0788s	
4392/5250 (epoch 41.829), train_loss = 1.28659950, grad/param norm = 5.2506e-02, time/batch = 0.0769s	
4393/5250 (epoch 41.838), train_loss = 1.27087028, grad/param norm = 5.0700e-02, time/batch = 0.0770s	
4394/5250 (epoch 41.848), train_loss = 1.26794322, grad/param norm = 5.0678e-02, time/batch = 0.0767s	
4395/5250 (epoch 41.857), train_loss = 1.28118481, grad/param norm = 4.9616e-02, time/batch = 0.0773s	
4396/5250 (epoch 41.867), train_loss = 1.27907519, grad/param norm = 5.0567e-02, time/batch = 0.0774s	
4397/5250 (epoch 41.876), train_loss = 1.28190162, grad/param norm = 4.7879e-02, time/batch = 0.0764s	
4398/5250 (epoch 41.886), train_loss = 1.26807256, grad/param norm = 5.0621e-02, time/batch = 0.0762s	
4399/5250 (epoch 41.895), train_loss = 1.31096659, grad/param norm = 5.7898e-02, time/batch = 0.0768s	
4400/5250 (epoch 41.905), train_loss = 1.29677071, grad/param norm = 5.0969e-02, time/batch = 0.0766s	
4401/5250 (epoch 41.914), train_loss = 1.31063693, grad/param norm = 5.2344e-02, time/batch = 0.0787s	
4402/5250 (epoch 41.924), train_loss = 1.30201816, grad/param norm = 5.1175e-02, time/batch = 0.0768s	
4403/5250 (epoch 41.933), train_loss = 1.27290115, grad/param norm = 5.2178e-02, time/batch = 0.0769s	
4404/5250 (epoch 41.943), train_loss = 1.31231338, grad/param norm = 5.5083e-02, time/batch = 0.0771s	
4405/5250 (epoch 41.952), train_loss = 1.30943302, grad/param norm = 5.3078e-02, time/batch = 0.0766s	
4406/5250 (epoch 41.962), train_loss = 1.28806741, grad/param norm = 4.9018e-02, time/batch = 0.0773s	
4407/5250 (epoch 41.971), train_loss = 1.28440850, grad/param norm = 5.3047e-02, time/batch = 0.0762s	
4408/5250 (epoch 41.981), train_loss = 1.30537432, grad/param norm = 5.2851e-02, time/batch = 0.0763s	
4409/5250 (epoch 41.990), train_loss = 1.30742398, grad/param norm = 5.8537e-02, time/batch = 0.0768s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
4410/5250 (epoch 42.000), train_loss = 1.29475863, grad/param norm = 5.5460e-02, time/batch = 0.0768s	
4411/5250 (epoch 42.010), train_loss = 1.49237620, grad/param norm = 6.4748e-02, time/batch = 0.0787s	
4412/5250 (epoch 42.019), train_loss = 1.27418951, grad/param norm = 5.9187e-02, time/batch = 0.0769s	
4413/5250 (epoch 42.029), train_loss = 1.28664894, grad/param norm = 5.0742e-02, time/batch = 0.0767s	
4414/5250 (epoch 42.038), train_loss = 1.27573922, grad/param norm = 5.1338e-02, time/batch = 0.0766s	
4415/5250 (epoch 42.048), train_loss = 1.25446121, grad/param norm = 5.1056e-02, time/batch = 0.0768s	
4416/5250 (epoch 42.057), train_loss = 1.26848529, grad/param norm = 4.8549e-02, time/batch = 0.0771s	
4417/5250 (epoch 42.067), train_loss = 1.27901692, grad/param norm = 4.8074e-02, time/batch = 0.0768s	
4418/5250 (epoch 42.076), train_loss = 1.28317051, grad/param norm = 5.5184e-02, time/batch = 0.0766s	
4419/5250 (epoch 42.086), train_loss = 1.23376424, grad/param norm = 5.5073e-02, time/batch = 0.0768s	
4420/5250 (epoch 42.095), train_loss = 1.25890058, grad/param norm = 4.8321e-02, time/batch = 0.0764s	
4421/5250 (epoch 42.105), train_loss = 1.28028756, grad/param norm = 5.1269e-02, time/batch = 0.0785s	
4422/5250 (epoch 42.114), train_loss = 1.26147872, grad/param norm = 5.4088e-02, time/batch = 0.0767s	
4423/5250 (epoch 42.124), train_loss = 1.28289274, grad/param norm = 5.5930e-02, time/batch = 0.0772s	
4424/5250 (epoch 42.133), train_loss = 1.26812096, grad/param norm = 5.0746e-02, time/batch = 0.0768s	
4425/5250 (epoch 42.143), train_loss = 1.25385052, grad/param norm = 5.1123e-02, time/batch = 0.0770s	
4426/5250 (epoch 42.152), train_loss = 1.25496382, grad/param norm = 5.0518e-02, time/batch = 0.0776s	
4427/5250 (epoch 42.162), train_loss = 1.28196860, grad/param norm = 5.0929e-02, time/batch = 0.0767s	
4428/5250 (epoch 42.171), train_loss = 1.27981016, grad/param norm = 4.7932e-02, time/batch = 0.0761s	
4429/5250 (epoch 42.181), train_loss = 1.28872902, grad/param norm = 5.2779e-02, time/batch = 0.0772s	
4430/5250 (epoch 42.190), train_loss = 1.28353878, grad/param norm = 5.0810e-02, time/batch = 0.0769s	
4431/5250 (epoch 42.200), train_loss = 1.26831311, grad/param norm = 5.3285e-02, time/batch = 0.0787s	
4432/5250 (epoch 42.210), train_loss = 1.26989649, grad/param norm = 4.9827e-02, time/batch = 0.0769s	
4433/5250 (epoch 42.219), train_loss = 1.31550817, grad/param norm = 5.0543e-02, time/batch = 0.0767s	
4434/5250 (epoch 42.229), train_loss = 1.27031993, grad/param norm = 5.0071e-02, time/batch = 0.0774s	
4435/5250 (epoch 42.238), train_loss = 1.27461802, grad/param norm = 5.2397e-02, time/batch = 0.0768s	
4436/5250 (epoch 42.248), train_loss = 1.27893737, grad/param norm = 5.1239e-02, time/batch = 0.0772s	
4437/5250 (epoch 42.257), train_loss = 1.27210211, grad/param norm = 4.9794e-02, time/batch = 0.0765s	
4438/5250 (epoch 42.267), train_loss = 1.25909938, grad/param norm = 5.2754e-02, time/batch = 0.0764s	
4439/5250 (epoch 42.276), train_loss = 1.25995871, grad/param norm = 4.7234e-02, time/batch = 0.0768s	
4440/5250 (epoch 42.286), train_loss = 1.24571089, grad/param norm = 5.0752e-02, time/batch = 0.0772s	
4441/5250 (epoch 42.295), train_loss = 1.27240621, grad/param norm = 5.0755e-02, time/batch = 0.0786s	
4442/5250 (epoch 42.305), train_loss = 1.26326018, grad/param norm = 5.1744e-02, time/batch = 0.0767s	
4443/5250 (epoch 42.314), train_loss = 1.25665850, grad/param norm = 5.1326e-02, time/batch = 0.0767s	
4444/5250 (epoch 42.324), train_loss = 1.26911771, grad/param norm = 5.3414e-02, time/batch = 0.0768s	
4445/5250 (epoch 42.333), train_loss = 1.27019165, grad/param norm = 5.0233e-02, time/batch = 0.0773s	
4446/5250 (epoch 42.343), train_loss = 1.27333962, grad/param norm = 5.1236e-02, time/batch = 0.0771s	
4447/5250 (epoch 42.352), train_loss = 1.28541923, grad/param norm = 5.3366e-02, time/batch = 0.0764s	
4448/5250 (epoch 42.362), train_loss = 1.28335567, grad/param norm = 5.3712e-02, time/batch = 0.0762s	
4449/5250 (epoch 42.371), train_loss = 1.26505681, grad/param norm = 4.9380e-02, time/batch = 0.0768s	
4450/5250 (epoch 42.381), train_loss = 1.26101763, grad/param norm = 5.0027e-02, time/batch = 0.0769s	
4451/5250 (epoch 42.390), train_loss = 1.27033379, grad/param norm = 5.4164e-02, time/batch = 0.0788s	
4452/5250 (epoch 42.400), train_loss = 1.27620006, grad/param norm = 4.9899e-02, time/batch = 0.0827s	
4453/5250 (epoch 42.410), train_loss = 1.27889257, grad/param norm = 5.3821e-02, time/batch = 0.0784s	
4454/5250 (epoch 42.419), train_loss = 1.27198079, grad/param norm = 5.1242e-02, time/batch = 0.0765s	
4455/5250 (epoch 42.429), train_loss = 1.28096351, grad/param norm = 5.0018e-02, time/batch = 0.0766s	
4456/5250 (epoch 42.438), train_loss = 1.29958652, grad/param norm = 5.7974e-02, time/batch = 0.0775s	
4457/5250 (epoch 42.448), train_loss = 1.26051555, grad/param norm = 5.0897e-02, time/batch = 0.0762s	
4458/5250 (epoch 42.457), train_loss = 1.26414315, grad/param norm = 5.2256e-02, time/batch = 0.0758s	
4459/5250 (epoch 42.467), train_loss = 1.27118423, grad/param norm = 4.9562e-02, time/batch = 0.0762s	
4460/5250 (epoch 42.476), train_loss = 1.26603331, grad/param norm = 5.2006e-02, time/batch = 0.0762s	
4461/5250 (epoch 42.486), train_loss = 1.28864132, grad/param norm = 5.4040e-02, time/batch = 0.0782s	
4462/5250 (epoch 42.495), train_loss = 1.28953394, grad/param norm = 5.4741e-02, time/batch = 0.0764s	
4463/5250 (epoch 42.505), train_loss = 1.29574755, grad/param norm = 5.9310e-02, time/batch = 0.0762s	
4464/5250 (epoch 42.514), train_loss = 1.28867138, grad/param norm = 5.0410e-02, time/batch = 0.0762s	
4465/5250 (epoch 42.524), train_loss = 1.26835012, grad/param norm = 6.1168e-02, time/batch = 0.0761s	
4466/5250 (epoch 42.533), train_loss = 1.27842486, grad/param norm = 5.7980e-02, time/batch = 0.0767s	
4467/5250 (epoch 42.543), train_loss = 1.26672090, grad/param norm = 5.3046e-02, time/batch = 0.0764s	
4468/5250 (epoch 42.552), train_loss = 1.27285832, grad/param norm = 5.2374e-02, time/batch = 0.0758s	
4469/5250 (epoch 42.562), train_loss = 1.27159182, grad/param norm = 5.1157e-02, time/batch = 0.0761s	
4470/5250 (epoch 42.571), train_loss = 1.27607618, grad/param norm = 5.1932e-02, time/batch = 0.0763s	
4471/5250 (epoch 42.581), train_loss = 1.30798681, grad/param norm = 5.4235e-02, time/batch = 0.0781s	
4472/5250 (epoch 42.590), train_loss = 1.27761120, grad/param norm = 5.1194e-02, time/batch = 0.0762s	
4473/5250 (epoch 42.600), train_loss = 1.30242955, grad/param norm = 5.3523e-02, time/batch = 0.0767s	
4474/5250 (epoch 42.610), train_loss = 1.28850172, grad/param norm = 5.5283e-02, time/batch = 0.0766s	
4475/5250 (epoch 42.619), train_loss = 1.27856005, grad/param norm = 5.4113e-02, time/batch = 0.0764s	
4476/5250 (epoch 42.629), train_loss = 1.28610868, grad/param norm = 5.1644e-02, time/batch = 0.0767s	
4477/5250 (epoch 42.638), train_loss = 1.26832343, grad/param norm = 4.8229e-02, time/batch = 0.0765s	
4478/5250 (epoch 42.648), train_loss = 1.27711392, grad/param norm = 5.0791e-02, time/batch = 0.0759s	
4479/5250 (epoch 42.657), train_loss = 1.27689159, grad/param norm = 5.0316e-02, time/batch = 0.0770s	
4480/5250 (epoch 42.667), train_loss = 1.28364818, grad/param norm = 5.3792e-02, time/batch = 0.0758s	
4481/5250 (epoch 42.676), train_loss = 1.27732057, grad/param norm = 5.4608e-02, time/batch = 0.0780s	
4482/5250 (epoch 42.686), train_loss = 1.30526841, grad/param norm = 4.9260e-02, time/batch = 0.0763s	
4483/5250 (epoch 42.695), train_loss = 1.28582621, grad/param norm = 5.7352e-02, time/batch = 0.0761s	
4484/5250 (epoch 42.705), train_loss = 1.26840055, grad/param norm = 5.3884e-02, time/batch = 0.0770s	
4485/5250 (epoch 42.714), train_loss = 1.30167308, grad/param norm = 5.5907e-02, time/batch = 0.0764s	
4486/5250 (epoch 42.724), train_loss = 1.27946254, grad/param norm = 4.9409e-02, time/batch = 0.0769s	
4487/5250 (epoch 42.733), train_loss = 1.26008120, grad/param norm = 5.0027e-02, time/batch = 0.0757s	
4488/5250 (epoch 42.743), train_loss = 1.26723587, grad/param norm = 5.5525e-02, time/batch = 0.0755s	
4489/5250 (epoch 42.752), train_loss = 1.27582523, grad/param norm = 5.4271e-02, time/batch = 0.0767s	
4490/5250 (epoch 42.762), train_loss = 1.26467223, grad/param norm = 5.0131e-02, time/batch = 0.0773s	
4491/5250 (epoch 42.771), train_loss = 1.26117444, grad/param norm = 5.4256e-02, time/batch = 0.0784s	
4492/5250 (epoch 42.781), train_loss = 1.28757130, grad/param norm = 5.3692e-02, time/batch = 0.0761s	
4493/5250 (epoch 42.790), train_loss = 1.29772313, grad/param norm = 6.0113e-02, time/batch = 0.0764s	
4494/5250 (epoch 42.800), train_loss = 1.27832416, grad/param norm = 5.5044e-02, time/batch = 0.0762s	
4495/5250 (epoch 42.810), train_loss = 1.28084185, grad/param norm = 5.1019e-02, time/batch = 0.0770s	
4496/5250 (epoch 42.819), train_loss = 1.28762338, grad/param norm = 5.4113e-02, time/batch = 0.0768s	
4497/5250 (epoch 42.829), train_loss = 1.28385368, grad/param norm = 5.2140e-02, time/batch = 0.0757s	
4498/5250 (epoch 42.838), train_loss = 1.26827267, grad/param norm = 5.0469e-02, time/batch = 0.0756s	
4499/5250 (epoch 42.848), train_loss = 1.26524603, grad/param norm = 4.9922e-02, time/batch = 0.0761s	
4500/5250 (epoch 42.857), train_loss = 1.27826056, grad/param norm = 4.9506e-02, time/batch = 0.0763s	
4501/5250 (epoch 42.867), train_loss = 1.27636306, grad/param norm = 5.0298e-02, time/batch = 0.0781s	
4502/5250 (epoch 42.876), train_loss = 1.27917342, grad/param norm = 4.7798e-02, time/batch = 0.0762s	
4503/5250 (epoch 42.886), train_loss = 1.26543519, grad/param norm = 5.0777e-02, time/batch = 0.0763s	
4504/5250 (epoch 42.895), train_loss = 1.30823469, grad/param norm = 5.7677e-02, time/batch = 0.0763s	
4505/5250 (epoch 42.905), train_loss = 1.29412800, grad/param norm = 5.0613e-02, time/batch = 0.0765s	
4506/5250 (epoch 42.914), train_loss = 1.30785913, grad/param norm = 5.2173e-02, time/batch = 0.0772s	
4507/5250 (epoch 42.924), train_loss = 1.29922611, grad/param norm = 5.1273e-02, time/batch = 0.0760s	
4508/5250 (epoch 42.933), train_loss = 1.27023616, grad/param norm = 5.2208e-02, time/batch = 0.0757s	
4509/5250 (epoch 42.943), train_loss = 1.30953121, grad/param norm = 5.4572e-02, time/batch = 0.0762s	
4510/5250 (epoch 42.952), train_loss = 1.30659325, grad/param norm = 5.3117e-02, time/batch = 0.0763s	
4511/5250 (epoch 42.962), train_loss = 1.28539982, grad/param norm = 4.9213e-02, time/batch = 0.0781s	
4512/5250 (epoch 42.971), train_loss = 1.28200227, grad/param norm = 5.3087e-02, time/batch = 0.0770s	
4513/5250 (epoch 42.981), train_loss = 1.30283939, grad/param norm = 5.3117e-02, time/batch = 0.0764s	
4514/5250 (epoch 42.990), train_loss = 1.30451637, grad/param norm = 5.8158e-02, time/batch = 0.0765s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
4515/5250 (epoch 43.000), train_loss = 1.29208710, grad/param norm = 5.4752e-02, time/batch = 0.0762s	
4516/5250 (epoch 43.010), train_loss = 1.49031311, grad/param norm = 6.4290e-02, time/batch = 0.0770s	
4517/5250 (epoch 43.019), train_loss = 1.27138965, grad/param norm = 5.8542e-02, time/batch = 0.0759s	
4518/5250 (epoch 43.029), train_loss = 1.28397298, grad/param norm = 5.0276e-02, time/batch = 0.0756s	
4519/5250 (epoch 43.038), train_loss = 1.27300947, grad/param norm = 5.0984e-02, time/batch = 0.0763s	
4520/5250 (epoch 43.048), train_loss = 1.25181625, grad/param norm = 5.0922e-02, time/batch = 0.0763s	
4521/5250 (epoch 43.057), train_loss = 1.26591537, grad/param norm = 4.8531e-02, time/batch = 0.0781s	
4522/5250 (epoch 43.067), train_loss = 1.27649242, grad/param norm = 4.8004e-02, time/batch = 0.0761s	
4523/5250 (epoch 43.076), train_loss = 1.28058150, grad/param norm = 5.4947e-02, time/batch = 0.0769s	
4524/5250 (epoch 43.086), train_loss = 1.23119034, grad/param norm = 5.4429e-02, time/batch = 0.0765s	
4525/5250 (epoch 43.095), train_loss = 1.25616480, grad/param norm = 4.8049e-02, time/batch = 0.0762s	
4526/5250 (epoch 43.105), train_loss = 1.27770063, grad/param norm = 5.1210e-02, time/batch = 0.0765s	
4527/5250 (epoch 43.114), train_loss = 1.25880801, grad/param norm = 5.3849e-02, time/batch = 0.0760s	
4528/5250 (epoch 43.124), train_loss = 1.28041134, grad/param norm = 5.6686e-02, time/batch = 0.0755s	
4529/5250 (epoch 43.133), train_loss = 1.26556120, grad/param norm = 5.0599e-02, time/batch = 0.0770s	
4530/5250 (epoch 43.143), train_loss = 1.25128227, grad/param norm = 5.1111e-02, time/batch = 0.0766s	
4531/5250 (epoch 43.152), train_loss = 1.25255686, grad/param norm = 5.0394e-02, time/batch = 0.0782s	
4532/5250 (epoch 43.162), train_loss = 1.27932752, grad/param norm = 5.0846e-02, time/batch = 0.0760s	
4533/5250 (epoch 43.171), train_loss = 1.27690176, grad/param norm = 4.7823e-02, time/batch = 0.0760s	
4534/5250 (epoch 43.181), train_loss = 1.28591445, grad/param norm = 5.2511e-02, time/batch = 0.0770s	
4535/5250 (epoch 43.190), train_loss = 1.28106098, grad/param norm = 5.0938e-02, time/batch = 0.0764s	
4536/5250 (epoch 43.200), train_loss = 1.26570072, grad/param norm = 5.3059e-02, time/batch = 0.0769s	
4537/5250 (epoch 43.210), train_loss = 1.26719442, grad/param norm = 4.9651e-02, time/batch = 0.0764s	
4538/5250 (epoch 43.219), train_loss = 1.31276491, grad/param norm = 5.0283e-02, time/batch = 0.0757s	
4539/5250 (epoch 43.229), train_loss = 1.26769489, grad/param norm = 5.0238e-02, time/batch = 0.0765s	
4540/5250 (epoch 43.238), train_loss = 1.27199845, grad/param norm = 5.2286e-02, time/batch = 0.0765s	
4541/5250 (epoch 43.248), train_loss = 1.27626983, grad/param norm = 5.1117e-02, time/batch = 0.0780s	
4542/5250 (epoch 43.257), train_loss = 1.26974172, grad/param norm = 4.9735e-02, time/batch = 0.0761s	
4543/5250 (epoch 43.267), train_loss = 1.25656484, grad/param norm = 5.2720e-02, time/batch = 0.0759s	
4544/5250 (epoch 43.276), train_loss = 1.25743170, grad/param norm = 4.7227e-02, time/batch = 0.0765s	
4545/5250 (epoch 43.286), train_loss = 1.24320723, grad/param norm = 5.0990e-02, time/batch = 0.0771s	
4546/5250 (epoch 43.295), train_loss = 1.27002342, grad/param norm = 5.1044e-02, time/batch = 0.0768s	
4547/5250 (epoch 43.305), train_loss = 1.26071824, grad/param norm = 5.2064e-02, time/batch = 0.0761s	
4548/5250 (epoch 43.314), train_loss = 1.25414165, grad/param norm = 5.0826e-02, time/batch = 0.0757s	
4549/5250 (epoch 43.324), train_loss = 1.26597878, grad/param norm = 5.0521e-02, time/batch = 0.0767s	
4550/5250 (epoch 43.333), train_loss = 1.26753136, grad/param norm = 5.0192e-02, time/batch = 0.0763s	
4551/5250 (epoch 43.343), train_loss = 1.27029709, grad/param norm = 5.0637e-02, time/batch = 0.0789s	
4552/5250 (epoch 43.352), train_loss = 1.28257277, grad/param norm = 5.1696e-02, time/batch = 0.0764s	
4553/5250 (epoch 43.362), train_loss = 1.28031613, grad/param norm = 5.1876e-02, time/batch = 0.0763s	
4554/5250 (epoch 43.371), train_loss = 1.26265705, grad/param norm = 4.9312e-02, time/batch = 0.0763s	
4555/5250 (epoch 43.381), train_loss = 1.25828953, grad/param norm = 4.9095e-02, time/batch = 0.0767s	
4556/5250 (epoch 43.390), train_loss = 1.26754740, grad/param norm = 5.3451e-02, time/batch = 0.0769s	
4557/5250 (epoch 43.400), train_loss = 1.27368863, grad/param norm = 4.9866e-02, time/batch = 0.0760s	
4558/5250 (epoch 43.410), train_loss = 1.27614773, grad/param norm = 5.4360e-02, time/batch = 0.0759s	
4559/5250 (epoch 43.419), train_loss = 1.26951762, grad/param norm = 5.1343e-02, time/batch = 0.0763s	
4560/5250 (epoch 43.429), train_loss = 1.27856060, grad/param norm = 4.9921e-02, time/batch = 0.0760s	
4561/5250 (epoch 43.438), train_loss = 1.29707641, grad/param norm = 5.8438e-02, time/batch = 0.0780s	
4562/5250 (epoch 43.448), train_loss = 1.25799885, grad/param norm = 5.1096e-02, time/batch = 0.0767s	
4563/5250 (epoch 43.457), train_loss = 1.26157914, grad/param norm = 5.1988e-02, time/batch = 0.0764s	
4564/5250 (epoch 43.467), train_loss = 1.26858687, grad/param norm = 4.9197e-02, time/batch = 0.0831s	
4565/5250 (epoch 43.476), train_loss = 1.26341605, grad/param norm = 5.1864e-02, time/batch = 0.0769s	
4566/5250 (epoch 43.486), train_loss = 1.28603197, grad/param norm = 5.3710e-02, time/batch = 0.0770s	
4567/5250 (epoch 43.495), train_loss = 1.28674176, grad/param norm = 5.3994e-02, time/batch = 0.0760s	
4568/5250 (epoch 43.505), train_loss = 1.29293532, grad/param norm = 5.8099e-02, time/batch = 0.0765s	
4569/5250 (epoch 43.514), train_loss = 1.28591967, grad/param norm = 4.9850e-02, time/batch = 0.0764s	
4570/5250 (epoch 43.524), train_loss = 1.26590261, grad/param norm = 6.2093e-02, time/batch = 0.0764s	
4571/5250 (epoch 43.533), train_loss = 1.27567147, grad/param norm = 5.7207e-02, time/batch = 0.0783s	
4572/5250 (epoch 43.543), train_loss = 1.26426791, grad/param norm = 5.3123e-02, time/batch = 0.0764s	
4573/5250 (epoch 43.552), train_loss = 1.27022284, grad/param norm = 5.2202e-02, time/batch = 0.0766s	
4574/5250 (epoch 43.562), train_loss = 1.26910707, grad/param norm = 5.1087e-02, time/batch = 0.0759s	
4575/5250 (epoch 43.571), train_loss = 1.27342051, grad/param norm = 5.1763e-02, time/batch = 0.0764s	
4576/5250 (epoch 43.581), train_loss = 1.30535546, grad/param norm = 5.4021e-02, time/batch = 0.0765s	
4577/5250 (epoch 43.590), train_loss = 1.27496990, grad/param norm = 5.1094e-02, time/batch = 0.0760s	
4578/5250 (epoch 43.600), train_loss = 1.29992979, grad/param norm = 5.3417e-02, time/batch = 0.0755s	
4579/5250 (epoch 43.610), train_loss = 1.28577218, grad/param norm = 5.4772e-02, time/batch = 0.0770s	
4580/5250 (epoch 43.619), train_loss = 1.27605899, grad/param norm = 5.3661e-02, time/batch = 0.0759s	
4581/5250 (epoch 43.629), train_loss = 1.28343881, grad/param norm = 5.1520e-02, time/batch = 0.0780s	
4582/5250 (epoch 43.638), train_loss = 1.26588850, grad/param norm = 4.8256e-02, time/batch = 0.0760s	
4583/5250 (epoch 43.648), train_loss = 1.27463182, grad/param norm = 5.0718e-02, time/batch = 0.0759s	
4584/5250 (epoch 43.657), train_loss = 1.27429698, grad/param norm = 5.0225e-02, time/batch = 0.0763s	
4585/5250 (epoch 43.667), train_loss = 1.28118095, grad/param norm = 5.3789e-02, time/batch = 0.0763s	
4586/5250 (epoch 43.676), train_loss = 1.27447857, grad/param norm = 5.4322e-02, time/batch = 0.0766s	
4587/5250 (epoch 43.686), train_loss = 1.30269943, grad/param norm = 4.9258e-02, time/batch = 0.0756s	
4588/5250 (epoch 43.695), train_loss = 1.28327162, grad/param norm = 5.7458e-02, time/batch = 0.0758s	
4589/5250 (epoch 43.705), train_loss = 1.26570001, grad/param norm = 5.3608e-02, time/batch = 0.0763s	
4590/5250 (epoch 43.714), train_loss = 1.29889577, grad/param norm = 5.5783e-02, time/batch = 0.0765s	
4591/5250 (epoch 43.724), train_loss = 1.27667610, grad/param norm = 4.9392e-02, time/batch = 0.0783s	
4592/5250 (epoch 43.733), train_loss = 1.25751056, grad/param norm = 4.9901e-02, time/batch = 0.0761s	
4593/5250 (epoch 43.743), train_loss = 1.26465908, grad/param norm = 5.5428e-02, time/batch = 0.0764s	
4594/5250 (epoch 43.752), train_loss = 1.27315276, grad/param norm = 5.3975e-02, time/batch = 0.0761s	
4595/5250 (epoch 43.762), train_loss = 1.26208356, grad/param norm = 5.0022e-02, time/batch = 0.0766s	
4596/5250 (epoch 43.771), train_loss = 1.25864820, grad/param norm = 5.3759e-02, time/batch = 0.0766s	
4597/5250 (epoch 43.781), train_loss = 1.28499100, grad/param norm = 5.3108e-02, time/batch = 0.0760s	
4598/5250 (epoch 43.790), train_loss = 1.29503172, grad/param norm = 6.0805e-02, time/batch = 0.0757s	
4599/5250 (epoch 43.800), train_loss = 1.27566378, grad/param norm = 5.4502e-02, time/batch = 0.0761s	
4600/5250 (epoch 43.810), train_loss = 1.27823088, grad/param norm = 5.1193e-02, time/batch = 0.0757s	
4601/5250 (epoch 43.819), train_loss = 1.28503363, grad/param norm = 5.3924e-02, time/batch = 0.0786s	
4602/5250 (epoch 43.829), train_loss = 1.28125837, grad/param norm = 5.1737e-02, time/batch = 0.0760s	
4603/5250 (epoch 43.838), train_loss = 1.26588905, grad/param norm = 5.0255e-02, time/batch = 0.0761s	
4604/5250 (epoch 43.848), train_loss = 1.26278808, grad/param norm = 4.9936e-02, time/batch = 0.0763s	
4605/5250 (epoch 43.857), train_loss = 1.27571538, grad/param norm = 4.9461e-02, time/batch = 0.0758s	
4606/5250 (epoch 43.867), train_loss = 1.27397660, grad/param norm = 5.0342e-02, time/batch = 0.0767s	
4607/5250 (epoch 43.876), train_loss = 1.27654266, grad/param norm = 4.7576e-02, time/batch = 0.0760s	
4608/5250 (epoch 43.886), train_loss = 1.26281657, grad/param norm = 5.0765e-02, time/batch = 0.0756s	
4609/5250 (epoch 43.895), train_loss = 1.30560146, grad/param norm = 5.7307e-02, time/batch = 0.0763s	
4610/5250 (epoch 43.905), train_loss = 1.29148991, grad/param norm = 5.0011e-02, time/batch = 0.0761s	
4611/5250 (epoch 43.914), train_loss = 1.30508243, grad/param norm = 5.1931e-02, time/batch = 0.0780s	
4612/5250 (epoch 43.924), train_loss = 1.29660723, grad/param norm = 5.1037e-02, time/batch = 0.0775s	
4613/5250 (epoch 43.933), train_loss = 1.26751834, grad/param norm = 5.1839e-02, time/batch = 0.0766s	
4614/5250 (epoch 43.943), train_loss = 1.30678040, grad/param norm = 5.4089e-02, time/batch = 0.0764s	
4615/5250 (epoch 43.952), train_loss = 1.30381571, grad/param norm = 5.2902e-02, time/batch = 0.0764s	
4616/5250 (epoch 43.962), train_loss = 1.28279905, grad/param norm = 4.8850e-02, time/batch = 0.0763s	
4617/5250 (epoch 43.971), train_loss = 1.27965717, grad/param norm = 5.3050e-02, time/batch = 0.0756s	
4618/5250 (epoch 43.981), train_loss = 1.30018616, grad/param norm = 5.2949e-02, time/batch = 0.0763s	
4619/5250 (epoch 43.990), train_loss = 1.30177660, grad/param norm = 5.7828e-02, time/batch = 0.0764s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
4620/5250 (epoch 44.000), train_loss = 1.28956453, grad/param norm = 5.4001e-02, time/batch = 0.0759s	
4621/5250 (epoch 44.010), train_loss = 1.48831180, grad/param norm = 6.3943e-02, time/batch = 0.0780s	
4622/5250 (epoch 44.019), train_loss = 1.26868175, grad/param norm = 5.7885e-02, time/batch = 0.0760s	
4623/5250 (epoch 44.029), train_loss = 1.28142788, grad/param norm = 4.9946e-02, time/batch = 0.0765s	
4624/5250 (epoch 44.038), train_loss = 1.27047832, grad/param norm = 5.0693e-02, time/batch = 0.0761s	
4625/5250 (epoch 44.048), train_loss = 1.24926854, grad/param norm = 5.0798e-02, time/batch = 0.0763s	
4626/5250 (epoch 44.057), train_loss = 1.26346025, grad/param norm = 4.8583e-02, time/batch = 0.0765s	
4627/5250 (epoch 44.067), train_loss = 1.27406882, grad/param norm = 4.7945e-02, time/batch = 0.0754s	
4628/5250 (epoch 44.076), train_loss = 1.27812700, grad/param norm = 5.4855e-02, time/batch = 0.0757s	
4629/5250 (epoch 44.086), train_loss = 1.22877040, grad/param norm = 5.4098e-02, time/batch = 0.0763s	
4630/5250 (epoch 44.095), train_loss = 1.25355571, grad/param norm = 4.7851e-02, time/batch = 0.0761s	
4631/5250 (epoch 44.105), train_loss = 1.27527356, grad/param norm = 5.1200e-02, time/batch = 0.0780s	
4632/5250 (epoch 44.114), train_loss = 1.25628373, grad/param norm = 5.3653e-02, time/batch = 0.0760s	
4633/5250 (epoch 44.124), train_loss = 1.27807387, grad/param norm = 5.5517e-02, time/batch = 0.0761s	
4634/5250 (epoch 44.133), train_loss = 1.26316458, grad/param norm = 5.0535e-02, time/batch = 0.0767s	
4635/5250 (epoch 44.143), train_loss = 1.24867541, grad/param norm = 5.1141e-02, time/batch = 0.0765s	
4636/5250 (epoch 44.152), train_loss = 1.25009719, grad/param norm = 5.0563e-02, time/batch = 0.0764s	
4637/5250 (epoch 44.162), train_loss = 1.27688869, grad/param norm = 5.0829e-02, time/batch = 0.0758s	
4638/5250 (epoch 44.171), train_loss = 1.27408386, grad/param norm = 4.7680e-02, time/batch = 0.0759s	
4639/5250 (epoch 44.181), train_loss = 1.28324219, grad/param norm = 5.2288e-02, time/batch = 0.0760s	
4640/5250 (epoch 44.190), train_loss = 1.27869905, grad/param norm = 5.1138e-02, time/batch = 0.0763s	
4641/5250 (epoch 44.200), train_loss = 1.26314388, grad/param norm = 5.2732e-02, time/batch = 0.0780s	
4642/5250 (epoch 44.210), train_loss = 1.26473111, grad/param norm = 4.9504e-02, time/batch = 0.0760s	
4643/5250 (epoch 44.219), train_loss = 1.31022288, grad/param norm = 5.0086e-02, time/batch = 0.0760s	
4644/5250 (epoch 44.229), train_loss = 1.26525856, grad/param norm = 5.0455e-02, time/batch = 0.0762s	
4645/5250 (epoch 44.238), train_loss = 1.26944845, grad/param norm = 5.2031e-02, time/batch = 0.0764s	
4646/5250 (epoch 44.248), train_loss = 1.27361814, grad/param norm = 5.1085e-02, time/batch = 0.0775s	
4647/5250 (epoch 44.257), train_loss = 1.26739306, grad/param norm = 4.9638e-02, time/batch = 0.0757s	
4648/5250 (epoch 44.267), train_loss = 1.25422145, grad/param norm = 5.2644e-02, time/batch = 0.0757s	
4649/5250 (epoch 44.276), train_loss = 1.25494435, grad/param norm = 4.9281e-02, time/batch = 0.0764s	
4650/5250 (epoch 44.286), train_loss = 1.24049266, grad/param norm = 5.0567e-02, time/batch = 0.0758s	
4651/5250 (epoch 44.295), train_loss = 1.26749161, grad/param norm = 5.0260e-02, time/batch = 0.0783s	
4652/5250 (epoch 44.305), train_loss = 1.25769141, grad/param norm = 5.0330e-02, time/batch = 0.0761s	
4653/5250 (epoch 44.314), train_loss = 1.25193144, grad/param norm = 5.0735e-02, time/batch = 0.0760s	
4654/5250 (epoch 44.324), train_loss = 1.26383999, grad/param norm = 5.1980e-02, time/batch = 0.0763s	
4655/5250 (epoch 44.333), train_loss = 1.26510912, grad/param norm = 4.9971e-02, time/batch = 0.0765s	
4656/5250 (epoch 44.343), train_loss = 1.26824482, grad/param norm = 5.1078e-02, time/batch = 0.0766s	
4657/5250 (epoch 44.352), train_loss = 1.28044703, grad/param norm = 5.2303e-02, time/batch = 0.0762s	
4658/5250 (epoch 44.362), train_loss = 1.27790056, grad/param norm = 5.2424e-02, time/batch = 0.0760s	
4659/5250 (epoch 44.371), train_loss = 1.26030210, grad/param norm = 4.9223e-02, time/batch = 0.0760s	
4660/5250 (epoch 44.381), train_loss = 1.25590901, grad/param norm = 4.9211e-02, time/batch = 0.0758s	
4661/5250 (epoch 44.390), train_loss = 1.26512984, grad/param norm = 5.3270e-02, time/batch = 0.0779s	
4662/5250 (epoch 44.400), train_loss = 1.27142460, grad/param norm = 4.9754e-02, time/batch = 0.0763s	
4663/5250 (epoch 44.410), train_loss = 1.27346311, grad/param norm = 5.3995e-02, time/batch = 0.0760s	
4664/5250 (epoch 44.419), train_loss = 1.26697506, grad/param norm = 5.0696e-02, time/batch = 0.0762s	
4665/5250 (epoch 44.429), train_loss = 1.27611165, grad/param norm = 5.0189e-02, time/batch = 0.0762s	
4666/5250 (epoch 44.438), train_loss = 1.29445817, grad/param norm = 5.7560e-02, time/batch = 0.0766s	
4667/5250 (epoch 44.448), train_loss = 1.25528996, grad/param norm = 4.9785e-02, time/batch = 0.0758s	
4668/5250 (epoch 44.457), train_loss = 1.25904982, grad/param norm = 5.1568e-02, time/batch = 0.0764s	
4669/5250 (epoch 44.467), train_loss = 1.26612546, grad/param norm = 4.8843e-02, time/batch = 0.0761s	
4670/5250 (epoch 44.476), train_loss = 1.26092196, grad/param norm = 5.1569e-02, time/batch = 0.0761s	
4671/5250 (epoch 44.486), train_loss = 1.28355351, grad/param norm = 5.3465e-02, time/batch = 0.0780s	
4672/5250 (epoch 44.495), train_loss = 1.28421189, grad/param norm = 5.3730e-02, time/batch = 0.0758s	
4673/5250 (epoch 44.505), train_loss = 1.29024311, grad/param norm = 5.7493e-02, time/batch = 0.0764s	
4674/5250 (epoch 44.514), train_loss = 1.28329089, grad/param norm = 4.9627e-02, time/batch = 0.0758s	
4675/5250 (epoch 44.524), train_loss = 1.26361440, grad/param norm = 6.2638e-02, time/batch = 0.0795s	
4676/5250 (epoch 44.533), train_loss = 1.27313886, grad/param norm = 5.6450e-02, time/batch = 0.0809s	
4677/5250 (epoch 44.543), train_loss = 1.26179546, grad/param norm = 5.3094e-02, time/batch = 0.0764s	
4678/5250 (epoch 44.552), train_loss = 1.26765926, grad/param norm = 5.1761e-02, time/batch = 0.0762s	
4679/5250 (epoch 44.562), train_loss = 1.26672468, grad/param norm = 5.1470e-02, time/batch = 0.0766s	
4680/5250 (epoch 44.571), train_loss = 1.27096107, grad/param norm = 5.1640e-02, time/batch = 0.0761s	
4681/5250 (epoch 44.581), train_loss = 1.30285560, grad/param norm = 5.4069e-02, time/batch = 0.0779s	
4682/5250 (epoch 44.590), train_loss = 1.27253529, grad/param norm = 5.1063e-02, time/batch = 0.0759s	
4683/5250 (epoch 44.600), train_loss = 1.29753666, grad/param norm = 5.3092e-02, time/batch = 0.0757s	
4684/5250 (epoch 44.610), train_loss = 1.28307316, grad/param norm = 5.4090e-02, time/batch = 0.0760s	
4685/5250 (epoch 44.619), train_loss = 1.27361700, grad/param norm = 5.3196e-02, time/batch = 0.0769s	
4686/5250 (epoch 44.629), train_loss = 1.28079387, grad/param norm = 5.1427e-02, time/batch = 0.0766s	
4687/5250 (epoch 44.638), train_loss = 1.26358289, grad/param norm = 4.8329e-02, time/batch = 0.0757s	
4688/5250 (epoch 44.648), train_loss = 1.27219811, grad/param norm = 5.0890e-02, time/batch = 0.0756s	
4689/5250 (epoch 44.657), train_loss = 1.27187354, grad/param norm = 5.0148e-02, time/batch = 0.0760s	
4690/5250 (epoch 44.667), train_loss = 1.27889783, grad/param norm = 5.3796e-02, time/batch = 0.0765s	
4691/5250 (epoch 44.676), train_loss = 1.27173857, grad/param norm = 5.4063e-02, time/batch = 0.0781s	
4692/5250 (epoch 44.686), train_loss = 1.30022552, grad/param norm = 4.9266e-02, time/batch = 0.0759s	
4693/5250 (epoch 44.695), train_loss = 1.28081449, grad/param norm = 5.7349e-02, time/batch = 0.0757s	
4694/5250 (epoch 44.705), train_loss = 1.26312281, grad/param norm = 5.3408e-02, time/batch = 0.0760s	
4695/5250 (epoch 44.714), train_loss = 1.29624277, grad/param norm = 5.5657e-02, time/batch = 0.0763s	
4696/5250 (epoch 44.724), train_loss = 1.27407292, grad/param norm = 4.9339e-02, time/batch = 0.0767s	
4697/5250 (epoch 44.733), train_loss = 1.25514907, grad/param norm = 4.9777e-02, time/batch = 0.0758s	
4698/5250 (epoch 44.743), train_loss = 1.26221213, grad/param norm = 5.5132e-02, time/batch = 0.0757s	
4699/5250 (epoch 44.752), train_loss = 1.27055219, grad/param norm = 5.3705e-02, time/batch = 0.0761s	
4700/5250 (epoch 44.762), train_loss = 1.25964359, grad/param norm = 4.9924e-02, time/batch = 0.0757s	
4701/5250 (epoch 44.771), train_loss = 1.25627452, grad/param norm = 5.3355e-02, time/batch = 0.0783s	
4702/5250 (epoch 44.781), train_loss = 1.28255394, grad/param norm = 5.2801e-02, time/batch = 0.0761s	
4703/5250 (epoch 44.790), train_loss = 1.29228535, grad/param norm = 5.9082e-02, time/batch = 0.0756s	
4704/5250 (epoch 44.800), train_loss = 1.27293940, grad/param norm = 5.3266e-02, time/batch = 0.0761s	
4705/5250 (epoch 44.810), train_loss = 1.27552033, grad/param norm = 5.0949e-02, time/batch = 0.0764s	
4706/5250 (epoch 44.819), train_loss = 1.28245592, grad/param norm = 5.3274e-02, time/batch = 0.0763s	
4707/5250 (epoch 44.829), train_loss = 1.27880253, grad/param norm = 5.1459e-02, time/batch = 0.0764s	
4708/5250 (epoch 44.838), train_loss = 1.26352837, grad/param norm = 5.0168e-02, time/batch = 0.0757s	
4709/5250 (epoch 44.848), train_loss = 1.26044292, grad/param norm = 4.9716e-02, time/batch = 0.0764s	
4710/5250 (epoch 44.857), train_loss = 1.27318135, grad/param norm = 4.9421e-02, time/batch = 0.0759s	
4711/5250 (epoch 44.867), train_loss = 1.27158952, grad/param norm = 5.0262e-02, time/batch = 0.0785s	
4712/5250 (epoch 44.876), train_loss = 1.27406105, grad/param norm = 4.7861e-02, time/batch = 0.0764s	
4713/5250 (epoch 44.886), train_loss = 1.26039718, grad/param norm = 5.0699e-02, time/batch = 0.0757s	
4714/5250 (epoch 44.895), train_loss = 1.30306370, grad/param norm = 5.6849e-02, time/batch = 0.0757s	
4715/5250 (epoch 44.905), train_loss = 1.28904928, grad/param norm = 4.9909e-02, time/batch = 0.0759s	
4716/5250 (epoch 44.914), train_loss = 1.30252607, grad/param norm = 5.1793e-02, time/batch = 0.0767s	
4717/5250 (epoch 44.924), train_loss = 1.29403608, grad/param norm = 5.1068e-02, time/batch = 0.0759s	
4718/5250 (epoch 44.933), train_loss = 1.26502502, grad/param norm = 5.1832e-02, time/batch = 0.0760s	
4719/5250 (epoch 44.943), train_loss = 1.30419322, grad/param norm = 5.3667e-02, time/batch = 0.0764s	
4720/5250 (epoch 44.952), train_loss = 1.30125333, grad/param norm = 5.2860e-02, time/batch = 0.0765s	
4721/5250 (epoch 44.962), train_loss = 1.28034751, grad/param norm = 4.8977e-02, time/batch = 0.0783s	
4722/5250 (epoch 44.971), train_loss = 1.27745375, grad/param norm = 5.3035e-02, time/batch = 0.0760s	
4723/5250 (epoch 44.981), train_loss = 1.29778075, grad/param norm = 5.2974e-02, time/batch = 0.0759s	
4724/5250 (epoch 44.990), train_loss = 1.29918543, grad/param norm = 5.7442e-02, time/batch = 0.0761s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
4725/5250 (epoch 45.000), train_loss = 1.28710570, grad/param norm = 5.3331e-02, time/batch = 0.0760s	
4726/5250 (epoch 45.010), train_loss = 1.48641838, grad/param norm = 6.3589e-02, time/batch = 0.0766s	
4727/5250 (epoch 45.019), train_loss = 1.26604949, grad/param norm = 5.7444e-02, time/batch = 0.0758s	
4728/5250 (epoch 45.029), train_loss = 1.27908267, grad/param norm = 4.9810e-02, time/batch = 0.0755s	
4729/5250 (epoch 45.038), train_loss = 1.26801836, grad/param norm = 5.0474e-02, time/batch = 0.0760s	
4730/5250 (epoch 45.048), train_loss = 1.24687162, grad/param norm = 5.0724e-02, time/batch = 0.0761s	
4731/5250 (epoch 45.057), train_loss = 1.26111966, grad/param norm = 4.8626e-02, time/batch = 0.0781s	
4732/5250 (epoch 45.067), train_loss = 1.27180444, grad/param norm = 4.7919e-02, time/batch = 0.0761s	
4733/5250 (epoch 45.076), train_loss = 1.27573479, grad/param norm = 5.4657e-02, time/batch = 0.0760s	
4734/5250 (epoch 45.086), train_loss = 1.22641479, grad/param norm = 5.3601e-02, time/batch = 0.0760s	
4735/5250 (epoch 45.095), train_loss = 1.25105708, grad/param norm = 4.7741e-02, time/batch = 0.0766s	
4736/5250 (epoch 45.105), train_loss = 1.27291594, grad/param norm = 5.1178e-02, time/batch = 0.0762s	
4737/5250 (epoch 45.114), train_loss = 1.25390329, grad/param norm = 5.3443e-02, time/batch = 0.0756s	
4738/5250 (epoch 45.124), train_loss = 1.27570649, grad/param norm = 5.5121e-02, time/batch = 0.0756s	
4739/5250 (epoch 45.133), train_loss = 1.26074227, grad/param norm = 5.0248e-02, time/batch = 0.0760s	
4740/5250 (epoch 45.143), train_loss = 1.24626722, grad/param norm = 5.1107e-02, time/batch = 0.0756s	
4741/5250 (epoch 45.152), train_loss = 1.24784907, grad/param norm = 5.0634e-02, time/batch = 0.0778s	
4742/5250 (epoch 45.162), train_loss = 1.27455400, grad/param norm = 5.0825e-02, time/batch = 0.0759s	
4743/5250 (epoch 45.171), train_loss = 1.27143361, grad/param norm = 4.7616e-02, time/batch = 0.0760s	
4744/5250 (epoch 45.181), train_loss = 1.28064621, grad/param norm = 5.2108e-02, time/batch = 0.0763s	
4745/5250 (epoch 45.190), train_loss = 1.27648941, grad/param norm = 5.1368e-02, time/batch = 0.0758s	
4746/5250 (epoch 45.200), train_loss = 1.26069673, grad/param norm = 5.2456e-02, time/batch = 0.0769s	
4747/5250 (epoch 45.210), train_loss = 1.26233810, grad/param norm = 4.9406e-02, time/batch = 0.0758s	
4748/5250 (epoch 45.219), train_loss = 1.30773213, grad/param norm = 4.9854e-02, time/batch = 0.0758s	
4749/5250 (epoch 45.229), train_loss = 1.26285146, grad/param norm = 5.0551e-02, time/batch = 0.0761s	
4750/5250 (epoch 45.238), train_loss = 1.26701442, grad/param norm = 5.1802e-02, time/batch = 0.0756s	
4751/5250 (epoch 45.248), train_loss = 1.27112077, grad/param norm = 5.1000e-02, time/batch = 0.0781s	
4752/5250 (epoch 45.257), train_loss = 1.26519129, grad/param norm = 4.9540e-02, time/batch = 0.0761s	
4753/5250 (epoch 45.267), train_loss = 1.25194281, grad/param norm = 5.2505e-02, time/batch = 0.0760s	
4754/5250 (epoch 45.276), train_loss = 1.25274265, grad/param norm = 4.6672e-02, time/batch = 0.0762s	
4755/5250 (epoch 45.286), train_loss = 1.23830942, grad/param norm = 5.0806e-02, time/batch = 0.0758s	
4756/5250 (epoch 45.295), train_loss = 1.26544471, grad/param norm = 5.1004e-02, time/batch = 0.0764s	
4757/5250 (epoch 45.305), train_loss = 1.25556069, grad/param norm = 5.1476e-02, time/batch = 0.0762s	
4758/5250 (epoch 45.314), train_loss = 1.24929176, grad/param norm = 5.0752e-02, time/batch = 0.0760s	
4759/5250 (epoch 45.324), train_loss = 1.26177620, grad/param norm = 5.1936e-02, time/batch = 0.0762s	
4760/5250 (epoch 45.333), train_loss = 1.26264078, grad/param norm = 4.9780e-02, time/batch = 0.0762s	
4761/5250 (epoch 45.343), train_loss = 1.26581638, grad/param norm = 5.1107e-02, time/batch = 0.0780s	
4762/5250 (epoch 45.352), train_loss = 1.27809873, grad/param norm = 5.1831e-02, time/batch = 0.0759s	
4763/5250 (epoch 45.362), train_loss = 1.27512578, grad/param norm = 5.2023e-02, time/batch = 0.0763s	
4764/5250 (epoch 45.371), train_loss = 1.25840812, grad/param norm = 4.9351e-02, time/batch = 0.0760s	
4765/5250 (epoch 45.381), train_loss = 1.25339772, grad/param norm = 4.9295e-02, time/batch = 0.0764s	
4766/5250 (epoch 45.390), train_loss = 1.26258809, grad/param norm = 5.3113e-02, time/batch = 0.0765s	
4767/5250 (epoch 45.400), train_loss = 1.26895252, grad/param norm = 4.9481e-02, time/batch = 0.0761s	
4768/5250 (epoch 45.410), train_loss = 1.27090978, grad/param norm = 5.3608e-02, time/batch = 0.0756s	
4769/5250 (epoch 45.419), train_loss = 1.26453730, grad/param norm = 5.0241e-02, time/batch = 0.0764s	
4770/5250 (epoch 45.429), train_loss = 1.27389071, grad/param norm = 5.0503e-02, time/batch = 0.0759s	
4771/5250 (epoch 45.438), train_loss = 1.29186874, grad/param norm = 5.7390e-02, time/batch = 0.0781s	
4772/5250 (epoch 45.448), train_loss = 1.25287550, grad/param norm = 4.9294e-02, time/batch = 0.0758s	
4773/5250 (epoch 45.457), train_loss = 1.25680378, grad/param norm = 5.1315e-02, time/batch = 0.0759s	
4774/5250 (epoch 45.467), train_loss = 1.26374684, grad/param norm = 4.8424e-02, time/batch = 0.0765s	
4775/5250 (epoch 45.476), train_loss = 1.25832265, grad/param norm = 5.1230e-02, time/batch = 0.0764s	
4776/5250 (epoch 45.486), train_loss = 1.28120749, grad/param norm = 5.3152e-02, time/batch = 0.0763s	
4777/5250 (epoch 45.495), train_loss = 1.28174977, grad/param norm = 5.3006e-02, time/batch = 0.0756s	
4778/5250 (epoch 45.505), train_loss = 1.28758005, grad/param norm = 5.6082e-02, time/batch = 0.0759s	
4779/5250 (epoch 45.514), train_loss = 1.28083122, grad/param norm = 4.9538e-02, time/batch = 0.0762s	
4780/5250 (epoch 45.524), train_loss = 1.26149203, grad/param norm = 6.3765e-02, time/batch = 0.0765s	
4781/5250 (epoch 45.533), train_loss = 1.27059659, grad/param norm = 5.5505e-02, time/batch = 0.0779s	
4782/5250 (epoch 45.543), train_loss = 1.25949576, grad/param norm = 5.3420e-02, time/batch = 0.0759s	
4783/5250 (epoch 45.552), train_loss = 1.26517973, grad/param norm = 5.1530e-02, time/batch = 0.0760s	
4784/5250 (epoch 45.562), train_loss = 1.26448904, grad/param norm = 5.1804e-02, time/batch = 0.0763s	
4785/5250 (epoch 45.571), train_loss = 1.26852947, grad/param norm = 5.1500e-02, time/batch = 0.0762s	
4786/5250 (epoch 45.581), train_loss = 1.30046839, grad/param norm = 5.3563e-02, time/batch = 0.0765s	
4787/5250 (epoch 45.590), train_loss = 1.26992378, grad/param norm = 5.0892e-02, time/batch = 0.0796s	
4788/5250 (epoch 45.600), train_loss = 1.29529780, grad/param norm = 5.3023e-02, time/batch = 0.0778s	
4789/5250 (epoch 45.610), train_loss = 1.28055957, grad/param norm = 5.3274e-02, time/batch = 0.0769s	
4790/5250 (epoch 45.619), train_loss = 1.27127462, grad/param norm = 5.2643e-02, time/batch = 0.0763s	
4791/5250 (epoch 45.629), train_loss = 1.27828811, grad/param norm = 5.1364e-02, time/batch = 0.0781s	
4792/5250 (epoch 45.638), train_loss = 1.26137229, grad/param norm = 4.8419e-02, time/batch = 0.0762s	
4793/5250 (epoch 45.648), train_loss = 1.27000054, grad/param norm = 5.0835e-02, time/batch = 0.0754s	
4794/5250 (epoch 45.657), train_loss = 1.26953091, grad/param norm = 4.9984e-02, time/batch = 0.0760s	
4795/5250 (epoch 45.667), train_loss = 1.27659449, grad/param norm = 5.3743e-02, time/batch = 0.0762s	
4796/5250 (epoch 45.676), train_loss = 1.26907318, grad/param norm = 5.3815e-02, time/batch = 0.0767s	
4797/5250 (epoch 45.686), train_loss = 1.29783074, grad/param norm = 4.9308e-02, time/batch = 0.0760s	
4798/5250 (epoch 45.695), train_loss = 1.27837821, grad/param norm = 5.7169e-02, time/batch = 0.0757s	
4799/5250 (epoch 45.705), train_loss = 1.26068671, grad/param norm = 5.3297e-02, time/batch = 0.0759s	
4800/5250 (epoch 45.714), train_loss = 1.29371551, grad/param norm = 5.5630e-02, time/batch = 0.0759s	
4801/5250 (epoch 45.724), train_loss = 1.27149170, grad/param norm = 4.9253e-02, time/batch = 0.0779s	
4802/5250 (epoch 45.733), train_loss = 1.25291052, grad/param norm = 4.9771e-02, time/batch = 0.0766s	
4803/5250 (epoch 45.743), train_loss = 1.25986887, grad/param norm = 5.4995e-02, time/batch = 0.0760s	
4804/5250 (epoch 45.752), train_loss = 1.26810892, grad/param norm = 5.3380e-02, time/batch = 0.0760s	
4805/5250 (epoch 45.762), train_loss = 1.25730005, grad/param norm = 4.9940e-02, time/batch = 0.0762s	
4806/5250 (epoch 45.771), train_loss = 1.25403149, grad/param norm = 5.3390e-02, time/batch = 0.0762s	
4807/5250 (epoch 45.781), train_loss = 1.28017898, grad/param norm = 5.2509e-02, time/batch = 0.0762s	
4808/5250 (epoch 45.790), train_loss = 1.28969936, grad/param norm = 5.9465e-02, time/batch = 0.0757s	
4809/5250 (epoch 45.800), train_loss = 1.27055735, grad/param norm = 5.3075e-02, time/batch = 0.0760s	
4810/5250 (epoch 45.810), train_loss = 1.27313807, grad/param norm = 5.0930e-02, time/batch = 0.0758s	
4811/5250 (epoch 45.819), train_loss = 1.28008842, grad/param norm = 5.2957e-02, time/batch = 0.0780s	
4812/5250 (epoch 45.829), train_loss = 1.27648667, grad/param norm = 5.1281e-02, time/batch = 0.0760s	
4813/5250 (epoch 45.838), train_loss = 1.26132515, grad/param norm = 5.0109e-02, time/batch = 0.0765s	
4814/5250 (epoch 45.848), train_loss = 1.25816811, grad/param norm = 4.9605e-02, time/batch = 0.0760s	
4815/5250 (epoch 45.857), train_loss = 1.27082491, grad/param norm = 4.9418e-02, time/batch = 0.0763s	
4816/5250 (epoch 45.867), train_loss = 1.26934278, grad/param norm = 5.0288e-02, time/batch = 0.0763s	
4817/5250 (epoch 45.876), train_loss = 1.27163743, grad/param norm = 4.7482e-02, time/batch = 0.0756s	
4818/5250 (epoch 45.886), train_loss = 1.25803136, grad/param norm = 5.0762e-02, time/batch = 0.0754s	
4819/5250 (epoch 45.895), train_loss = 1.30069088, grad/param norm = 5.6538e-02, time/batch = 0.0766s	
4820/5250 (epoch 45.905), train_loss = 1.28664570, grad/param norm = 4.9414e-02, time/batch = 0.0759s	
4821/5250 (epoch 45.914), train_loss = 1.29997414, grad/param norm = 5.1640e-02, time/batch = 0.0779s	
4822/5250 (epoch 45.924), train_loss = 1.29165410, grad/param norm = 5.0829e-02, time/batch = 0.0759s	
4823/5250 (epoch 45.933), train_loss = 1.26250668, grad/param norm = 5.1534e-02, time/batch = 0.0761s	
4824/5250 (epoch 45.943), train_loss = 1.30169971, grad/param norm = 5.3196e-02, time/batch = 0.0759s	
4825/5250 (epoch 45.952), train_loss = 1.29873518, grad/param norm = 5.2754e-02, time/batch = 0.0761s	
4826/5250 (epoch 45.962), train_loss = 1.27794996, grad/param norm = 4.8688e-02, time/batch = 0.0765s	
4827/5250 (epoch 45.971), train_loss = 1.27531661, grad/param norm = 5.3032e-02, time/batch = 0.0760s	
4828/5250 (epoch 45.981), train_loss = 1.29530126, grad/param norm = 5.2833e-02, time/batch = 0.0755s	
4829/5250 (epoch 45.990), train_loss = 1.29667904, grad/param norm = 5.7155e-02, time/batch = 0.0761s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
4830/5250 (epoch 46.000), train_loss = 1.28483987, grad/param norm = 5.2777e-02, time/batch = 0.0761s	
4831/5250 (epoch 46.010), train_loss = 1.48459719, grad/param norm = 6.3382e-02, time/batch = 0.0780s	
4832/5250 (epoch 46.019), train_loss = 1.26363445, grad/param norm = 5.6946e-02, time/batch = 0.0757s	
4833/5250 (epoch 46.029), train_loss = 1.27675290, grad/param norm = 4.9686e-02, time/batch = 0.0756s	
4834/5250 (epoch 46.038), train_loss = 1.26568856, grad/param norm = 5.0296e-02, time/batch = 0.0760s	
4835/5250 (epoch 46.048), train_loss = 1.24456923, grad/param norm = 5.0687e-02, time/batch = 0.0767s	
4836/5250 (epoch 46.057), train_loss = 1.25894627, grad/param norm = 4.8715e-02, time/batch = 0.0765s	
4837/5250 (epoch 46.067), train_loss = 1.26952285, grad/param norm = 4.7864e-02, time/batch = 0.0760s	
4838/5250 (epoch 46.076), train_loss = 1.27348920, grad/param norm = 5.4488e-02, time/batch = 0.0752s	
4839/5250 (epoch 46.086), train_loss = 1.22414787, grad/param norm = 5.3197e-02, time/batch = 0.0761s	
4840/5250 (epoch 46.095), train_loss = 1.24867298, grad/param norm = 4.7881e-02, time/batch = 0.0761s	
4841/5250 (epoch 46.105), train_loss = 1.27067971, grad/param norm = 5.1177e-02, time/batch = 0.0785s	
4842/5250 (epoch 46.114), train_loss = 1.25159080, grad/param norm = 5.3238e-02, time/batch = 0.0760s	
4843/5250 (epoch 46.124), train_loss = 1.27359703, grad/param norm = 5.5149e-02, time/batch = 0.0761s	
4844/5250 (epoch 46.133), train_loss = 1.25857018, grad/param norm = 5.0165e-02, time/batch = 0.0758s	
4845/5250 (epoch 46.143), train_loss = 1.24385803, grad/param norm = 5.0780e-02, time/batch = 0.0762s	
4846/5250 (epoch 46.152), train_loss = 1.24577248, grad/param norm = 5.0893e-02, time/batch = 0.0767s	
4847/5250 (epoch 46.162), train_loss = 1.27222138, grad/param norm = 5.0767e-02, time/batch = 0.0755s	
4848/5250 (epoch 46.171), train_loss = 1.26893100, grad/param norm = 4.7572e-02, time/batch = 0.0754s	
4849/5250 (epoch 46.181), train_loss = 1.27820584, grad/param norm = 5.2027e-02, time/batch = 0.0764s	
4850/5250 (epoch 46.190), train_loss = 1.27430348, grad/param norm = 5.1630e-02, time/batch = 0.0757s	
4851/5250 (epoch 46.200), train_loss = 1.25842678, grad/param norm = 5.2171e-02, time/batch = 0.0780s	
4852/5250 (epoch 46.210), train_loss = 1.26005713, grad/param norm = 4.9338e-02, time/batch = 0.0764s	
4853/5250 (epoch 46.219), train_loss = 1.30539492, grad/param norm = 4.9669e-02, time/batch = 0.0758s	
4854/5250 (epoch 46.229), train_loss = 1.26057770, grad/param norm = 5.0616e-02, time/batch = 0.0758s	
4855/5250 (epoch 46.238), train_loss = 1.26468829, grad/param norm = 5.1583e-02, time/batch = 0.0761s	
4856/5250 (epoch 46.248), train_loss = 1.26871202, grad/param norm = 5.0946e-02, time/batch = 0.0764s	
4857/5250 (epoch 46.257), train_loss = 1.26309160, grad/param norm = 4.9484e-02, time/batch = 0.0756s	
4858/5250 (epoch 46.267), train_loss = 1.24976635, grad/param norm = 5.2511e-02, time/batch = 0.0760s	
4859/5250 (epoch 46.276), train_loss = 1.25049759, grad/param norm = 4.6615e-02, time/batch = 0.0761s	
4860/5250 (epoch 46.286), train_loss = 1.23603822, grad/param norm = 5.0824e-02, time/batch = 0.0761s	
4861/5250 (epoch 46.295), train_loss = 1.26335974, grad/param norm = 5.1113e-02, time/batch = 0.0780s	
4862/5250 (epoch 46.305), train_loss = 1.25321774, grad/param norm = 5.1319e-02, time/batch = 0.0758s	
4863/5250 (epoch 46.314), train_loss = 1.24703029, grad/param norm = 5.0393e-02, time/batch = 0.0761s	
4864/5250 (epoch 46.324), train_loss = 1.25930777, grad/param norm = 5.0737e-02, time/batch = 0.0765s	
4865/5250 (epoch 46.333), train_loss = 1.26028806, grad/param norm = 4.9762e-02, time/batch = 0.0761s	
4866/5250 (epoch 46.343), train_loss = 1.26335204, grad/param norm = 5.0747e-02, time/batch = 0.0759s	
4867/5250 (epoch 46.352), train_loss = 1.27576302, grad/param norm = 5.1066e-02, time/batch = 0.0758s	
4868/5250 (epoch 46.362), train_loss = 1.27266476, grad/param norm = 5.1368e-02, time/batch = 0.0754s	
4869/5250 (epoch 46.371), train_loss = 1.25636255, grad/param norm = 4.9315e-02, time/batch = 0.0766s	
4870/5250 (epoch 46.381), train_loss = 1.25101455, grad/param norm = 4.8896e-02, time/batch = 0.0760s	
4871/5250 (epoch 46.390), train_loss = 1.26020770, grad/param norm = 5.2762e-02, time/batch = 0.0781s	
4872/5250 (epoch 46.400), train_loss = 1.26672409, grad/param norm = 4.9502e-02, time/batch = 0.0763s	
4873/5250 (epoch 46.410), train_loss = 1.26850926, grad/param norm = 5.3670e-02, time/batch = 0.0762s	
4874/5250 (epoch 46.419), train_loss = 1.26230213, grad/param norm = 5.0071e-02, time/batch = 0.0765s	
4875/5250 (epoch 46.429), train_loss = 1.27176502, grad/param norm = 5.0617e-02, time/batch = 0.0759s	
4876/5250 (epoch 46.438), train_loss = 1.28952843, grad/param norm = 5.7256e-02, time/batch = 0.0762s	
4877/5250 (epoch 46.448), train_loss = 1.25060980, grad/param norm = 4.9009e-02, time/batch = 0.0754s	
4878/5250 (epoch 46.457), train_loss = 1.25456271, grad/param norm = 5.1061e-02, time/batch = 0.0753s	
4879/5250 (epoch 46.467), train_loss = 1.26152572, grad/param norm = 4.8177e-02, time/batch = 0.0780s	
4880/5250 (epoch 46.476), train_loss = 1.25602039, grad/param norm = 5.1148e-02, time/batch = 0.0776s	
4881/5250 (epoch 46.486), train_loss = 1.27892366, grad/param norm = 5.2908e-02, time/batch = 0.0779s	
4882/5250 (epoch 46.495), train_loss = 1.27941268, grad/param norm = 5.2491e-02, time/batch = 0.0759s	
4883/5250 (epoch 46.505), train_loss = 1.28513968, grad/param norm = 5.5291e-02, time/batch = 0.0757s	
4884/5250 (epoch 46.514), train_loss = 1.27851068, grad/param norm = 4.9609e-02, time/batch = 0.0760s	
4885/5250 (epoch 46.524), train_loss = 1.25927337, grad/param norm = 6.4090e-02, time/batch = 0.0755s	
4886/5250 (epoch 46.533), train_loss = 1.26817399, grad/param norm = 5.4651e-02, time/batch = 0.0764s	
4887/5250 (epoch 46.543), train_loss = 1.25728585, grad/param norm = 5.3535e-02, time/batch = 0.0757s	
4888/5250 (epoch 46.552), train_loss = 1.26285104, grad/param norm = 5.1282e-02, time/batch = 0.0757s	
4889/5250 (epoch 46.562), train_loss = 1.26231021, grad/param norm = 5.1876e-02, time/batch = 0.0760s	
4890/5250 (epoch 46.571), train_loss = 1.26622144, grad/param norm = 5.1341e-02, time/batch = 0.0760s	
4891/5250 (epoch 46.581), train_loss = 1.29817064, grad/param norm = 5.3437e-02, time/batch = 0.0784s	
4892/5250 (epoch 46.590), train_loss = 1.26764660, grad/param norm = 5.0870e-02, time/batch = 0.0758s	
4893/5250 (epoch 46.600), train_loss = 1.29303476, grad/param norm = 5.2819e-02, time/batch = 0.0758s	
4894/5250 (epoch 46.610), train_loss = 1.27815672, grad/param norm = 5.2775e-02, time/batch = 0.0760s	
4895/5250 (epoch 46.619), train_loss = 1.26907401, grad/param norm = 5.2334e-02, time/batch = 0.0760s	
4896/5250 (epoch 46.629), train_loss = 1.27593689, grad/param norm = 5.1310e-02, time/batch = 0.0762s	
4897/5250 (epoch 46.638), train_loss = 1.25928395, grad/param norm = 4.8555e-02, time/batch = 0.0765s	
4898/5250 (epoch 46.648), train_loss = 1.26788847, grad/param norm = 5.0774e-02, time/batch = 0.0760s	
4899/5250 (epoch 46.657), train_loss = 1.26728693, grad/param norm = 4.9831e-02, time/batch = 0.0763s	
4900/5250 (epoch 46.667), train_loss = 1.27442145, grad/param norm = 5.3747e-02, time/batch = 0.0754s	
4901/5250 (epoch 46.676), train_loss = 1.26657698, grad/param norm = 5.3555e-02, time/batch = 0.0778s	
4902/5250 (epoch 46.686), train_loss = 1.29548774, grad/param norm = 4.9396e-02, time/batch = 0.0765s	
4903/5250 (epoch 46.695), train_loss = 1.27613381, grad/param norm = 5.7055e-02, time/batch = 0.0758s	
4904/5250 (epoch 46.705), train_loss = 1.25830389, grad/param norm = 5.3147e-02, time/batch = 0.0760s	
4905/5250 (epoch 46.714), train_loss = 1.29128208, grad/param norm = 5.5570e-02, time/batch = 0.0760s	
4906/5250 (epoch 46.724), train_loss = 1.26906359, grad/param norm = 4.9258e-02, time/batch = 0.0762s	
4907/5250 (epoch 46.733), train_loss = 1.25077223, grad/param norm = 4.9657e-02, time/batch = 0.0753s	
4908/5250 (epoch 46.743), train_loss = 1.25761871, grad/param norm = 5.4800e-02, time/batch = 0.0760s	
4909/5250 (epoch 46.752), train_loss = 1.26575170, grad/param norm = 5.3120e-02, time/batch = 0.0764s	
4910/5250 (epoch 46.762), train_loss = 1.25504652, grad/param norm = 4.9950e-02, time/batch = 0.0759s	
4911/5250 (epoch 46.771), train_loss = 1.25183509, grad/param norm = 5.3254e-02, time/batch = 0.0780s	
4912/5250 (epoch 46.781), train_loss = 1.27791877, grad/param norm = 5.2219e-02, time/batch = 0.0759s	
4913/5250 (epoch 46.790), train_loss = 1.28730367, grad/param norm = 5.9834e-02, time/batch = 0.0765s	
4914/5250 (epoch 46.800), train_loss = 1.26825715, grad/param norm = 5.2758e-02, time/batch = 0.0763s	
4915/5250 (epoch 46.810), train_loss = 1.27083432, grad/param norm = 5.0924e-02, time/batch = 0.0760s	
4916/5250 (epoch 46.819), train_loss = 1.27773710, grad/param norm = 5.2480e-02, time/batch = 0.0761s	
4917/5250 (epoch 46.829), train_loss = 1.27424892, grad/param norm = 5.1000e-02, time/batch = 0.0755s	
4918/5250 (epoch 46.838), train_loss = 1.25920982, grad/param norm = 5.0098e-02, time/batch = 0.0753s	
4919/5250 (epoch 46.848), train_loss = 1.25598942, grad/param norm = 4.9510e-02, time/batch = 0.0764s	
4920/5250 (epoch 46.857), train_loss = 1.26858468, grad/param norm = 4.9430e-02, time/batch = 0.0760s	
4921/5250 (epoch 46.867), train_loss = 1.26717078, grad/param norm = 5.0282e-02, time/batch = 0.0781s	
4922/5250 (epoch 46.876), train_loss = 1.26935934, grad/param norm = 4.7842e-02, time/batch = 0.0760s	
4923/5250 (epoch 46.886), train_loss = 1.25583558, grad/param norm = 5.0869e-02, time/batch = 0.0761s	
4924/5250 (epoch 46.895), train_loss = 1.29840578, grad/param norm = 5.6169e-02, time/batch = 0.0763s	
4925/5250 (epoch 46.905), train_loss = 1.28437024, grad/param norm = 4.9214e-02, time/batch = 0.0763s	
4926/5250 (epoch 46.914), train_loss = 1.29767109, grad/param norm = 5.1600e-02, time/batch = 0.0763s	
4927/5250 (epoch 46.924), train_loss = 1.28928903, grad/param norm = 5.0749e-02, time/batch = 0.0756s	
4928/5250 (epoch 46.933), train_loss = 1.26025094, grad/param norm = 5.1441e-02, time/batch = 0.0756s	
4929/5250 (epoch 46.943), train_loss = 1.29933851, grad/param norm = 5.2875e-02, time/batch = 0.0762s	
4930/5250 (epoch 46.952), train_loss = 1.29640195, grad/param norm = 5.2733e-02, time/batch = 0.0762s	
4931/5250 (epoch 46.962), train_loss = 1.27564929, grad/param norm = 4.8692e-02, time/batch = 0.0781s	
4932/5250 (epoch 46.971), train_loss = 1.27324438, grad/param norm = 5.2975e-02, time/batch = 0.0760s	
4933/5250 (epoch 46.981), train_loss = 1.29309019, grad/param norm = 5.2748e-02, time/batch = 0.0761s	
4934/5250 (epoch 46.990), train_loss = 1.29423515, grad/param norm = 5.6649e-02, time/batch = 0.0763s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
4935/5250 (epoch 47.000), train_loss = 1.28256743, grad/param norm = 5.2210e-02, time/batch = 0.0764s	
4936/5250 (epoch 47.010), train_loss = 1.48289625, grad/param norm = 6.3116e-02, time/batch = 0.0769s	
4937/5250 (epoch 47.019), train_loss = 1.26122939, grad/param norm = 5.6371e-02, time/batch = 0.0755s	
4938/5250 (epoch 47.029), train_loss = 1.27460012, grad/param norm = 4.9571e-02, time/batch = 0.0752s	
4939/5250 (epoch 47.038), train_loss = 1.26344792, grad/param norm = 5.0120e-02, time/batch = 0.0755s	
4940/5250 (epoch 47.048), train_loss = 1.24235000, grad/param norm = 5.0674e-02, time/batch = 0.0757s	
4941/5250 (epoch 47.057), train_loss = 1.25681057, grad/param norm = 4.8788e-02, time/batch = 0.0782s	
4942/5250 (epoch 47.067), train_loss = 1.26742100, grad/param norm = 4.7872e-02, time/batch = 0.0759s	
4943/5250 (epoch 47.076), train_loss = 1.27131219, grad/param norm = 5.4383e-02, time/batch = 0.0761s	
4944/5250 (epoch 47.086), train_loss = 1.22200887, grad/param norm = 5.2782e-02, time/batch = 0.0760s	
4945/5250 (epoch 47.095), train_loss = 1.24639690, grad/param norm = 4.7212e-02, time/batch = 0.0755s	
4946/5250 (epoch 47.105), train_loss = 1.26858012, grad/param norm = 5.1201e-02, time/batch = 0.0763s	
4947/5250 (epoch 47.114), train_loss = 1.24947868, grad/param norm = 5.3046e-02, time/batch = 0.0764s	
4948/5250 (epoch 47.124), train_loss = 1.27117431, grad/param norm = 5.4264e-02, time/batch = 0.0753s	
4949/5250 (epoch 47.133), train_loss = 1.25649476, grad/param norm = 5.0479e-02, time/batch = 0.0757s	
4950/5250 (epoch 47.143), train_loss = 1.24177087, grad/param norm = 5.1565e-02, time/batch = 0.0761s	
4951/5250 (epoch 47.152), train_loss = 1.24374547, grad/param norm = 5.0769e-02, time/batch = 0.0780s	
4952/5250 (epoch 47.162), train_loss = 1.27006782, grad/param norm = 5.0691e-02, time/batch = 0.0762s	
4953/5250 (epoch 47.171), train_loss = 1.26651108, grad/param norm = 4.7471e-02, time/batch = 0.0763s	
4954/5250 (epoch 47.181), train_loss = 1.27581204, grad/param norm = 5.1776e-02, time/batch = 0.0760s	
4955/5250 (epoch 47.190), train_loss = 1.27225592, grad/param norm = 5.1830e-02, time/batch = 0.0758s	
4956/5250 (epoch 47.200), train_loss = 1.25619263, grad/param norm = 5.1835e-02, time/batch = 0.0765s	
4957/5250 (epoch 47.210), train_loss = 1.25784723, grad/param norm = 4.9292e-02, time/batch = 0.0755s	
4958/5250 (epoch 47.219), train_loss = 1.30312627, grad/param norm = 4.9530e-02, time/batch = 0.0756s	
4959/5250 (epoch 47.229), train_loss = 1.25837511, grad/param norm = 5.0713e-02, time/batch = 0.0758s	
4960/5250 (epoch 47.238), train_loss = 1.26241098, grad/param norm = 5.1341e-02, time/batch = 0.0762s	
4961/5250 (epoch 47.248), train_loss = 1.26643462, grad/param norm = 5.0967e-02, time/batch = 0.0780s	
4962/5250 (epoch 47.257), train_loss = 1.26109377, grad/param norm = 4.9451e-02, time/batch = 0.0758s	
4963/5250 (epoch 47.267), train_loss = 1.24769123, grad/param norm = 5.2436e-02, time/batch = 0.0762s	
4964/5250 (epoch 47.276), train_loss = 1.24837398, grad/param norm = 4.6731e-02, time/batch = 0.0761s	
4965/5250 (epoch 47.286), train_loss = 1.23387658, grad/param norm = 5.0972e-02, time/batch = 0.0761s	
4966/5250 (epoch 47.295), train_loss = 1.26135618, grad/param norm = 5.1266e-02, time/batch = 0.0763s	
4967/5250 (epoch 47.305), train_loss = 1.25101726, grad/param norm = 5.1256e-02, time/batch = 0.0757s	
4968/5250 (epoch 47.314), train_loss = 1.24487309, grad/param norm = 5.0617e-02, time/batch = 0.0752s	
4969/5250 (epoch 47.324), train_loss = 1.25748648, grad/param norm = 5.1552e-02, time/batch = 0.0765s	
4970/5250 (epoch 47.333), train_loss = 1.25803026, grad/param norm = 4.9537e-02, time/batch = 0.0758s	
4971/5250 (epoch 47.343), train_loss = 1.26130597, grad/param norm = 5.0855e-02, time/batch = 0.0780s	
4972/5250 (epoch 47.352), train_loss = 1.27366287, grad/param norm = 5.1039e-02, time/batch = 0.0760s	
4973/5250 (epoch 47.362), train_loss = 1.27032478, grad/param norm = 5.1419e-02, time/batch = 0.0758s	
4974/5250 (epoch 47.371), train_loss = 1.25449127, grad/param norm = 4.9420e-02, time/batch = 0.0760s	
4975/5250 (epoch 47.381), train_loss = 1.24882901, grad/param norm = 4.8937e-02, time/batch = 0.0765s	
4976/5250 (epoch 47.390), train_loss = 1.25799079, grad/param norm = 5.2589e-02, time/batch = 0.0764s	
4977/5250 (epoch 47.400), train_loss = 1.26456560, grad/param norm = 4.9415e-02, time/batch = 0.0751s	
4978/5250 (epoch 47.410), train_loss = 1.26614084, grad/param norm = 5.3307e-02, time/batch = 0.0752s	
4979/5250 (epoch 47.419), train_loss = 1.26009725, grad/param norm = 4.9787e-02, time/batch = 0.0760s	
4980/5250 (epoch 47.429), train_loss = 1.26976601, grad/param norm = 5.0998e-02, time/batch = 0.0758s	
4981/5250 (epoch 47.438), train_loss = 1.28711664, grad/param norm = 5.6683e-02, time/batch = 0.0779s	
4982/5250 (epoch 47.448), train_loss = 1.24836512, grad/param norm = 4.8394e-02, time/batch = 0.0759s	
4983/5250 (epoch 47.457), train_loss = 1.25246664, grad/param norm = 5.0854e-02, time/batch = 0.0757s	
4984/5250 (epoch 47.467), train_loss = 1.25939467, grad/param norm = 4.7884e-02, time/batch = 0.0761s	
4985/5250 (epoch 47.476), train_loss = 1.25369637, grad/param norm = 5.0871e-02, time/batch = 0.0759s	
4986/5250 (epoch 47.486), train_loss = 1.27675980, grad/param norm = 5.2666e-02, time/batch = 0.0769s	
4987/5250 (epoch 47.495), train_loss = 1.27718182, grad/param norm = 5.2055e-02, time/batch = 0.0761s	
4988/5250 (epoch 47.505), train_loss = 1.28275601, grad/param norm = 5.4428e-02, time/batch = 0.0753s	
4989/5250 (epoch 47.514), train_loss = 1.27628041, grad/param norm = 4.9855e-02, time/batch = 0.0760s	
4990/5250 (epoch 47.524), train_loss = 1.25728726, grad/param norm = 6.4651e-02, time/batch = 0.0758s	
4991/5250 (epoch 47.533), train_loss = 1.26588723, grad/param norm = 5.3781e-02, time/batch = 0.0784s	
4992/5250 (epoch 47.543), train_loss = 1.25516982, grad/param norm = 5.3749e-02, time/batch = 0.0760s	
4993/5250 (epoch 47.552), train_loss = 1.26058655, grad/param norm = 5.0983e-02, time/batch = 0.0761s	
4994/5250 (epoch 47.562), train_loss = 1.26025724, grad/param norm = 5.2219e-02, time/batch = 0.0759s	
4995/5250 (epoch 47.571), train_loss = 1.26403812, grad/param norm = 5.1239e-02, time/batch = 0.0761s	
4996/5250 (epoch 47.581), train_loss = 1.29600824, grad/param norm = 5.3305e-02, time/batch = 0.0764s	
4997/5250 (epoch 47.590), train_loss = 1.26543687, grad/param norm = 5.0816e-02, time/batch = 0.0758s	
4998/5250 (epoch 47.600), train_loss = 1.29091990, grad/param norm = 5.2657e-02, time/batch = 0.0753s	
4999/5250 (epoch 47.610), train_loss = 1.27588760, grad/param norm = 5.2275e-02, time/batch = 0.0761s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch47.62_1.4189.t7	
5000/5250 (epoch 47.619), train_loss = 1.26700157, grad/param norm = 5.2053e-02, time/batch = 0.0784s	
5001/5250 (epoch 47.629), train_loss = 1.53925406, grad/param norm = 6.8453e-02, time/batch = 0.0787s	
5002/5250 (epoch 47.638), train_loss = 1.26100594, grad/param norm = 5.9692e-02, time/batch = 0.0761s	
5003/5250 (epoch 47.648), train_loss = 1.26850898, grad/param norm = 5.7577e-02, time/batch = 0.0760s	
5004/5250 (epoch 47.657), train_loss = 1.26554296, grad/param norm = 4.8222e-02, time/batch = 0.0768s	
5005/5250 (epoch 47.667), train_loss = 1.27260800, grad/param norm = 5.3948e-02, time/batch = 0.0781s	
5006/5250 (epoch 47.676), train_loss = 1.26379598, grad/param norm = 5.2259e-02, time/batch = 0.0772s	
5007/5250 (epoch 47.686), train_loss = 1.29377280, grad/param norm = 4.9866e-02, time/batch = 0.0763s	
5008/5250 (epoch 47.695), train_loss = 1.27385407, grad/param norm = 5.5696e-02, time/batch = 0.0766s	
5009/5250 (epoch 47.705), train_loss = 1.25638217, grad/param norm = 5.3556e-02, time/batch = 0.0767s	
5010/5250 (epoch 47.714), train_loss = 1.28864575, grad/param norm = 5.4876e-02, time/batch = 0.0764s	
5011/5250 (epoch 47.724), train_loss = 1.26671033, grad/param norm = 4.8986e-02, time/batch = 0.0781s	
5012/5250 (epoch 47.733), train_loss = 1.24833409, grad/param norm = 4.9183e-02, time/batch = 0.0762s	
5013/5250 (epoch 47.743), train_loss = 1.25537816, grad/param norm = 5.4236e-02, time/batch = 0.0760s	
5014/5250 (epoch 47.752), train_loss = 1.26366006, grad/param norm = 5.1905e-02, time/batch = 0.0758s	
5015/5250 (epoch 47.762), train_loss = 1.25289939, grad/param norm = 5.0123e-02, time/batch = 0.0760s	
5016/5250 (epoch 47.771), train_loss = 1.24962819, grad/param norm = 5.2840e-02, time/batch = 0.0771s	
5017/5250 (epoch 47.781), train_loss = 1.27565775, grad/param norm = 5.1920e-02, time/batch = 0.0759s	
5018/5250 (epoch 47.790), train_loss = 1.28475193, grad/param norm = 5.9173e-02, time/batch = 0.0751s	
5019/5250 (epoch 47.800), train_loss = 1.26569123, grad/param norm = 5.1646e-02, time/batch = 0.0757s	
5020/5250 (epoch 47.810), train_loss = 1.26860964, grad/param norm = 5.0916e-02, time/batch = 0.0759s	
5021/5250 (epoch 47.819), train_loss = 1.27551735, grad/param norm = 5.1956e-02, time/batch = 0.0781s	
5022/5250 (epoch 47.829), train_loss = 1.27227761, grad/param norm = 5.1032e-02, time/batch = 0.0767s	
5023/5250 (epoch 47.838), train_loss = 1.25716512, grad/param norm = 5.0034e-02, time/batch = 0.0761s	
5024/5250 (epoch 47.848), train_loss = 1.25381762, grad/param norm = 4.9174e-02, time/batch = 0.0760s	
5025/5250 (epoch 47.857), train_loss = 1.26642183, grad/param norm = 4.9306e-02, time/batch = 0.0761s	
5026/5250 (epoch 47.867), train_loss = 1.26495122, grad/param norm = 5.0042e-02, time/batch = 0.0762s	
5027/5250 (epoch 47.876), train_loss = 1.26702533, grad/param norm = 4.7056e-02, time/batch = 0.0755s	
5028/5250 (epoch 47.886), train_loss = 1.25358252, grad/param norm = 5.0900e-02, time/batch = 0.0759s	
5029/5250 (epoch 47.895), train_loss = 1.29605073, grad/param norm = 5.5428e-02, time/batch = 0.0761s	
5030/5250 (epoch 47.905), train_loss = 1.28211905, grad/param norm = 4.8435e-02, time/batch = 0.0756s	
5031/5250 (epoch 47.914), train_loss = 1.29525925, grad/param norm = 5.1589e-02, time/batch = 0.0781s	
5032/5250 (epoch 47.924), train_loss = 1.28717297, grad/param norm = 5.0743e-02, time/batch = 0.0759s	
5033/5250 (epoch 47.933), train_loss = 1.25795128, grad/param norm = 5.1165e-02, time/batch = 0.0769s	
5034/5250 (epoch 47.943), train_loss = 1.29698536, grad/param norm = 5.2324e-02, time/batch = 0.0758s	
5035/5250 (epoch 47.952), train_loss = 1.29415755, grad/param norm = 5.2791e-02, time/batch = 0.0761s	
5036/5250 (epoch 47.962), train_loss = 1.27347092, grad/param norm = 4.8718e-02, time/batch = 0.0763s	
5037/5250 (epoch 47.971), train_loss = 1.27132921, grad/param norm = 5.2793e-02, time/batch = 0.0757s	
5038/5250 (epoch 47.981), train_loss = 1.29072971, grad/param norm = 5.2554e-02, time/batch = 0.0757s	
5039/5250 (epoch 47.990), train_loss = 1.29179732, grad/param norm = 5.5845e-02, time/batch = 0.0770s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
5040/5250 (epoch 48.000), train_loss = 1.28045017, grad/param norm = 5.1573e-02, time/batch = 0.0761s	
5041/5250 (epoch 48.010), train_loss = 1.48030332, grad/param norm = 6.2611e-02, time/batch = 0.0780s	
5042/5250 (epoch 48.019), train_loss = 1.25888474, grad/param norm = 5.5508e-02, time/batch = 0.0759s	
5043/5250 (epoch 48.029), train_loss = 1.27253874, grad/param norm = 4.9339e-02, time/batch = 0.0760s	
5044/5250 (epoch 48.038), train_loss = 1.26130573, grad/param norm = 4.9960e-02, time/batch = 0.0764s	
5045/5250 (epoch 48.048), train_loss = 1.24021268, grad/param norm = 5.0594e-02, time/batch = 0.0763s	
5046/5250 (epoch 48.057), train_loss = 1.25481644, grad/param norm = 4.8863e-02, time/batch = 0.0763s	
5047/5250 (epoch 48.067), train_loss = 1.26536819, grad/param norm = 4.7833e-02, time/batch = 0.0754s	
5048/5250 (epoch 48.076), train_loss = 1.26929775, grad/param norm = 5.4186e-02, time/batch = 0.0755s	
5049/5250 (epoch 48.086), train_loss = 1.21993510, grad/param norm = 5.2263e-02, time/batch = 0.0763s	
5050/5250 (epoch 48.095), train_loss = 1.24422297, grad/param norm = 4.7375e-02, time/batch = 0.0763s	
5051/5250 (epoch 48.105), train_loss = 1.26648095, grad/param norm = 5.1019e-02, time/batch = 0.0783s	
5052/5250 (epoch 48.114), train_loss = 1.24740004, grad/param norm = 5.2627e-02, time/batch = 0.0759s	
5053/5250 (epoch 48.124), train_loss = 1.26922946, grad/param norm = 5.4333e-02, time/batch = 0.0760s	
5054/5250 (epoch 48.133), train_loss = 1.25441553, grad/param norm = 5.0282e-02, time/batch = 0.0757s	
5055/5250 (epoch 48.143), train_loss = 1.23937714, grad/param norm = 5.0717e-02, time/batch = 0.0766s	
5056/5250 (epoch 48.152), train_loss = 1.24182725, grad/param norm = 5.1180e-02, time/batch = 0.0764s	
5057/5250 (epoch 48.162), train_loss = 1.26776085, grad/param norm = 5.0557e-02, time/batch = 0.0759s	
5058/5250 (epoch 48.171), train_loss = 1.26423907, grad/param norm = 4.7492e-02, time/batch = 0.0756s	
5059/5250 (epoch 48.181), train_loss = 1.27362025, grad/param norm = 5.1747e-02, time/batch = 0.0762s	
5060/5250 (epoch 48.190), train_loss = 1.27032368, grad/param norm = 5.2120e-02, time/batch = 0.0759s	
5061/5250 (epoch 48.200), train_loss = 1.25413411, grad/param norm = 5.1501e-02, time/batch = 0.0787s	
5062/5250 (epoch 48.210), train_loss = 1.25572911, grad/param norm = 4.9216e-02, time/batch = 0.0764s	
5063/5250 (epoch 48.219), train_loss = 1.30094354, grad/param norm = 4.9302e-02, time/batch = 0.0763s	
5064/5250 (epoch 48.229), train_loss = 1.25628946, grad/param norm = 5.0733e-02, time/batch = 0.0761s	
5065/5250 (epoch 48.238), train_loss = 1.26023143, grad/param norm = 5.1039e-02, time/batch = 0.0758s	
5066/5250 (epoch 48.248), train_loss = 1.26418950, grad/param norm = 5.0855e-02, time/batch = 0.0766s	
5067/5250 (epoch 48.257), train_loss = 1.25912921, grad/param norm = 4.9439e-02, time/batch = 0.0764s	
5068/5250 (epoch 48.267), train_loss = 1.24570913, grad/param norm = 5.2428e-02, time/batch = 0.0757s	
5069/5250 (epoch 48.276), train_loss = 1.24625213, grad/param norm = 4.6439e-02, time/batch = 0.0761s	
5070/5250 (epoch 48.286), train_loss = 1.23173624, grad/param norm = 5.0766e-02, time/batch = 0.0756s	
5071/5250 (epoch 48.295), train_loss = 1.25940566, grad/param norm = 5.1225e-02, time/batch = 0.0781s	
5072/5250 (epoch 48.305), train_loss = 1.24880889, grad/param norm = 5.1039e-02, time/batch = 0.0766s	
5073/5250 (epoch 48.314), train_loss = 1.24278567, grad/param norm = 5.0490e-02, time/batch = 0.0763s	
5074/5250 (epoch 48.324), train_loss = 1.25546186, grad/param norm = 5.1285e-02, time/batch = 0.0763s	
5075/5250 (epoch 48.333), train_loss = 1.25594473, grad/param norm = 4.9411e-02, time/batch = 0.0764s	
5076/5250 (epoch 48.343), train_loss = 1.25920505, grad/param norm = 5.0723e-02, time/batch = 0.0764s	
5077/5250 (epoch 48.352), train_loss = 1.27157937, grad/param norm = 5.0664e-02, time/batch = 0.0756s	
5078/5250 (epoch 48.362), train_loss = 1.26805047, grad/param norm = 5.1192e-02, time/batch = 0.0761s	
5079/5250 (epoch 48.371), train_loss = 1.25265538, grad/param norm = 4.9361e-02, time/batch = 0.0761s	
5080/5250 (epoch 48.381), train_loss = 1.24671548, grad/param norm = 4.8718e-02, time/batch = 0.0761s	
5081/5250 (epoch 48.390), train_loss = 1.25589079, grad/param norm = 5.2387e-02, time/batch = 0.0781s	
5082/5250 (epoch 48.400), train_loss = 1.26247287, grad/param norm = 4.9317e-02, time/batch = 0.0759s	
5083/5250 (epoch 48.410), train_loss = 1.26389486, grad/param norm = 5.3062e-02, time/batch = 0.0763s	
5084/5250 (epoch 48.419), train_loss = 1.25799324, grad/param norm = 4.9635e-02, time/batch = 0.0760s	
5085/5250 (epoch 48.429), train_loss = 1.26779017, grad/param norm = 5.1092e-02, time/batch = 0.0763s	
5086/5250 (epoch 48.438), train_loss = 1.28487093, grad/param norm = 5.6003e-02, time/batch = 0.0763s	
5087/5250 (epoch 48.448), train_loss = 1.24619604, grad/param norm = 4.7943e-02, time/batch = 0.0755s	
5088/5250 (epoch 48.457), train_loss = 1.25042712, grad/param norm = 5.0630e-02, time/batch = 0.0752s	
5089/5250 (epoch 48.467), train_loss = 1.25736731, grad/param norm = 4.7663e-02, time/batch = 0.0764s	
5090/5250 (epoch 48.476), train_loss = 1.25153790, grad/param norm = 5.0720e-02, time/batch = 0.0759s	
5091/5250 (epoch 48.486), train_loss = 1.27466313, grad/param norm = 5.2399e-02, time/batch = 0.0781s	
5092/5250 (epoch 48.495), train_loss = 1.27511603, grad/param norm = 5.1620e-02, time/batch = 0.0762s	
5093/5250 (epoch 48.505), train_loss = 1.28052342, grad/param norm = 5.3795e-02, time/batch = 0.0759s	
5094/5250 (epoch 48.514), train_loss = 1.27411724, grad/param norm = 5.0050e-02, time/batch = 0.0764s	
5095/5250 (epoch 48.524), train_loss = 1.25523306, grad/param norm = 6.4585e-02, time/batch = 0.0761s	
5096/5250 (epoch 48.533), train_loss = 1.26368750, grad/param norm = 5.3064e-02, time/batch = 0.0764s	
5097/5250 (epoch 48.543), train_loss = 1.25317946, grad/param norm = 5.3771e-02, time/batch = 0.0758s	
5098/5250 (epoch 48.552), train_loss = 1.25845136, grad/param norm = 5.0680e-02, time/batch = 0.0759s	
5099/5250 (epoch 48.562), train_loss = 1.25825073, grad/param norm = 5.2382e-02, time/batch = 0.0760s	
5100/5250 (epoch 48.571), train_loss = 1.26196333, grad/param norm = 5.1115e-02, time/batch = 0.0759s	
5101/5250 (epoch 48.581), train_loss = 1.29387416, grad/param norm = 5.3139e-02, time/batch = 0.0779s	
5102/5250 (epoch 48.590), train_loss = 1.26336357, grad/param norm = 5.0839e-02, time/batch = 0.0758s	
5103/5250 (epoch 48.600), train_loss = 1.28890564, grad/param norm = 5.2470e-02, time/batch = 0.0759s	
5104/5250 (epoch 48.610), train_loss = 1.27369783, grad/param norm = 5.1889e-02, time/batch = 0.0758s	
5105/5250 (epoch 48.619), train_loss = 1.26495867, grad/param norm = 5.1764e-02, time/batch = 0.0758s	
5106/5250 (epoch 48.629), train_loss = 1.27253220, grad/param norm = 5.1200e-02, time/batch = 0.0769s	
5107/5250 (epoch 48.638), train_loss = 1.25555340, grad/param norm = 4.8654e-02, time/batch = 0.0759s	
5108/5250 (epoch 48.648), train_loss = 1.26395144, grad/param norm = 5.0354e-02, time/batch = 0.0758s	
5109/5250 (epoch 48.657), train_loss = 1.26318592, grad/param norm = 4.9610e-02, time/batch = 0.0762s	
5110/5250 (epoch 48.667), train_loss = 1.27054982, grad/param norm = 5.3789e-02, time/batch = 0.0763s	
5111/5250 (epoch 48.676), train_loss = 1.26181426, grad/param norm = 5.3090e-02, time/batch = 0.0793s	
5112/5250 (epoch 48.686), train_loss = 1.29131547, grad/param norm = 4.9635e-02, time/batch = 0.0763s	
5113/5250 (epoch 48.695), train_loss = 1.27201380, grad/param norm = 5.6620e-02, time/batch = 0.0763s	
5114/5250 (epoch 48.705), train_loss = 1.25400411, grad/param norm = 5.2990e-02, time/batch = 0.0761s	
5115/5250 (epoch 48.714), train_loss = 1.28666185, grad/param norm = 5.5370e-02, time/batch = 0.0756s	
5116/5250 (epoch 48.724), train_loss = 1.26459162, grad/param norm = 4.9111e-02, time/batch = 0.0763s	
5117/5250 (epoch 48.733), train_loss = 1.24671106, grad/param norm = 4.9289e-02, time/batch = 0.0760s	
5118/5250 (epoch 48.743), train_loss = 1.25341638, grad/param norm = 5.4353e-02, time/batch = 0.0756s	
5119/5250 (epoch 48.752), train_loss = 1.26136928, grad/param norm = 5.2586e-02, time/batch = 0.0760s	
5120/5250 (epoch 48.762), train_loss = 1.25085803, grad/param norm = 4.9881e-02, time/batch = 0.0762s	
5121/5250 (epoch 48.771), train_loss = 1.24768019, grad/param norm = 5.2757e-02, time/batch = 0.0783s	
5122/5250 (epoch 48.781), train_loss = 1.27369801, grad/param norm = 5.1777e-02, time/batch = 0.0765s	
5123/5250 (epoch 48.790), train_loss = 1.28260507, grad/param norm = 5.8696e-02, time/batch = 0.0764s	
5124/5250 (epoch 48.800), train_loss = 1.26392273, grad/param norm = 5.1819e-02, time/batch = 0.0762s	
5125/5250 (epoch 48.810), train_loss = 1.26645674, grad/param norm = 5.0655e-02, time/batch = 0.0758s	
5126/5250 (epoch 48.819), train_loss = 1.27336592, grad/param norm = 5.1642e-02, time/batch = 0.0763s	
5127/5250 (epoch 48.829), train_loss = 1.27018115, grad/param norm = 5.0832e-02, time/batch = 0.0755s	
5128/5250 (epoch 48.838), train_loss = 1.25530824, grad/param norm = 5.0104e-02, time/batch = 0.0757s	
5129/5250 (epoch 48.848), train_loss = 1.25186694, grad/param norm = 4.9280e-02, time/batch = 0.0763s	
5130/5250 (epoch 48.857), train_loss = 1.26440638, grad/param norm = 4.9423e-02, time/batch = 0.0759s	
5131/5250 (epoch 48.867), train_loss = 1.26307384, grad/param norm = 5.0176e-02, time/batch = 0.0781s	
5132/5250 (epoch 48.876), train_loss = 1.26502309, grad/param norm = 4.7431e-02, time/batch = 0.0761s	
5133/5250 (epoch 48.886), train_loss = 1.25162215, grad/param norm = 5.0895e-02, time/batch = 0.0760s	
5134/5250 (epoch 48.895), train_loss = 1.29408325, grad/param norm = 5.5421e-02, time/batch = 0.0760s	
5135/5250 (epoch 48.905), train_loss = 1.28006319, grad/param norm = 4.8851e-02, time/batch = 0.0764s	
5136/5250 (epoch 48.914), train_loss = 1.29321800, grad/param norm = 5.1356e-02, time/batch = 0.0763s	
5137/5250 (epoch 48.924), train_loss = 1.28490727, grad/param norm = 5.0435e-02, time/batch = 0.0753s	
5138/5250 (epoch 48.933), train_loss = 1.25591649, grad/param norm = 5.1192e-02, time/batch = 0.0754s	
5139/5250 (epoch 48.943), train_loss = 1.29490820, grad/param norm = 5.2124e-02, time/batch = 0.0766s	
5140/5250 (epoch 48.952), train_loss = 1.29198965, grad/param norm = 5.2653e-02, time/batch = 0.0757s	
5141/5250 (epoch 48.962), train_loss = 1.27131559, grad/param norm = 4.8619e-02, time/batch = 0.0780s	
5142/5250 (epoch 48.971), train_loss = 1.26941684, grad/param norm = 5.2892e-02, time/batch = 0.0761s	
5143/5250 (epoch 48.981), train_loss = 1.28881476, grad/param norm = 5.2535e-02, time/batch = 0.0760s	
5144/5250 (epoch 48.990), train_loss = 1.28969857, grad/param norm = 5.5749e-02, time/batch = 0.0761s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
5145/5250 (epoch 49.000), train_loss = 1.27844971, grad/param norm = 5.1311e-02, time/batch = 0.0768s	
5146/5250 (epoch 49.010), train_loss = 1.47923767, grad/param norm = 6.2733e-02, time/batch = 0.0762s	
5147/5250 (epoch 49.019), train_loss = 1.25681094, grad/param norm = 5.5486e-02, time/batch = 0.0755s	
5148/5250 (epoch 49.029), train_loss = 1.27058976, grad/param norm = 4.9496e-02, time/batch = 0.0759s	
5149/5250 (epoch 49.038), train_loss = 1.25929161, grad/param norm = 4.9886e-02, time/batch = 0.0764s	
5150/5250 (epoch 49.048), train_loss = 1.23822693, grad/param norm = 5.0635e-02, time/batch = 0.0759s	
5151/5250 (epoch 49.057), train_loss = 1.25288508, grad/param norm = 4.8968e-02, time/batch = 0.0782s	
5152/5250 (epoch 49.067), train_loss = 1.26341867, grad/param norm = 4.7806e-02, time/batch = 0.0762s	
5153/5250 (epoch 49.076), train_loss = 1.26728061, grad/param norm = 5.4019e-02, time/batch = 0.0760s	
5154/5250 (epoch 49.086), train_loss = 1.21795402, grad/param norm = 5.2004e-02, time/batch = 0.0760s	
5155/5250 (epoch 49.095), train_loss = 1.24230761, grad/param norm = 5.1528e-02, time/batch = 0.0761s	
5156/5250 (epoch 49.105), train_loss = 1.26521081, grad/param norm = 5.2816e-02, time/batch = 0.0768s	
5157/5250 (epoch 49.114), train_loss = 1.24598048, grad/param norm = 5.1621e-02, time/batch = 0.0756s	
5158/5250 (epoch 49.124), train_loss = 1.26662407, grad/param norm = 5.2862e-02, time/batch = 0.0755s	
5159/5250 (epoch 49.133), train_loss = 1.25293951, grad/param norm = 5.1701e-02, time/batch = 0.0762s	
5160/5250 (epoch 49.143), train_loss = 1.23746795, grad/param norm = 5.0709e-02, time/batch = 0.0758s	
5161/5250 (epoch 49.152), train_loss = 1.24005728, grad/param norm = 5.1538e-02, time/batch = 0.0784s	
5162/5250 (epoch 49.162), train_loss = 1.26586782, grad/param norm = 5.0633e-02, time/batch = 0.0762s	
5163/5250 (epoch 49.171), train_loss = 1.26191355, grad/param norm = 4.7244e-02, time/batch = 0.0762s	
5164/5250 (epoch 49.181), train_loss = 1.27147819, grad/param norm = 5.1567e-02, time/batch = 0.0760s	
5165/5250 (epoch 49.190), train_loss = 1.26852390, grad/param norm = 5.2302e-02, time/batch = 0.0758s	
5166/5250 (epoch 49.200), train_loss = 1.25210264, grad/param norm = 5.1207e-02, time/batch = 0.0764s	
5167/5250 (epoch 49.210), train_loss = 1.25374379, grad/param norm = 4.9266e-02, time/batch = 0.0760s	
5168/5250 (epoch 49.219), train_loss = 1.29877134, grad/param norm = 4.9127e-02, time/batch = 0.0755s	
5169/5250 (epoch 49.229), train_loss = 1.25432168, grad/param norm = 5.0620e-02, time/batch = 0.0763s	
5170/5250 (epoch 49.238), train_loss = 1.25810587, grad/param norm = 5.0731e-02, time/batch = 0.0758s	
5171/5250 (epoch 49.248), train_loss = 1.26209550, grad/param norm = 5.0835e-02, time/batch = 0.0782s	
5172/5250 (epoch 49.257), train_loss = 1.25736133, grad/param norm = 4.9483e-02, time/batch = 0.0759s	
5173/5250 (epoch 49.267), train_loss = 1.24388934, grad/param norm = 5.2040e-02, time/batch = 0.0763s	
5174/5250 (epoch 49.276), train_loss = 1.24453038, grad/param norm = 4.6838e-02, time/batch = 0.0759s	
5175/5250 (epoch 49.286), train_loss = 1.22980825, grad/param norm = 5.0962e-02, time/batch = 0.0760s	
5176/5250 (epoch 49.295), train_loss = 1.25750676, grad/param norm = 5.1396e-02, time/batch = 0.0765s	
5177/5250 (epoch 49.305), train_loss = 1.24676935, grad/param norm = 5.1192e-02, time/batch = 0.0757s	
5178/5250 (epoch 49.314), train_loss = 1.24109592, grad/param norm = 5.0974e-02, time/batch = 0.0760s	
5179/5250 (epoch 49.324), train_loss = 1.25362267, grad/param norm = 5.1612e-02, time/batch = 0.0761s	
5180/5250 (epoch 49.333), train_loss = 1.25393095, grad/param norm = 4.9333e-02, time/batch = 0.0759s	
5181/5250 (epoch 49.343), train_loss = 1.25726496, grad/param norm = 5.0627e-02, time/batch = 0.0780s	
5182/5250 (epoch 49.352), train_loss = 1.26949436, grad/param norm = 5.0469e-02, time/batch = 0.0757s	
5183/5250 (epoch 49.362), train_loss = 1.26588604, grad/param norm = 5.1218e-02, time/batch = 0.0763s	
5184/5250 (epoch 49.371), train_loss = 1.25097201, grad/param norm = 4.9411e-02, time/batch = 0.0765s	
5185/5250 (epoch 49.381), train_loss = 1.24468823, grad/param norm = 4.8650e-02, time/batch = 0.0761s	
5186/5250 (epoch 49.390), train_loss = 1.25386395, grad/param norm = 5.2243e-02, time/batch = 0.0764s	
5187/5250 (epoch 49.400), train_loss = 1.26060444, grad/param norm = 4.9325e-02, time/batch = 0.0754s	
5188/5250 (epoch 49.410), train_loss = 1.26175360, grad/param norm = 5.2860e-02, time/batch = 0.0755s	
5189/5250 (epoch 49.419), train_loss = 1.25598608, grad/param norm = 4.9544e-02, time/batch = 0.0761s	
5190/5250 (epoch 49.429), train_loss = 1.26591337, grad/param norm = 5.1430e-02, time/batch = 0.0760s	
5191/5250 (epoch 49.438), train_loss = 1.28268767, grad/param norm = 5.5862e-02, time/batch = 0.0781s	
5192/5250 (epoch 49.448), train_loss = 1.24431923, grad/param norm = 4.7707e-02, time/batch = 0.0759s	
5193/5250 (epoch 49.457), train_loss = 1.24852337, grad/param norm = 5.0550e-02, time/batch = 0.0759s	
5194/5250 (epoch 49.467), train_loss = 1.25539682, grad/param norm = 4.7509e-02, time/batch = 0.0760s	
5195/5250 (epoch 49.476), train_loss = 1.24944935, grad/param norm = 5.0564e-02, time/batch = 0.0765s	
5196/5250 (epoch 49.486), train_loss = 1.27270002, grad/param norm = 5.2247e-02, time/batch = 0.0766s	
5197/5250 (epoch 49.495), train_loss = 1.27308734, grad/param norm = 5.1494e-02, time/batch = 0.0759s	
5198/5250 (epoch 49.505), train_loss = 1.27835598, grad/param norm = 5.3302e-02, time/batch = 0.0759s	
5199/5250 (epoch 49.514), train_loss = 1.27216378, grad/param norm = 5.0385e-02, time/batch = 0.0763s	
5200/5250 (epoch 49.524), train_loss = 1.25333334, grad/param norm = 6.4796e-02, time/batch = 0.0758s	
5201/5250 (epoch 49.533), train_loss = 1.26158258, grad/param norm = 5.2391e-02, time/batch = 0.0782s	
5202/5250 (epoch 49.543), train_loss = 1.25122254, grad/param norm = 5.3933e-02, time/batch = 0.0761s	
5203/5250 (epoch 49.552), train_loss = 1.25641341, grad/param norm = 5.0499e-02, time/batch = 0.0762s	
5204/5250 (epoch 49.562), train_loss = 1.25628800, grad/param norm = 5.2704e-02, time/batch = 0.0762s	
5205/5250 (epoch 49.571), train_loss = 1.26000137, grad/param norm = 5.1076e-02, time/batch = 0.0761s	
5206/5250 (epoch 49.581), train_loss = 1.29186992, grad/param norm = 5.3066e-02, time/batch = 0.0765s	
5207/5250 (epoch 49.590), train_loss = 1.26141195, grad/param norm = 5.0719e-02, time/batch = 0.0757s	
5208/5250 (epoch 49.600), train_loss = 1.28692623, grad/param norm = 5.2364e-02, time/batch = 0.0756s	
5209/5250 (epoch 49.610), train_loss = 1.27165580, grad/param norm = 5.1516e-02, time/batch = 0.0762s	
5210/5250 (epoch 49.619), train_loss = 1.26303935, grad/param norm = 5.1577e-02, time/batch = 0.0758s	
5211/5250 (epoch 49.629), train_loss = 1.27017908, grad/param norm = 5.1144e-02, time/batch = 0.0781s	
5212/5250 (epoch 49.638), train_loss = 1.25368627, grad/param norm = 4.8864e-02, time/batch = 0.0764s	
5213/5250 (epoch 49.648), train_loss = 1.26207489, grad/param norm = 5.0558e-02, time/batch = 0.0763s	
5214/5250 (epoch 49.657), train_loss = 1.26117252, grad/param norm = 4.9563e-02, time/batch = 0.0758s	
5215/5250 (epoch 49.667), train_loss = 1.26860775, grad/param norm = 5.3648e-02, time/batch = 0.0756s	
5216/5250 (epoch 49.676), train_loss = 1.25956989, grad/param norm = 5.2836e-02, time/batch = 0.0762s	
5217/5250 (epoch 49.686), train_loss = 1.28924846, grad/param norm = 4.9827e-02, time/batch = 0.0765s	
5218/5250 (epoch 49.695), train_loss = 1.26992279, grad/param norm = 5.6296e-02, time/batch = 0.0759s	
5219/5250 (epoch 49.705), train_loss = 1.25188744, grad/param norm = 5.3016e-02, time/batch = 0.0759s	
5220/5250 (epoch 49.714), train_loss = 1.28451122, grad/param norm = 5.5448e-02, time/batch = 0.0758s	
5221/5250 (epoch 49.724), train_loss = 1.26236444, grad/param norm = 4.9038e-02, time/batch = 0.0780s	
5222/5250 (epoch 49.733), train_loss = 1.24477556, grad/param norm = 4.9174e-02, time/batch = 0.0759s	
5223/5250 (epoch 49.743), train_loss = 1.25139655, grad/param norm = 5.4152e-02, time/batch = 0.0766s	
5224/5250 (epoch 49.752), train_loss = 1.25934226, grad/param norm = 5.2332e-02, time/batch = 0.0759s	
5225/5250 (epoch 49.762), train_loss = 1.24883830, grad/param norm = 4.9788e-02, time/batch = 0.0762s	
5226/5250 (epoch 49.771), train_loss = 1.24562756, grad/param norm = 5.2128e-02, time/batch = 0.0764s	
5227/5250 (epoch 49.781), train_loss = 1.27167930, grad/param norm = 5.1630e-02, time/batch = 0.0759s	
5228/5250 (epoch 49.790), train_loss = 1.28037870, grad/param norm = 5.9099e-02, time/batch = 0.0752s	
5229/5250 (epoch 49.800), train_loss = 1.26185300, grad/param norm = 5.1545e-02, time/batch = 0.0770s	
5230/5250 (epoch 49.810), train_loss = 1.26448556, grad/param norm = 5.0819e-02, time/batch = 0.0758s	
5231/5250 (epoch 49.819), train_loss = 1.27126546, grad/param norm = 5.1510e-02, time/batch = 0.0779s	
5232/5250 (epoch 49.829), train_loss = 1.26819985, grad/param norm = 5.0843e-02, time/batch = 0.0760s	
5233/5250 (epoch 49.838), train_loss = 1.25348189, grad/param norm = 5.0094e-02, time/batch = 0.0760s	
5234/5250 (epoch 49.848), train_loss = 1.24995623, grad/param norm = 4.9178e-02, time/batch = 0.0765s	
5235/5250 (epoch 49.857), train_loss = 1.26235495, grad/param norm = 4.9394e-02, time/batch = 0.0761s	
5236/5250 (epoch 49.867), train_loss = 1.26112146, grad/param norm = 5.0007e-02, time/batch = 0.0764s	
5237/5250 (epoch 49.876), train_loss = 1.26291487, grad/param norm = 4.7023e-02, time/batch = 0.0756s	
5238/5250 (epoch 49.886), train_loss = 1.24957437, grad/param norm = 5.0845e-02, time/batch = 0.0756s	
5239/5250 (epoch 49.895), train_loss = 1.29203981, grad/param norm = 5.4945e-02, time/batch = 0.0761s	
5240/5250 (epoch 49.905), train_loss = 1.27801187, grad/param norm = 4.8597e-02, time/batch = 0.0767s	
5241/5250 (epoch 49.914), train_loss = 1.29104948, grad/param norm = 5.1245e-02, time/batch = 0.0781s	
5242/5250 (epoch 49.924), train_loss = 1.28290334, grad/param norm = 5.0304e-02, time/batch = 0.0760s	
5243/5250 (epoch 49.933), train_loss = 1.25384139, grad/param norm = 5.1127e-02, time/batch = 0.0761s	
5244/5250 (epoch 49.943), train_loss = 1.29287896, grad/param norm = 5.1921e-02, time/batch = 0.0761s	
5245/5250 (epoch 49.952), train_loss = 1.28995258, grad/param norm = 5.2816e-02, time/batch = 0.0762s	
5246/5250 (epoch 49.962), train_loss = 1.26924798, grad/param norm = 4.8660e-02, time/batch = 0.0766s	
5247/5250 (epoch 49.971), train_loss = 1.26767826, grad/param norm = 5.2881e-02, time/batch = 0.0759s	
5248/5250 (epoch 49.981), train_loss = 1.28680917, grad/param norm = 5.2376e-02, time/batch = 0.0755s	
5249/5250 (epoch 49.990), train_loss = 1.28753359, grad/param norm = 5.5300e-02, time/batch = 0.0762s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.4172.t7	
5250/5250 (epoch 50.000), train_loss = 1.27651418, grad/param norm = 5.0937e-02, time/batch = 0.0759s	
