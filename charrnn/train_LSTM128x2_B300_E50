using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 70, val: 4, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 240321	
cloning rnn	
cloning criterion	
1/3500 (epoch 0.014), train_loss = 4.16667619, grad/param norm = 5.4451e-01, time/batch = 0.3837s	
2/3500 (epoch 0.029), train_loss = 3.84590616, grad/param norm = 1.4186e+00, time/batch = 0.0870s	
3/3500 (epoch 0.043), train_loss = 3.43912027, grad/param norm = 1.0062e+00, time/batch = 0.0848s	
4/3500 (epoch 0.057), train_loss = 3.36835472, grad/param norm = 4.8159e-01, time/batch = 0.0909s	
5/3500 (epoch 0.071), train_loss = 3.35515101, grad/param norm = 3.6869e-01, time/batch = 0.0850s	
6/3500 (epoch 0.086), train_loss = 3.34714536, grad/param norm = 3.4979e-01, time/batch = 0.0832s	
7/3500 (epoch 0.100), train_loss = 3.34541451, grad/param norm = 4.7108e-01, time/batch = 0.0838s	
8/3500 (epoch 0.114), train_loss = 3.33281112, grad/param norm = 5.2499e-01, time/batch = 0.0836s	
9/3500 (epoch 0.129), train_loss = 3.31696555, grad/param norm = 5.5815e-01, time/batch = 0.0832s	
10/3500 (epoch 0.143), train_loss = 3.33871886, grad/param norm = 4.0558e-01, time/batch = 0.0837s	
11/3500 (epoch 0.157), train_loss = 3.32475729, grad/param norm = 2.5278e-01, time/batch = 0.0832s	
12/3500 (epoch 0.171), train_loss = 3.32447230, grad/param norm = 2.2698e-01, time/batch = 0.0823s	
13/3500 (epoch 0.186), train_loss = 3.31844337, grad/param norm = 2.0189e-01, time/batch = 0.0823s	
14/3500 (epoch 0.200), train_loss = 3.32471136, grad/param norm = 1.7674e-01, time/batch = 0.0838s	
15/3500 (epoch 0.214), train_loss = 3.30373015, grad/param norm = 1.7833e-01, time/batch = 0.0845s	
16/3500 (epoch 0.229), train_loss = 3.32726213, grad/param norm = 2.4540e-01, time/batch = 0.0837s	
17/3500 (epoch 0.243), train_loss = 3.31079793, grad/param norm = 2.7219e-01, time/batch = 0.0825s	
18/3500 (epoch 0.257), train_loss = 3.32107166, grad/param norm = 2.1887e-01, time/batch = 0.0825s	
19/3500 (epoch 0.271), train_loss = 3.32613882, grad/param norm = 1.7727e-01, time/batch = 0.0817s	
20/3500 (epoch 0.286), train_loss = 3.30251140, grad/param norm = 2.2486e-01, time/batch = 0.0834s	
21/3500 (epoch 0.300), train_loss = 3.32346882, grad/param norm = 2.3850e-01, time/batch = 0.0827s	
22/3500 (epoch 0.314), train_loss = 3.30445044, grad/param norm = 2.5865e-01, time/batch = 0.0820s	
23/3500 (epoch 0.329), train_loss = 3.30200963, grad/param norm = 2.8925e-01, time/batch = 0.0821s	
24/3500 (epoch 0.343), train_loss = 3.31533750, grad/param norm = 2.7116e-01, time/batch = 0.0839s	
25/3500 (epoch 0.357), train_loss = 3.32099688, grad/param norm = 2.5557e-01, time/batch = 0.0845s	
26/3500 (epoch 0.371), train_loss = 3.31295917, grad/param norm = 2.8051e-01, time/batch = 0.0836s	
27/3500 (epoch 0.386), train_loss = 3.31577220, grad/param norm = 2.8600e-01, time/batch = 0.0823s	
28/3500 (epoch 0.400), train_loss = 3.33280196, grad/param norm = 3.3055e-01, time/batch = 0.0823s	
29/3500 (epoch 0.414), train_loss = 3.32015017, grad/param norm = 3.7289e-01, time/batch = 0.0819s	
30/3500 (epoch 0.429), train_loss = 3.33484321, grad/param norm = 3.5100e-01, time/batch = 0.0824s	
31/3500 (epoch 0.443), train_loss = 3.31142791, grad/param norm = 3.0953e-01, time/batch = 0.0832s	
32/3500 (epoch 0.457), train_loss = 3.32589860, grad/param norm = 2.5558e-01, time/batch = 0.0822s	
33/3500 (epoch 0.471), train_loss = 3.33406554, grad/param norm = 2.4666e-01, time/batch = 0.0822s	
34/3500 (epoch 0.486), train_loss = 3.30481564, grad/param norm = 4.5523e-01, time/batch = 0.0838s	
35/3500 (epoch 0.500), train_loss = 3.31632949, grad/param norm = 4.5502e-01, time/batch = 0.0846s	
36/3500 (epoch 0.514), train_loss = 3.27312497, grad/param norm = 3.2861e-01, time/batch = 0.0839s	
37/3500 (epoch 0.529), train_loss = 3.30450809, grad/param norm = 2.5505e-01, time/batch = 0.0825s	
38/3500 (epoch 0.543), train_loss = 3.32002204, grad/param norm = 1.6841e-01, time/batch = 0.0825s	
39/3500 (epoch 0.557), train_loss = 3.31497680, grad/param norm = 1.3247e-01, time/batch = 0.0817s	
40/3500 (epoch 0.571), train_loss = 3.31683500, grad/param norm = 1.4655e-01, time/batch = 0.0824s	
41/3500 (epoch 0.586), train_loss = 3.30214035, grad/param norm = 2.5787e-01, time/batch = 0.0828s	
42/3500 (epoch 0.600), train_loss = 3.35472751, grad/param norm = 3.5841e-01, time/batch = 0.0821s	
43/3500 (epoch 0.614), train_loss = 3.34509225, grad/param norm = 3.1306e-01, time/batch = 0.0822s	
44/3500 (epoch 0.629), train_loss = 3.28717922, grad/param norm = 2.4316e-01, time/batch = 0.0838s	
45/3500 (epoch 0.643), train_loss = 3.28704516, grad/param norm = 4.3017e-01, time/batch = 0.0845s	
46/3500 (epoch 0.657), train_loss = 3.34014805, grad/param norm = 5.8449e-01, time/batch = 0.0835s	
47/3500 (epoch 0.671), train_loss = 3.29740497, grad/param norm = 4.3471e-01, time/batch = 0.0824s	
48/3500 (epoch 0.686), train_loss = 3.28562315, grad/param norm = 2.8064e-01, time/batch = 0.0823s	
49/3500 (epoch 0.700), train_loss = 3.28711236, grad/param norm = 2.9692e-01, time/batch = 0.0823s	
50/3500 (epoch 0.714), train_loss = 3.27040831, grad/param norm = 3.1921e-01, time/batch = 0.0829s	
51/3500 (epoch 0.729), train_loss = 3.36450938, grad/param norm = 1.6107e+00, time/batch = 0.0833s	
52/3500 (epoch 0.743), train_loss = 3.37926589, grad/param norm = 6.9327e-01, time/batch = 0.0823s	
53/3500 (epoch 0.757), train_loss = 3.29211390, grad/param norm = 2.8027e-01, time/batch = 0.0822s	
54/3500 (epoch 0.771), train_loss = 3.28782293, grad/param norm = 1.8268e-01, time/batch = 0.0839s	
55/3500 (epoch 0.786), train_loss = 3.26317401, grad/param norm = 1.5627e-01, time/batch = 0.0847s	
56/3500 (epoch 0.800), train_loss = 3.28072031, grad/param norm = 1.9766e-01, time/batch = 0.0837s	
57/3500 (epoch 0.814), train_loss = 3.25510472, grad/param norm = 2.6908e-01, time/batch = 0.0825s	
58/3500 (epoch 0.829), train_loss = 3.27407999, grad/param norm = 5.7002e-01, time/batch = 0.0825s	
59/3500 (epoch 0.843), train_loss = 3.25663290, grad/param norm = 5.8858e-01, time/batch = 0.0817s	
60/3500 (epoch 0.857), train_loss = 3.25553604, grad/param norm = 4.6111e-01, time/batch = 0.0829s	
61/3500 (epoch 0.871), train_loss = 3.23887819, grad/param norm = 2.4792e-01, time/batch = 0.0826s	
62/3500 (epoch 0.886), train_loss = 3.21910898, grad/param norm = 1.5896e-01, time/batch = 0.0820s	
63/3500 (epoch 0.900), train_loss = 3.19771316, grad/param norm = 2.0178e-01, time/batch = 0.0822s	
64/3500 (epoch 0.914), train_loss = 3.19609397, grad/param norm = 3.5344e-01, time/batch = 0.0844s	
65/3500 (epoch 0.929), train_loss = 3.24921917, grad/param norm = 1.4906e+00, time/batch = 0.0847s	
66/3500 (epoch 0.943), train_loss = 3.31376894, grad/param norm = 6.4850e-01, time/batch = 0.0834s	
67/3500 (epoch 0.957), train_loss = 3.22742200, grad/param norm = 3.8931e-01, time/batch = 0.0824s	
68/3500 (epoch 0.971), train_loss = 3.19355704, grad/param norm = 3.0429e-01, time/batch = 0.0822s	
69/3500 (epoch 0.986), train_loss = 3.19496250, grad/param norm = 2.3617e-01, time/batch = 0.0819s	
70/3500 (epoch 1.000), train_loss = 3.18887467, grad/param norm = 1.7477e-01, time/batch = 0.0828s	
71/3500 (epoch 1.014), train_loss = 3.18500105, grad/param norm = 1.8563e-01, time/batch = 0.0832s	
72/3500 (epoch 1.029), train_loss = 3.18089086, grad/param norm = 1.8863e-01, time/batch = 0.0823s	
73/3500 (epoch 1.043), train_loss = 3.15383993, grad/param norm = 2.0085e-01, time/batch = 0.0823s	
74/3500 (epoch 1.057), train_loss = 3.17027692, grad/param norm = 3.2021e-01, time/batch = 0.0839s	
75/3500 (epoch 1.071), train_loss = 3.16443580, grad/param norm = 4.7195e-01, time/batch = 0.0842s	
76/3500 (epoch 1.086), train_loss = 3.18218985, grad/param norm = 6.7631e-01, time/batch = 0.0837s	
77/3500 (epoch 1.100), train_loss = 3.21057919, grad/param norm = 1.0736e+00, time/batch = 0.0826s	
78/3500 (epoch 1.114), train_loss = 3.27336366, grad/param norm = 1.9061e+00, time/batch = 0.0825s	
79/3500 (epoch 1.129), train_loss = 3.26700577, grad/param norm = 9.8149e-01, time/batch = 0.0818s	
80/3500 (epoch 1.143), train_loss = 3.17612027, grad/param norm = 2.6892e-01, time/batch = 0.0824s	
81/3500 (epoch 1.157), train_loss = 3.14284536, grad/param norm = 1.7118e-01, time/batch = 0.0827s	
82/3500 (epoch 1.171), train_loss = 3.14218260, grad/param norm = 1.6247e-01, time/batch = 0.0820s	
83/3500 (epoch 1.186), train_loss = 3.12733227, grad/param norm = 1.6436e-01, time/batch = 0.0822s	
84/3500 (epoch 1.200), train_loss = 3.12406531, grad/param norm = 1.6878e-01, time/batch = 0.0842s	
85/3500 (epoch 1.214), train_loss = 3.10729561, grad/param norm = 2.5397e-01, time/batch = 0.0840s	
86/3500 (epoch 1.229), train_loss = 3.12346875, grad/param norm = 3.7194e-01, time/batch = 0.0836s	
87/3500 (epoch 1.243), train_loss = 3.11814843, grad/param norm = 4.9335e-01, time/batch = 0.0823s	
88/3500 (epoch 1.257), train_loss = 3.11156344, grad/param norm = 5.9150e-01, time/batch = 0.0822s	
89/3500 (epoch 1.271), train_loss = 3.11509748, grad/param norm = 5.7930e-01, time/batch = 0.0819s	
90/3500 (epoch 1.286), train_loss = 3.09894152, grad/param norm = 4.4420e-01, time/batch = 0.0824s	
91/3500 (epoch 1.300), train_loss = 3.09244100, grad/param norm = 4.2374e-01, time/batch = 0.0832s	
92/3500 (epoch 1.314), train_loss = 3.08720606, grad/param norm = 3.8307e-01, time/batch = 0.0822s	
93/3500 (epoch 1.329), train_loss = 3.08496832, grad/param norm = 5.1628e-01, time/batch = 0.0823s	
94/3500 (epoch 1.343), train_loss = 3.09435472, grad/param norm = 7.4644e-01, time/batch = 0.0841s	
95/3500 (epoch 1.357), train_loss = 3.16539834, grad/param norm = 1.2830e+00, time/batch = 0.0842s	
96/3500 (epoch 1.371), train_loss = 3.14300896, grad/param norm = 1.2307e+00, time/batch = 0.0836s	
97/3500 (epoch 1.386), train_loss = 3.10049355, grad/param norm = 7.5752e-01, time/batch = 0.0825s	
98/3500 (epoch 1.400), train_loss = 3.05678871, grad/param norm = 3.8039e-01, time/batch = 0.0825s	
99/3500 (epoch 1.414), train_loss = 3.05942053, grad/param norm = 3.7396e-01, time/batch = 0.0817s	
100/3500 (epoch 1.429), train_loss = 3.04368662, grad/param norm = 5.8573e-01, time/batch = 0.0823s	
101/3500 (epoch 1.443), train_loss = 3.04466863, grad/param norm = 8.0233e-01, time/batch = 0.0827s	
102/3500 (epoch 1.457), train_loss = 3.04528558, grad/param norm = 7.4125e-01, time/batch = 0.0820s	
103/3500 (epoch 1.471), train_loss = 3.03312181, grad/param norm = 5.4279e-01, time/batch = 0.0829s	
104/3500 (epoch 1.486), train_loss = 2.99558517, grad/param norm = 5.1740e-01, time/batch = 0.0855s	
105/3500 (epoch 1.500), train_loss = 2.99820944, grad/param norm = 5.0310e-01, time/batch = 0.0840s	
106/3500 (epoch 1.514), train_loss = 2.98622985, grad/param norm = 6.1602e-01, time/batch = 0.0837s	
107/3500 (epoch 1.529), train_loss = 2.99768537, grad/param norm = 6.1567e-01, time/batch = 0.0824s	
108/3500 (epoch 1.543), train_loss = 2.98148047, grad/param norm = 6.8512e-01, time/batch = 0.0822s	
109/3500 (epoch 1.557), train_loss = 2.96967165, grad/param norm = 7.2320e-01, time/batch = 0.0820s	
110/3500 (epoch 1.571), train_loss = 2.97264944, grad/param norm = 9.5636e-01, time/batch = 0.0824s	
111/3500 (epoch 1.586), train_loss = 2.99255974, grad/param norm = 1.0876e+00, time/batch = 0.0833s	
112/3500 (epoch 1.600), train_loss = 2.97517814, grad/param norm = 9.3286e-01, time/batch = 0.0822s	
113/3500 (epoch 1.614), train_loss = 2.93530359, grad/param norm = 6.5631e-01, time/batch = 0.0822s	
114/3500 (epoch 1.629), train_loss = 2.90279000, grad/param norm = 6.3439e-01, time/batch = 0.0843s	
115/3500 (epoch 1.643), train_loss = 2.95520789, grad/param norm = 1.1884e+00, time/batch = 0.0841s	
116/3500 (epoch 1.657), train_loss = 3.00226895, grad/param norm = 1.2708e+00, time/batch = 0.0837s	
117/3500 (epoch 1.671), train_loss = 2.92803263, grad/param norm = 8.4097e-01, time/batch = 0.0825s	
118/3500 (epoch 1.686), train_loss = 2.88627731, grad/param norm = 5.8869e-01, time/batch = 0.0824s	
119/3500 (epoch 1.700), train_loss = 2.86471387, grad/param norm = 4.5789e-01, time/batch = 0.0817s	
120/3500 (epoch 1.714), train_loss = 2.86373604, grad/param norm = 3.3939e-01, time/batch = 0.0824s	
121/3500 (epoch 1.729), train_loss = 2.85122367, grad/param norm = 3.0362e-01, time/batch = 0.0827s	
122/3500 (epoch 1.743), train_loss = 2.83397499, grad/param norm = 2.9110e-01, time/batch = 0.0820s	
123/3500 (epoch 1.757), train_loss = 2.81742988, grad/param norm = 3.7261e-01, time/batch = 0.0822s	
124/3500 (epoch 1.771), train_loss = 2.82641200, grad/param norm = 5.4502e-01, time/batch = 0.0842s	
125/3500 (epoch 1.786), train_loss = 2.83662681, grad/param norm = 8.6178e-01, time/batch = 0.0840s	
126/3500 (epoch 1.800), train_loss = 2.87541548, grad/param norm = 1.0151e+00, time/batch = 0.0835s	
127/3500 (epoch 1.814), train_loss = 2.85838795, grad/param norm = 9.2275e-01, time/batch = 0.0823s	
128/3500 (epoch 1.829), train_loss = 2.81685057, grad/param norm = 7.4816e-01, time/batch = 0.0823s	
129/3500 (epoch 1.843), train_loss = 2.81168187, grad/param norm = 8.3038e-01, time/batch = 0.0824s	
130/3500 (epoch 1.857), train_loss = 2.80689407, grad/param norm = 7.6282e-01, time/batch = 0.0826s	
131/3500 (epoch 1.871), train_loss = 2.78857846, grad/param norm = 5.4671e-01, time/batch = 0.0832s	
132/3500 (epoch 1.886), train_loss = 2.76680199, grad/param norm = 4.2510e-01, time/batch = 0.0822s	
133/3500 (epoch 1.900), train_loss = 2.75356432, grad/param norm = 4.0594e-01, time/batch = 0.0822s	
134/3500 (epoch 1.914), train_loss = 2.74947031, grad/param norm = 4.4319e-01, time/batch = 0.0841s	
135/3500 (epoch 1.929), train_loss = 2.73454617, grad/param norm = 4.5942e-01, time/batch = 0.0842s	
136/3500 (epoch 1.943), train_loss = 2.73518302, grad/param norm = 5.9038e-01, time/batch = 0.0837s	
137/3500 (epoch 1.957), train_loss = 2.76097005, grad/param norm = 8.7679e-01, time/batch = 0.0825s	
138/3500 (epoch 1.971), train_loss = 2.76636124, grad/param norm = 1.1456e+00, time/batch = 0.0825s	
139/3500 (epoch 1.986), train_loss = 2.77420601, grad/param norm = 9.9349e-01, time/batch = 0.0821s	
140/3500 (epoch 2.000), train_loss = 2.74316498, grad/param norm = 6.9936e-01, time/batch = 0.0824s	
141/3500 (epoch 2.014), train_loss = 2.72763091, grad/param norm = 4.8603e-01, time/batch = 0.0827s	
142/3500 (epoch 2.029), train_loss = 2.71161990, grad/param norm = 3.8776e-01, time/batch = 0.0820s	
143/3500 (epoch 2.043), train_loss = 2.68448692, grad/param norm = 4.3074e-01, time/batch = 0.0821s	
144/3500 (epoch 2.057), train_loss = 2.70303119, grad/param norm = 4.8053e-01, time/batch = 0.0839s	
145/3500 (epoch 2.071), train_loss = 2.68666526, grad/param norm = 5.2829e-01, time/batch = 0.0839s	
146/3500 (epoch 2.086), train_loss = 2.70223103, grad/param norm = 6.2443e-01, time/batch = 0.0836s	
147/3500 (epoch 2.100), train_loss = 2.72218230, grad/param norm = 8.2947e-01, time/batch = 0.0823s	
148/3500 (epoch 2.114), train_loss = 2.72894207, grad/param norm = 1.1483e+00, time/batch = 0.0824s	
149/3500 (epoch 2.129), train_loss = 2.73182545, grad/param norm = 8.6636e-01, time/batch = 0.0824s	
150/3500 (epoch 2.143), train_loss = 2.68569822, grad/param norm = 4.9030e-01, time/batch = 0.0824s	
151/3500 (epoch 2.157), train_loss = 2.64296752, grad/param norm = 3.8382e-01, time/batch = 0.0832s	
152/3500 (epoch 2.171), train_loss = 2.64354088, grad/param norm = 4.4540e-01, time/batch = 0.0822s	
153/3500 (epoch 2.186), train_loss = 2.64613963, grad/param norm = 5.5045e-01, time/batch = 0.0823s	
154/3500 (epoch 2.200), train_loss = 2.66838123, grad/param norm = 1.0469e+00, time/batch = 0.0838s	
155/3500 (epoch 2.214), train_loss = 2.73618590, grad/param norm = 1.4996e+00, time/batch = 0.0841s	
156/3500 (epoch 2.229), train_loss = 2.73020881, grad/param norm = 1.2744e+00, time/batch = 0.0837s	
157/3500 (epoch 2.243), train_loss = 2.66537743, grad/param norm = 6.6492e-01, time/batch = 0.0825s	
158/3500 (epoch 2.257), train_loss = 2.62605968, grad/param norm = 3.6386e-01, time/batch = 0.0824s	
159/3500 (epoch 2.271), train_loss = 2.61307178, grad/param norm = 2.8675e-01, time/batch = 0.0822s	
160/3500 (epoch 2.286), train_loss = 2.60279047, grad/param norm = 2.8423e-01, time/batch = 0.0823s	
161/3500 (epoch 2.300), train_loss = 2.59473286, grad/param norm = 2.7581e-01, time/batch = 0.0828s	
162/3500 (epoch 2.314), train_loss = 2.59168588, grad/param norm = 3.3930e-01, time/batch = 0.0820s	
163/3500 (epoch 2.329), train_loss = 2.60133403, grad/param norm = 4.1696e-01, time/batch = 0.0822s	
164/3500 (epoch 2.343), train_loss = 2.58725295, grad/param norm = 5.1152e-01, time/batch = 0.0837s	
165/3500 (epoch 2.357), train_loss = 2.60207621, grad/param norm = 5.7703e-01, time/batch = 0.0839s	
166/3500 (epoch 2.371), train_loss = 2.59115825, grad/param norm = 5.5878e-01, time/batch = 0.0836s	
167/3500 (epoch 2.386), train_loss = 2.57369209, grad/param norm = 4.7890e-01, time/batch = 0.0823s	
168/3500 (epoch 2.400), train_loss = 2.56569851, grad/param norm = 3.7228e-01, time/batch = 0.0822s	
169/3500 (epoch 2.414), train_loss = 2.58187303, grad/param norm = 3.6082e-01, time/batch = 0.0820s	
170/3500 (epoch 2.429), train_loss = 2.56265059, grad/param norm = 4.0523e-01, time/batch = 0.0824s	
171/3500 (epoch 2.443), train_loss = 2.56506372, grad/param norm = 4.8001e-01, time/batch = 0.0832s	
172/3500 (epoch 2.457), train_loss = 2.57550894, grad/param norm = 7.3702e-01, time/batch = 0.0822s	
173/3500 (epoch 2.471), train_loss = 2.66495419, grad/param norm = 1.4811e+00, time/batch = 0.0823s	
174/3500 (epoch 2.486), train_loss = 2.70437269, grad/param norm = 1.5748e+00, time/batch = 0.0838s	
175/3500 (epoch 2.500), train_loss = 2.62517071, grad/param norm = 8.5298e-01, time/batch = 0.0841s	
176/3500 (epoch 2.514), train_loss = 2.58157279, grad/param norm = 5.1727e-01, time/batch = 0.0837s	
177/3500 (epoch 2.529), train_loss = 2.56879415, grad/param norm = 4.2576e-01, time/batch = 0.0825s	
178/3500 (epoch 2.543), train_loss = 2.55826073, grad/param norm = 5.3605e-01, time/batch = 0.0825s	
179/3500 (epoch 2.557), train_loss = 2.55784233, grad/param norm = 5.9952e-01, time/batch = 0.0817s	
180/3500 (epoch 2.571), train_loss = 2.53035046, grad/param norm = 5.1878e-01, time/batch = 0.0824s	
181/3500 (epoch 2.586), train_loss = 2.54554716, grad/param norm = 4.6135e-01, time/batch = 0.0827s	
182/3500 (epoch 2.600), train_loss = 2.52352009, grad/param norm = 3.6229e-01, time/batch = 0.0821s	
183/3500 (epoch 2.614), train_loss = 2.51316720, grad/param norm = 2.9672e-01, time/batch = 0.0822s	
184/3500 (epoch 2.629), train_loss = 2.48471952, grad/param norm = 2.9737e-01, time/batch = 0.0836s	
185/3500 (epoch 2.643), train_loss = 2.50690637, grad/param norm = 3.7221e-01, time/batch = 0.0840s	
186/3500 (epoch 2.657), train_loss = 2.50547026, grad/param norm = 5.2812e-01, time/batch = 0.0834s	
187/3500 (epoch 2.671), train_loss = 2.51246679, grad/param norm = 7.2595e-01, time/batch = 0.0824s	
188/3500 (epoch 2.686), train_loss = 2.52630386, grad/param norm = 8.7052e-01, time/batch = 0.0823s	
189/3500 (epoch 2.700), train_loss = 2.53281644, grad/param norm = 8.5904e-01, time/batch = 0.0819s	
190/3500 (epoch 2.714), train_loss = 2.54082225, grad/param norm = 7.2119e-01, time/batch = 0.0825s	
191/3500 (epoch 2.729), train_loss = 2.52887415, grad/param norm = 5.7174e-01, time/batch = 0.0832s	
192/3500 (epoch 2.743), train_loss = 2.50759582, grad/param norm = 5.8461e-01, time/batch = 0.0822s	
193/3500 (epoch 2.757), train_loss = 2.50449374, grad/param norm = 5.8065e-01, time/batch = 0.0828s	
194/3500 (epoch 2.771), train_loss = 2.50213693, grad/param norm = 5.1088e-01, time/batch = 0.0837s	
195/3500 (epoch 2.786), train_loss = 2.48052009, grad/param norm = 4.0635e-01, time/batch = 0.0840s	
196/3500 (epoch 2.800), train_loss = 2.49348956, grad/param norm = 3.5717e-01, time/batch = 0.0837s	
197/3500 (epoch 2.814), train_loss = 2.46696404, grad/param norm = 3.4214e-01, time/batch = 0.0828s	
198/3500 (epoch 2.829), train_loss = 2.45910938, grad/param norm = 4.8058e-01, time/batch = 0.0825s	
199/3500 (epoch 2.843), train_loss = 2.50277877, grad/param norm = 9.7363e-01, time/batch = 0.0818s	
200/3500 (epoch 2.857), train_loss = 2.56619898, grad/param norm = 1.2131e+00, time/batch = 0.0823s	
201/3500 (epoch 2.871), train_loss = 2.54583537, grad/param norm = 8.0793e-01, time/batch = 0.0827s	
202/3500 (epoch 2.886), train_loss = 2.49651438, grad/param norm = 6.0194e-01, time/batch = 0.0848s	
203/3500 (epoch 2.900), train_loss = 2.48499106, grad/param norm = 5.4030e-01, time/batch = 0.0832s	
204/3500 (epoch 2.914), train_loss = 2.47355204, grad/param norm = 5.1108e-01, time/batch = 0.0837s	
205/3500 (epoch 2.929), train_loss = 2.44718377, grad/param norm = 4.4089e-01, time/batch = 0.0842s	
206/3500 (epoch 2.943), train_loss = 2.45118180, grad/param norm = 4.5104e-01, time/batch = 0.0836s	
207/3500 (epoch 2.957), train_loss = 2.46098757, grad/param norm = 4.9482e-01, time/batch = 0.0824s	
208/3500 (epoch 2.971), train_loss = 2.43604660, grad/param norm = 5.6998e-01, time/batch = 0.0827s	
209/3500 (epoch 2.986), train_loss = 2.46730952, grad/param norm = 5.2084e-01, time/batch = 0.0819s	
210/3500 (epoch 3.000), train_loss = 2.45646974, grad/param norm = 4.5180e-01, time/batch = 0.0825s	
211/3500 (epoch 3.014), train_loss = 2.46448362, grad/param norm = 5.2147e-01, time/batch = 0.0833s	
212/3500 (epoch 3.029), train_loss = 2.47061110, grad/param norm = 6.2464e-01, time/batch = 0.0823s	
213/3500 (epoch 3.043), train_loss = 2.45054040, grad/param norm = 7.8193e-01, time/batch = 0.0826s	
214/3500 (epoch 3.057), train_loss = 2.49274149, grad/param norm = 8.0333e-01, time/batch = 0.0836s	
215/3500 (epoch 3.071), train_loss = 2.44527550, grad/param norm = 6.2397e-01, time/batch = 0.0843s	
216/3500 (epoch 3.086), train_loss = 2.44611612, grad/param norm = 4.6597e-01, time/batch = 0.0836s	
217/3500 (epoch 3.100), train_loss = 2.44134346, grad/param norm = 4.0620e-01, time/batch = 0.0825s	
218/3500 (epoch 3.114), train_loss = 2.42300753, grad/param norm = 3.9794e-01, time/batch = 0.0828s	
219/3500 (epoch 3.129), train_loss = 2.42497412, grad/param norm = 4.5043e-01, time/batch = 0.0817s	
220/3500 (epoch 3.143), train_loss = 2.43799479, grad/param norm = 5.2869e-01, time/batch = 0.0824s	
221/3500 (epoch 3.157), train_loss = 2.42706261, grad/param norm = 6.4396e-01, time/batch = 0.0827s	
222/3500 (epoch 3.171), train_loss = 2.43762181, grad/param norm = 6.6991e-01, time/batch = 0.0821s	
223/3500 (epoch 3.186), train_loss = 2.42946791, grad/param norm = 5.1635e-01, time/batch = 0.0826s	
224/3500 (epoch 3.200), train_loss = 2.41074957, grad/param norm = 3.7624e-01, time/batch = 0.0837s	
225/3500 (epoch 3.214), train_loss = 2.38069755, grad/param norm = 3.4070e-01, time/batch = 0.0840s	
226/3500 (epoch 3.229), train_loss = 2.39080251, grad/param norm = 3.6842e-01, time/batch = 0.0835s	
227/3500 (epoch 3.243), train_loss = 2.40626052, grad/param norm = 5.4197e-01, time/batch = 0.0824s	
228/3500 (epoch 3.257), train_loss = 2.43480055, grad/param norm = 8.5129e-01, time/batch = 0.0827s	
229/3500 (epoch 3.271), train_loss = 2.49165117, grad/param norm = 1.0782e+00, time/batch = 0.0820s	
230/3500 (epoch 3.286), train_loss = 2.46571829, grad/param norm = 7.2766e-01, time/batch = 0.0824s	
231/3500 (epoch 3.300), train_loss = 2.40698633, grad/param norm = 4.3884e-01, time/batch = 0.0832s	
232/3500 (epoch 3.314), train_loss = 2.39671756, grad/param norm = 4.4018e-01, time/batch = 0.0822s	
233/3500 (epoch 3.329), train_loss = 2.41308737, grad/param norm = 4.4419e-01, time/batch = 0.0823s	
234/3500 (epoch 3.343), train_loss = 2.39287415, grad/param norm = 4.2985e-01, time/batch = 0.0837s	
235/3500 (epoch 3.357), train_loss = 2.39140048, grad/param norm = 4.0453e-01, time/batch = 0.0841s	
236/3500 (epoch 3.371), train_loss = 2.38455732, grad/param norm = 3.9541e-01, time/batch = 0.0835s	
237/3500 (epoch 3.386), train_loss = 2.36560681, grad/param norm = 3.7600e-01, time/batch = 0.0825s	
238/3500 (epoch 3.400), train_loss = 2.36593526, grad/param norm = 3.8879e-01, time/batch = 0.0829s	
239/3500 (epoch 3.414), train_loss = 2.39857654, grad/param norm = 4.8686e-01, time/batch = 0.0818s	
240/3500 (epoch 3.429), train_loss = 2.37871598, grad/param norm = 6.4648e-01, time/batch = 0.0824s	
241/3500 (epoch 3.443), train_loss = 2.40084636, grad/param norm = 7.0798e-01, time/batch = 0.0827s	
242/3500 (epoch 3.457), train_loss = 2.38785084, grad/param norm = 6.3888e-01, time/batch = 0.0821s	
243/3500 (epoch 3.471), train_loss = 2.39104836, grad/param norm = 5.2543e-01, time/batch = 0.0822s	
244/3500 (epoch 3.486), train_loss = 2.36700155, grad/param norm = 5.1026e-01, time/batch = 0.0837s	
245/3500 (epoch 3.500), train_loss = 2.37470163, grad/param norm = 4.5307e-01, time/batch = 0.0841s	
246/3500 (epoch 3.514), train_loss = 2.38361579, grad/param norm = 4.5047e-01, time/batch = 0.0840s	
247/3500 (epoch 3.529), train_loss = 2.38354928, grad/param norm = 4.8257e-01, time/batch = 0.0824s	
248/3500 (epoch 3.543), train_loss = 2.36683401, grad/param norm = 4.6663e-01, time/batch = 0.0822s	
249/3500 (epoch 3.557), train_loss = 2.35350864, grad/param norm = 5.1220e-01, time/batch = 0.0819s	
250/3500 (epoch 3.571), train_loss = 2.35178504, grad/param norm = 5.6350e-01, time/batch = 0.0823s	
251/3500 (epoch 3.586), train_loss = 2.37127164, grad/param norm = 5.3803e-01, time/batch = 0.0833s	
252/3500 (epoch 3.600), train_loss = 2.35526411, grad/param norm = 5.0129e-01, time/batch = 0.0823s	
253/3500 (epoch 3.614), train_loss = 2.34853727, grad/param norm = 5.2035e-01, time/batch = 0.0822s	
254/3500 (epoch 3.629), train_loss = 2.33151757, grad/param norm = 5.5062e-01, time/batch = 0.0839s	
255/3500 (epoch 3.643), train_loss = 2.34992389, grad/param norm = 5.6091e-01, time/batch = 0.0842s	
256/3500 (epoch 3.657), train_loss = 2.35006457, grad/param norm = 5.9019e-01, time/batch = 0.0837s	
257/3500 (epoch 3.671), train_loss = 2.34968002, grad/param norm = 5.6944e-01, time/batch = 0.0825s	
258/3500 (epoch 3.686), train_loss = 2.33528871, grad/param norm = 4.4621e-01, time/batch = 0.0824s	
259/3500 (epoch 3.700), train_loss = 2.32502090, grad/param norm = 3.8529e-01, time/batch = 0.0818s	
260/3500 (epoch 3.714), train_loss = 2.33450386, grad/param norm = 3.4956e-01, time/batch = 0.0824s	
261/3500 (epoch 3.729), train_loss = 2.33355164, grad/param norm = 3.9487e-01, time/batch = 0.0827s	
262/3500 (epoch 3.743), train_loss = 2.32807338, grad/param norm = 4.7230e-01, time/batch = 0.0821s	
263/3500 (epoch 3.757), train_loss = 2.34229603, grad/param norm = 6.0860e-01, time/batch = 0.0822s	
264/3500 (epoch 3.771), train_loss = 2.38950422, grad/param norm = 8.1117e-01, time/batch = 0.0836s	
265/3500 (epoch 3.786), train_loss = 2.38893821, grad/param norm = 8.1498e-01, time/batch = 0.0841s	
266/3500 (epoch 3.800), train_loss = 2.36890154, grad/param norm = 5.6796e-01, time/batch = 0.0836s	
267/3500 (epoch 3.814), train_loss = 2.34228228, grad/param norm = 5.9208e-01, time/batch = 0.0824s	
268/3500 (epoch 3.829), train_loss = 2.34312102, grad/param norm = 7.6187e-01, time/batch = 0.0823s	
269/3500 (epoch 3.843), train_loss = 2.36675140, grad/param norm = 5.7586e-01, time/batch = 0.0819s	
270/3500 (epoch 3.857), train_loss = 2.31437057, grad/param norm = 3.9692e-01, time/batch = 0.0823s	
271/3500 (epoch 3.871), train_loss = 2.31759756, grad/param norm = 3.2534e-01, time/batch = 0.0832s	
272/3500 (epoch 3.886), train_loss = 2.28745768, grad/param norm = 2.7509e-01, time/batch = 0.0822s	
273/3500 (epoch 3.900), train_loss = 2.30992395, grad/param norm = 3.0098e-01, time/batch = 0.0823s	
274/3500 (epoch 3.914), train_loss = 2.30028139, grad/param norm = 3.3566e-01, time/batch = 0.0836s	
275/3500 (epoch 3.929), train_loss = 2.28532578, grad/param norm = 3.7492e-01, time/batch = 0.0841s	
276/3500 (epoch 3.943), train_loss = 2.29869714, grad/param norm = 3.8329e-01, time/batch = 0.0837s	
277/3500 (epoch 3.957), train_loss = 2.29575354, grad/param norm = 4.1462e-01, time/batch = 0.0825s	
278/3500 (epoch 3.971), train_loss = 2.27414761, grad/param norm = 4.7491e-01, time/batch = 0.0825s	
279/3500 (epoch 3.986), train_loss = 2.30933817, grad/param norm = 6.0008e-01, time/batch = 0.0817s	
280/3500 (epoch 4.000), train_loss = 2.32822319, grad/param norm = 6.1703e-01, time/batch = 0.0823s	
281/3500 (epoch 4.014), train_loss = 2.33182671, grad/param norm = 5.0955e-01, time/batch = 0.0829s	
282/3500 (epoch 4.029), train_loss = 2.30082116, grad/param norm = 4.3869e-01, time/batch = 0.0826s	
283/3500 (epoch 4.043), train_loss = 2.28166611, grad/param norm = 4.5309e-01, time/batch = 0.0822s	
284/3500 (epoch 4.057), train_loss = 2.31674670, grad/param norm = 4.8407e-01, time/batch = 0.0838s	
285/3500 (epoch 4.071), train_loss = 2.28627345, grad/param norm = 4.4028e-01, time/batch = 0.0841s	
286/3500 (epoch 4.086), train_loss = 2.29390804, grad/param norm = 3.6339e-01, time/batch = 0.0837s	
287/3500 (epoch 4.100), train_loss = 2.29975217, grad/param norm = 4.6925e-01, time/batch = 0.0824s	
288/3500 (epoch 4.114), train_loss = 2.30167751, grad/param norm = 4.5797e-01, time/batch = 0.0824s	
289/3500 (epoch 4.129), train_loss = 2.28563041, grad/param norm = 3.7221e-01, time/batch = 0.0820s	
290/3500 (epoch 4.143), train_loss = 2.28581911, grad/param norm = 3.3563e-01, time/batch = 0.0824s	
291/3500 (epoch 4.157), train_loss = 2.25228410, grad/param norm = 3.5819e-01, time/batch = 0.0832s	
292/3500 (epoch 4.171), train_loss = 2.25784109, grad/param norm = 4.7615e-01, time/batch = 0.0827s	
293/3500 (epoch 4.186), train_loss = 2.27398638, grad/param norm = 5.4894e-01, time/batch = 0.0823s	
294/3500 (epoch 4.200), train_loss = 2.27765291, grad/param norm = 5.0745e-01, time/batch = 0.0839s	
295/3500 (epoch 4.214), train_loss = 2.24701489, grad/param norm = 4.3361e-01, time/batch = 0.0842s	
296/3500 (epoch 4.229), train_loss = 2.24440372, grad/param norm = 3.4689e-01, time/batch = 0.0842s	
297/3500 (epoch 4.243), train_loss = 2.24188850, grad/param norm = 2.8899e-01, time/batch = 0.0830s	
298/3500 (epoch 4.257), train_loss = 2.24519102, grad/param norm = 2.6703e-01, time/batch = 0.0825s	
299/3500 (epoch 4.271), train_loss = 2.25845332, grad/param norm = 3.0939e-01, time/batch = 0.0818s	
300/3500 (epoch 4.286), train_loss = 2.25789043, grad/param norm = 4.0334e-01, time/batch = 0.0823s	
301/3500 (epoch 4.300), train_loss = 2.25928426, grad/param norm = 4.7140e-01, time/batch = 0.0840s	
302/3500 (epoch 4.314), train_loss = 2.26189220, grad/param norm = 4.5798e-01, time/batch = 0.0827s	
303/3500 (epoch 4.329), train_loss = 2.26911674, grad/param norm = 4.4297e-01, time/batch = 0.0822s	
304/3500 (epoch 4.343), train_loss = 2.26503562, grad/param norm = 4.5415e-01, time/batch = 0.0838s	
305/3500 (epoch 4.357), train_loss = 2.25568573, grad/param norm = 5.3124e-01, time/batch = 0.0840s	
306/3500 (epoch 4.371), train_loss = 2.27152937, grad/param norm = 5.0750e-01, time/batch = 0.0835s	
307/3500 (epoch 4.386), train_loss = 2.23542639, grad/param norm = 4.9504e-01, time/batch = 0.0828s	
308/3500 (epoch 4.400), train_loss = 2.24828556, grad/param norm = 5.4682e-01, time/batch = 0.0822s	
309/3500 (epoch 4.414), train_loss = 2.27264593, grad/param norm = 4.2580e-01, time/batch = 0.0819s	
310/3500 (epoch 4.429), train_loss = 2.21692408, grad/param norm = 3.0564e-01, time/batch = 0.0824s	
311/3500 (epoch 4.443), train_loss = 2.22827785, grad/param norm = 3.0807e-01, time/batch = 0.0833s	
312/3500 (epoch 4.457), train_loss = 2.22665924, grad/param norm = 3.3488e-01, time/batch = 0.0822s	
313/3500 (epoch 4.471), train_loss = 2.22968924, grad/param norm = 3.8252e-01, time/batch = 0.0823s	
314/3500 (epoch 4.486), train_loss = 2.22537336, grad/param norm = 3.5929e-01, time/batch = 0.0837s	
315/3500 (epoch 4.500), train_loss = 2.21963123, grad/param norm = 3.0691e-01, time/batch = 0.0843s	
316/3500 (epoch 4.514), train_loss = 2.22769068, grad/param norm = 3.3710e-01, time/batch = 0.0837s	
317/3500 (epoch 4.529), train_loss = 2.23000799, grad/param norm = 4.0804e-01, time/batch = 0.0830s	
318/3500 (epoch 4.543), train_loss = 2.22676934, grad/param norm = 4.5946e-01, time/batch = 0.0825s	
319/3500 (epoch 4.557), train_loss = 2.21776968, grad/param norm = 4.3126e-01, time/batch = 0.0817s	
320/3500 (epoch 4.571), train_loss = 2.19859265, grad/param norm = 3.7880e-01, time/batch = 0.0824s	
321/3500 (epoch 4.586), train_loss = 2.21914919, grad/param norm = 3.7439e-01, time/batch = 0.0828s	
322/3500 (epoch 4.600), train_loss = 2.20807027, grad/param norm = 3.5480e-01, time/batch = 0.0821s	
323/3500 (epoch 4.614), train_loss = 2.20044850, grad/param norm = 3.5589e-01, time/batch = 0.0822s	
324/3500 (epoch 4.629), train_loss = 2.18335158, grad/param norm = 3.5612e-01, time/batch = 0.0836s	
325/3500 (epoch 4.643), train_loss = 2.19381383, grad/param norm = 3.3444e-01, time/batch = 0.0840s	
326/3500 (epoch 4.657), train_loss = 2.19987356, grad/param norm = 3.7644e-01, time/batch = 0.0835s	
327/3500 (epoch 4.671), train_loss = 2.20781182, grad/param norm = 5.2514e-01, time/batch = 0.0824s	
328/3500 (epoch 4.686), train_loss = 2.23321476, grad/param norm = 6.2083e-01, time/batch = 0.1479s	
329/3500 (epoch 4.700), train_loss = 2.23421047, grad/param norm = 4.9449e-01, time/batch = 0.1976s	
330/3500 (epoch 4.714), train_loss = 2.21443406, grad/param norm = 3.1442e-01, time/batch = 0.1994s	
331/3500 (epoch 4.729), train_loss = 2.19692306, grad/param norm = 2.2625e-01, time/batch = 0.2053s	
332/3500 (epoch 4.743), train_loss = 2.17061003, grad/param norm = 1.8218e-01, time/batch = 0.1464s	
333/3500 (epoch 4.757), train_loss = 2.16819685, grad/param norm = 1.8140e-01, time/batch = 0.1221s	
334/3500 (epoch 4.771), train_loss = 2.16959534, grad/param norm = 2.0154e-01, time/batch = 0.1265s	
335/3500 (epoch 4.786), train_loss = 2.18559780, grad/param norm = 2.3828e-01, time/batch = 0.1306s	
336/3500 (epoch 4.800), train_loss = 2.18718806, grad/param norm = 2.5860e-01, time/batch = 0.1185s	
337/3500 (epoch 4.814), train_loss = 2.18566338, grad/param norm = 2.9800e-01, time/batch = 0.1090s	
338/3500 (epoch 4.829), train_loss = 2.18591306, grad/param norm = 3.8648e-01, time/batch = 0.1082s	
339/3500 (epoch 4.843), train_loss = 2.21941263, grad/param norm = 4.2606e-01, time/batch = 0.1070s	
340/3500 (epoch 4.857), train_loss = 2.19319859, grad/param norm = 3.8976e-01, time/batch = 0.1085s	
341/3500 (epoch 4.871), train_loss = 2.18828150, grad/param norm = 3.0750e-01, time/batch = 0.1123s	
342/3500 (epoch 4.886), train_loss = 2.15177756, grad/param norm = 2.6011e-01, time/batch = 0.1081s	
343/3500 (epoch 4.900), train_loss = 2.17939135, grad/param norm = 3.3906e-01, time/batch = 0.1083s	
344/3500 (epoch 4.914), train_loss = 2.18385631, grad/param norm = 5.1403e-01, time/batch = 0.1103s	
345/3500 (epoch 4.929), train_loss = 2.18529542, grad/param norm = 5.6463e-01, time/batch = 0.0933s	
346/3500 (epoch 4.943), train_loss = 2.19400630, grad/param norm = 5.0229e-01, time/batch = 0.0909s	
347/3500 (epoch 4.957), train_loss = 2.18875778, grad/param norm = 4.3985e-01, time/batch = 0.0886s	
348/3500 (epoch 4.971), train_loss = 2.15510219, grad/param norm = 3.9225e-01, time/batch = 0.0882s	
349/3500 (epoch 4.986), train_loss = 2.16636550, grad/param norm = 2.9879e-01, time/batch = 0.0882s	
350/3500 (epoch 5.000), train_loss = 2.16382709, grad/param norm = 2.5240e-01, time/batch = 0.0884s	
351/3500 (epoch 5.014), train_loss = 2.20802488, grad/param norm = 2.3015e-01, time/batch = 0.0929s	
352/3500 (epoch 5.029), train_loss = 2.15253146, grad/param norm = 1.9830e-01, time/batch = 0.0885s	
353/3500 (epoch 5.043), train_loss = 2.14206314, grad/param norm = 2.3017e-01, time/batch = 0.0888s	
354/3500 (epoch 5.057), train_loss = 2.17476106, grad/param norm = 2.9843e-01, time/batch = 0.0923s	
355/3500 (epoch 5.071), train_loss = 2.14689893, grad/param norm = 3.7667e-01, time/batch = 0.0920s	
356/3500 (epoch 5.086), train_loss = 2.17178368, grad/param norm = 3.9117e-01, time/batch = 0.0913s	
357/3500 (epoch 5.100), train_loss = 2.16819206, grad/param norm = 3.8607e-01, time/batch = 0.0888s	
358/3500 (epoch 5.114), train_loss = 2.16288315, grad/param norm = 4.1450e-01, time/batch = 0.0884s	
359/3500 (epoch 5.129), train_loss = 2.17313892, grad/param norm = 4.5989e-01, time/batch = 0.0878s	
360/3500 (epoch 5.143), train_loss = 2.18617970, grad/param norm = 4.5918e-01, time/batch = 0.0884s	
361/3500 (epoch 5.157), train_loss = 2.14870096, grad/param norm = 4.2163e-01, time/batch = 0.0920s	
362/3500 (epoch 5.171), train_loss = 2.13794244, grad/param norm = 3.7095e-01, time/batch = 0.0883s	
363/3500 (epoch 5.186), train_loss = 2.14049136, grad/param norm = 3.3725e-01, time/batch = 0.0886s	
364/3500 (epoch 5.200), train_loss = 2.13574395, grad/param norm = 2.8892e-01, time/batch = 0.0921s	
365/3500 (epoch 5.214), train_loss = 2.10789576, grad/param norm = 2.6842e-01, time/batch = 0.0918s	
366/3500 (epoch 5.229), train_loss = 2.11727218, grad/param norm = 2.5317e-01, time/batch = 0.0911s	
367/3500 (epoch 5.243), train_loss = 2.12033213, grad/param norm = 2.3012e-01, time/batch = 0.0885s	
368/3500 (epoch 5.257), train_loss = 2.12648331, grad/param norm = 2.5997e-01, time/batch = 0.0882s	
369/3500 (epoch 5.271), train_loss = 2.14997242, grad/param norm = 2.7287e-01, time/batch = 0.0883s	
370/3500 (epoch 5.286), train_loss = 2.12636422, grad/param norm = 2.5316e-01, time/batch = 0.0886s	
371/3500 (epoch 5.300), train_loss = 2.11848850, grad/param norm = 2.4784e-01, time/batch = 0.0925s	
372/3500 (epoch 5.314), train_loss = 2.11443024, grad/param norm = 2.5449e-01, time/batch = 0.0888s	
373/3500 (epoch 5.329), train_loss = 2.13675396, grad/param norm = 2.7027e-01, time/batch = 0.0889s	
374/3500 (epoch 5.343), train_loss = 2.13722054, grad/param norm = 3.5249e-01, time/batch = 0.0916s	
375/3500 (epoch 5.357), train_loss = 2.15082806, grad/param norm = 5.1233e-01, time/batch = 0.0918s	
376/3500 (epoch 5.371), train_loss = 2.16995774, grad/param norm = 4.6235e-01, time/batch = 0.0913s	
377/3500 (epoch 5.386), train_loss = 2.12231783, grad/param norm = 4.1841e-01, time/batch = 0.0886s	
378/3500 (epoch 5.400), train_loss = 2.12962174, grad/param norm = 4.3230e-01, time/batch = 0.0891s	
379/3500 (epoch 5.414), train_loss = 2.15444783, grad/param norm = 3.2019e-01, time/batch = 0.0876s	
380/3500 (epoch 5.429), train_loss = 2.08827339, grad/param norm = 2.0491e-01, time/batch = 0.0886s	
381/3500 (epoch 5.443), train_loss = 2.10148024, grad/param norm = 1.6852e-01, time/batch = 0.0919s	
382/3500 (epoch 5.457), train_loss = 2.10042104, grad/param norm = 1.7665e-01, time/batch = 0.0883s	
383/3500 (epoch 5.471), train_loss = 2.09695190, grad/param norm = 2.1703e-01, time/batch = 0.0889s	
384/3500 (epoch 5.486), train_loss = 2.10729205, grad/param norm = 2.4351e-01, time/batch = 0.0917s	
385/3500 (epoch 5.500), train_loss = 2.10500571, grad/param norm = 2.4792e-01, time/batch = 0.0920s	
386/3500 (epoch 5.514), train_loss = 2.12175527, grad/param norm = 2.5193e-01, time/batch = 0.0911s	
387/3500 (epoch 5.529), train_loss = 2.11299668, grad/param norm = 2.9100e-01, time/batch = 0.0886s	
388/3500 (epoch 5.543), train_loss = 2.10683721, grad/param norm = 3.3307e-01, time/batch = 0.0890s	
389/3500 (epoch 5.557), train_loss = 2.09852412, grad/param norm = 3.9627e-01, time/batch = 0.0877s	
390/3500 (epoch 5.571), train_loss = 2.10532488, grad/param norm = 4.8262e-01, time/batch = 0.0885s	
391/3500 (epoch 5.586), train_loss = 2.13574924, grad/param norm = 4.6764e-01, time/batch = 0.0928s	
392/3500 (epoch 5.600), train_loss = 2.10402644, grad/param norm = 4.0630e-01, time/batch = 0.0894s	
393/3500 (epoch 5.614), train_loss = 2.09515217, grad/param norm = 3.1880e-01, time/batch = 0.0885s	
394/3500 (epoch 5.629), train_loss = 2.06256238, grad/param norm = 2.5025e-01, time/batch = 0.0915s	
395/3500 (epoch 5.643), train_loss = 2.07403923, grad/param norm = 2.3206e-01, time/batch = 0.0920s	
396/3500 (epoch 5.657), train_loss = 2.07877774, grad/param norm = 2.1096e-01, time/batch = 0.0913s	
397/3500 (epoch 5.671), train_loss = 2.06563953, grad/param norm = 1.8580e-01, time/batch = 0.0888s	
398/3500 (epoch 5.686), train_loss = 2.07222576, grad/param norm = 1.7442e-01, time/batch = 0.0885s	
399/3500 (epoch 5.700), train_loss = 2.07176025, grad/param norm = 1.7791e-01, time/batch = 0.0876s	
400/3500 (epoch 5.714), train_loss = 2.08590538, grad/param norm = 2.3134e-01, time/batch = 0.0885s	
401/3500 (epoch 5.729), train_loss = 2.09659117, grad/param norm = 2.9089e-01, time/batch = 0.0921s	
402/3500 (epoch 5.743), train_loss = 2.08438737, grad/param norm = 3.3710e-01, time/batch = 0.0884s	
403/3500 (epoch 5.757), train_loss = 2.08933521, grad/param norm = 3.6403e-01, time/batch = 0.0885s	
404/3500 (epoch 5.771), train_loss = 2.09129683, grad/param norm = 3.8998e-01, time/batch = 0.0915s	
405/3500 (epoch 5.786), train_loss = 2.11147072, grad/param norm = 4.0605e-01, time/batch = 0.0919s	
406/3500 (epoch 5.800), train_loss = 2.09082384, grad/param norm = 3.3410e-01, time/batch = 0.0910s	
407/3500 (epoch 5.814), train_loss = 2.07863669, grad/param norm = 2.5023e-01, time/batch = 0.0889s	
408/3500 (epoch 5.829), train_loss = 2.06153914, grad/param norm = 2.4887e-01, time/batch = 0.0884s	
409/3500 (epoch 5.843), train_loss = 2.08691390, grad/param norm = 2.6446e-01, time/batch = 0.0879s	
410/3500 (epoch 5.857), train_loss = 2.07463853, grad/param norm = 2.7664e-01, time/batch = 0.0883s	
411/3500 (epoch 5.871), train_loss = 2.08144217, grad/param norm = 2.5019e-01, time/batch = 0.0929s	
412/3500 (epoch 5.886), train_loss = 2.05599680, grad/param norm = 2.3883e-01, time/batch = 0.0888s	
413/3500 (epoch 5.900), train_loss = 2.08373646, grad/param norm = 2.7464e-01, time/batch = 0.0884s	
414/3500 (epoch 5.914), train_loss = 2.07919028, grad/param norm = 3.7462e-01, time/batch = 0.0915s	
415/3500 (epoch 5.929), train_loss = 2.07327411, grad/param norm = 3.9411e-01, time/batch = 0.0922s	
416/3500 (epoch 5.943), train_loss = 2.07186543, grad/param norm = 3.2247e-01, time/batch = 0.0913s	
417/3500 (epoch 5.957), train_loss = 2.07221153, grad/param norm = 3.1028e-01, time/batch = 0.0892s	
418/3500 (epoch 5.971), train_loss = 2.04457106, grad/param norm = 3.2359e-01, time/batch = 0.0887s	
419/3500 (epoch 5.986), train_loss = 2.06577328, grad/param norm = 3.1615e-01, time/batch = 0.0877s	
420/3500 (epoch 6.000), train_loss = 2.06721294, grad/param norm = 3.1613e-01, time/batch = 0.0884s	
421/3500 (epoch 6.014), train_loss = 2.13396613, grad/param norm = 3.0575e-01, time/batch = 0.0923s	
422/3500 (epoch 6.029), train_loss = 2.05968268, grad/param norm = 2.7499e-01, time/batch = 0.0883s	
423/3500 (epoch 6.043), train_loss = 2.04837015, grad/param norm = 2.3407e-01, time/batch = 0.0883s	
424/3500 (epoch 6.057), train_loss = 2.06685177, grad/param norm = 2.0603e-01, time/batch = 0.0915s	
425/3500 (epoch 6.071), train_loss = 2.02697939, grad/param norm = 1.9393e-01, time/batch = 0.0919s	
426/3500 (epoch 6.086), train_loss = 2.04579357, grad/param norm = 2.0580e-01, time/batch = 0.0916s	
427/3500 (epoch 6.100), train_loss = 2.05392222, grad/param norm = 2.5447e-01, time/batch = 0.0886s	
428/3500 (epoch 6.114), train_loss = 2.06134057, grad/param norm = 3.4122e-01, time/batch = 0.0884s	
429/3500 (epoch 6.129), train_loss = 2.07277176, grad/param norm = 3.8818e-01, time/batch = 0.0879s	
430/3500 (epoch 6.143), train_loss = 2.08885500, grad/param norm = 3.2548e-01, time/batch = 0.0886s	
431/3500 (epoch 6.157), train_loss = 2.03198260, grad/param norm = 2.4660e-01, time/batch = 0.0931s	
432/3500 (epoch 6.171), train_loss = 2.02413014, grad/param norm = 2.3539e-01, time/batch = 0.0884s	
433/3500 (epoch 6.186), train_loss = 2.03306589, grad/param norm = 2.3638e-01, time/batch = 0.0883s	
434/3500 (epoch 6.200), train_loss = 2.02802770, grad/param norm = 2.2526e-01, time/batch = 0.0915s	
435/3500 (epoch 6.214), train_loss = 2.00794630, grad/param norm = 2.2789e-01, time/batch = 0.0920s	
436/3500 (epoch 6.229), train_loss = 2.02079881, grad/param norm = 2.5077e-01, time/batch = 0.0920s	
437/3500 (epoch 6.243), train_loss = 2.03523549, grad/param norm = 2.9830e-01, time/batch = 0.0888s	
438/3500 (epoch 6.257), train_loss = 2.04811008, grad/param norm = 3.5943e-01, time/batch = 0.0887s	
439/3500 (epoch 6.271), train_loss = 2.06548825, grad/param norm = 3.5589e-01, time/batch = 0.0876s	
440/3500 (epoch 6.286), train_loss = 2.04795611, grad/param norm = 3.0157e-01, time/batch = 0.0886s	
441/3500 (epoch 6.300), train_loss = 2.03172717, grad/param norm = 2.4043e-01, time/batch = 0.0921s	
442/3500 (epoch 6.314), train_loss = 2.01952124, grad/param norm = 2.9110e-01, time/batch = 0.0881s	
443/3500 (epoch 6.329), train_loss = 2.06380145, grad/param norm = 3.5373e-01, time/batch = 0.0885s	
444/3500 (epoch 6.343), train_loss = 2.05017864, grad/param norm = 3.6603e-01, time/batch = 0.0915s	
445/3500 (epoch 6.357), train_loss = 2.04721322, grad/param norm = 3.2683e-01, time/batch = 0.0918s	
446/3500 (epoch 6.371), train_loss = 2.03382539, grad/param norm = 2.4681e-01, time/batch = 0.0911s	
447/3500 (epoch 6.386), train_loss = 2.00121603, grad/param norm = 1.9010e-01, time/batch = 0.0886s	
448/3500 (epoch 6.400), train_loss = 2.00546253, grad/param norm = 1.8626e-01, time/batch = 0.0882s	
449/3500 (epoch 6.414), train_loss = 2.04712073, grad/param norm = 2.2289e-01, time/batch = 0.0878s	
450/3500 (epoch 6.429), train_loss = 1.99486699, grad/param norm = 2.3638e-01, time/batch = 0.0885s	
451/3500 (epoch 6.443), train_loss = 2.01352090, grad/param norm = 2.4809e-01, time/batch = 0.0928s	
452/3500 (epoch 6.457), train_loss = 2.02394404, grad/param norm = 2.5082e-01, time/batch = 0.0884s	
453/3500 (epoch 6.471), train_loss = 2.00178727, grad/param norm = 2.2339e-01, time/batch = 0.0885s	
454/3500 (epoch 6.486), train_loss = 2.01156119, grad/param norm = 2.1702e-01, time/batch = 0.0916s	
455/3500 (epoch 6.500), train_loss = 2.01032323, grad/param norm = 2.2437e-01, time/batch = 0.0923s	
456/3500 (epoch 6.514), train_loss = 2.02814047, grad/param norm = 2.4336e-01, time/batch = 0.0912s	
457/3500 (epoch 6.529), train_loss = 2.02300725, grad/param norm = 2.5844e-01, time/batch = 0.0888s	
458/3500 (epoch 6.543), train_loss = 2.00973657, grad/param norm = 2.3865e-01, time/batch = 0.0884s	
459/3500 (epoch 6.557), train_loss = 1.99113574, grad/param norm = 2.5922e-01, time/batch = 0.0875s	
460/3500 (epoch 6.571), train_loss = 2.00035338, grad/param norm = 3.3272e-01, time/batch = 0.0888s	
461/3500 (epoch 6.586), train_loss = 2.03594301, grad/param norm = 3.9133e-01, time/batch = 0.0920s	
462/3500 (epoch 6.600), train_loss = 2.02650586, grad/param norm = 4.2384e-01, time/batch = 0.0881s	
463/3500 (epoch 6.614), train_loss = 2.02190910, grad/param norm = 3.4364e-01, time/batch = 0.0884s	
464/3500 (epoch 6.629), train_loss = 1.97536441, grad/param norm = 2.4121e-01, time/batch = 0.0915s	
465/3500 (epoch 6.643), train_loss = 1.98508946, grad/param norm = 2.1682e-01, time/batch = 0.0926s	
466/3500 (epoch 6.657), train_loss = 1.99498239, grad/param norm = 2.8693e-01, time/batch = 0.0910s	
467/3500 (epoch 6.671), train_loss = 1.99972460, grad/param norm = 3.0845e-01, time/batch = 0.0885s	
468/3500 (epoch 6.686), train_loss = 2.00144261, grad/param norm = 2.9163e-01, time/batch = 0.0882s	
469/3500 (epoch 6.700), train_loss = 1.99730564, grad/param norm = 2.4922e-01, time/batch = 0.0881s	
470/3500 (epoch 6.714), train_loss = 1.99285594, grad/param norm = 2.1090e-01, time/batch = 0.0889s	
471/3500 (epoch 6.729), train_loss = 1.99058643, grad/param norm = 1.7493e-01, time/batch = 0.0924s	
472/3500 (epoch 6.743), train_loss = 1.96881026, grad/param norm = 1.5577e-01, time/batch = 0.0885s	
473/3500 (epoch 6.757), train_loss = 1.97686451, grad/param norm = 1.8003e-01, time/batch = 0.0884s	
474/3500 (epoch 6.771), train_loss = 1.97774194, grad/param norm = 2.0989e-01, time/batch = 0.0920s	
475/3500 (epoch 6.786), train_loss = 1.99864018, grad/param norm = 2.4749e-01, time/batch = 0.0919s	
476/3500 (epoch 6.800), train_loss = 1.99138779, grad/param norm = 2.7862e-01, time/batch = 0.0916s	
477/3500 (epoch 6.814), train_loss = 1.99689997, grad/param norm = 2.8890e-01, time/batch = 0.0886s	
478/3500 (epoch 6.829), train_loss = 1.98420619, grad/param norm = 2.9948e-01, time/batch = 0.0885s	
479/3500 (epoch 6.843), train_loss = 2.01555216, grad/param norm = 2.8849e-01, time/batch = 0.0880s	
480/3500 (epoch 6.857), train_loss = 2.00320940, grad/param norm = 3.2011e-01, time/batch = 0.0883s	
481/3500 (epoch 6.871), train_loss = 2.00965089, grad/param norm = 3.1805e-01, time/batch = 0.0918s	
482/3500 (epoch 6.886), train_loss = 1.97268254, grad/param norm = 2.7192e-01, time/batch = 0.0882s	
483/3500 (epoch 6.900), train_loss = 1.99712806, grad/param norm = 2.4414e-01, time/batch = 0.0883s	
484/3500 (epoch 6.914), train_loss = 1.98131786, grad/param norm = 2.3336e-01, time/batch = 0.0920s	
485/3500 (epoch 6.929), train_loss = 1.96415696, grad/param norm = 2.4037e-01, time/batch = 0.0917s	
486/3500 (epoch 6.943), train_loss = 1.98328546, grad/param norm = 2.2986e-01, time/batch = 0.0913s	
487/3500 (epoch 6.957), train_loss = 1.98891012, grad/param norm = 2.0855e-01, time/batch = 0.0884s	
488/3500 (epoch 6.971), train_loss = 1.96020750, grad/param norm = 2.2112e-01, time/batch = 0.0885s	
489/3500 (epoch 6.986), train_loss = 1.98009227, grad/param norm = 2.0912e-01, time/batch = 0.0889s	
490/3500 (epoch 7.000), train_loss = 1.97099233, grad/param norm = 1.7486e-01, time/batch = 0.0884s	
491/3500 (epoch 7.014), train_loss = 2.04729974, grad/param norm = 1.6309e-01, time/batch = 0.0925s	
492/3500 (epoch 7.029), train_loss = 1.96141132, grad/param norm = 1.5294e-01, time/batch = 0.0885s	
493/3500 (epoch 7.043), train_loss = 1.95369441, grad/param norm = 1.4596e-01, time/batch = 0.0885s	
494/3500 (epoch 7.057), train_loss = 1.97487831, grad/param norm = 1.3541e-01, time/batch = 0.0922s	
495/3500 (epoch 7.071), train_loss = 1.93562582, grad/param norm = 1.3268e-01, time/batch = 0.0921s	
496/3500 (epoch 7.086), train_loss = 1.95829530, grad/param norm = 1.8393e-01, time/batch = 0.0913s	
497/3500 (epoch 7.100), train_loss = 1.97704498, grad/param norm = 2.5917e-01, time/batch = 0.0886s	
498/3500 (epoch 7.114), train_loss = 1.98037286, grad/param norm = 2.9562e-01, time/batch = 0.0884s	
499/3500 (epoch 7.129), train_loss = 1.98214368, grad/param norm = 2.4842e-01, time/batch = 0.0880s	
500/3500 (epoch 7.143), train_loss = 1.99209893, grad/param norm = 2.5049e-01, time/batch = 0.0885s	
501/3500 (epoch 7.157), train_loss = 1.97028982, grad/param norm = 3.7562e-01, time/batch = 0.0919s	
502/3500 (epoch 7.171), train_loss = 1.97681598, grad/param norm = 4.4096e-01, time/batch = 0.0882s	
503/3500 (epoch 7.186), train_loss = 1.99376221, grad/param norm = 4.3273e-01, time/batch = 0.0888s	
504/3500 (epoch 7.200), train_loss = 1.97009502, grad/param norm = 3.2360e-01, time/batch = 0.0915s	
505/3500 (epoch 7.214), train_loss = 1.93638292, grad/param norm = 2.5094e-01, time/batch = 0.0919s	
506/3500 (epoch 7.229), train_loss = 1.94035912, grad/param norm = 2.1977e-01, time/batch = 0.0908s	
507/3500 (epoch 7.243), train_loss = 1.94457996, grad/param norm = 2.0640e-01, time/batch = 0.0887s	
508/3500 (epoch 7.257), train_loss = 1.95138148, grad/param norm = 1.9891e-01, time/batch = 0.0889s	
509/3500 (epoch 7.271), train_loss = 1.96401808, grad/param norm = 2.1511e-01, time/batch = 0.0877s	
510/3500 (epoch 7.286), train_loss = 1.95419697, grad/param norm = 2.3655e-01, time/batch = 0.0882s	
511/3500 (epoch 7.300), train_loss = 1.95503909, grad/param norm = 2.2646e-01, time/batch = 0.0927s	
512/3500 (epoch 7.314), train_loss = 1.93306993, grad/param norm = 1.9858e-01, time/batch = 0.0885s	
513/3500 (epoch 7.329), train_loss = 1.95819662, grad/param norm = 1.6930e-01, time/batch = 0.0890s	
514/3500 (epoch 7.343), train_loss = 1.94899077, grad/param norm = 2.0054e-01, time/batch = 0.0916s	
515/3500 (epoch 7.357), train_loss = 1.95002917, grad/param norm = 2.2444e-01, time/batch = 0.0921s	
516/3500 (epoch 7.371), train_loss = 1.95208030, grad/param norm = 2.1169e-01, time/batch = 0.0909s	
517/3500 (epoch 7.386), train_loss = 1.92526670, grad/param norm = 2.4265e-01, time/batch = 0.0888s	
518/3500 (epoch 7.400), train_loss = 1.93296745, grad/param norm = 2.5916e-01, time/batch = 0.0890s	
519/3500 (epoch 7.414), train_loss = 1.96933613, grad/param norm = 2.5629e-01, time/batch = 0.0875s	
520/3500 (epoch 7.429), train_loss = 1.91426940, grad/param norm = 2.3186e-01, time/batch = 0.0884s	
521/3500 (epoch 7.443), train_loss = 1.93322440, grad/param norm = 2.0282e-01, time/batch = 0.0919s	
522/3500 (epoch 7.457), train_loss = 1.93815416, grad/param norm = 1.9908e-01, time/batch = 0.0884s	
523/3500 (epoch 7.471), train_loss = 1.91802505, grad/param norm = 2.0401e-01, time/batch = 0.0885s	
524/3500 (epoch 7.486), train_loss = 1.93297055, grad/param norm = 1.9049e-01, time/batch = 0.0915s	
525/3500 (epoch 7.500), train_loss = 1.93181521, grad/param norm = 1.9060e-01, time/batch = 0.0916s	
526/3500 (epoch 7.514), train_loss = 1.95380422, grad/param norm = 2.2647e-01, time/batch = 0.0912s	
527/3500 (epoch 7.529), train_loss = 1.94682916, grad/param norm = 2.4027e-01, time/batch = 0.0887s	
528/3500 (epoch 7.543), train_loss = 1.93709275, grad/param norm = 2.4658e-01, time/batch = 0.0884s	
529/3500 (epoch 7.557), train_loss = 1.91870966, grad/param norm = 2.9417e-01, time/batch = 0.0878s	
530/3500 (epoch 7.571), train_loss = 1.92423569, grad/param norm = 3.3834e-01, time/batch = 0.0882s	
531/3500 (epoch 7.586), train_loss = 1.95453393, grad/param norm = 3.2653e-01, time/batch = 0.0927s	
532/3500 (epoch 7.600), train_loss = 1.92555309, grad/param norm = 2.8928e-01, time/batch = 0.0887s	
533/3500 (epoch 7.614), train_loss = 1.93087233, grad/param norm = 3.0439e-01, time/batch = 0.0885s	
534/3500 (epoch 7.629), train_loss = 1.90986541, grad/param norm = 2.3785e-01, time/batch = 0.0917s	
535/3500 (epoch 7.643), train_loss = 1.90847531, grad/param norm = 1.8199e-01, time/batch = 0.0918s	
536/3500 (epoch 7.657), train_loss = 1.91334558, grad/param norm = 1.7675e-01, time/batch = 0.0913s	
537/3500 (epoch 7.671), train_loss = 1.89801524, grad/param norm = 1.8224e-01, time/batch = 0.0890s	
538/3500 (epoch 7.686), train_loss = 1.90632031, grad/param norm = 1.9464e-01, time/batch = 0.0884s	
539/3500 (epoch 7.700), train_loss = 1.90799700, grad/param norm = 2.1696e-01, time/batch = 0.0874s	
540/3500 (epoch 7.714), train_loss = 1.91923616, grad/param norm = 2.6233e-01, time/batch = 0.0885s	
541/3500 (epoch 7.729), train_loss = 1.93089696, grad/param norm = 2.7694e-01, time/batch = 0.0919s	
542/3500 (epoch 7.743), train_loss = 1.91194836, grad/param norm = 2.5321e-01, time/batch = 0.0887s	
543/3500 (epoch 7.757), train_loss = 1.91713357, grad/param norm = 2.2550e-01, time/batch = 0.0887s	
544/3500 (epoch 7.771), train_loss = 1.91036476, grad/param norm = 1.9182e-01, time/batch = 0.0914s	
545/3500 (epoch 7.786), train_loss = 1.91641012, grad/param norm = 1.7317e-01, time/batch = 0.0916s	
546/3500 (epoch 7.800), train_loss = 1.89903904, grad/param norm = 1.6271e-01, time/batch = 0.0916s	
547/3500 (epoch 7.814), train_loss = 1.90794827, grad/param norm = 1.7221e-01, time/batch = 0.0889s	
548/3500 (epoch 7.829), train_loss = 1.89811544, grad/param norm = 1.9277e-01, time/batch = 0.0882s	
549/3500 (epoch 7.843), train_loss = 1.93256312, grad/param norm = 1.9799e-01, time/batch = 0.0877s	
550/3500 (epoch 7.857), train_loss = 1.92325835, grad/param norm = 2.3821e-01, time/batch = 0.0883s	
551/3500 (epoch 7.871), train_loss = 1.92984961, grad/param norm = 2.5303e-01, time/batch = 0.0932s	
552/3500 (epoch 7.886), train_loss = 1.89838449, grad/param norm = 2.4035e-01, time/batch = 0.0885s	
553/3500 (epoch 7.900), train_loss = 1.93241552, grad/param norm = 2.6074e-01, time/batch = 0.0887s	
554/3500 (epoch 7.914), train_loss = 1.91520500, grad/param norm = 2.6960e-01, time/batch = 0.0914s	
555/3500 (epoch 7.929), train_loss = 1.89569498, grad/param norm = 2.5229e-01, time/batch = 0.0920s	
556/3500 (epoch 7.943), train_loss = 1.90463835, grad/param norm = 2.1704e-01, time/batch = 0.0918s	
557/3500 (epoch 7.957), train_loss = 1.91137523, grad/param norm = 2.0881e-01, time/batch = 0.0888s	
558/3500 (epoch 7.971), train_loss = 1.88816315, grad/param norm = 2.2409e-01, time/batch = 0.0884s	
559/3500 (epoch 7.986), train_loss = 1.90542798, grad/param norm = 2.2188e-01, time/batch = 0.0874s	
560/3500 (epoch 8.000), train_loss = 1.89704675, grad/param norm = 2.1570e-01, time/batch = 0.0885s	
561/3500 (epoch 8.014), train_loss = 1.99374841, grad/param norm = 2.0923e-01, time/batch = 0.0926s	
562/3500 (epoch 8.029), train_loss = 1.89335905, grad/param norm = 1.8020e-01, time/batch = 0.0882s	
563/3500 (epoch 8.043), train_loss = 1.88220021, grad/param norm = 1.6000e-01, time/batch = 0.0887s	
564/3500 (epoch 8.057), train_loss = 1.90229590, grad/param norm = 1.5750e-01, time/batch = 0.0914s	
565/3500 (epoch 8.071), train_loss = 1.86740774, grad/param norm = 1.6416e-01, time/batch = 0.0921s	
566/3500 (epoch 8.086), train_loss = 1.88914234, grad/param norm = 2.1323e-01, time/batch = 0.0915s	
567/3500 (epoch 8.100), train_loss = 1.90069873, grad/param norm = 2.0667e-01, time/batch = 0.0886s	
568/3500 (epoch 8.114), train_loss = 1.89089736, grad/param norm = 1.7089e-01, time/batch = 0.0882s	
569/3500 (epoch 8.129), train_loss = 1.88403211, grad/param norm = 1.6585e-01, time/batch = 0.0877s	
570/3500 (epoch 8.143), train_loss = 1.89963899, grad/param norm = 1.7556e-01, time/batch = 0.0883s	
571/3500 (epoch 8.157), train_loss = 1.87500446, grad/param norm = 2.0079e-01, time/batch = 0.0931s	
572/3500 (epoch 8.171), train_loss = 1.86605643, grad/param norm = 2.5394e-01, time/batch = 0.0886s	
573/3500 (epoch 8.186), train_loss = 1.90496405, grad/param norm = 3.0192e-01, time/batch = 0.0884s	
574/3500 (epoch 8.200), train_loss = 1.89145947, grad/param norm = 2.9594e-01, time/batch = 0.0914s	
575/3500 (epoch 8.214), train_loss = 1.87609725, grad/param norm = 2.3536e-01, time/batch = 0.0921s	
576/3500 (epoch 8.229), train_loss = 1.86255824, grad/param norm = 1.6798e-01, time/batch = 0.0917s	
577/3500 (epoch 8.243), train_loss = 1.87706196, grad/param norm = 1.8490e-01, time/batch = 0.0887s	
578/3500 (epoch 8.257), train_loss = 1.88732954, grad/param norm = 2.3076e-01, time/batch = 0.0884s	
579/3500 (epoch 8.271), train_loss = 1.91122422, grad/param norm = 2.8395e-01, time/batch = 0.0875s	
580/3500 (epoch 8.286), train_loss = 1.89789025, grad/param norm = 2.9583e-01, time/batch = 0.0886s	
581/3500 (epoch 8.300), train_loss = 1.89757426, grad/param norm = 2.7597e-01, time/batch = 0.0917s	
582/3500 (epoch 8.314), train_loss = 1.87071979, grad/param norm = 2.4058e-01, time/batch = 0.0884s	
583/3500 (epoch 8.329), train_loss = 1.89263917, grad/param norm = 2.0735e-01, time/batch = 0.0883s	
584/3500 (epoch 8.343), train_loss = 1.88600557, grad/param norm = 1.8546e-01, time/batch = 0.0917s	
585/3500 (epoch 8.357), train_loss = 1.87760684, grad/param norm = 1.8155e-01, time/batch = 0.1707s	
586/3500 (epoch 8.371), train_loss = 1.88040697, grad/param norm = 1.8390e-01, time/batch = 0.1819s	
587/3500 (epoch 8.386), train_loss = 1.85615682, grad/param norm = 2.0657e-01, time/batch = 0.1685s	
588/3500 (epoch 8.400), train_loss = 1.85379286, grad/param norm = 2.1205e-01, time/batch = 0.1216s	
589/3500 (epoch 8.414), train_loss = 1.88954927, grad/param norm = 1.8736e-01, time/batch = 0.1028s	
590/3500 (epoch 8.429), train_loss = 1.82759000, grad/param norm = 1.6686e-01, time/batch = 0.1034s	
591/3500 (epoch 8.443), train_loss = 1.85200019, grad/param norm = 1.5326e-01, time/batch = 0.1074s	
592/3500 (epoch 8.457), train_loss = 1.85677319, grad/param norm = 1.5284e-01, time/batch = 0.0988s	
593/3500 (epoch 8.471), train_loss = 1.84353047, grad/param norm = 1.7438e-01, time/batch = 0.0942s	
594/3500 (epoch 8.486), train_loss = 1.86052343, grad/param norm = 1.8208e-01, time/batch = 0.0972s	
595/3500 (epoch 8.500), train_loss = 1.86044697, grad/param norm = 1.7771e-01, time/batch = 0.0986s	
596/3500 (epoch 8.514), train_loss = 1.87532724, grad/param norm = 1.9713e-01, time/batch = 0.0984s	
597/3500 (epoch 8.529), train_loss = 1.87558177, grad/param norm = 2.1406e-01, time/batch = 0.1607s	
598/3500 (epoch 8.543), train_loss = 1.87149785, grad/param norm = 2.4081e-01, time/batch = 0.1676s	
599/3500 (epoch 8.557), train_loss = 1.85009020, grad/param norm = 2.7594e-01, time/batch = 0.1662s	
600/3500 (epoch 8.571), train_loss = 1.85286632, grad/param norm = 2.5632e-01, time/batch = 0.1178s	
601/3500 (epoch 8.586), train_loss = 1.86648038, grad/param norm = 2.1336e-01, time/batch = 0.1062s	
602/3500 (epoch 8.600), train_loss = 1.84551923, grad/param norm = 1.8612e-01, time/batch = 0.1043s	
603/3500 (epoch 8.614), train_loss = 1.85571241, grad/param norm = 2.1469e-01, time/batch = 0.1047s	
604/3500 (epoch 8.629), train_loss = 1.83924200, grad/param norm = 2.2501e-01, time/batch = 0.1020s	
605/3500 (epoch 8.643), train_loss = 1.84782505, grad/param norm = 2.2226e-01, time/batch = 0.0993s	
606/3500 (epoch 8.657), train_loss = 1.85450233, grad/param norm = 2.0145e-01, time/batch = 0.0986s	
607/3500 (epoch 8.671), train_loss = 1.84365184, grad/param norm = 2.2919e-01, time/batch = 0.0951s	
608/3500 (epoch 8.686), train_loss = 1.86087492, grad/param norm = 2.6391e-01, time/batch = 0.0945s	
609/3500 (epoch 8.700), train_loss = 1.85908056, grad/param norm = 2.7183e-01, time/batch = 0.0946s	
610/3500 (epoch 8.714), train_loss = 1.86390042, grad/param norm = 2.7950e-01, time/batch = 0.0947s	
611/3500 (epoch 8.729), train_loss = 1.85731158, grad/param norm = 2.2746e-01, time/batch = 0.0969s	
612/3500 (epoch 8.743), train_loss = 1.83412201, grad/param norm = 1.9904e-01, time/batch = 0.0950s	
613/3500 (epoch 8.757), train_loss = 1.84393016, grad/param norm = 1.9241e-01, time/batch = 0.0897s	
614/3500 (epoch 8.771), train_loss = 1.83894554, grad/param norm = 1.7626e-01, time/batch = 0.0839s	
615/3500 (epoch 8.786), train_loss = 1.84304059, grad/param norm = 1.6583e-01, time/batch = 0.0840s	
616/3500 (epoch 8.800), train_loss = 1.82694251, grad/param norm = 1.6604e-01, time/batch = 0.0837s	
617/3500 (epoch 8.814), train_loss = 1.83907785, grad/param norm = 1.7119e-01, time/batch = 0.0826s	
618/3500 (epoch 8.829), train_loss = 1.82116898, grad/param norm = 1.8465e-01, time/batch = 0.0825s	
619/3500 (epoch 8.843), train_loss = 1.86331755, grad/param norm = 2.0746e-01, time/batch = 0.0818s	
620/3500 (epoch 8.857), train_loss = 1.85369024, grad/param norm = 2.1002e-01, time/batch = 0.0824s	
621/3500 (epoch 8.871), train_loss = 1.85430052, grad/param norm = 1.9990e-01, time/batch = 0.0826s	
622/3500 (epoch 8.886), train_loss = 1.83452896, grad/param norm = 1.9269e-01, time/batch = 0.0821s	
623/3500 (epoch 8.900), train_loss = 1.86325814, grad/param norm = 2.0569e-01, time/batch = 0.0827s	
624/3500 (epoch 8.914), train_loss = 1.84861177, grad/param norm = 2.1161e-01, time/batch = 0.0838s	
625/3500 (epoch 8.929), train_loss = 1.82257307, grad/param norm = 1.9976e-01, time/batch = 0.0840s	
626/3500 (epoch 8.943), train_loss = 1.84102610, grad/param norm = 1.7404e-01, time/batch = 0.0835s	
627/3500 (epoch 8.957), train_loss = 1.84758571, grad/param norm = 1.6494e-01, time/batch = 0.0824s	
628/3500 (epoch 8.971), train_loss = 1.82622493, grad/param norm = 1.7853e-01, time/batch = 0.0823s	
629/3500 (epoch 8.986), train_loss = 1.84251426, grad/param norm = 1.5899e-01, time/batch = 0.0819s	
630/3500 (epoch 9.000), train_loss = 1.82678944, grad/param norm = 1.6000e-01, time/batch = 0.0824s	
631/3500 (epoch 9.014), train_loss = 1.93919956, grad/param norm = 2.1882e-01, time/batch = 0.0832s	
632/3500 (epoch 9.029), train_loss = 1.84420968, grad/param norm = 2.5390e-01, time/batch = 0.0824s	
633/3500 (epoch 9.043), train_loss = 1.82885464, grad/param norm = 2.4991e-01, time/batch = 0.0826s	
634/3500 (epoch 9.057), train_loss = 1.84710783, grad/param norm = 2.2942e-01, time/batch = 0.0837s	
635/3500 (epoch 9.071), train_loss = 1.81046341, grad/param norm = 2.1966e-01, time/batch = 0.0841s	
636/3500 (epoch 9.086), train_loss = 1.83382918, grad/param norm = 2.0986e-01, time/batch = 0.0835s	
637/3500 (epoch 9.100), train_loss = 1.83246676, grad/param norm = 1.9403e-01, time/batch = 0.0827s	
638/3500 (epoch 9.114), train_loss = 1.82612828, grad/param norm = 1.6749e-01, time/batch = 0.0829s	
639/3500 (epoch 9.129), train_loss = 1.82104408, grad/param norm = 1.4581e-01, time/batch = 0.0818s	
640/3500 (epoch 9.143), train_loss = 1.83047447, grad/param norm = 1.3638e-01, time/batch = 0.0824s	
641/3500 (epoch 9.157), train_loss = 1.80545195, grad/param norm = 1.4666e-01, time/batch = 0.0827s	
642/3500 (epoch 9.171), train_loss = 1.78792584, grad/param norm = 1.5867e-01, time/batch = 0.0822s	
643/3500 (epoch 9.186), train_loss = 1.81505644, grad/param norm = 1.8142e-01, time/batch = 0.0826s	
644/3500 (epoch 9.200), train_loss = 1.81202188, grad/param norm = 1.9441e-01, time/batch = 0.0837s	
645/3500 (epoch 9.214), train_loss = 1.80039921, grad/param norm = 2.1423e-01, time/batch = 0.0841s	
646/3500 (epoch 9.229), train_loss = 1.81182695, grad/param norm = 2.2256e-01, time/batch = 0.0834s	
647/3500 (epoch 9.243), train_loss = 1.81617235, grad/param norm = 2.2053e-01, time/batch = 0.0824s	
648/3500 (epoch 9.257), train_loss = 1.82651800, grad/param norm = 2.1409e-01, time/batch = 0.0826s	
649/3500 (epoch 9.271), train_loss = 1.83728220, grad/param norm = 2.1871e-01, time/batch = 0.0820s	
650/3500 (epoch 9.286), train_loss = 1.83271380, grad/param norm = 2.3738e-01, time/batch = 0.0825s	
651/3500 (epoch 9.300), train_loss = 1.83641419, grad/param norm = 2.1696e-01, time/batch = 0.0832s	
652/3500 (epoch 9.314), train_loss = 1.80015883, grad/param norm = 1.8635e-01, time/batch = 0.0823s	
653/3500 (epoch 9.329), train_loss = 1.83008644, grad/param norm = 1.8019e-01, time/batch = 0.0825s	
654/3500 (epoch 9.343), train_loss = 1.82449212, grad/param norm = 2.2587e-01, time/batch = 0.0836s	
655/3500 (epoch 9.357), train_loss = 1.83085525, grad/param norm = 1.9516e-01, time/batch = 0.0842s	
656/3500 (epoch 9.371), train_loss = 1.82146716, grad/param norm = 1.7241e-01, time/batch = 0.0837s	
657/3500 (epoch 9.386), train_loss = 1.79151788, grad/param norm = 1.9210e-01, time/batch = 0.0826s	
658/3500 (epoch 9.400), train_loss = 1.79268967, grad/param norm = 1.8217e-01, time/batch = 0.0828s	
659/3500 (epoch 9.414), train_loss = 1.82354271, grad/param norm = 1.6541e-01, time/batch = 0.0817s	
660/3500 (epoch 9.429), train_loss = 1.76235527, grad/param norm = 1.4366e-01, time/batch = 0.0824s	
661/3500 (epoch 9.443), train_loss = 1.78500899, grad/param norm = 1.1396e-01, time/batch = 0.0827s	
662/3500 (epoch 9.457), train_loss = 1.78831042, grad/param norm = 1.1512e-01, time/batch = 0.0821s	
663/3500 (epoch 9.471), train_loss = 1.78466884, grad/param norm = 1.6236e-01, time/batch = 0.0822s	
664/3500 (epoch 9.486), train_loss = 1.81389149, grad/param norm = 2.2585e-01, time/batch = 0.0836s	
665/3500 (epoch 9.500), train_loss = 1.82650815, grad/param norm = 2.4112e-01, time/batch = 0.0840s	
666/3500 (epoch 9.514), train_loss = 1.82446831, grad/param norm = 2.0319e-01, time/batch = 0.0835s	
667/3500 (epoch 9.529), train_loss = 1.81797849, grad/param norm = 1.7920e-01, time/batch = 0.0824s	
668/3500 (epoch 9.543), train_loss = 1.80402811, grad/param norm = 1.7789e-01, time/batch = 0.0827s	
669/3500 (epoch 9.557), train_loss = 1.77622606, grad/param norm = 1.8156e-01, time/batch = 0.0820s	
670/3500 (epoch 9.571), train_loss = 1.77705384, grad/param norm = 1.6113e-01, time/batch = 0.0824s	
671/3500 (epoch 9.586), train_loss = 1.79305152, grad/param norm = 1.5048e-01, time/batch = 0.0832s	
672/3500 (epoch 9.600), train_loss = 1.77783439, grad/param norm = 1.4168e-01, time/batch = 0.0824s	
673/3500 (epoch 9.614), train_loss = 1.78766374, grad/param norm = 1.6445e-01, time/batch = 0.0823s	
674/3500 (epoch 9.629), train_loss = 1.77344387, grad/param norm = 1.8785e-01, time/batch = 0.0838s	
675/3500 (epoch 9.643), train_loss = 1.78743329, grad/param norm = 1.8997e-01, time/batch = 0.0840s	
676/3500 (epoch 9.657), train_loss = 1.78701500, grad/param norm = 1.6145e-01, time/batch = 0.0837s	
677/3500 (epoch 9.671), train_loss = 1.77618784, grad/param norm = 1.9024e-01, time/batch = 0.0859s	
678/3500 (epoch 9.686), train_loss = 1.80023091, grad/param norm = 2.6745e-01, time/batch = 0.0835s	
679/3500 (epoch 9.700), train_loss = 1.80960487, grad/param norm = 3.0400e-01, time/batch = 0.0818s	
680/3500 (epoch 9.714), train_loss = 1.82063711, grad/param norm = 3.2797e-01, time/batch = 0.0824s	
681/3500 (epoch 9.729), train_loss = 1.80963044, grad/param norm = 2.3682e-01, time/batch = 0.0827s	
682/3500 (epoch 9.743), train_loss = 1.77685474, grad/param norm = 1.8388e-01, time/batch = 0.0821s	
683/3500 (epoch 9.757), train_loss = 1.78621472, grad/param norm = 1.6899e-01, time/batch = 0.0822s	
684/3500 (epoch 9.771), train_loss = 1.77892091, grad/param norm = 1.5025e-01, time/batch = 0.0835s	
685/3500 (epoch 9.786), train_loss = 1.78023276, grad/param norm = 1.2932e-01, time/batch = 0.0839s	
686/3500 (epoch 9.800), train_loss = 1.76256434, grad/param norm = 1.1827e-01, time/batch = 0.0836s	
687/3500 (epoch 9.814), train_loss = 1.77343301, grad/param norm = 1.1518e-01, time/batch = 0.0824s	
688/3500 (epoch 9.829), train_loss = 1.75240091, grad/param norm = 1.2322e-01, time/batch = 0.0822s	
689/3500 (epoch 9.843), train_loss = 1.79772451, grad/param norm = 1.4658e-01, time/batch = 0.0820s	
690/3500 (epoch 9.857), train_loss = 1.79250460, grad/param norm = 1.5687e-01, time/batch = 0.0824s	
691/3500 (epoch 9.871), train_loss = 1.79484808, grad/param norm = 1.5017e-01, time/batch = 0.0833s	
692/3500 (epoch 9.886), train_loss = 1.77443650, grad/param norm = 1.3968e-01, time/batch = 0.0824s	
693/3500 (epoch 9.900), train_loss = 1.79910484, grad/param norm = 1.3131e-01, time/batch = 0.0823s	
694/3500 (epoch 9.914), train_loss = 1.78133109, grad/param norm = 1.2582e-01, time/batch = 0.0837s	
695/3500 (epoch 9.929), train_loss = 1.75916936, grad/param norm = 1.3915e-01, time/batch = 0.0840s	
696/3500 (epoch 9.943), train_loss = 1.78274436, grad/param norm = 1.4178e-01, time/batch = 0.0836s	
697/3500 (epoch 9.957), train_loss = 1.79399312, grad/param norm = 1.4410e-01, time/batch = 0.0826s	
698/3500 (epoch 9.971), train_loss = 1.77811084, grad/param norm = 1.6656e-01, time/batch = 0.0825s	
699/3500 (epoch 9.986), train_loss = 1.79315320, grad/param norm = 2.0053e-01, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00194	
700/3500 (epoch 10.000), train_loss = 1.78285337, grad/param norm = 2.0048e-01, time/batch = 0.0823s	
701/3500 (epoch 10.014), train_loss = 1.89738410, grad/param norm = 1.6424e-01, time/batch = 0.0827s	
702/3500 (epoch 10.029), train_loss = 1.76887776, grad/param norm = 1.2605e-01, time/batch = 0.0821s	
703/3500 (epoch 10.043), train_loss = 1.75684990, grad/param norm = 1.1968e-01, time/batch = 0.0822s	
704/3500 (epoch 10.057), train_loss = 1.77535205, grad/param norm = 1.4258e-01, time/batch = 0.0836s	
705/3500 (epoch 10.071), train_loss = 1.75325437, grad/param norm = 1.6087e-01, time/batch = 0.0839s	
706/3500 (epoch 10.086), train_loss = 1.77064348, grad/param norm = 1.5914e-01, time/batch = 0.0834s	
707/3500 (epoch 10.100), train_loss = 1.76959748, grad/param norm = 1.3893e-01, time/batch = 0.0824s	
708/3500 (epoch 10.114), train_loss = 1.76360271, grad/param norm = 1.3228e-01, time/batch = 0.0822s	
709/3500 (epoch 10.129), train_loss = 1.76159993, grad/param norm = 1.4198e-01, time/batch = 0.0819s	
710/3500 (epoch 10.143), train_loss = 1.77426720, grad/param norm = 1.7591e-01, time/batch = 0.0824s	
711/3500 (epoch 10.157), train_loss = 1.76438315, grad/param norm = 2.3986e-01, time/batch = 0.0833s	
712/3500 (epoch 10.171), train_loss = 1.76018203, grad/param norm = 2.8522e-01, time/batch = 0.0827s	
713/3500 (epoch 10.186), train_loss = 1.79180549, grad/param norm = 2.6735e-01, time/batch = 0.0823s	
714/3500 (epoch 10.200), train_loss = 1.76173346, grad/param norm = 2.1490e-01, time/batch = 0.0838s	
715/3500 (epoch 10.214), train_loss = 1.74594679, grad/param norm = 1.7535e-01, time/batch = 0.0841s	
716/3500 (epoch 10.229), train_loss = 1.74514966, grad/param norm = 1.5287e-01, time/batch = 0.0838s	
717/3500 (epoch 10.243), train_loss = 1.75245436, grad/param norm = 1.2267e-01, time/batch = 0.0831s	
718/3500 (epoch 10.257), train_loss = 1.75274859, grad/param norm = 1.1272e-01, time/batch = 0.0824s	
719/3500 (epoch 10.271), train_loss = 1.76514110, grad/param norm = 1.3058e-01, time/batch = 0.0817s	
720/3500 (epoch 10.286), train_loss = 1.75699085, grad/param norm = 1.6880e-01, time/batch = 0.0823s	
721/3500 (epoch 10.300), train_loss = 1.77460716, grad/param norm = 1.7439e-01, time/batch = 0.0828s	
722/3500 (epoch 10.314), train_loss = 1.74520098, grad/param norm = 1.5911e-01, time/batch = 0.0825s	
723/3500 (epoch 10.329), train_loss = 1.77499215, grad/param norm = 1.4954e-01, time/batch = 0.0822s	
724/3500 (epoch 10.343), train_loss = 1.76115559, grad/param norm = 1.6264e-01, time/batch = 0.0836s	
725/3500 (epoch 10.357), train_loss = 1.76518581, grad/param norm = 1.5495e-01, time/batch = 0.0839s	
726/3500 (epoch 10.371), train_loss = 1.75907110, grad/param norm = 1.5563e-01, time/batch = 0.0835s	
727/3500 (epoch 10.386), train_loss = 1.73829747, grad/param norm = 1.4677e-01, time/batch = 0.0828s	
728/3500 (epoch 10.400), train_loss = 1.73345557, grad/param norm = 1.4170e-01, time/batch = 0.0822s	
729/3500 (epoch 10.414), train_loss = 1.77059595, grad/param norm = 1.4997e-01, time/batch = 0.0820s	
730/3500 (epoch 10.429), train_loss = 1.71069535, grad/param norm = 1.5069e-01, time/batch = 0.0824s	
731/3500 (epoch 10.443), train_loss = 1.74075986, grad/param norm = 1.5267e-01, time/batch = 0.0832s	
732/3500 (epoch 10.457), train_loss = 1.74371548, grad/param norm = 1.4999e-01, time/batch = 0.0827s	
733/3500 (epoch 10.471), train_loss = 1.73925172, grad/param norm = 1.6170e-01, time/batch = 0.0823s	
734/3500 (epoch 10.486), train_loss = 1.76162343, grad/param norm = 1.9591e-01, time/batch = 0.0836s	
735/3500 (epoch 10.500), train_loss = 1.75897726, grad/param norm = 1.8893e-01, time/batch = 0.0841s	
736/3500 (epoch 10.514), train_loss = 1.76419120, grad/param norm = 1.6631e-01, time/batch = 0.0837s	
737/3500 (epoch 10.529), train_loss = 1.76389349, grad/param norm = 1.6002e-01, time/batch = 0.0829s	
738/3500 (epoch 10.543), train_loss = 1.74867312, grad/param norm = 1.5939e-01, time/batch = 0.0825s	
739/3500 (epoch 10.557), train_loss = 1.71864279, grad/param norm = 1.5139e-01, time/batch = 0.0817s	
740/3500 (epoch 10.571), train_loss = 1.72046297, grad/param norm = 1.3305e-01, time/batch = 0.0824s	
741/3500 (epoch 10.586), train_loss = 1.74025274, grad/param norm = 1.3940e-01, time/batch = 0.0828s	
742/3500 (epoch 10.600), train_loss = 1.72632090, grad/param norm = 1.4621e-01, time/batch = 0.0821s	
743/3500 (epoch 10.614), train_loss = 1.73906906, grad/param norm = 1.4208e-01, time/batch = 0.0822s	
744/3500 (epoch 10.629), train_loss = 1.71833129, grad/param norm = 1.4527e-01, time/batch = 0.0836s	
745/3500 (epoch 10.643), train_loss = 1.73585527, grad/param norm = 1.6590e-01, time/batch = 0.0839s	
746/3500 (epoch 10.657), train_loss = 1.73953522, grad/param norm = 2.0025e-01, time/batch = 0.0834s	
747/3500 (epoch 10.671), train_loss = 1.73732074, grad/param norm = 2.4123e-01, time/batch = 0.0827s	
748/3500 (epoch 10.686), train_loss = 1.75838692, grad/param norm = 2.4385e-01, time/batch = 0.0822s	
749/3500 (epoch 10.700), train_loss = 1.75654497, grad/param norm = 2.3463e-01, time/batch = 0.0820s	
750/3500 (epoch 10.714), train_loss = 1.74782465, grad/param norm = 2.3942e-01, time/batch = 0.0824s	
751/3500 (epoch 10.729), train_loss = 1.74879987, grad/param norm = 1.9533e-01, time/batch = 0.0831s	
752/3500 (epoch 10.743), train_loss = 1.71667836, grad/param norm = 1.4202e-01, time/batch = 0.0823s	
753/3500 (epoch 10.757), train_loss = 1.73474586, grad/param norm = 1.3197e-01, time/batch = 0.0824s	
754/3500 (epoch 10.771), train_loss = 1.72429353, grad/param norm = 1.2807e-01, time/batch = 0.0836s	
755/3500 (epoch 10.786), train_loss = 1.73038487, grad/param norm = 1.1934e-01, time/batch = 0.0842s	
756/3500 (epoch 10.800), train_loss = 1.71141487, grad/param norm = 1.1154e-01, time/batch = 0.0837s	
757/3500 (epoch 10.814), train_loss = 1.72288327, grad/param norm = 1.1343e-01, time/batch = 0.0826s	
758/3500 (epoch 10.829), train_loss = 1.70016346, grad/param norm = 1.1954e-01, time/batch = 0.0824s	
759/3500 (epoch 10.843), train_loss = 1.74420957, grad/param norm = 1.1482e-01, time/batch = 0.0817s	
760/3500 (epoch 10.857), train_loss = 1.73830876, grad/param norm = 1.4338e-01, time/batch = 0.0824s	
761/3500 (epoch 10.871), train_loss = 1.74833100, grad/param norm = 1.6483e-01, time/batch = 0.0827s	
762/3500 (epoch 10.886), train_loss = 1.72765021, grad/param norm = 1.6431e-01, time/batch = 0.0821s	
763/3500 (epoch 10.900), train_loss = 1.75350994, grad/param norm = 1.6146e-01, time/batch = 0.0822s	
764/3500 (epoch 10.914), train_loss = 1.73815059, grad/param norm = 1.6779e-01, time/batch = 0.0834s	
765/3500 (epoch 10.929), train_loss = 1.72035299, grad/param norm = 1.9420e-01, time/batch = 0.0840s	
766/3500 (epoch 10.943), train_loss = 1.74480932, grad/param norm = 1.6734e-01, time/batch = 0.0840s	
767/3500 (epoch 10.957), train_loss = 1.74790382, grad/param norm = 1.5460e-01, time/batch = 0.0824s	
768/3500 (epoch 10.971), train_loss = 1.73315009, grad/param norm = 1.8506e-01, time/batch = 0.0822s	
769/3500 (epoch 10.986), train_loss = 1.74361351, grad/param norm = 1.8568e-01, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0018818	
770/3500 (epoch 11.000), train_loss = 1.71940094, grad/param norm = 1.5398e-01, time/batch = 0.0825s	
771/3500 (epoch 11.014), train_loss = 1.84921935, grad/param norm = 1.2582e-01, time/batch = 0.0833s	
772/3500 (epoch 11.029), train_loss = 1.71414934, grad/param norm = 9.0105e-02, time/batch = 0.0823s	
773/3500 (epoch 11.043), train_loss = 1.70426577, grad/param norm = 9.3136e-02, time/batch = 0.0823s	
774/3500 (epoch 11.057), train_loss = 1.71854860, grad/param norm = 1.0362e-01, time/batch = 0.0836s	
775/3500 (epoch 11.071), train_loss = 1.70184430, grad/param norm = 1.3018e-01, time/batch = 0.0841s	
776/3500 (epoch 11.086), train_loss = 1.72441065, grad/param norm = 1.9348e-01, time/batch = 0.0868s	
777/3500 (epoch 11.100), train_loss = 1.74061212, grad/param norm = 1.8717e-01, time/batch = 0.0829s	
778/3500 (epoch 11.114), train_loss = 1.72322893, grad/param norm = 1.4041e-01, time/batch = 0.0825s	
779/3500 (epoch 11.129), train_loss = 1.71749952, grad/param norm = 1.2758e-01, time/batch = 0.0818s	
780/3500 (epoch 11.143), train_loss = 1.72677719, grad/param norm = 1.2640e-01, time/batch = 0.0824s	
781/3500 (epoch 11.157), train_loss = 1.71009860, grad/param norm = 1.4789e-01, time/batch = 0.0831s	
782/3500 (epoch 11.171), train_loss = 1.69667503, grad/param norm = 1.7382e-01, time/batch = 0.0821s	
783/3500 (epoch 11.186), train_loss = 1.72207891, grad/param norm = 1.9847e-01, time/batch = 0.0821s	
784/3500 (epoch 11.200), train_loss = 1.71692993, grad/param norm = 2.0751e-01, time/batch = 0.0834s	
785/3500 (epoch 11.214), train_loss = 1.69967915, grad/param norm = 2.0865e-01, time/batch = 0.0841s	
786/3500 (epoch 11.229), train_loss = 1.70925503, grad/param norm = 2.0313e-01, time/batch = 0.0838s	
787/3500 (epoch 11.243), train_loss = 1.70730231, grad/param norm = 1.6894e-01, time/batch = 0.0825s	
788/3500 (epoch 11.257), train_loss = 1.71045880, grad/param norm = 1.3388e-01, time/batch = 0.0823s	
789/3500 (epoch 11.271), train_loss = 1.71918913, grad/param norm = 1.3513e-01, time/batch = 0.0820s	
790/3500 (epoch 11.286), train_loss = 1.71508747, grad/param norm = 1.5738e-01, time/batch = 0.0824s	
791/3500 (epoch 11.300), train_loss = 1.72858195, grad/param norm = 1.5046e-01, time/batch = 0.0836s	
792/3500 (epoch 11.314), train_loss = 1.69801213, grad/param norm = 1.2521e-01, time/batch = 0.0823s	
793/3500 (epoch 11.329), train_loss = 1.72154818, grad/param norm = 1.0397e-01, time/batch = 0.0823s	
794/3500 (epoch 11.343), train_loss = 1.71224667, grad/param norm = 1.1985e-01, time/batch = 0.0837s	
795/3500 (epoch 11.357), train_loss = 1.71971840, grad/param norm = 1.4383e-01, time/batch = 0.0841s	
796/3500 (epoch 11.371), train_loss = 1.71960516, grad/param norm = 1.5963e-01, time/batch = 0.0840s	
797/3500 (epoch 11.386), train_loss = 1.69726829, grad/param norm = 1.4609e-01, time/batch = 0.0825s	
798/3500 (epoch 11.400), train_loss = 1.69039375, grad/param norm = 1.2732e-01, time/batch = 0.0824s	
799/3500 (epoch 11.414), train_loss = 1.71790052, grad/param norm = 1.1737e-01, time/batch = 0.0818s	
800/3500 (epoch 11.429), train_loss = 1.65846133, grad/param norm = 1.0581e-01, time/batch = 0.0824s	
801/3500 (epoch 11.443), train_loss = 1.68588933, grad/param norm = 9.8041e-02, time/batch = 0.0831s	
802/3500 (epoch 11.457), train_loss = 1.68819536, grad/param norm = 9.2667e-02, time/batch = 0.0821s	
803/3500 (epoch 11.471), train_loss = 1.68577434, grad/param norm = 1.2362e-01, time/batch = 0.0822s	
804/3500 (epoch 11.486), train_loss = 1.71533647, grad/param norm = 1.7951e-01, time/batch = 0.0837s	
805/3500 (epoch 11.500), train_loss = 1.72036733, grad/param norm = 1.9578e-01, time/batch = 0.0839s	
806/3500 (epoch 11.514), train_loss = 1.72995417, grad/param norm = 1.6336e-01, time/batch = 0.0839s	
807/3500 (epoch 11.529), train_loss = 1.71694623, grad/param norm = 1.2913e-01, time/batch = 0.0825s	
808/3500 (epoch 11.543), train_loss = 1.70138127, grad/param norm = 1.2544e-01, time/batch = 0.0823s	
809/3500 (epoch 11.557), train_loss = 1.66684193, grad/param norm = 1.2672e-01, time/batch = 0.0820s	
810/3500 (epoch 11.571), train_loss = 1.67643212, grad/param norm = 1.3371e-01, time/batch = 0.0824s	
811/3500 (epoch 11.586), train_loss = 1.69418909, grad/param norm = 1.6844e-01, time/batch = 0.0836s	
812/3500 (epoch 11.600), train_loss = 1.69076111, grad/param norm = 1.8770e-01, time/batch = 0.0823s	
813/3500 (epoch 11.614), train_loss = 1.70223088, grad/param norm = 2.0929e-01, time/batch = 0.0823s	
814/3500 (epoch 11.629), train_loss = 1.68894499, grad/param norm = 2.0290e-01, time/batch = 0.0838s	
815/3500 (epoch 11.643), train_loss = 1.69444447, grad/param norm = 1.8910e-01, time/batch = 0.0842s	
816/3500 (epoch 11.657), train_loss = 1.69639568, grad/param norm = 1.8999e-01, time/batch = 0.0841s	
817/3500 (epoch 11.671), train_loss = 1.67936803, grad/param norm = 1.7770e-01, time/batch = 0.0825s	
818/3500 (epoch 11.686), train_loss = 1.69052275, grad/param norm = 1.4856e-01, time/batch = 0.0825s	
819/3500 (epoch 11.700), train_loss = 1.68448141, grad/param norm = 1.1852e-01, time/batch = 0.0818s	
820/3500 (epoch 11.714), train_loss = 1.68548965, grad/param norm = 1.3731e-01, time/batch = 0.0824s	
821/3500 (epoch 11.729), train_loss = 1.69235466, grad/param norm = 1.6731e-01, time/batch = 0.0826s	
822/3500 (epoch 11.743), train_loss = 1.68633104, grad/param norm = 1.9268e-01, time/batch = 0.0821s	
823/3500 (epoch 11.757), train_loss = 1.70634723, grad/param norm = 1.6121e-01, time/batch = 0.0822s	
824/3500 (epoch 11.771), train_loss = 1.68974944, grad/param norm = 1.3701e-01, time/batch = 0.0835s	
825/3500 (epoch 11.786), train_loss = 1.69063410, grad/param norm = 1.2269e-01, time/batch = 0.0839s	
826/3500 (epoch 11.800), train_loss = 1.67265218, grad/param norm = 1.1544e-01, time/batch = 0.0838s	
827/3500 (epoch 11.814), train_loss = 1.68139482, grad/param norm = 1.1552e-01, time/batch = 0.0825s	
828/3500 (epoch 11.829), train_loss = 1.65841445, grad/param norm = 1.0796e-01, time/batch = 0.0822s	
829/3500 (epoch 11.843), train_loss = 1.69844968, grad/param norm = 9.7623e-02, time/batch = 0.0819s	
830/3500 (epoch 11.857), train_loss = 1.69508469, grad/param norm = 1.2038e-01, time/batch = 0.0824s	
831/3500 (epoch 11.871), train_loss = 1.70412818, grad/param norm = 1.4967e-01, time/batch = 0.0832s	
832/3500 (epoch 11.886), train_loss = 1.68889697, grad/param norm = 1.7580e-01, time/batch = 0.0823s	
833/3500 (epoch 11.900), train_loss = 1.72116792, grad/param norm = 1.7417e-01, time/batch = 0.0823s	
834/3500 (epoch 11.914), train_loss = 1.70107672, grad/param norm = 1.6476e-01, time/batch = 0.0836s	
835/3500 (epoch 11.929), train_loss = 1.67898125, grad/param norm = 1.5268e-01, time/batch = 0.0841s	
836/3500 (epoch 11.943), train_loss = 1.69551892, grad/param norm = 1.4253e-01, time/batch = 0.0838s	
837/3500 (epoch 11.957), train_loss = 1.70785209, grad/param norm = 1.5191e-01, time/batch = 0.0825s	
838/3500 (epoch 11.971), train_loss = 1.69295302, grad/param norm = 1.6761e-01, time/batch = 0.0825s	
839/3500 (epoch 11.986), train_loss = 1.69943251, grad/param norm = 1.5766e-01, time/batch = 0.0817s	
decayed learning rate by a factor 0.97 to 0.001825346	
840/3500 (epoch 12.000), train_loss = 1.67559834, grad/param norm = 1.3138e-01, time/batch = 0.0825s	
841/3500 (epoch 12.014), train_loss = 1.81475095, grad/param norm = 1.0951e-01, time/batch = 0.0828s	
842/3500 (epoch 12.029), train_loss = 1.67490619, grad/param norm = 9.1565e-02, time/batch = 0.0821s	
843/3500 (epoch 12.043), train_loss = 1.66674353, grad/param norm = 9.7639e-02, time/batch = 0.0822s	
844/3500 (epoch 12.057), train_loss = 1.67975849, grad/param norm = 1.1144e-01, time/batch = 0.0835s	
845/3500 (epoch 12.071), train_loss = 1.66280360, grad/param norm = 1.1713e-01, time/batch = 0.0843s	
846/3500 (epoch 12.086), train_loss = 1.67441618, grad/param norm = 1.1735e-01, time/batch = 0.0834s	
847/3500 (epoch 12.100), train_loss = 1.67895997, grad/param norm = 1.1641e-01, time/batch = 0.0824s	
848/3500 (epoch 12.114), train_loss = 1.67799249, grad/param norm = 1.3403e-01, time/batch = 0.0822s	
849/3500 (epoch 12.129), train_loss = 1.68189595, grad/param norm = 1.7737e-01, time/batch = 0.0820s	
850/3500 (epoch 12.143), train_loss = 1.70011135, grad/param norm = 1.6657e-01, time/batch = 0.0832s	
851/3500 (epoch 12.157), train_loss = 1.67430011, grad/param norm = 1.5094e-01, time/batch = 0.0831s	
852/3500 (epoch 12.171), train_loss = 1.65516446, grad/param norm = 1.3878e-01, time/batch = 0.0824s	
853/3500 (epoch 12.186), train_loss = 1.67448545, grad/param norm = 1.1778e-01, time/batch = 0.0823s	
854/3500 (epoch 12.200), train_loss = 1.66124731, grad/param norm = 1.0139e-01, time/batch = 0.0838s	
855/3500 (epoch 12.214), train_loss = 1.64518542, grad/param norm = 9.4900e-02, time/batch = 0.0845s	
856/3500 (epoch 12.229), train_loss = 1.65021795, grad/param norm = 1.0567e-01, time/batch = 0.0837s	
857/3500 (epoch 12.243), train_loss = 1.65812714, grad/param norm = 1.1534e-01, time/batch = 0.0826s	
858/3500 (epoch 12.257), train_loss = 1.66698288, grad/param norm = 1.1689e-01, time/batch = 0.0825s	
859/3500 (epoch 12.271), train_loss = 1.67590335, grad/param norm = 1.2591e-01, time/batch = 0.0818s	
860/3500 (epoch 12.286), train_loss = 1.67217230, grad/param norm = 1.5684e-01, time/batch = 0.0824s	
861/3500 (epoch 12.300), train_loss = 1.69663702, grad/param norm = 2.0606e-01, time/batch = 0.0826s	
862/3500 (epoch 12.314), train_loss = 1.67810133, grad/param norm = 2.1776e-01, time/batch = 0.0821s	
863/3500 (epoch 12.329), train_loss = 1.69554698, grad/param norm = 1.8593e-01, time/batch = 0.0822s	
864/3500 (epoch 12.343), train_loss = 1.68149827, grad/param norm = 1.6124e-01, time/batch = 0.0836s	
865/3500 (epoch 12.357), train_loss = 1.68743482, grad/param norm = 1.6522e-01, time/batch = 0.0842s	
866/3500 (epoch 12.371), train_loss = 1.68642581, grad/param norm = 1.8973e-01, time/batch = 0.0834s	
867/3500 (epoch 12.386), train_loss = 1.66482612, grad/param norm = 1.6904e-01, time/batch = 0.0824s	
868/3500 (epoch 12.400), train_loss = 1.65528577, grad/param norm = 1.2628e-01, time/batch = 0.0823s	
869/3500 (epoch 12.414), train_loss = 1.67638232, grad/param norm = 1.0323e-01, time/batch = 0.0820s	
870/3500 (epoch 12.429), train_loss = 1.61988799, grad/param norm = 9.6888e-02, time/batch = 0.0826s	
871/3500 (epoch 12.443), train_loss = 1.64791205, grad/param norm = 9.3326e-02, time/batch = 0.0832s	
872/3500 (epoch 12.457), train_loss = 1.64806818, grad/param norm = 8.1184e-02, time/batch = 0.0823s	
873/3500 (epoch 12.471), train_loss = 1.64332069, grad/param norm = 8.6059e-02, time/batch = 0.0823s	
874/3500 (epoch 12.486), train_loss = 1.66427039, grad/param norm = 1.0376e-01, time/batch = 0.0839s	
875/3500 (epoch 12.500), train_loss = 1.66019619, grad/param norm = 1.1582e-01, time/batch = 0.0863s	
876/3500 (epoch 12.514), train_loss = 1.68062894, grad/param norm = 1.1285e-01, time/batch = 0.0838s	
877/3500 (epoch 12.529), train_loss = 1.67592670, grad/param norm = 1.1571e-01, time/batch = 0.0826s	
878/3500 (epoch 12.543), train_loss = 1.66248694, grad/param norm = 1.1436e-01, time/batch = 0.0825s	
879/3500 (epoch 12.557), train_loss = 1.62629900, grad/param norm = 1.1767e-01, time/batch = 0.0818s	
880/3500 (epoch 12.571), train_loss = 1.63921155, grad/param norm = 1.3131e-01, time/batch = 0.0825s	
881/3500 (epoch 12.586), train_loss = 1.65622453, grad/param norm = 1.4249e-01, time/batch = 0.0828s	
882/3500 (epoch 12.600), train_loss = 1.65033990, grad/param norm = 1.5370e-01, time/batch = 0.0821s	
883/3500 (epoch 12.614), train_loss = 1.66522053, grad/param norm = 1.7447e-01, time/batch = 0.0821s	
884/3500 (epoch 12.629), train_loss = 1.65417147, grad/param norm = 2.0399e-01, time/batch = 0.0835s	
885/3500 (epoch 12.643), train_loss = 1.66917523, grad/param norm = 2.2575e-01, time/batch = 0.0843s	
886/3500 (epoch 12.657), train_loss = 1.66002428, grad/param norm = 1.5839e-01, time/batch = 0.0834s	
887/3500 (epoch 12.671), train_loss = 1.64101556, grad/param norm = 1.2299e-01, time/batch = 0.0825s	
888/3500 (epoch 12.686), train_loss = 1.65031080, grad/param norm = 1.2688e-01, time/batch = 0.0822s	
889/3500 (epoch 12.700), train_loss = 1.65459667, grad/param norm = 1.1929e-01, time/batch = 0.0819s	
890/3500 (epoch 12.714), train_loss = 1.65086842, grad/param norm = 1.5387e-01, time/batch = 0.0828s	
891/3500 (epoch 12.729), train_loss = 1.65405622, grad/param norm = 1.2073e-01, time/batch = 0.0832s	
892/3500 (epoch 12.743), train_loss = 1.63930558, grad/param norm = 1.3108e-01, time/batch = 0.0823s	
893/3500 (epoch 12.757), train_loss = 1.66525221, grad/param norm = 1.5687e-01, time/batch = 0.0822s	
894/3500 (epoch 12.771), train_loss = 1.65753747, grad/param norm = 1.5067e-01, time/batch = 0.0838s	
895/3500 (epoch 12.786), train_loss = 1.65161647, grad/param norm = 1.1192e-01, time/batch = 0.0848s	
896/3500 (epoch 12.800), train_loss = 1.63373733, grad/param norm = 9.7799e-02, time/batch = 0.0837s	
897/3500 (epoch 12.814), train_loss = 1.64369662, grad/param norm = 9.5598e-02, time/batch = 0.0825s	
898/3500 (epoch 12.829), train_loss = 1.61941282, grad/param norm = 9.1560e-02, time/batch = 0.0825s	
899/3500 (epoch 12.843), train_loss = 1.66347239, grad/param norm = 9.8561e-02, time/batch = 0.0817s	
900/3500 (epoch 12.857), train_loss = 1.66251893, grad/param norm = 1.2498e-01, time/batch = 0.0829s	
901/3500 (epoch 12.871), train_loss = 1.67195889, grad/param norm = 1.5195e-01, time/batch = 0.0827s	
902/3500 (epoch 12.886), train_loss = 1.65431840, grad/param norm = 1.6630e-01, time/batch = 0.0821s	
903/3500 (epoch 12.900), train_loss = 1.67990614, grad/param norm = 1.6390e-01, time/batch = 0.0822s	
904/3500 (epoch 12.914), train_loss = 1.66505294, grad/param norm = 1.6096e-01, time/batch = 0.0835s	
905/3500 (epoch 12.929), train_loss = 1.64600205, grad/param norm = 1.4671e-01, time/batch = 0.0843s	
906/3500 (epoch 12.943), train_loss = 1.65954939, grad/param norm = 1.4926e-01, time/batch = 0.0833s	
907/3500 (epoch 12.957), train_loss = 1.67602629, grad/param norm = 1.6968e-01, time/batch = 0.0823s	
908/3500 (epoch 12.971), train_loss = 1.65899108, grad/param norm = 1.6690e-01, time/batch = 0.0823s	
909/3500 (epoch 12.986), train_loss = 1.65923071, grad/param norm = 1.2522e-01, time/batch = 0.0819s	
decayed learning rate by a factor 0.97 to 0.00177058562	
910/3500 (epoch 13.000), train_loss = 1.63455275, grad/param norm = 1.0321e-01, time/batch = 0.0828s	
911/3500 (epoch 13.014), train_loss = 1.78541332, grad/param norm = 1.0435e-01, time/batch = 0.0832s	
912/3500 (epoch 13.029), train_loss = 1.64108618, grad/param norm = 9.2767e-02, time/batch = 0.0824s	
913/3500 (epoch 13.043), train_loss = 1.63147190, grad/param norm = 9.0320e-02, time/batch = 0.0823s	
914/3500 (epoch 13.057), train_loss = 1.63945596, grad/param norm = 8.8675e-02, time/batch = 0.0838s	
915/3500 (epoch 13.071), train_loss = 1.62280717, grad/param norm = 7.9380e-02, time/batch = 0.0841s	
916/3500 (epoch 13.086), train_loss = 1.63088382, grad/param norm = 7.5584e-02, time/batch = 0.0837s	
917/3500 (epoch 13.100), train_loss = 1.63736682, grad/param norm = 7.4636e-02, time/batch = 0.0825s	
918/3500 (epoch 13.114), train_loss = 1.63457198, grad/param norm = 7.5951e-02, time/batch = 0.0824s	
919/3500 (epoch 13.129), train_loss = 1.63353015, grad/param norm = 8.1308e-02, time/batch = 0.0817s	
920/3500 (epoch 13.143), train_loss = 1.64233306, grad/param norm = 8.5288e-02, time/batch = 0.0828s	
921/3500 (epoch 13.157), train_loss = 1.62783720, grad/param norm = 1.0250e-01, time/batch = 0.0826s	
922/3500 (epoch 13.171), train_loss = 1.61596610, grad/param norm = 1.1165e-01, time/batch = 0.0821s	
923/3500 (epoch 13.186), train_loss = 1.64001688, grad/param norm = 1.1104e-01, time/batch = 0.0822s	
924/3500 (epoch 13.200), train_loss = 1.63324895, grad/param norm = 1.1319e-01, time/batch = 0.0840s	
925/3500 (epoch 13.214), train_loss = 1.61885721, grad/param norm = 1.1706e-01, time/batch = 0.0840s	
926/3500 (epoch 13.229), train_loss = 1.62755923, grad/param norm = 1.4351e-01, time/batch = 0.0833s	
927/3500 (epoch 13.243), train_loss = 1.63722823, grad/param norm = 1.3842e-01, time/batch = 0.0824s	
928/3500 (epoch 13.257), train_loss = 1.63869192, grad/param norm = 1.1941e-01, time/batch = 0.0822s	
929/3500 (epoch 13.271), train_loss = 1.64428230, grad/param norm = 1.0779e-01, time/batch = 0.0820s	
930/3500 (epoch 13.286), train_loss = 1.63775053, grad/param norm = 1.3297e-01, time/batch = 0.0825s	
931/3500 (epoch 13.300), train_loss = 1.66533237, grad/param norm = 1.7601e-01, time/batch = 0.0832s	
932/3500 (epoch 13.314), train_loss = 1.64203637, grad/param norm = 1.9604e-01, time/batch = 0.0824s	
933/3500 (epoch 13.329), train_loss = 1.67267388, grad/param norm = 2.0330e-01, time/batch = 0.0823s	
934/3500 (epoch 13.343), train_loss = 1.65604156, grad/param norm = 2.0114e-01, time/batch = 0.0841s	
935/3500 (epoch 13.357), train_loss = 1.66072191, grad/param norm = 1.6925e-01, time/batch = 0.0840s	
936/3500 (epoch 13.371), train_loss = 1.64252862, grad/param norm = 1.4839e-01, time/batch = 0.0837s	
937/3500 (epoch 13.386), train_loss = 1.62291740, grad/param norm = 1.3028e-01, time/batch = 0.0826s	
938/3500 (epoch 13.400), train_loss = 1.61411608, grad/param norm = 1.1175e-01, time/batch = 0.0824s	
939/3500 (epoch 13.414), train_loss = 1.64018994, grad/param norm = 1.0045e-01, time/batch = 0.0818s	
940/3500 (epoch 13.429), train_loss = 1.58614273, grad/param norm = 9.9410e-02, time/batch = 0.0824s	
941/3500 (epoch 13.443), train_loss = 1.61671207, grad/param norm = 1.0305e-01, time/batch = 0.0827s	
942/3500 (epoch 13.457), train_loss = 1.61732711, grad/param norm = 9.7684e-02, time/batch = 0.0821s	
943/3500 (epoch 13.471), train_loss = 1.61529491, grad/param norm = 9.1851e-02, time/batch = 0.0822s	
944/3500 (epoch 13.486), train_loss = 1.63481063, grad/param norm = 1.0179e-01, time/batch = 0.0840s	
945/3500 (epoch 13.500), train_loss = 1.62965948, grad/param norm = 1.1018e-01, time/batch = 0.0840s	
946/3500 (epoch 13.514), train_loss = 1.64880768, grad/param norm = 1.0789e-01, time/batch = 0.0834s	
947/3500 (epoch 13.529), train_loss = 1.64158536, grad/param norm = 1.0441e-01, time/batch = 0.0824s	
948/3500 (epoch 13.543), train_loss = 1.63370852, grad/param norm = 1.2033e-01, time/batch = 0.0823s	
949/3500 (epoch 13.557), train_loss = 1.59960892, grad/param norm = 1.2813e-01, time/batch = 0.0820s	
950/3500 (epoch 13.571), train_loss = 1.60785868, grad/param norm = 1.2286e-01, time/batch = 0.0825s	
951/3500 (epoch 13.586), train_loss = 1.62141865, grad/param norm = 1.2910e-01, time/batch = 0.0832s	
952/3500 (epoch 13.600), train_loss = 1.61459266, grad/param norm = 1.2594e-01, time/batch = 0.0823s	
953/3500 (epoch 13.614), train_loss = 1.62453354, grad/param norm = 1.1551e-01, time/batch = 0.0823s	
954/3500 (epoch 13.629), train_loss = 1.60480936, grad/param norm = 1.0450e-01, time/batch = 0.0843s	
955/3500 (epoch 13.643), train_loss = 1.61662736, grad/param norm = 1.1102e-01, time/batch = 0.0840s	
956/3500 (epoch 13.657), train_loss = 1.61180315, grad/param norm = 1.1843e-01, time/batch = 0.0836s	
957/3500 (epoch 13.671), train_loss = 1.60018870, grad/param norm = 1.2809e-01, time/batch = 0.0826s	
958/3500 (epoch 13.686), train_loss = 1.61973761, grad/param norm = 1.4453e-01, time/batch = 0.0827s	
959/3500 (epoch 13.700), train_loss = 1.62620471, grad/param norm = 1.7079e-01, time/batch = 0.0818s	
960/3500 (epoch 13.714), train_loss = 1.63620227, grad/param norm = 2.3566e-01, time/batch = 0.0824s	
961/3500 (epoch 13.729), train_loss = 1.63576430, grad/param norm = 1.7704e-01, time/batch = 0.0826s	
962/3500 (epoch 13.743), train_loss = 1.61452802, grad/param norm = 1.4670e-01, time/batch = 0.0821s	
963/3500 (epoch 13.757), train_loss = 1.62730840, grad/param norm = 1.3925e-01, time/batch = 0.0822s	
964/3500 (epoch 13.771), train_loss = 1.62158914, grad/param norm = 1.2650e-01, time/batch = 0.0841s	
965/3500 (epoch 13.786), train_loss = 1.61717226, grad/param norm = 9.9670e-02, time/batch = 0.0838s	
966/3500 (epoch 13.800), train_loss = 1.60169804, grad/param norm = 8.8373e-02, time/batch = 0.0835s	
967/3500 (epoch 13.814), train_loss = 1.61078686, grad/param norm = 7.9615e-02, time/batch = 0.0824s	
968/3500 (epoch 13.829), train_loss = 1.58794348, grad/param norm = 8.1478e-02, time/batch = 0.0823s	
969/3500 (epoch 13.843), train_loss = 1.63075676, grad/param norm = 9.5661e-02, time/batch = 0.0824s	
970/3500 (epoch 13.857), train_loss = 1.62800311, grad/param norm = 1.0168e-01, time/batch = 0.0824s	
971/3500 (epoch 13.871), train_loss = 1.63140384, grad/param norm = 1.0519e-01, time/batch = 0.0832s	
972/3500 (epoch 13.886), train_loss = 1.61620618, grad/param norm = 1.0917e-01, time/batch = 0.0823s	
973/3500 (epoch 13.900), train_loss = 1.63670927, grad/param norm = 1.1334e-01, time/batch = 0.0824s	
974/3500 (epoch 13.914), train_loss = 1.63013954, grad/param norm = 1.2238e-01, time/batch = 0.0861s	
975/3500 (epoch 13.929), train_loss = 1.61159723, grad/param norm = 1.3666e-01, time/batch = 0.0843s	
976/3500 (epoch 13.943), train_loss = 1.63026453, grad/param norm = 1.3498e-01, time/batch = 0.0838s	
977/3500 (epoch 13.957), train_loss = 1.64067905, grad/param norm = 1.4019e-01, time/batch = 0.0826s	
978/3500 (epoch 13.971), train_loss = 1.63243264, grad/param norm = 1.5071e-01, time/batch = 0.0825s	
979/3500 (epoch 13.986), train_loss = 1.63492164, grad/param norm = 1.5153e-01, time/batch = 0.0821s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
980/3500 (epoch 14.000), train_loss = 1.61695908, grad/param norm = 1.4328e-01, time/batch = 0.0824s	
981/3500 (epoch 14.014), train_loss = 1.76737711, grad/param norm = 1.2941e-01, time/batch = 0.0827s	
982/3500 (epoch 14.029), train_loss = 1.61389129, grad/param norm = 1.1172e-01, time/batch = 0.0820s	
983/3500 (epoch 14.043), train_loss = 1.60419252, grad/param norm = 1.0918e-01, time/batch = 0.0821s	
984/3500 (epoch 14.057), train_loss = 1.61072496, grad/param norm = 1.2805e-01, time/batch = 0.0841s	
985/3500 (epoch 14.071), train_loss = 1.60256462, grad/param norm = 1.3288e-01, time/batch = 0.0840s	
986/3500 (epoch 14.086), train_loss = 1.61103542, grad/param norm = 1.3209e-01, time/batch = 0.0835s	
987/3500 (epoch 14.100), train_loss = 1.61965032, grad/param norm = 1.2190e-01, time/batch = 0.0824s	
988/3500 (epoch 14.114), train_loss = 1.61233503, grad/param norm = 1.0616e-01, time/batch = 0.0823s	
989/3500 (epoch 14.129), train_loss = 1.61115896, grad/param norm = 1.0788e-01, time/batch = 0.0823s	
990/3500 (epoch 14.143), train_loss = 1.61654314, grad/param norm = 9.7599e-02, time/batch = 0.0824s	
991/3500 (epoch 14.157), train_loss = 1.60137350, grad/param norm = 1.0517e-01, time/batch = 0.0832s	
992/3500 (epoch 14.171), train_loss = 1.58759856, grad/param norm = 1.0139e-01, time/batch = 0.0823s	
993/3500 (epoch 14.186), train_loss = 1.60821194, grad/param norm = 1.0326e-01, time/batch = 0.0824s	
994/3500 (epoch 14.200), train_loss = 1.60582232, grad/param norm = 1.2633e-01, time/batch = 0.0839s	
995/3500 (epoch 14.214), train_loss = 1.59229922, grad/param norm = 1.3423e-01, time/batch = 0.0841s	
996/3500 (epoch 14.229), train_loss = 1.59466152, grad/param norm = 1.3951e-01, time/batch = 0.0837s	
997/3500 (epoch 14.243), train_loss = 1.60419050, grad/param norm = 1.2521e-01, time/batch = 0.0826s	
998/3500 (epoch 14.257), train_loss = 1.61021080, grad/param norm = 1.1658e-01, time/batch = 0.0828s	
999/3500 (epoch 14.271), train_loss = 1.61821681, grad/param norm = 1.2130e-01, time/batch = 0.0823s	
evaluating loss over split index 2	
1/4...	
2/4...	
3/4...	
4/4...	
saving checkpoint to cv/lm_lstm_epoch14.29_1.6506.t7	
1000/3500 (epoch 14.286), train_loss = 1.61348780, grad/param norm = 1.2766e-01, time/batch = 0.0823s	
1001/3500 (epoch 14.300), train_loss = 1.76733689, grad/param norm = 1.2236e-01, time/batch = 0.1701s	
1002/3500 (epoch 14.314), train_loss = 1.59845870, grad/param norm = 1.1833e-01, time/batch = 0.1664s	
1003/3500 (epoch 14.329), train_loss = 1.62411613, grad/param norm = 1.1166e-01, time/batch = 0.1568s	
1004/3500 (epoch 14.343), train_loss = 1.60718669, grad/param norm = 1.1324e-01, time/batch = 0.1107s	
1005/3500 (epoch 14.357), train_loss = 1.61917451, grad/param norm = 1.0713e-01, time/batch = 0.1120s	
1006/3500 (epoch 14.371), train_loss = 1.60767569, grad/param norm = 1.0073e-01, time/batch = 0.1120s	
1007/3500 (epoch 14.386), train_loss = 1.58738512, grad/param norm = 9.2278e-02, time/batch = 0.1069s	
1008/3500 (epoch 14.400), train_loss = 1.58194304, grad/param norm = 8.6561e-02, time/batch = 0.0996s	
1009/3500 (epoch 14.414), train_loss = 1.60814453, grad/param norm = 8.5812e-02, time/batch = 0.0952s	
1010/3500 (epoch 14.429), train_loss = 1.55731405, grad/param norm = 9.4979e-02, time/batch = 0.0957s	
1011/3500 (epoch 14.443), train_loss = 1.58947613, grad/param norm = 1.1026e-01, time/batch = 0.0970s	
1012/3500 (epoch 14.457), train_loss = 1.59288903, grad/param norm = 1.2958e-01, time/batch = 0.0960s	
1013/3500 (epoch 14.471), train_loss = 1.59891820, grad/param norm = 1.5662e-01, time/batch = 0.0950s	
1014/3500 (epoch 14.486), train_loss = 1.62311682, grad/param norm = 1.8394e-01, time/batch = 0.0980s	
1015/3500 (epoch 14.500), train_loss = 1.61646278, grad/param norm = 1.8378e-01, time/batch = 0.0994s	
1016/3500 (epoch 14.514), train_loss = 1.62972204, grad/param norm = 1.4861e-01, time/batch = 0.0988s	
1017/3500 (epoch 14.529), train_loss = 1.61784253, grad/param norm = 1.2278e-01, time/batch = 0.0948s	
1018/3500 (epoch 14.543), train_loss = 1.60350873, grad/param norm = 1.1849e-01, time/batch = 0.0831s	
1019/3500 (epoch 14.557), train_loss = 1.56886696, grad/param norm = 1.1988e-01, time/batch = 0.0817s	
1020/3500 (epoch 14.571), train_loss = 1.57718437, grad/param norm = 1.1856e-01, time/batch = 0.0824s	
1021/3500 (epoch 14.586), train_loss = 1.59173745, grad/param norm = 1.2556e-01, time/batch = 0.0829s	
1022/3500 (epoch 14.600), train_loss = 1.58631091, grad/param norm = 1.2390e-01, time/batch = 0.0824s	
1023/3500 (epoch 14.614), train_loss = 1.59361360, grad/param norm = 1.1516e-01, time/batch = 0.0823s	
1024/3500 (epoch 14.629), train_loss = 1.57628117, grad/param norm = 1.1100e-01, time/batch = 0.0836s	
1025/3500 (epoch 14.643), train_loss = 1.58828559, grad/param norm = 1.0914e-01, time/batch = 0.0839s	
1026/3500 (epoch 14.657), train_loss = 1.57896648, grad/param norm = 8.8627e-02, time/batch = 0.0835s	
1027/3500 (epoch 14.671), train_loss = 1.56548120, grad/param norm = 8.5770e-02, time/batch = 0.0828s	
1028/3500 (epoch 14.686), train_loss = 1.58481299, grad/param norm = 1.0026e-01, time/batch = 0.0823s	
1029/3500 (epoch 14.700), train_loss = 1.59117907, grad/param norm = 1.0860e-01, time/batch = 0.0820s	
1030/3500 (epoch 14.714), train_loss = 1.59235245, grad/param norm = 1.7475e-01, time/batch = 0.0824s	
1031/3500 (epoch 14.729), train_loss = 1.59410550, grad/param norm = 1.0283e-01, time/batch = 0.0833s	
1032/3500 (epoch 14.743), train_loss = 1.57657831, grad/param norm = 9.9401e-02, time/batch = 0.0828s	
1033/3500 (epoch 14.757), train_loss = 1.59803770, grad/param norm = 1.2285e-01, time/batch = 0.0823s	
1034/3500 (epoch 14.771), train_loss = 1.59501106, grad/param norm = 1.1769e-01, time/batch = 0.0837s	
1035/3500 (epoch 14.786), train_loss = 1.59149205, grad/param norm = 1.0608e-01, time/batch = 0.0842s	
1036/3500 (epoch 14.800), train_loss = 1.58028530, grad/param norm = 1.1339e-01, time/batch = 0.0838s	
1037/3500 (epoch 14.814), train_loss = 1.59272844, grad/param norm = 1.2693e-01, time/batch = 0.0830s	
1038/3500 (epoch 14.829), train_loss = 1.57781721, grad/param norm = 1.4386e-01, time/batch = 0.0825s	
1039/3500 (epoch 14.843), train_loss = 1.61973253, grad/param norm = 1.4847e-01, time/batch = 0.0818s	
1040/3500 (epoch 14.857), train_loss = 1.60863741, grad/param norm = 1.1937e-01, time/batch = 0.0824s	
1041/3500 (epoch 14.871), train_loss = 1.60322176, grad/param norm = 9.8641e-02, time/batch = 0.0827s	
1042/3500 (epoch 14.886), train_loss = 1.58770947, grad/param norm = 9.8574e-02, time/batch = 0.0821s	
1043/3500 (epoch 14.900), train_loss = 1.60673977, grad/param norm = 9.8564e-02, time/batch = 0.0823s	
1044/3500 (epoch 14.914), train_loss = 1.60339523, grad/param norm = 1.0469e-01, time/batch = 0.0836s	
1045/3500 (epoch 14.929), train_loss = 1.58246084, grad/param norm = 1.0189e-01, time/batch = 0.0841s	
1046/3500 (epoch 14.943), train_loss = 1.59690905, grad/param norm = 8.8657e-02, time/batch = 0.0835s	
1047/3500 (epoch 14.957), train_loss = 1.60900552, grad/param norm = 9.5905e-02, time/batch = 0.0829s	
1048/3500 (epoch 14.971), train_loss = 1.59914006, grad/param norm = 1.1123e-01, time/batch = 0.0823s	
1049/3500 (epoch 14.986), train_loss = 1.59973462, grad/param norm = 1.0953e-01, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
1050/3500 (epoch 15.000), train_loss = 1.58219377, grad/param norm = 1.1359e-01, time/batch = 0.0825s	
1051/3500 (epoch 15.014), train_loss = 1.75181025, grad/param norm = 1.4170e-01, time/batch = 0.0832s	
1052/3500 (epoch 15.029), train_loss = 1.59851695, grad/param norm = 1.4739e-01, time/batch = 0.0824s	
1053/3500 (epoch 15.043), train_loss = 1.58806438, grad/param norm = 1.5094e-01, time/batch = 0.0823s	
1054/3500 (epoch 15.057), train_loss = 1.59249231, grad/param norm = 1.6246e-01, time/batch = 0.0838s	
1055/3500 (epoch 15.071), train_loss = 1.58014746, grad/param norm = 1.4458e-01, time/batch = 0.0842s	
1056/3500 (epoch 15.086), train_loss = 1.58304686, grad/param norm = 1.1454e-01, time/batch = 0.0836s	
1057/3500 (epoch 15.100), train_loss = 1.58653754, grad/param norm = 9.6222e-02, time/batch = 0.0826s	
1058/3500 (epoch 15.114), train_loss = 1.58139507, grad/param norm = 8.4658e-02, time/batch = 0.0825s	
1059/3500 (epoch 15.129), train_loss = 1.58127338, grad/param norm = 9.1299e-02, time/batch = 0.0818s	
1060/3500 (epoch 15.143), train_loss = 1.58812004, grad/param norm = 9.3670e-02, time/batch = 0.0825s	
1061/3500 (epoch 15.157), train_loss = 1.57525466, grad/param norm = 1.1541e-01, time/batch = 0.0830s	
1062/3500 (epoch 15.171), train_loss = 1.56417994, grad/param norm = 1.0874e-01, time/batch = 0.0822s	
1063/3500 (epoch 15.186), train_loss = 1.58151854, grad/param norm = 9.9522e-02, time/batch = 0.0822s	
1064/3500 (epoch 15.200), train_loss = 1.57597040, grad/param norm = 1.0326e-01, time/batch = 0.0835s	
1065/3500 (epoch 15.214), train_loss = 1.55927977, grad/param norm = 1.0820e-01, time/batch = 0.0841s	
1066/3500 (epoch 15.229), train_loss = 1.56405764, grad/param norm = 1.2247e-01, time/batch = 0.0845s	
1067/3500 (epoch 15.243), train_loss = 1.57386052, grad/param norm = 1.1949e-01, time/batch = 0.0835s	
1068/3500 (epoch 15.257), train_loss = 1.58072152, grad/param norm = 1.0609e-01, time/batch = 0.0823s	
1069/3500 (epoch 15.271), train_loss = 1.58738166, grad/param norm = 1.0255e-01, time/batch = 0.0820s	
1070/3500 (epoch 15.286), train_loss = 1.58392334, grad/param norm = 1.1030e-01, time/batch = 0.0825s	
1071/3500 (epoch 15.300), train_loss = 1.60225860, grad/param norm = 1.0949e-01, time/batch = 0.0833s	
1072/3500 (epoch 15.314), train_loss = 1.57034902, grad/param norm = 1.1254e-01, time/batch = 0.0824s	
1073/3500 (epoch 15.329), train_loss = 1.59880835, grad/param norm = 1.2066e-01, time/batch = 0.0823s	
1074/3500 (epoch 15.343), train_loss = 1.58741790, grad/param norm = 1.3797e-01, time/batch = 0.0837s	
1075/3500 (epoch 15.357), train_loss = 1.60343966, grad/param norm = 1.4913e-01, time/batch = 0.0842s	
1076/3500 (epoch 15.371), train_loss = 1.59259582, grad/param norm = 1.3931e-01, time/batch = 0.0840s	
1077/3500 (epoch 15.386), train_loss = 1.56952113, grad/param norm = 1.2408e-01, time/batch = 0.0826s	
1078/3500 (epoch 15.400), train_loss = 1.56113985, grad/param norm = 9.4023e-02, time/batch = 0.0824s	
1079/3500 (epoch 15.414), train_loss = 1.57997876, grad/param norm = 7.0229e-02, time/batch = 0.0818s	
1080/3500 (epoch 15.429), train_loss = 1.53085582, grad/param norm = 6.5392e-02, time/batch = 0.0824s	
1081/3500 (epoch 15.443), train_loss = 1.55984304, grad/param norm = 6.9443e-02, time/batch = 0.0827s	
1082/3500 (epoch 15.457), train_loss = 1.56071691, grad/param norm = 6.8611e-02, time/batch = 0.0821s	
1083/3500 (epoch 15.471), train_loss = 1.56165102, grad/param norm = 8.2040e-02, time/batch = 0.0823s	
1084/3500 (epoch 15.486), train_loss = 1.58055098, grad/param norm = 8.7148e-02, time/batch = 0.0836s	
1085/3500 (epoch 15.500), train_loss = 1.57331608, grad/param norm = 9.6444e-02, time/batch = 0.0841s	
1086/3500 (epoch 15.514), train_loss = 1.60038999, grad/param norm = 1.2359e-01, time/batch = 0.0839s	
1087/3500 (epoch 15.529), train_loss = 1.59727626, grad/param norm = 1.4759e-01, time/batch = 0.0825s	
1088/3500 (epoch 15.543), train_loss = 1.59214675, grad/param norm = 1.5381e-01, time/batch = 0.0823s	
1089/3500 (epoch 15.557), train_loss = 1.54877756, grad/param norm = 1.3310e-01, time/batch = 0.0820s	
1090/3500 (epoch 15.571), train_loss = 1.55270275, grad/param norm = 1.1102e-01, time/batch = 0.0825s	
1091/3500 (epoch 15.586), train_loss = 1.56084527, grad/param norm = 1.0595e-01, time/batch = 0.0836s	
1092/3500 (epoch 15.600), train_loss = 1.55569114, grad/param norm = 9.2443e-02, time/batch = 0.0823s	
1093/3500 (epoch 15.614), train_loss = 1.56165316, grad/param norm = 8.6456e-02, time/batch = 0.0822s	
1094/3500 (epoch 15.629), train_loss = 1.54683440, grad/param norm = 8.2963e-02, time/batch = 0.0835s	
1095/3500 (epoch 15.643), train_loss = 1.56217577, grad/param norm = 9.1374e-02, time/batch = 0.0842s	
1096/3500 (epoch 15.657), train_loss = 1.55571440, grad/param norm = 9.9739e-02, time/batch = 0.0840s	
1097/3500 (epoch 15.671), train_loss = 1.54444394, grad/param norm = 1.0742e-01, time/batch = 0.0826s	
1098/3500 (epoch 15.686), train_loss = 1.56423391, grad/param norm = 1.1153e-01, time/batch = 0.0825s	
1099/3500 (epoch 15.700), train_loss = 1.56740182, grad/param norm = 1.0405e-01, time/batch = 0.0817s	
1100/3500 (epoch 15.714), train_loss = 1.56276361, grad/param norm = 1.1659e-01, time/batch = 0.0824s	
1101/3500 (epoch 15.729), train_loss = 1.56653316, grad/param norm = 1.1847e-01, time/batch = 0.0832s	
1102/3500 (epoch 15.743), train_loss = 1.55201463, grad/param norm = 1.1517e-01, time/batch = 0.0820s	
1103/3500 (epoch 15.757), train_loss = 1.57324350, grad/param norm = 1.1461e-01, time/batch = 0.0822s	
1104/3500 (epoch 15.771), train_loss = 1.56690315, grad/param norm = 1.1802e-01, time/batch = 0.0835s	
1105/3500 (epoch 15.786), train_loss = 1.56886474, grad/param norm = 1.1274e-01, time/batch = 0.0843s	
1106/3500 (epoch 15.800), train_loss = 1.55312403, grad/param norm = 9.5699e-02, time/batch = 0.0840s	
1107/3500 (epoch 15.814), train_loss = 1.56237887, grad/param norm = 9.0973e-02, time/batch = 0.0824s	
1108/3500 (epoch 15.829), train_loss = 1.54475750, grad/param norm = 1.0113e-01, time/batch = 0.0822s	
1109/3500 (epoch 15.843), train_loss = 1.58866554, grad/param norm = 1.2766e-01, time/batch = 0.0820s	
1110/3500 (epoch 15.857), train_loss = 1.58882038, grad/param norm = 1.3806e-01, time/batch = 0.0825s	
1111/3500 (epoch 15.871), train_loss = 1.58929098, grad/param norm = 1.4424e-01, time/batch = 0.0837s	
1112/3500 (epoch 15.886), train_loss = 1.57561520, grad/param norm = 1.3461e-01, time/batch = 0.0823s	
1113/3500 (epoch 15.900), train_loss = 1.58785652, grad/param norm = 1.2162e-01, time/batch = 0.0823s	
1114/3500 (epoch 15.914), train_loss = 1.58566506, grad/param norm = 1.3443e-01, time/batch = 0.0836s	
1115/3500 (epoch 15.929), train_loss = 1.56589703, grad/param norm = 1.3706e-01, time/batch = 0.0841s	
1116/3500 (epoch 15.943), train_loss = 1.58261228, grad/param norm = 1.3742e-01, time/batch = 0.0841s	
1117/3500 (epoch 15.957), train_loss = 1.59231797, grad/param norm = 1.1572e-01, time/batch = 0.0825s	
1118/3500 (epoch 15.971), train_loss = 1.57988854, grad/param norm = 1.0904e-01, time/batch = 0.0825s	
1119/3500 (epoch 15.986), train_loss = 1.57393668, grad/param norm = 1.1893e-01, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
1120/3500 (epoch 16.000), train_loss = 1.56356431, grad/param norm = 1.2432e-01, time/batch = 0.0825s	
1121/3500 (epoch 16.014), train_loss = 1.72943742, grad/param norm = 1.3045e-01, time/batch = 0.0827s	
1122/3500 (epoch 16.029), train_loss = 1.56705083, grad/param norm = 1.1642e-01, time/batch = 0.0821s	
1123/3500 (epoch 16.043), train_loss = 1.55617595, grad/param norm = 1.0513e-01, time/batch = 0.0823s	
1124/3500 (epoch 16.057), train_loss = 1.55766732, grad/param norm = 1.2810e-01, time/batch = 0.0836s	
1125/3500 (epoch 16.071), train_loss = 1.55369614, grad/param norm = 1.0373e-01, time/batch = 0.0840s	
1126/3500 (epoch 16.086), train_loss = 1.55668118, grad/param norm = 8.6995e-02, time/batch = 0.0838s	
1127/3500 (epoch 16.100), train_loss = 1.56414811, grad/param norm = 9.1908e-02, time/batch = 0.0825s	
1128/3500 (epoch 16.114), train_loss = 1.55935589, grad/param norm = 8.2260e-02, time/batch = 0.0823s	
1129/3500 (epoch 16.129), train_loss = 1.55645143, grad/param norm = 7.0190e-02, time/batch = 0.0820s	
1130/3500 (epoch 16.143), train_loss = 1.56131882, grad/param norm = 6.8469e-02, time/batch = 0.0826s	
1131/3500 (epoch 16.157), train_loss = 1.54953281, grad/param norm = 8.9310e-02, time/batch = 0.0833s	
1132/3500 (epoch 16.171), train_loss = 1.54121886, grad/param norm = 1.0024e-01, time/batch = 0.0823s	
1133/3500 (epoch 16.186), train_loss = 1.55849731, grad/param norm = 9.5585e-02, time/batch = 0.0822s	
1134/3500 (epoch 16.200), train_loss = 1.55280057, grad/param norm = 9.4181e-02, time/batch = 0.0837s	
1135/3500 (epoch 16.214), train_loss = 1.53792966, grad/param norm = 1.1018e-01, time/batch = 0.0840s	
1136/3500 (epoch 16.229), train_loss = 1.54314869, grad/param norm = 1.2395e-01, time/batch = 0.0837s	
1137/3500 (epoch 16.243), train_loss = 1.55153421, grad/param norm = 1.2194e-01, time/batch = 0.0825s	
1138/3500 (epoch 16.257), train_loss = 1.56046457, grad/param norm = 1.0838e-01, time/batch = 0.0825s	
1139/3500 (epoch 16.271), train_loss = 1.56463333, grad/param norm = 9.5294e-02, time/batch = 0.0818s	
1140/3500 (epoch 16.286), train_loss = 1.55987253, grad/param norm = 9.6703e-02, time/batch = 0.0824s	
1141/3500 (epoch 16.300), train_loss = 1.57909325, grad/param norm = 1.0080e-01, time/batch = 0.0827s	
1142/3500 (epoch 16.314), train_loss = 1.54754732, grad/param norm = 1.1571e-01, time/batch = 0.0821s	
1143/3500 (epoch 16.329), train_loss = 1.57888724, grad/param norm = 1.1727e-01, time/batch = 0.0822s	
1144/3500 (epoch 16.343), train_loss = 1.56077147, grad/param norm = 1.0821e-01, time/batch = 0.0837s	
1145/3500 (epoch 16.357), train_loss = 1.57325675, grad/param norm = 1.0928e-01, time/batch = 0.0844s	
1146/3500 (epoch 16.371), train_loss = 1.56237372, grad/param norm = 1.0113e-01, time/batch = 0.0834s	
1147/3500 (epoch 16.386), train_loss = 1.54123177, grad/param norm = 9.7188e-02, time/batch = 0.0825s	
1148/3500 (epoch 16.400), train_loss = 1.53702499, grad/param norm = 8.9906e-02, time/batch = 0.0823s	
1149/3500 (epoch 16.414), train_loss = 1.55843348, grad/param norm = 8.6598e-02, time/batch = 0.0820s	
1150/3500 (epoch 16.429), train_loss = 1.51272741, grad/param norm = 8.3737e-02, time/batch = 0.0825s	
1151/3500 (epoch 16.443), train_loss = 1.54063422, grad/param norm = 8.6758e-02, time/batch = 0.0833s	
1152/3500 (epoch 16.457), train_loss = 1.54317515, grad/param norm = 9.3589e-02, time/batch = 0.0823s	
1153/3500 (epoch 16.471), train_loss = 1.54548412, grad/param norm = 1.1078e-01, time/batch = 0.0823s	
1154/3500 (epoch 16.486), train_loss = 1.56418815, grad/param norm = 1.0845e-01, time/batch = 0.0836s	
1155/3500 (epoch 16.500), train_loss = 1.55379396, grad/param norm = 1.0943e-01, time/batch = 0.0845s	
1156/3500 (epoch 16.514), train_loss = 1.57828084, grad/param norm = 1.1606e-01, time/batch = 0.0835s	
1157/3500 (epoch 16.529), train_loss = 1.56657354, grad/param norm = 1.1283e-01, time/batch = 0.0826s	
1158/3500 (epoch 16.543), train_loss = 1.55723208, grad/param norm = 1.0454e-01, time/batch = 0.0825s	
1159/3500 (epoch 16.557), train_loss = 1.51640785, grad/param norm = 9.3806e-02, time/batch = 0.0818s	
1160/3500 (epoch 16.571), train_loss = 1.52570474, grad/param norm = 9.6910e-02, time/batch = 0.0825s	
1161/3500 (epoch 16.586), train_loss = 1.54016517, grad/param norm = 1.2289e-01, time/batch = 0.0827s	
1162/3500 (epoch 16.600), train_loss = 1.53810977, grad/param norm = 1.1639e-01, time/batch = 0.0821s	
1163/3500 (epoch 16.614), train_loss = 1.54403573, grad/param norm = 9.2578e-02, time/batch = 0.0822s	
1164/3500 (epoch 16.629), train_loss = 1.52714641, grad/param norm = 8.6972e-02, time/batch = 0.0838s	
1165/3500 (epoch 16.643), train_loss = 1.54188362, grad/param norm = 9.3701e-02, time/batch = 0.0852s	
1166/3500 (epoch 16.657), train_loss = 1.53426826, grad/param norm = 9.8053e-02, time/batch = 0.0840s	
1167/3500 (epoch 16.671), train_loss = 1.52193352, grad/param norm = 1.0639e-01, time/batch = 0.0825s	
1168/3500 (epoch 16.686), train_loss = 1.54321867, grad/param norm = 1.1236e-01, time/batch = 0.0823s	
1169/3500 (epoch 16.700), train_loss = 1.54677751, grad/param norm = 1.0610e-01, time/batch = 0.0819s	
1170/3500 (epoch 16.714), train_loss = 1.54198132, grad/param norm = 1.3347e-01, time/batch = 0.0825s	
1171/3500 (epoch 16.729), train_loss = 1.54619462, grad/param norm = 1.0888e-01, time/batch = 0.0832s	
1172/3500 (epoch 16.743), train_loss = 1.53043785, grad/param norm = 9.5941e-02, time/batch = 0.0823s	
1173/3500 (epoch 16.757), train_loss = 1.55014979, grad/param norm = 9.7330e-02, time/batch = 0.0823s	
1174/3500 (epoch 16.771), train_loss = 1.54432326, grad/param norm = 9.7295e-02, time/batch = 0.0836s	
1175/3500 (epoch 16.786), train_loss = 1.54327825, grad/param norm = 9.6524e-02, time/batch = 0.0845s	
1176/3500 (epoch 16.800), train_loss = 1.53223503, grad/param norm = 9.8605e-02, time/batch = 0.0835s	
1177/3500 (epoch 16.814), train_loss = 1.54208905, grad/param norm = 1.0373e-01, time/batch = 0.0825s	
1178/3500 (epoch 16.829), train_loss = 1.52564228, grad/param norm = 1.1068e-01, time/batch = 0.0825s	
1179/3500 (epoch 16.843), train_loss = 1.56861563, grad/param norm = 1.2701e-01, time/batch = 0.0817s	
1180/3500 (epoch 16.857), train_loss = 1.56441245, grad/param norm = 1.1974e-01, time/batch = 0.0823s	
1181/3500 (epoch 16.871), train_loss = 1.56018388, grad/param norm = 1.1379e-01, time/batch = 0.0827s	
1182/3500 (epoch 16.886), train_loss = 1.54666925, grad/param norm = 1.0691e-01, time/batch = 0.0821s	
1183/3500 (epoch 16.900), train_loss = 1.56131847, grad/param norm = 9.5283e-02, time/batch = 0.0822s	
1184/3500 (epoch 16.914), train_loss = 1.55946299, grad/param norm = 9.7213e-02, time/batch = 0.0836s	
1185/3500 (epoch 16.929), train_loss = 1.53800976, grad/param norm = 9.9613e-02, time/batch = 0.0844s	
1186/3500 (epoch 16.943), train_loss = 1.55459648, grad/param norm = 9.9113e-02, time/batch = 0.0835s	
1187/3500 (epoch 16.957), train_loss = 1.56557074, grad/param norm = 1.0706e-01, time/batch = 0.0824s	
1188/3500 (epoch 16.971), train_loss = 1.55732729, grad/param norm = 1.0772e-01, time/batch = 0.0822s	
1189/3500 (epoch 16.986), train_loss = 1.55126856, grad/param norm = 9.2457e-02, time/batch = 0.0819s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
1190/3500 (epoch 17.000), train_loss = 1.53815939, grad/param norm = 1.0353e-01, time/batch = 0.0825s	
1191/3500 (epoch 17.014), train_loss = 1.71525647, grad/param norm = 1.3197e-01, time/batch = 0.0833s	
1192/3500 (epoch 17.029), train_loss = 1.54965659, grad/param norm = 1.2334e-01, time/batch = 0.0823s	
1193/3500 (epoch 17.043), train_loss = 1.53679453, grad/param norm = 1.0005e-01, time/batch = 0.0823s	
1194/3500 (epoch 17.057), train_loss = 1.53463022, grad/param norm = 9.8839e-02, time/batch = 0.0837s	
1195/3500 (epoch 17.071), train_loss = 1.52906039, grad/param norm = 9.6876e-02, time/batch = 0.0845s	
1196/3500 (epoch 17.086), train_loss = 1.53496182, grad/param norm = 9.3749e-02, time/batch = 0.0837s	
1197/3500 (epoch 17.100), train_loss = 1.54360193, grad/param norm = 9.2296e-02, time/batch = 0.0825s	
1198/3500 (epoch 17.114), train_loss = 1.53951315, grad/param norm = 8.0225e-02, time/batch = 0.0825s	
1199/3500 (epoch 17.129), train_loss = 1.53750624, grad/param norm = 7.8077e-02, time/batch = 0.0818s	
1200/3500 (epoch 17.143), train_loss = 1.54149993, grad/param norm = 7.8601e-02, time/batch = 0.0828s	
1201/3500 (epoch 17.157), train_loss = 1.53141649, grad/param norm = 9.7772e-02, time/batch = 0.0827s	
1202/3500 (epoch 17.171), train_loss = 1.52190547, grad/param norm = 9.5997e-02, time/batch = 0.0821s	
1203/3500 (epoch 17.186), train_loss = 1.53664094, grad/param norm = 8.6585e-02, time/batch = 0.0822s	
1204/3500 (epoch 17.200), train_loss = 1.53411971, grad/param norm = 1.0378e-01, time/batch = 0.0835s	
1205/3500 (epoch 17.214), train_loss = 1.52281226, grad/param norm = 1.3154e-01, time/batch = 0.0843s	
1206/3500 (epoch 17.229), train_loss = 1.52912403, grad/param norm = 1.5415e-01, time/batch = 0.0836s	
1207/3500 (epoch 17.243), train_loss = 1.53880208, grad/param norm = 1.3338e-01, time/batch = 0.0824s	
1208/3500 (epoch 17.257), train_loss = 1.54278189, grad/param norm = 1.1067e-01, time/batch = 0.0822s	
1209/3500 (epoch 17.271), train_loss = 1.54694883, grad/param norm = 1.0391e-01, time/batch = 0.0820s	
1210/3500 (epoch 17.286), train_loss = 1.54148596, grad/param norm = 9.8494e-02, time/batch = 0.0831s	
1211/3500 (epoch 17.300), train_loss = 1.55730224, grad/param norm = 8.3674e-02, time/batch = 0.0832s	
1212/3500 (epoch 17.314), train_loss = 1.52247076, grad/param norm = 7.4747e-02, time/batch = 0.0823s	
1213/3500 (epoch 17.329), train_loss = 1.54959517, grad/param norm = 7.2828e-02, time/batch = 0.0823s	
1214/3500 (epoch 17.343), train_loss = 1.53366001, grad/param norm = 7.2808e-02, time/batch = 0.0838s	
1215/3500 (epoch 17.357), train_loss = 1.54476885, grad/param norm = 7.8203e-02, time/batch = 0.0840s	
1216/3500 (epoch 17.371), train_loss = 1.53768507, grad/param norm = 8.3122e-02, time/batch = 0.0836s	
1217/3500 (epoch 17.386), train_loss = 1.52088759, grad/param norm = 9.2670e-02, time/batch = 0.0826s	
1218/3500 (epoch 17.400), train_loss = 1.51918073, grad/param norm = 9.0720e-02, time/batch = 0.0825s	
1219/3500 (epoch 17.414), train_loss = 1.53824566, grad/param norm = 8.2235e-02, time/batch = 0.0818s	
1220/3500 (epoch 17.429), train_loss = 1.49340758, grad/param norm = 7.7562e-02, time/batch = 0.0828s	
1221/3500 (epoch 17.443), train_loss = 1.52079416, grad/param norm = 8.0741e-02, time/batch = 0.0826s	
1222/3500 (epoch 17.457), train_loss = 1.52303417, grad/param norm = 8.3941e-02, time/batch = 0.0821s	
1223/3500 (epoch 17.471), train_loss = 1.52585592, grad/param norm = 1.0085e-01, time/batch = 0.0822s	
1224/3500 (epoch 17.486), train_loss = 1.54482547, grad/param norm = 1.0353e-01, time/batch = 0.0841s	
1225/3500 (epoch 17.500), train_loss = 1.53363024, grad/param norm = 1.0832e-01, time/batch = 0.0839s	
1226/3500 (epoch 17.514), train_loss = 1.55644474, grad/param norm = 1.2340e-01, time/batch = 0.0834s	
1227/3500 (epoch 17.529), train_loss = 1.54923770, grad/param norm = 1.1504e-01, time/batch = 0.0824s	
1228/3500 (epoch 17.543), train_loss = 1.54016862, grad/param norm = 1.0111e-01, time/batch = 0.0822s	
1229/3500 (epoch 17.557), train_loss = 1.49701104, grad/param norm = 8.2634e-02, time/batch = 0.0821s	
1230/3500 (epoch 17.571), train_loss = 1.50330719, grad/param norm = 6.9734e-02, time/batch = 0.0824s	
1231/3500 (epoch 17.586), train_loss = 1.51246505, grad/param norm = 7.5261e-02, time/batch = 0.0832s	
1232/3500 (epoch 17.600), train_loss = 1.51179082, grad/param norm = 7.5302e-02, time/batch = 0.0822s	
1233/3500 (epoch 17.614), train_loss = 1.51773912, grad/param norm = 8.1788e-02, time/batch = 0.0823s	
1234/3500 (epoch 17.629), train_loss = 1.50740437, grad/param norm = 8.9914e-02, time/batch = 0.0840s	
1235/3500 (epoch 17.643), train_loss = 1.52427635, grad/param norm = 9.7784e-02, time/batch = 0.0843s	
1236/3500 (epoch 17.657), train_loss = 1.51681941, grad/param norm = 1.0217e-01, time/batch = 0.0837s	
1237/3500 (epoch 17.671), train_loss = 1.50364986, grad/param norm = 1.1110e-01, time/batch = 0.0826s	
1238/3500 (epoch 17.686), train_loss = 1.52353768, grad/param norm = 1.0994e-01, time/batch = 0.0825s	
1239/3500 (epoch 17.700), train_loss = 1.52607719, grad/param norm = 9.8349e-02, time/batch = 0.0817s	
1240/3500 (epoch 17.714), train_loss = 1.52017050, grad/param norm = 1.0200e-01, time/batch = 0.0823s	
1241/3500 (epoch 17.729), train_loss = 1.52187722, grad/param norm = 9.2905e-02, time/batch = 0.0827s	
1242/3500 (epoch 17.743), train_loss = 1.50927990, grad/param norm = 9.4024e-02, time/batch = 0.0821s	
1243/3500 (epoch 17.757), train_loss = 1.53139202, grad/param norm = 1.0902e-01, time/batch = 0.0822s	
1244/3500 (epoch 17.771), train_loss = 1.53258471, grad/param norm = 1.2517e-01, time/batch = 0.0840s	
1245/3500 (epoch 17.786), train_loss = 1.53194170, grad/param norm = 1.2938e-01, time/batch = 0.0840s	
1246/3500 (epoch 17.800), train_loss = 1.52078358, grad/param norm = 1.1692e-01, time/batch = 0.0835s	
1247/3500 (epoch 17.814), train_loss = 1.52573880, grad/param norm = 1.0363e-01, time/batch = 0.0824s	
1248/3500 (epoch 17.829), train_loss = 1.50426620, grad/param norm = 9.5239e-02, time/batch = 0.0823s	
1249/3500 (epoch 17.843), train_loss = 1.54349846, grad/param norm = 8.3460e-02, time/batch = 0.0819s	
1250/3500 (epoch 17.857), train_loss = 1.54005139, grad/param norm = 8.8245e-02, time/batch = 0.0824s	
1251/3500 (epoch 17.871), train_loss = 1.54300010, grad/param norm = 1.0224e-01, time/batch = 0.0831s	
1252/3500 (epoch 17.886), train_loss = 1.53237531, grad/param norm = 1.2319e-01, time/batch = 0.0823s	
1253/3500 (epoch 17.900), train_loss = 1.55271938, grad/param norm = 1.3227e-01, time/batch = 0.0823s	
1254/3500 (epoch 17.914), train_loss = 1.54997522, grad/param norm = 1.2905e-01, time/batch = 0.0840s	
1255/3500 (epoch 17.929), train_loss = 1.52599035, grad/param norm = 1.1290e-01, time/batch = 0.0839s	
1256/3500 (epoch 17.943), train_loss = 1.53689955, grad/param norm = 9.5161e-02, time/batch = 0.0837s	
1257/3500 (epoch 17.957), train_loss = 1.54355176, grad/param norm = 8.8342e-02, time/batch = 0.0826s	
1258/3500 (epoch 17.971), train_loss = 1.53524525, grad/param norm = 9.4395e-02, time/batch = 0.0824s	
1259/3500 (epoch 17.986), train_loss = 1.52821085, grad/param norm = 8.7314e-02, time/batch = 0.0821s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
1260/3500 (epoch 18.000), train_loss = 1.51317531, grad/param norm = 7.9324e-02, time/batch = 0.0824s	
1261/3500 (epoch 18.014), train_loss = 1.68846692, grad/param norm = 6.9933e-02, time/batch = 0.0826s	
1262/3500 (epoch 18.029), train_loss = 1.51705048, grad/param norm = 6.0881e-02, time/batch = 0.0822s	
1263/3500 (epoch 18.043), train_loss = 1.51250038, grad/param norm = 6.2445e-02, time/batch = 0.0822s	
1264/3500 (epoch 18.057), train_loss = 1.51034636, grad/param norm = 7.2774e-02, time/batch = 0.0860s	
1265/3500 (epoch 18.071), train_loss = 1.50760189, grad/param norm = 7.5401e-02, time/batch = 0.0842s	
1266/3500 (epoch 18.086), train_loss = 1.51360172, grad/param norm = 7.3201e-02, time/batch = 0.0835s	
1267/3500 (epoch 18.100), train_loss = 1.52186159, grad/param norm = 7.5233e-02, time/batch = 0.0824s	
1268/3500 (epoch 18.114), train_loss = 1.52089815, grad/param norm = 7.5107e-02, time/batch = 0.0822s	
1269/3500 (epoch 18.129), train_loss = 1.51978813, grad/param norm = 8.0313e-02, time/batch = 0.0820s	
1270/3500 (epoch 18.143), train_loss = 1.52253847, grad/param norm = 7.9055e-02, time/batch = 0.0824s	
1271/3500 (epoch 18.157), train_loss = 1.51397755, grad/param norm = 9.5203e-02, time/batch = 0.0833s	
1272/3500 (epoch 18.171), train_loss = 1.50424573, grad/param norm = 9.0219e-02, time/batch = 0.0823s	
1273/3500 (epoch 18.186), train_loss = 1.51726842, grad/param norm = 7.1936e-02, time/batch = 0.0823s	
1274/3500 (epoch 18.200), train_loss = 1.51170223, grad/param norm = 7.4456e-02, time/batch = 0.0843s	
1275/3500 (epoch 18.214), train_loss = 1.49857285, grad/param norm = 8.8674e-02, time/batch = 0.0841s	
1276/3500 (epoch 18.229), train_loss = 1.50012135, grad/param norm = 1.0794e-01, time/batch = 0.0836s	
1277/3500 (epoch 18.243), train_loss = 1.51256605, grad/param norm = 1.0367e-01, time/batch = 0.0826s	
1278/3500 (epoch 18.257), train_loss = 1.52071896, grad/param norm = 9.8339e-02, time/batch = 0.0825s	
1279/3500 (epoch 18.271), train_loss = 1.52932064, grad/param norm = 1.0613e-01, time/batch = 0.0823s	
1280/3500 (epoch 18.286), train_loss = 1.52773540, grad/param norm = 1.1678e-01, time/batch = 0.0824s	
1281/3500 (epoch 18.300), train_loss = 1.54727688, grad/param norm = 1.2053e-01, time/batch = 0.0827s	
1282/3500 (epoch 18.314), train_loss = 1.51320789, grad/param norm = 1.1841e-01, time/batch = 0.0821s	
1283/3500 (epoch 18.329), train_loss = 1.53862017, grad/param norm = 1.1658e-01, time/batch = 0.0822s	
1284/3500 (epoch 18.343), train_loss = 1.52378839, grad/param norm = 1.1610e-01, time/batch = 0.0841s	
1285/3500 (epoch 18.357), train_loss = 1.53415206, grad/param norm = 1.1574e-01, time/batch = 0.0839s	
1286/3500 (epoch 18.371), train_loss = 1.52466724, grad/param norm = 1.0172e-01, time/batch = 0.0835s	
1287/3500 (epoch 18.386), train_loss = 1.50249581, grad/param norm = 8.9397e-02, time/batch = 0.0824s	
1288/3500 (epoch 18.400), train_loss = 1.49998369, grad/param norm = 7.7772e-02, time/batch = 0.0830s	
1289/3500 (epoch 18.414), train_loss = 1.51885546, grad/param norm = 7.6741e-02, time/batch = 0.0826s	
1290/3500 (epoch 18.429), train_loss = 1.47924770, grad/param norm = 8.7539e-02, time/batch = 0.0825s	
1291/3500 (epoch 18.443), train_loss = 1.50842229, grad/param norm = 9.2060e-02, time/batch = 0.0832s	
1292/3500 (epoch 18.457), train_loss = 1.51089050, grad/param norm = 9.6206e-02, time/batch = 0.0824s	
1293/3500 (epoch 18.471), train_loss = 1.51276166, grad/param norm = 1.0510e-01, time/batch = 0.0823s	
1294/3500 (epoch 18.486), train_loss = 1.53018101, grad/param norm = 9.6880e-02, time/batch = 0.0836s	
1295/3500 (epoch 18.500), train_loss = 1.51563838, grad/param norm = 9.1629e-02, time/batch = 0.0839s	
1296/3500 (epoch 18.514), train_loss = 1.53324816, grad/param norm = 8.3352e-02, time/batch = 0.0836s	
1297/3500 (epoch 18.529), train_loss = 1.52238736, grad/param norm = 7.0723e-02, time/batch = 0.0826s	
1298/3500 (epoch 18.543), train_loss = 1.51371652, grad/param norm = 6.4460e-02, time/batch = 0.0824s	
1299/3500 (epoch 18.557), train_loss = 1.47688510, grad/param norm = 6.4879e-02, time/batch = 0.0821s	
1300/3500 (epoch 18.571), train_loss = 1.48528291, grad/param norm = 6.8655e-02, time/batch = 0.0824s	
1301/3500 (epoch 18.586), train_loss = 1.49645967, grad/param norm = 8.3666e-02, time/batch = 0.0828s	
1302/3500 (epoch 18.600), train_loss = 1.49626094, grad/param norm = 9.2085e-02, time/batch = 0.0821s	
1303/3500 (epoch 18.614), train_loss = 1.50542812, grad/param norm = 8.6429e-02, time/batch = 0.0822s	
1304/3500 (epoch 18.629), train_loss = 1.48803041, grad/param norm = 7.9717e-02, time/batch = 0.0836s	
1305/3500 (epoch 18.643), train_loss = 1.50500499, grad/param norm = 8.0014e-02, time/batch = 0.0839s	
1306/3500 (epoch 18.657), train_loss = 1.49514737, grad/param norm = 8.5892e-02, time/batch = 0.0834s	
1307/3500 (epoch 18.671), train_loss = 1.48422142, grad/param norm = 8.6077e-02, time/batch = 0.0824s	
1308/3500 (epoch 18.686), train_loss = 1.50449523, grad/param norm = 9.6575e-02, time/batch = 0.0823s	
1309/3500 (epoch 18.700), train_loss = 1.51671137, grad/param norm = 1.1276e-01, time/batch = 0.0821s	
1310/3500 (epoch 18.714), train_loss = 1.50972463, grad/param norm = 1.2802e-01, time/batch = 0.0825s	
1311/3500 (epoch 18.729), train_loss = 1.51465344, grad/param norm = 1.2950e-01, time/batch = 0.0832s	
1312/3500 (epoch 18.743), train_loss = 1.49924378, grad/param norm = 1.1437e-01, time/batch = 0.0823s	
1313/3500 (epoch 18.757), train_loss = 1.51610682, grad/param norm = 9.7436e-02, time/batch = 0.0823s	
1314/3500 (epoch 18.771), train_loss = 1.50700098, grad/param norm = 8.8800e-02, time/batch = 0.0837s	
1315/3500 (epoch 18.786), train_loss = 1.50291170, grad/param norm = 7.7699e-02, time/batch = 0.0842s	
1316/3500 (epoch 18.800), train_loss = 1.49017307, grad/param norm = 8.0425e-02, time/batch = 0.0838s	
1317/3500 (epoch 18.814), train_loss = 1.50348199, grad/param norm = 8.9090e-02, time/batch = 0.0826s	
1318/3500 (epoch 18.829), train_loss = 1.48618623, grad/param norm = 9.8103e-02, time/batch = 0.0825s	
1319/3500 (epoch 18.843), train_loss = 1.53005237, grad/param norm = 9.5880e-02, time/batch = 0.0817s	
1320/3500 (epoch 18.857), train_loss = 1.52708177, grad/param norm = 1.1177e-01, time/batch = 0.0823s	
1321/3500 (epoch 18.871), train_loss = 1.53271239, grad/param norm = 1.5065e-01, time/batch = 0.0826s	
1322/3500 (epoch 18.886), train_loss = 1.51971687, grad/param norm = 1.3205e-01, time/batch = 0.0822s	
1323/3500 (epoch 18.900), train_loss = 1.52914141, grad/param norm = 9.5152e-02, time/batch = 0.0822s	
1324/3500 (epoch 18.914), train_loss = 1.52333769, grad/param norm = 8.2775e-02, time/batch = 0.0836s	
1325/3500 (epoch 18.929), train_loss = 1.50050671, grad/param norm = 7.4688e-02, time/batch = 0.0838s	
1326/3500 (epoch 18.943), train_loss = 1.51414648, grad/param norm = 6.8075e-02, time/batch = 0.0833s	
1327/3500 (epoch 18.957), train_loss = 1.52230158, grad/param norm = 7.6516e-02, time/batch = 0.0824s	
1328/3500 (epoch 18.971), train_loss = 1.51657300, grad/param norm = 8.4744e-02, time/batch = 0.0823s	
1329/3500 (epoch 18.986), train_loss = 1.50839655, grad/param norm = 7.0529e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1330/3500 (epoch 19.000), train_loss = 1.49397438, grad/param norm = 6.2602e-02, time/batch = 0.0824s	
1331/3500 (epoch 19.014), train_loss = 1.67376745, grad/param norm = 6.2601e-02, time/batch = 0.0832s	
1332/3500 (epoch 19.029), train_loss = 1.50103688, grad/param norm = 6.3995e-02, time/batch = 0.0824s	
1333/3500 (epoch 19.043), train_loss = 1.49771059, grad/param norm = 6.9384e-02, time/batch = 0.0827s	
1334/3500 (epoch 19.057), train_loss = 1.49400918, grad/param norm = 7.5997e-02, time/batch = 0.0836s	
1335/3500 (epoch 19.071), train_loss = 1.49139830, grad/param norm = 8.3414e-02, time/batch = 0.0840s	
1336/3500 (epoch 19.086), train_loss = 1.49783460, grad/param norm = 8.4936e-02, time/batch = 0.0837s	
1337/3500 (epoch 19.100), train_loss = 1.50670170, grad/param norm = 8.4932e-02, time/batch = 0.0825s	
1338/3500 (epoch 19.114), train_loss = 1.50587211, grad/param norm = 7.6951e-02, time/batch = 0.0825s	
1339/3500 (epoch 19.129), train_loss = 1.50359653, grad/param norm = 8.1368e-02, time/batch = 0.0817s	
1340/3500 (epoch 19.143), train_loss = 1.50764773, grad/param norm = 8.8143e-02, time/batch = 0.0824s	
1341/3500 (epoch 19.157), train_loss = 1.50227280, grad/param norm = 1.1776e-01, time/batch = 0.0827s	
1342/3500 (epoch 19.171), train_loss = 1.49533488, grad/param norm = 1.1540e-01, time/batch = 0.0822s	
1343/3500 (epoch 19.186), train_loss = 1.50540876, grad/param norm = 1.0272e-01, time/batch = 0.0825s	
1344/3500 (epoch 19.200), train_loss = 1.50376213, grad/param norm = 1.1593e-01, time/batch = 0.0836s	
1345/3500 (epoch 19.214), train_loss = 1.49083774, grad/param norm = 1.2536e-01, time/batch = 0.0839s	
1346/3500 (epoch 19.229), train_loss = 1.48860870, grad/param norm = 1.2204e-01, time/batch = 0.0834s	
1347/3500 (epoch 19.243), train_loss = 1.49410140, grad/param norm = 9.3538e-02, time/batch = 0.0824s	
1348/3500 (epoch 19.257), train_loss = 1.49957177, grad/param norm = 7.7636e-02, time/batch = 0.0827s	
1349/3500 (epoch 19.271), train_loss = 1.50750261, grad/param norm = 8.1394e-02, time/batch = 0.0820s	
1350/3500 (epoch 19.286), train_loss = 1.50333764, grad/param norm = 8.5870e-02, time/batch = 0.0824s	
1351/3500 (epoch 19.300), train_loss = 1.52411655, grad/param norm = 8.4811e-02, time/batch = 0.0832s	
1352/3500 (epoch 19.314), train_loss = 1.49076687, grad/param norm = 7.6901e-02, time/batch = 0.0823s	
1353/3500 (epoch 19.329), train_loss = 1.51510650, grad/param norm = 7.1158e-02, time/batch = 0.0828s	
1354/3500 (epoch 19.343), train_loss = 1.50072194, grad/param norm = 7.8527e-02, time/batch = 0.0836s	
1355/3500 (epoch 19.357), train_loss = 1.51360322, grad/param norm = 9.0104e-02, time/batch = 0.0841s	
1356/3500 (epoch 19.371), train_loss = 1.51110940, grad/param norm = 1.0083e-01, time/batch = 0.0837s	
1357/3500 (epoch 19.386), train_loss = 1.49404093, grad/param norm = 1.0493e-01, time/batch = 0.0826s	
1358/3500 (epoch 19.400), train_loss = 1.49008568, grad/param norm = 9.2465e-02, time/batch = 0.0833s	
1359/3500 (epoch 19.414), train_loss = 1.50364042, grad/param norm = 7.7418e-02, time/batch = 0.0818s	
1360/3500 (epoch 19.429), train_loss = 1.46168101, grad/param norm = 7.7223e-02, time/batch = 0.0824s	
1361/3500 (epoch 19.443), train_loss = 1.48963070, grad/param norm = 7.9846e-02, time/batch = 0.0827s	
1362/3500 (epoch 19.457), train_loss = 1.49086051, grad/param norm = 7.9680e-02, time/batch = 0.0821s	
1363/3500 (epoch 19.471), train_loss = 1.49334939, grad/param norm = 8.1348e-02, time/batch = 0.0836s	
1364/3500 (epoch 19.486), train_loss = 1.51227144, grad/param norm = 8.8664e-02, time/batch = 0.0837s	
1365/3500 (epoch 19.500), train_loss = 1.49711615, grad/param norm = 9.1530e-02, time/batch = 0.0840s	
1366/3500 (epoch 19.514), train_loss = 1.51531930, grad/param norm = 8.5593e-02, time/batch = 0.0835s	
1367/3500 (epoch 19.529), train_loss = 1.50831025, grad/param norm = 7.8745e-02, time/batch = 0.0824s	
1368/3500 (epoch 19.543), train_loss = 1.50138124, grad/param norm = 8.3150e-02, time/batch = 0.0828s	
1369/3500 (epoch 19.557), train_loss = 1.46588386, grad/param norm = 8.4956e-02, time/batch = 0.0820s	
1370/3500 (epoch 19.571), train_loss = 1.47142773, grad/param norm = 8.3299e-02, time/batch = 0.0825s	
1371/3500 (epoch 19.586), train_loss = 1.48260363, grad/param norm = 9.6020e-02, time/batch = 0.0832s	
1372/3500 (epoch 19.600), train_loss = 1.48233847, grad/param norm = 1.0371e-01, time/batch = 0.0824s	
1373/3500 (epoch 19.614), train_loss = 1.49284542, grad/param norm = 1.0182e-01, time/batch = 0.0823s	
1374/3500 (epoch 19.629), train_loss = 1.47704928, grad/param norm = 1.0836e-01, time/batch = 0.0836s	
1375/3500 (epoch 19.643), train_loss = 1.49551049, grad/param norm = 1.1727e-01, time/batch = 0.0843s	
1376/3500 (epoch 19.657), train_loss = 1.48390887, grad/param norm = 1.0512e-01, time/batch = 0.0836s	
1377/3500 (epoch 19.671), train_loss = 1.46598597, grad/param norm = 7.9236e-02, time/batch = 0.0825s	
1378/3500 (epoch 19.686), train_loss = 1.48574310, grad/param norm = 7.3125e-02, time/batch = 0.0826s	
1379/3500 (epoch 19.700), train_loss = 1.49154041, grad/param norm = 7.6221e-02, time/batch = 0.0818s	
1380/3500 (epoch 19.714), train_loss = 1.48538670, grad/param norm = 9.4449e-02, time/batch = 0.0824s	
1381/3500 (epoch 19.729), train_loss = 1.49192015, grad/param norm = 9.6978e-02, time/batch = 0.0827s	
1382/3500 (epoch 19.743), train_loss = 1.47763296, grad/param norm = 9.2736e-02, time/batch = 0.0821s	
1383/3500 (epoch 19.757), train_loss = 1.49876151, grad/param norm = 8.7782e-02, time/batch = 0.0822s	
1384/3500 (epoch 19.771), train_loss = 1.49148034, grad/param norm = 8.1627e-02, time/batch = 0.0834s	
1385/3500 (epoch 19.786), train_loss = 1.48670245, grad/param norm = 7.1998e-02, time/batch = 0.0840s	
1386/3500 (epoch 19.800), train_loss = 1.47207698, grad/param norm = 7.5718e-02, time/batch = 0.0834s	
1387/3500 (epoch 19.814), train_loss = 1.48451225, grad/param norm = 7.5930e-02, time/batch = 0.0824s	
1388/3500 (epoch 19.829), train_loss = 1.46818374, grad/param norm = 7.9403e-02, time/batch = 0.0823s	
1389/3500 (epoch 19.843), train_loss = 1.51033345, grad/param norm = 8.0654e-02, time/batch = 0.0820s	
1390/3500 (epoch 19.857), train_loss = 1.51119176, grad/param norm = 1.0144e-01, time/batch = 0.0825s	
1391/3500 (epoch 19.871), train_loss = 1.51525230, grad/param norm = 1.2547e-01, time/batch = 0.0832s	
1392/3500 (epoch 19.886), train_loss = 1.50328682, grad/param norm = 1.3170e-01, time/batch = 0.0823s	
1393/3500 (epoch 19.900), train_loss = 1.51647235, grad/param norm = 1.1375e-01, time/batch = 0.0824s	
1394/3500 (epoch 19.914), train_loss = 1.51134857, grad/param norm = 9.5268e-02, time/batch = 0.0835s	
1395/3500 (epoch 19.929), train_loss = 1.48685822, grad/param norm = 7.8479e-02, time/batch = 0.0840s	
1396/3500 (epoch 19.943), train_loss = 1.50019275, grad/param norm = 6.6116e-02, time/batch = 0.0836s	
1397/3500 (epoch 19.957), train_loss = 1.50666682, grad/param norm = 6.6697e-02, time/batch = 0.0825s	
1398/3500 (epoch 19.971), train_loss = 1.50163280, grad/param norm = 7.7904e-02, time/batch = 0.0825s	
1399/3500 (epoch 19.986), train_loss = 1.49534985, grad/param norm = 8.5217e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1400/3500 (epoch 20.000), train_loss = 1.48933703, grad/param norm = 1.0556e-01, time/batch = 0.0824s	
1401/3500 (epoch 20.014), train_loss = 1.67413157, grad/param norm = 1.1121e-01, time/batch = 0.0828s	
1402/3500 (epoch 20.029), train_loss = 1.49804913, grad/param norm = 1.0719e-01, time/batch = 0.0822s	
1403/3500 (epoch 20.043), train_loss = 1.48910753, grad/param norm = 9.8880e-02, time/batch = 0.0822s	
1404/3500 (epoch 20.057), train_loss = 1.48549796, grad/param norm = 1.3582e-01, time/batch = 0.0837s	
1405/3500 (epoch 20.071), train_loss = 1.48336709, grad/param norm = 9.8222e-02, time/batch = 0.0839s	
1406/3500 (epoch 20.086), train_loss = 1.48477445, grad/param norm = 7.4938e-02, time/batch = 0.0834s	
1407/3500 (epoch 20.100), train_loss = 1.49213768, grad/param norm = 8.6834e-02, time/batch = 0.0824s	
1408/3500 (epoch 20.114), train_loss = 1.49309072, grad/param norm = 8.4273e-02, time/batch = 0.0824s	
1409/3500 (epoch 20.129), train_loss = 1.48665776, grad/param norm = 6.9285e-02, time/batch = 0.0819s	
1410/3500 (epoch 20.143), train_loss = 1.48896143, grad/param norm = 6.6137e-02, time/batch = 0.0825s	
1411/3500 (epoch 20.157), train_loss = 1.47990051, grad/param norm = 8.0634e-02, time/batch = 0.0833s	
1412/3500 (epoch 20.171), train_loss = 1.47226293, grad/param norm = 7.7673e-02, time/batch = 0.0827s	
1413/3500 (epoch 20.186), train_loss = 1.48329877, grad/param norm = 6.7896e-02, time/batch = 0.0824s	
1414/3500 (epoch 20.200), train_loss = 1.47937187, grad/param norm = 6.5022e-02, time/batch = 0.0838s	
1415/3500 (epoch 20.214), train_loss = 1.46657180, grad/param norm = 6.9932e-02, time/batch = 0.0842s	
1416/3500 (epoch 20.229), train_loss = 1.46398355, grad/param norm = 7.1453e-02, time/batch = 0.0836s	
1417/3500 (epoch 20.243), train_loss = 1.47424605, grad/param norm = 7.0284e-02, time/batch = 0.0825s	
1418/3500 (epoch 20.257), train_loss = 1.48471817, grad/param norm = 7.2662e-02, time/batch = 0.0825s	
1419/3500 (epoch 20.271), train_loss = 1.49302032, grad/param norm = 7.5765e-02, time/batch = 0.0818s	
1420/3500 (epoch 20.286), train_loss = 1.48852247, grad/param norm = 8.1140e-02, time/batch = 0.0823s	
1421/3500 (epoch 20.300), train_loss = 1.51104744, grad/param norm = 8.4964e-02, time/batch = 0.0828s	
1422/3500 (epoch 20.314), train_loss = 1.47829868, grad/param norm = 7.6831e-02, time/batch = 0.0826s	
1423/3500 (epoch 20.329), train_loss = 1.50090825, grad/param norm = 6.7649e-02, time/batch = 0.0822s	
1424/3500 (epoch 20.343), train_loss = 1.48469649, grad/param norm = 6.2156e-02, time/batch = 0.0834s	
1425/3500 (epoch 20.357), train_loss = 1.49288811, grad/param norm = 5.8519e-02, time/batch = 0.0839s	
1426/3500 (epoch 20.371), train_loss = 1.48790359, grad/param norm = 6.5590e-02, time/batch = 0.0835s	
1427/3500 (epoch 20.386), train_loss = 1.47134611, grad/param norm = 7.5710e-02, time/batch = 0.0829s	
1428/3500 (epoch 20.400), train_loss = 1.47093603, grad/param norm = 7.9396e-02, time/batch = 0.0822s	
1429/3500 (epoch 20.414), train_loss = 1.49100639, grad/param norm = 9.3618e-02, time/batch = 0.0820s	
1430/3500 (epoch 20.429), train_loss = 1.45485167, grad/param norm = 1.1439e-01, time/batch = 0.0824s	
1431/3500 (epoch 20.443), train_loss = 1.48697135, grad/param norm = 1.2727e-01, time/batch = 0.0832s	
1432/3500 (epoch 20.457), train_loss = 1.48785363, grad/param norm = 1.3154e-01, time/batch = 0.0828s	
1433/3500 (epoch 20.471), train_loss = 1.48790427, grad/param norm = 1.1261e-01, time/batch = 0.0823s	
1434/3500 (epoch 20.486), train_loss = 1.49957636, grad/param norm = 1.0171e-01, time/batch = 0.0837s	
1435/3500 (epoch 20.500), train_loss = 1.48276019, grad/param norm = 9.5697e-02, time/batch = 0.0841s	
1436/3500 (epoch 20.514), train_loss = 1.49946820, grad/param norm = 7.8241e-02, time/batch = 0.0838s	
1437/3500 (epoch 20.529), train_loss = 1.49271115, grad/param norm = 6.8183e-02, time/batch = 0.0832s	
1438/3500 (epoch 20.543), train_loss = 1.48420742, grad/param norm = 6.5421e-02, time/batch = 0.0825s	
1439/3500 (epoch 20.557), train_loss = 1.44901931, grad/param norm = 7.1981e-02, time/batch = 0.0818s	
1440/3500 (epoch 20.571), train_loss = 1.45796172, grad/param norm = 9.0002e-02, time/batch = 0.0824s	
1441/3500 (epoch 20.586), train_loss = 1.47252571, grad/param norm = 1.0846e-01, time/batch = 0.0827s	
1442/3500 (epoch 20.600), train_loss = 1.46802040, grad/param norm = 9.1736e-02, time/batch = 0.0825s	
1443/3500 (epoch 20.614), train_loss = 1.47595120, grad/param norm = 7.6026e-02, time/batch = 0.0822s	
1444/3500 (epoch 20.629), train_loss = 1.45813203, grad/param norm = 8.7635e-02, time/batch = 0.0835s	
1445/3500 (epoch 20.643), train_loss = 1.47647214, grad/param norm = 9.0792e-02, time/batch = 0.0840s	
1446/3500 (epoch 20.657), train_loss = 1.46532312, grad/param norm = 7.1543e-02, time/batch = 0.0835s	
1447/3500 (epoch 20.671), train_loss = 1.45180795, grad/param norm = 8.1166e-02, time/batch = 0.0829s	
1448/3500 (epoch 20.686), train_loss = 1.47559024, grad/param norm = 9.2731e-02, time/batch = 0.0823s	
1449/3500 (epoch 20.700), train_loss = 1.48151407, grad/param norm = 9.4747e-02, time/batch = 0.0820s	
1450/3500 (epoch 20.714), train_loss = 1.47496471, grad/param norm = 1.0556e-01, time/batch = 0.0825s	
1451/3500 (epoch 20.729), train_loss = 1.47759617, grad/param norm = 8.8999e-02, time/batch = 0.0832s	
1452/3500 (epoch 20.743), train_loss = 1.46123793, grad/param norm = 7.7650e-02, time/batch = 0.0824s	
1453/3500 (epoch 20.757), train_loss = 1.48185359, grad/param norm = 7.6928e-02, time/batch = 0.0824s	
1454/3500 (epoch 20.771), train_loss = 1.47730247, grad/param norm = 7.5628e-02, time/batch = 0.0835s	
1455/3500 (epoch 20.786), train_loss = 1.47178721, grad/param norm = 7.2050e-02, time/batch = 0.0841s	
1456/3500 (epoch 20.800), train_loss = 1.45842551, grad/param norm = 6.8600e-02, time/batch = 0.0836s	
1457/3500 (epoch 20.814), train_loss = 1.47065613, grad/param norm = 6.9707e-02, time/batch = 0.0827s	
1458/3500 (epoch 20.829), train_loss = 1.45558578, grad/param norm = 8.4424e-02, time/batch = 0.0825s	
1459/3500 (epoch 20.843), train_loss = 1.50057522, grad/param norm = 9.3968e-02, time/batch = 0.0818s	
1460/3500 (epoch 20.857), train_loss = 1.49844991, grad/param norm = 9.5467e-02, time/batch = 0.0824s	
1461/3500 (epoch 20.871), train_loss = 1.49306163, grad/param norm = 9.1595e-02, time/batch = 0.0828s	
1462/3500 (epoch 20.886), train_loss = 1.48270071, grad/param norm = 9.0929e-02, time/batch = 0.0834s	
1463/3500 (epoch 20.900), train_loss = 1.49317727, grad/param norm = 9.0575e-02, time/batch = 0.0822s	
1464/3500 (epoch 20.914), train_loss = 1.49630586, grad/param norm = 9.7264e-02, time/batch = 0.0835s	
1465/3500 (epoch 20.929), train_loss = 1.47544811, grad/param norm = 1.0729e-01, time/batch = 0.0840s	
1466/3500 (epoch 20.943), train_loss = 1.49311364, grad/param norm = 1.0280e-01, time/batch = 0.0836s	
1467/3500 (epoch 20.957), train_loss = 1.49786762, grad/param norm = 9.7883e-02, time/batch = 0.0824s	
1468/3500 (epoch 20.971), train_loss = 1.49094343, grad/param norm = 9.8212e-02, time/batch = 0.0823s	
1469/3500 (epoch 20.986), train_loss = 1.48257211, grad/param norm = 8.9305e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1470/3500 (epoch 21.000), train_loss = 1.47368303, grad/param norm = 9.1481e-02, time/batch = 0.0824s	
1471/3500 (epoch 21.014), train_loss = 1.65826439, grad/param norm = 1.0103e-01, time/batch = 0.0832s	
1472/3500 (epoch 21.029), train_loss = 1.48037145, grad/param norm = 9.1248e-02, time/batch = 0.0823s	
1473/3500 (epoch 21.043), train_loss = 1.47177449, grad/param norm = 7.4728e-02, time/batch = 0.0823s	
1474/3500 (epoch 21.057), train_loss = 1.46476538, grad/param norm = 7.2011e-02, time/batch = 0.0836s	
1475/3500 (epoch 21.071), train_loss = 1.46142645, grad/param norm = 7.1385e-02, time/batch = 0.0841s	
1476/3500 (epoch 21.086), train_loss = 1.46708228, grad/param norm = 6.9086e-02, time/batch = 0.0840s	
1477/3500 (epoch 21.100), train_loss = 1.47667585, grad/param norm = 7.1817e-02, time/batch = 0.0827s	
1478/3500 (epoch 21.114), train_loss = 1.47774806, grad/param norm = 7.1029e-02, time/batch = 0.0824s	
1479/3500 (epoch 21.129), train_loss = 1.47351234, grad/param norm = 7.1181e-02, time/batch = 0.0818s	
1480/3500 (epoch 21.143), train_loss = 1.47473132, grad/param norm = 6.5740e-02, time/batch = 0.0824s	
1481/3500 (epoch 21.157), train_loss = 1.46640192, grad/param norm = 7.3075e-02, time/batch = 0.0828s	
1482/3500 (epoch 21.171), train_loss = 1.45860016, grad/param norm = 6.9356e-02, time/batch = 0.0821s	
1483/3500 (epoch 21.186), train_loss = 1.46773406, grad/param norm = 5.7740e-02, time/batch = 0.0822s	
1484/3500 (epoch 21.200), train_loss = 1.46609632, grad/param norm = 6.2223e-02, time/batch = 0.0836s	
1485/3500 (epoch 21.214), train_loss = 1.45496307, grad/param norm = 7.7870e-02, time/batch = 0.0840s	
1486/3500 (epoch 21.229), train_loss = 1.45478431, grad/param norm = 9.9240e-02, time/batch = 0.0840s	
1487/3500 (epoch 21.243), train_loss = 1.46964650, grad/param norm = 9.4612e-02, time/batch = 0.0825s	
1488/3500 (epoch 21.257), train_loss = 1.47922284, grad/param norm = 9.5381e-02, time/batch = 0.0823s	
1489/3500 (epoch 21.271), train_loss = 1.48658814, grad/param norm = 1.0353e-01, time/batch = 0.0820s	
1490/3500 (epoch 21.286), train_loss = 1.48092475, grad/param norm = 9.6243e-02, time/batch = 0.0824s	
1491/3500 (epoch 21.300), train_loss = 1.49752678, grad/param norm = 8.4654e-02, time/batch = 0.0837s	
1492/3500 (epoch 21.314), train_loss = 1.46346026, grad/param norm = 6.9667e-02, time/batch = 0.0823s	
1493/3500 (epoch 21.329), train_loss = 1.48629521, grad/param norm = 6.1794e-02, time/batch = 0.0824s	
1494/3500 (epoch 21.343), train_loss = 1.47155183, grad/param norm = 6.1185e-02, time/batch = 0.0838s	
1495/3500 (epoch 21.357), train_loss = 1.47986743, grad/param norm = 6.4753e-02, time/batch = 0.0849s	
1496/3500 (epoch 21.371), train_loss = 1.47530358, grad/param norm = 7.3844e-02, time/batch = 0.0841s	
1497/3500 (epoch 21.386), train_loss = 1.45979098, grad/param norm = 8.6805e-02, time/batch = 0.0826s	
1498/3500 (epoch 21.400), train_loss = 1.46086022, grad/param norm = 8.6935e-02, time/batch = 0.0825s	
1499/3500 (epoch 21.414), train_loss = 1.47531194, grad/param norm = 8.6656e-02, time/batch = 0.0818s	
1500/3500 (epoch 21.429), train_loss = 1.43845632, grad/param norm = 8.9049e-02, time/batch = 0.0824s	
1501/3500 (epoch 21.443), train_loss = 1.46623734, grad/param norm = 9.5151e-02, time/batch = 0.0832s	
1502/3500 (epoch 21.457), train_loss = 1.46879535, grad/param norm = 9.8918e-02, time/batch = 0.0821s	
1503/3500 (epoch 21.471), train_loss = 1.47053144, grad/param norm = 9.9903e-02, time/batch = 0.0822s	
1504/3500 (epoch 21.486), train_loss = 1.48959544, grad/param norm = 1.0527e-01, time/batch = 0.0835s	
1505/3500 (epoch 21.500), train_loss = 1.47272632, grad/param norm = 1.0592e-01, time/batch = 0.0840s	
1506/3500 (epoch 21.514), train_loss = 1.48878332, grad/param norm = 8.8663e-02, time/batch = 0.0844s	
1507/3500 (epoch 21.529), train_loss = 1.48136516, grad/param norm = 7.7701e-02, time/batch = 0.0825s	
1508/3500 (epoch 21.543), train_loss = 1.47517382, grad/param norm = 7.7116e-02, time/batch = 0.0822s	
1509/3500 (epoch 21.557), train_loss = 1.43668167, grad/param norm = 6.9769e-02, time/batch = 0.0820s	
1510/3500 (epoch 21.571), train_loss = 1.44121179, grad/param norm = 6.1619e-02, time/batch = 0.0825s	
1511/3500 (epoch 21.586), train_loss = 1.45070431, grad/param norm = 6.9077e-02, time/batch = 0.0837s	
1512/3500 (epoch 21.600), train_loss = 1.44867114, grad/param norm = 6.7942e-02, time/batch = 0.0823s	
1513/3500 (epoch 21.614), train_loss = 1.45803952, grad/param norm = 6.4355e-02, time/batch = 0.0824s	
1514/3500 (epoch 21.629), train_loss = 1.44076700, grad/param norm = 6.3857e-02, time/batch = 0.0837s	
1515/3500 (epoch 21.643), train_loss = 1.45936200, grad/param norm = 6.3682e-02, time/batch = 0.0842s	
1516/3500 (epoch 21.657), train_loss = 1.44932568, grad/param norm = 6.3110e-02, time/batch = 0.0842s	
1517/3500 (epoch 21.671), train_loss = 1.43628138, grad/param norm = 7.6864e-02, time/batch = 0.0826s	
1518/3500 (epoch 21.686), train_loss = 1.46123659, grad/param norm = 8.5762e-02, time/batch = 0.0825s	
1519/3500 (epoch 21.700), train_loss = 1.46856078, grad/param norm = 8.7180e-02, time/batch = 0.0818s	
1520/3500 (epoch 21.714), train_loss = 1.46104330, grad/param norm = 9.1130e-02, time/batch = 0.0824s	
1521/3500 (epoch 21.729), train_loss = 1.46434940, grad/param norm = 9.0295e-02, time/batch = 0.0828s	
1522/3500 (epoch 21.743), train_loss = 1.45200819, grad/param norm = 9.1661e-02, time/batch = 0.0821s	
1523/3500 (epoch 21.757), train_loss = 1.47342774, grad/param norm = 9.5846e-02, time/batch = 0.0822s	
1524/3500 (epoch 21.771), train_loss = 1.46917121, grad/param norm = 9.3949e-02, time/batch = 0.0836s	
1525/3500 (epoch 21.786), train_loss = 1.46318021, grad/param norm = 9.5896e-02, time/batch = 0.0840s	
1526/3500 (epoch 21.800), train_loss = 1.45263255, grad/param norm = 9.8797e-02, time/batch = 0.0840s	
1527/3500 (epoch 21.814), train_loss = 1.46287168, grad/param norm = 9.4969e-02, time/batch = 0.0825s	
1528/3500 (epoch 21.829), train_loss = 1.44658927, grad/param norm = 9.5570e-02, time/batch = 0.0823s	
1529/3500 (epoch 21.843), train_loss = 1.48811606, grad/param norm = 9.6045e-02, time/batch = 0.0820s	
1530/3500 (epoch 21.857), train_loss = 1.48327393, grad/param norm = 8.6600e-02, time/batch = 0.0825s	
1531/3500 (epoch 21.871), train_loss = 1.47771089, grad/param norm = 8.8141e-02, time/batch = 0.0833s	
1532/3500 (epoch 21.886), train_loss = 1.46874446, grad/param norm = 8.6677e-02, time/batch = 0.0824s	
1533/3500 (epoch 21.900), train_loss = 1.48088707, grad/param norm = 7.7398e-02, time/batch = 0.0823s	
1534/3500 (epoch 21.914), train_loss = 1.48211361, grad/param norm = 8.0812e-02, time/batch = 0.0838s	
1535/3500 (epoch 21.929), train_loss = 1.46167157, grad/param norm = 8.4024e-02, time/batch = 0.0841s	
1536/3500 (epoch 21.943), train_loss = 1.47801922, grad/param norm = 8.3724e-02, time/batch = 0.0837s	
1537/3500 (epoch 21.957), train_loss = 1.48575936, grad/param norm = 8.7496e-02, time/batch = 0.0826s	
1538/3500 (epoch 21.971), train_loss = 1.47875239, grad/param norm = 8.8772e-02, time/batch = 0.0824s	
1539/3500 (epoch 21.986), train_loss = 1.46996303, grad/param norm = 8.0955e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1540/3500 (epoch 22.000), train_loss = 1.46041971, grad/param norm = 8.9344e-02, time/batch = 0.0824s	
1541/3500 (epoch 22.014), train_loss = 1.64685925, grad/param norm = 8.3459e-02, time/batch = 0.0827s	
1542/3500 (epoch 22.029), train_loss = 1.46518129, grad/param norm = 7.0717e-02, time/batch = 0.0821s	
1543/3500 (epoch 22.043), train_loss = 1.45826581, grad/param norm = 6.6828e-02, time/batch = 0.0822s	
1544/3500 (epoch 22.057), train_loss = 1.45366092, grad/param norm = 9.0193e-02, time/batch = 0.0837s	
1545/3500 (epoch 22.071), train_loss = 1.45174634, grad/param norm = 7.6455e-02, time/batch = 0.0844s	
1546/3500 (epoch 22.086), train_loss = 1.45471472, grad/param norm = 5.9502e-02, time/batch = 0.0835s	
1547/3500 (epoch 22.100), train_loss = 1.46299284, grad/param norm = 6.7571e-02, time/batch = 0.0824s	
1548/3500 (epoch 22.114), train_loss = 1.46548429, grad/param norm = 6.9699e-02, time/batch = 0.0823s	
1549/3500 (epoch 22.129), train_loss = 1.45906577, grad/param norm = 6.2964e-02, time/batch = 0.0820s	
1550/3500 (epoch 22.143), train_loss = 1.46087810, grad/param norm = 5.7116e-02, time/batch = 0.0825s	
1551/3500 (epoch 22.157), train_loss = 1.45338084, grad/param norm = 7.0666e-02, time/batch = 0.0832s	
1552/3500 (epoch 22.171), train_loss = 1.44747597, grad/param norm = 7.0915e-02, time/batch = 0.0823s	
1553/3500 (epoch 22.186), train_loss = 1.45700128, grad/param norm = 6.8585e-02, time/batch = 0.0823s	
1554/3500 (epoch 22.200), train_loss = 1.45497346, grad/param norm = 6.7742e-02, time/batch = 0.0837s	
1555/3500 (epoch 22.214), train_loss = 1.44282575, grad/param norm = 6.3920e-02, time/batch = 0.0851s	
1556/3500 (epoch 22.229), train_loss = 1.43763625, grad/param norm = 6.0177e-02, time/batch = 0.0839s	
1557/3500 (epoch 22.243), train_loss = 1.44910138, grad/param norm = 6.6499e-02, time/batch = 0.0826s	
1558/3500 (epoch 22.257), train_loss = 1.46140035, grad/param norm = 8.3103e-02, time/batch = 0.0825s	
1559/3500 (epoch 22.271), train_loss = 1.47227453, grad/param norm = 1.0551e-01, time/batch = 0.0818s	
1560/3500 (epoch 22.286), train_loss = 1.46896653, grad/param norm = 1.0083e-01, time/batch = 0.0831s	
1561/3500 (epoch 22.300), train_loss = 1.49233522, grad/param norm = 1.0114e-01, time/batch = 0.0828s	
1562/3500 (epoch 22.314), train_loss = 1.45728118, grad/param norm = 9.9203e-02, time/batch = 0.0822s	
1563/3500 (epoch 22.329), train_loss = 1.48236915, grad/param norm = 1.0179e-01, time/batch = 0.0822s	
1564/3500 (epoch 22.343), train_loss = 1.46604093, grad/param norm = 1.0042e-01, time/batch = 0.0837s	
1565/3500 (epoch 22.357), train_loss = 1.47491098, grad/param norm = 1.0023e-01, time/batch = 0.0844s	
1566/3500 (epoch 22.371), train_loss = 1.46900521, grad/param norm = 9.6078e-02, time/batch = 0.0837s	
1567/3500 (epoch 22.386), train_loss = 1.44744132, grad/param norm = 8.0167e-02, time/batch = 0.0824s	
1568/3500 (epoch 22.400), train_loss = 1.44517140, grad/param norm = 7.0416e-02, time/batch = 0.0823s	
1569/3500 (epoch 22.414), train_loss = 1.46189817, grad/param norm = 7.6097e-02, time/batch = 0.0820s	
1570/3500 (epoch 22.429), train_loss = 1.42482032, grad/param norm = 8.0921e-02, time/batch = 0.0824s	
1571/3500 (epoch 22.443), train_loss = 1.45364407, grad/param norm = 7.8732e-02, time/batch = 0.0831s	
1572/3500 (epoch 22.457), train_loss = 1.45329877, grad/param norm = 7.9091e-02, time/batch = 0.0824s	
1573/3500 (epoch 22.471), train_loss = 1.45699958, grad/param norm = 7.8218e-02, time/batch = 0.0823s	
1574/3500 (epoch 22.486), train_loss = 1.47362762, grad/param norm = 7.7657e-02, time/batch = 0.0839s	
1575/3500 (epoch 22.500), train_loss = 1.45433701, grad/param norm = 7.6194e-02, time/batch = 0.0845s	
1576/3500 (epoch 22.514), train_loss = 1.47239394, grad/param norm = 6.7811e-02, time/batch = 0.0837s	
1577/3500 (epoch 22.529), train_loss = 1.46707837, grad/param norm = 6.5954e-02, time/batch = 0.0825s	
1578/3500 (epoch 22.543), train_loss = 1.45919436, grad/param norm = 6.3982e-02, time/batch = 0.0825s	
1579/3500 (epoch 22.557), train_loss = 1.42305021, grad/param norm = 6.4629e-02, time/batch = 0.0818s	
1580/3500 (epoch 22.571), train_loss = 1.43000732, grad/param norm = 5.7170e-02, time/batch = 0.0824s	
1581/3500 (epoch 22.586), train_loss = 1.44049843, grad/param norm = 7.2534e-02, time/batch = 0.0827s	
1582/3500 (epoch 22.600), train_loss = 1.44056413, grad/param norm = 8.5879e-02, time/batch = 0.0822s	
1583/3500 (epoch 22.614), train_loss = 1.45023392, grad/param norm = 8.0566e-02, time/batch = 0.0822s	
1584/3500 (epoch 22.629), train_loss = 1.43099527, grad/param norm = 7.8569e-02, time/batch = 0.0837s	
1585/3500 (epoch 22.643), train_loss = 1.44929343, grad/param norm = 6.9698e-02, time/batch = 0.0843s	
1586/3500 (epoch 22.657), train_loss = 1.43872302, grad/param norm = 6.3853e-02, time/batch = 0.0833s	
1587/3500 (epoch 22.671), train_loss = 1.42431536, grad/param norm = 7.2811e-02, time/batch = 0.0825s	
1588/3500 (epoch 22.686), train_loss = 1.45000796, grad/param norm = 8.0039e-02, time/batch = 0.0823s	
1589/3500 (epoch 22.700), train_loss = 1.45652549, grad/param norm = 8.7802e-02, time/batch = 0.0821s	
1590/3500 (epoch 22.714), train_loss = 1.45014812, grad/param norm = 9.3155e-02, time/batch = 0.0829s	
1591/3500 (epoch 22.729), train_loss = 1.45226834, grad/param norm = 9.3594e-02, time/batch = 0.0832s	
1592/3500 (epoch 22.743), train_loss = 1.44215592, grad/param norm = 9.7242e-02, time/batch = 0.0823s	
1593/3500 (epoch 22.757), train_loss = 1.46240198, grad/param norm = 9.8806e-02, time/batch = 0.0823s	
1594/3500 (epoch 22.771), train_loss = 1.45648767, grad/param norm = 8.8676e-02, time/batch = 0.0839s	
1595/3500 (epoch 22.786), train_loss = 1.44868821, grad/param norm = 7.7111e-02, time/batch = 0.0846s	
1596/3500 (epoch 22.800), train_loss = 1.43473279, grad/param norm = 7.6711e-02, time/batch = 0.0837s	
1597/3500 (epoch 22.814), train_loss = 1.44867294, grad/param norm = 8.0736e-02, time/batch = 0.0825s	
1598/3500 (epoch 22.829), train_loss = 1.43142240, grad/param norm = 8.1006e-02, time/batch = 0.0824s	
1599/3500 (epoch 22.843), train_loss = 1.47622774, grad/param norm = 9.6754e-02, time/batch = 0.0819s	
1600/3500 (epoch 22.857), train_loss = 1.47500653, grad/param norm = 1.0011e-01, time/batch = 0.0829s	
1601/3500 (epoch 22.871), train_loss = 1.46759676, grad/param norm = 9.5702e-02, time/batch = 0.0827s	
1602/3500 (epoch 22.886), train_loss = 1.45796816, grad/param norm = 7.8923e-02, time/batch = 0.0821s	
1603/3500 (epoch 22.900), train_loss = 1.46817078, grad/param norm = 7.2614e-02, time/batch = 0.0822s	
1604/3500 (epoch 22.914), train_loss = 1.47131869, grad/param norm = 8.5148e-02, time/batch = 0.0835s	
1605/3500 (epoch 22.929), train_loss = 1.44934808, grad/param norm = 8.0089e-02, time/batch = 0.0849s	
1606/3500 (epoch 22.943), train_loss = 1.46458992, grad/param norm = 7.3568e-02, time/batch = 0.0835s	
1607/3500 (epoch 22.957), train_loss = 1.47164551, grad/param norm = 7.3288e-02, time/batch = 0.0824s	
1608/3500 (epoch 22.971), train_loss = 1.46548890, grad/param norm = 7.8674e-02, time/batch = 0.0823s	
1609/3500 (epoch 22.986), train_loss = 1.45977601, grad/param norm = 9.4188e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1610/3500 (epoch 23.000), train_loss = 1.45431035, grad/param norm = 1.0598e-01, time/batch = 0.0829s	
1611/3500 (epoch 23.014), train_loss = 1.64028138, grad/param norm = 9.0697e-02, time/batch = 0.0832s	
1612/3500 (epoch 23.029), train_loss = 1.45571383, grad/param norm = 7.5821e-02, time/batch = 0.0824s	
1613/3500 (epoch 23.043), train_loss = 1.44809239, grad/param norm = 6.9196e-02, time/batch = 0.0824s	
1614/3500 (epoch 23.057), train_loss = 1.44096228, grad/param norm = 8.0329e-02, time/batch = 0.0839s	
1615/3500 (epoch 23.071), train_loss = 1.43762892, grad/param norm = 7.0709e-02, time/batch = 0.0841s	
1616/3500 (epoch 23.086), train_loss = 1.44246586, grad/param norm = 5.9606e-02, time/batch = 0.0836s	
1617/3500 (epoch 23.100), train_loss = 1.45143094, grad/param norm = 6.5846e-02, time/batch = 0.0826s	
1618/3500 (epoch 23.114), train_loss = 1.45353378, grad/param norm = 6.0979e-02, time/batch = 0.0825s	
1619/3500 (epoch 23.129), train_loss = 1.44681787, grad/param norm = 5.5505e-02, time/batch = 0.0818s	
1620/3500 (epoch 23.143), train_loss = 1.44905974, grad/param norm = 5.7389e-02, time/batch = 0.0824s	
1621/3500 (epoch 23.157), train_loss = 1.44249074, grad/param norm = 7.3723e-02, time/batch = 0.0828s	
1622/3500 (epoch 23.171), train_loss = 1.43792984, grad/param norm = 7.8001e-02, time/batch = 0.0821s	
1623/3500 (epoch 23.186), train_loss = 1.44673993, grad/param norm = 8.1274e-02, time/batch = 0.0822s	
1624/3500 (epoch 23.200), train_loss = 1.44928897, grad/param norm = 9.5331e-02, time/batch = 0.0839s	
1625/3500 (epoch 23.214), train_loss = 1.44120626, grad/param norm = 1.1099e-01, time/batch = 0.0840s	
1626/3500 (epoch 23.229), train_loss = 1.43630414, grad/param norm = 1.0515e-01, time/batch = 0.0834s	
1627/3500 (epoch 23.243), train_loss = 1.44295277, grad/param norm = 9.0097e-02, time/batch = 0.0824s	
1628/3500 (epoch 23.257), train_loss = 1.45129779, grad/param norm = 7.7923e-02, time/batch = 0.0822s	
1629/3500 (epoch 23.271), train_loss = 1.45764492, grad/param norm = 7.3567e-02, time/batch = 0.0820s	
1630/3500 (epoch 23.286), train_loss = 1.45042796, grad/param norm = 7.3784e-02, time/batch = 0.0824s	
1631/3500 (epoch 23.300), train_loss = 1.47276648, grad/param norm = 7.1253e-02, time/batch = 0.0831s	
1632/3500 (epoch 23.314), train_loss = 1.44016939, grad/param norm = 7.1916e-02, time/batch = 0.0823s	
1633/3500 (epoch 23.329), train_loss = 1.46407189, grad/param norm = 6.4512e-02, time/batch = 0.0823s	
1634/3500 (epoch 23.343), train_loss = 1.44822437, grad/param norm = 5.5846e-02, time/batch = 0.0840s	
1635/3500 (epoch 23.357), train_loss = 1.45715707, grad/param norm = 6.1540e-02, time/batch = 0.0844s	
1636/3500 (epoch 23.371), train_loss = 1.45202180, grad/param norm = 6.3641e-02, time/batch = 0.0837s	
1637/3500 (epoch 23.386), train_loss = 1.43313401, grad/param norm = 6.9720e-02, time/batch = 0.0826s	
1638/3500 (epoch 23.400), train_loss = 1.43590716, grad/param norm = 7.0834e-02, time/batch = 0.0825s	
1639/3500 (epoch 23.414), train_loss = 1.45068818, grad/param norm = 7.2838e-02, time/batch = 0.0818s	
1640/3500 (epoch 23.429), train_loss = 1.41333077, grad/param norm = 6.8465e-02, time/batch = 0.0824s	
1641/3500 (epoch 23.443), train_loss = 1.43938554, grad/param norm = 6.1303e-02, time/batch = 0.0827s	
1642/3500 (epoch 23.457), train_loss = 1.44090470, grad/param norm = 6.9554e-02, time/batch = 0.0821s	
1643/3500 (epoch 23.471), train_loss = 1.44618279, grad/param norm = 7.9588e-02, time/batch = 0.0823s	
1644/3500 (epoch 23.486), train_loss = 1.46470883, grad/param norm = 8.5213e-02, time/batch = 0.0838s	
1645/3500 (epoch 23.500), train_loss = 1.44566421, grad/param norm = 8.6290e-02, time/batch = 0.0839s	
1646/3500 (epoch 23.514), train_loss = 1.46357229, grad/param norm = 7.6849e-02, time/batch = 0.0834s	
1647/3500 (epoch 23.529), train_loss = 1.45835687, grad/param norm = 7.2167e-02, time/batch = 0.0824s	
1648/3500 (epoch 23.543), train_loss = 1.45161947, grad/param norm = 7.5372e-02, time/batch = 0.0823s	
1649/3500 (epoch 23.557), train_loss = 1.41583702, grad/param norm = 7.8000e-02, time/batch = 0.0820s	
1650/3500 (epoch 23.571), train_loss = 1.42147127, grad/param norm = 7.6472e-02, time/batch = 0.0825s	
1651/3500 (epoch 23.586), train_loss = 1.43088852, grad/param norm = 8.8304e-02, time/batch = 0.0832s	
1652/3500 (epoch 23.600), train_loss = 1.42923595, grad/param norm = 8.6827e-02, time/batch = 0.0823s	
1653/3500 (epoch 23.614), train_loss = 1.43864955, grad/param norm = 8.2854e-02, time/batch = 0.0824s	
1654/3500 (epoch 23.629), train_loss = 1.42150372, grad/param norm = 8.5776e-02, time/batch = 0.0845s	
1655/3500 (epoch 23.643), train_loss = 1.44144779, grad/param norm = 9.0197e-02, time/batch = 0.0841s	
1656/3500 (epoch 23.657), train_loss = 1.43351473, grad/param norm = 9.3704e-02, time/batch = 0.0837s	
1657/3500 (epoch 23.671), train_loss = 1.41865087, grad/param norm = 1.0086e-01, time/batch = 0.0826s	
1658/3500 (epoch 23.686), train_loss = 1.44475371, grad/param norm = 9.6628e-02, time/batch = 0.0825s	
1659/3500 (epoch 23.700), train_loss = 1.44770519, grad/param norm = 8.9479e-02, time/batch = 0.0819s	
1660/3500 (epoch 23.714), train_loss = 1.43888448, grad/param norm = 8.3448e-02, time/batch = 0.0836s	
1661/3500 (epoch 23.729), train_loss = 1.43742423, grad/param norm = 6.9281e-02, time/batch = 0.0828s	
1662/3500 (epoch 23.743), train_loss = 1.42445129, grad/param norm = 6.4338e-02, time/batch = 0.0821s	
1663/3500 (epoch 23.757), train_loss = 1.44531110, grad/param norm = 6.4154e-02, time/batch = 0.0822s	
1664/3500 (epoch 23.771), train_loss = 1.44128592, grad/param norm = 5.9016e-02, time/batch = 0.0839s	
1665/3500 (epoch 23.786), train_loss = 1.43361405, grad/param norm = 5.2657e-02, time/batch = 0.0840s	
1666/3500 (epoch 23.800), train_loss = 1.42104056, grad/param norm = 5.5847e-02, time/batch = 0.0837s	
1667/3500 (epoch 23.814), train_loss = 1.43465335, grad/param norm = 6.0891e-02, time/batch = 0.0824s	
1668/3500 (epoch 23.829), train_loss = 1.41860141, grad/param norm = 7.2592e-02, time/batch = 0.0822s	
1669/3500 (epoch 23.843), train_loss = 1.46322230, grad/param norm = 6.4737e-02, time/batch = 0.0825s	
1670/3500 (epoch 23.857), train_loss = 1.45914922, grad/param norm = 6.2459e-02, time/batch = 0.0824s	
1671/3500 (epoch 23.871), train_loss = 1.45355714, grad/param norm = 6.6836e-02, time/batch = 0.0832s	
1672/3500 (epoch 23.886), train_loss = 1.44549917, grad/param norm = 7.4911e-02, time/batch = 0.0823s	
1673/3500 (epoch 23.900), train_loss = 1.45570697, grad/param norm = 8.3153e-02, time/batch = 0.0824s	
1674/3500 (epoch 23.914), train_loss = 1.46000665, grad/param norm = 8.7981e-02, time/batch = 0.0840s	
1675/3500 (epoch 23.929), train_loss = 1.43899540, grad/param norm = 9.0875e-02, time/batch = 0.0840s	
1676/3500 (epoch 23.943), train_loss = 1.45523610, grad/param norm = 8.4710e-02, time/batch = 0.0838s	
1677/3500 (epoch 23.957), train_loss = 1.46214437, grad/param norm = 7.9571e-02, time/batch = 0.0826s	
1678/3500 (epoch 23.971), train_loss = 1.45569433, grad/param norm = 8.8755e-02, time/batch = 0.0826s	
1679/3500 (epoch 23.986), train_loss = 1.44821897, grad/param norm = 8.3819e-02, time/batch = 0.0822s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
1680/3500 (epoch 24.000), train_loss = 1.43675291, grad/param norm = 7.8299e-02, time/batch = 0.0824s	
1681/3500 (epoch 24.014), train_loss = 1.62592281, grad/param norm = 7.2107e-02, time/batch = 0.0827s	
1682/3500 (epoch 24.029), train_loss = 1.44370297, grad/param norm = 6.8810e-02, time/batch = 0.0820s	
1683/3500 (epoch 24.043), train_loss = 1.43879842, grad/param norm = 6.8701e-02, time/batch = 0.0822s	
1684/3500 (epoch 24.057), train_loss = 1.43074682, grad/param norm = 6.8569e-02, time/batch = 0.0836s	
1685/3500 (epoch 24.071), train_loss = 1.42605344, grad/param norm = 6.7109e-02, time/batch = 0.0839s	
1686/3500 (epoch 24.086), train_loss = 1.43215847, grad/param norm = 6.3622e-02, time/batch = 0.0834s	
1687/3500 (epoch 24.100), train_loss = 1.44150179, grad/param norm = 6.5693e-02, time/batch = 0.0824s	
1688/3500 (epoch 24.114), train_loss = 1.44392793, grad/param norm = 6.2627e-02, time/batch = 0.0823s	
1689/3500 (epoch 24.129), train_loss = 1.43736375, grad/param norm = 5.8005e-02, time/batch = 0.0825s	
1690/3500 (epoch 24.143), train_loss = 1.43798277, grad/param norm = 5.3158e-02, time/batch = 0.0825s	
1691/3500 (epoch 24.157), train_loss = 1.43042396, grad/param norm = 5.9524e-02, time/batch = 0.0832s	
1692/3500 (epoch 24.171), train_loss = 1.42518471, grad/param norm = 5.9786e-02, time/batch = 0.0823s	
1693/3500 (epoch 24.186), train_loss = 1.43258711, grad/param norm = 6.0328e-02, time/batch = 0.0823s	
1694/3500 (epoch 24.200), train_loss = 1.43488568, grad/param norm = 7.3236e-02, time/batch = 0.0839s	
1695/3500 (epoch 24.214), train_loss = 1.42637818, grad/param norm = 8.5688e-02, time/batch = 0.0840s	
1696/3500 (epoch 24.229), train_loss = 1.42171563, grad/param norm = 9.0196e-02, time/batch = 0.0835s	
1697/3500 (epoch 24.243), train_loss = 1.43442806, grad/param norm = 8.6328e-02, time/batch = 0.0826s	
1698/3500 (epoch 24.257), train_loss = 1.44429394, grad/param norm = 8.5569e-02, time/batch = 0.0826s	
1699/3500 (epoch 24.271), train_loss = 1.45268477, grad/param norm = 9.1638e-02, time/batch = 0.0818s	
1700/3500 (epoch 24.286), train_loss = 1.44500764, grad/param norm = 8.9574e-02, time/batch = 0.0824s	
1701/3500 (epoch 24.300), train_loss = 1.46399629, grad/param norm = 8.0278e-02, time/batch = 0.0826s	
1702/3500 (epoch 24.314), train_loss = 1.43122688, grad/param norm = 6.9504e-02, time/batch = 0.0821s	
1703/3500 (epoch 24.329), train_loss = 1.45255514, grad/param norm = 5.9492e-02, time/batch = 0.0822s	
1704/3500 (epoch 24.343), train_loss = 1.43911545, grad/param norm = 5.3736e-02, time/batch = 0.0837s	
1705/3500 (epoch 24.357), train_loss = 1.44611678, grad/param norm = 5.8370e-02, time/batch = 0.0838s	
1706/3500 (epoch 24.371), train_loss = 1.44089820, grad/param norm = 5.5437e-02, time/batch = 0.0835s	
1707/3500 (epoch 24.386), train_loss = 1.42206689, grad/param norm = 6.3898e-02, time/batch = 0.0825s	
1708/3500 (epoch 24.400), train_loss = 1.42622539, grad/param norm = 7.0303e-02, time/batch = 0.0823s	
1709/3500 (epoch 24.414), train_loss = 1.43842927, grad/param norm = 7.1316e-02, time/batch = 0.0820s	
1710/3500 (epoch 24.429), train_loss = 1.40347499, grad/param norm = 6.8320e-02, time/batch = 0.0825s	
1711/3500 (epoch 24.443), train_loss = 1.43019004, grad/param norm = 7.1274e-02, time/batch = 0.0833s	
1712/3500 (epoch 24.457), train_loss = 1.43370018, grad/param norm = 8.7218e-02, time/batch = 0.0823s	
1713/3500 (epoch 24.471), train_loss = 1.44047141, grad/param norm = 1.0205e-01, time/batch = 0.0824s	
1714/3500 (epoch 24.486), train_loss = 1.45970463, grad/param norm = 9.2014e-02, time/batch = 0.0837s	
1715/3500 (epoch 24.500), train_loss = 1.43373708, grad/param norm = 8.3835e-02, time/batch = 0.0841s	
1716/3500 (epoch 24.514), train_loss = 1.45511541, grad/param norm = 9.1248e-02, time/batch = 0.0837s	
1717/3500 (epoch 24.529), train_loss = 1.45236913, grad/param norm = 9.8838e-02, time/batch = 0.0827s	
1718/3500 (epoch 24.543), train_loss = 1.44811747, grad/param norm = 1.0604e-01, time/batch = 0.0825s	
1719/3500 (epoch 24.557), train_loss = 1.41215916, grad/param norm = 9.6228e-02, time/batch = 0.0818s	
1720/3500 (epoch 24.571), train_loss = 1.41243916, grad/param norm = 7.4582e-02, time/batch = 0.0824s	
1721/3500 (epoch 24.586), train_loss = 1.41828373, grad/param norm = 6.8389e-02, time/batch = 0.0827s	
1722/3500 (epoch 24.600), train_loss = 1.41468206, grad/param norm = 6.0231e-02, time/batch = 0.0821s	
1723/3500 (epoch 24.614), train_loss = 1.42662256, grad/param norm = 6.9120e-02, time/batch = 0.0822s	
1724/3500 (epoch 24.629), train_loss = 1.41176378, grad/param norm = 8.2481e-02, time/batch = 0.0835s	
1725/3500 (epoch 24.643), train_loss = 1.43026594, grad/param norm = 7.5206e-02, time/batch = 0.0840s	
1726/3500 (epoch 24.657), train_loss = 1.41830791, grad/param norm = 6.1307e-02, time/batch = 0.0833s	
1727/3500 (epoch 24.671), train_loss = 1.40365994, grad/param norm = 7.9605e-02, time/batch = 0.0824s	
1728/3500 (epoch 24.686), train_loss = 1.43202200, grad/param norm = 8.9788e-02, time/batch = 0.0823s	
1729/3500 (epoch 24.700), train_loss = 1.43803152, grad/param norm = 8.8124e-02, time/batch = 0.0820s	
1730/3500 (epoch 24.714), train_loss = 1.42911550, grad/param norm = 8.3096e-02, time/batch = 0.0824s	
1731/3500 (epoch 24.729), train_loss = 1.42826182, grad/param norm = 6.8514e-02, time/batch = 0.0832s	
1732/3500 (epoch 24.743), train_loss = 1.41358353, grad/param norm = 6.0736e-02, time/batch = 0.0826s	
1733/3500 (epoch 24.757), train_loss = 1.43512890, grad/param norm = 6.0253e-02, time/batch = 0.0829s	
1734/3500 (epoch 24.771), train_loss = 1.43163236, grad/param norm = 5.6823e-02, time/batch = 0.0837s	
1735/3500 (epoch 24.786), train_loss = 1.42319353, grad/param norm = 5.2120e-02, time/batch = 0.0840s	
1736/3500 (epoch 24.800), train_loss = 1.41103853, grad/param norm = 5.4124e-02, time/batch = 0.0838s	
1737/3500 (epoch 24.814), train_loss = 1.42386951, grad/param norm = 5.5832e-02, time/batch = 0.0827s	
1738/3500 (epoch 24.829), train_loss = 1.40797067, grad/param norm = 6.0173e-02, time/batch = 0.0825s	
1739/3500 (epoch 24.843), train_loss = 1.45135623, grad/param norm = 5.9209e-02, time/batch = 0.0817s	
1740/3500 (epoch 24.857), train_loss = 1.44905920, grad/param norm = 6.6037e-02, time/batch = 0.0824s	
1741/3500 (epoch 24.871), train_loss = 1.44341579, grad/param norm = 6.5757e-02, time/batch = 0.0828s	
1742/3500 (epoch 24.886), train_loss = 1.43479659, grad/param norm = 6.6205e-02, time/batch = 0.0822s	
1743/3500 (epoch 24.900), train_loss = 1.44332160, grad/param norm = 6.9288e-02, time/batch = 0.0827s	
1744/3500 (epoch 24.914), train_loss = 1.44850505, grad/param norm = 7.8636e-02, time/batch = 0.0834s	
1745/3500 (epoch 24.929), train_loss = 1.42908717, grad/param norm = 8.2900e-02, time/batch = 0.0840s	
1746/3500 (epoch 24.943), train_loss = 1.44520943, grad/param norm = 7.9445e-02, time/batch = 0.0834s	
1747/3500 (epoch 24.957), train_loss = 1.45071486, grad/param norm = 7.7613e-02, time/batch = 0.0824s	
1748/3500 (epoch 24.971), train_loss = 1.44506323, grad/param norm = 8.4406e-02, time/batch = 0.0827s	
1749/3500 (epoch 24.986), train_loss = 1.43649300, grad/param norm = 7.3522e-02, time/batch = 0.0819s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
1750/3500 (epoch 25.000), train_loss = 1.42404076, grad/param norm = 6.1162e-02, time/batch = 0.0824s	
1751/3500 (epoch 25.014), train_loss = 1.61505967, grad/param norm = 5.7145e-02, time/batch = 0.0831s	
1752/3500 (epoch 25.029), train_loss = 1.43183433, grad/param norm = 5.7815e-02, time/batch = 0.0824s	
1753/3500 (epoch 25.043), train_loss = 1.42925378, grad/param norm = 7.3814e-02, time/batch = 0.0831s	
1754/3500 (epoch 25.057), train_loss = 1.42641201, grad/param norm = 9.4153e-02, time/batch = 0.0837s	
1755/3500 (epoch 25.071), train_loss = 1.42540674, grad/param norm = 1.0800e-01, time/batch = 0.0841s	
1756/3500 (epoch 25.086), train_loss = 1.43270124, grad/param norm = 1.0590e-01, time/batch = 0.0836s	
1757/3500 (epoch 25.100), train_loss = 1.43928851, grad/param norm = 9.0844e-02, time/batch = 0.0826s	
1758/3500 (epoch 25.114), train_loss = 1.43677912, grad/param norm = 6.8534e-02, time/batch = 0.0838s	
1759/3500 (epoch 25.129), train_loss = 1.42801648, grad/param norm = 6.1769e-02, time/batch = 0.0827s	
1760/3500 (epoch 25.143), train_loss = 1.42950644, grad/param norm = 6.1114e-02, time/batch = 0.0825s	
1761/3500 (epoch 25.157), train_loss = 1.42236284, grad/param norm = 7.1710e-02, time/batch = 0.0830s	
1762/3500 (epoch 25.171), train_loss = 1.41843791, grad/param norm = 7.0111e-02, time/batch = 0.0822s	
1763/3500 (epoch 25.186), train_loss = 1.42388691, grad/param norm = 6.6290e-02, time/batch = 0.0822s	
1764/3500 (epoch 25.200), train_loss = 1.42605300, grad/param norm = 7.3640e-02, time/batch = 0.0837s	
1765/3500 (epoch 25.214), train_loss = 1.41620283, grad/param norm = 8.1546e-02, time/batch = 0.0839s	
1766/3500 (epoch 25.229), train_loss = 1.41016720, grad/param norm = 7.7819e-02, time/batch = 0.0836s	
1767/3500 (epoch 25.243), train_loss = 1.41921507, grad/param norm = 6.1443e-02, time/batch = 0.0824s	
1768/3500 (epoch 25.257), train_loss = 1.42838534, grad/param norm = 6.0910e-02, time/batch = 0.0828s	
1769/3500 (epoch 25.271), train_loss = 1.43704264, grad/param norm = 6.6077e-02, time/batch = 0.0820s	
1770/3500 (epoch 25.286), train_loss = 1.43088197, grad/param norm = 7.5611e-02, time/batch = 0.0824s	
1771/3500 (epoch 25.300), train_loss = 1.45487924, grad/param norm = 8.1594e-02, time/batch = 0.0832s	
1772/3500 (epoch 25.314), train_loss = 1.42365532, grad/param norm = 7.3641e-02, time/batch = 0.0823s	
1773/3500 (epoch 25.329), train_loss = 1.44467460, grad/param norm = 6.9149e-02, time/batch = 0.0824s	
1774/3500 (epoch 25.343), train_loss = 1.43218725, grad/param norm = 6.5991e-02, time/batch = 0.0837s	
1775/3500 (epoch 25.357), train_loss = 1.43726305, grad/param norm = 6.3331e-02, time/batch = 0.0840s	
1776/3500 (epoch 25.371), train_loss = 1.43248033, grad/param norm = 5.8987e-02, time/batch = 0.0837s	
1777/3500 (epoch 25.386), train_loss = 1.41224537, grad/param norm = 5.9867e-02, time/batch = 0.0826s	
1778/3500 (epoch 25.400), train_loss = 1.41520727, grad/param norm = 5.8935e-02, time/batch = 0.0825s	
1779/3500 (epoch 25.414), train_loss = 1.42667451, grad/param norm = 6.0771e-02, time/batch = 0.0818s	
1780/3500 (epoch 25.429), train_loss = 1.39278391, grad/param norm = 6.5375e-02, time/batch = 0.0824s	
1781/3500 (epoch 25.443), train_loss = 1.42133224, grad/param norm = 7.1962e-02, time/batch = 0.0827s	
1782/3500 (epoch 25.457), train_loss = 1.42317346, grad/param norm = 8.2829e-02, time/batch = 0.0822s	
1783/3500 (epoch 25.471), train_loss = 1.42803219, grad/param norm = 8.1619e-02, time/batch = 0.0822s	
1784/3500 (epoch 25.486), train_loss = 1.44656181, grad/param norm = 8.4997e-02, time/batch = 0.0837s	
1785/3500 (epoch 25.500), train_loss = 1.42608722, grad/param norm = 9.4698e-02, time/batch = 0.0839s	
1786/3500 (epoch 25.514), train_loss = 1.44640851, grad/param norm = 9.5749e-02, time/batch = 0.0836s	
1787/3500 (epoch 25.529), train_loss = 1.44520304, grad/param norm = 9.3184e-02, time/batch = 0.0824s	
1788/3500 (epoch 25.543), train_loss = 1.43585041, grad/param norm = 9.1766e-02, time/batch = 0.0823s	
1789/3500 (epoch 25.557), train_loss = 1.40133604, grad/param norm = 8.3403e-02, time/batch = 0.0820s	
1790/3500 (epoch 25.571), train_loss = 1.40297524, grad/param norm = 7.5728e-02, time/batch = 0.0824s	
1791/3500 (epoch 25.586), train_loss = 1.41120538, grad/param norm = 7.8479e-02, time/batch = 0.0832s	
1792/3500 (epoch 25.600), train_loss = 1.40766387, grad/param norm = 7.4229e-02, time/batch = 0.0824s	
1793/3500 (epoch 25.614), train_loss = 1.41979530, grad/param norm = 7.6530e-02, time/batch = 0.0823s	
1794/3500 (epoch 25.629), train_loss = 1.40401390, grad/param norm = 8.8839e-02, time/batch = 0.0836s	
1795/3500 (epoch 25.643), train_loss = 1.42125508, grad/param norm = 7.8480e-02, time/batch = 0.0841s	
1796/3500 (epoch 25.657), train_loss = 1.40903526, grad/param norm = 5.6449e-02, time/batch = 0.0838s	
1797/3500 (epoch 25.671), train_loss = 1.39212024, grad/param norm = 6.3525e-02, time/batch = 0.0826s	
1798/3500 (epoch 25.686), train_loss = 1.41910148, grad/param norm = 7.1286e-02, time/batch = 0.0825s	
1799/3500 (epoch 25.700), train_loss = 1.42414738, grad/param norm = 6.9237e-02, time/batch = 0.0818s	
1800/3500 (epoch 25.714), train_loss = 1.41531840, grad/param norm = 7.0098e-02, time/batch = 0.0824s	
1801/3500 (epoch 25.729), train_loss = 1.41848358, grad/param norm = 6.4593e-02, time/batch = 0.0827s	
1802/3500 (epoch 25.743), train_loss = 1.40532930, grad/param norm = 6.4021e-02, time/batch = 0.0826s	
1803/3500 (epoch 25.757), train_loss = 1.42722991, grad/param norm = 6.2903e-02, time/batch = 0.0823s	
1804/3500 (epoch 25.771), train_loss = 1.42408888, grad/param norm = 6.2732e-02, time/batch = 0.0833s	
1805/3500 (epoch 25.786), train_loss = 1.41521644, grad/param norm = 5.7743e-02, time/batch = 0.0841s	
1806/3500 (epoch 25.800), train_loss = 1.40249712, grad/param norm = 6.0391e-02, time/batch = 0.0835s	
1807/3500 (epoch 25.814), train_loss = 1.41611497, grad/param norm = 6.3157e-02, time/batch = 0.0825s	
1808/3500 (epoch 25.829), train_loss = 1.40092679, grad/param norm = 7.1097e-02, time/batch = 0.0823s	
1809/3500 (epoch 25.843), train_loss = 1.44465329, grad/param norm = 7.0014e-02, time/batch = 0.0819s	
1810/3500 (epoch 25.857), train_loss = 1.44440520, grad/param norm = 8.9152e-02, time/batch = 0.0824s	
1811/3500 (epoch 25.871), train_loss = 1.44355910, grad/param norm = 1.0385e-01, time/batch = 0.0832s	
1812/3500 (epoch 25.886), train_loss = 1.43532738, grad/param norm = 1.0990e-01, time/batch = 0.0828s	
1813/3500 (epoch 25.900), train_loss = 1.44318627, grad/param norm = 1.0282e-01, time/batch = 0.0824s	
1814/3500 (epoch 25.914), train_loss = 1.44172365, grad/param norm = 8.5405e-02, time/batch = 0.0837s	
1815/3500 (epoch 25.929), train_loss = 1.41762718, grad/param norm = 6.8821e-02, time/batch = 0.0841s	
1816/3500 (epoch 25.943), train_loss = 1.43213006, grad/param norm = 5.6458e-02, time/batch = 0.0838s	
1817/3500 (epoch 25.957), train_loss = 1.43948169, grad/param norm = 6.1468e-02, time/batch = 0.0829s	
1818/3500 (epoch 25.971), train_loss = 1.43310187, grad/param norm = 6.8246e-02, time/batch = 0.0825s	
1819/3500 (epoch 25.986), train_loss = 1.42577554, grad/param norm = 6.3920e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
1820/3500 (epoch 26.000), train_loss = 1.41826250, grad/param norm = 7.4524e-02, time/batch = 0.0824s	
1821/3500 (epoch 26.014), train_loss = 1.61514287, grad/param norm = 9.7212e-02, time/batch = 0.0827s	
1822/3500 (epoch 26.029), train_loss = 1.43202959, grad/param norm = 9.7145e-02, time/batch = 0.0825s	
1823/3500 (epoch 26.043), train_loss = 1.42272882, grad/param norm = 8.3218e-02, time/batch = 0.0822s	
1824/3500 (epoch 26.057), train_loss = 1.41298188, grad/param norm = 7.5568e-02, time/batch = 0.0834s	
1825/3500 (epoch 26.071), train_loss = 1.40718190, grad/param norm = 6.9733e-02, time/batch = 0.0839s	
1826/3500 (epoch 26.086), train_loss = 1.41324801, grad/param norm = 6.7612e-02, time/batch = 0.0833s	
1827/3500 (epoch 26.100), train_loss = 1.42341963, grad/param norm = 6.2126e-02, time/batch = 0.0828s	
1828/3500 (epoch 26.114), train_loss = 1.42520796, grad/param norm = 5.3989e-02, time/batch = 0.0823s	
1829/3500 (epoch 26.129), train_loss = 1.41752611, grad/param norm = 5.1652e-02, time/batch = 0.0820s	
1830/3500 (epoch 26.143), train_loss = 1.41882960, grad/param norm = 4.8479e-02, time/batch = 0.0824s	
1831/3500 (epoch 26.157), train_loss = 1.41153308, grad/param norm = 5.7202e-02, time/batch = 0.0832s	
1832/3500 (epoch 26.171), train_loss = 1.40739722, grad/param norm = 5.5756e-02, time/batch = 0.0828s	
1833/3500 (epoch 26.186), train_loss = 1.41211603, grad/param norm = 5.2172e-02, time/batch = 0.0823s	
1834/3500 (epoch 26.200), train_loss = 1.41453226, grad/param norm = 6.0066e-02, time/batch = 0.0836s	
1835/3500 (epoch 26.214), train_loss = 1.40528045, grad/param norm = 6.6363e-02, time/batch = 0.0842s	
1836/3500 (epoch 26.229), train_loss = 1.39899055, grad/param norm = 6.5165e-02, time/batch = 0.0837s	
1837/3500 (epoch 26.243), train_loss = 1.41071802, grad/param norm = 5.8307e-02, time/batch = 0.0831s	
1838/3500 (epoch 26.257), train_loss = 1.42112838, grad/param norm = 6.5565e-02, time/batch = 0.0825s	
1839/3500 (epoch 26.271), train_loss = 1.43045699, grad/param norm = 7.4082e-02, time/batch = 0.0818s	
1840/3500 (epoch 26.286), train_loss = 1.42356480, grad/param norm = 8.0174e-02, time/batch = 0.0824s	
1841/3500 (epoch 26.300), train_loss = 1.44561687, grad/param norm = 7.8464e-02, time/batch = 0.0826s	
1842/3500 (epoch 26.314), train_loss = 1.41393067, grad/param norm = 6.7665e-02, time/batch = 0.0821s	
1843/3500 (epoch 26.329), train_loss = 1.43411502, grad/param norm = 5.7582e-02, time/batch = 0.0822s	
1844/3500 (epoch 26.343), train_loss = 1.42188041, grad/param norm = 5.4819e-02, time/batch = 0.0836s	
1845/3500 (epoch 26.357), train_loss = 1.42742767, grad/param norm = 5.7800e-02, time/batch = 0.0840s	
1846/3500 (epoch 26.371), train_loss = 1.42351928, grad/param norm = 5.5702e-02, time/batch = 0.0835s	
1847/3500 (epoch 26.386), train_loss = 1.40362705, grad/param norm = 5.8712e-02, time/batch = 0.0824s	
1848/3500 (epoch 26.400), train_loss = 1.40852719, grad/param norm = 6.5001e-02, time/batch = 0.0823s	
1849/3500 (epoch 26.414), train_loss = 1.42073629, grad/param norm = 7.4233e-02, time/batch = 0.0819s	
1850/3500 (epoch 26.429), train_loss = 1.38852914, grad/param norm = 8.5766e-02, time/batch = 0.0825s	
1851/3500 (epoch 26.443), train_loss = 1.41889490, grad/param norm = 9.4768e-02, time/batch = 0.0833s	
1852/3500 (epoch 26.457), train_loss = 1.42038252, grad/param norm = 9.9815e-02, time/batch = 0.0824s	
1853/3500 (epoch 26.471), train_loss = 1.42292781, grad/param norm = 8.4396e-02, time/batch = 0.0823s	
1854/3500 (epoch 26.486), train_loss = 1.43777206, grad/param norm = 7.8151e-02, time/batch = 0.0836s	
1855/3500 (epoch 26.500), train_loss = 1.41567932, grad/param norm = 8.4573e-02, time/batch = 0.0841s	
1856/3500 (epoch 26.514), train_loss = 1.43452536, grad/param norm = 8.9181e-02, time/batch = 0.0837s	
1857/3500 (epoch 26.529), train_loss = 1.43504361, grad/param norm = 7.7913e-02, time/batch = 0.0834s	
1858/3500 (epoch 26.543), train_loss = 1.42526522, grad/param norm = 6.9831e-02, time/batch = 0.0828s	
1859/3500 (epoch 26.557), train_loss = 1.38797615, grad/param norm = 6.3592e-02, time/batch = 0.0818s	
1860/3500 (epoch 26.571), train_loss = 1.39267560, grad/param norm = 6.1827e-02, time/batch = 0.0824s	
1861/3500 (epoch 26.586), train_loss = 1.40057205, grad/param norm = 6.7426e-02, time/batch = 0.0828s	
1862/3500 (epoch 26.600), train_loss = 1.39867831, grad/param norm = 7.3341e-02, time/batch = 0.0821s	
1863/3500 (epoch 26.614), train_loss = 1.41070801, grad/param norm = 7.3189e-02, time/batch = 0.0822s	
1864/3500 (epoch 26.629), train_loss = 1.39307081, grad/param norm = 7.5720e-02, time/batch = 0.0835s	
1865/3500 (epoch 26.643), train_loss = 1.41148393, grad/param norm = 6.7046e-02, time/batch = 0.0839s	
1866/3500 (epoch 26.657), train_loss = 1.39908952, grad/param norm = 5.5885e-02, time/batch = 0.0839s	
1867/3500 (epoch 26.671), train_loss = 1.38201261, grad/param norm = 6.0532e-02, time/batch = 0.0824s	
1868/3500 (epoch 26.686), train_loss = 1.41036491, grad/param norm = 6.7479e-02, time/batch = 0.0822s	
1869/3500 (epoch 26.700), train_loss = 1.41611414, grad/param norm = 6.7342e-02, time/batch = 0.0819s	
1870/3500 (epoch 26.714), train_loss = 1.40705647, grad/param norm = 6.7133e-02, time/batch = 0.0824s	
1871/3500 (epoch 26.729), train_loss = 1.41014410, grad/param norm = 6.3501e-02, time/batch = 0.0833s	
1872/3500 (epoch 26.743), train_loss = 1.39690332, grad/param norm = 6.3893e-02, time/batch = 0.0823s	
1873/3500 (epoch 26.757), train_loss = 1.41884481, grad/param norm = 6.2688e-02, time/batch = 0.0823s	
1874/3500 (epoch 26.771), train_loss = 1.41560145, grad/param norm = 5.9330e-02, time/batch = 0.0836s	
1875/3500 (epoch 26.786), train_loss = 1.40600295, grad/param norm = 5.1033e-02, time/batch = 0.0841s	
1876/3500 (epoch 26.800), train_loss = 1.39265488, grad/param norm = 5.5365e-02, time/batch = 0.0841s	
1877/3500 (epoch 26.814), train_loss = 1.40671390, grad/param norm = 5.9511e-02, time/batch = 0.0826s	
1878/3500 (epoch 26.829), train_loss = 1.39140312, grad/param norm = 6.5440e-02, time/batch = 0.0825s	
1879/3500 (epoch 26.843), train_loss = 1.43551626, grad/param norm = 6.6524e-02, time/batch = 0.0818s	
1880/3500 (epoch 26.857), train_loss = 1.43514125, grad/param norm = 8.6451e-02, time/batch = 0.0824s	
1881/3500 (epoch 26.871), train_loss = 1.43459976, grad/param norm = 1.0902e-01, time/batch = 0.0834s	
1882/3500 (epoch 26.886), train_loss = 1.42729656, grad/param norm = 1.1367e-01, time/batch = 0.0821s	
1883/3500 (epoch 26.900), train_loss = 1.43320519, grad/param norm = 9.5296e-02, time/batch = 0.0822s	
1884/3500 (epoch 26.914), train_loss = 1.43196922, grad/param norm = 7.8164e-02, time/batch = 0.0836s	
1885/3500 (epoch 26.929), train_loss = 1.40942658, grad/param norm = 6.9802e-02, time/batch = 0.0839s	
1886/3500 (epoch 26.943), train_loss = 1.42517977, grad/param norm = 6.8632e-02, time/batch = 0.0839s	
1887/3500 (epoch 26.957), train_loss = 1.43316291, grad/param norm = 7.4909e-02, time/batch = 0.0825s	
1888/3500 (epoch 26.971), train_loss = 1.42585214, grad/param norm = 6.7060e-02, time/batch = 0.0823s	
1889/3500 (epoch 26.986), train_loss = 1.41765175, grad/param norm = 5.4358e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
1890/3500 (epoch 27.000), train_loss = 1.40919339, grad/param norm = 6.9925e-02, time/batch = 0.0824s	
1891/3500 (epoch 27.014), train_loss = 1.60611142, grad/param norm = 7.9914e-02, time/batch = 0.0837s	
1892/3500 (epoch 27.029), train_loss = 1.42059971, grad/param norm = 8.0164e-02, time/batch = 0.0823s	
1893/3500 (epoch 27.043), train_loss = 1.41411373, grad/param norm = 7.8298e-02, time/batch = 0.0823s	
1894/3500 (epoch 27.057), train_loss = 1.40580511, grad/param norm = 8.2489e-02, time/batch = 0.0837s	
1895/3500 (epoch 27.071), train_loss = 1.40048673, grad/param norm = 7.3152e-02, time/batch = 0.0840s	
1896/3500 (epoch 27.086), train_loss = 1.40492808, grad/param norm = 5.8586e-02, time/batch = 0.0842s	
1897/3500 (epoch 27.100), train_loss = 1.41521760, grad/param norm = 6.1057e-02, time/batch = 0.0826s	
1898/3500 (epoch 27.114), train_loss = 1.41801503, grad/param norm = 5.9467e-02, time/batch = 0.0825s	
1899/3500 (epoch 27.129), train_loss = 1.40930717, grad/param norm = 5.2308e-02, time/batch = 0.0817s	
1900/3500 (epoch 27.143), train_loss = 1.41092169, grad/param norm = 4.7271e-02, time/batch = 0.0824s	
1901/3500 (epoch 27.157), train_loss = 1.40337787, grad/param norm = 5.6599e-02, time/batch = 0.0835s	
1902/3500 (epoch 27.171), train_loss = 1.39953705, grad/param norm = 5.6211e-02, time/batch = 0.0822s	
1903/3500 (epoch 27.186), train_loss = 1.40449914, grad/param norm = 5.6741e-02, time/batch = 0.0821s	
1904/3500 (epoch 27.200), train_loss = 1.40746148, grad/param norm = 6.5285e-02, time/batch = 0.0835s	
1905/3500 (epoch 27.214), train_loss = 1.39846472, grad/param norm = 6.4859e-02, time/batch = 0.0840s	
1906/3500 (epoch 27.229), train_loss = 1.39129973, grad/param norm = 5.8956e-02, time/batch = 0.0839s	
1907/3500 (epoch 27.243), train_loss = 1.40283886, grad/param norm = 6.6387e-02, time/batch = 0.0824s	
1908/3500 (epoch 27.257), train_loss = 1.41443892, grad/param norm = 7.3659e-02, time/batch = 0.0823s	
1909/3500 (epoch 27.271), train_loss = 1.42429605, grad/param norm = 9.3975e-02, time/batch = 0.0820s	
1910/3500 (epoch 27.286), train_loss = 1.41596382, grad/param norm = 7.4519e-02, time/batch = 0.0824s	
1911/3500 (epoch 27.300), train_loss = 1.43791625, grad/param norm = 6.7662e-02, time/batch = 0.0832s	
1912/3500 (epoch 27.314), train_loss = 1.40444768, grad/param norm = 6.1834e-02, time/batch = 0.0823s	
1913/3500 (epoch 27.329), train_loss = 1.42539432, grad/param norm = 5.5697e-02, time/batch = 0.0823s	
1914/3500 (epoch 27.343), train_loss = 1.41260652, grad/param norm = 5.2042e-02, time/batch = 0.0839s	
1915/3500 (epoch 27.357), train_loss = 1.41928059, grad/param norm = 5.7362e-02, time/batch = 0.0842s	
1916/3500 (epoch 27.371), train_loss = 1.41655224, grad/param norm = 6.1247e-02, time/batch = 0.0842s	
1917/3500 (epoch 27.386), train_loss = 1.39765615, grad/param norm = 7.3432e-02, time/batch = 0.0826s	
1918/3500 (epoch 27.400), train_loss = 1.40390675, grad/param norm = 7.8307e-02, time/batch = 0.0825s	
1919/3500 (epoch 27.414), train_loss = 1.41337688, grad/param norm = 7.7670e-02, time/batch = 0.0818s	
1920/3500 (epoch 27.429), train_loss = 1.37933482, grad/param norm = 7.0293e-02, time/batch = 0.0824s	
1921/3500 (epoch 27.443), train_loss = 1.40589313, grad/param norm = 6.9744e-02, time/batch = 0.0828s	
1922/3500 (epoch 27.457), train_loss = 1.40674857, grad/param norm = 8.0105e-02, time/batch = 0.0821s	
1923/3500 (epoch 27.471), train_loss = 1.41400304, grad/param norm = 8.9761e-02, time/batch = 0.0822s	
1924/3500 (epoch 27.486), train_loss = 1.43520846, grad/param norm = 9.7405e-02, time/batch = 0.0835s	
1925/3500 (epoch 27.500), train_loss = 1.41079444, grad/param norm = 8.8206e-02, time/batch = 0.0841s	
1926/3500 (epoch 27.514), train_loss = 1.42522452, grad/param norm = 6.9051e-02, time/batch = 0.0835s	
1927/3500 (epoch 27.529), train_loss = 1.42352885, grad/param norm = 6.3008e-02, time/batch = 0.0824s	
1928/3500 (epoch 27.543), train_loss = 1.41512734, grad/param norm = 6.4071e-02, time/batch = 0.0823s	
1929/3500 (epoch 27.557), train_loss = 1.37984116, grad/param norm = 6.4755e-02, time/batch = 0.0819s	
1930/3500 (epoch 27.571), train_loss = 1.38504770, grad/param norm = 5.8823e-02, time/batch = 0.0824s	
1931/3500 (epoch 27.586), train_loss = 1.39200656, grad/param norm = 6.7447e-02, time/batch = 0.0832s	
1932/3500 (epoch 27.600), train_loss = 1.38901598, grad/param norm = 6.5548e-02, time/batch = 0.0824s	
1933/3500 (epoch 27.614), train_loss = 1.40144729, grad/param norm = 6.1088e-02, time/batch = 0.0823s	
1934/3500 (epoch 27.629), train_loss = 1.38324707, grad/param norm = 6.3859e-02, time/batch = 0.0839s	
1935/3500 (epoch 27.643), train_loss = 1.40198944, grad/param norm = 5.7612e-02, time/batch = 0.0847s	
1936/3500 (epoch 27.657), train_loss = 1.39065537, grad/param norm = 5.3610e-02, time/batch = 0.0836s	
1937/3500 (epoch 27.671), train_loss = 1.37460134, grad/param norm = 6.4955e-02, time/batch = 0.0826s	
1938/3500 (epoch 27.686), train_loss = 1.40392181, grad/param norm = 6.8836e-02, time/batch = 0.0824s	
1939/3500 (epoch 27.700), train_loss = 1.40834317, grad/param norm = 6.7452e-02, time/batch = 0.0817s	
1940/3500 (epoch 27.714), train_loss = 1.40076738, grad/param norm = 7.0631e-02, time/batch = 0.0824s	
1941/3500 (epoch 27.729), train_loss = 1.40203185, grad/param norm = 6.6131e-02, time/batch = 0.0827s	
1942/3500 (epoch 27.743), train_loss = 1.38974154, grad/param norm = 6.3101e-02, time/batch = 0.0821s	
1943/3500 (epoch 27.757), train_loss = 1.41081126, grad/param norm = 6.4292e-02, time/batch = 0.0822s	
1944/3500 (epoch 27.771), train_loss = 1.40808639, grad/param norm = 6.1461e-02, time/batch = 0.0836s	
1945/3500 (epoch 27.786), train_loss = 1.39873098, grad/param norm = 6.0354e-02, time/batch = 0.0842s	
1946/3500 (epoch 27.800), train_loss = 1.38651253, grad/param norm = 6.5390e-02, time/batch = 0.0835s	
1947/3500 (epoch 27.814), train_loss = 1.40060715, grad/param norm = 7.1204e-02, time/batch = 0.0824s	
1948/3500 (epoch 27.829), train_loss = 1.38640043, grad/param norm = 8.2352e-02, time/batch = 0.0823s	
1949/3500 (epoch 27.843), train_loss = 1.43389689, grad/param norm = 8.6361e-02, time/batch = 0.0819s	
1950/3500 (epoch 27.857), train_loss = 1.42869582, grad/param norm = 8.2827e-02, time/batch = 0.0826s	
1951/3500 (epoch 27.871), train_loss = 1.42007752, grad/param norm = 8.6214e-02, time/batch = 0.0833s	
1952/3500 (epoch 27.886), train_loss = 1.41416554, grad/param norm = 8.3083e-02, time/batch = 0.0824s	
1953/3500 (epoch 27.900), train_loss = 1.41943344, grad/param norm = 6.8262e-02, time/batch = 0.0823s	
1954/3500 (epoch 27.914), train_loss = 1.42137040, grad/param norm = 6.4513e-02, time/batch = 0.0838s	
1955/3500 (epoch 27.929), train_loss = 1.40059902, grad/param norm = 7.2564e-02, time/batch = 0.0844s	
1956/3500 (epoch 27.943), train_loss = 1.41899793, grad/param norm = 7.7734e-02, time/batch = 0.0856s	
1957/3500 (epoch 27.957), train_loss = 1.42669116, grad/param norm = 8.2078e-02, time/batch = 0.0826s	
1958/3500 (epoch 27.971), train_loss = 1.41829167, grad/param norm = 7.0397e-02, time/batch = 0.0824s	
1959/3500 (epoch 27.986), train_loss = 1.41095509, grad/param norm = 6.5718e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
1960/3500 (epoch 28.000), train_loss = 1.40464963, grad/param norm = 8.1949e-02, time/batch = 0.0824s	
1961/3500 (epoch 28.014), train_loss = 1.60205730, grad/param norm = 9.2135e-02, time/batch = 0.0828s	
1962/3500 (epoch 28.029), train_loss = 1.41336598, grad/param norm = 8.1459e-02, time/batch = 0.0821s	
1963/3500 (epoch 28.043), train_loss = 1.40522934, grad/param norm = 7.1278e-02, time/batch = 0.0822s	
1964/3500 (epoch 28.057), train_loss = 1.39699100, grad/param norm = 7.5614e-02, time/batch = 0.0837s	
1965/3500 (epoch 28.071), train_loss = 1.39208194, grad/param norm = 6.9089e-02, time/batch = 0.0844s	
1966/3500 (epoch 28.086), train_loss = 1.39722442, grad/param norm = 6.0060e-02, time/batch = 0.0834s	
1967/3500 (epoch 28.100), train_loss = 1.40846133, grad/param norm = 6.2912e-02, time/batch = 0.0824s	
1968/3500 (epoch 28.114), train_loss = 1.41158466, grad/param norm = 6.1466e-02, time/batch = 0.0822s	
1969/3500 (epoch 28.129), train_loss = 1.40285338, grad/param norm = 5.9463e-02, time/batch = 0.0820s	
1970/3500 (epoch 28.143), train_loss = 1.40505222, grad/param norm = 5.7255e-02, time/batch = 0.0824s	
1971/3500 (epoch 28.157), train_loss = 1.39750040, grad/param norm = 6.4247e-02, time/batch = 0.0833s	
1972/3500 (epoch 28.171), train_loss = 1.39485808, grad/param norm = 6.6161e-02, time/batch = 0.0823s	
1973/3500 (epoch 28.186), train_loss = 1.39881849, grad/param norm = 6.6443e-02, time/batch = 0.0823s	
1974/3500 (epoch 28.200), train_loss = 1.40146133, grad/param norm = 6.9475e-02, time/batch = 0.0838s	
1975/3500 (epoch 28.214), train_loss = 1.39203024, grad/param norm = 7.0633e-02, time/batch = 0.0846s	
1976/3500 (epoch 28.229), train_loss = 1.38480974, grad/param norm = 6.6106e-02, time/batch = 0.0837s	
1977/3500 (epoch 28.243), train_loss = 1.39557398, grad/param norm = 6.7274e-02, time/batch = 0.0826s	
1978/3500 (epoch 28.257), train_loss = 1.40678579, grad/param norm = 7.2291e-02, time/batch = 0.0825s	
1979/3500 (epoch 28.271), train_loss = 1.41541194, grad/param norm = 8.0899e-02, time/batch = 0.0818s	
1980/3500 (epoch 28.286), train_loss = 1.40646182, grad/param norm = 6.9583e-02, time/batch = 0.0825s	
1981/3500 (epoch 28.300), train_loss = 1.42842166, grad/param norm = 6.2588e-02, time/batch = 0.0827s	
1982/3500 (epoch 28.314), train_loss = 1.39558279, grad/param norm = 5.7140e-02, time/batch = 0.0821s	
1983/3500 (epoch 28.329), train_loss = 1.41741232, grad/param norm = 5.3898e-02, time/batch = 0.0822s	
1984/3500 (epoch 28.343), train_loss = 1.40510714, grad/param norm = 5.0669e-02, time/batch = 0.0836s	
1985/3500 (epoch 28.357), train_loss = 1.41106103, grad/param norm = 5.6499e-02, time/batch = 0.0845s	
1986/3500 (epoch 28.371), train_loss = 1.40834624, grad/param norm = 5.6918e-02, time/batch = 0.0836s	
1987/3500 (epoch 28.386), train_loss = 1.38816808, grad/param norm = 6.0501e-02, time/batch = 0.0824s	
1988/3500 (epoch 28.400), train_loss = 1.39387554, grad/param norm = 6.2562e-02, time/batch = 0.0823s	
1989/3500 (epoch 28.414), train_loss = 1.40312096, grad/param norm = 6.1772e-02, time/batch = 0.0820s	
1990/3500 (epoch 28.429), train_loss = 1.36859170, grad/param norm = 5.2258e-02, time/batch = 0.0829s	
1991/3500 (epoch 28.443), train_loss = 1.39544798, grad/param norm = 4.6475e-02, time/batch = 0.0832s	
1992/3500 (epoch 28.457), train_loss = 1.39453117, grad/param norm = 5.1196e-02, time/batch = 0.0824s	
1993/3500 (epoch 28.471), train_loss = 1.40046395, grad/param norm = 5.6865e-02, time/batch = 0.0823s	
1994/3500 (epoch 28.486), train_loss = 1.42096003, grad/param norm = 6.0853e-02, time/batch = 0.0838s	
1995/3500 (epoch 28.500), train_loss = 1.39715155, grad/param norm = 6.8144e-02, time/batch = 0.0845s	
1996/3500 (epoch 28.514), train_loss = 1.41664573, grad/param norm = 7.1008e-02, time/batch = 0.0836s	
1997/3500 (epoch 28.529), train_loss = 1.41841321, grad/param norm = 7.5066e-02, time/batch = 0.0825s	
1998/3500 (epoch 28.543), train_loss = 1.41202627, grad/param norm = 8.1070e-02, time/batch = 0.0825s	
1999/3500 (epoch 28.557), train_loss = 1.37719477, grad/param norm = 8.4211e-02, time/batch = 0.0817s	
evaluating loss over split index 2	
1/4...	
2/4...	
3/4...	
4/4...	
saving checkpoint to cv/lm_lstm_epoch28.57_1.4868.t7	
2000/3500 (epoch 28.571), train_loss = 1.38169009, grad/param norm = 7.7150e-02, time/batch = 0.0829s	
2001/3500 (epoch 28.586), train_loss = 1.60111659, grad/param norm = 9.4230e-02, time/batch = 0.0830s	
2002/3500 (epoch 28.600), train_loss = 1.38652722, grad/param norm = 8.4064e-02, time/batch = 0.0822s	
2003/3500 (epoch 28.614), train_loss = 1.39579172, grad/param norm = 7.0771e-02, time/batch = 0.0822s	
2004/3500 (epoch 28.629), train_loss = 1.37719014, grad/param norm = 7.1268e-02, time/batch = 0.0836s	
2005/3500 (epoch 28.643), train_loss = 1.39762566, grad/param norm = 7.0471e-02, time/batch = 0.0842s	
2006/3500 (epoch 28.657), train_loss = 1.38656941, grad/param norm = 6.8681e-02, time/batch = 0.0839s	
2007/3500 (epoch 28.671), train_loss = 1.36871435, grad/param norm = 7.2780e-02, time/batch = 0.0826s	
2008/3500 (epoch 28.686), train_loss = 1.39739269, grad/param norm = 6.9009e-02, time/batch = 0.0824s	
2009/3500 (epoch 28.700), train_loss = 1.40081103, grad/param norm = 6.9522e-02, time/batch = 0.0822s	
2010/3500 (epoch 28.714), train_loss = 1.39468040, grad/param norm = 7.6665e-02, time/batch = 0.0825s	
2011/3500 (epoch 28.729), train_loss = 1.39546899, grad/param norm = 7.1242e-02, time/batch = 0.0833s	
2012/3500 (epoch 28.743), train_loss = 1.38478274, grad/param norm = 6.6860e-02, time/batch = 0.0824s	
2013/3500 (epoch 28.757), train_loss = 1.40430645, grad/param norm = 6.8614e-02, time/batch = 0.0823s	
2014/3500 (epoch 28.771), train_loss = 1.40148360, grad/param norm = 6.1606e-02, time/batch = 0.0836s	
2015/3500 (epoch 28.786), train_loss = 1.39088043, grad/param norm = 5.2098e-02, time/batch = 0.0841s	
2016/3500 (epoch 28.800), train_loss = 1.37741285, grad/param norm = 5.2604e-02, time/batch = 0.0836s	
2017/3500 (epoch 28.814), train_loss = 1.39094102, grad/param norm = 5.2659e-02, time/batch = 0.0826s	
2018/3500 (epoch 28.829), train_loss = 1.37500520, grad/param norm = 5.3046e-02, time/batch = 0.0825s	
2019/3500 (epoch 28.843), train_loss = 1.41961354, grad/param norm = 5.4345e-02, time/batch = 0.0818s	
2020/3500 (epoch 28.857), train_loss = 1.41632137, grad/param norm = 6.2494e-02, time/batch = 0.0824s	
2021/3500 (epoch 28.871), train_loss = 1.41050292, grad/param norm = 7.6078e-02, time/batch = 0.0827s	
2022/3500 (epoch 28.886), train_loss = 1.40569203, grad/param norm = 7.7079e-02, time/batch = 0.0822s	
2023/3500 (epoch 28.900), train_loss = 1.41248745, grad/param norm = 6.5972e-02, time/batch = 0.0822s	
2024/3500 (epoch 28.914), train_loss = 1.41453770, grad/param norm = 6.3569e-02, time/batch = 0.0836s	
2025/3500 (epoch 28.929), train_loss = 1.39339848, grad/param norm = 6.5012e-02, time/batch = 0.0839s	
2026/3500 (epoch 28.943), train_loss = 1.41109769, grad/param norm = 6.6595e-02, time/batch = 0.0834s	
2027/3500 (epoch 28.957), train_loss = 1.41865311, grad/param norm = 7.1763e-02, time/batch = 0.0824s	
2028/3500 (epoch 28.971), train_loss = 1.41186269, grad/param norm = 7.0994e-02, time/batch = 0.0824s	
2029/3500 (epoch 28.986), train_loss = 1.40626294, grad/param norm = 7.2138e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
2030/3500 (epoch 29.000), train_loss = 1.39854459, grad/param norm = 8.4384e-02, time/batch = 0.0825s	
2031/3500 (epoch 29.014), train_loss = 1.59381879, grad/param norm = 8.1556e-02, time/batch = 0.0834s	
2032/3500 (epoch 29.029), train_loss = 1.40449194, grad/param norm = 6.9308e-02, time/batch = 0.0828s	
2033/3500 (epoch 29.043), train_loss = 1.39799662, grad/param norm = 6.6680e-02, time/batch = 0.0823s	
2034/3500 (epoch 29.057), train_loss = 1.39048079, grad/param norm = 7.6154e-02, time/batch = 0.0836s	
2035/3500 (epoch 29.071), train_loss = 1.38458743, grad/param norm = 6.8690e-02, time/batch = 0.0840s	
2036/3500 (epoch 29.086), train_loss = 1.38946842, grad/param norm = 5.6199e-02, time/batch = 0.0840s	
2037/3500 (epoch 29.100), train_loss = 1.40029570, grad/param norm = 5.9238e-02, time/batch = 0.0826s	
2038/3500 (epoch 29.114), train_loss = 1.40349763, grad/param norm = 5.6292e-02, time/batch = 0.0825s	
2039/3500 (epoch 29.129), train_loss = 1.39487402, grad/param norm = 5.4458e-02, time/batch = 0.0818s	
2040/3500 (epoch 29.143), train_loss = 1.39708910, grad/param norm = 5.3993e-02, time/batch = 0.0823s	
2041/3500 (epoch 29.157), train_loss = 1.38984356, grad/param norm = 6.2855e-02, time/batch = 0.0828s	
2042/3500 (epoch 29.171), train_loss = 1.38695635, grad/param norm = 6.3687e-02, time/batch = 0.0826s	
2043/3500 (epoch 29.186), train_loss = 1.39028668, grad/param norm = 6.2703e-02, time/batch = 0.0822s	
2044/3500 (epoch 29.200), train_loss = 1.39424598, grad/param norm = 6.9218e-02, time/batch = 0.0834s	
2045/3500 (epoch 29.214), train_loss = 1.38662001, grad/param norm = 7.8084e-02, time/batch = 0.0840s	
2046/3500 (epoch 29.229), train_loss = 1.37962553, grad/param norm = 7.4027e-02, time/batch = 0.0835s	
2047/3500 (epoch 29.243), train_loss = 1.38867439, grad/param norm = 6.7340e-02, time/batch = 0.0828s	
2048/3500 (epoch 29.257), train_loss = 1.39851471, grad/param norm = 6.4899e-02, time/batch = 0.0823s	
2049/3500 (epoch 29.271), train_loss = 1.40764020, grad/param norm = 7.3193e-02, time/batch = 0.0820s	
2050/3500 (epoch 29.286), train_loss = 1.39898793, grad/param norm = 6.8802e-02, time/batch = 0.0824s	
2051/3500 (epoch 29.300), train_loss = 1.42075470, grad/param norm = 6.1591e-02, time/batch = 0.0832s	
2052/3500 (epoch 29.314), train_loss = 1.38876240, grad/param norm = 5.8558e-02, time/batch = 0.0836s	
2053/3500 (epoch 29.329), train_loss = 1.41061064, grad/param norm = 5.4539e-02, time/batch = 0.0837s	
2054/3500 (epoch 29.343), train_loss = 1.39849819, grad/param norm = 5.0409e-02, time/batch = 0.0840s	
2055/3500 (epoch 29.357), train_loss = 1.40454849, grad/param norm = 5.7698e-02, time/batch = 0.0843s	
2056/3500 (epoch 29.371), train_loss = 1.40158493, grad/param norm = 5.5998e-02, time/batch = 0.0840s	
2057/3500 (epoch 29.386), train_loss = 1.38092674, grad/param norm = 5.7879e-02, time/batch = 0.0829s	
2058/3500 (epoch 29.400), train_loss = 1.38684845, grad/param norm = 6.0164e-02, time/batch = 0.0825s	
2059/3500 (epoch 29.414), train_loss = 1.39572363, grad/param norm = 5.9541e-02, time/batch = 0.0818s	
2060/3500 (epoch 29.429), train_loss = 1.36223080, grad/param norm = 5.2568e-02, time/batch = 0.0823s	
2061/3500 (epoch 29.443), train_loss = 1.38923456, grad/param norm = 4.8330e-02, time/batch = 0.0828s	
2062/3500 (epoch 29.457), train_loss = 1.38836541, grad/param norm = 5.5050e-02, time/batch = 0.0821s	
2063/3500 (epoch 29.471), train_loss = 1.39559556, grad/param norm = 6.4340e-02, time/batch = 0.0822s	
2064/3500 (epoch 29.486), train_loss = 1.41650665, grad/param norm = 6.9337e-02, time/batch = 0.0835s	
2065/3500 (epoch 29.500), train_loss = 1.39183785, grad/param norm = 7.4348e-02, time/batch = 0.0838s	
2066/3500 (epoch 29.514), train_loss = 1.40990457, grad/param norm = 7.2840e-02, time/batch = 0.0835s	
2067/3500 (epoch 29.529), train_loss = 1.41187053, grad/param norm = 6.9883e-02, time/batch = 0.0829s	
2068/3500 (epoch 29.543), train_loss = 1.40287187, grad/param norm = 6.8118e-02, time/batch = 0.0822s	
2069/3500 (epoch 29.557), train_loss = 1.36713358, grad/param norm = 6.5109e-02, time/batch = 0.0820s	
2070/3500 (epoch 29.571), train_loss = 1.37240715, grad/param norm = 6.0897e-02, time/batch = 0.0824s	
2071/3500 (epoch 29.586), train_loss = 1.37869156, grad/param norm = 6.5620e-02, time/batch = 0.0833s	
2072/3500 (epoch 29.600), train_loss = 1.37449898, grad/param norm = 6.1601e-02, time/batch = 0.0823s	
2073/3500 (epoch 29.614), train_loss = 1.38677540, grad/param norm = 5.5102e-02, time/batch = 0.0823s	
2074/3500 (epoch 29.629), train_loss = 1.36755468, grad/param norm = 5.5004e-02, time/batch = 0.0835s	
2075/3500 (epoch 29.643), train_loss = 1.38802252, grad/param norm = 5.5213e-02, time/batch = 0.0840s	
2076/3500 (epoch 29.657), train_loss = 1.37757107, grad/param norm = 5.7199e-02, time/batch = 0.0836s	
2077/3500 (epoch 29.671), train_loss = 1.36034510, grad/param norm = 6.6938e-02, time/batch = 0.0826s	
2078/3500 (epoch 29.686), train_loss = 1.39087050, grad/param norm = 7.2203e-02, time/batch = 0.0825s	
2079/3500 (epoch 29.700), train_loss = 1.39448661, grad/param norm = 7.4076e-02, time/batch = 0.0818s	
2080/3500 (epoch 29.714), train_loss = 1.38913877, grad/param norm = 8.0098e-02, time/batch = 0.0825s	
2081/3500 (epoch 29.729), train_loss = 1.39005569, grad/param norm = 8.0303e-02, time/batch = 0.0828s	
2082/3500 (epoch 29.743), train_loss = 1.37897137, grad/param norm = 7.8811e-02, time/batch = 0.0821s	
2083/3500 (epoch 29.757), train_loss = 1.39808756, grad/param norm = 7.4692e-02, time/batch = 0.0822s	
2084/3500 (epoch 29.771), train_loss = 1.39557176, grad/param norm = 6.5350e-02, time/batch = 0.0834s	
2085/3500 (epoch 29.786), train_loss = 1.38525922, grad/param norm = 5.7729e-02, time/batch = 0.0839s	
2086/3500 (epoch 29.800), train_loss = 1.37218099, grad/param norm = 5.9175e-02, time/batch = 0.0841s	
2087/3500 (epoch 29.814), train_loss = 1.38645886, grad/param norm = 6.4622e-02, time/batch = 0.0825s	
2088/3500 (epoch 29.829), train_loss = 1.37149578, grad/param norm = 6.6018e-02, time/batch = 0.0822s	
2089/3500 (epoch 29.843), train_loss = 1.41610207, grad/param norm = 7.1810e-02, time/batch = 0.0819s	
2090/3500 (epoch 29.857), train_loss = 1.41206623, grad/param norm = 7.1696e-02, time/batch = 0.0824s	
2091/3500 (epoch 29.871), train_loss = 1.40245683, grad/param norm = 7.0103e-02, time/batch = 0.0832s	
2092/3500 (epoch 29.886), train_loss = 1.39596196, grad/param norm = 5.6887e-02, time/batch = 0.0824s	
2093/3500 (epoch 29.900), train_loss = 1.40269353, grad/param norm = 5.4895e-02, time/batch = 0.0823s	
2094/3500 (epoch 29.914), train_loss = 1.40873160, grad/param norm = 7.7360e-02, time/batch = 0.0838s	
2095/3500 (epoch 29.929), train_loss = 1.39196472, grad/param norm = 9.1861e-02, time/batch = 0.0841s	
2096/3500 (epoch 29.943), train_loss = 1.41025606, grad/param norm = 9.3861e-02, time/batch = 0.0841s	
2097/3500 (epoch 29.957), train_loss = 1.41518085, grad/param norm = 8.7379e-02, time/batch = 0.0830s	
2098/3500 (epoch 29.971), train_loss = 1.40688203, grad/param norm = 7.4521e-02, time/batch = 0.0826s	
2099/3500 (epoch 29.986), train_loss = 1.39962175, grad/param norm = 8.1002e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
2100/3500 (epoch 30.000), train_loss = 1.39178769, grad/param norm = 8.2601e-02, time/batch = 0.0824s	
2101/3500 (epoch 30.014), train_loss = 1.58869514, grad/param norm = 8.9213e-02, time/batch = 0.0828s	
2102/3500 (epoch 30.029), train_loss = 1.40003718, grad/param norm = 8.2835e-02, time/batch = 0.0822s	
2103/3500 (epoch 30.043), train_loss = 1.39282856, grad/param norm = 7.5829e-02, time/batch = 0.0822s	
2104/3500 (epoch 30.057), train_loss = 1.38375198, grad/param norm = 7.3075e-02, time/batch = 0.0834s	
2105/3500 (epoch 30.071), train_loss = 1.37652279, grad/param norm = 6.1749e-02, time/batch = 0.0839s	
2106/3500 (epoch 30.086), train_loss = 1.38160628, grad/param norm = 5.1749e-02, time/batch = 0.0839s	
2107/3500 (epoch 30.100), train_loss = 1.39314806, grad/param norm = 5.5383e-02, time/batch = 0.0824s	
2108/3500 (epoch 30.114), train_loss = 1.39651019, grad/param norm = 5.2415e-02, time/batch = 0.0822s	
2109/3500 (epoch 30.129), train_loss = 1.38781151, grad/param norm = 5.0189e-02, time/batch = 0.0819s	
2110/3500 (epoch 30.143), train_loss = 1.38976926, grad/param norm = 4.9136e-02, time/batch = 0.0825s	
2111/3500 (epoch 30.157), train_loss = 1.38210059, grad/param norm = 5.4191e-02, time/batch = 0.0836s	
2112/3500 (epoch 30.171), train_loss = 1.37896194, grad/param norm = 5.1631e-02, time/batch = 0.0823s	
2113/3500 (epoch 30.186), train_loss = 1.38233222, grad/param norm = 5.1666e-02, time/batch = 0.0823s	
2114/3500 (epoch 30.200), train_loss = 1.38470784, grad/param norm = 5.1794e-02, time/batch = 0.0837s	
2115/3500 (epoch 30.214), train_loss = 1.37604471, grad/param norm = 5.0752e-02, time/batch = 0.0841s	
2116/3500 (epoch 30.229), train_loss = 1.36877514, grad/param norm = 4.9582e-02, time/batch = 0.0840s	
2117/3500 (epoch 30.243), train_loss = 1.38029609, grad/param norm = 5.5309e-02, time/batch = 0.0825s	
2118/3500 (epoch 30.257), train_loss = 1.39192456, grad/param norm = 6.4251e-02, time/batch = 0.0825s	
2119/3500 (epoch 30.271), train_loss = 1.40092535, grad/param norm = 6.6513e-02, time/batch = 0.0818s	
2120/3500 (epoch 30.286), train_loss = 1.39226455, grad/param norm = 6.7859e-02, time/batch = 0.0824s	
2121/3500 (epoch 30.300), train_loss = 1.41544573, grad/param norm = 6.7934e-02, time/batch = 0.0832s	
2122/3500 (epoch 30.314), train_loss = 1.38333575, grad/param norm = 6.0444e-02, time/batch = 0.0821s	
2123/3500 (epoch 30.329), train_loss = 1.40457477, grad/param norm = 5.4765e-02, time/batch = 0.0822s	
2124/3500 (epoch 30.343), train_loss = 1.39246236, grad/param norm = 5.2202e-02, time/batch = 0.0835s	
2125/3500 (epoch 30.357), train_loss = 1.39813301, grad/param norm = 6.3043e-02, time/batch = 0.0840s	
2126/3500 (epoch 30.371), train_loss = 1.39712040, grad/param norm = 6.6596e-02, time/batch = 0.0840s	
2127/3500 (epoch 30.386), train_loss = 1.37592546, grad/param norm = 6.2216e-02, time/batch = 0.0824s	
2128/3500 (epoch 30.400), train_loss = 1.38175770, grad/param norm = 6.3618e-02, time/batch = 0.0823s	
2129/3500 (epoch 30.414), train_loss = 1.39110576, grad/param norm = 6.8929e-02, time/batch = 0.0820s	
2130/3500 (epoch 30.429), train_loss = 1.35858133, grad/param norm = 7.3110e-02, time/batch = 0.0824s	
2131/3500 (epoch 30.443), train_loss = 1.38820431, grad/param norm = 7.4524e-02, time/batch = 0.0837s	
2132/3500 (epoch 30.457), train_loss = 1.38601193, grad/param norm = 7.7400e-02, time/batch = 0.0823s	
2133/3500 (epoch 30.471), train_loss = 1.39100069, grad/param norm = 6.9993e-02, time/batch = 0.0823s	
2134/3500 (epoch 30.486), train_loss = 1.40943868, grad/param norm = 6.6155e-02, time/batch = 0.0836s	
2135/3500 (epoch 30.500), train_loss = 1.38338768, grad/param norm = 6.6102e-02, time/batch = 0.0841s	
2136/3500 (epoch 30.514), train_loss = 1.40127861, grad/param norm = 6.0210e-02, time/batch = 0.0842s	
2137/3500 (epoch 30.529), train_loss = 1.40415414, grad/param norm = 6.1270e-02, time/batch = 0.0825s	
2138/3500 (epoch 30.543), train_loss = 1.39369545, grad/param norm = 6.1587e-02, time/batch = 0.0825s	
2139/3500 (epoch 30.557), train_loss = 1.36019959, grad/param norm = 6.0755e-02, time/batch = 0.0817s	
2140/3500 (epoch 30.571), train_loss = 1.36702784, grad/param norm = 6.3376e-02, time/batch = 0.0823s	
2141/3500 (epoch 30.586), train_loss = 1.37421367, grad/param norm = 7.6116e-02, time/batch = 0.0828s	
2142/3500 (epoch 30.600), train_loss = 1.37052226, grad/param norm = 7.5566e-02, time/batch = 0.0821s	
2143/3500 (epoch 30.614), train_loss = 1.38302886, grad/param norm = 6.3371e-02, time/batch = 0.0822s	
2144/3500 (epoch 30.629), train_loss = 1.36305844, grad/param norm = 6.3516e-02, time/batch = 0.0835s	
2145/3500 (epoch 30.643), train_loss = 1.38262356, grad/param norm = 6.0718e-02, time/batch = 0.0840s	
2146/3500 (epoch 30.657), train_loss = 1.37032989, grad/param norm = 5.5569e-02, time/batch = 0.0844s	
2147/3500 (epoch 30.671), train_loss = 1.35150819, grad/param norm = 5.2683e-02, time/batch = 0.0825s	
2148/3500 (epoch 30.686), train_loss = 1.38210465, grad/param norm = 5.5138e-02, time/batch = 0.0823s	
2149/3500 (epoch 30.700), train_loss = 1.38525442, grad/param norm = 5.5284e-02, time/batch = 0.0820s	
2150/3500 (epoch 30.714), train_loss = 1.37802885, grad/param norm = 5.7382e-02, time/batch = 0.0825s	
2151/3500 (epoch 30.729), train_loss = 1.38014928, grad/param norm = 5.5608e-02, time/batch = 0.0848s	
2152/3500 (epoch 30.743), train_loss = 1.36914162, grad/param norm = 6.2794e-02, time/batch = 0.0831s	
2153/3500 (epoch 30.757), train_loss = 1.39093059, grad/param norm = 7.1282e-02, time/batch = 0.0824s	
2154/3500 (epoch 30.771), train_loss = 1.39071014, grad/param norm = 7.6882e-02, time/batch = 0.0836s	
2155/3500 (epoch 30.786), train_loss = 1.37949819, grad/param norm = 5.5252e-02, time/batch = 0.0842s	
2156/3500 (epoch 30.800), train_loss = 1.36446868, grad/param norm = 5.1932e-02, time/batch = 0.0837s	
2157/3500 (epoch 30.814), train_loss = 1.37850332, grad/param norm = 5.5931e-02, time/batch = 0.0825s	
2158/3500 (epoch 30.829), train_loss = 1.36300016, grad/param norm = 5.8132e-02, time/batch = 0.0824s	
2159/3500 (epoch 30.843), train_loss = 1.40747117, grad/param norm = 5.9622e-02, time/batch = 0.0817s	
2160/3500 (epoch 30.857), train_loss = 1.40568024, grad/param norm = 7.5596e-02, time/batch = 0.0824s	
2161/3500 (epoch 30.871), train_loss = 1.40190693, grad/param norm = 9.3386e-02, time/batch = 0.0828s	
2162/3500 (epoch 30.886), train_loss = 1.39645856, grad/param norm = 9.5999e-02, time/batch = 0.0821s	
2163/3500 (epoch 30.900), train_loss = 1.40211598, grad/param norm = 8.3665e-02, time/batch = 0.0822s	
2164/3500 (epoch 30.914), train_loss = 1.40250019, grad/param norm = 7.5221e-02, time/batch = 0.0834s	
2165/3500 (epoch 30.929), train_loss = 1.38089904, grad/param norm = 6.6786e-02, time/batch = 0.0843s	
2166/3500 (epoch 30.943), train_loss = 1.39672185, grad/param norm = 5.7889e-02, time/batch = 0.0834s	
2167/3500 (epoch 30.957), train_loss = 1.40328425, grad/param norm = 5.9417e-02, time/batch = 0.0824s	
2168/3500 (epoch 30.971), train_loss = 1.39650336, grad/param norm = 5.9594e-02, time/batch = 0.0823s	
2169/3500 (epoch 30.986), train_loss = 1.39181133, grad/param norm = 6.9436e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
2170/3500 (epoch 31.000), train_loss = 1.38594186, grad/param norm = 8.7160e-02, time/batch = 0.0825s	
2171/3500 (epoch 31.014), train_loss = 1.58450658, grad/param norm = 8.4353e-02, time/batch = 0.0832s	
2172/3500 (epoch 31.029), train_loss = 1.39273248, grad/param norm = 7.2034e-02, time/batch = 0.0823s	
2173/3500 (epoch 31.043), train_loss = 1.38596339, grad/param norm = 6.7980e-02, time/batch = 0.0823s	
2174/3500 (epoch 31.057), train_loss = 1.37719406, grad/param norm = 7.4232e-02, time/batch = 0.0836s	
2175/3500 (epoch 31.071), train_loss = 1.37105730, grad/param norm = 6.2462e-02, time/batch = 0.0854s	
2176/3500 (epoch 31.086), train_loss = 1.37559696, grad/param norm = 5.0906e-02, time/batch = 0.0837s	
2177/3500 (epoch 31.100), train_loss = 1.38705292, grad/param norm = 5.6318e-02, time/batch = 0.0826s	
2178/3500 (epoch 31.114), train_loss = 1.39074986, grad/param norm = 5.3310e-02, time/batch = 0.0825s	
2179/3500 (epoch 31.129), train_loss = 1.38126772, grad/param norm = 4.7552e-02, time/batch = 0.0819s	
2180/3500 (epoch 31.143), train_loss = 1.38304779, grad/param norm = 4.5764e-02, time/batch = 0.0824s	
2181/3500 (epoch 31.157), train_loss = 1.37583053, grad/param norm = 5.2338e-02, time/batch = 0.0828s	
2182/3500 (epoch 31.171), train_loss = 1.37262578, grad/param norm = 5.0046e-02, time/batch = 0.0821s	
2183/3500 (epoch 31.186), train_loss = 1.37582982, grad/param norm = 5.0088e-02, time/batch = 0.0822s	
2184/3500 (epoch 31.200), train_loss = 1.37862181, grad/param norm = 5.2290e-02, time/batch = 0.0836s	
2185/3500 (epoch 31.214), train_loss = 1.37065992, grad/param norm = 5.2039e-02, time/batch = 0.0844s	
2186/3500 (epoch 31.229), train_loss = 1.36290258, grad/param norm = 4.9310e-02, time/batch = 0.0835s	
2187/3500 (epoch 31.243), train_loss = 1.37403167, grad/param norm = 5.1851e-02, time/batch = 0.0824s	
2188/3500 (epoch 31.257), train_loss = 1.38478833, grad/param norm = 5.7155e-02, time/batch = 0.0823s	
2189/3500 (epoch 31.271), train_loss = 1.39420993, grad/param norm = 6.0135e-02, time/batch = 0.0820s	
2190/3500 (epoch 31.286), train_loss = 1.38524980, grad/param norm = 6.4999e-02, time/batch = 0.0825s	
2191/3500 (epoch 31.300), train_loss = 1.40846550, grad/param norm = 6.5346e-02, time/batch = 0.0833s	
2192/3500 (epoch 31.314), train_loss = 1.37698438, grad/param norm = 5.7035e-02, time/batch = 0.0823s	
2193/3500 (epoch 31.329), train_loss = 1.39761698, grad/param norm = 5.2186e-02, time/batch = 0.0823s	
2194/3500 (epoch 31.343), train_loss = 1.38677652, grad/param norm = 5.1487e-02, time/batch = 0.0838s	
2195/3500 (epoch 31.357), train_loss = 1.39206288, grad/param norm = 6.0975e-02, time/batch = 0.0845s	
2196/3500 (epoch 31.371), train_loss = 1.39053036, grad/param norm = 5.9184e-02, time/batch = 0.0838s	
2197/3500 (epoch 31.386), train_loss = 1.36957599, grad/param norm = 5.7535e-02, time/batch = 0.0825s	
2198/3500 (epoch 31.400), train_loss = 1.37594214, grad/param norm = 6.2020e-02, time/batch = 0.0824s	
2199/3500 (epoch 31.414), train_loss = 1.38429655, grad/param norm = 6.7409e-02, time/batch = 0.0818s	
2200/3500 (epoch 31.429), train_loss = 1.35258706, grad/param norm = 7.1972e-02, time/batch = 0.0823s	
2201/3500 (epoch 31.443), train_loss = 1.38283219, grad/param norm = 7.6570e-02, time/batch = 0.0827s	
2202/3500 (epoch 31.457), train_loss = 1.38094575, grad/param norm = 8.2967e-02, time/batch = 0.0821s	
2203/3500 (epoch 31.471), train_loss = 1.38657525, grad/param norm = 7.5569e-02, time/batch = 0.0823s	
2204/3500 (epoch 31.486), train_loss = 1.40479461, grad/param norm = 6.9138e-02, time/batch = 0.0834s	
2205/3500 (epoch 31.500), train_loss = 1.37766927, grad/param norm = 6.9615e-02, time/batch = 0.0846s	
2206/3500 (epoch 31.514), train_loss = 1.39654473, grad/param norm = 6.3317e-02, time/batch = 0.0835s	
2207/3500 (epoch 31.529), train_loss = 1.39920909, grad/param norm = 6.2599e-02, time/batch = 0.0824s	
2208/3500 (epoch 31.543), train_loss = 1.38781166, grad/param norm = 6.1502e-02, time/batch = 0.0822s	
2209/3500 (epoch 31.557), train_loss = 1.35484519, grad/param norm = 6.0329e-02, time/batch = 0.0819s	
2210/3500 (epoch 31.571), train_loss = 1.36119007, grad/param norm = 6.5889e-02, time/batch = 0.0828s	
2211/3500 (epoch 31.586), train_loss = 1.36782481, grad/param norm = 7.5719e-02, time/batch = 0.0831s	
2212/3500 (epoch 31.600), train_loss = 1.36310794, grad/param norm = 6.5854e-02, time/batch = 0.0823s	
2213/3500 (epoch 31.614), train_loss = 1.37633848, grad/param norm = 5.6687e-02, time/batch = 0.0823s	
2214/3500 (epoch 31.629), train_loss = 1.35721485, grad/param norm = 6.6944e-02, time/batch = 0.0836s	
2215/3500 (epoch 31.643), train_loss = 1.37792784, grad/param norm = 7.1547e-02, time/batch = 0.0847s	
2216/3500 (epoch 31.657), train_loss = 1.36548330, grad/param norm = 5.5695e-02, time/batch = 0.0836s	
2217/3500 (epoch 31.671), train_loss = 1.34655242, grad/param norm = 5.4872e-02, time/batch = 0.0826s	
2218/3500 (epoch 31.686), train_loss = 1.37731385, grad/param norm = 6.2538e-02, time/batch = 0.0825s	
2219/3500 (epoch 31.700), train_loss = 1.37992780, grad/param norm = 6.0196e-02, time/batch = 0.0818s	
2220/3500 (epoch 31.714), train_loss = 1.37306152, grad/param norm = 6.0518e-02, time/batch = 0.0829s	
2221/3500 (epoch 31.729), train_loss = 1.37453009, grad/param norm = 5.9295e-02, time/batch = 0.0827s	
2222/3500 (epoch 31.743), train_loss = 1.36271142, grad/param norm = 6.0700e-02, time/batch = 0.0822s	
2223/3500 (epoch 31.757), train_loss = 1.38312725, grad/param norm = 5.6607e-02, time/batch = 0.0822s	
2224/3500 (epoch 31.771), train_loss = 1.38247836, grad/param norm = 5.5139e-02, time/batch = 0.0835s	
2225/3500 (epoch 31.786), train_loss = 1.37042717, grad/param norm = 5.4490e-02, time/batch = 0.0845s	
2226/3500 (epoch 31.800), train_loss = 1.35868515, grad/param norm = 5.2924e-02, time/batch = 0.0836s	
2227/3500 (epoch 31.814), train_loss = 1.37185352, grad/param norm = 5.1659e-02, time/batch = 0.0824s	
2228/3500 (epoch 31.829), train_loss = 1.35816140, grad/param norm = 6.1687e-02, time/batch = 0.0822s	
2229/3500 (epoch 31.843), train_loss = 1.40238690, grad/param norm = 5.8499e-02, time/batch = 0.0820s	
2230/3500 (epoch 31.857), train_loss = 1.39820535, grad/param norm = 6.1797e-02, time/batch = 0.0829s	
2231/3500 (epoch 31.871), train_loss = 1.39084121, grad/param norm = 5.8248e-02, time/batch = 0.0832s	
2232/3500 (epoch 31.886), train_loss = 1.38448282, grad/param norm = 6.1898e-02, time/batch = 0.0822s	
2233/3500 (epoch 31.900), train_loss = 1.39182736, grad/param norm = 6.4419e-02, time/batch = 0.0823s	
2234/3500 (epoch 31.914), train_loss = 1.39358275, grad/param norm = 5.9274e-02, time/batch = 0.0838s	
2235/3500 (epoch 31.929), train_loss = 1.37305485, grad/param norm = 5.6561e-02, time/batch = 0.0842s	
2236/3500 (epoch 31.943), train_loss = 1.39080413, grad/param norm = 5.8325e-02, time/batch = 0.0836s	
2237/3500 (epoch 31.957), train_loss = 1.39899325, grad/param norm = 6.4815e-02, time/batch = 0.0825s	
2238/3500 (epoch 31.971), train_loss = 1.39277140, grad/param norm = 7.5617e-02, time/batch = 0.0825s	
2239/3500 (epoch 31.986), train_loss = 1.39010708, grad/param norm = 8.4442e-02, time/batch = 0.0817s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
2240/3500 (epoch 32.000), train_loss = 1.38145701, grad/param norm = 8.8685e-02, time/batch = 0.0829s	
2241/3500 (epoch 32.014), train_loss = 1.57865936, grad/param norm = 7.9326e-02, time/batch = 0.0827s	
2242/3500 (epoch 32.029), train_loss = 1.38511454, grad/param norm = 6.3449e-02, time/batch = 0.0821s	
2243/3500 (epoch 32.043), train_loss = 1.37961261, grad/param norm = 6.2323e-02, time/batch = 0.0822s	
2244/3500 (epoch 32.057), train_loss = 1.37153804, grad/param norm = 6.9950e-02, time/batch = 0.0840s	
2245/3500 (epoch 32.071), train_loss = 1.36481829, grad/param norm = 6.1976e-02, time/batch = 0.0845s	
2246/3500 (epoch 32.086), train_loss = 1.36976827, grad/param norm = 5.1776e-02, time/batch = 0.0834s	
2247/3500 (epoch 32.100), train_loss = 1.38100289, grad/param norm = 5.2732e-02, time/batch = 0.0824s	
2248/3500 (epoch 32.114), train_loss = 1.38473491, grad/param norm = 5.0929e-02, time/batch = 0.0822s	
2249/3500 (epoch 32.129), train_loss = 1.37556880, grad/param norm = 4.8690e-02, time/batch = 0.0820s	
2250/3500 (epoch 32.143), train_loss = 1.37727069, grad/param norm = 4.5718e-02, time/batch = 0.0833s	
2251/3500 (epoch 32.157), train_loss = 1.37028097, grad/param norm = 5.2108e-02, time/batch = 0.0835s	
2252/3500 (epoch 32.171), train_loss = 1.36720408, grad/param norm = 5.1227e-02, time/batch = 0.0823s	
2253/3500 (epoch 32.186), train_loss = 1.36991180, grad/param norm = 5.0526e-02, time/batch = 0.0824s	
2254/3500 (epoch 32.200), train_loss = 1.37321343, grad/param norm = 5.4949e-02, time/batch = 0.0842s	
2255/3500 (epoch 32.214), train_loss = 1.36623378, grad/param norm = 5.8793e-02, time/batch = 0.0841s	
2256/3500 (epoch 32.229), train_loss = 1.35832516, grad/param norm = 5.7043e-02, time/batch = 0.0836s	
2257/3500 (epoch 32.243), train_loss = 1.36923809, grad/param norm = 5.6957e-02, time/batch = 0.0826s	
2258/3500 (epoch 32.257), train_loss = 1.37901355, grad/param norm = 5.6061e-02, time/batch = 0.0825s	
2259/3500 (epoch 32.271), train_loss = 1.38871265, grad/param norm = 6.3743e-02, time/batch = 0.0817s	
2260/3500 (epoch 32.286), train_loss = 1.38012062, grad/param norm = 6.8675e-02, time/batch = 0.0823s	
2261/3500 (epoch 32.300), train_loss = 1.40191584, grad/param norm = 6.2732e-02, time/batch = 0.0827s	
2262/3500 (epoch 32.314), train_loss = 1.37127135, grad/param norm = 5.9866e-02, time/batch = 0.0821s	
2263/3500 (epoch 32.329), train_loss = 1.39266212, grad/param norm = 6.0266e-02, time/batch = 0.0821s	
2264/3500 (epoch 32.343), train_loss = 1.38243450, grad/param norm = 6.0281e-02, time/batch = 0.0840s	
2265/3500 (epoch 32.357), train_loss = 1.38796582, grad/param norm = 6.6784e-02, time/batch = 0.0838s	
2266/3500 (epoch 32.371), train_loss = 1.38531515, grad/param norm = 6.2134e-02, time/batch = 0.0836s	
2267/3500 (epoch 32.386), train_loss = 1.36423460, grad/param norm = 6.3970e-02, time/batch = 0.0824s	
2268/3500 (epoch 32.400), train_loss = 1.37069567, grad/param norm = 6.5156e-02, time/batch = 0.0823s	
2269/3500 (epoch 32.414), train_loss = 1.37658750, grad/param norm = 6.1052e-02, time/batch = 0.0820s	
2270/3500 (epoch 32.429), train_loss = 1.34504546, grad/param norm = 5.6104e-02, time/batch = 0.0824s	
2271/3500 (epoch 32.443), train_loss = 1.37360697, grad/param norm = 5.6374e-02, time/batch = 0.0832s	
2272/3500 (epoch 32.457), train_loss = 1.37076920, grad/param norm = 6.1090e-02, time/batch = 0.0824s	
2273/3500 (epoch 32.471), train_loss = 1.37914729, grad/param norm = 6.7494e-02, time/batch = 0.0823s	
2274/3500 (epoch 32.486), train_loss = 1.40063163, grad/param norm = 6.4931e-02, time/batch = 0.0844s	
2275/3500 (epoch 32.500), train_loss = 1.37136839, grad/param norm = 6.6068e-02, time/batch = 0.0841s	
2276/3500 (epoch 32.514), train_loss = 1.39139693, grad/param norm = 7.9620e-02, time/batch = 0.0835s	
2277/3500 (epoch 32.529), train_loss = 1.39671959, grad/param norm = 7.4316e-02, time/batch = 0.0826s	
2278/3500 (epoch 32.543), train_loss = 1.38610880, grad/param norm = 6.4964e-02, time/batch = 0.0825s	
2279/3500 (epoch 32.557), train_loss = 1.34998903, grad/param norm = 6.3405e-02, time/batch = 0.0822s	
2280/3500 (epoch 32.571), train_loss = 1.35451679, grad/param norm = 5.4977e-02, time/batch = 0.0824s	
2281/3500 (epoch 32.586), train_loss = 1.35849199, grad/param norm = 5.5063e-02, time/batch = 0.0827s	
2282/3500 (epoch 32.600), train_loss = 1.35417862, grad/param norm = 5.0232e-02, time/batch = 0.0821s	
2283/3500 (epoch 32.614), train_loss = 1.36901674, grad/param norm = 5.5466e-02, time/batch = 0.0822s	
2284/3500 (epoch 32.629), train_loss = 1.35164263, grad/param norm = 6.4901e-02, time/batch = 0.0840s	
2285/3500 (epoch 32.643), train_loss = 1.37204066, grad/param norm = 6.0584e-02, time/batch = 0.0838s	
2286/3500 (epoch 32.657), train_loss = 1.35927926, grad/param norm = 5.2580e-02, time/batch = 0.0835s	
2287/3500 (epoch 32.671), train_loss = 1.34154614, grad/param norm = 6.7366e-02, time/batch = 0.0824s	
2288/3500 (epoch 32.686), train_loss = 1.37414924, grad/param norm = 7.8151e-02, time/batch = 0.0824s	
2289/3500 (epoch 32.700), train_loss = 1.37693222, grad/param norm = 7.2882e-02, time/batch = 0.0824s	
2290/3500 (epoch 32.714), train_loss = 1.37033243, grad/param norm = 6.8349e-02, time/batch = 0.0824s	
2291/3500 (epoch 32.729), train_loss = 1.36886195, grad/param norm = 6.0038e-02, time/batch = 0.0832s	
2292/3500 (epoch 32.743), train_loss = 1.35627435, grad/param norm = 5.6247e-02, time/batch = 0.0824s	
2293/3500 (epoch 32.757), train_loss = 1.37642878, grad/param norm = 5.5112e-02, time/batch = 0.0823s	
2294/3500 (epoch 32.771), train_loss = 1.37681417, grad/param norm = 5.6158e-02, time/batch = 0.0849s	
2295/3500 (epoch 32.786), train_loss = 1.36421549, grad/param norm = 5.8209e-02, time/batch = 0.0842s	
2296/3500 (epoch 32.800), train_loss = 1.35440150, grad/param norm = 5.6336e-02, time/batch = 0.0835s	
2297/3500 (epoch 32.814), train_loss = 1.36739454, grad/param norm = 5.9817e-02, time/batch = 0.0826s	
2298/3500 (epoch 32.829), train_loss = 1.35426156, grad/param norm = 7.2080e-02, time/batch = 0.0825s	
2299/3500 (epoch 32.843), train_loss = 1.39881898, grad/param norm = 6.7067e-02, time/batch = 0.0821s	
2300/3500 (epoch 32.857), train_loss = 1.39310026, grad/param norm = 6.1045e-02, time/batch = 0.0824s	
2301/3500 (epoch 32.871), train_loss = 1.38376187, grad/param norm = 5.3563e-02, time/batch = 0.0827s	
2302/3500 (epoch 32.886), train_loss = 1.37715046, grad/param norm = 5.2317e-02, time/batch = 0.0821s	
2303/3500 (epoch 32.900), train_loss = 1.38389717, grad/param norm = 5.1054e-02, time/batch = 0.0822s	
2304/3500 (epoch 32.914), train_loss = 1.38654192, grad/param norm = 5.1703e-02, time/batch = 0.0837s	
2305/3500 (epoch 32.929), train_loss = 1.36801763, grad/param norm = 5.9714e-02, time/batch = 0.0838s	
2306/3500 (epoch 32.943), train_loss = 1.38656568, grad/param norm = 6.4689e-02, time/batch = 0.0834s	
2307/3500 (epoch 32.957), train_loss = 1.39370166, grad/param norm = 7.4804e-02, time/batch = 0.0824s	
2308/3500 (epoch 32.971), train_loss = 1.38669306, grad/param norm = 7.2815e-02, time/batch = 0.0823s	
2309/3500 (epoch 32.986), train_loss = 1.38094511, grad/param norm = 6.6401e-02, time/batch = 0.0824s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
2310/3500 (epoch 33.000), train_loss = 1.37274920, grad/param norm = 7.3565e-02, time/batch = 0.0825s	
2311/3500 (epoch 33.014), train_loss = 1.57475215, grad/param norm = 9.2283e-02, time/batch = 0.0832s	
2312/3500 (epoch 33.029), train_loss = 1.38402928, grad/param norm = 8.5586e-02, time/batch = 0.0823s	
2313/3500 (epoch 33.043), train_loss = 1.37684695, grad/param norm = 7.6328e-02, time/batch = 0.0823s	
2314/3500 (epoch 33.057), train_loss = 1.36765207, grad/param norm = 7.2746e-02, time/batch = 0.0836s	
2315/3500 (epoch 33.071), train_loss = 1.36013459, grad/param norm = 6.6093e-02, time/batch = 0.0840s	
2316/3500 (epoch 33.086), train_loss = 1.36480006, grad/param norm = 5.8965e-02, time/batch = 0.0836s	
2317/3500 (epoch 33.100), train_loss = 1.37655568, grad/param norm = 5.5361e-02, time/batch = 0.0825s	
2318/3500 (epoch 33.114), train_loss = 1.38008738, grad/param norm = 5.3250e-02, time/batch = 0.0825s	
2319/3500 (epoch 33.129), train_loss = 1.37075434, grad/param norm = 5.1348e-02, time/batch = 0.0818s	
2320/3500 (epoch 33.143), train_loss = 1.37209837, grad/param norm = 4.5950e-02, time/batch = 0.0824s	
2321/3500 (epoch 33.157), train_loss = 1.36480343, grad/param norm = 5.0272e-02, time/batch = 0.0827s	
2322/3500 (epoch 33.171), train_loss = 1.36200842, grad/param norm = 4.9872e-02, time/batch = 0.0821s	
2323/3500 (epoch 33.186), train_loss = 1.36442762, grad/param norm = 5.0837e-02, time/batch = 0.0824s	
2324/3500 (epoch 33.200), train_loss = 1.36764463, grad/param norm = 5.3850e-02, time/batch = 0.0837s	
2325/3500 (epoch 33.214), train_loss = 1.36043181, grad/param norm = 5.3219e-02, time/batch = 0.0840s	
2326/3500 (epoch 33.229), train_loss = 1.35193630, grad/param norm = 4.8724e-02, time/batch = 0.0834s	
2327/3500 (epoch 33.243), train_loss = 1.36348478, grad/param norm = 5.1962e-02, time/batch = 0.0824s	
2328/3500 (epoch 33.257), train_loss = 1.37434557, grad/param norm = 6.2001e-02, time/batch = 0.0823s	
2329/3500 (epoch 33.271), train_loss = 1.38401394, grad/param norm = 6.4021e-02, time/batch = 0.0820s	
2330/3500 (epoch 33.286), train_loss = 1.37461806, grad/param norm = 6.8237e-02, time/batch = 0.0824s	
2331/3500 (epoch 33.300), train_loss = 1.39702341, grad/param norm = 6.9391e-02, time/batch = 0.0832s	
2332/3500 (epoch 33.314), train_loss = 1.36644727, grad/param norm = 6.2037e-02, time/batch = 0.0823s	
2333/3500 (epoch 33.329), train_loss = 1.38671465, grad/param norm = 5.9366e-02, time/batch = 0.0823s	
2334/3500 (epoch 33.343), train_loss = 1.37735744, grad/param norm = 5.4637e-02, time/batch = 0.0836s	
2335/3500 (epoch 33.357), train_loss = 1.38084726, grad/param norm = 5.3160e-02, time/batch = 0.0840s	
2336/3500 (epoch 33.371), train_loss = 1.37813695, grad/param norm = 4.8690e-02, time/batch = 0.0835s	
2337/3500 (epoch 33.386), train_loss = 1.35739863, grad/param norm = 5.1670e-02, time/batch = 0.0825s	
2338/3500 (epoch 33.400), train_loss = 1.36388776, grad/param norm = 5.1673e-02, time/batch = 0.0825s	
2339/3500 (epoch 33.414), train_loss = 1.36953723, grad/param norm = 5.1696e-02, time/batch = 0.0818s	
2340/3500 (epoch 33.429), train_loss = 1.33925496, grad/param norm = 5.6430e-02, time/batch = 0.0824s	
2341/3500 (epoch 33.443), train_loss = 1.36961127, grad/param norm = 6.6660e-02, time/batch = 0.0827s	
2342/3500 (epoch 33.457), train_loss = 1.36742511, grad/param norm = 7.3885e-02, time/batch = 0.0821s	
2343/3500 (epoch 33.471), train_loss = 1.37330928, grad/param norm = 6.2504e-02, time/batch = 0.0823s	
2344/3500 (epoch 33.486), train_loss = 1.39282534, grad/param norm = 5.1049e-02, time/batch = 0.0842s	
2345/3500 (epoch 33.500), train_loss = 1.36340116, grad/param norm = 5.3746e-02, time/batch = 0.0839s	
2346/3500 (epoch 33.514), train_loss = 1.38454812, grad/param norm = 6.1020e-02, time/batch = 0.0834s	
2347/3500 (epoch 33.529), train_loss = 1.38922261, grad/param norm = 6.4012e-02, time/batch = 0.0824s	
2348/3500 (epoch 33.543), train_loss = 1.37806504, grad/param norm = 6.5839e-02, time/batch = 0.0823s	
2349/3500 (epoch 33.557), train_loss = 1.34572827, grad/param norm = 6.5512e-02, time/batch = 0.0849s	
2350/3500 (epoch 33.571), train_loss = 1.35186758, grad/param norm = 6.7904e-02, time/batch = 0.0831s	
2351/3500 (epoch 33.586), train_loss = 1.35680836, grad/param norm = 7.2746e-02, time/batch = 0.0835s	
2352/3500 (epoch 33.600), train_loss = 1.35289145, grad/param norm = 7.2062e-02, time/batch = 0.0823s	
2353/3500 (epoch 33.614), train_loss = 1.36702499, grad/param norm = 6.9059e-02, time/batch = 0.0827s	
2354/3500 (epoch 33.629), train_loss = 1.34734285, grad/param norm = 7.1220e-02, time/batch = 0.0836s	
2355/3500 (epoch 33.643), train_loss = 1.36734866, grad/param norm = 6.3237e-02, time/batch = 0.0840s	
2356/3500 (epoch 33.657), train_loss = 1.35386958, grad/param norm = 5.2755e-02, time/batch = 0.0836s	
2357/3500 (epoch 33.671), train_loss = 1.33494858, grad/param norm = 5.7436e-02, time/batch = 0.0825s	
2358/3500 (epoch 33.686), train_loss = 1.36695880, grad/param norm = 6.3534e-02, time/batch = 0.0830s	
2359/3500 (epoch 33.700), train_loss = 1.36942053, grad/param norm = 5.9442e-02, time/batch = 0.0817s	
2360/3500 (epoch 33.714), train_loss = 1.36244869, grad/param norm = 5.8217e-02, time/batch = 0.0823s	
2361/3500 (epoch 33.729), train_loss = 1.36371266, grad/param norm = 5.9227e-02, time/batch = 0.0827s	
2362/3500 (epoch 33.743), train_loss = 1.35253478, grad/param norm = 6.3760e-02, time/batch = 0.0821s	
2363/3500 (epoch 33.757), train_loss = 1.37257922, grad/param norm = 6.0134e-02, time/batch = 0.0827s	
2364/3500 (epoch 33.771), train_loss = 1.37239774, grad/param norm = 5.8407e-02, time/batch = 0.0835s	
2365/3500 (epoch 33.786), train_loss = 1.35876790, grad/param norm = 5.5094e-02, time/batch = 0.0840s	
2366/3500 (epoch 33.800), train_loss = 1.34817668, grad/param norm = 5.3105e-02, time/batch = 0.0835s	
2367/3500 (epoch 33.814), train_loss = 1.36136419, grad/param norm = 5.3390e-02, time/batch = 0.0824s	
2368/3500 (epoch 33.829), train_loss = 1.34767968, grad/param norm = 6.1581e-02, time/batch = 0.0826s	
2369/3500 (epoch 33.843), train_loss = 1.39169289, grad/param norm = 5.5785e-02, time/batch = 0.0820s	
2370/3500 (epoch 33.857), train_loss = 1.38742239, grad/param norm = 6.0011e-02, time/batch = 0.0824s	
2371/3500 (epoch 33.871), train_loss = 1.38012609, grad/param norm = 6.3744e-02, time/batch = 0.0832s	
2372/3500 (epoch 33.886), train_loss = 1.37439875, grad/param norm = 7.1080e-02, time/batch = 0.0823s	
2373/3500 (epoch 33.900), train_loss = 1.38201540, grad/param norm = 6.9936e-02, time/batch = 0.0824s	
2374/3500 (epoch 33.914), train_loss = 1.38273575, grad/param norm = 6.2484e-02, time/batch = 0.0839s	
2375/3500 (epoch 33.929), train_loss = 1.36260381, grad/param norm = 5.7775e-02, time/batch = 0.0843s	
2376/3500 (epoch 33.943), train_loss = 1.37926634, grad/param norm = 5.3820e-02, time/batch = 0.0835s	
2377/3500 (epoch 33.957), train_loss = 1.38657660, grad/param norm = 5.8656e-02, time/batch = 0.0825s	
2378/3500 (epoch 33.971), train_loss = 1.37970160, grad/param norm = 6.3577e-02, time/batch = 0.0828s	
2379/3500 (epoch 33.986), train_loss = 1.37556750, grad/param norm = 6.4391e-02, time/batch = 0.0817s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
2380/3500 (epoch 34.000), train_loss = 1.36687085, grad/param norm = 7.2865e-02, time/batch = 0.0824s	
2381/3500 (epoch 34.014), train_loss = 1.56833284, grad/param norm = 7.5252e-02, time/batch = 0.0827s	
2382/3500 (epoch 34.029), train_loss = 1.37443837, grad/param norm = 6.2883e-02, time/batch = 0.0821s	
2383/3500 (epoch 34.043), train_loss = 1.36933959, grad/param norm = 6.0253e-02, time/batch = 0.0822s	
2384/3500 (epoch 34.057), train_loss = 1.36124650, grad/param norm = 6.8051e-02, time/batch = 0.0835s	
2385/3500 (epoch 34.071), train_loss = 1.35445843, grad/param norm = 6.3225e-02, time/batch = 0.0839s	
2386/3500 (epoch 34.086), train_loss = 1.35921647, grad/param norm = 5.4243e-02, time/batch = 0.0836s	
2387/3500 (epoch 34.100), train_loss = 1.37055486, grad/param norm = 5.1596e-02, time/batch = 0.0825s	
2388/3500 (epoch 34.114), train_loss = 1.37444463, grad/param norm = 5.0379e-02, time/batch = 0.0823s	
2389/3500 (epoch 34.129), train_loss = 1.36519500, grad/param norm = 4.9122e-02, time/batch = 0.0820s	
2390/3500 (epoch 34.143), train_loss = 1.36669503, grad/param norm = 4.4572e-02, time/batch = 0.0824s	
2391/3500 (epoch 34.157), train_loss = 1.35978239, grad/param norm = 4.9782e-02, time/batch = 0.0832s	
2392/3500 (epoch 34.171), train_loss = 1.35678575, grad/param norm = 4.9253e-02, time/batch = 0.0823s	
2393/3500 (epoch 34.186), train_loss = 1.35891464, grad/param norm = 4.9523e-02, time/batch = 0.0827s	
2394/3500 (epoch 34.200), train_loss = 1.36260651, grad/param norm = 5.5047e-02, time/batch = 0.0837s	
2395/3500 (epoch 34.214), train_loss = 1.35623436, grad/param norm = 5.5053e-02, time/batch = 0.0841s	
2396/3500 (epoch 34.229), train_loss = 1.34724946, grad/param norm = 4.9996e-02, time/batch = 0.0836s	
2397/3500 (epoch 34.243), train_loss = 1.35868014, grad/param norm = 5.3231e-02, time/batch = 0.0825s	
2398/3500 (epoch 34.257), train_loss = 1.36834250, grad/param norm = 5.6487e-02, time/batch = 0.0825s	
2399/3500 (epoch 34.271), train_loss = 1.37854291, grad/param norm = 6.6512e-02, time/batch = 0.0818s	
2400/3500 (epoch 34.286), train_loss = 1.36977824, grad/param norm = 6.8550e-02, time/batch = 0.0824s	
2401/3500 (epoch 34.300), train_loss = 1.39060713, grad/param norm = 5.7026e-02, time/batch = 0.0828s	
2402/3500 (epoch 34.314), train_loss = 1.35972914, grad/param norm = 5.1198e-02, time/batch = 0.0822s	
2403/3500 (epoch 34.329), train_loss = 1.38044962, grad/param norm = 4.9280e-02, time/batch = 0.0823s	
2404/3500 (epoch 34.343), train_loss = 1.37002027, grad/param norm = 4.6551e-02, time/batch = 0.0834s	
2405/3500 (epoch 34.357), train_loss = 1.37526768, grad/param norm = 5.0309e-02, time/batch = 0.0838s	
2406/3500 (epoch 34.371), train_loss = 1.37335572, grad/param norm = 5.1059e-02, time/batch = 0.0835s	
2407/3500 (epoch 34.386), train_loss = 1.35299853, grad/param norm = 5.7244e-02, time/batch = 0.0825s	
2408/3500 (epoch 34.400), train_loss = 1.36095574, grad/param norm = 6.1042e-02, time/batch = 0.0823s	
2409/3500 (epoch 34.414), train_loss = 1.36748555, grad/param norm = 6.1227e-02, time/batch = 0.0820s	
2410/3500 (epoch 34.429), train_loss = 1.33520567, grad/param norm = 6.1108e-02, time/batch = 0.0824s	
2411/3500 (epoch 34.443), train_loss = 1.36533375, grad/param norm = 6.3700e-02, time/batch = 0.0832s	
2412/3500 (epoch 34.457), train_loss = 1.36214821, grad/param norm = 6.9275e-02, time/batch = 0.0824s	
2413/3500 (epoch 34.471), train_loss = 1.36860170, grad/param norm = 6.4358e-02, time/batch = 0.0823s	
2414/3500 (epoch 34.486), train_loss = 1.38913073, grad/param norm = 6.5894e-02, time/batch = 0.0839s	
2415/3500 (epoch 34.500), train_loss = 1.36188396, grad/param norm = 7.0495e-02, time/batch = 0.0840s	
2416/3500 (epoch 34.514), train_loss = 1.38079518, grad/param norm = 6.9300e-02, time/batch = 0.0836s	
2417/3500 (epoch 34.529), train_loss = 1.38610373, grad/param norm = 6.7921e-02, time/batch = 0.0825s	
2418/3500 (epoch 34.543), train_loss = 1.37262775, grad/param norm = 6.3249e-02, time/batch = 0.0825s	
2419/3500 (epoch 34.557), train_loss = 1.33953994, grad/param norm = 6.2109e-02, time/batch = 0.0818s	
2420/3500 (epoch 34.571), train_loss = 1.34626218, grad/param norm = 5.9917e-02, time/batch = 0.0824s	
2421/3500 (epoch 34.586), train_loss = 1.34984697, grad/param norm = 6.0552e-02, time/batch = 0.0828s	
2422/3500 (epoch 34.600), train_loss = 1.34553346, grad/param norm = 6.0098e-02, time/batch = 0.0824s	
2423/3500 (epoch 34.614), train_loss = 1.35956006, grad/param norm = 5.5209e-02, time/batch = 0.0822s	
2424/3500 (epoch 34.629), train_loss = 1.33960976, grad/param norm = 5.5405e-02, time/batch = 0.0836s	
2425/3500 (epoch 34.643), train_loss = 1.36041826, grad/param norm = 5.0046e-02, time/batch = 0.0839s	
2426/3500 (epoch 34.657), train_loss = 1.34737745, grad/param norm = 4.6930e-02, time/batch = 0.0835s	
2427/3500 (epoch 34.671), train_loss = 1.32878200, grad/param norm = 5.4620e-02, time/batch = 0.0824s	
2428/3500 (epoch 34.686), train_loss = 1.36177995, grad/param norm = 6.0352e-02, time/batch = 0.0823s	
2429/3500 (epoch 34.700), train_loss = 1.36394752, grad/param norm = 5.6618e-02, time/batch = 0.0819s	
2430/3500 (epoch 34.714), train_loss = 1.35751899, grad/param norm = 5.7207e-02, time/batch = 0.0825s	
2431/3500 (epoch 34.729), train_loss = 1.35806098, grad/param norm = 5.7043e-02, time/batch = 0.0831s	
2432/3500 (epoch 34.743), train_loss = 1.34695339, grad/param norm = 6.0023e-02, time/batch = 0.0828s	
2433/3500 (epoch 34.757), train_loss = 1.36672292, grad/param norm = 5.6971e-02, time/batch = 0.0824s	
2434/3500 (epoch 34.771), train_loss = 1.36698482, grad/param norm = 5.5377e-02, time/batch = 0.0836s	
2435/3500 (epoch 34.786), train_loss = 1.35338114, grad/param norm = 5.6189e-02, time/batch = 0.0841s	
2436/3500 (epoch 34.800), train_loss = 1.34317864, grad/param norm = 5.3568e-02, time/batch = 0.0837s	
2437/3500 (epoch 34.814), train_loss = 1.35647519, grad/param norm = 5.3673e-02, time/batch = 0.0830s	
2438/3500 (epoch 34.829), train_loss = 1.34379922, grad/param norm = 6.8278e-02, time/batch = 0.0825s	
2439/3500 (epoch 34.843), train_loss = 1.38866961, grad/param norm = 6.6373e-02, time/batch = 0.0818s	
2440/3500 (epoch 34.857), train_loss = 1.38299732, grad/param norm = 6.2588e-02, time/batch = 0.0824s	
2441/3500 (epoch 34.871), train_loss = 1.37380779, grad/param norm = 5.1997e-02, time/batch = 0.0827s	
2442/3500 (epoch 34.886), train_loss = 1.36688062, grad/param norm = 5.2105e-02, time/batch = 0.0826s	
2443/3500 (epoch 34.900), train_loss = 1.37447226, grad/param norm = 5.3167e-02, time/batch = 0.0822s	
2444/3500 (epoch 34.914), train_loss = 1.37576600, grad/param norm = 4.7902e-02, time/batch = 0.0835s	
2445/3500 (epoch 34.929), train_loss = 1.35643068, grad/param norm = 4.9618e-02, time/batch = 0.0841s	
2446/3500 (epoch 34.943), train_loss = 1.37470517, grad/param norm = 5.4950e-02, time/batch = 0.0836s	
2447/3500 (epoch 34.957), train_loss = 1.38251801, grad/param norm = 6.5206e-02, time/batch = 0.0829s	
2448/3500 (epoch 34.971), train_loss = 1.37451535, grad/param norm = 6.5118e-02, time/batch = 0.0851s	
2449/3500 (epoch 34.986), train_loss = 1.37063777, grad/param norm = 6.4729e-02, time/batch = 0.0822s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
2450/3500 (epoch 35.000), train_loss = 1.36339081, grad/param norm = 7.6858e-02, time/batch = 0.0825s	
2451/3500 (epoch 35.014), train_loss = 1.56744466, grad/param norm = 9.5251e-02, time/batch = 0.0833s	
2452/3500 (epoch 35.029), train_loss = 1.37394885, grad/param norm = 8.4606e-02, time/batch = 0.0824s	
2453/3500 (epoch 35.043), train_loss = 1.36706482, grad/param norm = 7.3042e-02, time/batch = 0.0823s	
2454/3500 (epoch 35.057), train_loss = 1.35798733, grad/param norm = 7.1304e-02, time/batch = 0.0835s	
2455/3500 (epoch 35.071), train_loss = 1.35074630, grad/param norm = 6.8442e-02, time/batch = 0.0840s	
2456/3500 (epoch 35.086), train_loss = 1.35525889, grad/param norm = 6.1911e-02, time/batch = 0.0835s	
2457/3500 (epoch 35.100), train_loss = 1.36731132, grad/param norm = 5.8463e-02, time/batch = 0.0830s	
2458/3500 (epoch 35.114), train_loss = 1.37111552, grad/param norm = 5.6456e-02, time/batch = 0.0825s	
2459/3500 (epoch 35.129), train_loss = 1.36145875, grad/param norm = 5.4764e-02, time/batch = 0.0817s	
2460/3500 (epoch 35.143), train_loss = 1.36273583, grad/param norm = 4.8239e-02, time/batch = 0.0824s	
2461/3500 (epoch 35.157), train_loss = 1.35532727, grad/param norm = 5.1127e-02, time/batch = 0.0827s	
2462/3500 (epoch 35.171), train_loss = 1.35257250, grad/param norm = 5.0793e-02, time/batch = 0.0821s	
2463/3500 (epoch 35.186), train_loss = 1.35432395, grad/param norm = 5.1278e-02, time/batch = 0.0822s	
2464/3500 (epoch 35.200), train_loss = 1.35769854, grad/param norm = 5.4636e-02, time/batch = 0.0835s	
2465/3500 (epoch 35.214), train_loss = 1.35144104, grad/param norm = 5.3399e-02, time/batch = 0.0839s	
2466/3500 (epoch 35.229), train_loss = 1.34212339, grad/param norm = 4.7080e-02, time/batch = 0.0835s	
2467/3500 (epoch 35.243), train_loss = 1.35358719, grad/param norm = 5.2655e-02, time/batch = 0.0824s	
2468/3500 (epoch 35.257), train_loss = 1.36393930, grad/param norm = 5.9686e-02, time/batch = 0.0822s	
2469/3500 (epoch 35.271), train_loss = 1.37384912, grad/param norm = 6.8527e-02, time/batch = 0.0820s	
2470/3500 (epoch 35.286), train_loss = 1.36458345, grad/param norm = 6.5505e-02, time/batch = 0.0824s	
2471/3500 (epoch 35.300), train_loss = 1.38528595, grad/param norm = 5.5287e-02, time/batch = 0.0832s	
2472/3500 (epoch 35.314), train_loss = 1.35464478, grad/param norm = 5.1277e-02, time/batch = 0.0823s	
2473/3500 (epoch 35.329), train_loss = 1.37545659, grad/param norm = 4.9189e-02, time/batch = 0.0823s	
2474/3500 (epoch 35.343), train_loss = 1.36489150, grad/param norm = 4.5257e-02, time/batch = 0.0835s	
2475/3500 (epoch 35.357), train_loss = 1.37046941, grad/param norm = 4.9548e-02, time/batch = 0.0841s	
2476/3500 (epoch 35.371), train_loss = 1.36858331, grad/param norm = 4.9699e-02, time/batch = 0.0840s	
2477/3500 (epoch 35.386), train_loss = 1.34789732, grad/param norm = 5.3361e-02, time/batch = 0.0826s	
2478/3500 (epoch 35.400), train_loss = 1.35530233, grad/param norm = 5.4801e-02, time/batch = 0.0824s	
2479/3500 (epoch 35.414), train_loss = 1.36091459, grad/param norm = 5.2727e-02, time/batch = 0.0818s	
2480/3500 (epoch 35.429), train_loss = 1.32850829, grad/param norm = 4.7885e-02, time/batch = 0.0823s	
2481/3500 (epoch 35.443), train_loss = 1.35808662, grad/param norm = 4.7365e-02, time/batch = 0.0827s	
2482/3500 (epoch 35.457), train_loss = 1.35407256, grad/param norm = 5.1502e-02, time/batch = 0.0821s	
2483/3500 (epoch 35.471), train_loss = 1.36146427, grad/param norm = 5.0275e-02, time/batch = 0.0823s	
2484/3500 (epoch 35.486), train_loss = 1.38269594, grad/param norm = 4.7323e-02, time/batch = 0.0834s	
2485/3500 (epoch 35.500), train_loss = 1.35329188, grad/param norm = 5.1021e-02, time/batch = 0.0841s	
2486/3500 (epoch 35.514), train_loss = 1.37356305, grad/param norm = 5.4718e-02, time/batch = 0.0838s	
2487/3500 (epoch 35.529), train_loss = 1.37939204, grad/param norm = 5.7068e-02, time/batch = 0.0825s	
2488/3500 (epoch 35.543), train_loss = 1.36733380, grad/param norm = 5.7998e-02, time/batch = 0.0823s	
2489/3500 (epoch 35.557), train_loss = 1.33539799, grad/param norm = 5.8896e-02, time/batch = 0.0820s	
2490/3500 (epoch 35.571), train_loss = 1.34225420, grad/param norm = 6.0868e-02, time/batch = 0.0825s	
2491/3500 (epoch 35.586), train_loss = 1.34614516, grad/param norm = 6.5845e-02, time/batch = 0.0837s	
2492/3500 (epoch 35.600), train_loss = 1.34213235, grad/param norm = 6.6535e-02, time/batch = 0.0827s	
2493/3500 (epoch 35.614), train_loss = 1.35667778, grad/param norm = 6.1913e-02, time/batch = 0.0824s	
2494/3500 (epoch 35.629), train_loss = 1.33624696, grad/param norm = 6.3774e-02, time/batch = 0.0837s	
2495/3500 (epoch 35.643), train_loss = 1.35813521, grad/param norm = 6.4899e-02, time/batch = 0.0840s	
2496/3500 (epoch 35.657), train_loss = 1.34487078, grad/param norm = 6.1254e-02, time/batch = 0.0839s	
2497/3500 (epoch 35.671), train_loss = 1.32484160, grad/param norm = 5.4554e-02, time/batch = 0.0825s	
2498/3500 (epoch 35.686), train_loss = 1.35696819, grad/param norm = 5.5399e-02, time/batch = 0.0825s	
2499/3500 (epoch 35.700), train_loss = 1.35910117, grad/param norm = 5.5716e-02, time/batch = 0.0818s	
2500/3500 (epoch 35.714), train_loss = 1.35238948, grad/param norm = 5.5966e-02, time/batch = 0.0823s	
2501/3500 (epoch 35.729), train_loss = 1.35330324, grad/param norm = 5.5723e-02, time/batch = 0.0831s	
2502/3500 (epoch 35.743), train_loss = 1.34221805, grad/param norm = 6.0602e-02, time/batch = 0.0821s	
2503/3500 (epoch 35.757), train_loss = 1.36180300, grad/param norm = 5.7519e-02, time/batch = 0.0822s	
2504/3500 (epoch 35.771), train_loss = 1.36195120, grad/param norm = 5.2053e-02, time/batch = 0.0833s	
2505/3500 (epoch 35.786), train_loss = 1.34796392, grad/param norm = 4.5013e-02, time/batch = 0.0840s	
2506/3500 (epoch 35.800), train_loss = 1.33630804, grad/param norm = 4.6143e-02, time/batch = 0.0839s	
2507/3500 (epoch 35.814), train_loss = 1.35133057, grad/param norm = 4.7509e-02, time/batch = 0.0824s	
2508/3500 (epoch 35.829), train_loss = 1.33703040, grad/param norm = 5.0885e-02, time/batch = 0.0822s	
2509/3500 (epoch 35.843), train_loss = 1.38131570, grad/param norm = 5.0794e-02, time/batch = 0.0820s	
2510/3500 (epoch 35.857), train_loss = 1.37768973, grad/param norm = 5.7689e-02, time/batch = 0.0824s	
2511/3500 (epoch 35.871), train_loss = 1.37066215, grad/param norm = 6.8429e-02, time/batch = 0.0836s	
2512/3500 (epoch 35.886), train_loss = 1.36592807, grad/param norm = 7.9172e-02, time/batch = 0.0824s	
2513/3500 (epoch 35.900), train_loss = 1.37399254, grad/param norm = 7.7845e-02, time/batch = 0.0823s	
2514/3500 (epoch 35.914), train_loss = 1.37456830, grad/param norm = 7.0229e-02, time/batch = 0.0837s	
2515/3500 (epoch 35.929), train_loss = 1.35465863, grad/param norm = 6.3642e-02, time/batch = 0.0841s	
2516/3500 (epoch 35.943), train_loss = 1.37066217, grad/param norm = 5.6116e-02, time/batch = 0.0840s	
2517/3500 (epoch 35.957), train_loss = 1.37749991, grad/param norm = 6.0354e-02, time/batch = 0.0826s	
2518/3500 (epoch 35.971), train_loss = 1.37012750, grad/param norm = 6.4269e-02, time/batch = 0.0825s	
2519/3500 (epoch 35.986), train_loss = 1.36568481, grad/param norm = 5.7475e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
2520/3500 (epoch 36.000), train_loss = 1.35526869, grad/param norm = 5.9090e-02, time/batch = 0.0823s	
2521/3500 (epoch 36.014), train_loss = 1.55799744, grad/param norm = 6.5937e-02, time/batch = 0.0832s	
2522/3500 (epoch 36.029), train_loss = 1.36391896, grad/param norm = 5.9886e-02, time/batch = 0.0822s	
2523/3500 (epoch 36.043), train_loss = 1.36004990, grad/param norm = 5.6679e-02, time/batch = 0.0822s	
2524/3500 (epoch 36.057), train_loss = 1.35109273, grad/param norm = 5.5931e-02, time/batch = 0.0834s	
2525/3500 (epoch 36.071), train_loss = 1.34397639, grad/param norm = 5.6126e-02, time/batch = 0.0840s	
2526/3500 (epoch 36.086), train_loss = 1.34934765, grad/param norm = 5.6904e-02, time/batch = 0.0840s	
2527/3500 (epoch 36.100), train_loss = 1.36148881, grad/param norm = 5.5877e-02, time/batch = 0.0824s	
2528/3500 (epoch 36.114), train_loss = 1.36581832, grad/param norm = 5.2887e-02, time/batch = 0.0822s	
2529/3500 (epoch 36.129), train_loss = 1.35645493, grad/param norm = 4.9113e-02, time/batch = 0.0820s	
2530/3500 (epoch 36.143), train_loss = 1.35729567, grad/param norm = 4.3909e-02, time/batch = 0.0824s	
2531/3500 (epoch 36.157), train_loss = 1.35065823, grad/param norm = 4.8454e-02, time/batch = 0.0833s	
2532/3500 (epoch 36.171), train_loss = 1.34774310, grad/param norm = 4.8259e-02, time/batch = 0.0823s	
2533/3500 (epoch 36.186), train_loss = 1.34905388, grad/param norm = 4.7364e-02, time/batch = 0.0823s	
2534/3500 (epoch 36.200), train_loss = 1.35291261, grad/param norm = 5.0901e-02, time/batch = 0.0836s	
2535/3500 (epoch 36.214), train_loss = 1.34705548, grad/param norm = 5.2238e-02, time/batch = 0.0840s	
2536/3500 (epoch 36.229), train_loss = 1.33780540, grad/param norm = 4.8196e-02, time/batch = 0.0841s	
2537/3500 (epoch 36.243), train_loss = 1.34910879, grad/param norm = 4.9091e-02, time/batch = 0.0826s	
2538/3500 (epoch 36.257), train_loss = 1.35870028, grad/param norm = 5.2934e-02, time/batch = 0.0824s	
2539/3500 (epoch 36.271), train_loss = 1.36865631, grad/param norm = 5.6013e-02, time/batch = 0.0817s	
2540/3500 (epoch 36.286), train_loss = 1.35952025, grad/param norm = 6.3101e-02, time/batch = 0.0823s	
2541/3500 (epoch 36.300), train_loss = 1.38150676, grad/param norm = 6.6768e-02, time/batch = 0.0828s	
2542/3500 (epoch 36.314), train_loss = 1.35223569, grad/param norm = 6.2684e-02, time/batch = 0.0822s	
2543/3500 (epoch 36.329), train_loss = 1.37200651, grad/param norm = 5.8478e-02, time/batch = 0.0822s	
2544/3500 (epoch 36.343), train_loss = 1.36346088, grad/param norm = 5.5328e-02, time/batch = 0.0836s	
2545/3500 (epoch 36.357), train_loss = 1.36745457, grad/param norm = 5.5001e-02, time/batch = 0.0840s	
2546/3500 (epoch 36.371), train_loss = 1.36469135, grad/param norm = 5.0239e-02, time/batch = 0.0845s	
2547/3500 (epoch 36.386), train_loss = 1.34383010, grad/param norm = 5.0825e-02, time/batch = 0.0839s	
2548/3500 (epoch 36.400), train_loss = 1.35109756, grad/param norm = 5.2107e-02, time/batch = 0.0823s	
2549/3500 (epoch 36.414), train_loss = 1.35580040, grad/param norm = 5.6728e-02, time/batch = 0.0820s	
2550/3500 (epoch 36.429), train_loss = 1.32679699, grad/param norm = 6.6749e-02, time/batch = 0.0824s	
2551/3500 (epoch 36.443), train_loss = 1.35830446, grad/param norm = 7.7058e-02, time/batch = 0.0832s	
2552/3500 (epoch 36.457), train_loss = 1.35428349, grad/param norm = 7.6841e-02, time/batch = 0.0823s	
2553/3500 (epoch 36.471), train_loss = 1.35930753, grad/param norm = 5.8285e-02, time/batch = 0.0823s	
2554/3500 (epoch 36.486), train_loss = 1.37903356, grad/param norm = 5.2303e-02, time/batch = 0.0837s	
2555/3500 (epoch 36.500), train_loss = 1.34945786, grad/param norm = 5.8222e-02, time/batch = 0.0845s	
2556/3500 (epoch 36.514), train_loss = 1.36985835, grad/param norm = 6.1351e-02, time/batch = 0.0837s	
2557/3500 (epoch 36.529), train_loss = 1.37583177, grad/param norm = 5.9476e-02, time/batch = 0.0826s	
2558/3500 (epoch 36.543), train_loss = 1.36253473, grad/param norm = 5.7736e-02, time/batch = 0.0825s	
2559/3500 (epoch 36.557), train_loss = 1.33026964, grad/param norm = 5.6489e-02, time/batch = 0.0818s	
2560/3500 (epoch 36.571), train_loss = 1.33703523, grad/param norm = 5.5631e-02, time/batch = 0.0824s	
2561/3500 (epoch 36.586), train_loss = 1.34022779, grad/param norm = 6.0640e-02, time/batch = 0.0827s	
2562/3500 (epoch 36.600), train_loss = 1.33570729, grad/param norm = 5.7101e-02, time/batch = 0.0821s	
2563/3500 (epoch 36.614), train_loss = 1.35060743, grad/param norm = 5.3829e-02, time/batch = 0.0822s	
2564/3500 (epoch 36.629), train_loss = 1.33043015, grad/param norm = 5.6816e-02, time/batch = 0.0837s	
2565/3500 (epoch 36.643), train_loss = 1.35201858, grad/param norm = 5.0922e-02, time/batch = 0.0843s	
2566/3500 (epoch 36.657), train_loss = 1.33810397, grad/param norm = 4.6804e-02, time/batch = 0.0835s	
2567/3500 (epoch 36.671), train_loss = 1.31928665, grad/param norm = 5.5456e-02, time/batch = 0.0824s	
2568/3500 (epoch 36.686), train_loss = 1.35309527, grad/param norm = 6.0702e-02, time/batch = 0.0822s	
2569/3500 (epoch 36.700), train_loss = 1.35482694, grad/param norm = 5.6045e-02, time/batch = 0.0819s	
2570/3500 (epoch 36.714), train_loss = 1.34855437, grad/param norm = 5.7828e-02, time/batch = 0.0824s	
2571/3500 (epoch 36.729), train_loss = 1.34876490, grad/param norm = 5.7708e-02, time/batch = 0.0832s	
2572/3500 (epoch 36.743), train_loss = 1.33759973, grad/param norm = 5.9166e-02, time/batch = 0.0823s	
2573/3500 (epoch 36.757), train_loss = 1.35705959, grad/param norm = 5.5667e-02, time/batch = 0.0822s	
2574/3500 (epoch 36.771), train_loss = 1.35762717, grad/param norm = 5.3555e-02, time/batch = 0.0838s	
2575/3500 (epoch 36.786), train_loss = 1.34316603, grad/param norm = 5.3993e-02, time/batch = 0.0843s	
2576/3500 (epoch 36.800), train_loss = 1.33342711, grad/param norm = 5.2924e-02, time/batch = 0.0836s	
2577/3500 (epoch 36.814), train_loss = 1.34766740, grad/param norm = 5.5513e-02, time/batch = 0.0826s	
2578/3500 (epoch 36.829), train_loss = 1.33464432, grad/param norm = 6.5954e-02, time/batch = 0.0825s	
2579/3500 (epoch 36.843), train_loss = 1.37922922, grad/param norm = 6.1680e-02, time/batch = 0.0818s	
2580/3500 (epoch 36.857), train_loss = 1.37328882, grad/param norm = 5.4662e-02, time/batch = 0.0826s	
2581/3500 (epoch 36.871), train_loss = 1.36314140, grad/param norm = 4.8253e-02, time/batch = 0.0827s	
2582/3500 (epoch 36.886), train_loss = 1.35682516, grad/param norm = 4.9600e-02, time/batch = 0.0822s	
2583/3500 (epoch 36.900), train_loss = 1.36503402, grad/param norm = 4.8465e-02, time/batch = 0.0822s	
2584/3500 (epoch 36.914), train_loss = 1.36631296, grad/param norm = 4.6631e-02, time/batch = 0.0835s	
2585/3500 (epoch 36.929), train_loss = 1.34797219, grad/param norm = 5.3390e-02, time/batch = 0.0844s	
2586/3500 (epoch 36.943), train_loss = 1.36656365, grad/param norm = 5.9682e-02, time/batch = 0.0834s	
2587/3500 (epoch 36.957), train_loss = 1.37373204, grad/param norm = 6.9443e-02, time/batch = 0.0824s	
2588/3500 (epoch 36.971), train_loss = 1.36581561, grad/param norm = 6.6075e-02, time/batch = 0.0822s	
2589/3500 (epoch 36.986), train_loss = 1.36184294, grad/param norm = 6.1812e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
2590/3500 (epoch 37.000), train_loss = 1.35342239, grad/param norm = 7.2195e-02, time/batch = 0.0824s	
2591/3500 (epoch 37.014), train_loss = 1.55865979, grad/param norm = 8.7642e-02, time/batch = 0.0833s	
2592/3500 (epoch 37.029), train_loss = 1.36342238, grad/param norm = 7.7701e-02, time/batch = 0.0824s	
2593/3500 (epoch 37.043), train_loss = 1.35800172, grad/param norm = 7.0013e-02, time/batch = 0.0823s	
2594/3500 (epoch 37.057), train_loss = 1.34936280, grad/param norm = 7.1504e-02, time/batch = 0.0836s	
2595/3500 (epoch 37.071), train_loss = 1.34131730, grad/param norm = 6.5198e-02, time/batch = 0.0845s	
2596/3500 (epoch 37.086), train_loss = 1.34517678, grad/param norm = 5.5278e-02, time/batch = 0.0836s	
2597/3500 (epoch 37.100), train_loss = 1.35754323, grad/param norm = 5.4711e-02, time/batch = 0.0825s	
2598/3500 (epoch 37.114), train_loss = 1.36194203, grad/param norm = 5.4876e-02, time/batch = 0.0826s	
2599/3500 (epoch 37.129), train_loss = 1.35244436, grad/param norm = 5.2707e-02, time/batch = 0.0818s	
2600/3500 (epoch 37.143), train_loss = 1.35384085, grad/param norm = 4.6782e-02, time/batch = 0.0828s	
2601/3500 (epoch 37.157), train_loss = 1.34671506, grad/param norm = 5.0845e-02, time/batch = 0.0828s	
2602/3500 (epoch 37.171), train_loss = 1.34377812, grad/param norm = 4.9865e-02, time/batch = 0.0822s	
2603/3500 (epoch 37.186), train_loss = 1.34538883, grad/param norm = 5.0698e-02, time/batch = 0.0822s	
2604/3500 (epoch 37.200), train_loss = 1.34865302, grad/param norm = 5.3025e-02, time/batch = 0.0836s	
2605/3500 (epoch 37.214), train_loss = 1.34297536, grad/param norm = 5.0079e-02, time/batch = 0.0844s	
2606/3500 (epoch 37.229), train_loss = 1.33339507, grad/param norm = 4.6446e-02, time/batch = 0.0833s	
2607/3500 (epoch 37.243), train_loss = 1.34515254, grad/param norm = 5.5984e-02, time/batch = 0.0825s	
2608/3500 (epoch 37.257), train_loss = 1.35545930, grad/param norm = 6.0396e-02, time/batch = 0.0822s	
2609/3500 (epoch 37.271), train_loss = 1.36487781, grad/param norm = 6.5002e-02, time/batch = 0.0819s	
2610/3500 (epoch 37.286), train_loss = 1.35502839, grad/param norm = 5.9400e-02, time/batch = 0.0830s	
2611/3500 (epoch 37.300), train_loss = 1.37574274, grad/param norm = 5.4062e-02, time/batch = 0.0832s	
2612/3500 (epoch 37.314), train_loss = 1.34616391, grad/param norm = 5.3332e-02, time/batch = 0.0823s	
2613/3500 (epoch 37.329), train_loss = 1.36665610, grad/param norm = 4.9905e-02, time/batch = 0.0822s	
2614/3500 (epoch 37.343), train_loss = 1.35607425, grad/param norm = 4.4564e-02, time/batch = 0.0837s	
2615/3500 (epoch 37.357), train_loss = 1.36221847, grad/param norm = 4.9965e-02, time/batch = 0.0841s	
2616/3500 (epoch 37.371), train_loss = 1.36047942, grad/param norm = 5.1059e-02, time/batch = 0.0835s	
2617/3500 (epoch 37.386), train_loss = 1.33968923, grad/param norm = 5.4744e-02, time/batch = 0.0825s	
2618/3500 (epoch 37.400), train_loss = 1.34733701, grad/param norm = 5.4422e-02, time/batch = 0.0824s	
2619/3500 (epoch 37.414), train_loss = 1.35190854, grad/param norm = 5.0640e-02, time/batch = 0.0819s	
2620/3500 (epoch 37.429), train_loss = 1.31955522, grad/param norm = 4.5089e-02, time/batch = 0.0830s	
2621/3500 (epoch 37.443), train_loss = 1.34958448, grad/param norm = 4.4340e-02, time/batch = 0.0828s	
2622/3500 (epoch 37.457), train_loss = 1.34479006, grad/param norm = 4.7694e-02, time/batch = 0.0821s	
2623/3500 (epoch 37.471), train_loss = 1.35270319, grad/param norm = 4.7971e-02, time/batch = 0.0822s	
2624/3500 (epoch 37.486), train_loss = 1.37450058, grad/param norm = 4.8479e-02, time/batch = 0.0840s	
2625/3500 (epoch 37.500), train_loss = 1.34457093, grad/param norm = 5.2611e-02, time/batch = 0.0839s	
2626/3500 (epoch 37.514), train_loss = 1.36436266, grad/param norm = 5.0808e-02, time/batch = 0.0833s	
2627/3500 (epoch 37.529), train_loss = 1.37010440, grad/param norm = 4.8952e-02, time/batch = 0.0824s	
2628/3500 (epoch 37.543), train_loss = 1.35705947, grad/param norm = 5.0289e-02, time/batch = 0.0823s	
2629/3500 (epoch 37.557), train_loss = 1.32608607, grad/param norm = 5.6502e-02, time/batch = 0.0820s	
2630/3500 (epoch 37.571), train_loss = 1.33299611, grad/param norm = 5.4346e-02, time/batch = 0.0825s	
2631/3500 (epoch 37.586), train_loss = 1.33619546, grad/param norm = 6.3673e-02, time/batch = 0.0831s	
2632/3500 (epoch 37.600), train_loss = 1.33164635, grad/param norm = 6.0738e-02, time/batch = 0.0824s	
2633/3500 (epoch 37.614), train_loss = 1.34703721, grad/param norm = 5.8911e-02, time/batch = 0.0823s	
2634/3500 (epoch 37.629), train_loss = 1.32764466, grad/param norm = 6.3623e-02, time/batch = 0.0840s	
2635/3500 (epoch 37.643), train_loss = 1.35011462, grad/param norm = 6.4268e-02, time/batch = 0.0840s	
2636/3500 (epoch 37.657), train_loss = 1.33737716, grad/param norm = 6.8202e-02, time/batch = 0.0836s	
2637/3500 (epoch 37.671), train_loss = 1.31903306, grad/param norm = 8.0353e-02, time/batch = 0.0826s	
2638/3500 (epoch 37.686), train_loss = 1.35247118, grad/param norm = 7.7679e-02, time/batch = 0.0825s	
2639/3500 (epoch 37.700), train_loss = 1.35267037, grad/param norm = 6.7911e-02, time/batch = 0.0818s	
2640/3500 (epoch 37.714), train_loss = 1.34663283, grad/param norm = 6.8428e-02, time/batch = 0.0823s	
2641/3500 (epoch 37.729), train_loss = 1.34425922, grad/param norm = 5.8567e-02, time/batch = 0.0827s	
2642/3500 (epoch 37.743), train_loss = 1.33277969, grad/param norm = 5.3115e-02, time/batch = 0.0821s	
2643/3500 (epoch 37.757), train_loss = 1.35155935, grad/param norm = 4.9650e-02, time/batch = 0.0823s	
2644/3500 (epoch 37.771), train_loss = 1.35265127, grad/param norm = 4.7670e-02, time/batch = 0.0840s	
2645/3500 (epoch 37.786), train_loss = 1.33778416, grad/param norm = 4.8943e-02, time/batch = 0.0849s	
2646/3500 (epoch 37.800), train_loss = 1.32847410, grad/param norm = 4.9201e-02, time/batch = 0.0844s	
2647/3500 (epoch 37.814), train_loss = 1.34331348, grad/param norm = 5.2714e-02, time/batch = 0.0825s	
2648/3500 (epoch 37.829), train_loss = 1.33009323, grad/param norm = 6.1672e-02, time/batch = 0.0823s	
2649/3500 (epoch 37.843), train_loss = 1.37409161, grad/param norm = 5.6018e-02, time/batch = 0.0820s	
2650/3500 (epoch 37.857), train_loss = 1.36882911, grad/param norm = 5.2056e-02, time/batch = 0.0825s	
2651/3500 (epoch 37.871), train_loss = 1.35916746, grad/param norm = 5.2381e-02, time/batch = 0.0833s	
2652/3500 (epoch 37.886), train_loss = 1.35291659, grad/param norm = 5.3361e-02, time/batch = 0.0823s	
2653/3500 (epoch 37.900), train_loss = 1.36058047, grad/param norm = 4.8718e-02, time/batch = 0.0824s	
2654/3500 (epoch 37.914), train_loss = 1.36193172, grad/param norm = 4.5809e-02, time/batch = 0.0839s	
2655/3500 (epoch 37.929), train_loss = 1.34327001, grad/param norm = 4.8624e-02, time/batch = 0.0840s	
2656/3500 (epoch 37.943), train_loss = 1.36077510, grad/param norm = 4.8060e-02, time/batch = 0.0835s	
2657/3500 (epoch 37.957), train_loss = 1.36707844, grad/param norm = 5.4439e-02, time/batch = 0.0825s	
2658/3500 (epoch 37.971), train_loss = 1.35953969, grad/param norm = 5.1755e-02, time/batch = 0.0825s	
2659/3500 (epoch 37.986), train_loss = 1.35543561, grad/param norm = 4.4567e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
2660/3500 (epoch 38.000), train_loss = 1.34596997, grad/param norm = 5.5573e-02, time/batch = 0.0823s	
2661/3500 (epoch 38.014), train_loss = 1.55179574, grad/param norm = 6.9621e-02, time/batch = 0.0827s	
2662/3500 (epoch 38.029), train_loss = 1.35681518, grad/param norm = 6.6350e-02, time/batch = 0.0821s	
2663/3500 (epoch 38.043), train_loss = 1.35370708, grad/param norm = 6.7124e-02, time/batch = 0.0823s	
2664/3500 (epoch 38.057), train_loss = 1.34527169, grad/param norm = 6.9699e-02, time/batch = 0.0840s	
2665/3500 (epoch 38.071), train_loss = 1.33700868, grad/param norm = 6.4964e-02, time/batch = 0.0839s	
2666/3500 (epoch 38.086), train_loss = 1.34112706, grad/param norm = 5.8158e-02, time/batch = 0.0835s	
2667/3500 (epoch 38.100), train_loss = 1.35372480, grad/param norm = 5.6256e-02, time/batch = 0.0824s	
2668/3500 (epoch 38.114), train_loss = 1.35815984, grad/param norm = 5.5575e-02, time/batch = 0.0822s	
2669/3500 (epoch 38.129), train_loss = 1.34882083, grad/param norm = 5.5465e-02, time/batch = 0.0820s	
2670/3500 (epoch 38.143), train_loss = 1.35017586, grad/param norm = 4.9130e-02, time/batch = 0.0824s	
2671/3500 (epoch 38.157), train_loss = 1.34323344, grad/param norm = 5.2457e-02, time/batch = 0.0832s	
2672/3500 (epoch 38.171), train_loss = 1.34029577, grad/param norm = 5.2507e-02, time/batch = 0.0823s	
2673/3500 (epoch 38.186), train_loss = 1.34157794, grad/param norm = 5.2360e-02, time/batch = 0.0823s	
2674/3500 (epoch 38.200), train_loss = 1.34511928, grad/param norm = 5.5406e-02, time/batch = 0.0841s	
2675/3500 (epoch 38.214), train_loss = 1.33989030, grad/param norm = 5.3789e-02, time/batch = 0.0839s	
2676/3500 (epoch 38.229), train_loss = 1.32996220, grad/param norm = 4.9346e-02, time/batch = 0.0837s	
2677/3500 (epoch 38.243), train_loss = 1.34143593, grad/param norm = 5.5554e-02, time/batch = 0.0825s	
2678/3500 (epoch 38.257), train_loss = 1.35115882, grad/param norm = 5.6887e-02, time/batch = 0.0824s	
2679/3500 (epoch 38.271), train_loss = 1.36048822, grad/param norm = 5.9089e-02, time/batch = 0.0821s	
2680/3500 (epoch 38.286), train_loss = 1.35057235, grad/param norm = 5.7660e-02, time/batch = 0.0824s	
2681/3500 (epoch 38.300), train_loss = 1.37130900, grad/param norm = 5.3255e-02, time/batch = 0.0827s	
2682/3500 (epoch 38.314), train_loss = 1.34205633, grad/param norm = 4.9967e-02, time/batch = 0.0821s	
2683/3500 (epoch 38.329), train_loss = 1.36202954, grad/param norm = 4.8517e-02, time/batch = 0.0822s	
2684/3500 (epoch 38.343), train_loss = 1.35207386, grad/param norm = 4.5166e-02, time/batch = 0.0838s	
2685/3500 (epoch 38.357), train_loss = 1.35814217, grad/param norm = 4.8550e-02, time/batch = 0.0838s	
2686/3500 (epoch 38.371), train_loss = 1.35630994, grad/param norm = 4.7657e-02, time/batch = 0.0833s	
2687/3500 (epoch 38.386), train_loss = 1.33562098, grad/param norm = 5.2880e-02, time/batch = 0.0824s	
2688/3500 (epoch 38.400), train_loss = 1.34365926, grad/param norm = 5.4699e-02, time/batch = 0.0822s	
2689/3500 (epoch 38.414), train_loss = 1.34759102, grad/param norm = 5.0109e-02, time/batch = 0.0825s	
2690/3500 (epoch 38.429), train_loss = 1.31552991, grad/param norm = 4.4078e-02, time/batch = 0.0828s	
2691/3500 (epoch 38.443), train_loss = 1.34561588, grad/param norm = 4.3418e-02, time/batch = 0.0831s	
2692/3500 (epoch 38.457), train_loss = 1.34056113, grad/param norm = 4.7217e-02, time/batch = 0.0823s	
2693/3500 (epoch 38.471), train_loss = 1.34876752, grad/param norm = 4.8221e-02, time/batch = 0.0823s	
2694/3500 (epoch 38.486), train_loss = 1.37101255, grad/param norm = 4.9128e-02, time/batch = 0.0837s	
2695/3500 (epoch 38.500), train_loss = 1.34071362, grad/param norm = 5.6065e-02, time/batch = 0.0841s	
2696/3500 (epoch 38.514), train_loss = 1.36099928, grad/param norm = 5.7966e-02, time/batch = 0.0837s	
2697/3500 (epoch 38.529), train_loss = 1.36731469, grad/param norm = 5.5256e-02, time/batch = 0.0825s	
2698/3500 (epoch 38.543), train_loss = 1.35444930, grad/param norm = 5.6421e-02, time/batch = 0.0824s	
2699/3500 (epoch 38.557), train_loss = 1.32353319, grad/param norm = 6.5015e-02, time/batch = 0.0823s	
2700/3500 (epoch 38.571), train_loss = 1.33031475, grad/param norm = 6.1159e-02, time/batch = 0.0824s	
2701/3500 (epoch 38.586), train_loss = 1.33223417, grad/param norm = 6.5066e-02, time/batch = 0.0827s	
2702/3500 (epoch 38.600), train_loss = 1.32741498, grad/param norm = 5.9850e-02, time/batch = 0.0821s	
2703/3500 (epoch 38.614), train_loss = 1.34301110, grad/param norm = 5.9898e-02, time/batch = 0.0822s	
2704/3500 (epoch 38.629), train_loss = 1.32403684, grad/param norm = 6.4917e-02, time/batch = 0.0835s	
2705/3500 (epoch 38.643), train_loss = 1.34581101, grad/param norm = 6.0945e-02, time/batch = 0.0839s	
2706/3500 (epoch 38.657), train_loss = 1.33139603, grad/param norm = 5.7491e-02, time/batch = 0.0833s	
2707/3500 (epoch 38.671), train_loss = 1.31227543, grad/param norm = 6.6997e-02, time/batch = 0.0824s	
2708/3500 (epoch 38.686), train_loss = 1.34653782, grad/param norm = 6.8723e-02, time/batch = 0.0822s	
2709/3500 (epoch 38.700), train_loss = 1.34736955, grad/param norm = 6.0621e-02, time/batch = 0.0820s	
2710/3500 (epoch 38.714), train_loss = 1.34119667, grad/param norm = 5.9550e-02, time/batch = 0.0825s	
2711/3500 (epoch 38.729), train_loss = 1.33936996, grad/param norm = 5.2373e-02, time/batch = 0.0833s	
2712/3500 (epoch 38.743), train_loss = 1.32813559, grad/param norm = 5.0656e-02, time/batch = 0.0824s	
2713/3500 (epoch 38.757), train_loss = 1.34718691, grad/param norm = 4.7826e-02, time/batch = 0.0823s	
2714/3500 (epoch 38.771), train_loss = 1.34878194, grad/param norm = 4.8022e-02, time/batch = 0.0835s	
2715/3500 (epoch 38.786), train_loss = 1.33364773, grad/param norm = 5.0755e-02, time/batch = 0.0840s	
2716/3500 (epoch 38.800), train_loss = 1.32439433, grad/param norm = 4.9323e-02, time/batch = 0.0835s	
2717/3500 (epoch 38.814), train_loss = 1.33914443, grad/param norm = 4.9921e-02, time/batch = 0.0825s	
2718/3500 (epoch 38.829), train_loss = 1.32616387, grad/param norm = 5.8562e-02, time/batch = 0.0824s	
2719/3500 (epoch 38.843), train_loss = 1.36967641, grad/param norm = 5.4772e-02, time/batch = 0.0818s	
2720/3500 (epoch 38.857), train_loss = 1.36467207, grad/param norm = 5.1875e-02, time/batch = 0.0823s	
2721/3500 (epoch 38.871), train_loss = 1.35518452, grad/param norm = 5.1042e-02, time/batch = 0.0827s	
2722/3500 (epoch 38.886), train_loss = 1.34898541, grad/param norm = 5.3117e-02, time/batch = 0.0821s	
2723/3500 (epoch 38.900), train_loss = 1.35681525, grad/param norm = 4.8991e-02, time/batch = 0.0822s	
2724/3500 (epoch 38.914), train_loss = 1.35780206, grad/param norm = 4.5052e-02, time/batch = 0.0834s	
2725/3500 (epoch 38.929), train_loss = 1.33902813, grad/param norm = 4.5552e-02, time/batch = 0.0839s	
2726/3500 (epoch 38.943), train_loss = 1.35659591, grad/param norm = 4.4636e-02, time/batch = 0.0834s	
2727/3500 (epoch 38.957), train_loss = 1.36284257, grad/param norm = 4.9908e-02, time/batch = 0.0823s	
2728/3500 (epoch 38.971), train_loss = 1.35513952, grad/param norm = 4.9170e-02, time/batch = 0.0822s	
2729/3500 (epoch 38.986), train_loss = 1.35182278, grad/param norm = 4.8632e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
2730/3500 (epoch 39.000), train_loss = 1.34334832, grad/param norm = 6.3440e-02, time/batch = 0.0824s	
2731/3500 (epoch 39.014), train_loss = 1.55014019, grad/param norm = 7.4570e-02, time/batch = 0.0832s	
2732/3500 (epoch 39.029), train_loss = 1.35320190, grad/param norm = 6.5914e-02, time/batch = 0.0824s	
2733/3500 (epoch 39.043), train_loss = 1.34960100, grad/param norm = 6.2674e-02, time/batch = 0.0824s	
2734/3500 (epoch 39.057), train_loss = 1.34083603, grad/param norm = 6.7791e-02, time/batch = 0.0835s	
2735/3500 (epoch 39.071), train_loss = 1.33271942, grad/param norm = 6.2444e-02, time/batch = 0.0840s	
2736/3500 (epoch 39.086), train_loss = 1.33652733, grad/param norm = 5.3175e-02, time/batch = 0.0835s	
2737/3500 (epoch 39.100), train_loss = 1.34886028, grad/param norm = 5.1581e-02, time/batch = 0.0825s	
2738/3500 (epoch 39.114), train_loss = 1.35352403, grad/param norm = 5.2330e-02, time/batch = 0.0825s	
2739/3500 (epoch 39.129), train_loss = 1.34441873, grad/param norm = 5.2340e-02, time/batch = 0.0818s	
2740/3500 (epoch 39.143), train_loss = 1.34601741, grad/param norm = 4.7292e-02, time/batch = 0.0824s	
2741/3500 (epoch 39.157), train_loss = 1.33946924, grad/param norm = 5.2411e-02, time/batch = 0.0827s	
2742/3500 (epoch 39.171), train_loss = 1.33659284, grad/param norm = 5.2908e-02, time/batch = 0.0823s	
2743/3500 (epoch 39.186), train_loss = 1.33769232, grad/param norm = 5.2803e-02, time/batch = 0.0826s	
2744/3500 (epoch 39.200), train_loss = 1.34139472, grad/param norm = 5.6476e-02, time/batch = 0.0868s	
2745/3500 (epoch 39.214), train_loss = 1.33673139, grad/param norm = 5.6007e-02, time/batch = 0.0847s	
2746/3500 (epoch 39.229), train_loss = 1.32670393, grad/param norm = 5.3048e-02, time/batch = 0.0835s	
2747/3500 (epoch 39.243), train_loss = 1.33798376, grad/param norm = 5.8695e-02, time/batch = 0.0824s	
2748/3500 (epoch 39.257), train_loss = 1.34757068, grad/param norm = 5.5908e-02, time/batch = 0.0823s	
2749/3500 (epoch 39.271), train_loss = 1.35635782, grad/param norm = 5.4583e-02, time/batch = 0.0820s	
2750/3500 (epoch 39.286), train_loss = 1.34620191, grad/param norm = 5.3240e-02, time/batch = 0.0825s	
2751/3500 (epoch 39.300), train_loss = 1.36711157, grad/param norm = 5.2671e-02, time/batch = 0.0833s	
2752/3500 (epoch 39.314), train_loss = 1.33821632, grad/param norm = 5.0810e-02, time/batch = 0.0823s	
2753/3500 (epoch 39.329), train_loss = 1.35817931, grad/param norm = 4.8189e-02, time/batch = 0.0827s	
2754/3500 (epoch 39.343), train_loss = 1.34802811, grad/param norm = 4.4737e-02, time/batch = 0.0836s	
2755/3500 (epoch 39.357), train_loss = 1.35483647, grad/param norm = 5.1037e-02, time/batch = 0.0840s	
2756/3500 (epoch 39.371), train_loss = 1.35305214, grad/param norm = 5.0572e-02, time/batch = 0.0836s	
2757/3500 (epoch 39.386), train_loss = 1.33234854, grad/param norm = 5.5385e-02, time/batch = 0.0826s	
2758/3500 (epoch 39.400), train_loss = 1.34036622, grad/param norm = 5.5052e-02, time/batch = 0.0829s	
2759/3500 (epoch 39.414), train_loss = 1.34361841, grad/param norm = 4.9205e-02, time/batch = 0.0817s	
2760/3500 (epoch 39.429), train_loss = 1.31163244, grad/param norm = 4.3280e-02, time/batch = 0.0823s	
2761/3500 (epoch 39.443), train_loss = 1.34196367, grad/param norm = 4.2840e-02, time/batch = 0.0827s	
2762/3500 (epoch 39.457), train_loss = 1.33661255, grad/param norm = 4.7053e-02, time/batch = 0.0821s	
2763/3500 (epoch 39.471), train_loss = 1.34545998, grad/param norm = 5.0886e-02, time/batch = 0.0827s	
2764/3500 (epoch 39.486), train_loss = 1.36809034, grad/param norm = 5.4633e-02, time/batch = 0.0835s	
2765/3500 (epoch 39.500), train_loss = 1.33771170, grad/param norm = 6.0793e-02, time/batch = 0.0839s	
2766/3500 (epoch 39.514), train_loss = 1.35731483, grad/param norm = 5.7551e-02, time/batch = 0.0833s	
2767/3500 (epoch 39.529), train_loss = 1.36355772, grad/param norm = 5.4593e-02, time/batch = 0.0824s	
2768/3500 (epoch 39.543), train_loss = 1.35039317, grad/param norm = 5.7206e-02, time/batch = 0.0830s	
2769/3500 (epoch 39.557), train_loss = 1.31961663, grad/param norm = 6.4414e-02, time/batch = 0.0820s	
2770/3500 (epoch 39.571), train_loss = 1.32641330, grad/param norm = 5.8141e-02, time/batch = 0.0824s	
2771/3500 (epoch 39.586), train_loss = 1.32804184, grad/param norm = 6.2828e-02, time/batch = 0.0832s	
2772/3500 (epoch 39.600), train_loss = 1.32314367, grad/param norm = 5.7391e-02, time/batch = 0.0823s	
2773/3500 (epoch 39.614), train_loss = 1.33866195, grad/param norm = 5.4730e-02, time/batch = 0.0823s	
2774/3500 (epoch 39.629), train_loss = 1.31915829, grad/param norm = 5.9161e-02, time/batch = 0.0835s	
2775/3500 (epoch 39.643), train_loss = 1.34116556, grad/param norm = 5.5064e-02, time/batch = 0.0841s	
2776/3500 (epoch 39.657), train_loss = 1.32640246, grad/param norm = 5.1604e-02, time/batch = 0.0836s	
2777/3500 (epoch 39.671), train_loss = 1.30734674, grad/param norm = 6.1235e-02, time/batch = 0.0825s	
2778/3500 (epoch 39.686), train_loss = 1.34210249, grad/param norm = 6.3445e-02, time/batch = 0.0830s	
2779/3500 (epoch 39.700), train_loss = 1.34301601, grad/param norm = 5.7475e-02, time/batch = 0.0817s	
2780/3500 (epoch 39.714), train_loss = 1.33716499, grad/param norm = 5.8741e-02, time/batch = 0.0825s	
2781/3500 (epoch 39.729), train_loss = 1.33546883, grad/param norm = 5.2865e-02, time/batch = 0.0827s	
2782/3500 (epoch 39.743), train_loss = 1.32448535, grad/param norm = 5.1295e-02, time/batch = 0.0821s	
2783/3500 (epoch 39.757), train_loss = 1.34333077, grad/param norm = 4.8022e-02, time/batch = 0.0822s	
2784/3500 (epoch 39.771), train_loss = 1.34490268, grad/param norm = 4.6870e-02, time/batch = 0.0835s	
2785/3500 (epoch 39.786), train_loss = 1.32951296, grad/param norm = 4.8727e-02, time/batch = 0.0838s	
2786/3500 (epoch 39.800), train_loss = 1.32007227, grad/param norm = 4.8428e-02, time/batch = 0.0834s	
2787/3500 (epoch 39.814), train_loss = 1.33541516, grad/param norm = 4.9497e-02, time/batch = 0.0824s	
2788/3500 (epoch 39.829), train_loss = 1.32232478, grad/param norm = 5.6687e-02, time/batch = 0.0823s	
2789/3500 (epoch 39.843), train_loss = 1.36589154, grad/param norm = 5.4357e-02, time/batch = 0.0821s	
2790/3500 (epoch 39.857), train_loss = 1.36082838, grad/param norm = 5.0579e-02, time/batch = 0.0825s	
2791/3500 (epoch 39.871), train_loss = 1.35107785, grad/param norm = 4.9733e-02, time/batch = 0.0832s	
2792/3500 (epoch 39.886), train_loss = 1.34497431, grad/param norm = 5.1885e-02, time/batch = 0.0823s	
2793/3500 (epoch 39.900), train_loss = 1.35298913, grad/param norm = 4.7935e-02, time/batch = 0.0824s	
2794/3500 (epoch 39.914), train_loss = 1.35384778, grad/param norm = 4.4402e-02, time/batch = 0.0838s	
2795/3500 (epoch 39.929), train_loss = 1.33533462, grad/param norm = 4.5714e-02, time/batch = 0.0841s	
2796/3500 (epoch 39.943), train_loss = 1.35297280, grad/param norm = 4.5274e-02, time/batch = 0.0836s	
2797/3500 (epoch 39.957), train_loss = 1.35912663, grad/param norm = 5.1038e-02, time/batch = 0.0826s	
2798/3500 (epoch 39.971), train_loss = 1.35140099, grad/param norm = 5.0241e-02, time/batch = 0.0825s	
2799/3500 (epoch 39.986), train_loss = 1.34795449, grad/param norm = 4.6370e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
2800/3500 (epoch 40.000), train_loss = 1.33894632, grad/param norm = 5.8979e-02, time/batch = 0.0823s	
2801/3500 (epoch 40.014), train_loss = 1.54622249, grad/param norm = 7.1961e-02, time/batch = 0.0827s	
2802/3500 (epoch 40.029), train_loss = 1.34911070, grad/param norm = 6.5572e-02, time/batch = 0.0822s	
2803/3500 (epoch 40.043), train_loss = 1.34603006, grad/param norm = 6.2539e-02, time/batch = 0.0822s	
2804/3500 (epoch 40.057), train_loss = 1.33714545, grad/param norm = 6.5454e-02, time/batch = 0.0835s	
2805/3500 (epoch 40.071), train_loss = 1.32892826, grad/param norm = 6.1848e-02, time/batch = 0.0838s	
2806/3500 (epoch 40.086), train_loss = 1.33275020, grad/param norm = 5.4632e-02, time/batch = 0.0833s	
2807/3500 (epoch 40.100), train_loss = 1.34529049, grad/param norm = 5.2550e-02, time/batch = 0.0824s	
2808/3500 (epoch 40.114), train_loss = 1.35005614, grad/param norm = 5.3017e-02, time/batch = 0.0823s	
2809/3500 (epoch 40.129), train_loss = 1.34103219, grad/param norm = 5.4246e-02, time/batch = 0.0819s	
2810/3500 (epoch 40.143), train_loss = 1.34258040, grad/param norm = 4.8699e-02, time/batch = 0.0824s	
2811/3500 (epoch 40.157), train_loss = 1.33609790, grad/param norm = 5.2966e-02, time/batch = 0.0832s	
2812/3500 (epoch 40.171), train_loss = 1.33321595, grad/param norm = 5.3374e-02, time/batch = 0.0823s	
2813/3500 (epoch 40.186), train_loss = 1.33395546, grad/param norm = 5.2586e-02, time/batch = 0.0824s	
2814/3500 (epoch 40.200), train_loss = 1.33754613, grad/param norm = 5.5538e-02, time/batch = 0.0836s	
2815/3500 (epoch 40.214), train_loss = 1.33310895, grad/param norm = 5.4595e-02, time/batch = 0.0841s	
2816/3500 (epoch 40.229), train_loss = 1.32280944, grad/param norm = 5.0712e-02, time/batch = 0.0836s	
2817/3500 (epoch 40.243), train_loss = 1.33405186, grad/param norm = 5.5828e-02, time/batch = 0.0826s	
2818/3500 (epoch 40.257), train_loss = 1.34358535, grad/param norm = 5.4018e-02, time/batch = 0.0825s	
2819/3500 (epoch 40.271), train_loss = 1.35247737, grad/param norm = 5.3452e-02, time/batch = 0.0817s	
2820/3500 (epoch 40.286), train_loss = 1.34265343, grad/param norm = 5.3621e-02, time/batch = 0.0823s	
2821/3500 (epoch 40.300), train_loss = 1.36324876, grad/param norm = 5.1942e-02, time/batch = 0.0828s	
2822/3500 (epoch 40.314), train_loss = 1.33440489, grad/param norm = 4.8186e-02, time/batch = 0.0826s	
2823/3500 (epoch 40.329), train_loss = 1.35398653, grad/param norm = 4.7313e-02, time/batch = 0.0822s	
2824/3500 (epoch 40.343), train_loss = 1.34443261, grad/param norm = 4.5064e-02, time/batch = 0.0834s	
2825/3500 (epoch 40.357), train_loss = 1.35100796, grad/param norm = 4.8929e-02, time/batch = 0.0838s	
2826/3500 (epoch 40.371), train_loss = 1.34922066, grad/param norm = 4.6949e-02, time/batch = 0.0835s	
2827/3500 (epoch 40.386), train_loss = 1.32830297, grad/param norm = 5.0659e-02, time/batch = 0.0824s	
2828/3500 (epoch 40.400), train_loss = 1.33644847, grad/param norm = 5.2596e-02, time/batch = 0.0823s	
2829/3500 (epoch 40.414), train_loss = 1.33950315, grad/param norm = 4.8959e-02, time/batch = 0.0820s	
2830/3500 (epoch 40.429), train_loss = 1.30822950, grad/param norm = 4.5812e-02, time/batch = 0.0824s	
2831/3500 (epoch 40.443), train_loss = 1.33907372, grad/param norm = 4.7093e-02, time/batch = 0.0832s	
2832/3500 (epoch 40.457), train_loss = 1.33339832, grad/param norm = 5.1220e-02, time/batch = 0.0828s	
2833/3500 (epoch 40.471), train_loss = 1.34154507, grad/param norm = 4.8760e-02, time/batch = 0.0824s	
2834/3500 (epoch 40.486), train_loss = 1.36354169, grad/param norm = 4.5224e-02, time/batch = 0.0836s	
2835/3500 (epoch 40.500), train_loss = 1.33197658, grad/param norm = 4.8066e-02, time/batch = 0.0841s	
2836/3500 (epoch 40.514), train_loss = 1.35262643, grad/param norm = 5.0668e-02, time/batch = 0.0836s	
2837/3500 (epoch 40.529), train_loss = 1.36017677, grad/param norm = 5.4620e-02, time/batch = 0.0830s	
2838/3500 (epoch 40.543), train_loss = 1.34619142, grad/param norm = 5.5070e-02, time/batch = 0.0828s	
2839/3500 (epoch 40.557), train_loss = 1.31545794, grad/param norm = 5.6636e-02, time/batch = 0.0818s	
2840/3500 (epoch 40.571), train_loss = 1.32366457, grad/param norm = 5.9981e-02, time/batch = 0.0824s	
2841/3500 (epoch 40.586), train_loss = 1.32558792, grad/param norm = 6.5053e-02, time/batch = 0.0827s	
2842/3500 (epoch 40.600), train_loss = 1.32146167, grad/param norm = 6.6747e-02, time/batch = 0.0826s	
2843/3500 (epoch 40.614), train_loss = 1.33669881, grad/param norm = 6.1178e-02, time/batch = 0.0875s	
2844/3500 (epoch 40.629), train_loss = 1.31605192, grad/param norm = 6.3805e-02, time/batch = 0.0842s	
2845/3500 (epoch 40.643), train_loss = 1.33864531, grad/param norm = 6.3470e-02, time/batch = 0.0841s	
2846/3500 (epoch 40.657), train_loss = 1.32318567, grad/param norm = 5.4708e-02, time/batch = 0.0836s	
2847/3500 (epoch 40.671), train_loss = 1.30279722, grad/param norm = 4.9558e-02, time/batch = 0.0829s	
2848/3500 (epoch 40.686), train_loss = 1.33720583, grad/param norm = 5.2549e-02, time/batch = 0.0822s	
2849/3500 (epoch 40.700), train_loss = 1.33839248, grad/param norm = 5.0657e-02, time/batch = 0.0820s	
2850/3500 (epoch 40.714), train_loss = 1.33204236, grad/param norm = 5.0303e-02, time/batch = 0.0824s	
2851/3500 (epoch 40.729), train_loss = 1.33132010, grad/param norm = 4.8745e-02, time/batch = 0.0833s	
2852/3500 (epoch 40.743), train_loss = 1.32086491, grad/param norm = 5.2718e-02, time/batch = 0.0824s	
2853/3500 (epoch 40.757), train_loss = 1.33985178, grad/param norm = 4.9225e-02, time/batch = 0.0823s	
2854/3500 (epoch 40.771), train_loss = 1.34146781, grad/param norm = 4.6609e-02, time/batch = 0.0836s	
2855/3500 (epoch 40.786), train_loss = 1.32575410, grad/param norm = 4.5802e-02, time/batch = 0.0839s	
2856/3500 (epoch 40.800), train_loss = 1.31580958, grad/param norm = 4.6424e-02, time/batch = 0.0835s	
2857/3500 (epoch 40.814), train_loss = 1.33162904, grad/param norm = 4.6779e-02, time/batch = 0.0830s	
2858/3500 (epoch 40.829), train_loss = 1.31829180, grad/param norm = 5.1348e-02, time/batch = 0.0824s	
2859/3500 (epoch 40.843), train_loss = 1.36157569, grad/param norm = 4.9728e-02, time/batch = 0.0818s	
2860/3500 (epoch 40.857), train_loss = 1.35732415, grad/param norm = 5.1269e-02, time/batch = 0.0824s	
2861/3500 (epoch 40.871), train_loss = 1.34843428, grad/param norm = 5.7703e-02, time/batch = 0.0827s	
2862/3500 (epoch 40.886), train_loss = 1.34303399, grad/param norm = 6.4065e-02, time/batch = 0.0821s	
2863/3500 (epoch 40.900), train_loss = 1.35120776, grad/param norm = 5.9141e-02, time/batch = 0.0823s	
2864/3500 (epoch 40.914), train_loss = 1.35135246, grad/param norm = 5.2869e-02, time/batch = 0.0836s	
2865/3500 (epoch 40.929), train_loss = 1.33282110, grad/param norm = 5.2099e-02, time/batch = 0.0839s	
2866/3500 (epoch 40.943), train_loss = 1.35022696, grad/param norm = 4.9728e-02, time/batch = 0.0834s	
2867/3500 (epoch 40.957), train_loss = 1.35628411, grad/param norm = 5.4548e-02, time/batch = 0.0825s	
2868/3500 (epoch 40.971), train_loss = 1.34899879, grad/param norm = 5.7587e-02, time/batch = 0.0822s	
2869/3500 (epoch 40.986), train_loss = 1.34608861, grad/param norm = 5.8700e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
2870/3500 (epoch 41.000), train_loss = 1.33675535, grad/param norm = 6.8678e-02, time/batch = 0.0825s	
2871/3500 (epoch 41.014), train_loss = 1.54304792, grad/param norm = 7.0011e-02, time/batch = 0.0833s	
2872/3500 (epoch 41.029), train_loss = 1.34379071, grad/param norm = 5.6992e-02, time/batch = 0.0823s	
2873/3500 (epoch 41.043), train_loss = 1.34154923, grad/param norm = 5.7059e-02, time/batch = 0.0823s	
2874/3500 (epoch 41.057), train_loss = 1.33332591, grad/param norm = 6.4664e-02, time/batch = 0.0836s	
2875/3500 (epoch 41.071), train_loss = 1.32484926, grad/param norm = 5.8055e-02, time/batch = 0.0838s	
2876/3500 (epoch 41.086), train_loss = 1.32835240, grad/param norm = 4.7616e-02, time/batch = 0.0840s	
2877/3500 (epoch 41.100), train_loss = 1.34087510, grad/param norm = 4.9961e-02, time/batch = 0.0826s	
2878/3500 (epoch 41.114), train_loss = 1.34598880, grad/param norm = 5.1522e-02, time/batch = 0.0824s	
2879/3500 (epoch 41.129), train_loss = 1.33682626, grad/param norm = 4.8441e-02, time/batch = 0.0818s	
2880/3500 (epoch 41.143), train_loss = 1.33841955, grad/param norm = 4.4284e-02, time/batch = 0.0824s	
2881/3500 (epoch 41.157), train_loss = 1.33221580, grad/param norm = 5.0569e-02, time/batch = 0.0827s	
2882/3500 (epoch 41.171), train_loss = 1.32895928, grad/param norm = 4.7940e-02, time/batch = 0.0821s	
2883/3500 (epoch 41.186), train_loss = 1.32981886, grad/param norm = 4.7784e-02, time/batch = 0.0821s	
2884/3500 (epoch 41.200), train_loss = 1.33296978, grad/param norm = 4.8337e-02, time/batch = 0.0836s	
2885/3500 (epoch 41.214), train_loss = 1.32879642, grad/param norm = 4.6998e-02, time/batch = 0.0838s	
2886/3500 (epoch 41.229), train_loss = 1.31873293, grad/param norm = 4.6815e-02, time/batch = 0.0839s	
2887/3500 (epoch 41.243), train_loss = 1.32991788, grad/param norm = 5.2534e-02, time/batch = 0.0824s	
2888/3500 (epoch 41.257), train_loss = 1.34001208, grad/param norm = 5.1810e-02, time/batch = 0.0823s	
2889/3500 (epoch 41.271), train_loss = 1.34874180, grad/param norm = 5.1308e-02, time/batch = 0.0820s	
2890/3500 (epoch 41.286), train_loss = 1.33940581, grad/param norm = 5.3583e-02, time/batch = 0.0824s	
2891/3500 (epoch 41.300), train_loss = 1.36009598, grad/param norm = 5.3703e-02, time/batch = 0.0832s	
2892/3500 (epoch 41.314), train_loss = 1.33116483, grad/param norm = 5.0411e-02, time/batch = 0.0823s	
2893/3500 (epoch 41.329), train_loss = 1.35100976, grad/param norm = 5.1277e-02, time/batch = 0.0823s	
2894/3500 (epoch 41.343), train_loss = 1.34148514, grad/param norm = 5.0642e-02, time/batch = 0.0836s	
2895/3500 (epoch 41.357), train_loss = 1.34864086, grad/param norm = 5.8838e-02, time/batch = 0.0841s	
2896/3500 (epoch 41.371), train_loss = 1.34783824, grad/param norm = 5.9291e-02, time/batch = 0.0839s	
2897/3500 (epoch 41.386), train_loss = 1.32611218, grad/param norm = 5.6277e-02, time/batch = 0.0826s	
2898/3500 (epoch 41.400), train_loss = 1.33365720, grad/param norm = 5.4617e-02, time/batch = 0.0824s	
2899/3500 (epoch 41.414), train_loss = 1.33645347, grad/param norm = 5.4143e-02, time/batch = 0.0818s	
2900/3500 (epoch 41.429), train_loss = 1.30573606, grad/param norm = 5.3666e-02, time/batch = 0.0824s	
2901/3500 (epoch 41.443), train_loss = 1.33709735, grad/param norm = 5.3493e-02, time/batch = 0.0831s	
2902/3500 (epoch 41.457), train_loss = 1.33042059, grad/param norm = 5.4231e-02, time/batch = 0.0822s	
2903/3500 (epoch 41.471), train_loss = 1.33834460, grad/param norm = 4.9445e-02, time/batch = 0.0822s	
2904/3500 (epoch 41.486), train_loss = 1.36018134, grad/param norm = 4.7005e-02, time/batch = 0.0834s	
2905/3500 (epoch 41.500), train_loss = 1.32868399, grad/param norm = 4.8641e-02, time/batch = 0.0838s	
2906/3500 (epoch 41.514), train_loss = 1.34887136, grad/param norm = 4.8347e-02, time/batch = 0.0839s	
2907/3500 (epoch 41.529), train_loss = 1.35635820, grad/param norm = 5.1196e-02, time/batch = 0.0824s	
2908/3500 (epoch 41.543), train_loss = 1.34173314, grad/param norm = 5.0759e-02, time/batch = 0.0822s	
2909/3500 (epoch 41.557), train_loss = 1.31126066, grad/param norm = 5.2739e-02, time/batch = 0.0820s	
2910/3500 (epoch 41.571), train_loss = 1.31938523, grad/param norm = 5.2600e-02, time/batch = 0.0825s	
2911/3500 (epoch 41.586), train_loss = 1.32132466, grad/param norm = 6.1542e-02, time/batch = 0.0836s	
2912/3500 (epoch 41.600), train_loss = 1.31673421, grad/param norm = 6.0312e-02, time/batch = 0.0823s	
2913/3500 (epoch 41.614), train_loss = 1.33192685, grad/param norm = 5.2094e-02, time/batch = 0.0823s	
2914/3500 (epoch 41.629), train_loss = 1.31113727, grad/param norm = 5.3547e-02, time/batch = 0.0835s	
2915/3500 (epoch 41.643), train_loss = 1.33376109, grad/param norm = 4.9632e-02, time/batch = 0.0839s	
2916/3500 (epoch 41.657), train_loss = 1.31815555, grad/param norm = 4.5935e-02, time/batch = 0.0841s	
2917/3500 (epoch 41.671), train_loss = 1.29868690, grad/param norm = 5.0573e-02, time/batch = 0.0826s	
2918/3500 (epoch 41.686), train_loss = 1.33405673, grad/param norm = 5.3977e-02, time/batch = 0.0825s	
2919/3500 (epoch 41.700), train_loss = 1.33509247, grad/param norm = 5.0594e-02, time/batch = 0.0818s	
2920/3500 (epoch 41.714), train_loss = 1.32901373, grad/param norm = 5.2744e-02, time/batch = 0.0824s	
2921/3500 (epoch 41.729), train_loss = 1.32813711, grad/param norm = 5.1531e-02, time/batch = 0.0832s	
2922/3500 (epoch 41.743), train_loss = 1.31770322, grad/param norm = 5.3513e-02, time/batch = 0.0821s	
2923/3500 (epoch 41.757), train_loss = 1.33641071, grad/param norm = 4.9985e-02, time/batch = 0.0822s	
2924/3500 (epoch 41.771), train_loss = 1.33816683, grad/param norm = 4.7807e-02, time/batch = 0.0834s	
2925/3500 (epoch 41.786), train_loss = 1.32215050, grad/param norm = 4.8555e-02, time/batch = 0.0838s	
2926/3500 (epoch 41.800), train_loss = 1.31257860, grad/param norm = 4.8193e-02, time/batch = 0.0839s	
2927/3500 (epoch 41.814), train_loss = 1.32856836, grad/param norm = 4.9895e-02, time/batch = 0.0824s	
2928/3500 (epoch 41.829), train_loss = 1.31560740, grad/param norm = 5.7185e-02, time/batch = 0.0823s	
2929/3500 (epoch 41.843), train_loss = 1.35917019, grad/param norm = 5.4710e-02, time/batch = 0.0819s	
2930/3500 (epoch 41.857), train_loss = 1.35379619, grad/param norm = 4.8847e-02, time/batch = 0.0824s	
2931/3500 (epoch 41.871), train_loss = 1.34356241, grad/param norm = 4.6941e-02, time/batch = 0.0831s	
2932/3500 (epoch 41.886), train_loss = 1.33760302, grad/param norm = 5.0340e-02, time/batch = 0.0824s	
2933/3500 (epoch 41.900), train_loss = 1.34619486, grad/param norm = 4.7138e-02, time/batch = 0.0822s	
2934/3500 (epoch 41.914), train_loss = 1.34660902, grad/param norm = 4.3751e-02, time/batch = 0.0836s	
2935/3500 (epoch 41.929), train_loss = 1.32860624, grad/param norm = 4.7064e-02, time/batch = 0.0841s	
2936/3500 (epoch 41.943), train_loss = 1.34658717, grad/param norm = 4.8697e-02, time/batch = 0.0842s	
2937/3500 (epoch 41.957), train_loss = 1.35256070, grad/param norm = 5.4701e-02, time/batch = 0.0830s	
2938/3500 (epoch 41.971), train_loss = 1.34454347, grad/param norm = 5.1754e-02, time/batch = 0.0825s	
2939/3500 (epoch 41.986), train_loss = 1.34136007, grad/param norm = 4.7664e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
2940/3500 (epoch 42.000), train_loss = 1.33218158, grad/param norm = 5.9879e-02, time/batch = 0.0824s	
2941/3500 (epoch 42.014), train_loss = 1.54050553, grad/param norm = 7.3196e-02, time/batch = 0.0827s	
2942/3500 (epoch 42.029), train_loss = 1.34227664, grad/param norm = 6.8594e-02, time/batch = 0.0845s	
2943/3500 (epoch 42.043), train_loss = 1.34004337, grad/param norm = 6.7182e-02, time/batch = 0.0824s	
2944/3500 (epoch 42.057), train_loss = 1.33112354, grad/param norm = 6.7454e-02, time/batch = 0.0840s	
2945/3500 (epoch 42.071), train_loss = 1.32206509, grad/param norm = 6.0509e-02, time/batch = 0.0841s	
2946/3500 (epoch 42.086), train_loss = 1.32536041, grad/param norm = 5.1638e-02, time/batch = 0.0835s	
2947/3500 (epoch 42.100), train_loss = 1.33829794, grad/param norm = 5.3598e-02, time/batch = 0.0824s	
2948/3500 (epoch 42.114), train_loss = 1.34329761, grad/param norm = 5.4242e-02, time/batch = 0.0822s	
2949/3500 (epoch 42.129), train_loss = 1.33415612, grad/param norm = 5.3029e-02, time/batch = 0.0820s	
2950/3500 (epoch 42.143), train_loss = 1.33578895, grad/param norm = 4.8088e-02, time/batch = 0.0825s	
2951/3500 (epoch 42.157), train_loss = 1.32942331, grad/param norm = 5.2864e-02, time/batch = 0.0832s	
2952/3500 (epoch 42.171), train_loss = 1.32621073, grad/param norm = 5.0443e-02, time/batch = 0.0823s	
2953/3500 (epoch 42.186), train_loss = 1.32677332, grad/param norm = 4.9270e-02, time/batch = 0.0823s	
2954/3500 (epoch 42.200), train_loss = 1.32966432, grad/param norm = 4.8737e-02, time/batch = 0.0837s	
2955/3500 (epoch 42.214), train_loss = 1.32571734, grad/param norm = 4.8042e-02, time/batch = 0.0845s	
2956/3500 (epoch 42.229), train_loss = 1.31547814, grad/param norm = 4.7272e-02, time/batch = 0.0837s	
2957/3500 (epoch 42.243), train_loss = 1.32664408, grad/param norm = 5.2088e-02, time/batch = 0.0826s	
2958/3500 (epoch 42.257), train_loss = 1.33663995, grad/param norm = 5.1165e-02, time/batch = 0.0826s	
2959/3500 (epoch 42.271), train_loss = 1.34509605, grad/param norm = 4.9181e-02, time/batch = 0.0818s	
2960/3500 (epoch 42.286), train_loss = 1.33570385, grad/param norm = 5.0954e-02, time/batch = 0.0824s	
2961/3500 (epoch 42.300), train_loss = 1.35628577, grad/param norm = 5.1784e-02, time/batch = 0.0827s	
2962/3500 (epoch 42.314), train_loss = 1.32745083, grad/param norm = 4.7504e-02, time/batch = 0.0821s	
2963/3500 (epoch 42.329), train_loss = 1.34690357, grad/param norm = 4.8247e-02, time/batch = 0.0822s	
2964/3500 (epoch 42.343), train_loss = 1.33775030, grad/param norm = 4.7355e-02, time/batch = 0.0833s	
2965/3500 (epoch 42.357), train_loss = 1.34477705, grad/param norm = 5.2553e-02, time/batch = 0.0843s	
2966/3500 (epoch 42.371), train_loss = 1.34336924, grad/param norm = 4.9056e-02, time/batch = 0.0837s	
2967/3500 (epoch 42.386), train_loss = 1.32186961, grad/param norm = 4.8952e-02, time/batch = 0.0825s	
2968/3500 (epoch 42.400), train_loss = 1.32975524, grad/param norm = 4.9811e-02, time/batch = 0.0822s	
2969/3500 (epoch 42.414), train_loss = 1.33220022, grad/param norm = 4.8001e-02, time/batch = 0.0820s	
2970/3500 (epoch 42.429), train_loss = 1.30159245, grad/param norm = 4.6721e-02, time/batch = 0.0824s	
2971/3500 (epoch 42.443), train_loss = 1.33314393, grad/param norm = 4.8200e-02, time/batch = 0.0832s	
2972/3500 (epoch 42.457), train_loss = 1.32663606, grad/param norm = 5.1994e-02, time/batch = 0.0823s	
2973/3500 (epoch 42.471), train_loss = 1.33511132, grad/param norm = 4.9256e-02, time/batch = 0.0824s	
2974/3500 (epoch 42.486), train_loss = 1.35724125, grad/param norm = 4.5118e-02, time/batch = 0.0835s	
2975/3500 (epoch 42.500), train_loss = 1.32491862, grad/param norm = 4.6071e-02, time/batch = 0.0843s	
2976/3500 (epoch 42.514), train_loss = 1.34538644, grad/param norm = 4.6279e-02, time/batch = 0.0836s	
2977/3500 (epoch 42.529), train_loss = 1.35298359, grad/param norm = 4.9339e-02, time/batch = 0.0825s	
2978/3500 (epoch 42.543), train_loss = 1.33839470, grad/param norm = 4.8829e-02, time/batch = 0.0824s	
2979/3500 (epoch 42.557), train_loss = 1.30812456, grad/param norm = 5.0775e-02, time/batch = 0.0818s	
2980/3500 (epoch 42.571), train_loss = 1.31629965, grad/param norm = 5.3200e-02, time/batch = 0.0824s	
2981/3500 (epoch 42.586), train_loss = 1.31803803, grad/param norm = 6.1682e-02, time/batch = 0.0827s	
2982/3500 (epoch 42.600), train_loss = 1.31350530, grad/param norm = 6.1236e-02, time/batch = 0.0820s	
2983/3500 (epoch 42.614), train_loss = 1.32901669, grad/param norm = 5.2968e-02, time/batch = 0.0822s	
2984/3500 (epoch 42.629), train_loss = 1.30823396, grad/param norm = 5.5644e-02, time/batch = 0.0835s	
2985/3500 (epoch 42.643), train_loss = 1.33118918, grad/param norm = 5.4054e-02, time/batch = 0.0842s	
2986/3500 (epoch 42.657), train_loss = 1.31512176, grad/param norm = 4.8518e-02, time/batch = 0.0840s	
2987/3500 (epoch 42.671), train_loss = 1.29527924, grad/param norm = 4.9253e-02, time/batch = 0.0825s	
2988/3500 (epoch 42.686), train_loss = 1.33074677, grad/param norm = 5.2595e-02, time/batch = 0.0822s	
2989/3500 (epoch 42.700), train_loss = 1.33176636, grad/param norm = 4.9981e-02, time/batch = 0.0819s	
2990/3500 (epoch 42.714), train_loss = 1.32550198, grad/param norm = 5.0995e-02, time/batch = 0.0824s	
2991/3500 (epoch 42.729), train_loss = 1.32455157, grad/param norm = 5.0103e-02, time/batch = 0.0832s	
2992/3500 (epoch 42.743), train_loss = 1.31414842, grad/param norm = 5.2628e-02, time/batch = 0.0823s	
2993/3500 (epoch 42.757), train_loss = 1.33289329, grad/param norm = 4.9130e-02, time/batch = 0.0823s	
2994/3500 (epoch 42.771), train_loss = 1.33488146, grad/param norm = 4.6926e-02, time/batch = 0.0836s	
2995/3500 (epoch 42.786), train_loss = 1.31854342, grad/param norm = 4.7750e-02, time/batch = 0.0845s	
2996/3500 (epoch 42.800), train_loss = 1.30903637, grad/param norm = 4.7415e-02, time/batch = 0.0836s	
2997/3500 (epoch 42.814), train_loss = 1.32526229, grad/param norm = 4.8673e-02, time/batch = 0.0826s	
2998/3500 (epoch 42.829), train_loss = 1.31235061, grad/param norm = 5.4707e-02, time/batch = 0.0825s	
2999/3500 (epoch 42.843), train_loss = 1.35553601, grad/param norm = 5.2837e-02, time/batch = 0.0818s	
evaluating loss over split index 2	
1/4...	
2/4...	
3/4...	
4/4...	
saving checkpoint to cv/lm_lstm_epoch42.86_1.4411.t7	
3000/3500 (epoch 42.857), train_loss = 1.35040473, grad/param norm = 4.7931e-02, time/batch = 0.0830s	
3001/3500 (epoch 42.871), train_loss = 1.56798237, grad/param norm = 6.1347e-02, time/batch = 0.0830s	
3002/3500 (epoch 42.886), train_loss = 1.33897753, grad/param norm = 6.6117e-02, time/batch = 0.0821s	
3003/3500 (epoch 42.900), train_loss = 1.34686219, grad/param norm = 6.8865e-02, time/batch = 0.0822s	
3004/3500 (epoch 42.914), train_loss = 1.34644675, grad/param norm = 6.5559e-02, time/batch = 0.0836s	
3005/3500 (epoch 42.929), train_loss = 1.32857802, grad/param norm = 6.3051e-02, time/batch = 0.0841s	
3006/3500 (epoch 42.943), train_loss = 1.34508135, grad/param norm = 5.9717e-02, time/batch = 0.0840s	
3007/3500 (epoch 42.957), train_loss = 1.35005772, grad/param norm = 6.0562e-02, time/batch = 0.0826s	
3008/3500 (epoch 42.971), train_loss = 1.34152822, grad/param norm = 5.5526e-02, time/batch = 0.0827s	
3009/3500 (epoch 42.986), train_loss = 1.33865061, grad/param norm = 5.7569e-02, time/batch = 0.0821s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
3010/3500 (epoch 43.000), train_loss = 1.32903562, grad/param norm = 5.9320e-02, time/batch = 0.0825s	
3011/3500 (epoch 43.014), train_loss = 1.53448999, grad/param norm = 6.7674e-02, time/batch = 0.0833s	
3012/3500 (epoch 43.029), train_loss = 1.33721138, grad/param norm = 6.2151e-02, time/batch = 0.0823s	
3013/3500 (epoch 43.043), train_loss = 1.33539369, grad/param norm = 5.7501e-02, time/batch = 0.0823s	
3014/3500 (epoch 43.057), train_loss = 1.32611295, grad/param norm = 5.3708e-02, time/batch = 0.0836s	
3015/3500 (epoch 43.071), train_loss = 1.31742455, grad/param norm = 4.9898e-02, time/batch = 0.0839s	
3016/3500 (epoch 43.086), train_loss = 1.32120967, grad/param norm = 4.4956e-02, time/batch = 0.0836s	
3017/3500 (epoch 43.100), train_loss = 1.33410615, grad/param norm = 5.0694e-02, time/batch = 0.0826s	
3018/3500 (epoch 43.114), train_loss = 1.33943078, grad/param norm = 4.9974e-02, time/batch = 0.0826s	
3019/3500 (epoch 43.129), train_loss = 1.33045133, grad/param norm = 4.7987e-02, time/batch = 0.0818s	
3020/3500 (epoch 43.143), train_loss = 1.33239619, grad/param norm = 4.7754e-02, time/batch = 0.0824s	
3021/3500 (epoch 43.157), train_loss = 1.32641546, grad/param norm = 5.2731e-02, time/batch = 0.0827s	
3022/3500 (epoch 43.171), train_loss = 1.32292024, grad/param norm = 4.8143e-02, time/batch = 0.0821s	
3023/3500 (epoch 43.186), train_loss = 1.32348256, grad/param norm = 4.7716e-02, time/batch = 0.0823s	
3024/3500 (epoch 43.200), train_loss = 1.32610941, grad/param norm = 4.5731e-02, time/batch = 0.0836s	
3025/3500 (epoch 43.214), train_loss = 1.32243670, grad/param norm = 4.6537e-02, time/batch = 0.0837s	
3026/3500 (epoch 43.229), train_loss = 1.31234322, grad/param norm = 4.7653e-02, time/batch = 0.0834s	
3027/3500 (epoch 43.243), train_loss = 1.32321372, grad/param norm = 5.0474e-02, time/batch = 0.0824s	
3028/3500 (epoch 43.257), train_loss = 1.33352807, grad/param norm = 5.0512e-02, time/batch = 0.0822s	
3029/3500 (epoch 43.271), train_loss = 1.34183868, grad/param norm = 4.8591e-02, time/batch = 0.0820s	
3030/3500 (epoch 43.286), train_loss = 1.33273618, grad/param norm = 5.0386e-02, time/batch = 0.0824s	
3031/3500 (epoch 43.300), train_loss = 1.35322468, grad/param norm = 5.2170e-02, time/batch = 0.0832s	
3032/3500 (epoch 43.314), train_loss = 1.32413605, grad/param norm = 4.7251e-02, time/batch = 0.0823s	
3033/3500 (epoch 43.329), train_loss = 1.34364233, grad/param norm = 4.8707e-02, time/batch = 0.0823s	
3034/3500 (epoch 43.343), train_loss = 1.33463972, grad/param norm = 4.8832e-02, time/batch = 0.0840s	
3035/3500 (epoch 43.357), train_loss = 1.34186092, grad/param norm = 5.3970e-02, time/batch = 0.0840s	
3036/3500 (epoch 43.371), train_loss = 1.34050189, grad/param norm = 4.8817e-02, time/batch = 0.0835s	
3037/3500 (epoch 43.386), train_loss = 1.31870797, grad/param norm = 4.6702e-02, time/batch = 0.0825s	
3038/3500 (epoch 43.400), train_loss = 1.32643251, grad/param norm = 4.7718e-02, time/batch = 0.0825s	
3039/3500 (epoch 43.414), train_loss = 1.32866658, grad/param norm = 4.7421e-02, time/batch = 0.0831s	
3040/3500 (epoch 43.429), train_loss = 1.29848113, grad/param norm = 4.7172e-02, time/batch = 0.0825s	
3041/3500 (epoch 43.443), train_loss = 1.33038383, grad/param norm = 4.9500e-02, time/batch = 0.0827s	
3042/3500 (epoch 43.457), train_loss = 1.32367880, grad/param norm = 5.4152e-02, time/batch = 0.0824s	
3043/3500 (epoch 43.471), train_loss = 1.33235221, grad/param norm = 5.0847e-02, time/batch = 0.0822s	
3044/3500 (epoch 43.486), train_loss = 1.35438884, grad/param norm = 4.5500e-02, time/batch = 0.0835s	
3045/3500 (epoch 43.500), train_loss = 1.32162151, grad/param norm = 4.5543e-02, time/batch = 0.0838s	
3046/3500 (epoch 43.514), train_loss = 1.34216532, grad/param norm = 4.5680e-02, time/batch = 0.0836s	
3047/3500 (epoch 43.529), train_loss = 1.34984005, grad/param norm = 4.8684e-02, time/batch = 0.0824s	
3048/3500 (epoch 43.543), train_loss = 1.33517098, grad/param norm = 4.7702e-02, time/batch = 0.0823s	
3049/3500 (epoch 43.557), train_loss = 1.30500617, grad/param norm = 4.9950e-02, time/batch = 0.0820s	
3050/3500 (epoch 43.571), train_loss = 1.31318520, grad/param norm = 5.2118e-02, time/batch = 0.0824s	
3051/3500 (epoch 43.586), train_loss = 1.31452626, grad/param norm = 5.9853e-02, time/batch = 0.0832s	
3052/3500 (epoch 43.600), train_loss = 1.30968947, grad/param norm = 5.7543e-02, time/batch = 0.0828s	
3053/3500 (epoch 43.614), train_loss = 1.32536118, grad/param norm = 5.0851e-02, time/batch = 0.0823s	
3054/3500 (epoch 43.629), train_loss = 1.30484536, grad/param norm = 5.5262e-02, time/batch = 0.0838s	
3055/3500 (epoch 43.643), train_loss = 1.32809338, grad/param norm = 5.1752e-02, time/batch = 0.0840s	
3056/3500 (epoch 43.657), train_loss = 1.31154762, grad/param norm = 4.5364e-02, time/batch = 0.0836s	
3057/3500 (epoch 43.671), train_loss = 1.29194639, grad/param norm = 5.0958e-02, time/batch = 0.0830s	
3058/3500 (epoch 43.686), train_loss = 1.32799610, grad/param norm = 5.5457e-02, time/batch = 0.0825s	
3059/3500 (epoch 43.700), train_loss = 1.32897233, grad/param norm = 5.0995e-02, time/batch = 0.0818s	
3060/3500 (epoch 43.714), train_loss = 1.32268476, grad/param norm = 5.3057e-02, time/batch = 0.0824s	
3061/3500 (epoch 43.729), train_loss = 1.32149922, grad/param norm = 5.1746e-02, time/batch = 0.0827s	
3062/3500 (epoch 43.743), train_loss = 1.31095676, grad/param norm = 5.2548e-02, time/batch = 0.0827s	
3063/3500 (epoch 43.757), train_loss = 1.32962425, grad/param norm = 4.9237e-02, time/batch = 0.0826s	
3064/3500 (epoch 43.771), train_loss = 1.33184653, grad/param norm = 4.7957e-02, time/batch = 0.0835s	
3065/3500 (epoch 43.786), train_loss = 1.31515353, grad/param norm = 4.9963e-02, time/batch = 0.0838s	
3066/3500 (epoch 43.800), train_loss = 1.30615286, grad/param norm = 4.9098e-02, time/batch = 0.0834s	
3067/3500 (epoch 43.814), train_loss = 1.32247005, grad/param norm = 5.1115e-02, time/batch = 0.0828s	
3068/3500 (epoch 43.829), train_loss = 1.30963046, grad/param norm = 5.7100e-02, time/batch = 0.0823s	
3069/3500 (epoch 43.843), train_loss = 1.35261292, grad/param norm = 5.2921e-02, time/batch = 0.0820s	
3070/3500 (epoch 43.857), train_loss = 1.34727930, grad/param norm = 4.7342e-02, time/batch = 0.0824s	
3071/3500 (epoch 43.871), train_loss = 1.33781604, grad/param norm = 4.8201e-02, time/batch = 0.0832s	
3072/3500 (epoch 43.886), train_loss = 1.33128871, grad/param norm = 5.1127e-02, time/batch = 0.0827s	
3073/3500 (epoch 43.900), train_loss = 1.34011498, grad/param norm = 4.6540e-02, time/batch = 0.0824s	
3074/3500 (epoch 43.914), train_loss = 1.34038894, grad/param norm = 4.4781e-02, time/batch = 0.0837s	
3075/3500 (epoch 43.929), train_loss = 1.32267553, grad/param norm = 4.9037e-02, time/batch = 0.0840s	
3076/3500 (epoch 43.943), train_loss = 1.34044865, grad/param norm = 4.8102e-02, time/batch = 0.0838s	
3077/3500 (epoch 43.957), train_loss = 1.34586381, grad/param norm = 5.1578e-02, time/batch = 0.0830s	
3078/3500 (epoch 43.971), train_loss = 1.33815428, grad/param norm = 4.9105e-02, time/batch = 0.0825s	
3079/3500 (epoch 43.986), train_loss = 1.33552074, grad/param norm = 5.1331e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
3080/3500 (epoch 44.000), train_loss = 1.32632613, grad/param norm = 6.2906e-02, time/batch = 0.0824s	
3081/3500 (epoch 44.014), train_loss = 1.53390543, grad/param norm = 6.6967e-02, time/batch = 0.0827s	
3082/3500 (epoch 44.029), train_loss = 1.33387642, grad/param norm = 5.7746e-02, time/batch = 0.0821s	
3083/3500 (epoch 44.043), train_loss = 1.33245074, grad/param norm = 5.5933e-02, time/batch = 0.0825s	
3084/3500 (epoch 44.057), train_loss = 1.32364047, grad/param norm = 5.7808e-02, time/batch = 0.0834s	
3085/3500 (epoch 44.071), train_loss = 1.31474363, grad/param norm = 5.2056e-02, time/batch = 0.0840s	
3086/3500 (epoch 44.086), train_loss = 1.31818350, grad/param norm = 4.5397e-02, time/batch = 0.0834s	
3087/3500 (epoch 44.100), train_loss = 1.33110617, grad/param norm = 4.9285e-02, time/batch = 0.0829s	
3088/3500 (epoch 44.114), train_loss = 1.33629486, grad/param norm = 5.0037e-02, time/batch = 0.0822s	
3089/3500 (epoch 44.129), train_loss = 1.32755653, grad/param norm = 4.8996e-02, time/batch = 0.0820s	
3090/3500 (epoch 44.143), train_loss = 1.32944687, grad/param norm = 4.6817e-02, time/batch = 0.0824s	
3091/3500 (epoch 44.157), train_loss = 1.32366236, grad/param norm = 5.2889e-02, time/batch = 0.0832s	
3092/3500 (epoch 44.171), train_loss = 1.32027805, grad/param norm = 5.0596e-02, time/batch = 0.0823s	
3093/3500 (epoch 44.186), train_loss = 1.32069320, grad/param norm = 4.9498e-02, time/batch = 0.0824s	
3094/3500 (epoch 44.200), train_loss = 1.32354628, grad/param norm = 4.9268e-02, time/batch = 0.0837s	
3095/3500 (epoch 44.214), train_loss = 1.32025337, grad/param norm = 5.0531e-02, time/batch = 0.0841s	
3096/3500 (epoch 44.229), train_loss = 1.30982965, grad/param norm = 4.9681e-02, time/batch = 0.0836s	
3097/3500 (epoch 44.243), train_loss = 1.32045851, grad/param norm = 5.0455e-02, time/batch = 0.0826s	
3098/3500 (epoch 44.257), train_loss = 1.33033937, grad/param norm = 4.8358e-02, time/batch = 0.0825s	
3099/3500 (epoch 44.271), train_loss = 1.33869294, grad/param norm = 4.7051e-02, time/batch = 0.0818s	
3100/3500 (epoch 44.286), train_loss = 1.32971466, grad/param norm = 4.9784e-02, time/batch = 0.0824s	
3101/3500 (epoch 44.300), train_loss = 1.34998566, grad/param norm = 5.2374e-02, time/batch = 0.0828s	
3102/3500 (epoch 44.314), train_loss = 1.32129629, grad/param norm = 4.7669e-02, time/batch = 0.0822s	
3103/3500 (epoch 44.329), train_loss = 1.34022214, grad/param norm = 4.9331e-02, time/batch = 0.0822s	
3104/3500 (epoch 44.343), train_loss = 1.33181984, grad/param norm = 4.8262e-02, time/batch = 0.0835s	
3105/3500 (epoch 44.357), train_loss = 1.33877234, grad/param norm = 4.9215e-02, time/batch = 0.0839s	
3106/3500 (epoch 44.371), train_loss = 1.33693626, grad/param norm = 4.3009e-02, time/batch = 0.0838s	
3107/3500 (epoch 44.386), train_loss = 1.31548707, grad/param norm = 4.3996e-02, time/batch = 0.0824s	
3108/3500 (epoch 44.400), train_loss = 1.32355455, grad/param norm = 4.6499e-02, time/batch = 0.0822s	
3109/3500 (epoch 44.414), train_loss = 1.32518482, grad/param norm = 4.5682e-02, time/batch = 0.0819s	
3110/3500 (epoch 44.429), train_loss = 1.29549017, grad/param norm = 4.6519e-02, time/batch = 0.0824s	
3111/3500 (epoch 44.443), train_loss = 1.32793083, grad/param norm = 5.3566e-02, time/batch = 0.0833s	
3112/3500 (epoch 44.457), train_loss = 1.32152998, grad/param norm = 6.0500e-02, time/batch = 0.0824s	
3113/3500 (epoch 44.471), train_loss = 1.32982668, grad/param norm = 5.1836e-02, time/batch = 0.0824s	
3114/3500 (epoch 44.486), train_loss = 1.35174821, grad/param norm = 4.3942e-02, time/batch = 0.0836s	
3115/3500 (epoch 44.500), train_loss = 1.31863685, grad/param norm = 4.7215e-02, time/batch = 0.0840s	
3116/3500 (epoch 44.514), train_loss = 1.33938574, grad/param norm = 5.0904e-02, time/batch = 0.0841s	
3117/3500 (epoch 44.529), train_loss = 1.34716853, grad/param norm = 4.9799e-02, time/batch = 0.0826s	
3118/3500 (epoch 44.543), train_loss = 1.33231621, grad/param norm = 4.6037e-02, time/batch = 0.0824s	
3119/3500 (epoch 44.557), train_loss = 1.30181536, grad/param norm = 4.8345e-02, time/batch = 0.0818s	
3120/3500 (epoch 44.571), train_loss = 1.30977085, grad/param norm = 4.8031e-02, time/batch = 0.0824s	
3121/3500 (epoch 44.586), train_loss = 1.31053972, grad/param norm = 5.2849e-02, time/batch = 0.0834s	
3122/3500 (epoch 44.600), train_loss = 1.30562152, grad/param norm = 5.1121e-02, time/batch = 0.0821s	
3123/3500 (epoch 44.614), train_loss = 1.32187412, grad/param norm = 5.0765e-02, time/batch = 0.0822s	
3124/3500 (epoch 44.629), train_loss = 1.30197724, grad/param norm = 5.6434e-02, time/batch = 0.0834s	
3125/3500 (epoch 44.643), train_loss = 1.32523308, grad/param norm = 4.9795e-02, time/batch = 0.0839s	
3126/3500 (epoch 44.657), train_loss = 1.30830343, grad/param norm = 4.4065e-02, time/batch = 0.0838s	
3127/3500 (epoch 44.671), train_loss = 1.28909811, grad/param norm = 5.4959e-02, time/batch = 0.0824s	
3128/3500 (epoch 44.686), train_loss = 1.32539267, grad/param norm = 5.8134e-02, time/batch = 0.0822s	
3129/3500 (epoch 44.700), train_loss = 1.32632061, grad/param norm = 5.1034e-02, time/batch = 0.0819s	
3130/3500 (epoch 44.714), train_loss = 1.31992738, grad/param norm = 5.4273e-02, time/batch = 0.0825s	
3131/3500 (epoch 44.729), train_loss = 1.31857651, grad/param norm = 5.3171e-02, time/batch = 0.0837s	
3132/3500 (epoch 44.743), train_loss = 1.30810897, grad/param norm = 5.3147e-02, time/batch = 0.0823s	
3133/3500 (epoch 44.757), train_loss = 1.32674554, grad/param norm = 5.0168e-02, time/batch = 0.0824s	
3134/3500 (epoch 44.771), train_loss = 1.32899299, grad/param norm = 4.8938e-02, time/batch = 0.0837s	
3135/3500 (epoch 44.786), train_loss = 1.31189549, grad/param norm = 5.0213e-02, time/batch = 0.0841s	
3136/3500 (epoch 44.800), train_loss = 1.30316125, grad/param norm = 4.9384e-02, time/batch = 0.0842s	
3137/3500 (epoch 44.814), train_loss = 1.31975796, grad/param norm = 5.2967e-02, time/batch = 0.0830s	
3138/3500 (epoch 44.829), train_loss = 1.30665838, grad/param norm = 5.6658e-02, time/batch = 0.0844s	
3139/3500 (epoch 44.843), train_loss = 1.34961645, grad/param norm = 5.1433e-02, time/batch = 0.0819s	
3140/3500 (epoch 44.857), train_loss = 1.34433912, grad/param norm = 4.8255e-02, time/batch = 0.0826s	
3141/3500 (epoch 44.871), train_loss = 1.33467470, grad/param norm = 5.2203e-02, time/batch = 0.0832s	
3142/3500 (epoch 44.886), train_loss = 1.32840819, grad/param norm = 5.2265e-02, time/batch = 0.0822s	
3143/3500 (epoch 44.900), train_loss = 1.33731491, grad/param norm = 4.5812e-02, time/batch = 0.0822s	
3144/3500 (epoch 44.914), train_loss = 1.33750066, grad/param norm = 4.7533e-02, time/batch = 0.0835s	
3145/3500 (epoch 44.929), train_loss = 1.32008969, grad/param norm = 5.1927e-02, time/batch = 0.0838s	
3146/3500 (epoch 44.943), train_loss = 1.33750752, grad/param norm = 4.8868e-02, time/batch = 0.0839s	
3147/3500 (epoch 44.957), train_loss = 1.34263212, grad/param norm = 5.0091e-02, time/batch = 0.0825s	
3148/3500 (epoch 44.971), train_loss = 1.33491953, grad/param norm = 4.7682e-02, time/batch = 0.0822s	
3149/3500 (epoch 44.986), train_loss = 1.33259071, grad/param norm = 5.3845e-02, time/batch = 0.0819s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
3150/3500 (epoch 45.000), train_loss = 1.32318796, grad/param norm = 6.2064e-02, time/batch = 0.0824s	
3151/3500 (epoch 45.014), train_loss = 1.53119736, grad/param norm = 6.4776e-02, time/batch = 0.0832s	
3152/3500 (epoch 45.029), train_loss = 1.33060305, grad/param norm = 5.7741e-02, time/batch = 0.0823s	
3153/3500 (epoch 45.043), train_loss = 1.32965504, grad/param norm = 5.6372e-02, time/batch = 0.0822s	
3154/3500 (epoch 45.057), train_loss = 1.32065113, grad/param norm = 5.5687e-02, time/batch = 0.0837s	
3155/3500 (epoch 45.071), train_loss = 1.31155546, grad/param norm = 4.9791e-02, time/batch = 0.0840s	
3156/3500 (epoch 45.086), train_loss = 1.31502235, grad/param norm = 4.4726e-02, time/batch = 0.0840s	
3157/3500 (epoch 45.100), train_loss = 1.32806715, grad/param norm = 4.9748e-02, time/batch = 0.0826s	
3158/3500 (epoch 45.114), train_loss = 1.33334008, grad/param norm = 4.9700e-02, time/batch = 0.0824s	
3159/3500 (epoch 45.129), train_loss = 1.32459365, grad/param norm = 4.8728e-02, time/batch = 0.0818s	
3160/3500 (epoch 45.143), train_loss = 1.32660502, grad/param norm = 4.7743e-02, time/batch = 0.0824s	
3161/3500 (epoch 45.157), train_loss = 1.32093483, grad/param norm = 5.3053e-02, time/batch = 0.0827s	
3162/3500 (epoch 45.171), train_loss = 1.31736212, grad/param norm = 4.9836e-02, time/batch = 0.0821s	
3163/3500 (epoch 45.186), train_loss = 1.31769325, grad/param norm = 4.8596e-02, time/batch = 0.0821s	
3164/3500 (epoch 45.200), train_loss = 1.32040755, grad/param norm = 4.7502e-02, time/batch = 0.0834s	
3165/3500 (epoch 45.214), train_loss = 1.31721051, grad/param norm = 4.8788e-02, time/batch = 0.0839s	
3166/3500 (epoch 45.229), train_loss = 1.30677431, grad/param norm = 4.8379e-02, time/batch = 0.0835s	
3167/3500 (epoch 45.243), train_loss = 1.31732967, grad/param norm = 4.8704e-02, time/batch = 0.0824s	
3168/3500 (epoch 45.257), train_loss = 1.32750209, grad/param norm = 4.8596e-02, time/batch = 0.0822s	
3169/3500 (epoch 45.271), train_loss = 1.33578925, grad/param norm = 4.7436e-02, time/batch = 0.0820s	
3170/3500 (epoch 45.286), train_loss = 1.32702109, grad/param norm = 4.9728e-02, time/batch = 0.0824s	
3171/3500 (epoch 45.300), train_loss = 1.34704579, grad/param norm = 5.2617e-02, time/batch = 0.0832s	
3172/3500 (epoch 45.314), train_loss = 1.31849280, grad/param norm = 4.8099e-02, time/batch = 0.0823s	
3173/3500 (epoch 45.329), train_loss = 1.33717501, grad/param norm = 5.0474e-02, time/batch = 0.0823s	
3174/3500 (epoch 45.343), train_loss = 1.32896392, grad/param norm = 4.8870e-02, time/batch = 0.0836s	
3175/3500 (epoch 45.357), train_loss = 1.33592783, grad/param norm = 4.8629e-02, time/batch = 0.0846s	
3176/3500 (epoch 45.371), train_loss = 1.33412709, grad/param norm = 4.3118e-02, time/batch = 0.0836s	
3177/3500 (epoch 45.386), train_loss = 1.31273314, grad/param norm = 4.4052e-02, time/batch = 0.0825s	
3178/3500 (epoch 45.400), train_loss = 1.32084325, grad/param norm = 4.6472e-02, time/batch = 0.0826s	
3179/3500 (epoch 45.414), train_loss = 1.32226284, grad/param norm = 4.6343e-02, time/batch = 0.0818s	
3180/3500 (epoch 45.429), train_loss = 1.29278898, grad/param norm = 4.8726e-02, time/batch = 0.0824s	
3181/3500 (epoch 45.443), train_loss = 1.32548563, grad/param norm = 5.5889e-02, time/batch = 0.0829s	
3182/3500 (epoch 45.457), train_loss = 1.31862082, grad/param norm = 5.9326e-02, time/batch = 0.0821s	
3183/3500 (epoch 45.471), train_loss = 1.32663745, grad/param norm = 4.8943e-02, time/batch = 0.0822s	
3184/3500 (epoch 45.486), train_loss = 1.34884552, grad/param norm = 4.4725e-02, time/batch = 0.0834s	
3185/3500 (epoch 45.500), train_loss = 1.31609663, grad/param norm = 5.0389e-02, time/batch = 0.0844s	
3186/3500 (epoch 45.514), train_loss = 1.33644283, grad/param norm = 5.1666e-02, time/batch = 0.0834s	
3187/3500 (epoch 45.529), train_loss = 1.34448684, grad/param norm = 4.9243e-02, time/batch = 0.0824s	
3188/3500 (epoch 45.543), train_loss = 1.32946411, grad/param norm = 4.6763e-02, time/batch = 0.0823s	
3189/3500 (epoch 45.557), train_loss = 1.29905885, grad/param norm = 4.9251e-02, time/batch = 0.0819s	
3190/3500 (epoch 45.571), train_loss = 1.30723252, grad/param norm = 4.8073e-02, time/batch = 0.0824s	
3191/3500 (epoch 45.586), train_loss = 1.30785857, grad/param norm = 5.3844e-02, time/batch = 0.0831s	
3192/3500 (epoch 45.600), train_loss = 1.30277718, grad/param norm = 5.2236e-02, time/batch = 0.0823s	
3193/3500 (epoch 45.614), train_loss = 1.31894506, grad/param norm = 5.0628e-02, time/batch = 0.0823s	
3194/3500 (epoch 45.629), train_loss = 1.29894194, grad/param norm = 5.5186e-02, time/batch = 0.0838s	
3195/3500 (epoch 45.643), train_loss = 1.32223897, grad/param norm = 4.7509e-02, time/batch = 0.0844s	
3196/3500 (epoch 45.657), train_loss = 1.30511891, grad/param norm = 4.4053e-02, time/batch = 0.0835s	
3197/3500 (epoch 45.671), train_loss = 1.28590477, grad/param norm = 5.5502e-02, time/batch = 0.0826s	
3198/3500 (epoch 45.686), train_loss = 1.32231048, grad/param norm = 5.5841e-02, time/batch = 0.0824s	
3199/3500 (epoch 45.700), train_loss = 1.32336289, grad/param norm = 4.9915e-02, time/batch = 0.0817s	
3200/3500 (epoch 45.714), train_loss = 1.31696462, grad/param norm = 5.4610e-02, time/batch = 0.0824s	
3201/3500 (epoch 45.729), train_loss = 1.31539305, grad/param norm = 5.1832e-02, time/batch = 0.0828s	
3202/3500 (epoch 45.743), train_loss = 1.30500049, grad/param norm = 5.1518e-02, time/batch = 0.0821s	
3203/3500 (epoch 45.757), train_loss = 1.32357674, grad/param norm = 4.8869e-02, time/batch = 0.0822s	
3204/3500 (epoch 45.771), train_loss = 1.32593329, grad/param norm = 4.6846e-02, time/batch = 0.0837s	
3205/3500 (epoch 45.786), train_loss = 1.30853992, grad/param norm = 4.7474e-02, time/batch = 0.0843s	
3206/3500 (epoch 45.800), train_loss = 1.29981332, grad/param norm = 4.7188e-02, time/batch = 0.0834s	
3207/3500 (epoch 45.814), train_loss = 1.31665636, grad/param norm = 5.0365e-02, time/batch = 0.0824s	
3208/3500 (epoch 45.829), train_loss = 1.30349658, grad/param norm = 5.2604e-02, time/batch = 0.0822s	
3209/3500 (epoch 45.843), train_loss = 1.34617389, grad/param norm = 4.8907e-02, time/batch = 0.0820s	
3210/3500 (epoch 45.857), train_loss = 1.34133551, grad/param norm = 4.8089e-02, time/batch = 0.0827s	
3211/3500 (epoch 45.871), train_loss = 1.33189760, grad/param norm = 5.4316e-02, time/batch = 0.0832s	
3212/3500 (epoch 45.886), train_loss = 1.32582631, grad/param norm = 5.4617e-02, time/batch = 0.0823s	
3213/3500 (epoch 45.900), train_loss = 1.33480798, grad/param norm = 4.7669e-02, time/batch = 0.0823s	
3214/3500 (epoch 45.914), train_loss = 1.33472947, grad/param norm = 4.9028e-02, time/batch = 0.0835s	
3215/3500 (epoch 45.929), train_loss = 1.31736701, grad/param norm = 5.1953e-02, time/batch = 0.0844s	
3216/3500 (epoch 45.943), train_loss = 1.33459554, grad/param norm = 4.8097e-02, time/batch = 0.0835s	
3217/3500 (epoch 45.957), train_loss = 1.33976364, grad/param norm = 4.9459e-02, time/batch = 0.0825s	
3218/3500 (epoch 45.971), train_loss = 1.33215861, grad/param norm = 4.9031e-02, time/batch = 0.0824s	
3219/3500 (epoch 45.986), train_loss = 1.33007145, grad/param norm = 5.5877e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
3220/3500 (epoch 46.000), train_loss = 1.32039916, grad/param norm = 6.2271e-02, time/batch = 0.0829s	
3221/3500 (epoch 46.014), train_loss = 1.52862794, grad/param norm = 6.3033e-02, time/batch = 0.0827s	
3222/3500 (epoch 46.029), train_loss = 1.32730026, grad/param norm = 5.6061e-02, time/batch = 0.0821s	
3223/3500 (epoch 46.043), train_loss = 1.32677257, grad/param norm = 5.5027e-02, time/batch = 0.0822s	
3224/3500 (epoch 46.057), train_loss = 1.31781382, grad/param norm = 5.4137e-02, time/batch = 0.0835s	
3225/3500 (epoch 46.071), train_loss = 1.30866978, grad/param norm = 4.8761e-02, time/batch = 0.0842s	
3226/3500 (epoch 46.086), train_loss = 1.31206610, grad/param norm = 4.4199e-02, time/batch = 0.0833s	
3227/3500 (epoch 46.100), train_loss = 1.32510097, grad/param norm = 4.9012e-02, time/batch = 0.0824s	
3228/3500 (epoch 46.114), train_loss = 1.33036120, grad/param norm = 4.8766e-02, time/batch = 0.0823s	
3229/3500 (epoch 46.129), train_loss = 1.32165485, grad/param norm = 4.7434e-02, time/batch = 0.0820s	
3230/3500 (epoch 46.143), train_loss = 1.32369892, grad/param norm = 4.6697e-02, time/batch = 0.0829s	
3231/3500 (epoch 46.157), train_loss = 1.31817951, grad/param norm = 5.2078e-02, time/batch = 0.0835s	
3232/3500 (epoch 46.171), train_loss = 1.31446792, grad/param norm = 4.8493e-02, time/batch = 0.0823s	
3233/3500 (epoch 46.186), train_loss = 1.31481183, grad/param norm = 4.7612e-02, time/batch = 0.0823s	
3234/3500 (epoch 46.200), train_loss = 1.31745555, grad/param norm = 4.6304e-02, time/batch = 0.0836s	
3235/3500 (epoch 46.214), train_loss = 1.31442763, grad/param norm = 4.7491e-02, time/batch = 0.0846s	
3236/3500 (epoch 46.229), train_loss = 1.30392254, grad/param norm = 4.7385e-02, time/batch = 0.0885s	
3237/3500 (epoch 46.243), train_loss = 1.31442816, grad/param norm = 4.7818e-02, time/batch = 0.0833s	
3238/3500 (epoch 46.257), train_loss = 1.32473688, grad/param norm = 4.8761e-02, time/batch = 0.0825s	
3239/3500 (epoch 46.271), train_loss = 1.33305566, grad/param norm = 4.7802e-02, time/batch = 0.0818s	
3240/3500 (epoch 46.286), train_loss = 1.32448442, grad/param norm = 5.0184e-02, time/batch = 0.0829s	
3241/3500 (epoch 46.300), train_loss = 1.34414876, grad/param norm = 5.3205e-02, time/batch = 0.0827s	
3242/3500 (epoch 46.314), train_loss = 1.31593717, grad/param norm = 4.9258e-02, time/batch = 0.0822s	
3243/3500 (epoch 46.329), train_loss = 1.33428282, grad/param norm = 5.1765e-02, time/batch = 0.0822s	
3244/3500 (epoch 46.343), train_loss = 1.32627660, grad/param norm = 4.9246e-02, time/batch = 0.0834s	
3245/3500 (epoch 46.357), train_loss = 1.33323251, grad/param norm = 4.7959e-02, time/batch = 0.0837s	
3246/3500 (epoch 46.371), train_loss = 1.33143286, grad/param norm = 4.3183e-02, time/batch = 0.0835s	
3247/3500 (epoch 46.386), train_loss = 1.31014684, grad/param norm = 4.4143e-02, time/batch = 0.0824s	
3248/3500 (epoch 46.400), train_loss = 1.31829052, grad/param norm = 4.6343e-02, time/batch = 0.0822s	
3249/3500 (epoch 46.414), train_loss = 1.31940271, grad/param norm = 4.6245e-02, time/batch = 0.0820s	
3250/3500 (epoch 46.429), train_loss = 1.29011363, grad/param norm = 4.9456e-02, time/batch = 0.0830s	
3251/3500 (epoch 46.443), train_loss = 1.32299887, grad/param norm = 5.6671e-02, time/batch = 0.0832s	
3252/3500 (epoch 46.457), train_loss = 1.31574386, grad/param norm = 5.7945e-02, time/batch = 0.0823s	
3253/3500 (epoch 46.471), train_loss = 1.32376623, grad/param norm = 4.7569e-02, time/batch = 0.0823s	
3254/3500 (epoch 46.486), train_loss = 1.34628004, grad/param norm = 4.6103e-02, time/batch = 0.0840s	
3255/3500 (epoch 46.500), train_loss = 1.31357227, grad/param norm = 5.1910e-02, time/batch = 0.0841s	
3256/3500 (epoch 46.514), train_loss = 1.33352926, grad/param norm = 4.9852e-02, time/batch = 0.0835s	
3257/3500 (epoch 46.529), train_loss = 1.34164763, grad/param norm = 4.7480e-02, time/batch = 0.0826s	
3258/3500 (epoch 46.543), train_loss = 1.32651536, grad/param norm = 4.6117e-02, time/batch = 0.0825s	
3259/3500 (epoch 46.557), train_loss = 1.29635274, grad/param norm = 4.8587e-02, time/batch = 0.0817s	
3260/3500 (epoch 46.571), train_loss = 1.30460257, grad/param norm = 4.7405e-02, time/batch = 0.0824s	
3261/3500 (epoch 46.586), train_loss = 1.30511930, grad/param norm = 5.3998e-02, time/batch = 0.0827s	
3262/3500 (epoch 46.600), train_loss = 1.29978934, grad/param norm = 5.1148e-02, time/batch = 0.0821s	
3263/3500 (epoch 46.614), train_loss = 1.31601247, grad/param norm = 4.9455e-02, time/batch = 0.0822s	
3264/3500 (epoch 46.629), train_loss = 1.29610634, grad/param norm = 5.4214e-02, time/batch = 0.0839s	
3265/3500 (epoch 46.643), train_loss = 1.31949753, grad/param norm = 4.6130e-02, time/batch = 0.0838s	
3266/3500 (epoch 46.657), train_loss = 1.30223584, grad/param norm = 4.4268e-02, time/batch = 0.0835s	
3267/3500 (epoch 46.671), train_loss = 1.28315001, grad/param norm = 5.7297e-02, time/batch = 0.0824s	
3268/3500 (epoch 46.686), train_loss = 1.31976032, grad/param norm = 5.6553e-02, time/batch = 0.0822s	
3269/3500 (epoch 46.700), train_loss = 1.32091319, grad/param norm = 5.1587e-02, time/batch = 0.0820s	
3270/3500 (epoch 46.714), train_loss = 1.31455715, grad/param norm = 5.6943e-02, time/batch = 0.0825s	
3271/3500 (epoch 46.729), train_loss = 1.31260721, grad/param norm = 5.2580e-02, time/batch = 0.0832s	
3272/3500 (epoch 46.743), train_loss = 1.30220476, grad/param norm = 5.1393e-02, time/batch = 0.0824s	
3273/3500 (epoch 46.757), train_loss = 1.32067564, grad/param norm = 4.8735e-02, time/batch = 0.0824s	
3274/3500 (epoch 46.771), train_loss = 1.32319176, grad/param norm = 4.6210e-02, time/batch = 0.0840s	
3275/3500 (epoch 46.786), train_loss = 1.30552490, grad/param norm = 4.6965e-02, time/batch = 0.0840s	
3276/3500 (epoch 46.800), train_loss = 1.29687617, grad/param norm = 4.6660e-02, time/batch = 0.0836s	
3277/3500 (epoch 46.814), train_loss = 1.31381962, grad/param norm = 4.9149e-02, time/batch = 0.0825s	
3278/3500 (epoch 46.829), train_loss = 1.30071828, grad/param norm = 5.0709e-02, time/batch = 0.0824s	
3279/3500 (epoch 46.843), train_loss = 1.34309109, grad/param norm = 4.7850e-02, time/batch = 0.0818s	
3280/3500 (epoch 46.857), train_loss = 1.33851590, grad/param norm = 4.8125e-02, time/batch = 0.0824s	
3281/3500 (epoch 46.871), train_loss = 1.32918290, grad/param norm = 5.4810e-02, time/batch = 0.0827s	
3282/3500 (epoch 46.886), train_loss = 1.32302979, grad/param norm = 5.4620e-02, time/batch = 0.0821s	
3283/3500 (epoch 46.900), train_loss = 1.33213185, grad/param norm = 4.7728e-02, time/batch = 0.0822s	
3284/3500 (epoch 46.914), train_loss = 1.33181150, grad/param norm = 4.8780e-02, time/batch = 0.0839s	
3285/3500 (epoch 46.929), train_loss = 1.31459380, grad/param norm = 5.0916e-02, time/batch = 0.0839s	
3286/3500 (epoch 46.943), train_loss = 1.33168683, grad/param norm = 4.6816e-02, time/batch = 0.0834s	
3287/3500 (epoch 46.957), train_loss = 1.33692503, grad/param norm = 4.8551e-02, time/batch = 0.0825s	
3288/3500 (epoch 46.971), train_loss = 1.32917087, grad/param norm = 4.8183e-02, time/batch = 0.0822s	
3289/3500 (epoch 46.986), train_loss = 1.32711664, grad/param norm = 5.3677e-02, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
3290/3500 (epoch 47.000), train_loss = 1.31716989, grad/param norm = 5.9025e-02, time/batch = 0.0824s	
3291/3500 (epoch 47.014), train_loss = 1.52615643, grad/param norm = 6.1743e-02, time/batch = 0.0831s	
3292/3500 (epoch 47.029), train_loss = 1.32447130, grad/param norm = 5.6454e-02, time/batch = 0.0823s	
3293/3500 (epoch 47.043), train_loss = 1.32421546, grad/param norm = 5.5241e-02, time/batch = 0.0823s	
3294/3500 (epoch 47.057), train_loss = 1.31524776, grad/param norm = 5.3424e-02, time/batch = 0.0840s	
3295/3500 (epoch 47.071), train_loss = 1.30603352, grad/param norm = 4.8503e-02, time/batch = 0.0839s	
3296/3500 (epoch 47.086), train_loss = 1.30929875, grad/param norm = 4.4123e-02, time/batch = 0.0836s	
3297/3500 (epoch 47.100), train_loss = 1.32240925, grad/param norm = 4.8773e-02, time/batch = 0.0825s	
3298/3500 (epoch 47.114), train_loss = 1.32761576, grad/param norm = 4.8521e-02, time/batch = 0.0825s	
3299/3500 (epoch 47.129), train_loss = 1.31900282, grad/param norm = 4.7389e-02, time/batch = 0.0821s	
3300/3500 (epoch 47.143), train_loss = 1.32110201, grad/param norm = 4.6688e-02, time/batch = 0.0824s	
3301/3500 (epoch 47.157), train_loss = 1.31570609, grad/param norm = 5.2031e-02, time/batch = 0.0827s	
3302/3500 (epoch 47.171), train_loss = 1.31186059, grad/param norm = 4.8187e-02, time/batch = 0.0821s	
3303/3500 (epoch 47.186), train_loss = 1.31219385, grad/param norm = 4.7379e-02, time/batch = 0.0822s	
3304/3500 (epoch 47.200), train_loss = 1.31471214, grad/param norm = 4.5770e-02, time/batch = 0.0839s	
3305/3500 (epoch 47.214), train_loss = 1.31185330, grad/param norm = 4.7012e-02, time/batch = 0.0837s	
3306/3500 (epoch 47.229), train_loss = 1.30125018, grad/param norm = 4.7007e-02, time/batch = 0.0834s	
3307/3500 (epoch 47.243), train_loss = 1.31173636, grad/param norm = 4.7566e-02, time/batch = 0.0824s	
3308/3500 (epoch 47.257), train_loss = 1.32214920, grad/param norm = 4.9198e-02, time/batch = 0.0822s	
3309/3500 (epoch 47.271), train_loss = 1.33043460, grad/param norm = 4.7907e-02, time/batch = 0.0825s	
3310/3500 (epoch 47.286), train_loss = 1.32198249, grad/param norm = 5.0065e-02, time/batch = 0.0824s	
3311/3500 (epoch 47.300), train_loss = 1.34130774, grad/param norm = 5.3280e-02, time/batch = 0.0833s	
3312/3500 (epoch 47.314), train_loss = 1.31337701, grad/param norm = 4.9385e-02, time/batch = 0.0823s	
3313/3500 (epoch 47.329), train_loss = 1.33139346, grad/param norm = 5.1360e-02, time/batch = 0.0823s	
3314/3500 (epoch 47.343), train_loss = 1.32345215, grad/param norm = 4.8356e-02, time/batch = 0.0836s	
3315/3500 (epoch 47.357), train_loss = 1.33056467, grad/param norm = 4.7046e-02, time/batch = 0.0840s	
3316/3500 (epoch 47.371), train_loss = 1.32879351, grad/param norm = 4.2792e-02, time/batch = 0.0835s	
3317/3500 (epoch 47.386), train_loss = 1.30760717, grad/param norm = 4.3723e-02, time/batch = 0.0826s	
3318/3500 (epoch 47.400), train_loss = 1.31580070, grad/param norm = 4.5944e-02, time/batch = 0.0825s	
3319/3500 (epoch 47.414), train_loss = 1.31662205, grad/param norm = 4.5393e-02, time/batch = 0.0822s	
3320/3500 (epoch 47.429), train_loss = 1.28735920, grad/param norm = 4.8520e-02, time/batch = 0.0823s	
3321/3500 (epoch 47.443), train_loss = 1.32033080, grad/param norm = 5.5064e-02, time/batch = 0.0827s	
3322/3500 (epoch 47.457), train_loss = 1.31279822, grad/param norm = 5.5624e-02, time/batch = 0.0821s	
3323/3500 (epoch 47.471), train_loss = 1.32108424, grad/param norm = 4.7023e-02, time/batch = 0.0822s	
3324/3500 (epoch 47.486), train_loss = 1.34386557, grad/param norm = 4.7059e-02, time/batch = 0.0833s	
3325/3500 (epoch 47.500), train_loss = 1.31108547, grad/param norm = 5.2485e-02, time/batch = 0.0837s	
3326/3500 (epoch 47.514), train_loss = 1.33075422, grad/param norm = 4.8541e-02, time/batch = 0.0834s	
3327/3500 (epoch 47.529), train_loss = 1.33897572, grad/param norm = 4.6312e-02, time/batch = 0.0824s	
3328/3500 (epoch 47.543), train_loss = 1.32378659, grad/param norm = 4.5499e-02, time/batch = 0.0822s	
3329/3500 (epoch 47.557), train_loss = 1.29382520, grad/param norm = 4.8083e-02, time/batch = 0.0820s	
3330/3500 (epoch 47.571), train_loss = 1.30210465, grad/param norm = 4.7089e-02, time/batch = 0.0826s	
3331/3500 (epoch 47.586), train_loss = 1.30247931, grad/param norm = 5.3902e-02, time/batch = 0.0832s	
3332/3500 (epoch 47.600), train_loss = 1.29697772, grad/param norm = 5.0505e-02, time/batch = 0.0824s	
3333/3500 (epoch 47.614), train_loss = 1.31328824, grad/param norm = 4.8895e-02, time/batch = 0.0831s	
3334/3500 (epoch 47.629), train_loss = 1.29352108, grad/param norm = 5.4024e-02, time/batch = 0.0836s	
3335/3500 (epoch 47.643), train_loss = 1.31699691, grad/param norm = 4.5890e-02, time/batch = 0.0879s	
3336/3500 (epoch 47.657), train_loss = 1.29956392, grad/param norm = 4.4882e-02, time/batch = 0.0839s	
3337/3500 (epoch 47.671), train_loss = 1.28049461, grad/param norm = 5.8538e-02, time/batch = 0.0826s	
3338/3500 (epoch 47.686), train_loss = 1.31723391, grad/param norm = 5.6804e-02, time/batch = 0.0825s	
3339/3500 (epoch 47.700), train_loss = 1.31846501, grad/param norm = 5.2299e-02, time/batch = 0.0818s	
3340/3500 (epoch 47.714), train_loss = 1.31203869, grad/param norm = 5.7423e-02, time/batch = 0.0824s	
3341/3500 (epoch 47.729), train_loss = 1.30977119, grad/param norm = 5.1777e-02, time/batch = 0.0827s	
3342/3500 (epoch 47.743), train_loss = 1.29938519, grad/param norm = 5.0379e-02, time/batch = 0.0821s	
3343/3500 (epoch 47.757), train_loss = 1.31785051, grad/param norm = 4.7884e-02, time/batch = 0.0823s	
3344/3500 (epoch 47.771), train_loss = 1.32057785, grad/param norm = 4.5410e-02, time/batch = 0.0835s	
3345/3500 (epoch 47.786), train_loss = 1.30262386, grad/param norm = 4.6510e-02, time/batch = 0.0837s	
3346/3500 (epoch 47.800), train_loss = 1.29408110, grad/param norm = 4.6233e-02, time/batch = 0.0834s	
3347/3500 (epoch 47.814), train_loss = 1.31114311, grad/param norm = 4.8318e-02, time/batch = 0.0824s	
3348/3500 (epoch 47.829), train_loss = 1.29815396, grad/param norm = 4.9801e-02, time/batch = 0.0822s	
3349/3500 (epoch 47.843), train_loss = 1.34026482, grad/param norm = 4.7257e-02, time/batch = 0.0820s	
3350/3500 (epoch 47.857), train_loss = 1.33586280, grad/param norm = 4.8011e-02, time/batch = 0.0824s	
3351/3500 (epoch 47.871), train_loss = 1.32658854, grad/param norm = 5.4655e-02, time/batch = 0.0832s	
3352/3500 (epoch 47.886), train_loss = 1.32031522, grad/param norm = 5.4434e-02, time/batch = 0.0823s	
3353/3500 (epoch 47.900), train_loss = 1.32954926, grad/param norm = 4.7606e-02, time/batch = 0.0823s	
3354/3500 (epoch 47.914), train_loss = 1.32899550, grad/param norm = 4.8066e-02, time/batch = 0.0836s	
3355/3500 (epoch 47.929), train_loss = 1.31194926, grad/param norm = 4.9820e-02, time/batch = 0.0839s	
3356/3500 (epoch 47.943), train_loss = 1.32894505, grad/param norm = 4.5776e-02, time/batch = 0.0834s	
3357/3500 (epoch 47.957), train_loss = 1.33425884, grad/param norm = 4.7948e-02, time/batch = 0.0825s	
3358/3500 (epoch 47.971), train_loss = 1.32636281, grad/param norm = 4.7602e-02, time/batch = 0.0825s	
3359/3500 (epoch 47.986), train_loss = 1.32436515, grad/param norm = 5.1831e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
3360/3500 (epoch 48.000), train_loss = 1.31419367, grad/param norm = 5.6611e-02, time/batch = 0.0824s	
3361/3500 (epoch 48.014), train_loss = 1.52382730, grad/param norm = 6.0807e-02, time/batch = 0.0827s	
3362/3500 (epoch 48.029), train_loss = 1.32172983, grad/param norm = 5.6467e-02, time/batch = 0.0821s	
3363/3500 (epoch 48.043), train_loss = 1.32170516, grad/param norm = 5.5022e-02, time/batch = 0.0827s	
3364/3500 (epoch 48.057), train_loss = 1.31276936, grad/param norm = 5.2693e-02, time/batch = 0.0835s	
3365/3500 (epoch 48.071), train_loss = 1.30351624, grad/param norm = 4.8257e-02, time/batch = 0.0839s	
3366/3500 (epoch 48.086), train_loss = 1.30666266, grad/param norm = 4.4021e-02, time/batch = 0.0833s	
3367/3500 (epoch 48.100), train_loss = 1.31984091, grad/param norm = 4.8470e-02, time/batch = 0.0824s	
3368/3500 (epoch 48.114), train_loss = 1.32497100, grad/param norm = 4.8233e-02, time/batch = 0.0823s	
3369/3500 (epoch 48.129), train_loss = 1.31645591, grad/param norm = 4.7197e-02, time/batch = 0.0821s	
3370/3500 (epoch 48.143), train_loss = 1.31860898, grad/param norm = 4.6555e-02, time/batch = 0.0824s	
3371/3500 (epoch 48.157), train_loss = 1.31334905, grad/param norm = 5.1953e-02, time/batch = 0.0832s	
3372/3500 (epoch 48.171), train_loss = 1.30936558, grad/param norm = 4.7866e-02, time/batch = 0.0823s	
3373/3500 (epoch 48.186), train_loss = 1.30971001, grad/param norm = 4.7173e-02, time/batch = 0.0828s	
3374/3500 (epoch 48.200), train_loss = 1.31210173, grad/param norm = 4.5360e-02, time/batch = 0.0836s	
3375/3500 (epoch 48.214), train_loss = 1.30941983, grad/param norm = 4.6742e-02, time/batch = 0.0840s	
3376/3500 (epoch 48.229), train_loss = 1.29872178, grad/param norm = 4.6826e-02, time/batch = 0.0834s	
3377/3500 (epoch 48.243), train_loss = 1.30917865, grad/param norm = 4.7351e-02, time/batch = 0.0825s	
3378/3500 (epoch 48.257), train_loss = 1.31966737, grad/param norm = 4.9508e-02, time/batch = 0.0828s	
3379/3500 (epoch 48.271), train_loss = 1.32793356, grad/param norm = 4.7909e-02, time/batch = 0.0817s	
3380/3500 (epoch 48.286), train_loss = 1.31959971, grad/param norm = 4.9870e-02, time/batch = 0.0824s	
3381/3500 (epoch 48.300), train_loss = 1.33857848, grad/param norm = 5.3243e-02, time/batch = 0.0827s	
3382/3500 (epoch 48.314), train_loss = 1.31090050, grad/param norm = 4.9277e-02, time/batch = 0.0821s	
3383/3500 (epoch 48.329), train_loss = 1.32863126, grad/param norm = 5.0776e-02, time/batch = 0.0826s	
3384/3500 (epoch 48.343), train_loss = 1.32073763, grad/param norm = 4.7596e-02, time/batch = 0.0836s	
3385/3500 (epoch 48.357), train_loss = 1.32801652, grad/param norm = 4.6423e-02, time/batch = 0.0840s	
3386/3500 (epoch 48.371), train_loss = 1.32629818, grad/param norm = 4.2574e-02, time/batch = 0.0834s	
3387/3500 (epoch 48.386), train_loss = 1.30518544, grad/param norm = 4.3432e-02, time/batch = 0.0824s	
3388/3500 (epoch 48.400), train_loss = 1.31344025, grad/param norm = 4.5864e-02, time/batch = 0.0828s	
3389/3500 (epoch 48.414), train_loss = 1.31401151, grad/param norm = 4.5030e-02, time/batch = 0.0820s	
3390/3500 (epoch 48.429), train_loss = 1.28475304, grad/param norm = 4.7894e-02, time/batch = 0.0825s	
3391/3500 (epoch 48.443), train_loss = 1.31779705, grad/param norm = 5.3396e-02, time/batch = 0.0832s	
3392/3500 (epoch 48.457), train_loss = 1.30997187, grad/param norm = 5.3453e-02, time/batch = 0.0824s	
3393/3500 (epoch 48.471), train_loss = 1.31852167, grad/param norm = 4.6719e-02, time/batch = 0.0824s	
3394/3500 (epoch 48.486), train_loss = 1.34151586, grad/param norm = 4.7768e-02, time/batch = 0.0835s	
3395/3500 (epoch 48.500), train_loss = 1.30868273, grad/param norm = 5.2596e-02, time/batch = 0.0840s	
3396/3500 (epoch 48.514), train_loss = 1.32811321, grad/param norm = 4.7488e-02, time/batch = 0.0837s	
3397/3500 (epoch 48.529), train_loss = 1.33648751, grad/param norm = 4.5854e-02, time/batch = 0.0826s	
3398/3500 (epoch 48.543), train_loss = 1.32123490, grad/param norm = 4.5275e-02, time/batch = 0.0830s	
3399/3500 (epoch 48.557), train_loss = 1.29142462, grad/param norm = 4.7678e-02, time/batch = 0.0818s	
3400/3500 (epoch 48.571), train_loss = 1.29975423, grad/param norm = 4.7020e-02, time/batch = 0.0824s	
3401/3500 (epoch 48.586), train_loss = 1.29999002, grad/param norm = 5.3900e-02, time/batch = 0.0827s	
3402/3500 (epoch 48.600), train_loss = 1.29437138, grad/param norm = 5.0405e-02, time/batch = 0.0826s	
3403/3500 (epoch 48.614), train_loss = 1.31074790, grad/param norm = 4.8715e-02, time/batch = 0.0822s	
3404/3500 (epoch 48.629), train_loss = 1.29107026, grad/param norm = 5.4025e-02, time/batch = 0.0835s	
3405/3500 (epoch 48.643), train_loss = 1.31459914, grad/param norm = 4.5690e-02, time/batch = 0.0838s	
3406/3500 (epoch 48.657), train_loss = 1.29695589, grad/param norm = 4.4956e-02, time/batch = 0.0834s	
3407/3500 (epoch 48.671), train_loss = 1.27775557, grad/param norm = 5.8165e-02, time/batch = 0.0823s	
3408/3500 (epoch 48.686), train_loss = 1.31458383, grad/param norm = 5.5460e-02, time/batch = 0.0823s	
3409/3500 (epoch 48.700), train_loss = 1.31592147, grad/param norm = 5.1428e-02, time/batch = 0.0821s	
3410/3500 (epoch 48.714), train_loss = 1.30937223, grad/param norm = 5.6184e-02, time/batch = 0.0825s	
3411/3500 (epoch 48.729), train_loss = 1.30698596, grad/param norm = 5.0250e-02, time/batch = 0.0832s	
3412/3500 (epoch 48.743), train_loss = 1.29667716, grad/param norm = 4.9478e-02, time/batch = 0.0823s	
3413/3500 (epoch 48.757), train_loss = 1.31518078, grad/param norm = 4.7225e-02, time/batch = 0.0824s	
3414/3500 (epoch 48.771), train_loss = 1.31812717, grad/param norm = 4.4917e-02, time/batch = 0.0835s	
3415/3500 (epoch 48.786), train_loss = 1.29988938, grad/param norm = 4.6381e-02, time/batch = 0.0841s	
3416/3500 (epoch 48.800), train_loss = 1.29143363, grad/param norm = 4.6056e-02, time/batch = 0.0837s	
3417/3500 (epoch 48.814), train_loss = 1.30861322, grad/param norm = 4.7824e-02, time/batch = 0.0829s	
3418/3500 (epoch 48.829), train_loss = 1.29573973, grad/param norm = 4.9317e-02, time/batch = 0.0826s	
3419/3500 (epoch 48.843), train_loss = 1.33761788, grad/param norm = 4.6909e-02, time/batch = 0.0817s	
3420/3500 (epoch 48.857), train_loss = 1.33332897, grad/param norm = 4.7793e-02, time/batch = 0.0823s	
3421/3500 (epoch 48.871), train_loss = 1.32409196, grad/param norm = 5.4314e-02, time/batch = 0.0827s	
3422/3500 (epoch 48.886), train_loss = 1.31771379, grad/param norm = 5.4235e-02, time/batch = 0.0821s	
3423/3500 (epoch 48.900), train_loss = 1.32707581, grad/param norm = 4.7404e-02, time/batch = 0.0822s	
3424/3500 (epoch 48.914), train_loss = 1.32631303, grad/param norm = 4.7381e-02, time/batch = 0.0834s	
3425/3500 (epoch 48.929), train_loss = 1.30944036, grad/param norm = 4.8889e-02, time/batch = 0.0838s	
3426/3500 (epoch 48.943), train_loss = 1.32635427, grad/param norm = 4.4917e-02, time/batch = 0.0832s	
3427/3500 (epoch 48.957), train_loss = 1.33172818, grad/param norm = 4.7459e-02, time/batch = 0.0824s	
3428/3500 (epoch 48.971), train_loss = 1.32369364, grad/param norm = 4.7124e-02, time/batch = 0.0823s	
3429/3500 (epoch 48.986), train_loss = 1.32177617, grad/param norm = 5.0303e-02, time/batch = 0.0823s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
3430/3500 (epoch 49.000), train_loss = 1.31140448, grad/param norm = 5.4643e-02, time/batch = 0.0825s	
3431/3500 (epoch 49.014), train_loss = 1.52160651, grad/param norm = 6.0020e-02, time/batch = 0.0832s	
3432/3500 (epoch 49.029), train_loss = 1.31909869, grad/param norm = 5.6353e-02, time/batch = 0.0824s	
3433/3500 (epoch 49.043), train_loss = 1.31928546, grad/param norm = 5.4736e-02, time/batch = 0.0823s	
3434/3500 (epoch 49.057), train_loss = 1.31038346, grad/param norm = 5.1980e-02, time/batch = 0.0856s	
3435/3500 (epoch 49.071), train_loss = 1.30110593, grad/param norm = 4.8002e-02, time/batch = 0.0840s	
3436/3500 (epoch 49.086), train_loss = 1.30415000, grad/param norm = 4.3941e-02, time/batch = 0.0837s	
3437/3500 (epoch 49.100), train_loss = 1.31739131, grad/param norm = 4.8179e-02, time/batch = 0.0826s	
3438/3500 (epoch 49.114), train_loss = 1.32243247, grad/param norm = 4.7933e-02, time/batch = 0.0825s	
3439/3500 (epoch 49.129), train_loss = 1.31401540, grad/param norm = 4.6986e-02, time/batch = 0.0818s	
3440/3500 (epoch 49.143), train_loss = 1.31622671, grad/param norm = 4.6463e-02, time/batch = 0.0823s	
3441/3500 (epoch 49.157), train_loss = 1.31110463, grad/param norm = 5.1924e-02, time/batch = 0.0827s	
3442/3500 (epoch 49.171), train_loss = 1.30698614, grad/param norm = 4.7606e-02, time/batch = 0.0826s	
3443/3500 (epoch 49.186), train_loss = 1.30734694, grad/param norm = 4.7008e-02, time/batch = 0.0823s	
3444/3500 (epoch 49.200), train_loss = 1.30961217, grad/param norm = 4.5043e-02, time/batch = 0.0835s	
3445/3500 (epoch 49.214), train_loss = 1.30710270, grad/param norm = 4.6618e-02, time/batch = 0.0838s	
3446/3500 (epoch 49.229), train_loss = 1.29631226, grad/param norm = 4.6721e-02, time/batch = 0.0834s	
3447/3500 (epoch 49.243), train_loss = 1.30673052, grad/param norm = 4.7084e-02, time/batch = 0.0824s	
3448/3500 (epoch 49.257), train_loss = 1.31728785, grad/param norm = 4.9792e-02, time/batch = 0.0823s	
3449/3500 (epoch 49.271), train_loss = 1.32554517, grad/param norm = 4.7886e-02, time/batch = 0.0820s	
3450/3500 (epoch 49.286), train_loss = 1.31733266, grad/param norm = 4.9659e-02, time/batch = 0.0824s	
3451/3500 (epoch 49.300), train_loss = 1.33596179, grad/param norm = 5.3170e-02, time/batch = 0.0832s	
3452/3500 (epoch 49.314), train_loss = 1.30850957, grad/param norm = 4.9035e-02, time/batch = 0.0828s	
3453/3500 (epoch 49.329), train_loss = 1.32599054, grad/param norm = 5.0122e-02, time/batch = 0.0823s	
3454/3500 (epoch 49.343), train_loss = 1.31813109, grad/param norm = 4.6972e-02, time/batch = 0.0837s	
3455/3500 (epoch 49.357), train_loss = 1.32558238, grad/param norm = 4.5960e-02, time/batch = 0.0839s	
3456/3500 (epoch 49.371), train_loss = 1.32391954, grad/param norm = 4.2347e-02, time/batch = 0.0835s	
3457/3500 (epoch 49.386), train_loss = 1.30285708, grad/param norm = 4.3192e-02, time/batch = 0.0831s	
3458/3500 (epoch 49.400), train_loss = 1.31119594, grad/param norm = 4.6059e-02, time/batch = 0.0825s	
3459/3500 (epoch 49.414), train_loss = 1.31154733, grad/param norm = 4.4973e-02, time/batch = 0.0818s	
3460/3500 (epoch 49.429), train_loss = 1.28226779, grad/param norm = 4.7333e-02, time/batch = 0.0824s	
3461/3500 (epoch 49.443), train_loss = 1.31536982, grad/param norm = 5.1479e-02, time/batch = 0.0828s	
3462/3500 (epoch 49.457), train_loss = 1.30722929, grad/param norm = 5.1197e-02, time/batch = 0.0826s	
3463/3500 (epoch 49.471), train_loss = 1.31606653, grad/param norm = 4.6533e-02, time/batch = 0.0823s	
3464/3500 (epoch 49.486), train_loss = 1.33923168, grad/param norm = 4.8314e-02, time/batch = 0.0835s	
3465/3500 (epoch 49.500), train_loss = 1.30637082, grad/param norm = 5.2356e-02, time/batch = 0.0838s	
3466/3500 (epoch 49.514), train_loss = 1.32558515, grad/param norm = 4.6493e-02, time/batch = 0.0833s	
3467/3500 (epoch 49.529), train_loss = 1.33413943, grad/param norm = 4.5762e-02, time/batch = 0.0828s	
3468/3500 (epoch 49.543), train_loss = 1.31882411, grad/param norm = 4.5216e-02, time/batch = 0.0823s	
3469/3500 (epoch 49.557), train_loss = 1.28913678, grad/param norm = 4.7276e-02, time/batch = 0.0820s	
3470/3500 (epoch 49.571), train_loss = 1.29752226, grad/param norm = 4.7046e-02, time/batch = 0.0825s	
3471/3500 (epoch 49.586), train_loss = 1.29763579, grad/param norm = 5.3970e-02, time/batch = 0.0833s	
3472/3500 (epoch 49.600), train_loss = 1.29190701, grad/param norm = 5.0447e-02, time/batch = 0.0823s	
3473/3500 (epoch 49.614), train_loss = 1.30833996, grad/param norm = 4.8602e-02, time/batch = 0.0823s	
3474/3500 (epoch 49.629), train_loss = 1.28872190, grad/param norm = 5.4010e-02, time/batch = 0.0836s	
3475/3500 (epoch 49.643), train_loss = 1.31229885, grad/param norm = 4.5406e-02, time/batch = 0.0841s	
3476/3500 (epoch 49.657), train_loss = 1.29444934, grad/param norm = 4.4869e-02, time/batch = 0.0836s	
3477/3500 (epoch 49.671), train_loss = 1.27509393, grad/param norm = 5.7476e-02, time/batch = 0.0831s	
3478/3500 (epoch 49.686), train_loss = 1.31200987, grad/param norm = 5.3950e-02, time/batch = 0.0825s	
3479/3500 (epoch 49.700), train_loss = 1.31347745, grad/param norm = 5.0448e-02, time/batch = 0.0818s	
3480/3500 (epoch 49.714), train_loss = 1.30680321, grad/param norm = 5.4868e-02, time/batch = 0.0824s	
3481/3500 (epoch 49.729), train_loss = 1.30435071, grad/param norm = 4.8943e-02, time/batch = 0.0827s	
3482/3500 (epoch 49.743), train_loss = 1.29410418, grad/param norm = 4.8829e-02, time/batch = 0.0821s	
3483/3500 (epoch 49.757), train_loss = 1.31263396, grad/param norm = 4.6678e-02, time/batch = 0.0822s	
3484/3500 (epoch 49.771), train_loss = 1.31580618, grad/param norm = 4.4595e-02, time/batch = 0.0834s	
3485/3500 (epoch 49.786), train_loss = 1.29728891, grad/param norm = 4.6475e-02, time/batch = 0.0839s	
3486/3500 (epoch 49.800), train_loss = 1.28891512, grad/param norm = 4.6017e-02, time/batch = 0.0834s	
3487/3500 (epoch 49.814), train_loss = 1.30620304, grad/param norm = 4.7500e-02, time/batch = 0.0825s	
3488/3500 (epoch 49.829), train_loss = 1.29343643, grad/param norm = 4.9001e-02, time/batch = 0.0823s	
3489/3500 (epoch 49.843), train_loss = 1.33509432, grad/param norm = 4.6630e-02, time/batch = 0.0820s	
3490/3500 (epoch 49.857), train_loss = 1.33090234, grad/param norm = 4.7613e-02, time/batch = 0.0824s	
3491/3500 (epoch 49.871), train_loss = 1.32170244, grad/param norm = 5.4067e-02, time/batch = 0.0832s	
3492/3500 (epoch 49.886), train_loss = 1.31520851, grad/param norm = 5.3985e-02, time/batch = 0.0823s	
3493/3500 (epoch 49.900), train_loss = 1.32469069, grad/param norm = 4.7074e-02, time/batch = 0.0822s	
3494/3500 (epoch 49.914), train_loss = 1.32375125, grad/param norm = 4.6760e-02, time/batch = 0.0836s	
3495/3500 (epoch 49.929), train_loss = 1.30704359, grad/param norm = 4.8098e-02, time/batch = 0.0840s	
3496/3500 (epoch 49.943), train_loss = 1.32389022, grad/param norm = 4.4194e-02, time/batch = 0.0839s	
3497/3500 (epoch 49.957), train_loss = 1.32931930, grad/param norm = 4.7048e-02, time/batch = 0.0826s	
3498/3500 (epoch 49.971), train_loss = 1.32113558, grad/param norm = 4.6648e-02, time/batch = 0.0825s	
3499/3500 (epoch 49.986), train_loss = 1.31931652, grad/param norm = 4.8953e-02, time/batch = 0.0818s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/4...	
2/4...	
3/4...	
4/4...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.4325.t7	
3500/3500 (epoch 50.000), train_loss = 1.30875393, grad/param norm = 5.2883e-02, time/batch = 0.0823s	
