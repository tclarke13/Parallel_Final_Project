using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 105, val: 6, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 873793	
cloning rnn	
cloning criterion	
1/5250 (epoch 0.010), train_loss = 4.19148554, grad/param norm = 5.3360e-01, time/batch = 0.4055s	
2/5250 (epoch 0.019), train_loss = 3.50878998, grad/param norm = 8.7600e-01, time/batch = 0.1169s	
3/5250 (epoch 0.029), train_loss = 3.67936578, grad/param norm = 1.5624e+00, time/batch = 0.1156s	
4/5250 (epoch 0.038), train_loss = 3.43758527, grad/param norm = 9.6218e-01, time/batch = 0.1160s	
5/5250 (epoch 0.048), train_loss = 3.43466735, grad/param norm = 6.3551e-01, time/batch = 0.1161s	
6/5250 (epoch 0.057), train_loss = 3.39613483, grad/param norm = 7.4480e-01, time/batch = 0.1157s	
7/5250 (epoch 0.067), train_loss = 3.37277790, grad/param norm = 6.4805e-01, time/batch = 0.1158s	
8/5250 (epoch 0.076), train_loss = 3.31510862, grad/param norm = 2.9473e-01, time/batch = 0.1154s	
9/5250 (epoch 0.086), train_loss = 3.36476676, grad/param norm = 2.7470e-01, time/batch = 0.1162s	
10/5250 (epoch 0.095), train_loss = 3.32612955, grad/param norm = 2.6554e-01, time/batch = 0.1160s	
11/5250 (epoch 0.105), train_loss = 3.30899304, grad/param norm = 2.7191e-01, time/batch = 0.1154s	
12/5250 (epoch 0.114), train_loss = 3.35003318, grad/param norm = 2.3366e-01, time/batch = 0.1144s	
13/5250 (epoch 0.124), train_loss = 3.32269312, grad/param norm = 1.9236e-01, time/batch = 0.1146s	
14/5250 (epoch 0.133), train_loss = 3.34317378, grad/param norm = 1.7401e-01, time/batch = 0.1149s	
15/5250 (epoch 0.143), train_loss = 3.33327397, grad/param norm = 1.3917e-01, time/batch = 0.1148s	
16/5250 (epoch 0.152), train_loss = 3.33683394, grad/param norm = 1.4673e-01, time/batch = 0.1146s	
17/5250 (epoch 0.162), train_loss = 3.31815073, grad/param norm = 1.8268e-01, time/batch = 0.1148s	
18/5250 (epoch 0.171), train_loss = 3.31330464, grad/param norm = 1.6226e-01, time/batch = 0.1142s	
19/5250 (epoch 0.181), train_loss = 3.34478551, grad/param norm = 1.4738e-01, time/batch = 0.1151s	
20/5250 (epoch 0.190), train_loss = 3.31890533, grad/param norm = 1.6174e-01, time/batch = 0.1157s	
21/5250 (epoch 0.200), train_loss = 3.31872668, grad/param norm = 1.6605e-01, time/batch = 0.1153s	
22/5250 (epoch 0.210), train_loss = 3.30770597, grad/param norm = 2.3767e-01, time/batch = 0.1143s	
23/5250 (epoch 0.219), train_loss = 3.29856304, grad/param norm = 2.7947e-01, time/batch = 0.1147s	
24/5250 (epoch 0.229), train_loss = 3.33141599, grad/param norm = 2.5538e-01, time/batch = 0.1147s	
25/5250 (epoch 0.238), train_loss = 3.32130727, grad/param norm = 2.3054e-01, time/batch = 0.1150s	
26/5250 (epoch 0.248), train_loss = 3.29711637, grad/param norm = 2.8957e-01, time/batch = 0.1147s	
27/5250 (epoch 0.257), train_loss = 3.33883372, grad/param norm = 4.0704e-01, time/batch = 0.1150s	
28/5250 (epoch 0.267), train_loss = 3.33854822, grad/param norm = 3.4667e-01, time/batch = 0.1143s	
29/5250 (epoch 0.276), train_loss = 3.31213514, grad/param norm = 2.4472e-01, time/batch = 0.1152s	
30/5250 (epoch 0.286), train_loss = 3.62172051, grad/param norm = 6.5261e+00, time/batch = 0.1148s	
31/5250 (epoch 0.295), train_loss = 3.34873099, grad/param norm = 3.8354e-01, time/batch = 0.1155s	
32/5250 (epoch 0.305), train_loss = 3.35382565, grad/param norm = 2.9037e-01, time/batch = 0.1142s	
33/5250 (epoch 0.314), train_loss = 3.35823211, grad/param norm = 2.1193e-01, time/batch = 0.1145s	
34/5250 (epoch 0.324), train_loss = 3.31348278, grad/param norm = 1.9161e-01, time/batch = 0.1146s	
35/5250 (epoch 0.333), train_loss = 3.29839768, grad/param norm = 1.7202e-01, time/batch = 0.1147s	
36/5250 (epoch 0.343), train_loss = 3.30298696, grad/param norm = 1.3795e-01, time/batch = 0.1147s	
37/5250 (epoch 0.352), train_loss = 3.29755733, grad/param norm = 1.5900e-01, time/batch = 0.1148s	
38/5250 (epoch 0.362), train_loss = 3.32340299, grad/param norm = 1.8935e-01, time/batch = 0.1144s	
39/5250 (epoch 0.371), train_loss = 3.31307000, grad/param norm = 1.9859e-01, time/batch = 0.1152s	
40/5250 (epoch 0.381), train_loss = 3.30509233, grad/param norm = 2.2112e-01, time/batch = 0.1150s	
41/5250 (epoch 0.390), train_loss = 3.30232941, grad/param norm = 2.6731e-01, time/batch = 0.1154s	
42/5250 (epoch 0.400), train_loss = 3.29820013, grad/param norm = 2.5150e-01, time/batch = 0.1144s	
43/5250 (epoch 0.410), train_loss = 3.28927056, grad/param norm = 2.5217e-01, time/batch = 0.1146s	
44/5250 (epoch 0.419), train_loss = 3.27879593, grad/param norm = 2.7298e-01, time/batch = 0.1147s	
45/5250 (epoch 0.429), train_loss = 3.27663714, grad/param norm = 4.5262e-01, time/batch = 0.1149s	
46/5250 (epoch 0.438), train_loss = 3.29958899, grad/param norm = 4.9004e-01, time/batch = 0.1148s	
47/5250 (epoch 0.448), train_loss = 3.28038696, grad/param norm = 3.4282e-01, time/batch = 0.1148s	
48/5250 (epoch 0.457), train_loss = 3.26779006, grad/param norm = 2.9145e-01, time/batch = 0.1140s	
49/5250 (epoch 0.467), train_loss = 3.25640644, grad/param norm = 3.3011e-01, time/batch = 0.1152s	
50/5250 (epoch 0.476), train_loss = 3.26415483, grad/param norm = 4.1129e-01, time/batch = 0.1148s	
51/5250 (epoch 0.486), train_loss = 3.28082307, grad/param norm = 3.6094e-01, time/batch = 0.1160s	
52/5250 (epoch 0.495), train_loss = 3.20985668, grad/param norm = 1.7822e-01, time/batch = 0.1143s	
53/5250 (epoch 0.505), train_loss = 3.19576435, grad/param norm = 1.2921e-01, time/batch = 0.1146s	
54/5250 (epoch 0.514), train_loss = 3.19535910, grad/param norm = 1.4014e-01, time/batch = 0.1148s	
55/5250 (epoch 0.524), train_loss = 3.19221201, grad/param norm = 1.5103e-01, time/batch = 0.1149s	
56/5250 (epoch 0.533), train_loss = 3.19952576, grad/param norm = 2.1759e-01, time/batch = 0.1149s	
57/5250 (epoch 0.543), train_loss = 3.20855473, grad/param norm = 2.2313e-01, time/batch = 0.1147s	
58/5250 (epoch 0.552), train_loss = 3.20078895, grad/param norm = 2.1087e-01, time/batch = 0.1143s	
59/5250 (epoch 0.562), train_loss = 3.19508965, grad/param norm = 2.3723e-01, time/batch = 0.1150s	
60/5250 (epoch 0.571), train_loss = 3.20935781, grad/param norm = 3.8742e-01, time/batch = 0.1150s	
61/5250 (epoch 0.581), train_loss = 3.27475331, grad/param norm = 4.9215e-01, time/batch = 0.1153s	
62/5250 (epoch 0.590), train_loss = 3.20955904, grad/param norm = 2.9994e-01, time/batch = 0.1142s	
63/5250 (epoch 0.600), train_loss = 3.18812112, grad/param norm = 1.9559e-01, time/batch = 0.1148s	
64/5250 (epoch 0.610), train_loss = 3.16541606, grad/param norm = 1.5714e-01, time/batch = 0.1148s	
65/5250 (epoch 0.619), train_loss = 3.15997427, grad/param norm = 1.6830e-01, time/batch = 0.1152s	
66/5250 (epoch 0.629), train_loss = 3.17867927, grad/param norm = 2.0226e-01, time/batch = 0.1146s	
67/5250 (epoch 0.638), train_loss = 3.17552155, grad/param norm = 2.1488e-01, time/batch = 0.1150s	
68/5250 (epoch 0.648), train_loss = 3.14953652, grad/param norm = 2.4511e-01, time/batch = 0.1143s	
69/5250 (epoch 0.657), train_loss = 3.15637261, grad/param norm = 3.0069e-01, time/batch = 0.1149s	
70/5250 (epoch 0.667), train_loss = 3.16382376, grad/param norm = 3.4129e-01, time/batch = 0.1149s	
71/5250 (epoch 0.676), train_loss = 3.16010596, grad/param norm = 4.2739e-01, time/batch = 0.1153s	
72/5250 (epoch 0.686), train_loss = 3.16558628, grad/param norm = 4.3487e-01, time/batch = 0.1144s	
73/5250 (epoch 0.695), train_loss = 3.13504093, grad/param norm = 3.8090e-01, time/batch = 0.1145s	
74/5250 (epoch 0.705), train_loss = 3.13603850, grad/param norm = 4.0704e-01, time/batch = 0.1147s	
75/5250 (epoch 0.714), train_loss = 3.17177951, grad/param norm = 5.8479e-01, time/batch = 0.1149s	
76/5250 (epoch 0.724), train_loss = 3.30974511, grad/param norm = 8.3601e-01, time/batch = 0.1148s	
77/5250 (epoch 0.733), train_loss = 3.18273368, grad/param norm = 5.3857e-01, time/batch = 0.1148s	
78/5250 (epoch 0.743), train_loss = 3.20775188, grad/param norm = 4.1667e-01, time/batch = 0.1142s	
79/5250 (epoch 0.752), train_loss = 3.13782922, grad/param norm = 2.1571e-01, time/batch = 0.1151s	
80/5250 (epoch 0.762), train_loss = 3.14417813, grad/param norm = 1.5540e-01, time/batch = 0.1150s	
81/5250 (epoch 0.771), train_loss = 3.11897400, grad/param norm = 1.4468e-01, time/batch = 0.1156s	
82/5250 (epoch 0.781), train_loss = 3.11590820, grad/param norm = 1.1925e-01, time/batch = 0.1141s	
83/5250 (epoch 0.790), train_loss = 3.11304424, grad/param norm = 1.1323e-01, time/batch = 0.1146s	
84/5250 (epoch 0.800), train_loss = 3.10281847, grad/param norm = 1.1085e-01, time/batch = 0.1146s	
85/5250 (epoch 0.810), train_loss = 3.08317039, grad/param norm = 1.3401e-01, time/batch = 0.1148s	
86/5250 (epoch 0.819), train_loss = 3.09019907, grad/param norm = 1.6419e-01, time/batch = 0.1147s	
87/5250 (epoch 0.829), train_loss = 3.08918740, grad/param norm = 1.6734e-01, time/batch = 0.1148s	
88/5250 (epoch 0.838), train_loss = 3.07857540, grad/param norm = 1.6888e-01, time/batch = 0.1144s	
89/5250 (epoch 0.848), train_loss = 3.08606567, grad/param norm = 2.9331e-01, time/batch = 0.1151s	
90/5250 (epoch 0.857), train_loss = 3.13399664, grad/param norm = 5.3131e-01, time/batch = 0.1149s	
91/5250 (epoch 0.867), train_loss = 3.15568233, grad/param norm = 7.1925e-01, time/batch = 0.1154s	
92/5250 (epoch 0.876), train_loss = 3.20512002, grad/param norm = 7.5966e-01, time/batch = 0.1144s	
93/5250 (epoch 0.886), train_loss = 3.07815510, grad/param norm = 3.0155e-01, time/batch = 0.1147s	
94/5250 (epoch 0.895), train_loss = 3.05670835, grad/param norm = 2.1669e-01, time/batch = 0.1148s	
95/5250 (epoch 0.905), train_loss = 3.04270123, grad/param norm = 1.9018e-01, time/batch = 0.1150s	
96/5250 (epoch 0.914), train_loss = 3.03242481, grad/param norm = 1.9342e-01, time/batch = 0.1149s	
97/5250 (epoch 0.924), train_loss = 3.01771282, grad/param norm = 2.1971e-01, time/batch = 0.1149s	
98/5250 (epoch 0.933), train_loss = 3.01398904, grad/param norm = 2.9249e-01, time/batch = 0.1141s	
99/5250 (epoch 0.943), train_loss = 3.04181694, grad/param norm = 5.9497e-01, time/batch = 0.1150s	
100/5250 (epoch 0.952), train_loss = 3.13025197, grad/param norm = 8.5384e-01, time/batch = 0.1149s	
101/5250 (epoch 0.962), train_loss = 3.07786160, grad/param norm = 5.3034e-01, time/batch = 0.1155s	
102/5250 (epoch 0.971), train_loss = 3.02695914, grad/param norm = 3.3177e-01, time/batch = 0.1142s	
103/5250 (epoch 0.981), train_loss = 3.00545207, grad/param norm = 3.1537e-01, time/batch = 0.1146s	
104/5250 (epoch 0.990), train_loss = 3.00545802, grad/param norm = 3.6415e-01, time/batch = 0.1147s	
105/5250 (epoch 1.000), train_loss = 2.98481003, grad/param norm = 3.8785e-01, time/batch = 0.1150s	
106/5250 (epoch 1.010), train_loss = 2.99942733, grad/param norm = 4.1439e-01, time/batch = 0.1158s	
107/5250 (epoch 1.019), train_loss = 2.98934003, grad/param norm = 4.4527e-01, time/batch = 0.1150s	
108/5250 (epoch 1.029), train_loss = 2.97130219, grad/param norm = 3.8115e-01, time/batch = 0.1143s	
109/5250 (epoch 1.038), train_loss = 2.97595963, grad/param norm = 3.9806e-01, time/batch = 0.1151s	
110/5250 (epoch 1.048), train_loss = 2.98044517, grad/param norm = 5.1898e-01, time/batch = 0.1150s	
111/5250 (epoch 1.057), train_loss = 2.96864834, grad/param norm = 5.4739e-01, time/batch = 0.1156s	
112/5250 (epoch 1.067), train_loss = 2.97294651, grad/param norm = 5.9848e-01, time/batch = 0.1143s	
113/5250 (epoch 1.076), train_loss = 2.93397604, grad/param norm = 5.4796e-01, time/batch = 0.1147s	
114/5250 (epoch 1.086), train_loss = 2.92542333, grad/param norm = 4.9148e-01, time/batch = 0.1149s	
115/5250 (epoch 1.095), train_loss = 2.91781493, grad/param norm = 4.2505e-01, time/batch = 0.1149s	
116/5250 (epoch 1.105), train_loss = 2.88753103, grad/param norm = 3.7814e-01, time/batch = 0.1148s	
117/5250 (epoch 1.114), train_loss = 2.87384264, grad/param norm = 3.3688e-01, time/batch = 0.1150s	
118/5250 (epoch 1.124), train_loss = 2.83754270, grad/param norm = 2.9081e-01, time/batch = 0.1142s	
119/5250 (epoch 1.133), train_loss = 2.81812072, grad/param norm = 3.0701e-01, time/batch = 0.1152s	
120/5250 (epoch 1.143), train_loss = 2.80078210, grad/param norm = 3.8624e-01, time/batch = 0.1150s	
121/5250 (epoch 1.152), train_loss = 2.81993921, grad/param norm = 5.0195e-01, time/batch = 0.1162s	
122/5250 (epoch 1.162), train_loss = 2.87561206, grad/param norm = 9.7106e-01, time/batch = 0.1142s	
123/5250 (epoch 1.171), train_loss = 2.96997432, grad/param norm = 8.7292e-01, time/batch = 0.1147s	
124/5250 (epoch 1.181), train_loss = 2.84498910, grad/param norm = 4.1267e-01, time/batch = 0.1150s	
125/5250 (epoch 1.190), train_loss = 2.81823325, grad/param norm = 5.1544e-01, time/batch = 0.1151s	
126/5250 (epoch 1.200), train_loss = 2.77525014, grad/param norm = 3.3812e-01, time/batch = 0.1148s	
127/5250 (epoch 1.210), train_loss = 2.75368567, grad/param norm = 2.4262e-01, time/batch = 0.1149s	
128/5250 (epoch 1.219), train_loss = 2.73965719, grad/param norm = 3.0034e-01, time/batch = 0.1143s	
129/5250 (epoch 1.229), train_loss = 2.75313876, grad/param norm = 4.6019e-01, time/batch = 0.1152s	
130/5250 (epoch 1.238), train_loss = 2.80743387, grad/param norm = 5.9753e-01, time/batch = 0.1150s	
131/5250 (epoch 1.248), train_loss = 2.79095935, grad/param norm = 5.4896e-01, time/batch = 0.1155s	
132/5250 (epoch 1.257), train_loss = 2.74339869, grad/param norm = 3.5023e-01, time/batch = 0.1143s	
133/5250 (epoch 1.267), train_loss = 2.69551398, grad/param norm = 2.8831e-01, time/batch = 0.1147s	
134/5250 (epoch 1.276), train_loss = 2.68554723, grad/param norm = 4.4385e-01, time/batch = 0.1147s	
135/5250 (epoch 1.286), train_loss = 2.70400750, grad/param norm = 5.0714e-01, time/batch = 0.1148s	
136/5250 (epoch 1.295), train_loss = 2.66265861, grad/param norm = 4.2178e-01, time/batch = 0.1147s	
137/5250 (epoch 1.305), train_loss = 2.67356369, grad/param norm = 4.7184e-01, time/batch = 0.1149s	
138/5250 (epoch 1.314), train_loss = 2.68344628, grad/param norm = 5.5628e-01, time/batch = 0.1143s	
139/5250 (epoch 1.324), train_loss = 2.69389364, grad/param norm = 5.9502e-01, time/batch = 0.1151s	
140/5250 (epoch 1.333), train_loss = 2.69555511, grad/param norm = 5.4456e-01, time/batch = 0.1149s	
141/5250 (epoch 1.343), train_loss = 2.63661441, grad/param norm = 3.3626e-01, time/batch = 0.1154s	
142/5250 (epoch 1.352), train_loss = 2.60321891, grad/param norm = 3.2074e-01, time/batch = 0.1142s	
143/5250 (epoch 1.362), train_loss = 2.64495541, grad/param norm = 4.4848e-01, time/batch = 0.1147s	
144/5250 (epoch 1.371), train_loss = 2.65656811, grad/param norm = 4.5162e-01, time/batch = 0.1147s	
145/5250 (epoch 1.381), train_loss = 2.59271695, grad/param norm = 3.2845e-01, time/batch = 0.1151s	
146/5250 (epoch 1.390), train_loss = 2.60350850, grad/param norm = 3.7615e-01, time/batch = 0.1147s	
147/5250 (epoch 1.400), train_loss = 2.64380929, grad/param norm = 1.0539e+00, time/batch = 0.1148s	
148/5250 (epoch 1.410), train_loss = 2.70594851, grad/param norm = 8.3780e-01, time/batch = 0.1142s	
149/5250 (epoch 1.419), train_loss = 2.66522843, grad/param norm = 6.0189e-01, time/batch = 0.1151s	
150/5250 (epoch 1.429), train_loss = 2.58359576, grad/param norm = 3.1151e-01, time/batch = 0.1150s	
151/5250 (epoch 1.438), train_loss = 2.57431008, grad/param norm = 1.7963e-01, time/batch = 0.1161s	
152/5250 (epoch 1.448), train_loss = 2.53209692, grad/param norm = 1.1278e-01, time/batch = 0.1143s	
153/5250 (epoch 1.457), train_loss = 2.51466488, grad/param norm = 1.2066e-01, time/batch = 0.1146s	
154/5250 (epoch 1.467), train_loss = 2.50900044, grad/param norm = 1.6358e-01, time/batch = 0.1148s	
155/5250 (epoch 1.476), train_loss = 2.52010813, grad/param norm = 2.5070e-01, time/batch = 0.1149s	
156/5250 (epoch 1.486), train_loss = 2.55726357, grad/param norm = 4.4967e-01, time/batch = 0.1148s	
157/5250 (epoch 1.495), train_loss = 2.57081609, grad/param norm = 5.5527e-01, time/batch = 0.1148s	
158/5250 (epoch 1.505), train_loss = 2.58972203, grad/param norm = 5.1462e-01, time/batch = 0.1144s	
159/5250 (epoch 1.514), train_loss = 2.54443483, grad/param norm = 3.5793e-01, time/batch = 0.1150s	
160/5250 (epoch 1.524), train_loss = 2.51319162, grad/param norm = 3.1965e-01, time/batch = 0.1147s	
161/5250 (epoch 1.533), train_loss = 2.51561580, grad/param norm = 4.6892e-01, time/batch = 0.1155s	
162/5250 (epoch 1.543), train_loss = 2.54882363, grad/param norm = 5.4775e-01, time/batch = 0.1142s	
163/5250 (epoch 1.552), train_loss = 2.55687365, grad/param norm = 5.1881e-01, time/batch = 0.1147s	
164/5250 (epoch 1.562), train_loss = 2.51815021, grad/param norm = 3.5801e-01, time/batch = 0.1148s	
165/5250 (epoch 1.571), train_loss = 2.48396891, grad/param norm = 2.7493e-01, time/batch = 0.1149s	
166/5250 (epoch 1.581), train_loss = 2.47886250, grad/param norm = 2.7329e-01, time/batch = 0.1149s	
167/5250 (epoch 1.590), train_loss = 2.47084456, grad/param norm = 3.7485e-01, time/batch = 0.1150s	
168/5250 (epoch 1.600), train_loss = 2.51830045, grad/param norm = 4.7700e-01, time/batch = 0.1144s	
169/5250 (epoch 1.610), train_loss = 2.48890678, grad/param norm = 4.2054e-01, time/batch = 0.1152s	
170/5250 (epoch 1.619), train_loss = 2.45953286, grad/param norm = 3.3977e-01, time/batch = 0.1148s	
171/5250 (epoch 1.629), train_loss = 2.47641904, grad/param norm = 2.6944e-01, time/batch = 0.1155s	
172/5250 (epoch 1.638), train_loss = 2.45938272, grad/param norm = 2.7226e-01, time/batch = 0.1144s	
173/5250 (epoch 1.648), train_loss = 2.45177665, grad/param norm = 3.9636e-01, time/batch = 0.1146s	
174/5250 (epoch 1.657), train_loss = 2.49821511, grad/param norm = 6.1793e-01, time/batch = 0.1149s	
175/5250 (epoch 1.667), train_loss = 2.57914182, grad/param norm = 5.4391e-01, time/batch = 0.1149s	
176/5250 (epoch 1.676), train_loss = 2.52184730, grad/param norm = 5.7643e-01, time/batch = 0.1150s	
177/5250 (epoch 1.686), train_loss = 2.52132792, grad/param norm = 3.8262e-01, time/batch = 0.1149s	
178/5250 (epoch 1.695), train_loss = 2.45438559, grad/param norm = 3.6777e-01, time/batch = 0.1142s	
179/5250 (epoch 1.705), train_loss = 2.45353708, grad/param norm = 3.3403e-01, time/batch = 0.1151s	
180/5250 (epoch 1.714), train_loss = 2.43848160, grad/param norm = 3.2986e-01, time/batch = 0.1149s	
181/5250 (epoch 1.724), train_loss = 2.44106019, grad/param norm = 4.1416e-01, time/batch = 0.1155s	
182/5250 (epoch 1.733), train_loss = 2.42987905, grad/param norm = 4.5051e-01, time/batch = 0.1143s	
183/5250 (epoch 1.743), train_loss = 2.44402789, grad/param norm = 4.5245e-01, time/batch = 0.1145s	
184/5250 (epoch 1.752), train_loss = 2.43589013, grad/param norm = 4.4718e-01, time/batch = 0.1147s	
185/5250 (epoch 1.762), train_loss = 2.45165689, grad/param norm = 4.6111e-01, time/batch = 0.1150s	
186/5250 (epoch 1.771), train_loss = 2.39574942, grad/param norm = 3.6129e-01, time/batch = 0.1148s	
187/5250 (epoch 1.781), train_loss = 2.41707158, grad/param norm = 2.8117e-01, time/batch = 0.1149s	
188/5250 (epoch 1.790), train_loss = 2.39851756, grad/param norm = 2.5230e-01, time/batch = 0.1143s	
189/5250 (epoch 1.800), train_loss = 2.39671406, grad/param norm = 2.5889e-01, time/batch = 0.1150s	
190/5250 (epoch 1.810), train_loss = 2.36177237, grad/param norm = 2.6103e-01, time/batch = 0.1149s	
191/5250 (epoch 1.819), train_loss = 2.36864290, grad/param norm = 2.7557e-01, time/batch = 0.1153s	
192/5250 (epoch 1.829), train_loss = 2.38629025, grad/param norm = 2.8815e-01, time/batch = 0.1144s	
193/5250 (epoch 1.838), train_loss = 2.38113941, grad/param norm = 3.2183e-01, time/batch = 0.1146s	
194/5250 (epoch 1.848), train_loss = 2.40155589, grad/param norm = 4.8406e-01, time/batch = 0.1147s	
195/5250 (epoch 1.857), train_loss = 2.42451859, grad/param norm = 4.9573e-01, time/batch = 0.1150s	
196/5250 (epoch 1.867), train_loss = 2.41935629, grad/param norm = 5.0624e-01, time/batch = 0.1147s	
197/5250 (epoch 1.876), train_loss = 2.42868903, grad/param norm = 4.8240e-01, time/batch = 0.1146s	
198/5250 (epoch 1.886), train_loss = 2.39442232, grad/param norm = 3.2456e-01, time/batch = 0.1143s	
199/5250 (epoch 1.895), train_loss = 2.36594478, grad/param norm = 3.2861e-01, time/batch = 0.1151s	
200/5250 (epoch 1.905), train_loss = 2.36734019, grad/param norm = 3.3666e-01, time/batch = 0.1149s	
201/5250 (epoch 1.914), train_loss = 2.34597859, grad/param norm = 3.7642e-01, time/batch = 0.1161s	
202/5250 (epoch 1.924), train_loss = 2.36035693, grad/param norm = 4.3863e-01, time/batch = 0.1144s	
203/5250 (epoch 1.933), train_loss = 2.37299295, grad/param norm = 4.4932e-01, time/batch = 0.1147s	
204/5250 (epoch 1.943), train_loss = 2.35081630, grad/param norm = 3.3780e-01, time/batch = 0.1147s	
205/5250 (epoch 1.952), train_loss = 2.34310744, grad/param norm = 2.5576e-01, time/batch = 0.1149s	
206/5250 (epoch 1.962), train_loss = 2.33548310, grad/param norm = 2.7887e-01, time/batch = 0.1147s	
207/5250 (epoch 1.971), train_loss = 2.33021783, grad/param norm = 3.2506e-01, time/batch = 0.1148s	
208/5250 (epoch 1.981), train_loss = 2.36699721, grad/param norm = 4.0136e-01, time/batch = 0.1143s	
209/5250 (epoch 1.990), train_loss = 2.37607643, grad/param norm = 4.3666e-01, time/batch = 0.1150s	
210/5250 (epoch 2.000), train_loss = 2.33870916, grad/param norm = 3.9781e-01, time/batch = 0.1150s	
211/5250 (epoch 2.010), train_loss = 2.36081389, grad/param norm = 3.8850e-01, time/batch = 0.1152s	
212/5250 (epoch 2.019), train_loss = 2.37077199, grad/param norm = 3.8914e-01, time/batch = 0.1143s	
213/5250 (epoch 2.029), train_loss = 2.33346676, grad/param norm = 2.9632e-01, time/batch = 0.1146s	
214/5250 (epoch 2.038), train_loss = 2.33568726, grad/param norm = 1.9479e-01, time/batch = 0.1148s	
215/5250 (epoch 2.048), train_loss = 2.29571032, grad/param norm = 1.7698e-01, time/batch = 0.1149s	
216/5250 (epoch 2.057), train_loss = 2.31995070, grad/param norm = 2.3415e-01, time/batch = 0.1149s	
217/5250 (epoch 2.067), train_loss = 2.32169317, grad/param norm = 3.4560e-01, time/batch = 0.1148s	
218/5250 (epoch 2.076), train_loss = 2.33309706, grad/param norm = 5.6433e-01, time/batch = 0.1141s	
219/5250 (epoch 2.086), train_loss = 2.36395340, grad/param norm = 6.6268e-01, time/batch = 0.1151s	
220/5250 (epoch 2.095), train_loss = 2.38646558, grad/param norm = 4.4288e-01, time/batch = 0.1148s	
221/5250 (epoch 2.105), train_loss = 2.30486274, grad/param norm = 1.9755e-01, time/batch = 0.1154s	
222/5250 (epoch 2.114), train_loss = 2.28792041, grad/param norm = 2.0512e-01, time/batch = 0.1141s	
223/5250 (epoch 2.124), train_loss = 2.28799812, grad/param norm = 2.2127e-01, time/batch = 0.1147s	
224/5250 (epoch 2.133), train_loss = 2.26687287, grad/param norm = 2.3708e-01, time/batch = 0.1150s	
225/5250 (epoch 2.143), train_loss = 2.24741342, grad/param norm = 2.7109e-01, time/batch = 0.1150s	
226/5250 (epoch 2.152), train_loss = 2.26866884, grad/param norm = 3.0691e-01, time/batch = 0.1148s	
227/5250 (epoch 2.162), train_loss = 2.28241137, grad/param norm = 3.4817e-01, time/batch = 0.1150s	
228/5250 (epoch 2.171), train_loss = 2.30045536, grad/param norm = 3.5455e-01, time/batch = 0.1142s	
229/5250 (epoch 2.181), train_loss = 2.31342402, grad/param norm = 3.1307e-01, time/batch = 0.1149s	
230/5250 (epoch 2.190), train_loss = 2.27959217, grad/param norm = 2.3627e-01, time/batch = 0.1151s	
231/5250 (epoch 2.200), train_loss = 2.24139459, grad/param norm = 2.2599e-01, time/batch = 0.1157s	
232/5250 (epoch 2.210), train_loss = 2.27359106, grad/param norm = 2.6052e-01, time/batch = 0.1143s	
233/5250 (epoch 2.219), train_loss = 2.29137999, grad/param norm = 3.1562e-01, time/batch = 0.1146s	
234/5250 (epoch 2.229), train_loss = 2.28293321, grad/param norm = 3.2998e-01, time/batch = 0.1148s	
235/5250 (epoch 2.238), train_loss = 2.23538289, grad/param norm = 3.0367e-01, time/batch = 0.1150s	
236/5250 (epoch 2.248), train_loss = 2.24969460, grad/param norm = 2.5644e-01, time/batch = 0.1149s	
237/5250 (epoch 2.257), train_loss = 2.22775383, grad/param norm = 2.7478e-01, time/batch = 0.1148s	
238/5250 (epoch 2.267), train_loss = 2.24461406, grad/param norm = 3.6210e-01, time/batch = 0.1142s	
239/5250 (epoch 2.276), train_loss = 2.28638271, grad/param norm = 4.1976e-01, time/batch = 0.1151s	
240/5250 (epoch 2.286), train_loss = 2.25129896, grad/param norm = 3.4412e-01, time/batch = 0.1150s	
241/5250 (epoch 2.295), train_loss = 2.24981883, grad/param norm = 2.4589e-01, time/batch = 0.1153s	
242/5250 (epoch 2.305), train_loss = 2.24946361, grad/param norm = 2.4496e-01, time/batch = 0.1143s	
243/5250 (epoch 2.314), train_loss = 2.23955079, grad/param norm = 3.8425e-01, time/batch = 0.1146s	
244/5250 (epoch 2.324), train_loss = 2.27869477, grad/param norm = 4.5628e-01, time/batch = 0.1148s	
245/5250 (epoch 2.333), train_loss = 2.26753911, grad/param norm = 3.6039e-01, time/batch = 0.1150s	
246/5250 (epoch 2.343), train_loss = 2.23594557, grad/param norm = 2.5562e-01, time/batch = 0.1149s	
247/5250 (epoch 2.352), train_loss = 2.20042353, grad/param norm = 2.4684e-01, time/batch = 0.1149s	
248/5250 (epoch 2.362), train_loss = 2.21755435, grad/param norm = 3.0604e-01, time/batch = 0.1140s	
249/5250 (epoch 2.371), train_loss = 2.21853271, grad/param norm = 2.8062e-01, time/batch = 0.1153s	
250/5250 (epoch 2.381), train_loss = 2.17652533, grad/param norm = 2.2291e-01, time/batch = 0.1150s	
251/5250 (epoch 2.390), train_loss = 2.21456033, grad/param norm = 2.4943e-01, time/batch = 0.1163s	
252/5250 (epoch 2.400), train_loss = 2.18972382, grad/param norm = 2.5692e-01, time/batch = 0.1143s	
253/5250 (epoch 2.410), train_loss = 2.19951195, grad/param norm = 2.3996e-01, time/batch = 0.1147s	
254/5250 (epoch 2.419), train_loss = 2.19223432, grad/param norm = 2.1046e-01, time/batch = 0.1148s	
255/5250 (epoch 2.429), train_loss = 2.17549780, grad/param norm = 2.1250e-01, time/batch = 0.1150s	
256/5250 (epoch 2.438), train_loss = 2.22256202, grad/param norm = 2.9137e-01, time/batch = 0.1148s	
257/5250 (epoch 2.448), train_loss = 2.20921089, grad/param norm = 3.9947e-01, time/batch = 0.1149s	
258/5250 (epoch 2.457), train_loss = 2.19683640, grad/param norm = 3.8114e-01, time/batch = 0.1141s	
259/5250 (epoch 2.467), train_loss = 2.17631023, grad/param norm = 2.9488e-01, time/batch = 0.1152s	
260/5250 (epoch 2.476), train_loss = 2.15969718, grad/param norm = 2.5824e-01, time/batch = 0.1148s	
261/5250 (epoch 2.486), train_loss = 2.18996806, grad/param norm = 3.1926e-01, time/batch = 0.1155s	
262/5250 (epoch 2.495), train_loss = 2.19935750, grad/param norm = 4.1564e-01, time/batch = 0.1144s	
263/5250 (epoch 2.505), train_loss = 2.21262865, grad/param norm = 3.9348e-01, time/batch = 0.1145s	
264/5250 (epoch 2.514), train_loss = 2.19011512, grad/param norm = 2.9501e-01, time/batch = 0.1146s	
265/5250 (epoch 2.524), train_loss = 2.14483142, grad/param norm = 1.7770e-01, time/batch = 0.1151s	
266/5250 (epoch 2.533), train_loss = 2.13560052, grad/param norm = 1.7927e-01, time/batch = 0.1149s	
267/5250 (epoch 2.543), train_loss = 2.14514390, grad/param norm = 2.4499e-01, time/batch = 0.1148s	
268/5250 (epoch 2.552), train_loss = 2.15188465, grad/param norm = 2.9305e-01, time/batch = 0.1142s	
269/5250 (epoch 2.562), train_loss = 2.18161252, grad/param norm = 2.6565e-01, time/batch = 0.1148s	
270/5250 (epoch 2.571), train_loss = 2.15340464, grad/param norm = 2.2467e-01, time/batch = 0.1151s	
271/5250 (epoch 2.581), train_loss = 2.14611694, grad/param norm = 2.2688e-01, time/batch = 0.1163s	
272/5250 (epoch 2.590), train_loss = 2.14036611, grad/param norm = 2.4193e-01, time/batch = 0.1144s	
273/5250 (epoch 2.600), train_loss = 2.16949809, grad/param norm = 2.8026e-01, time/batch = 0.1148s	
274/5250 (epoch 2.610), train_loss = 2.14729935, grad/param norm = 2.7521e-01, time/batch = 0.1150s	
275/5250 (epoch 2.619), train_loss = 2.11891496, grad/param norm = 2.1583e-01, time/batch = 0.1150s	
276/5250 (epoch 2.629), train_loss = 2.15270879, grad/param norm = 1.9684e-01, time/batch = 0.1167s	
277/5250 (epoch 2.638), train_loss = 2.13509055, grad/param norm = 2.4166e-01, time/batch = 0.1148s	
278/5250 (epoch 2.648), train_loss = 2.14999759, grad/param norm = 3.1978e-01, time/batch = 0.1142s	
279/5250 (epoch 2.657), train_loss = 2.13051291, grad/param norm = 2.8279e-01, time/batch = 0.1149s	
280/5250 (epoch 2.667), train_loss = 2.15561999, grad/param norm = 2.5550e-01, time/batch = 0.1148s	
281/5250 (epoch 2.676), train_loss = 2.13668798, grad/param norm = 2.7999e-01, time/batch = 0.1153s	
282/5250 (epoch 2.686), train_loss = 2.17597506, grad/param norm = 2.9019e-01, time/batch = 0.1140s	
283/5250 (epoch 2.695), train_loss = 2.12684121, grad/param norm = 2.5727e-01, time/batch = 0.1145s	
284/5250 (epoch 2.705), train_loss = 2.10517713, grad/param norm = 2.4641e-01, time/batch = 0.1147s	
285/5250 (epoch 2.714), train_loss = 2.11386809, grad/param norm = 2.2381e-01, time/batch = 0.1151s	
286/5250 (epoch 2.724), train_loss = 2.08703780, grad/param norm = 2.0755e-01, time/batch = 0.1146s	
287/5250 (epoch 2.733), train_loss = 2.08987882, grad/param norm = 2.1295e-01, time/batch = 0.1150s	
288/5250 (epoch 2.743), train_loss = 2.08304879, grad/param norm = 2.1702e-01, time/batch = 0.1142s	
289/5250 (epoch 2.752), train_loss = 2.11007143, grad/param norm = 3.3094e-01, time/batch = 0.1149s	
290/5250 (epoch 2.762), train_loss = 2.12880590, grad/param norm = 3.5887e-01, time/batch = 0.1147s	
291/5250 (epoch 2.771), train_loss = 2.09432103, grad/param norm = 3.0911e-01, time/batch = 0.1155s	
292/5250 (epoch 2.781), train_loss = 2.12312101, grad/param norm = 2.6930e-01, time/batch = 0.1142s	
293/5250 (epoch 2.790), train_loss = 2.10515248, grad/param norm = 2.0464e-01, time/batch = 0.1149s	
294/5250 (epoch 2.800), train_loss = 2.09492762, grad/param norm = 1.7327e-01, time/batch = 0.1147s	
295/5250 (epoch 2.810), train_loss = 2.06045944, grad/param norm = 2.0118e-01, time/batch = 0.1150s	
296/5250 (epoch 2.819), train_loss = 2.07879415, grad/param norm = 2.2492e-01, time/batch = 0.1147s	
297/5250 (epoch 2.829), train_loss = 2.08596547, grad/param norm = 2.1441e-01, time/batch = 0.1149s	
298/5250 (epoch 2.838), train_loss = 2.06931335, grad/param norm = 2.1299e-01, time/batch = 0.1142s	
299/5250 (epoch 2.848), train_loss = 2.07136343, grad/param norm = 2.4016e-01, time/batch = 0.1150s	
300/5250 (epoch 2.857), train_loss = 2.09537258, grad/param norm = 2.9785e-01, time/batch = 0.1148s	
301/5250 (epoch 2.867), train_loss = 2.10826881, grad/param norm = 2.8158e-01, time/batch = 0.1153s	
302/5250 (epoch 2.876), train_loss = 2.10864414, grad/param norm = 2.7467e-01, time/batch = 0.1141s	
303/5250 (epoch 2.886), train_loss = 2.10633625, grad/param norm = 2.9541e-01, time/batch = 0.1146s	
304/5250 (epoch 2.895), train_loss = 2.09178913, grad/param norm = 2.7813e-01, time/batch = 0.1147s	
305/5250 (epoch 2.905), train_loss = 2.08474358, grad/param norm = 2.2731e-01, time/batch = 0.1149s	
306/5250 (epoch 2.914), train_loss = 2.05615863, grad/param norm = 2.0102e-01, time/batch = 0.1147s	
307/5250 (epoch 2.924), train_loss = 2.05029894, grad/param norm = 2.0713e-01, time/batch = 0.1148s	
308/5250 (epoch 2.933), train_loss = 2.07590701, grad/param norm = 2.6356e-01, time/batch = 0.1141s	
309/5250 (epoch 2.943), train_loss = 2.08621002, grad/param norm = 3.5101e-01, time/batch = 0.1151s	
310/5250 (epoch 2.952), train_loss = 2.10974719, grad/param norm = 3.3111e-01, time/batch = 0.1147s	
311/5250 (epoch 2.962), train_loss = 2.07081241, grad/param norm = 2.6874e-01, time/batch = 0.1161s	
312/5250 (epoch 2.971), train_loss = 2.04766126, grad/param norm = 2.0391e-01, time/batch = 0.1142s	
313/5250 (epoch 2.981), train_loss = 2.06897561, grad/param norm = 1.9313e-01, time/batch = 0.1147s	
314/5250 (epoch 2.990), train_loss = 2.05092523, grad/param norm = 1.7250e-01, time/batch = 0.1149s	
315/5250 (epoch 3.000), train_loss = 2.01534275, grad/param norm = 1.7487e-01, time/batch = 0.1150s	
316/5250 (epoch 3.010), train_loss = 2.10356868, grad/param norm = 1.8079e-01, time/batch = 0.1149s	
317/5250 (epoch 3.019), train_loss = 2.04985651, grad/param norm = 1.8221e-01, time/batch = 0.1150s	
318/5250 (epoch 3.029), train_loss = 2.04150772, grad/param norm = 1.8643e-01, time/batch = 0.1143s	
319/5250 (epoch 3.038), train_loss = 2.06816993, grad/param norm = 1.7887e-01, time/batch = 0.1150s	
320/5250 (epoch 3.048), train_loss = 2.01929315, grad/param norm = 1.9738e-01, time/batch = 0.1149s	
321/5250 (epoch 3.057), train_loss = 2.04892132, grad/param norm = 2.4142e-01, time/batch = 0.1159s	
322/5250 (epoch 3.067), train_loss = 2.05940745, grad/param norm = 2.7912e-01, time/batch = 0.1140s	
323/5250 (epoch 3.076), train_loss = 2.05179903, grad/param norm = 2.8985e-01, time/batch = 0.1147s	
324/5250 (epoch 3.086), train_loss = 2.01700174, grad/param norm = 2.6444e-01, time/batch = 0.1147s	
325/5250 (epoch 3.095), train_loss = 2.05714375, grad/param norm = 2.5177e-01, time/batch = 0.1149s	
326/5250 (epoch 3.105), train_loss = 2.06044287, grad/param norm = 2.8765e-01, time/batch = 0.1150s	
327/5250 (epoch 3.114), train_loss = 2.04665666, grad/param norm = 2.6719e-01, time/batch = 0.1150s	
328/5250 (epoch 3.124), train_loss = 2.03597350, grad/param norm = 2.4782e-01, time/batch = 0.1144s	
329/5250 (epoch 3.133), train_loss = 2.03079099, grad/param norm = 2.2478e-01, time/batch = 0.1149s	
330/5250 (epoch 3.143), train_loss = 1.98255798, grad/param norm = 1.8099e-01, time/batch = 0.1149s	
331/5250 (epoch 3.152), train_loss = 1.98782786, grad/param norm = 1.6066e-01, time/batch = 0.1153s	
332/5250 (epoch 3.162), train_loss = 1.99175447, grad/param norm = 1.4238e-01, time/batch = 0.1144s	
333/5250 (epoch 3.171), train_loss = 2.00983702, grad/param norm = 1.3946e-01, time/batch = 0.1145s	
334/5250 (epoch 3.181), train_loss = 2.01503077, grad/param norm = 1.4632e-01, time/batch = 0.1147s	
335/5250 (epoch 3.190), train_loss = 2.01079006, grad/param norm = 1.6816e-01, time/batch = 0.1148s	
336/5250 (epoch 3.200), train_loss = 1.99982500, grad/param norm = 1.8993e-01, time/batch = 0.1149s	
337/5250 (epoch 3.210), train_loss = 2.01002733, grad/param norm = 1.9196e-01, time/batch = 0.1149s	
338/5250 (epoch 3.219), train_loss = 2.03885765, grad/param norm = 1.9790e-01, time/batch = 0.1142s	
339/5250 (epoch 3.229), train_loss = 2.01526007, grad/param norm = 2.3740e-01, time/batch = 0.1151s	
340/5250 (epoch 3.238), train_loss = 1.99426621, grad/param norm = 2.8466e-01, time/batch = 0.1147s	
341/5250 (epoch 3.248), train_loss = 2.00643266, grad/param norm = 2.6544e-01, time/batch = 0.1153s	
342/5250 (epoch 3.257), train_loss = 1.97887057, grad/param norm = 2.2048e-01, time/batch = 0.1142s	
343/5250 (epoch 3.267), train_loss = 1.97340172, grad/param norm = 2.1278e-01, time/batch = 0.1144s	
344/5250 (epoch 3.276), train_loss = 1.99590203, grad/param norm = 2.0008e-01, time/batch = 0.1149s	
345/5250 (epoch 3.286), train_loss = 1.95729111, grad/param norm = 1.8505e-01, time/batch = 0.1148s	
346/5250 (epoch 3.295), train_loss = 1.97960276, grad/param norm = 1.8306e-01, time/batch = 0.1150s	
347/5250 (epoch 3.305), train_loss = 1.99484930, grad/param norm = 2.1401e-01, time/batch = 0.1161s	
348/5250 (epoch 3.314), train_loss = 1.96821719, grad/param norm = 2.5323e-01, time/batch = 0.1143s	
349/5250 (epoch 3.324), train_loss = 2.01317785, grad/param norm = 2.6556e-01, time/batch = 0.1151s	
350/5250 (epoch 3.333), train_loss = 2.01403068, grad/param norm = 2.5246e-01, time/batch = 0.1149s	
351/5250 (epoch 3.343), train_loss = 1.99523299, grad/param norm = 1.9420e-01, time/batch = 0.1160s	
352/5250 (epoch 3.352), train_loss = 1.96639676, grad/param norm = 1.7776e-01, time/batch = 0.1143s	
353/5250 (epoch 3.362), train_loss = 1.95459450, grad/param norm = 1.7607e-01, time/batch = 0.1144s	
354/5250 (epoch 3.371), train_loss = 1.95047760, grad/param norm = 1.7718e-01, time/batch = 0.1146s	
355/5250 (epoch 3.381), train_loss = 1.94548550, grad/param norm = 1.8863e-01, time/batch = 0.1148s	
356/5250 (epoch 3.390), train_loss = 1.98327783, grad/param norm = 1.8791e-01, time/batch = 0.1148s	
357/5250 (epoch 3.400), train_loss = 1.93304740, grad/param norm = 1.8648e-01, time/batch = 0.1148s	
358/5250 (epoch 3.410), train_loss = 1.96250260, grad/param norm = 1.8446e-01, time/batch = 0.1141s	
359/5250 (epoch 3.419), train_loss = 1.95673582, grad/param norm = 1.8588e-01, time/batch = 0.1150s	
360/5250 (epoch 3.429), train_loss = 1.95977293, grad/param norm = 1.9151e-01, time/batch = 0.1148s	
361/5250 (epoch 3.438), train_loss = 1.98182084, grad/param norm = 1.7467e-01, time/batch = 0.1154s	
362/5250 (epoch 3.448), train_loss = 1.93619180, grad/param norm = 1.4827e-01, time/batch = 0.1140s	
363/5250 (epoch 3.457), train_loss = 1.90723078, grad/param norm = 1.5719e-01, time/batch = 0.1147s	
364/5250 (epoch 3.467), train_loss = 1.91917836, grad/param norm = 1.7208e-01, time/batch = 0.1147s	
365/5250 (epoch 3.476), train_loss = 1.92506839, grad/param norm = 2.2381e-01, time/batch = 0.1149s	
366/5250 (epoch 3.486), train_loss = 1.97834732, grad/param norm = 2.6311e-01, time/batch = 0.1148s	
367/5250 (epoch 3.495), train_loss = 1.96265656, grad/param norm = 2.9954e-01, time/batch = 0.1149s	
368/5250 (epoch 3.505), train_loss = 1.98941830, grad/param norm = 3.1342e-01, time/batch = 0.1142s	
369/5250 (epoch 3.514), train_loss = 1.97804852, grad/param norm = 2.7347e-01, time/batch = 0.1150s	
370/5250 (epoch 3.524), train_loss = 1.92270316, grad/param norm = 1.9216e-01, time/batch = 0.1149s	
371/5250 (epoch 3.533), train_loss = 1.92270273, grad/param norm = 1.5565e-01, time/batch = 0.1155s	
372/5250 (epoch 3.543), train_loss = 1.89962609, grad/param norm = 1.3395e-01, time/batch = 0.1142s	
373/5250 (epoch 3.552), train_loss = 1.90346483, grad/param norm = 1.3897e-01, time/batch = 0.1148s	
374/5250 (epoch 3.562), train_loss = 1.92997042, grad/param norm = 1.5885e-01, time/batch = 0.1148s	
375/5250 (epoch 3.571), train_loss = 1.93104714, grad/param norm = 1.7244e-01, time/batch = 0.1147s	
376/5250 (epoch 3.581), train_loss = 1.93856218, grad/param norm = 1.6614e-01, time/batch = 0.1149s	
377/5250 (epoch 3.590), train_loss = 1.91955714, grad/param norm = 1.5399e-01, time/batch = 0.1149s	
378/5250 (epoch 3.600), train_loss = 1.93160876, grad/param norm = 1.4929e-01, time/batch = 0.1144s	
379/5250 (epoch 3.610), train_loss = 1.90556963, grad/param norm = 1.6086e-01, time/batch = 0.1149s	
380/5250 (epoch 3.619), train_loss = 1.89626987, grad/param norm = 1.7290e-01, time/batch = 0.1149s	
381/5250 (epoch 3.629), train_loss = 1.94809932, grad/param norm = 1.8066e-01, time/batch = 0.1154s	
382/5250 (epoch 3.638), train_loss = 1.91700234, grad/param norm = 1.9988e-01, time/batch = 0.1141s	
383/5250 (epoch 3.648), train_loss = 1.93812484, grad/param norm = 2.2590e-01, time/batch = 0.1146s	
384/5250 (epoch 3.657), train_loss = 1.91458440, grad/param norm = 2.1123e-01, time/batch = 0.1147s	
385/5250 (epoch 3.667), train_loss = 1.94000274, grad/param norm = 1.8094e-01, time/batch = 0.1149s	
386/5250 (epoch 3.676), train_loss = 1.90176437, grad/param norm = 1.6711e-01, time/batch = 0.1148s	
387/5250 (epoch 3.686), train_loss = 1.93785978, grad/param norm = 1.9820e-01, time/batch = 0.1150s	
388/5250 (epoch 3.695), train_loss = 1.91151422, grad/param norm = 2.2956e-01, time/batch = 0.1143s	
389/5250 (epoch 3.705), train_loss = 1.90044793, grad/param norm = 2.3938e-01, time/batch = 0.1149s	
390/5250 (epoch 3.714), train_loss = 1.92092946, grad/param norm = 2.2064e-01, time/batch = 0.1149s	
391/5250 (epoch 3.724), train_loss = 1.89175671, grad/param norm = 1.8718e-01, time/batch = 0.1154s	
392/5250 (epoch 3.733), train_loss = 1.89284690, grad/param norm = 1.6526e-01, time/batch = 0.1143s	
393/5250 (epoch 3.743), train_loss = 1.87702980, grad/param norm = 1.3629e-01, time/batch = 0.1145s	
394/5250 (epoch 3.752), train_loss = 1.88110723, grad/param norm = 1.3183e-01, time/batch = 0.1147s	
395/5250 (epoch 3.762), train_loss = 1.86817370, grad/param norm = 1.5353e-01, time/batch = 0.1149s	
396/5250 (epoch 3.771), train_loss = 1.85719882, grad/param norm = 1.7514e-01, time/batch = 0.1147s	
397/5250 (epoch 3.781), train_loss = 1.89351759, grad/param norm = 1.8196e-01, time/batch = 0.1147s	
398/5250 (epoch 3.790), train_loss = 1.90667753, grad/param norm = 1.8895e-01, time/batch = 0.1145s	
399/5250 (epoch 3.800), train_loss = 1.90874717, grad/param norm = 1.9923e-01, time/batch = 0.1152s	
400/5250 (epoch 3.810), train_loss = 1.89128358, grad/param norm = 2.0420e-01, time/batch = 0.1148s	
401/5250 (epoch 3.819), train_loss = 1.88222745, grad/param norm = 1.5713e-01, time/batch = 0.1154s	
402/5250 (epoch 3.829), train_loss = 1.87273394, grad/param norm = 1.1705e-01, time/batch = 0.1144s	
403/5250 (epoch 3.838), train_loss = 1.85090272, grad/param norm = 1.1824e-01, time/batch = 0.1146s	
404/5250 (epoch 3.848), train_loss = 1.84854996, grad/param norm = 1.3372e-01, time/batch = 0.1148s	
405/5250 (epoch 3.857), train_loss = 1.86818882, grad/param norm = 1.6480e-01, time/batch = 0.1152s	
406/5250 (epoch 3.867), train_loss = 1.87435587, grad/param norm = 1.9627e-01, time/batch = 0.1148s	
407/5250 (epoch 3.876), train_loss = 1.90362967, grad/param norm = 2.2110e-01, time/batch = 0.1150s	
408/5250 (epoch 3.886), train_loss = 1.89052922, grad/param norm = 2.3124e-01, time/batch = 0.1143s	
409/5250 (epoch 3.895), train_loss = 1.88849755, grad/param norm = 1.8816e-01, time/batch = 0.1150s	
410/5250 (epoch 3.905), train_loss = 1.86799449, grad/param norm = 1.4142e-01, time/batch = 0.1150s	
411/5250 (epoch 3.914), train_loss = 1.85043319, grad/param norm = 1.2422e-01, time/batch = 0.1154s	
412/5250 (epoch 3.924), train_loss = 1.84165097, grad/param norm = 1.0860e-01, time/batch = 0.1143s	
413/5250 (epoch 3.933), train_loss = 1.85632985, grad/param norm = 1.4891e-01, time/batch = 0.1148s	
414/5250 (epoch 3.943), train_loss = 1.89561759, grad/param norm = 1.9967e-01, time/batch = 0.1148s	
415/5250 (epoch 3.952), train_loss = 1.89507767, grad/param norm = 1.9246e-01, time/batch = 0.1148s	
416/5250 (epoch 3.962), train_loss = 1.86449933, grad/param norm = 1.8042e-01, time/batch = 0.1148s	
417/5250 (epoch 3.971), train_loss = 1.85083989, grad/param norm = 1.7922e-01, time/batch = 0.1168s	
418/5250 (epoch 3.981), train_loss = 1.89345429, grad/param norm = 2.3055e-01, time/batch = 0.1147s	
419/5250 (epoch 3.990), train_loss = 1.91367546, grad/param norm = 2.4925e-01, time/batch = 0.1150s	
420/5250 (epoch 4.000), train_loss = 1.86144112, grad/param norm = 2.1617e-01, time/batch = 0.1148s	
421/5250 (epoch 4.010), train_loss = 1.95312614, grad/param norm = 1.6013e-01, time/batch = 0.1153s	
422/5250 (epoch 4.019), train_loss = 1.83709579, grad/param norm = 1.0952e-01, time/batch = 0.1142s	
423/5250 (epoch 4.029), train_loss = 1.82543972, grad/param norm = 8.9590e-02, time/batch = 0.1146s	
424/5250 (epoch 4.038), train_loss = 1.84281306, grad/param norm = 9.5775e-02, time/batch = 0.1147s	
425/5250 (epoch 4.048), train_loss = 1.80715262, grad/param norm = 1.0820e-01, time/batch = 0.1149s	
426/5250 (epoch 4.057), train_loss = 1.83560268, grad/param norm = 1.1944e-01, time/batch = 0.1147s	
427/5250 (epoch 4.067), train_loss = 1.83220854, grad/param norm = 1.2123e-01, time/batch = 0.1147s	
428/5250 (epoch 4.076), train_loss = 1.83102541, grad/param norm = 1.4445e-01, time/batch = 0.1143s	
429/5250 (epoch 4.086), train_loss = 1.78665666, grad/param norm = 1.5572e-01, time/batch = 0.1151s	
430/5250 (epoch 4.095), train_loss = 1.83250753, grad/param norm = 1.6413e-01, time/batch = 0.1148s	
431/5250 (epoch 4.105), train_loss = 1.85157635, grad/param norm = 1.8284e-01, time/batch = 0.1155s	
432/5250 (epoch 4.114), train_loss = 1.82784108, grad/param norm = 1.7934e-01, time/batch = 0.1142s	
433/5250 (epoch 4.124), train_loss = 1.83882886, grad/param norm = 1.7695e-01, time/batch = 0.1146s	
434/5250 (epoch 4.133), train_loss = 1.83427547, grad/param norm = 1.9885e-01, time/batch = 0.1148s	
435/5250 (epoch 4.143), train_loss = 1.82005749, grad/param norm = 1.9739e-01, time/batch = 0.1152s	
436/5250 (epoch 4.152), train_loss = 1.79942910, grad/param norm = 1.6704e-01, time/batch = 0.1149s	
437/5250 (epoch 4.162), train_loss = 1.82502916, grad/param norm = 1.4664e-01, time/batch = 0.1147s	
438/5250 (epoch 4.171), train_loss = 1.83879487, grad/param norm = 1.4635e-01, time/batch = 0.1142s	
439/5250 (epoch 4.181), train_loss = 1.83862881, grad/param norm = 1.3964e-01, time/batch = 0.1150s	
440/5250 (epoch 4.190), train_loss = 1.81938814, grad/param norm = 1.4736e-01, time/batch = 0.1150s	
441/5250 (epoch 4.200), train_loss = 1.80258814, grad/param norm = 1.5040e-01, time/batch = 0.1153s	
442/5250 (epoch 4.210), train_loss = 1.81847455, grad/param norm = 1.4912e-01, time/batch = 0.1141s	
443/5250 (epoch 4.219), train_loss = 1.85168115, grad/param norm = 1.3498e-01, time/batch = 0.1148s	
444/5250 (epoch 4.229), train_loss = 1.82018575, grad/param norm = 1.3276e-01, time/batch = 0.1148s	
445/5250 (epoch 4.238), train_loss = 1.78887553, grad/param norm = 1.5122e-01, time/batch = 0.1149s	
446/5250 (epoch 4.248), train_loss = 1.81489961, grad/param norm = 1.4932e-01, time/batch = 0.1150s	
447/5250 (epoch 4.257), train_loss = 1.80588991, grad/param norm = 1.8382e-01, time/batch = 0.1146s	
448/5250 (epoch 4.267), train_loss = 1.82261177, grad/param norm = 2.1686e-01, time/batch = 0.1143s	
449/5250 (epoch 4.276), train_loss = 1.82662562, grad/param norm = 2.0523e-01, time/batch = 0.1151s	
450/5250 (epoch 4.286), train_loss = 1.78360655, grad/param norm = 1.7062e-01, time/batch = 0.1149s	
451/5250 (epoch 4.295), train_loss = 1.80118142, grad/param norm = 1.4905e-01, time/batch = 0.1154s	
452/5250 (epoch 4.305), train_loss = 1.81290924, grad/param norm = 1.7403e-01, time/batch = 0.1141s	
453/5250 (epoch 4.314), train_loss = 1.77572867, grad/param norm = 1.7049e-01, time/batch = 0.1146s	
454/5250 (epoch 4.324), train_loss = 1.81026361, grad/param norm = 1.5910e-01, time/batch = 0.1146s	
455/5250 (epoch 4.333), train_loss = 1.80889199, grad/param norm = 1.6455e-01, time/batch = 0.1150s	
456/5250 (epoch 4.343), train_loss = 1.80567170, grad/param norm = 1.5265e-01, time/batch = 0.1149s	
457/5250 (epoch 4.352), train_loss = 1.79399956, grad/param norm = 1.5596e-01, time/batch = 0.1149s	
458/5250 (epoch 4.362), train_loss = 1.78952343, grad/param norm = 1.7641e-01, time/batch = 0.1143s	
459/5250 (epoch 4.371), train_loss = 1.78285471, grad/param norm = 1.7745e-01, time/batch = 0.1150s	
460/5250 (epoch 4.381), train_loss = 1.77805816, grad/param norm = 1.7832e-01, time/batch = 0.1149s	
461/5250 (epoch 4.390), train_loss = 1.81872856, grad/param norm = 1.6672e-01, time/batch = 0.1154s	
462/5250 (epoch 4.400), train_loss = 1.76620827, grad/param norm = 1.6027e-01, time/batch = 0.1142s	
463/5250 (epoch 4.410), train_loss = 1.80759610, grad/param norm = 1.7112e-01, time/batch = 0.1146s	
464/5250 (epoch 4.419), train_loss = 1.79145414, grad/param norm = 1.7524e-01, time/batch = 0.1146s	
465/5250 (epoch 4.429), train_loss = 1.80207209, grad/param norm = 1.5600e-01, time/batch = 0.1147s	
466/5250 (epoch 4.438), train_loss = 1.80344076, grad/param norm = 1.2435e-01, time/batch = 0.1147s	
467/5250 (epoch 4.448), train_loss = 1.75408555, grad/param norm = 1.0112e-01, time/batch = 0.1148s	
468/5250 (epoch 4.457), train_loss = 1.73013475, grad/param norm = 1.0454e-01, time/batch = 0.1143s	
469/5250 (epoch 4.467), train_loss = 1.74013039, grad/param norm = 1.1623e-01, time/batch = 0.1150s	
470/5250 (epoch 4.476), train_loss = 1.75474258, grad/param norm = 1.4735e-01, time/batch = 0.1150s	
471/5250 (epoch 4.486), train_loss = 1.78189726, grad/param norm = 1.7175e-01, time/batch = 0.1153s	
472/5250 (epoch 4.495), train_loss = 1.78081919, grad/param norm = 1.5523e-01, time/batch = 0.1140s	
473/5250 (epoch 4.505), train_loss = 1.77809158, grad/param norm = 1.3226e-01, time/batch = 0.1147s	
474/5250 (epoch 4.514), train_loss = 1.78012681, grad/param norm = 1.2130e-01, time/batch = 0.1148s	
475/5250 (epoch 4.524), train_loss = 1.74951772, grad/param norm = 1.2619e-01, time/batch = 0.1149s	
476/5250 (epoch 4.533), train_loss = 1.77172365, grad/param norm = 1.7758e-01, time/batch = 0.1148s	
477/5250 (epoch 4.543), train_loss = 1.78182757, grad/param norm = 1.7601e-01, time/batch = 0.1146s	
478/5250 (epoch 4.552), train_loss = 1.76788654, grad/param norm = 1.5694e-01, time/batch = 0.1142s	
479/5250 (epoch 4.562), train_loss = 1.77463495, grad/param norm = 1.3662e-01, time/batch = 0.1152s	
480/5250 (epoch 4.571), train_loss = 1.76851731, grad/param norm = 1.3112e-01, time/batch = 0.1150s	
481/5250 (epoch 4.581), train_loss = 1.77840809, grad/param norm = 1.3054e-01, time/batch = 0.1152s	
482/5250 (epoch 4.590), train_loss = 1.75650316, grad/param norm = 1.3508e-01, time/batch = 0.1143s	
483/5250 (epoch 4.600), train_loss = 1.77705864, grad/param norm = 1.4970e-01, time/batch = 0.1147s	
484/5250 (epoch 4.610), train_loss = 1.76613784, grad/param norm = 1.5368e-01, time/batch = 0.1149s	
485/5250 (epoch 4.619), train_loss = 1.74732570, grad/param norm = 1.3588e-01, time/batch = 0.1148s	
486/5250 (epoch 4.629), train_loss = 1.78555738, grad/param norm = 1.3200e-01, time/batch = 0.1146s	
487/5250 (epoch 4.638), train_loss = 1.75098281, grad/param norm = 1.3017e-01, time/batch = 0.1147s	
488/5250 (epoch 4.648), train_loss = 1.75284820, grad/param norm = 1.3075e-01, time/batch = 0.1159s	
489/5250 (epoch 4.657), train_loss = 1.73747491, grad/param norm = 1.4802e-01, time/batch = 0.1152s	
490/5250 (epoch 4.667), train_loss = 1.77306382, grad/param norm = 1.7633e-01, time/batch = 0.1148s	
491/5250 (epoch 4.676), train_loss = 1.76453127, grad/param norm = 2.0650e-01, time/batch = 0.1154s	
492/5250 (epoch 4.686), train_loss = 1.79547473, grad/param norm = 1.9738e-01, time/batch = 0.1141s	
493/5250 (epoch 4.695), train_loss = 1.75507105, grad/param norm = 1.6623e-01, time/batch = 0.1146s	
494/5250 (epoch 4.705), train_loss = 1.72275005, grad/param norm = 1.3170e-01, time/batch = 0.1148s	
495/5250 (epoch 4.714), train_loss = 1.74326044, grad/param norm = 1.3105e-01, time/batch = 0.1148s	
496/5250 (epoch 4.724), train_loss = 1.71944077, grad/param norm = 1.2554e-01, time/batch = 0.1146s	
497/5250 (epoch 4.733), train_loss = 1.72105967, grad/param norm = 1.0860e-01, time/batch = 0.1148s	
498/5250 (epoch 4.743), train_loss = 1.72281754, grad/param norm = 1.5213e-01, time/batch = 0.1142s	
499/5250 (epoch 4.752), train_loss = 1.77047904, grad/param norm = 1.7348e-01, time/batch = 0.1151s	
500/5250 (epoch 4.762), train_loss = 1.76558691, grad/param norm = 2.3985e-01, time/batch = 0.1149s	
501/5250 (epoch 4.771), train_loss = 1.76479217, grad/param norm = 1.7694e-01, time/batch = 0.1156s	
502/5250 (epoch 4.781), train_loss = 1.74063547, grad/param norm = 1.1191e-01, time/batch = 0.1141s	
503/5250 (epoch 4.790), train_loss = 1.74388231, grad/param norm = 1.0091e-01, time/batch = 0.1147s	
504/5250 (epoch 4.800), train_loss = 1.72556173, grad/param norm = 9.2179e-02, time/batch = 0.1147s	
505/5250 (epoch 4.810), train_loss = 1.71197042, grad/param norm = 9.8672e-02, time/batch = 0.1153s	
506/5250 (epoch 4.819), train_loss = 1.71632164, grad/param norm = 1.1299e-01, time/batch = 0.1147s	
507/5250 (epoch 4.829), train_loss = 1.72876158, grad/param norm = 1.2235e-01, time/batch = 0.1150s	
508/5250 (epoch 4.838), train_loss = 1.70756858, grad/param norm = 1.2357e-01, time/batch = 0.1143s	
509/5250 (epoch 4.848), train_loss = 1.70527884, grad/param norm = 1.3416e-01, time/batch = 0.1151s	
510/5250 (epoch 4.857), train_loss = 1.72469062, grad/param norm = 1.4200e-01, time/batch = 0.1150s	
511/5250 (epoch 4.867), train_loss = 1.71161773, grad/param norm = 1.3684e-01, time/batch = 0.1155s	
512/5250 (epoch 4.876), train_loss = 1.72831666, grad/param norm = 1.1599e-01, time/batch = 0.1140s	
513/5250 (epoch 4.886), train_loss = 1.71266324, grad/param norm = 1.1523e-01, time/batch = 0.1145s	
514/5250 (epoch 4.895), train_loss = 1.73514892, grad/param norm = 1.5354e-01, time/batch = 0.1149s	
515/5250 (epoch 4.905), train_loss = 1.75236354, grad/param norm = 1.9417e-01, time/batch = 0.1149s	
516/5250 (epoch 4.914), train_loss = 1.75819927, grad/param norm = 1.7817e-01, time/batch = 0.1149s	
517/5250 (epoch 4.924), train_loss = 1.72501561, grad/param norm = 1.4452e-01, time/batch = 0.1149s	
518/5250 (epoch 4.933), train_loss = 1.72310472, grad/param norm = 1.5347e-01, time/batch = 0.1142s	
519/5250 (epoch 4.943), train_loss = 1.76263078, grad/param norm = 1.9068e-01, time/batch = 0.1149s	
520/5250 (epoch 4.952), train_loss = 1.77434250, grad/param norm = 1.7446e-01, time/batch = 0.1148s	
521/5250 (epoch 4.962), train_loss = 1.72692561, grad/param norm = 1.4803e-01, time/batch = 0.1155s	
522/5250 (epoch 4.971), train_loss = 1.70646663, grad/param norm = 1.2114e-01, time/batch = 0.1145s	
523/5250 (epoch 4.981), train_loss = 1.72981145, grad/param norm = 1.0862e-01, time/batch = 0.1146s	
524/5250 (epoch 4.990), train_loss = 1.73070200, grad/param norm = 1.0501e-01, time/batch = 0.1147s	
525/5250 (epoch 5.000), train_loss = 1.69698218, grad/param norm = 1.1116e-01, time/batch = 0.1149s	
526/5250 (epoch 5.010), train_loss = 1.82347579, grad/param norm = 1.2820e-01, time/batch = 0.1150s	
527/5250 (epoch 5.019), train_loss = 1.71050063, grad/param norm = 1.3076e-01, time/batch = 0.1149s	
528/5250 (epoch 5.029), train_loss = 1.71070285, grad/param norm = 1.2790e-01, time/batch = 0.1143s	
529/5250 (epoch 5.038), train_loss = 1.71376785, grad/param norm = 1.2446e-01, time/batch = 0.1150s	
530/5250 (epoch 5.048), train_loss = 1.68083626, grad/param norm = 1.3303e-01, time/batch = 0.1149s	
531/5250 (epoch 5.057), train_loss = 1.70128362, grad/param norm = 1.3112e-01, time/batch = 0.1155s	
532/5250 (epoch 5.067), train_loss = 1.69879936, grad/param norm = 1.2219e-01, time/batch = 0.1142s	
533/5250 (epoch 5.076), train_loss = 1.69121842, grad/param norm = 1.1333e-01, time/batch = 0.1147s	
534/5250 (epoch 5.086), train_loss = 1.62843036, grad/param norm = 9.8095e-02, time/batch = 0.1147s	
535/5250 (epoch 5.095), train_loss = 1.67541458, grad/param norm = 9.3320e-02, time/batch = 0.1149s	
536/5250 (epoch 5.105), train_loss = 1.69246881, grad/param norm = 1.0551e-01, time/batch = 0.1148s	
537/5250 (epoch 5.114), train_loss = 1.67149551, grad/param norm = 1.1127e-01, time/batch = 0.1149s	
538/5250 (epoch 5.124), train_loss = 1.68615080, grad/param norm = 1.1916e-01, time/batch = 0.1143s	
539/5250 (epoch 5.133), train_loss = 1.68070766, grad/param norm = 1.3121e-01, time/batch = 0.1151s	
540/5250 (epoch 5.143), train_loss = 1.66639763, grad/param norm = 1.5926e-01, time/batch = 0.1149s	
541/5250 (epoch 5.152), train_loss = 1.68312311, grad/param norm = 2.0803e-01, time/batch = 0.1155s	
542/5250 (epoch 5.162), train_loss = 1.73052831, grad/param norm = 1.7826e-01, time/batch = 0.1142s	
543/5250 (epoch 5.171), train_loss = 1.72834080, grad/param norm = 1.4558e-01, time/batch = 0.1147s	
544/5250 (epoch 5.181), train_loss = 1.70605824, grad/param norm = 1.2794e-01, time/batch = 0.1146s	
545/5250 (epoch 5.190), train_loss = 1.69001555, grad/param norm = 1.1725e-01, time/batch = 0.1149s	
546/5250 (epoch 5.200), train_loss = 1.66940644, grad/param norm = 1.1530e-01, time/batch = 0.1148s	
547/5250 (epoch 5.210), train_loss = 1.68534186, grad/param norm = 1.4440e-01, time/batch = 0.1149s	
548/5250 (epoch 5.219), train_loss = 1.74036658, grad/param norm = 1.5468e-01, time/batch = 0.1142s	
549/5250 (epoch 5.229), train_loss = 1.69377920, grad/param norm = 1.4975e-01, time/batch = 0.1151s	
550/5250 (epoch 5.238), train_loss = 1.66909609, grad/param norm = 1.3566e-01, time/batch = 0.1148s	
551/5250 (epoch 5.248), train_loss = 1.67738324, grad/param norm = 1.3172e-01, time/batch = 0.1154s	
552/5250 (epoch 5.257), train_loss = 1.66675150, grad/param norm = 1.2722e-01, time/batch = 0.1145s	
553/5250 (epoch 5.267), train_loss = 1.65318804, grad/param norm = 1.1880e-01, time/batch = 0.1144s	
554/5250 (epoch 5.276), train_loss = 1.66200519, grad/param norm = 1.1273e-01, time/batch = 0.1149s	
555/5250 (epoch 5.286), train_loss = 1.62880096, grad/param norm = 1.1276e-01, time/batch = 0.1149s	
556/5250 (epoch 5.295), train_loss = 1.66883792, grad/param norm = 1.1611e-01, time/batch = 0.1147s	
557/5250 (epoch 5.305), train_loss = 1.67591675, grad/param norm = 1.3845e-01, time/batch = 0.1147s	
558/5250 (epoch 5.314), train_loss = 1.64371801, grad/param norm = 1.3496e-01, time/batch = 0.1144s	
559/5250 (epoch 5.324), train_loss = 1.67947117, grad/param norm = 1.2811e-01, time/batch = 0.1168s	
560/5250 (epoch 5.333), train_loss = 1.67472984, grad/param norm = 1.1174e-01, time/batch = 0.1147s	
561/5250 (epoch 5.343), train_loss = 1.66517140, grad/param norm = 1.0084e-01, time/batch = 0.1159s	
562/5250 (epoch 5.352), train_loss = 1.66590323, grad/param norm = 1.0769e-01, time/batch = 0.1145s	
563/5250 (epoch 5.362), train_loss = 1.66494013, grad/param norm = 1.1333e-01, time/batch = 0.1146s	
564/5250 (epoch 5.371), train_loss = 1.64011633, grad/param norm = 1.1063e-01, time/batch = 0.1150s	
565/5250 (epoch 5.381), train_loss = 1.64689539, grad/param norm = 1.0705e-01, time/batch = 0.1148s	
566/5250 (epoch 5.390), train_loss = 1.66788163, grad/param norm = 1.1257e-01, time/batch = 0.1147s	
567/5250 (epoch 5.400), train_loss = 1.64111260, grad/param norm = 1.0778e-01, time/batch = 0.1148s	
568/5250 (epoch 5.410), train_loss = 1.66893870, grad/param norm = 1.2794e-01, time/batch = 0.1141s	
569/5250 (epoch 5.419), train_loss = 1.67023046, grad/param norm = 1.3739e-01, time/batch = 0.1151s	
570/5250 (epoch 5.429), train_loss = 1.68346620, grad/param norm = 1.7892e-01, time/batch = 0.1149s	
571/5250 (epoch 5.438), train_loss = 1.72083262, grad/param norm = 1.5809e-01, time/batch = 0.1155s	
572/5250 (epoch 5.448), train_loss = 1.66361112, grad/param norm = 1.6590e-01, time/batch = 0.1142s	
573/5250 (epoch 5.457), train_loss = 1.65563214, grad/param norm = 1.7242e-01, time/batch = 0.1145s	
574/5250 (epoch 5.467), train_loss = 1.65295451, grad/param norm = 1.4143e-01, time/batch = 0.1148s	
575/5250 (epoch 5.476), train_loss = 1.64316345, grad/param norm = 1.1315e-01, time/batch = 0.1149s	
576/5250 (epoch 5.486), train_loss = 1.64732404, grad/param norm = 9.7589e-02, time/batch = 0.1149s	
577/5250 (epoch 5.495), train_loss = 1.63927322, grad/param norm = 8.2113e-02, time/batch = 0.1148s	
578/5250 (epoch 5.505), train_loss = 1.65138697, grad/param norm = 8.1092e-02, time/batch = 0.1143s	
579/5250 (epoch 5.514), train_loss = 1.65184907, grad/param norm = 8.9816e-02, time/batch = 0.1150s	
580/5250 (epoch 5.524), train_loss = 1.62806767, grad/param norm = 1.0581e-01, time/batch = 0.1150s	
581/5250 (epoch 5.533), train_loss = 1.64045309, grad/param norm = 1.2705e-01, time/batch = 0.1153s	
582/5250 (epoch 5.543), train_loss = 1.63190355, grad/param norm = 1.4734e-01, time/batch = 0.1141s	
583/5250 (epoch 5.552), train_loss = 1.65317324, grad/param norm = 1.3934e-01, time/batch = 0.1147s	
584/5250 (epoch 5.562), train_loss = 1.66260522, grad/param norm = 1.2234e-01, time/batch = 0.1148s	
585/5250 (epoch 5.571), train_loss = 1.65248890, grad/param norm = 1.2060e-01, time/batch = 0.1149s	
586/5250 (epoch 5.581), train_loss = 1.67312324, grad/param norm = 1.1853e-01, time/batch = 0.1149s	
587/5250 (epoch 5.590), train_loss = 1.64899334, grad/param norm = 1.3971e-01, time/batch = 0.1146s	
588/5250 (epoch 5.600), train_loss = 1.67966593, grad/param norm = 1.4691e-01, time/batch = 0.1142s	
589/5250 (epoch 5.610), train_loss = 1.66427878, grad/param norm = 1.5520e-01, time/batch = 0.1152s	
590/5250 (epoch 5.619), train_loss = 1.64911750, grad/param norm = 1.2890e-01, time/batch = 0.1149s	
591/5250 (epoch 5.629), train_loss = 1.65677947, grad/param norm = 9.4224e-02, time/batch = 0.1153s	
592/5250 (epoch 5.638), train_loss = 1.62430259, grad/param norm = 8.5992e-02, time/batch = 0.1144s	
593/5250 (epoch 5.648), train_loss = 1.62961299, grad/param norm = 8.8841e-02, time/batch = 0.1147s	
594/5250 (epoch 5.657), train_loss = 1.61498189, grad/param norm = 8.6299e-02, time/batch = 0.1147s	
595/5250 (epoch 5.667), train_loss = 1.63443162, grad/param norm = 9.1226e-02, time/batch = 0.1150s	
596/5250 (epoch 5.676), train_loss = 1.62164023, grad/param norm = 9.9156e-02, time/batch = 0.1147s	
597/5250 (epoch 5.686), train_loss = 1.65757923, grad/param norm = 1.0044e-01, time/batch = 0.1147s	
598/5250 (epoch 5.695), train_loss = 1.63612396, grad/param norm = 1.0083e-01, time/batch = 0.1143s	
599/5250 (epoch 5.705), train_loss = 1.61616738, grad/param norm = 1.1421e-01, time/batch = 0.1152s	
600/5250 (epoch 5.714), train_loss = 1.65686796, grad/param norm = 1.2436e-01, time/batch = 0.1147s	
601/5250 (epoch 5.724), train_loss = 1.62729329, grad/param norm = 1.2301e-01, time/batch = 0.1155s	
602/5250 (epoch 5.733), train_loss = 1.62641612, grad/param norm = 1.1948e-01, time/batch = 0.1141s	
603/5250 (epoch 5.743), train_loss = 1.61051973, grad/param norm = 1.0667e-01, time/batch = 0.1146s	
604/5250 (epoch 5.752), train_loss = 1.62206003, grad/param norm = 9.0041e-02, time/batch = 0.1147s	
605/5250 (epoch 5.762), train_loss = 1.60176925, grad/param norm = 8.4941e-02, time/batch = 0.1148s	
606/5250 (epoch 5.771), train_loss = 1.59428932, grad/param norm = 9.2478e-02, time/batch = 0.1148s	
607/5250 (epoch 5.781), train_loss = 1.63021862, grad/param norm = 1.2015e-01, time/batch = 0.1148s	
608/5250 (epoch 5.790), train_loss = 1.65889014, grad/param norm = 1.5378e-01, time/batch = 0.1142s	
609/5250 (epoch 5.800), train_loss = 1.65686239, grad/param norm = 1.5231e-01, time/batch = 0.1149s	
610/5250 (epoch 5.810), train_loss = 1.63337768, grad/param norm = 1.3479e-01, time/batch = 0.1149s	
611/5250 (epoch 5.819), train_loss = 1.63069066, grad/param norm = 1.2913e-01, time/batch = 0.1152s	
612/5250 (epoch 5.829), train_loss = 1.63657760, grad/param norm = 1.2443e-01, time/batch = 0.1144s	
613/5250 (epoch 5.838), train_loss = 1.61575126, grad/param norm = 1.2287e-01, time/batch = 0.1146s	
614/5250 (epoch 5.848), train_loss = 1.60879467, grad/param norm = 1.2110e-01, time/batch = 0.1146s	
615/5250 (epoch 5.857), train_loss = 1.61634517, grad/param norm = 1.2079e-01, time/batch = 0.1149s	
616/5250 (epoch 5.867), train_loss = 1.60533869, grad/param norm = 1.2161e-01, time/batch = 0.1149s	
617/5250 (epoch 5.876), train_loss = 1.63726244, grad/param norm = 1.5494e-01, time/batch = 0.1148s	
618/5250 (epoch 5.886), train_loss = 1.64510729, grad/param norm = 1.7404e-01, time/batch = 0.1142s	
619/5250 (epoch 5.895), train_loss = 1.66034604, grad/param norm = 1.8165e-01, time/batch = 0.1151s	
620/5250 (epoch 5.905), train_loss = 1.65960565, grad/param norm = 1.5958e-01, time/batch = 0.1149s	
621/5250 (epoch 5.914), train_loss = 1.63988865, grad/param norm = 1.3228e-01, time/batch = 0.1155s	
622/5250 (epoch 5.924), train_loss = 1.62879755, grad/param norm = 1.1842e-01, time/batch = 0.1143s	
623/5250 (epoch 5.933), train_loss = 1.61231629, grad/param norm = 8.4064e-02, time/batch = 0.1147s	
624/5250 (epoch 5.943), train_loss = 1.63722682, grad/param norm = 7.1367e-02, time/batch = 0.1148s	
625/5250 (epoch 5.952), train_loss = 1.62726638, grad/param norm = 7.9947e-02, time/batch = 0.1149s	
626/5250 (epoch 5.962), train_loss = 1.60757127, grad/param norm = 8.8605e-02, time/batch = 0.1148s	
627/5250 (epoch 5.971), train_loss = 1.58783877, grad/param norm = 8.3876e-02, time/batch = 0.1149s	
628/5250 (epoch 5.981), train_loss = 1.62353704, grad/param norm = 8.6608e-02, time/batch = 0.1141s	
629/5250 (epoch 5.990), train_loss = 1.63008067, grad/param norm = 1.0080e-01, time/batch = 0.1159s	
630/5250 (epoch 6.000), train_loss = 1.60268975, grad/param norm = 1.2003e-01, time/batch = 0.1161s	
631/5250 (epoch 6.010), train_loss = 1.74460963, grad/param norm = 1.4619e-01, time/batch = 0.1157s	
632/5250 (epoch 6.019), train_loss = 1.62521875, grad/param norm = 1.4903e-01, time/batch = 0.1143s	
633/5250 (epoch 6.029), train_loss = 1.62098078, grad/param norm = 1.3123e-01, time/batch = 0.1147s	
634/5250 (epoch 6.038), train_loss = 1.61721903, grad/param norm = 1.1849e-01, time/batch = 0.1149s	
635/5250 (epoch 6.048), train_loss = 1.58193395, grad/param norm = 1.1333e-01, time/batch = 0.1149s	
636/5250 (epoch 6.057), train_loss = 1.59587806, grad/param norm = 1.0271e-01, time/batch = 0.1149s	
637/5250 (epoch 6.067), train_loss = 1.59442292, grad/param norm = 1.0166e-01, time/batch = 0.1148s	
638/5250 (epoch 6.076), train_loss = 1.59500451, grad/param norm = 1.0329e-01, time/batch = 0.1142s	
639/5250 (epoch 6.086), train_loss = 1.53619526, grad/param norm = 1.0948e-01, time/batch = 0.1150s	
640/5250 (epoch 6.095), train_loss = 1.59537910, grad/param norm = 1.2727e-01, time/batch = 0.1149s	
641/5250 (epoch 6.105), train_loss = 1.62424530, grad/param norm = 1.2787e-01, time/batch = 0.1157s	
642/5250 (epoch 6.114), train_loss = 1.58755549, grad/param norm = 1.1007e-01, time/batch = 0.1143s	
643/5250 (epoch 6.124), train_loss = 1.59220272, grad/param norm = 1.0040e-01, time/batch = 0.1147s	
644/5250 (epoch 6.133), train_loss = 1.57674848, grad/param norm = 1.0045e-01, time/batch = 0.1148s	
645/5250 (epoch 6.143), train_loss = 1.55483906, grad/param norm = 1.0402e-01, time/batch = 0.1151s	
646/5250 (epoch 6.152), train_loss = 1.54839945, grad/param norm = 1.0910e-01, time/batch = 0.1148s	
647/5250 (epoch 6.162), train_loss = 1.59569684, grad/param norm = 1.2011e-01, time/batch = 0.1152s	
648/5250 (epoch 6.171), train_loss = 1.61813886, grad/param norm = 1.3041e-01, time/batch = 0.1140s	
649/5250 (epoch 6.181), train_loss = 1.60757040, grad/param norm = 1.2483e-01, time/batch = 0.1151s	
650/5250 (epoch 6.190), train_loss = 1.60126232, grad/param norm = 1.0796e-01, time/batch = 0.1151s	
651/5250 (epoch 6.200), train_loss = 1.57442398, grad/param norm = 1.0351e-01, time/batch = 0.1154s	
652/5250 (epoch 6.210), train_loss = 1.58576253, grad/param norm = 1.0277e-01, time/batch = 0.1142s	
653/5250 (epoch 6.219), train_loss = 1.62831284, grad/param norm = 1.1403e-01, time/batch = 0.1147s	
654/5250 (epoch 6.229), train_loss = 1.59108047, grad/param norm = 9.8955e-02, time/batch = 0.1149s	
655/5250 (epoch 6.238), train_loss = 1.56887943, grad/param norm = 9.2532e-02, time/batch = 0.1148s	
656/5250 (epoch 6.248), train_loss = 1.58121777, grad/param norm = 1.0471e-01, time/batch = 0.1147s	
657/5250 (epoch 6.257), train_loss = 1.57824047, grad/param norm = 1.1371e-01, time/batch = 0.1149s	
658/5250 (epoch 6.267), train_loss = 1.56924748, grad/param norm = 1.0581e-01, time/batch = 0.1143s	
659/5250 (epoch 6.276), train_loss = 1.56381688, grad/param norm = 1.0023e-01, time/batch = 0.1151s	
660/5250 (epoch 6.286), train_loss = 1.53967284, grad/param norm = 9.7898e-02, time/batch = 0.1149s	
661/5250 (epoch 6.295), train_loss = 1.57062374, grad/param norm = 9.1748e-02, time/batch = 0.1154s	
662/5250 (epoch 6.305), train_loss = 1.57701042, grad/param norm = 9.2680e-02, time/batch = 0.1143s	
663/5250 (epoch 6.314), train_loss = 1.53644210, grad/param norm = 8.8195e-02, time/batch = 0.1145s	
664/5250 (epoch 6.324), train_loss = 1.57345189, grad/param norm = 9.2885e-02, time/batch = 0.1148s	
665/5250 (epoch 6.333), train_loss = 1.57665329, grad/param norm = 1.1727e-01, time/batch = 0.1148s	
666/5250 (epoch 6.343), train_loss = 1.59762202, grad/param norm = 1.5557e-01, time/batch = 0.1147s	
667/5250 (epoch 6.352), train_loss = 1.61778624, grad/param norm = 1.6844e-01, time/batch = 0.1149s	
668/5250 (epoch 6.362), train_loss = 1.59673917, grad/param norm = 1.2858e-01, time/batch = 0.1142s	
669/5250 (epoch 6.371), train_loss = 1.55416939, grad/param norm = 1.0012e-01, time/batch = 0.1150s	
670/5250 (epoch 6.381), train_loss = 1.55726152, grad/param norm = 8.9780e-02, time/batch = 0.1149s	
671/5250 (epoch 6.390), train_loss = 1.57193826, grad/param norm = 9.2963e-02, time/batch = 0.1155s	
672/5250 (epoch 6.400), train_loss = 1.55584973, grad/param norm = 9.1387e-02, time/batch = 0.1142s	
673/5250 (epoch 6.410), train_loss = 1.57530030, grad/param norm = 9.2345e-02, time/batch = 0.1146s	
674/5250 (epoch 6.419), train_loss = 1.55955504, grad/param norm = 8.1526e-02, time/batch = 0.1147s	
675/5250 (epoch 6.429), train_loss = 1.57000453, grad/param norm = 8.1282e-02, time/batch = 0.1147s	
676/5250 (epoch 6.438), train_loss = 1.59518677, grad/param norm = 9.8187e-02, time/batch = 0.1148s	
677/5250 (epoch 6.448), train_loss = 1.55094870, grad/param norm = 1.1120e-01, time/batch = 0.1149s	
678/5250 (epoch 6.457), train_loss = 1.54529811, grad/param norm = 1.2275e-01, time/batch = 0.1141s	
679/5250 (epoch 6.467), train_loss = 1.56675482, grad/param norm = 1.1425e-01, time/batch = 0.1151s	
680/5250 (epoch 6.476), train_loss = 1.55903209, grad/param norm = 9.2412e-02, time/batch = 0.1151s	
681/5250 (epoch 6.486), train_loss = 1.55834129, grad/param norm = 8.1511e-02, time/batch = 0.1161s	
682/5250 (epoch 6.495), train_loss = 1.55683963, grad/param norm = 8.0707e-02, time/batch = 0.1142s	
683/5250 (epoch 6.505), train_loss = 1.57114596, grad/param norm = 8.6505e-02, time/batch = 0.1146s	
684/5250 (epoch 6.514), train_loss = 1.57363115, grad/param norm = 1.0163e-01, time/batch = 0.1147s	
685/5250 (epoch 6.524), train_loss = 1.55117260, grad/param norm = 1.0228e-01, time/batch = 0.1149s	
686/5250 (epoch 6.533), train_loss = 1.55034785, grad/param norm = 1.0383e-01, time/batch = 0.1148s	
687/5250 (epoch 6.543), train_loss = 1.53819694, grad/param norm = 1.0146e-01, time/batch = 0.1149s	
688/5250 (epoch 6.552), train_loss = 1.54740381, grad/param norm = 9.4834e-02, time/batch = 0.1142s	
689/5250 (epoch 6.562), train_loss = 1.57267939, grad/param norm = 9.7059e-02, time/batch = 0.1151s	
690/5250 (epoch 6.571), train_loss = 1.56671803, grad/param norm = 1.0825e-01, time/batch = 0.1150s	
691/5250 (epoch 6.581), train_loss = 1.59459107, grad/param norm = 1.0225e-01, time/batch = 0.1153s	
692/5250 (epoch 6.590), train_loss = 1.56292799, grad/param norm = 1.0151e-01, time/batch = 0.1143s	
693/5250 (epoch 6.600), train_loss = 1.57656212, grad/param norm = 1.0441e-01, time/batch = 0.1146s	
694/5250 (epoch 6.610), train_loss = 1.57773294, grad/param norm = 1.1580e-01, time/batch = 0.1149s	
695/5250 (epoch 6.619), train_loss = 1.56175686, grad/param norm = 1.1549e-01, time/batch = 0.1149s	
696/5250 (epoch 6.629), train_loss = 1.59182875, grad/param norm = 1.1927e-01, time/batch = 0.1148s	
697/5250 (epoch 6.638), train_loss = 1.57249286, grad/param norm = 1.2736e-01, time/batch = 0.1148s	
698/5250 (epoch 6.648), train_loss = 1.57855650, grad/param norm = 1.1736e-01, time/batch = 0.1141s	
699/5250 (epoch 6.657), train_loss = 1.55226729, grad/param norm = 1.0082e-01, time/batch = 0.1151s	
700/5250 (epoch 6.667), train_loss = 1.56433011, grad/param norm = 9.5454e-02, time/batch = 0.1168s	
701/5250 (epoch 6.676), train_loss = 1.54516476, grad/param norm = 9.0867e-02, time/batch = 0.1156s	
702/5250 (epoch 6.686), train_loss = 1.57030879, grad/param norm = 8.0502e-02, time/batch = 0.1143s	
703/5250 (epoch 6.695), train_loss = 1.55347634, grad/param norm = 7.8848e-02, time/batch = 0.1144s	
704/5250 (epoch 6.705), train_loss = 1.52979438, grad/param norm = 8.5426e-02, time/batch = 0.1146s	
705/5250 (epoch 6.714), train_loss = 1.56068224, grad/param norm = 8.2803e-02, time/batch = 0.1148s	
706/5250 (epoch 6.724), train_loss = 1.53529462, grad/param norm = 8.5736e-02, time/batch = 0.1149s	
707/5250 (epoch 6.733), train_loss = 1.52997127, grad/param norm = 8.7555e-02, time/batch = 0.1149s	
708/5250 (epoch 6.743), train_loss = 1.52668192, grad/param norm = 8.5935e-02, time/batch = 0.1142s	
709/5250 (epoch 6.752), train_loss = 1.54544217, grad/param norm = 9.3396e-02, time/batch = 0.1151s	
710/5250 (epoch 6.762), train_loss = 1.54928039, grad/param norm = 1.0804e-01, time/batch = 0.1148s	
711/5250 (epoch 6.771), train_loss = 1.53745733, grad/param norm = 1.1009e-01, time/batch = 0.1153s	
712/5250 (epoch 6.781), train_loss = 1.56028752, grad/param norm = 1.0135e-01, time/batch = 0.1140s	
713/5250 (epoch 6.790), train_loss = 1.56574696, grad/param norm = 1.1069e-01, time/batch = 0.1147s	
714/5250 (epoch 6.800), train_loss = 1.56245143, grad/param norm = 1.1387e-01, time/batch = 0.1147s	
715/5250 (epoch 6.810), train_loss = 1.55696618, grad/param norm = 1.2559e-01, time/batch = 0.1148s	
716/5250 (epoch 6.819), train_loss = 1.55685207, grad/param norm = 1.2276e-01, time/batch = 0.1149s	
717/5250 (epoch 6.829), train_loss = 1.55599952, grad/param norm = 1.0952e-01, time/batch = 0.1151s	
718/5250 (epoch 6.838), train_loss = 1.52995406, grad/param norm = 1.0661e-01, time/batch = 0.1144s	
719/5250 (epoch 6.848), train_loss = 1.52820081, grad/param norm = 9.7792e-02, time/batch = 0.1151s	
720/5250 (epoch 6.857), train_loss = 1.53634121, grad/param norm = 9.2791e-02, time/batch = 0.1150s	
721/5250 (epoch 6.867), train_loss = 1.51989548, grad/param norm = 8.6947e-02, time/batch = 0.1154s	
722/5250 (epoch 6.876), train_loss = 1.53847617, grad/param norm = 8.8118e-02, time/batch = 0.1142s	
723/5250 (epoch 6.886), train_loss = 1.52913376, grad/param norm = 9.3956e-02, time/batch = 0.1147s	
724/5250 (epoch 6.895), train_loss = 1.54755906, grad/param norm = 8.7429e-02, time/batch = 0.1147s	
725/5250 (epoch 6.905), train_loss = 1.54877955, grad/param norm = 8.6106e-02, time/batch = 0.1150s	
726/5250 (epoch 6.914), train_loss = 1.55353342, grad/param norm = 9.8698e-02, time/batch = 0.1149s	
727/5250 (epoch 6.924), train_loss = 1.56066872, grad/param norm = 1.0021e-01, time/batch = 0.1147s	
728/5250 (epoch 6.933), train_loss = 1.54112795, grad/param norm = 1.0177e-01, time/batch = 0.1143s	
729/5250 (epoch 6.943), train_loss = 1.57951722, grad/param norm = 9.6507e-02, time/batch = 0.1149s	
730/5250 (epoch 6.952), train_loss = 1.56719639, grad/param norm = 1.0379e-01, time/batch = 0.1148s	
731/5250 (epoch 6.962), train_loss = 1.55256711, grad/param norm = 1.0744e-01, time/batch = 0.1160s	
732/5250 (epoch 6.971), train_loss = 1.52682347, grad/param norm = 1.0097e-01, time/batch = 0.1142s	
733/5250 (epoch 6.981), train_loss = 1.56251459, grad/param norm = 1.1577e-01, time/batch = 0.1148s	
734/5250 (epoch 6.990), train_loss = 1.57142314, grad/param norm = 1.3079e-01, time/batch = 0.1148s	
735/5250 (epoch 7.000), train_loss = 1.54466736, grad/param norm = 1.2915e-01, time/batch = 0.1148s	
736/5250 (epoch 7.010), train_loss = 1.67753652, grad/param norm = 1.2211e-01, time/batch = 0.1148s	
737/5250 (epoch 7.019), train_loss = 1.52931234, grad/param norm = 1.0668e-01, time/batch = 0.1147s	
738/5250 (epoch 7.029), train_loss = 1.53383978, grad/param norm = 9.4667e-02, time/batch = 0.1142s	
739/5250 (epoch 7.038), train_loss = 1.52803961, grad/param norm = 9.0709e-02, time/batch = 0.1149s	
740/5250 (epoch 7.048), train_loss = 1.50196535, grad/param norm = 9.2816e-02, time/batch = 0.1149s	
741/5250 (epoch 7.057), train_loss = 1.51593065, grad/param norm = 8.6008e-02, time/batch = 0.1154s	
742/5250 (epoch 7.067), train_loss = 1.51334754, grad/param norm = 7.9460e-02, time/batch = 0.1142s	
743/5250 (epoch 7.076), train_loss = 1.51674323, grad/param norm = 7.1529e-02, time/batch = 0.1144s	
744/5250 (epoch 7.086), train_loss = 1.45145907, grad/param norm = 7.8281e-02, time/batch = 0.1147s	
745/5250 (epoch 7.095), train_loss = 1.50173558, grad/param norm = 8.6019e-02, time/batch = 0.1150s	
746/5250 (epoch 7.105), train_loss = 1.52766596, grad/param norm = 8.6960e-02, time/batch = 0.1149s	
747/5250 (epoch 7.114), train_loss = 1.50077085, grad/param norm = 8.4066e-02, time/batch = 0.1149s	
748/5250 (epoch 7.124), train_loss = 1.51482072, grad/param norm = 8.9397e-02, time/batch = 0.1144s	
749/5250 (epoch 7.133), train_loss = 1.51403383, grad/param norm = 9.5999e-02, time/batch = 0.1150s	
750/5250 (epoch 7.143), train_loss = 1.48892508, grad/param norm = 1.0383e-01, time/batch = 0.1147s	
751/5250 (epoch 7.152), train_loss = 1.48939013, grad/param norm = 1.0592e-01, time/batch = 0.1151s	
752/5250 (epoch 7.162), train_loss = 1.53419286, grad/param norm = 1.1987e-01, time/batch = 0.1143s	
753/5250 (epoch 7.171), train_loss = 1.55144237, grad/param norm = 1.2603e-01, time/batch = 0.1147s	
754/5250 (epoch 7.181), train_loss = 1.52801747, grad/param norm = 1.0034e-01, time/batch = 0.1147s	
755/5250 (epoch 7.190), train_loss = 1.51484316, grad/param norm = 7.8539e-02, time/batch = 0.1149s	
756/5250 (epoch 7.200), train_loss = 1.49425760, grad/param norm = 7.4212e-02, time/batch = 0.1149s	
757/5250 (epoch 7.210), train_loss = 1.50298928, grad/param norm = 8.3950e-02, time/batch = 0.1149s	
758/5250 (epoch 7.219), train_loss = 1.55390238, grad/param norm = 8.8717e-02, time/batch = 0.1141s	
759/5250 (epoch 7.229), train_loss = 1.51346100, grad/param norm = 9.4103e-02, time/batch = 0.1151s	
760/5250 (epoch 7.238), train_loss = 1.51329927, grad/param norm = 9.3794e-02, time/batch = 0.1148s	
761/5250 (epoch 7.248), train_loss = 1.51102508, grad/param norm = 9.0744e-02, time/batch = 0.1160s	
762/5250 (epoch 7.257), train_loss = 1.49929571, grad/param norm = 8.8854e-02, time/batch = 0.1142s	
763/5250 (epoch 7.267), train_loss = 1.49200350, grad/param norm = 9.3934e-02, time/batch = 0.1147s	
764/5250 (epoch 7.276), train_loss = 1.49298616, grad/param norm = 1.0251e-01, time/batch = 0.1150s	
765/5250 (epoch 7.286), train_loss = 1.47731323, grad/param norm = 1.0822e-01, time/batch = 0.1150s	
766/5250 (epoch 7.295), train_loss = 1.50998003, grad/param norm = 1.0514e-01, time/batch = 0.1148s	
767/5250 (epoch 7.305), train_loss = 1.51544438, grad/param norm = 1.0216e-01, time/batch = 0.1148s	
768/5250 (epoch 7.314), train_loss = 1.47735566, grad/param norm = 8.4744e-02, time/batch = 0.1142s	
769/5250 (epoch 7.324), train_loss = 1.50458206, grad/param norm = 8.6640e-02, time/batch = 0.1152s	
770/5250 (epoch 7.333), train_loss = 1.50484181, grad/param norm = 8.6671e-02, time/batch = 0.1152s	
771/5250 (epoch 7.343), train_loss = 1.50238041, grad/param norm = 8.3114e-02, time/batch = 0.1159s	
772/5250 (epoch 7.352), train_loss = 1.51575653, grad/param norm = 9.1633e-02, time/batch = 0.1143s	
773/5250 (epoch 7.362), train_loss = 1.51713652, grad/param norm = 9.4955e-02, time/batch = 0.1148s	
774/5250 (epoch 7.371), train_loss = 1.48531638, grad/param norm = 8.9089e-02, time/batch = 0.1146s	
775/5250 (epoch 7.381), train_loss = 1.48839454, grad/param norm = 8.7086e-02, time/batch = 0.1148s	
776/5250 (epoch 7.390), train_loss = 1.50488041, grad/param norm = 8.6907e-02, time/batch = 0.1148s	
777/5250 (epoch 7.400), train_loss = 1.48506177, grad/param norm = 7.7777e-02, time/batch = 0.1148s	
778/5250 (epoch 7.410), train_loss = 1.50282111, grad/param norm = 7.5919e-02, time/batch = 0.1143s	
779/5250 (epoch 7.419), train_loss = 1.49403642, grad/param norm = 7.1118e-02, time/batch = 0.1153s	
780/5250 (epoch 7.429), train_loss = 1.50537371, grad/param norm = 7.4287e-02, time/batch = 0.1149s	
781/5250 (epoch 7.438), train_loss = 1.52703387, grad/param norm = 8.4713e-02, time/batch = 0.1154s	
782/5250 (epoch 7.448), train_loss = 1.48461143, grad/param norm = 1.0108e-01, time/batch = 0.1142s	
783/5250 (epoch 7.457), train_loss = 1.48432468, grad/param norm = 1.1448e-01, time/batch = 0.1146s	
784/5250 (epoch 7.467), train_loss = 1.50494147, grad/param norm = 1.1379e-01, time/batch = 0.1149s	
785/5250 (epoch 7.476), train_loss = 1.49965225, grad/param norm = 1.0043e-01, time/batch = 0.1151s	
786/5250 (epoch 7.486), train_loss = 1.50092309, grad/param norm = 8.8901e-02, time/batch = 0.1152s	
787/5250 (epoch 7.495), train_loss = 1.49681801, grad/param norm = 7.6502e-02, time/batch = 0.1147s	
788/5250 (epoch 7.505), train_loss = 1.50690363, grad/param norm = 7.8724e-02, time/batch = 0.1144s	
789/5250 (epoch 7.514), train_loss = 1.50782686, grad/param norm = 8.8261e-02, time/batch = 0.1150s	
790/5250 (epoch 7.524), train_loss = 1.49303190, grad/param norm = 1.1112e-01, time/batch = 0.1149s	
791/5250 (epoch 7.533), train_loss = 1.51162057, grad/param norm = 1.0498e-01, time/batch = 0.1161s	
792/5250 (epoch 7.543), train_loss = 1.48007729, grad/param norm = 9.6015e-02, time/batch = 0.1143s	
793/5250 (epoch 7.552), train_loss = 1.50307751, grad/param norm = 1.0170e-01, time/batch = 0.1147s	
794/5250 (epoch 7.562), train_loss = 1.51345992, grad/param norm = 1.0236e-01, time/batch = 0.1147s	
795/5250 (epoch 7.571), train_loss = 1.49902906, grad/param norm = 9.0016e-02, time/batch = 0.1149s	
796/5250 (epoch 7.581), train_loss = 1.52432661, grad/param norm = 8.4969e-02, time/batch = 0.1148s	
797/5250 (epoch 7.590), train_loss = 1.49941854, grad/param norm = 8.0529e-02, time/batch = 0.1149s	
798/5250 (epoch 7.600), train_loss = 1.50541928, grad/param norm = 7.2101e-02, time/batch = 0.1141s	
799/5250 (epoch 7.610), train_loss = 1.50372460, grad/param norm = 6.8225e-02, time/batch = 0.1152s	
800/5250 (epoch 7.619), train_loss = 1.48200481, grad/param norm = 6.6755e-02, time/batch = 0.1150s	
801/5250 (epoch 7.629), train_loss = 1.50129559, grad/param norm = 7.3874e-02, time/batch = 0.1154s	
802/5250 (epoch 7.638), train_loss = 1.48791070, grad/param norm = 8.7712e-02, time/batch = 0.1144s	
803/5250 (epoch 7.648), train_loss = 1.49753697, grad/param norm = 8.8932e-02, time/batch = 0.1146s	
804/5250 (epoch 7.657), train_loss = 1.48179747, grad/param norm = 8.7456e-02, time/batch = 0.1148s	
805/5250 (epoch 7.667), train_loss = 1.50204968, grad/param norm = 9.4941e-02, time/batch = 0.1151s	
806/5250 (epoch 7.676), train_loss = 1.49022378, grad/param norm = 1.1113e-01, time/batch = 0.1148s	
807/5250 (epoch 7.686), train_loss = 1.52964404, grad/param norm = 1.0624e-01, time/batch = 0.1148s	
808/5250 (epoch 7.695), train_loss = 1.50196061, grad/param norm = 1.0206e-01, time/batch = 0.1141s	
809/5250 (epoch 7.705), train_loss = 1.47847412, grad/param norm = 8.9332e-02, time/batch = 0.1152s	
810/5250 (epoch 7.714), train_loss = 1.50060632, grad/param norm = 7.8826e-02, time/batch = 0.1149s	
811/5250 (epoch 7.724), train_loss = 1.47647470, grad/param norm = 7.7695e-02, time/batch = 0.1153s	
812/5250 (epoch 7.733), train_loss = 1.46329832, grad/param norm = 7.4201e-02, time/batch = 0.1142s	
813/5250 (epoch 7.743), train_loss = 1.46173222, grad/param norm = 7.3467e-02, time/batch = 0.1145s	
814/5250 (epoch 7.752), train_loss = 1.47732858, grad/param norm = 7.8429e-02, time/batch = 0.1149s	
815/5250 (epoch 7.762), train_loss = 1.48997234, grad/param norm = 1.2475e-01, time/batch = 0.1150s	
816/5250 (epoch 7.771), train_loss = 1.49360899, grad/param norm = 1.2219e-01, time/batch = 0.1147s	
817/5250 (epoch 7.781), train_loss = 1.50262068, grad/param norm = 9.9393e-02, time/batch = 0.1148s	
818/5250 (epoch 7.790), train_loss = 1.50421298, grad/param norm = 8.4903e-02, time/batch = 0.1142s	
819/5250 (epoch 7.800), train_loss = 1.48615649, grad/param norm = 7.6747e-02, time/batch = 0.1150s	
820/5250 (epoch 7.810), train_loss = 1.48344021, grad/param norm = 8.7048e-02, time/batch = 0.1150s	
821/5250 (epoch 7.819), train_loss = 1.49307533, grad/param norm = 9.4238e-02, time/batch = 0.1155s	
822/5250 (epoch 7.829), train_loss = 1.49673583, grad/param norm = 9.0383e-02, time/batch = 0.1142s	
823/5250 (epoch 7.838), train_loss = 1.46950114, grad/param norm = 8.5941e-02, time/batch = 0.1145s	
824/5250 (epoch 7.848), train_loss = 1.46397337, grad/param norm = 8.5850e-02, time/batch = 0.1146s	
825/5250 (epoch 7.857), train_loss = 1.47849733, grad/param norm = 8.6613e-02, time/batch = 0.1149s	
826/5250 (epoch 7.867), train_loss = 1.46058094, grad/param norm = 8.4317e-02, time/batch = 0.1147s	
827/5250 (epoch 7.876), train_loss = 1.47649683, grad/param norm = 7.3507e-02, time/batch = 0.1148s	
828/5250 (epoch 7.886), train_loss = 1.45913323, grad/param norm = 6.2466e-02, time/batch = 0.1142s	
829/5250 (epoch 7.895), train_loss = 1.47899801, grad/param norm = 6.6373e-02, time/batch = 0.1149s	
830/5250 (epoch 7.905), train_loss = 1.48238792, grad/param norm = 7.3575e-02, time/batch = 0.1148s	
831/5250 (epoch 7.914), train_loss = 1.49003016, grad/param norm = 7.3559e-02, time/batch = 0.1154s	
832/5250 (epoch 7.924), train_loss = 1.48880146, grad/param norm = 7.5003e-02, time/batch = 0.1143s	
833/5250 (epoch 7.933), train_loss = 1.47617787, grad/param norm = 7.8130e-02, time/batch = 0.1144s	
834/5250 (epoch 7.943), train_loss = 1.51964888, grad/param norm = 1.0520e-01, time/batch = 0.1147s	
835/5250 (epoch 7.952), train_loss = 1.51917310, grad/param norm = 1.1406e-01, time/batch = 0.1150s	
836/5250 (epoch 7.962), train_loss = 1.50351030, grad/param norm = 1.1669e-01, time/batch = 0.1148s	
837/5250 (epoch 7.971), train_loss = 1.48553623, grad/param norm = 1.0889e-01, time/batch = 0.1150s	
838/5250 (epoch 7.981), train_loss = 1.50787630, grad/param norm = 8.8457e-02, time/batch = 0.1144s	
839/5250 (epoch 7.990), train_loss = 1.50709067, grad/param norm = 8.2644e-02, time/batch = 0.1151s	
840/5250 (epoch 8.000), train_loss = 1.48521513, grad/param norm = 1.0858e-01, time/batch = 0.1150s	
841/5250 (epoch 8.010), train_loss = 1.64224951, grad/param norm = 1.0953e-01, time/batch = 0.1170s	
842/5250 (epoch 8.019), train_loss = 1.46877374, grad/param norm = 8.5894e-02, time/batch = 0.1145s	
843/5250 (epoch 8.029), train_loss = 1.47606112, grad/param norm = 7.3432e-02, time/batch = 0.1146s	
844/5250 (epoch 8.038), train_loss = 1.45777848, grad/param norm = 6.7618e-02, time/batch = 0.1149s	
845/5250 (epoch 8.048), train_loss = 1.43702473, grad/param norm = 6.8073e-02, time/batch = 0.1148s	
846/5250 (epoch 8.057), train_loss = 1.44619310, grad/param norm = 6.7416e-02, time/batch = 0.1149s	
847/5250 (epoch 8.067), train_loss = 1.45218676, grad/param norm = 6.7879e-02, time/batch = 0.1151s	
848/5250 (epoch 8.076), train_loss = 1.46622596, grad/param norm = 7.6249e-02, time/batch = 0.1142s	
849/5250 (epoch 8.086), train_loss = 1.40315559, grad/param norm = 8.1957e-02, time/batch = 0.1150s	
850/5250 (epoch 8.095), train_loss = 1.44640301, grad/param norm = 8.7111e-02, time/batch = 0.1149s	
851/5250 (epoch 8.105), train_loss = 1.47484181, grad/param norm = 8.2628e-02, time/batch = 0.1162s	
852/5250 (epoch 8.114), train_loss = 1.44665484, grad/param norm = 7.5436e-02, time/batch = 0.1144s	
853/5250 (epoch 8.124), train_loss = 1.45574252, grad/param norm = 7.5531e-02, time/batch = 0.1146s	
854/5250 (epoch 8.133), train_loss = 1.45329857, grad/param norm = 8.2435e-02, time/batch = 0.1148s	
855/5250 (epoch 8.143), train_loss = 1.43017631, grad/param norm = 9.4929e-02, time/batch = 0.1149s	
856/5250 (epoch 8.152), train_loss = 1.43753187, grad/param norm = 1.1719e-01, time/batch = 0.1148s	
857/5250 (epoch 8.162), train_loss = 1.48572504, grad/param norm = 1.1078e-01, time/batch = 0.1152s	
858/5250 (epoch 8.171), train_loss = 1.48677016, grad/param norm = 9.6300e-02, time/batch = 0.1142s	
859/5250 (epoch 8.181), train_loss = 1.47422554, grad/param norm = 8.9277e-02, time/batch = 0.1152s	
860/5250 (epoch 8.190), train_loss = 1.46263735, grad/param norm = 7.6088e-02, time/batch = 0.1149s	
861/5250 (epoch 8.200), train_loss = 1.44225873, grad/param norm = 7.0714e-02, time/batch = 0.1154s	
862/5250 (epoch 8.210), train_loss = 1.45015256, grad/param norm = 7.4129e-02, time/batch = 0.1142s	
863/5250 (epoch 8.219), train_loss = 1.49518067, grad/param norm = 8.6354e-02, time/batch = 0.1146s	
864/5250 (epoch 8.229), train_loss = 1.45831556, grad/param norm = 8.1922e-02, time/batch = 0.1147s	
865/5250 (epoch 8.238), train_loss = 1.45615427, grad/param norm = 8.3788e-02, time/batch = 0.1147s	
866/5250 (epoch 8.248), train_loss = 1.45337868, grad/param norm = 8.3102e-02, time/batch = 0.1148s	
867/5250 (epoch 8.257), train_loss = 1.44499889, grad/param norm = 8.0107e-02, time/batch = 0.1147s	
868/5250 (epoch 8.267), train_loss = 1.43864222, grad/param norm = 8.0015e-02, time/batch = 0.1142s	
869/5250 (epoch 8.276), train_loss = 1.43684597, grad/param norm = 8.3110e-02, time/batch = 0.1150s	
870/5250 (epoch 8.286), train_loss = 1.41610736, grad/param norm = 8.6513e-02, time/batch = 0.1150s	
871/5250 (epoch 8.295), train_loss = 1.44671705, grad/param norm = 8.1054e-02, time/batch = 0.1161s	
872/5250 (epoch 8.305), train_loss = 1.45069898, grad/param norm = 8.1644e-02, time/batch = 0.1142s	
873/5250 (epoch 8.314), train_loss = 1.41853551, grad/param norm = 8.1086e-02, time/batch = 0.1148s	
874/5250 (epoch 8.324), train_loss = 1.44717924, grad/param norm = 7.8857e-02, time/batch = 0.1148s	
875/5250 (epoch 8.333), train_loss = 1.44286191, grad/param norm = 6.9421e-02, time/batch = 0.1148s	
876/5250 (epoch 8.343), train_loss = 1.44518732, grad/param norm = 7.0191e-02, time/batch = 0.1146s	
877/5250 (epoch 8.352), train_loss = 1.45740254, grad/param norm = 7.8518e-02, time/batch = 0.1149s	
878/5250 (epoch 8.362), train_loss = 1.46056813, grad/param norm = 8.1612e-02, time/batch = 0.1143s	
879/5250 (epoch 8.371), train_loss = 1.43045285, grad/param norm = 7.5828e-02, time/batch = 0.1152s	
880/5250 (epoch 8.381), train_loss = 1.43286289, grad/param norm = 7.5894e-02, time/batch = 0.1150s	
881/5250 (epoch 8.390), train_loss = 1.44958775, grad/param norm = 7.8699e-02, time/batch = 0.1154s	
882/5250 (epoch 8.400), train_loss = 1.43454146, grad/param norm = 7.6702e-02, time/batch = 0.1141s	
883/5250 (epoch 8.410), train_loss = 1.45660212, grad/param norm = 7.4981e-02, time/batch = 0.1147s	
884/5250 (epoch 8.419), train_loss = 1.44805808, grad/param norm = 7.8939e-02, time/batch = 0.1148s	
885/5250 (epoch 8.429), train_loss = 1.46340067, grad/param norm = 8.7897e-02, time/batch = 0.1150s	
886/5250 (epoch 8.438), train_loss = 1.48402064, grad/param norm = 9.1325e-02, time/batch = 0.1148s	
887/5250 (epoch 8.448), train_loss = 1.42965407, grad/param norm = 9.3041e-02, time/batch = 0.1149s	
888/5250 (epoch 8.457), train_loss = 1.43300621, grad/param norm = 9.7773e-02, time/batch = 0.1144s	
889/5250 (epoch 8.467), train_loss = 1.45249440, grad/param norm = 1.0885e-01, time/batch = 0.1150s	
890/5250 (epoch 8.476), train_loss = 1.46001811, grad/param norm = 1.0033e-01, time/batch = 0.1149s	
891/5250 (epoch 8.486), train_loss = 1.45623026, grad/param norm = 9.3319e-02, time/batch = 0.1152s	
892/5250 (epoch 8.495), train_loss = 1.46396410, grad/param norm = 8.5068e-02, time/batch = 0.1145s	
893/5250 (epoch 8.505), train_loss = 1.46011296, grad/param norm = 7.5697e-02, time/batch = 0.1147s	
894/5250 (epoch 8.514), train_loss = 1.44854324, grad/param norm = 6.6864e-02, time/batch = 0.1148s	
895/5250 (epoch 8.524), train_loss = 1.42071760, grad/param norm = 6.4608e-02, time/batch = 0.1148s	
896/5250 (epoch 8.533), train_loss = 1.43559876, grad/param norm = 8.1579e-02, time/batch = 0.1148s	
897/5250 (epoch 8.543), train_loss = 1.42884693, grad/param norm = 8.6061e-02, time/batch = 0.1148s	
898/5250 (epoch 8.552), train_loss = 1.44130244, grad/param norm = 8.4788e-02, time/batch = 0.1142s	
899/5250 (epoch 8.562), train_loss = 1.45562408, grad/param norm = 8.1371e-02, time/batch = 0.1151s	
900/5250 (epoch 8.571), train_loss = 1.43877661, grad/param norm = 7.1551e-02, time/batch = 0.1149s	
901/5250 (epoch 8.581), train_loss = 1.46783134, grad/param norm = 7.1997e-02, time/batch = 0.1154s	
902/5250 (epoch 8.590), train_loss = 1.44295717, grad/param norm = 7.0236e-02, time/batch = 0.1141s	
903/5250 (epoch 8.600), train_loss = 1.45544239, grad/param norm = 6.8587e-02, time/batch = 0.1147s	
904/5250 (epoch 8.610), train_loss = 1.45901462, grad/param norm = 7.0020e-02, time/batch = 0.1147s	
905/5250 (epoch 8.619), train_loss = 1.43900079, grad/param norm = 7.4489e-02, time/batch = 0.1150s	
906/5250 (epoch 8.629), train_loss = 1.45787828, grad/param norm = 8.0603e-02, time/batch = 0.1148s	
907/5250 (epoch 8.638), train_loss = 1.44568877, grad/param norm = 9.7995e-02, time/batch = 0.1151s	
908/5250 (epoch 8.648), train_loss = 1.45748821, grad/param norm = 8.8960e-02, time/batch = 0.1143s	
909/5250 (epoch 8.657), train_loss = 1.43395374, grad/param norm = 8.0619e-02, time/batch = 0.1151s	
910/5250 (epoch 8.667), train_loss = 1.45345470, grad/param norm = 8.8799e-02, time/batch = 0.1149s	
911/5250 (epoch 8.676), train_loss = 1.43915192, grad/param norm = 9.4479e-02, time/batch = 0.1153s	
912/5250 (epoch 8.686), train_loss = 1.47277914, grad/param norm = 9.2884e-02, time/batch = 0.1164s	
913/5250 (epoch 8.695), train_loss = 1.45352933, grad/param norm = 8.9461e-02, time/batch = 0.1148s	
914/5250 (epoch 8.705), train_loss = 1.42994300, grad/param norm = 8.1372e-02, time/batch = 0.1147s	
915/5250 (epoch 8.714), train_loss = 1.45274528, grad/param norm = 7.4933e-02, time/batch = 0.1148s	
916/5250 (epoch 8.724), train_loss = 1.42916272, grad/param norm = 7.5975e-02, time/batch = 0.1147s	
917/5250 (epoch 8.733), train_loss = 1.41958499, grad/param norm = 7.8791e-02, time/batch = 0.1149s	
918/5250 (epoch 8.743), train_loss = 1.41305690, grad/param norm = 7.4075e-02, time/batch = 0.1143s	
919/5250 (epoch 8.752), train_loss = 1.42979296, grad/param norm = 6.7148e-02, time/batch = 0.1150s	
920/5250 (epoch 8.762), train_loss = 1.42382845, grad/param norm = 7.7538e-02, time/batch = 0.1148s	
921/5250 (epoch 8.771), train_loss = 1.41683637, grad/param norm = 7.2936e-02, time/batch = 0.1153s	
922/5250 (epoch 8.781), train_loss = 1.43506157, grad/param norm = 6.3275e-02, time/batch = 0.1144s	
923/5250 (epoch 8.790), train_loss = 1.44276593, grad/param norm = 6.4486e-02, time/batch = 0.1146s	
924/5250 (epoch 8.800), train_loss = 1.43123414, grad/param norm = 6.9995e-02, time/batch = 0.1148s	
925/5250 (epoch 8.810), train_loss = 1.43695260, grad/param norm = 8.4436e-02, time/batch = 0.1148s	
926/5250 (epoch 8.819), train_loss = 1.45080038, grad/param norm = 8.6898e-02, time/batch = 0.1147s	
927/5250 (epoch 8.829), train_loss = 1.45026212, grad/param norm = 8.4323e-02, time/batch = 0.1149s	
928/5250 (epoch 8.838), train_loss = 1.42542188, grad/param norm = 8.3664e-02, time/batch = 0.1143s	
929/5250 (epoch 8.848), train_loss = 1.41953258, grad/param norm = 8.3841e-02, time/batch = 0.1151s	
930/5250 (epoch 8.857), train_loss = 1.43231642, grad/param norm = 8.1266e-02, time/batch = 0.1150s	
931/5250 (epoch 8.867), train_loss = 1.41762135, grad/param norm = 8.0574e-02, time/batch = 0.1155s	
932/5250 (epoch 8.876), train_loss = 1.43451272, grad/param norm = 7.6223e-02, time/batch = 0.1143s	
933/5250 (epoch 8.886), train_loss = 1.41643092, grad/param norm = 7.3912e-02, time/batch = 0.1146s	
934/5250 (epoch 8.895), train_loss = 1.44173037, grad/param norm = 8.0667e-02, time/batch = 0.1147s	
935/5250 (epoch 8.905), train_loss = 1.44684472, grad/param norm = 9.0042e-02, time/batch = 0.1150s	
936/5250 (epoch 8.914), train_loss = 1.46051919, grad/param norm = 1.0077e-01, time/batch = 0.1150s	
937/5250 (epoch 8.924), train_loss = 1.46906116, grad/param norm = 1.0549e-01, time/batch = 0.1149s	
938/5250 (epoch 8.933), train_loss = 1.44179837, grad/param norm = 9.0286e-02, time/batch = 0.1142s	
939/5250 (epoch 8.943), train_loss = 1.46773171, grad/param norm = 8.1459e-02, time/batch = 0.1151s	
940/5250 (epoch 8.952), train_loss = 1.45947073, grad/param norm = 7.4741e-02, time/batch = 0.1150s	
941/5250 (epoch 8.962), train_loss = 1.43355077, grad/param norm = 7.1519e-02, time/batch = 0.1153s	
942/5250 (epoch 8.971), train_loss = 1.42261083, grad/param norm = 7.1654e-02, time/batch = 0.1142s	
943/5250 (epoch 8.981), train_loss = 1.45626221, grad/param norm = 7.7823e-02, time/batch = 0.1147s	
944/5250 (epoch 8.990), train_loss = 1.45551445, grad/param norm = 8.3215e-02, time/batch = 0.1147s	
945/5250 (epoch 9.000), train_loss = 1.43275351, grad/param norm = 8.4089e-02, time/batch = 0.1148s	
946/5250 (epoch 9.010), train_loss = 1.57820630, grad/param norm = 8.0617e-02, time/batch = 0.1149s	
947/5250 (epoch 9.019), train_loss = 1.41276810, grad/param norm = 7.1665e-02, time/batch = 0.1149s	
948/5250 (epoch 9.029), train_loss = 1.42922351, grad/param norm = 7.1052e-02, time/batch = 0.1142s	
949/5250 (epoch 9.038), train_loss = 1.41432890, grad/param norm = 7.2246e-02, time/batch = 0.1150s	
950/5250 (epoch 9.048), train_loss = 1.39590806, grad/param norm = 7.7107e-02, time/batch = 0.1149s	
951/5250 (epoch 9.057), train_loss = 1.40526364, grad/param norm = 7.6173e-02, time/batch = 0.1153s	
952/5250 (epoch 9.067), train_loss = 1.40702997, grad/param norm = 7.3239e-02, time/batch = 0.1141s	
953/5250 (epoch 9.076), train_loss = 1.42316892, grad/param norm = 7.2947e-02, time/batch = 0.1146s	
954/5250 (epoch 9.086), train_loss = 1.35829492, grad/param norm = 7.7258e-02, time/batch = 0.1147s	
955/5250 (epoch 9.095), train_loss = 1.39986908, grad/param norm = 8.2029e-02, time/batch = 0.1147s	
956/5250 (epoch 9.105), train_loss = 1.42791146, grad/param norm = 7.6876e-02, time/batch = 0.1147s	
957/5250 (epoch 9.114), train_loss = 1.39894429, grad/param norm = 6.6985e-02, time/batch = 0.1149s	
958/5250 (epoch 9.124), train_loss = 1.41634602, grad/param norm = 7.0173e-02, time/batch = 0.1144s	
959/5250 (epoch 9.133), train_loss = 1.40983867, grad/param norm = 7.7324e-02, time/batch = 0.1148s	
960/5250 (epoch 9.143), train_loss = 1.38439343, grad/param norm = 7.5468e-02, time/batch = 0.1148s	
961/5250 (epoch 9.152), train_loss = 1.38178421, grad/param norm = 6.9151e-02, time/batch = 0.1155s	
962/5250 (epoch 9.162), train_loss = 1.42022965, grad/param norm = 6.9402e-02, time/batch = 0.1142s	
963/5250 (epoch 9.171), train_loss = 1.42281940, grad/param norm = 6.6393e-02, time/batch = 0.1145s	
964/5250 (epoch 9.181), train_loss = 1.41795855, grad/param norm = 6.6123e-02, time/batch = 0.1147s	
965/5250 (epoch 9.190), train_loss = 1.41965783, grad/param norm = 7.2472e-02, time/batch = 0.1150s	
966/5250 (epoch 9.200), train_loss = 1.40633708, grad/param norm = 8.0469e-02, time/batch = 0.1148s	
967/5250 (epoch 9.210), train_loss = 1.41566038, grad/param norm = 8.4554e-02, time/batch = 0.1148s	
968/5250 (epoch 9.219), train_loss = 1.45594623, grad/param norm = 8.9151e-02, time/batch = 0.1142s	
969/5250 (epoch 9.229), train_loss = 1.42292230, grad/param norm = 9.6920e-02, time/batch = 0.1151s	
970/5250 (epoch 9.238), train_loss = 1.42649720, grad/param norm = 9.5927e-02, time/batch = 0.1150s	
971/5250 (epoch 9.248), train_loss = 1.41832601, grad/param norm = 9.5078e-02, time/batch = 0.1153s	
972/5250 (epoch 9.257), train_loss = 1.40874240, grad/param norm = 9.1791e-02, time/batch = 0.1143s	
973/5250 (epoch 9.267), train_loss = 1.39588066, grad/param norm = 8.1374e-02, time/batch = 0.1145s	
974/5250 (epoch 9.276), train_loss = 1.38914694, grad/param norm = 7.4435e-02, time/batch = 0.1147s	
975/5250 (epoch 9.286), train_loss = 1.37106294, grad/param norm = 7.1888e-02, time/batch = 0.1151s	
976/5250 (epoch 9.295), train_loss = 1.40511729, grad/param norm = 7.3266e-02, time/batch = 0.1147s	
977/5250 (epoch 9.305), train_loss = 1.41386538, grad/param norm = 7.6158e-02, time/batch = 0.1149s	
978/5250 (epoch 9.314), train_loss = 1.37900455, grad/param norm = 7.3613e-02, time/batch = 0.1142s	
979/5250 (epoch 9.324), train_loss = 1.40534810, grad/param norm = 6.9129e-02, time/batch = 0.1150s	
980/5250 (epoch 9.333), train_loss = 1.40340544, grad/param norm = 7.3352e-02, time/batch = 0.1150s	
981/5250 (epoch 9.343), train_loss = 1.40715512, grad/param norm = 7.4448e-02, time/batch = 0.1153s	
982/5250 (epoch 9.352), train_loss = 1.41335680, grad/param norm = 7.6622e-02, time/batch = 0.1142s	
983/5250 (epoch 9.362), train_loss = 1.42408059, grad/param norm = 8.4937e-02, time/batch = 0.1161s	
984/5250 (epoch 9.371), train_loss = 1.40029642, grad/param norm = 8.8373e-02, time/batch = 0.1146s	
985/5250 (epoch 9.381), train_loss = 1.40147795, grad/param norm = 7.3194e-02, time/batch = 0.1150s	
986/5250 (epoch 9.390), train_loss = 1.40493949, grad/param norm = 7.3546e-02, time/batch = 0.1149s	
987/5250 (epoch 9.400), train_loss = 1.39204136, grad/param norm = 6.8960e-02, time/batch = 0.1150s	
988/5250 (epoch 9.410), train_loss = 1.40797909, grad/param norm = 7.1941e-02, time/batch = 0.1143s	
989/5250 (epoch 9.419), train_loss = 1.40176329, grad/param norm = 7.5883e-02, time/batch = 0.1151s	
990/5250 (epoch 9.429), train_loss = 1.41616663, grad/param norm = 7.8261e-02, time/batch = 0.1148s	
991/5250 (epoch 9.438), train_loss = 1.42824873, grad/param norm = 7.5840e-02, time/batch = 0.1155s	
992/5250 (epoch 9.448), train_loss = 1.38290095, grad/param norm = 7.2692e-02, time/batch = 0.1143s	
993/5250 (epoch 9.457), train_loss = 1.38055489, grad/param norm = 7.6178e-02, time/batch = 0.1146s	
994/5250 (epoch 9.467), train_loss = 1.40511477, grad/param norm = 8.0339e-02, time/batch = 0.1149s	
995/5250 (epoch 9.476), train_loss = 1.41064422, grad/param norm = 9.1821e-02, time/batch = 0.1148s	
996/5250 (epoch 9.486), train_loss = 1.42419908, grad/param norm = 9.5708e-02, time/batch = 0.1147s	
997/5250 (epoch 9.495), train_loss = 1.43174249, grad/param norm = 8.3793e-02, time/batch = 0.1148s	
998/5250 (epoch 9.505), train_loss = 1.43000402, grad/param norm = 8.1232e-02, time/batch = 0.1143s	
999/5250 (epoch 9.514), train_loss = 1.41558430, grad/param norm = 8.4403e-02, time/batch = 0.1150s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch9.52_1.4846.t7	
1000/5250 (epoch 9.524), train_loss = 1.39532461, grad/param norm = 7.7601e-02, time/batch = 0.1150s	
1001/5250 (epoch 9.533), train_loss = 1.57413324, grad/param norm = 8.5996e-02, time/batch = 0.1154s	
1002/5250 (epoch 9.543), train_loss = 1.39467060, grad/param norm = 8.3278e-02, time/batch = 0.1138s	
1003/5250 (epoch 9.552), train_loss = 1.39343110, grad/param norm = 7.3805e-02, time/batch = 0.1138s	
1004/5250 (epoch 9.562), train_loss = 1.40496589, grad/param norm = 7.1499e-02, time/batch = 0.1142s	
1005/5250 (epoch 9.571), train_loss = 1.40185746, grad/param norm = 7.9323e-02, time/batch = 0.1146s	
1006/5250 (epoch 9.581), train_loss = 1.43589417, grad/param norm = 8.4032e-02, time/batch = 0.1143s	
1007/5250 (epoch 9.590), train_loss = 1.40640981, grad/param norm = 7.3971e-02, time/batch = 0.1144s	
1008/5250 (epoch 9.600), train_loss = 1.41779476, grad/param norm = 6.6819e-02, time/batch = 0.1137s	
1009/5250 (epoch 9.610), train_loss = 1.41928439, grad/param norm = 6.9550e-02, time/batch = 0.1142s	
1010/5250 (epoch 9.619), train_loss = 1.40199384, grad/param norm = 7.1983e-02, time/batch = 0.1144s	
1011/5250 (epoch 9.629), train_loss = 1.41007723, grad/param norm = 7.0662e-02, time/batch = 0.1150s	
1012/5250 (epoch 9.638), train_loss = 1.39527322, grad/param norm = 7.1760e-02, time/batch = 0.1137s	
1013/5250 (epoch 9.648), train_loss = 1.40072096, grad/param norm = 7.3795e-02, time/batch = 0.1139s	
1014/5250 (epoch 9.657), train_loss = 1.38955951, grad/param norm = 6.9085e-02, time/batch = 0.1143s	
1015/5250 (epoch 9.667), train_loss = 1.40006104, grad/param norm = 6.3633e-02, time/batch = 0.1145s	
1016/5250 (epoch 9.676), train_loss = 1.38708835, grad/param norm = 6.0939e-02, time/batch = 0.1141s	
1017/5250 (epoch 9.686), train_loss = 1.42459232, grad/param norm = 7.1369e-02, time/batch = 0.1143s	
1018/5250 (epoch 9.695), train_loss = 1.41418025, grad/param norm = 7.9964e-02, time/batch = 0.1136s	
1019/5250 (epoch 9.705), train_loss = 1.39583760, grad/param norm = 7.5399e-02, time/batch = 0.1144s	
1020/5250 (epoch 9.714), train_loss = 1.42110288, grad/param norm = 8.3237e-02, time/batch = 0.1143s	
1021/5250 (epoch 9.724), train_loss = 1.38915657, grad/param norm = 6.5348e-02, time/batch = 0.1149s	
1022/5250 (epoch 9.733), train_loss = 1.36998222, grad/param norm = 5.4257e-02, time/batch = 0.1135s	
1023/5250 (epoch 9.743), train_loss = 1.37116286, grad/param norm = 6.3054e-02, time/batch = 0.1140s	
1024/5250 (epoch 9.752), train_loss = 1.39342204, grad/param norm = 6.6103e-02, time/batch = 0.1141s	
1025/5250 (epoch 9.762), train_loss = 1.38763375, grad/param norm = 7.3075e-02, time/batch = 0.1142s	
1026/5250 (epoch 9.771), train_loss = 1.38348139, grad/param norm = 7.1250e-02, time/batch = 0.1142s	
1027/5250 (epoch 9.781), train_loss = 1.40295599, grad/param norm = 7.3659e-02, time/batch = 0.1145s	
1028/5250 (epoch 9.790), train_loss = 1.41399146, grad/param norm = 8.0738e-02, time/batch = 0.1135s	
1029/5250 (epoch 9.800), train_loss = 1.40069648, grad/param norm = 8.3182e-02, time/batch = 0.1142s	
1030/5250 (epoch 9.810), train_loss = 1.39820175, grad/param norm = 7.5665e-02, time/batch = 0.1142s	
1031/5250 (epoch 9.819), train_loss = 1.40422458, grad/param norm = 7.1102e-02, time/batch = 0.1150s	
1032/5250 (epoch 9.829), train_loss = 1.40341999, grad/param norm = 6.6650e-02, time/batch = 0.1138s	
1033/5250 (epoch 9.838), train_loss = 1.37626874, grad/param norm = 6.3561e-02, time/batch = 0.1139s	
1034/5250 (epoch 9.848), train_loss = 1.37806505, grad/param norm = 7.2533e-02, time/batch = 0.1141s	
1035/5250 (epoch 9.857), train_loss = 1.39474301, grad/param norm = 7.8304e-02, time/batch = 0.1142s	
1036/5250 (epoch 9.867), train_loss = 1.38352129, grad/param norm = 7.8117e-02, time/batch = 0.1142s	
1037/5250 (epoch 9.876), train_loss = 1.39666208, grad/param norm = 8.5279e-02, time/batch = 0.1143s	
1038/5250 (epoch 9.886), train_loss = 1.38373052, grad/param norm = 8.3097e-02, time/batch = 0.1140s	
1039/5250 (epoch 9.895), train_loss = 1.41298384, grad/param norm = 8.7659e-02, time/batch = 0.1142s	
1040/5250 (epoch 9.905), train_loss = 1.41559619, grad/param norm = 8.8726e-02, time/batch = 0.1144s	
1041/5250 (epoch 9.914), train_loss = 1.42068309, grad/param norm = 8.7460e-02, time/batch = 0.1151s	
1042/5250 (epoch 9.924), train_loss = 1.41397102, grad/param norm = 7.8638e-02, time/batch = 0.1138s	
1043/5250 (epoch 9.933), train_loss = 1.39311990, grad/param norm = 6.7445e-02, time/batch = 0.1141s	
1044/5250 (epoch 9.943), train_loss = 1.42222524, grad/param norm = 6.4403e-02, time/batch = 0.1143s	
1045/5250 (epoch 9.952), train_loss = 1.41931798, grad/param norm = 7.5664e-02, time/batch = 0.1143s	
1046/5250 (epoch 9.962), train_loss = 1.40693520, grad/param norm = 8.0798e-02, time/batch = 0.1143s	
1047/5250 (epoch 9.971), train_loss = 1.39470602, grad/param norm = 8.3599e-02, time/batch = 0.1143s	
1048/5250 (epoch 9.981), train_loss = 1.43097454, grad/param norm = 8.0971e-02, time/batch = 0.1137s	
1049/5250 (epoch 9.990), train_loss = 1.42109500, grad/param norm = 8.4577e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00194	
1050/5250 (epoch 10.000), train_loss = 1.39603884, grad/param norm = 8.8612e-02, time/batch = 0.1143s	
1051/5250 (epoch 10.010), train_loss = 1.54765902, grad/param norm = 9.0007e-02, time/batch = 0.1159s	
1052/5250 (epoch 10.019), train_loss = 1.37836913, grad/param norm = 7.5991e-02, time/batch = 0.1135s	
1053/5250 (epoch 10.029), train_loss = 1.39381250, grad/param norm = 6.6578e-02, time/batch = 0.1139s	
1054/5250 (epoch 10.038), train_loss = 1.37894406, grad/param norm = 6.9211e-02, time/batch = 0.1141s	
1055/5250 (epoch 10.048), train_loss = 1.35712721, grad/param norm = 6.9800e-02, time/batch = 0.1144s	
1056/5250 (epoch 10.057), train_loss = 1.36499060, grad/param norm = 6.5921e-02, time/batch = 0.1149s	
1057/5250 (epoch 10.067), train_loss = 1.36859789, grad/param norm = 6.6398e-02, time/batch = 0.1145s	
1058/5250 (epoch 10.076), train_loss = 1.38750055, grad/param norm = 6.9505e-02, time/batch = 0.1138s	
1059/5250 (epoch 10.086), train_loss = 1.32192506, grad/param norm = 6.4808e-02, time/batch = 0.1144s	
1060/5250 (epoch 10.095), train_loss = 1.35486581, grad/param norm = 6.5832e-02, time/batch = 0.1143s	
1061/5250 (epoch 10.105), train_loss = 1.38620862, grad/param norm = 6.6938e-02, time/batch = 0.1158s	
1062/5250 (epoch 10.114), train_loss = 1.35967030, grad/param norm = 6.1653e-02, time/batch = 0.1137s	
1063/5250 (epoch 10.124), train_loss = 1.37160578, grad/param norm = 6.2264e-02, time/batch = 0.1140s	
1064/5250 (epoch 10.133), train_loss = 1.37291399, grad/param norm = 6.8215e-02, time/batch = 0.1141s	
1065/5250 (epoch 10.143), train_loss = 1.34682565, grad/param norm = 7.5520e-02, time/batch = 0.1143s	
1066/5250 (epoch 10.152), train_loss = 1.34700346, grad/param norm = 7.3747e-02, time/batch = 0.1142s	
1067/5250 (epoch 10.162), train_loss = 1.38701612, grad/param norm = 7.6681e-02, time/batch = 0.1140s	
1068/5250 (epoch 10.171), train_loss = 1.38740141, grad/param norm = 7.1595e-02, time/batch = 0.1138s	
1069/5250 (epoch 10.181), train_loss = 1.37923720, grad/param norm = 6.5640e-02, time/batch = 0.1143s	
1070/5250 (epoch 10.190), train_loss = 1.37858786, grad/param norm = 6.4888e-02, time/batch = 0.1145s	
1071/5250 (epoch 10.200), train_loss = 1.36356298, grad/param norm = 6.9999e-02, time/batch = 0.1151s	
1072/5250 (epoch 10.210), train_loss = 1.37593806, grad/param norm = 7.8344e-02, time/batch = 0.1135s	
1073/5250 (epoch 10.219), train_loss = 1.41470135, grad/param norm = 8.0114e-02, time/batch = 0.1140s	
1074/5250 (epoch 10.229), train_loss = 1.37470861, grad/param norm = 7.2487e-02, time/batch = 0.1139s	
1075/5250 (epoch 10.238), train_loss = 1.37673599, grad/param norm = 6.7075e-02, time/batch = 0.1145s	
1076/5250 (epoch 10.248), train_loss = 1.36444209, grad/param norm = 6.2364e-02, time/batch = 0.1142s	
1077/5250 (epoch 10.257), train_loss = 1.35762361, grad/param norm = 5.8591e-02, time/batch = 0.1142s	
1078/5250 (epoch 10.267), train_loss = 1.34961958, grad/param norm = 5.9210e-02, time/batch = 0.1136s	
1079/5250 (epoch 10.276), train_loss = 1.34870620, grad/param norm = 6.0161e-02, time/batch = 0.1141s	
1080/5250 (epoch 10.286), train_loss = 1.33175152, grad/param norm = 6.0986e-02, time/batch = 0.1144s	
1081/5250 (epoch 10.295), train_loss = 1.36597016, grad/param norm = 6.4986e-02, time/batch = 0.1150s	
1082/5250 (epoch 10.305), train_loss = 1.37370682, grad/param norm = 6.8519e-02, time/batch = 0.1138s	
1083/5250 (epoch 10.314), train_loss = 1.34448898, grad/param norm = 6.9931e-02, time/batch = 0.1139s	
1084/5250 (epoch 10.324), train_loss = 1.37268222, grad/param norm = 6.5438e-02, time/batch = 0.1140s	
1085/5250 (epoch 10.333), train_loss = 1.36557789, grad/param norm = 6.5743e-02, time/batch = 0.1144s	
1086/5250 (epoch 10.343), train_loss = 1.36654829, grad/param norm = 6.7073e-02, time/batch = 0.1142s	
1087/5250 (epoch 10.352), train_loss = 1.37466554, grad/param norm = 7.2650e-02, time/batch = 0.1142s	
1088/5250 (epoch 10.362), train_loss = 1.38141180, grad/param norm = 8.0101e-02, time/batch = 0.1138s	
1089/5250 (epoch 10.371), train_loss = 1.35919542, grad/param norm = 8.1133e-02, time/batch = 0.1143s	
1090/5250 (epoch 10.381), train_loss = 1.35720566, grad/param norm = 7.8473e-02, time/batch = 0.1144s	
1091/5250 (epoch 10.390), train_loss = 1.37073945, grad/param norm = 7.6994e-02, time/batch = 0.1149s	
1092/5250 (epoch 10.400), train_loss = 1.35646962, grad/param norm = 6.5306e-02, time/batch = 0.1137s	
1093/5250 (epoch 10.410), train_loss = 1.37133344, grad/param norm = 6.4430e-02, time/batch = 0.1140s	
1094/5250 (epoch 10.419), train_loss = 1.36354708, grad/param norm = 6.6058e-02, time/batch = 0.1142s	
1095/5250 (epoch 10.429), train_loss = 1.37513829, grad/param norm = 6.8996e-02, time/batch = 0.1141s	
1096/5250 (epoch 10.438), train_loss = 1.38977099, grad/param norm = 6.4028e-02, time/batch = 0.1143s	
1097/5250 (epoch 10.448), train_loss = 1.34142160, grad/param norm = 6.1611e-02, time/batch = 0.1142s	
1098/5250 (epoch 10.457), train_loss = 1.34394307, grad/param norm = 6.7378e-02, time/batch = 0.1136s	
1099/5250 (epoch 10.467), train_loss = 1.36736501, grad/param norm = 7.7808e-02, time/batch = 0.1143s	
1100/5250 (epoch 10.476), train_loss = 1.36697779, grad/param norm = 7.5964e-02, time/batch = 0.1140s	
1101/5250 (epoch 10.486), train_loss = 1.38020315, grad/param norm = 7.9197e-02, time/batch = 0.1149s	
1102/5250 (epoch 10.495), train_loss = 1.38124217, grad/param norm = 7.1894e-02, time/batch = 0.1138s	
1103/5250 (epoch 10.505), train_loss = 1.38048054, grad/param norm = 6.6134e-02, time/batch = 0.1139s	
1104/5250 (epoch 10.514), train_loss = 1.37166976, grad/param norm = 6.6409e-02, time/batch = 0.1141s	
1105/5250 (epoch 10.524), train_loss = 1.34985306, grad/param norm = 6.3173e-02, time/batch = 0.1141s	
1106/5250 (epoch 10.533), train_loss = 1.36404645, grad/param norm = 6.8677e-02, time/batch = 0.1142s	
1107/5250 (epoch 10.543), train_loss = 1.35771060, grad/param norm = 7.4887e-02, time/batch = 0.1141s	
1108/5250 (epoch 10.552), train_loss = 1.36820111, grad/param norm = 7.8676e-02, time/batch = 0.1137s	
1109/5250 (epoch 10.562), train_loss = 1.37921891, grad/param norm = 7.9812e-02, time/batch = 0.1143s	
1110/5250 (epoch 10.571), train_loss = 1.36961576, grad/param norm = 7.1622e-02, time/batch = 0.1141s	
1111/5250 (epoch 10.581), train_loss = 1.39247444, grad/param norm = 6.3143e-02, time/batch = 0.1156s	
1112/5250 (epoch 10.590), train_loss = 1.36267395, grad/param norm = 5.5831e-02, time/batch = 0.1137s	
1113/5250 (epoch 10.600), train_loss = 1.37898261, grad/param norm = 5.7636e-02, time/batch = 0.1142s	
1114/5250 (epoch 10.610), train_loss = 1.38573697, grad/param norm = 6.0620e-02, time/batch = 0.1141s	
1115/5250 (epoch 10.619), train_loss = 1.36793453, grad/param norm = 6.3850e-02, time/batch = 0.1143s	
1116/5250 (epoch 10.629), train_loss = 1.37802594, grad/param norm = 6.5010e-02, time/batch = 0.1142s	
1117/5250 (epoch 10.638), train_loss = 1.37030852, grad/param norm = 7.6747e-02, time/batch = 0.1141s	
1118/5250 (epoch 10.648), train_loss = 1.37433185, grad/param norm = 6.8618e-02, time/batch = 0.1137s	
1119/5250 (epoch 10.657), train_loss = 1.36138760, grad/param norm = 6.4980e-02, time/batch = 0.1143s	
1120/5250 (epoch 10.667), train_loss = 1.37328133, grad/param norm = 6.9595e-02, time/batch = 0.1142s	
1121/5250 (epoch 10.676), train_loss = 1.36099510, grad/param norm = 7.1325e-02, time/batch = 0.1148s	
1122/5250 (epoch 10.686), train_loss = 1.39236422, grad/param norm = 7.2519e-02, time/batch = 0.1136s	
1123/5250 (epoch 10.695), train_loss = 1.37662165, grad/param norm = 7.3420e-02, time/batch = 0.1139s	
1124/5250 (epoch 10.705), train_loss = 1.36041101, grad/param norm = 6.8880e-02, time/batch = 0.1140s	
1125/5250 (epoch 10.714), train_loss = 1.38098323, grad/param norm = 6.7809e-02, time/batch = 0.1144s	
1126/5250 (epoch 10.724), train_loss = 1.35717731, grad/param norm = 6.9897e-02, time/batch = 0.1141s	
1127/5250 (epoch 10.733), train_loss = 1.34807442, grad/param norm = 7.4155e-02, time/batch = 0.1140s	
1128/5250 (epoch 10.743), train_loss = 1.34098821, grad/param norm = 6.8636e-02, time/batch = 0.1136s	
1129/5250 (epoch 10.752), train_loss = 1.36006208, grad/param norm = 6.5720e-02, time/batch = 0.1143s	
1130/5250 (epoch 10.762), train_loss = 1.35273216, grad/param norm = 7.4495e-02, time/batch = 0.1142s	
1131/5250 (epoch 10.771), train_loss = 1.34720676, grad/param norm = 7.1602e-02, time/batch = 0.1149s	
1132/5250 (epoch 10.781), train_loss = 1.36578206, grad/param norm = 6.8871e-02, time/batch = 0.1136s	
1133/5250 (epoch 10.790), train_loss = 1.37814427, grad/param norm = 7.7308e-02, time/batch = 0.1140s	
1134/5250 (epoch 10.800), train_loss = 1.36151169, grad/param norm = 7.7669e-02, time/batch = 0.1142s	
1135/5250 (epoch 10.810), train_loss = 1.36762533, grad/param norm = 7.6620e-02, time/batch = 0.1144s	
1136/5250 (epoch 10.819), train_loss = 1.37105467, grad/param norm = 7.2606e-02, time/batch = 0.1143s	
1137/5250 (epoch 10.829), train_loss = 1.37200182, grad/param norm = 6.8826e-02, time/batch = 0.1142s	
1138/5250 (epoch 10.838), train_loss = 1.34303883, grad/param norm = 6.9654e-02, time/batch = 0.1137s	
1139/5250 (epoch 10.848), train_loss = 1.34451675, grad/param norm = 6.9832e-02, time/batch = 0.1144s	
1140/5250 (epoch 10.857), train_loss = 1.35275884, grad/param norm = 6.9756e-02, time/batch = 0.1142s	
1141/5250 (epoch 10.867), train_loss = 1.34625127, grad/param norm = 7.0632e-02, time/batch = 0.1151s	
1142/5250 (epoch 10.876), train_loss = 1.35794509, grad/param norm = 7.3492e-02, time/batch = 0.1134s	
1143/5250 (epoch 10.886), train_loss = 1.34198043, grad/param norm = 6.6047e-02, time/batch = 0.1138s	
1144/5250 (epoch 10.895), train_loss = 1.37023933, grad/param norm = 6.3736e-02, time/batch = 0.1142s	
1145/5250 (epoch 10.905), train_loss = 1.36436399, grad/param norm = 5.6690e-02, time/batch = 0.1142s	
1146/5250 (epoch 10.914), train_loss = 1.36875445, grad/param norm = 5.5762e-02, time/batch = 0.1142s	
1147/5250 (epoch 10.924), train_loss = 1.36981535, grad/param norm = 6.0825e-02, time/batch = 0.1142s	
1148/5250 (epoch 10.933), train_loss = 1.35743245, grad/param norm = 6.6798e-02, time/batch = 0.1138s	
1149/5250 (epoch 10.943), train_loss = 1.39043730, grad/param norm = 6.5735e-02, time/batch = 0.1142s	
1150/5250 (epoch 10.952), train_loss = 1.38924575, grad/param norm = 7.6192e-02, time/batch = 0.1143s	
1151/5250 (epoch 10.962), train_loss = 1.36757392, grad/param norm = 7.3579e-02, time/batch = 0.1148s	
1152/5250 (epoch 10.971), train_loss = 1.35940212, grad/param norm = 7.2333e-02, time/batch = 0.1137s	
1153/5250 (epoch 10.981), train_loss = 1.39815688, grad/param norm = 8.5664e-02, time/batch = 0.1141s	
1154/5250 (epoch 10.990), train_loss = 1.39490492, grad/param norm = 9.0786e-02, time/batch = 0.1140s	
decayed learning rate by a factor 0.97 to 0.0018818	
1155/5250 (epoch 11.000), train_loss = 1.36630103, grad/param norm = 8.2668e-02, time/batch = 0.1144s	
1156/5250 (epoch 11.010), train_loss = 1.52165478, grad/param norm = 7.9798e-02, time/batch = 0.1142s	
1157/5250 (epoch 11.019), train_loss = 1.34486229, grad/param norm = 6.8883e-02, time/batch = 0.1142s	
1158/5250 (epoch 11.029), train_loss = 1.36165353, grad/param norm = 6.7915e-02, time/batch = 0.1135s	
1159/5250 (epoch 11.038), train_loss = 1.34419611, grad/param norm = 6.4518e-02, time/batch = 0.1143s	
1160/5250 (epoch 11.048), train_loss = 1.32140511, grad/param norm = 6.0284e-02, time/batch = 0.1142s	
1161/5250 (epoch 11.057), train_loss = 1.32912957, grad/param norm = 5.6952e-02, time/batch = 0.1151s	
1162/5250 (epoch 11.067), train_loss = 1.33384770, grad/param norm = 5.7022e-02, time/batch = 0.1138s	
1163/5250 (epoch 11.076), train_loss = 1.35180756, grad/param norm = 6.1175e-02, time/batch = 0.1142s	
1164/5250 (epoch 11.086), train_loss = 1.29123850, grad/param norm = 6.0539e-02, time/batch = 0.1144s	
1165/5250 (epoch 11.095), train_loss = 1.32164442, grad/param norm = 6.3675e-02, time/batch = 0.1144s	
1166/5250 (epoch 11.105), train_loss = 1.35398181, grad/param norm = 6.1940e-02, time/batch = 0.1142s	
1167/5250 (epoch 11.114), train_loss = 1.32848698, grad/param norm = 5.8214e-02, time/batch = 0.1145s	
1168/5250 (epoch 11.124), train_loss = 1.33945405, grad/param norm = 6.2355e-02, time/batch = 0.1136s	
1169/5250 (epoch 11.133), train_loss = 1.33918098, grad/param norm = 6.3114e-02, time/batch = 0.1142s	
1170/5250 (epoch 11.143), train_loss = 1.30935004, grad/param norm = 6.3020e-02, time/batch = 0.1142s	
1171/5250 (epoch 11.152), train_loss = 1.31419787, grad/param norm = 6.7204e-02, time/batch = 0.1147s	
1172/5250 (epoch 11.162), train_loss = 1.35708545, grad/param norm = 7.1058e-02, time/batch = 0.1138s	
1173/5250 (epoch 11.171), train_loss = 1.35486302, grad/param norm = 6.7916e-02, time/batch = 0.1139s	
1174/5250 (epoch 11.181), train_loss = 1.34605839, grad/param norm = 6.3840e-02, time/batch = 0.1142s	
1175/5250 (epoch 11.190), train_loss = 1.34706833, grad/param norm = 5.9877e-02, time/batch = 0.1143s	
1176/5250 (epoch 11.200), train_loss = 1.32669479, grad/param norm = 5.8674e-02, time/batch = 0.1142s	
1177/5250 (epoch 11.210), train_loss = 1.33391518, grad/param norm = 5.9680e-02, time/batch = 0.1144s	
1178/5250 (epoch 11.219), train_loss = 1.37395869, grad/param norm = 6.1716e-02, time/batch = 0.1136s	
1179/5250 (epoch 11.229), train_loss = 1.33740339, grad/param norm = 5.9278e-02, time/batch = 0.1142s	
1180/5250 (epoch 11.238), train_loss = 1.34394420, grad/param norm = 5.9610e-02, time/batch = 0.1143s	
1181/5250 (epoch 11.248), train_loss = 1.33771442, grad/param norm = 6.9177e-02, time/batch = 0.1150s	
1182/5250 (epoch 11.257), train_loss = 1.34423088, grad/param norm = 8.3099e-02, time/batch = 0.1137s	
1183/5250 (epoch 11.267), train_loss = 1.33443941, grad/param norm = 7.1042e-02, time/batch = 0.1140s	
1184/5250 (epoch 11.276), train_loss = 1.32206054, grad/param norm = 5.9932e-02, time/batch = 0.1142s	
1185/5250 (epoch 11.286), train_loss = 1.30285748, grad/param norm = 5.6499e-02, time/batch = 0.1143s	
1186/5250 (epoch 11.295), train_loss = 1.33391148, grad/param norm = 5.9106e-02, time/batch = 0.1141s	
1187/5250 (epoch 11.305), train_loss = 1.33758782, grad/param norm = 6.2054e-02, time/batch = 0.1141s	
1188/5250 (epoch 11.314), train_loss = 1.31485498, grad/param norm = 6.8023e-02, time/batch = 0.1137s	
1189/5250 (epoch 11.324), train_loss = 1.34126601, grad/param norm = 6.9304e-02, time/batch = 0.1143s	
1190/5250 (epoch 11.333), train_loss = 1.34297559, grad/param norm = 6.4752e-02, time/batch = 0.1144s	
1191/5250 (epoch 11.343), train_loss = 1.33686266, grad/param norm = 6.0221e-02, time/batch = 0.1150s	
1192/5250 (epoch 11.352), train_loss = 1.34598418, grad/param norm = 6.7124e-02, time/batch = 0.1139s	
1193/5250 (epoch 11.362), train_loss = 1.34502463, grad/param norm = 6.5183e-02, time/batch = 0.1140s	
1194/5250 (epoch 11.371), train_loss = 1.31869312, grad/param norm = 6.2202e-02, time/batch = 0.1139s	
1195/5250 (epoch 11.381), train_loss = 1.32053582, grad/param norm = 6.6634e-02, time/batch = 0.1144s	
1196/5250 (epoch 11.390), train_loss = 1.33382524, grad/param norm = 6.3732e-02, time/batch = 0.1143s	
1197/5250 (epoch 11.400), train_loss = 1.32390749, grad/param norm = 5.7686e-02, time/batch = 0.1142s	
1198/5250 (epoch 11.410), train_loss = 1.33815651, grad/param norm = 6.5474e-02, time/batch = 0.1136s	
1199/5250 (epoch 11.419), train_loss = 1.33798938, grad/param norm = 6.7574e-02, time/batch = 0.1144s	
1200/5250 (epoch 11.429), train_loss = 1.34783978, grad/param norm = 6.8952e-02, time/batch = 0.1143s	
1201/5250 (epoch 11.438), train_loss = 1.36038946, grad/param norm = 7.2928e-02, time/batch = 0.1148s	
1202/5250 (epoch 11.448), train_loss = 1.32209048, grad/param norm = 7.9055e-02, time/batch = 0.1139s	
1203/5250 (epoch 11.457), train_loss = 1.32032481, grad/param norm = 7.3844e-02, time/batch = 0.1140s	
1204/5250 (epoch 11.467), train_loss = 1.33937483, grad/param norm = 7.2766e-02, time/batch = 0.1140s	
1205/5250 (epoch 11.476), train_loss = 1.33433144, grad/param norm = 6.5877e-02, time/batch = 0.1144s	
1206/5250 (epoch 11.486), train_loss = 1.34555655, grad/param norm = 6.7837e-02, time/batch = 0.1141s	
1207/5250 (epoch 11.495), train_loss = 1.35125002, grad/param norm = 6.0416e-02, time/batch = 0.1144s	
1208/5250 (epoch 11.505), train_loss = 1.34947046, grad/param norm = 6.0452e-02, time/batch = 0.1138s	
1209/5250 (epoch 11.514), train_loss = 1.34232949, grad/param norm = 6.3430e-02, time/batch = 0.1144s	
1210/5250 (epoch 11.524), train_loss = 1.32366062, grad/param norm = 5.7255e-02, time/batch = 0.1141s	
1211/5250 (epoch 11.533), train_loss = 1.33197653, grad/param norm = 5.8098e-02, time/batch = 0.1150s	
1212/5250 (epoch 11.543), train_loss = 1.31892112, grad/param norm = 5.6393e-02, time/batch = 0.1136s	
1213/5250 (epoch 11.552), train_loss = 1.32400422, grad/param norm = 5.7135e-02, time/batch = 0.1139s	
1214/5250 (epoch 11.562), train_loss = 1.33947614, grad/param norm = 6.8663e-02, time/batch = 0.1143s	
1215/5250 (epoch 11.571), train_loss = 1.34659890, grad/param norm = 7.7212e-02, time/batch = 0.1141s	
1216/5250 (epoch 11.581), train_loss = 1.37821916, grad/param norm = 8.6216e-02, time/batch = 0.1141s	
1217/5250 (epoch 11.590), train_loss = 1.35025983, grad/param norm = 7.1987e-02, time/batch = 0.1143s	
1218/5250 (epoch 11.600), train_loss = 1.35388563, grad/param norm = 6.1026e-02, time/batch = 0.1137s	
1219/5250 (epoch 11.610), train_loss = 1.35680539, grad/param norm = 5.9316e-02, time/batch = 0.1143s	
1220/5250 (epoch 11.619), train_loss = 1.33806892, grad/param norm = 5.9051e-02, time/batch = 0.1144s	
1221/5250 (epoch 11.629), train_loss = 1.34226822, grad/param norm = 5.7021e-02, time/batch = 0.1149s	
1222/5250 (epoch 11.638), train_loss = 1.33073830, grad/param norm = 5.8761e-02, time/batch = 0.1136s	
1223/5250 (epoch 11.648), train_loss = 1.33254657, grad/param norm = 5.4920e-02, time/batch = 0.1139s	
1224/5250 (epoch 11.657), train_loss = 1.32605872, grad/param norm = 5.8564e-02, time/batch = 0.1142s	
1225/5250 (epoch 11.667), train_loss = 1.34086376, grad/param norm = 6.7864e-02, time/batch = 0.1142s	
1226/5250 (epoch 11.676), train_loss = 1.33436754, grad/param norm = 7.6676e-02, time/batch = 0.1142s	
1227/5250 (epoch 11.686), train_loss = 1.36536546, grad/param norm = 7.2221e-02, time/batch = 0.1142s	
1228/5250 (epoch 11.695), train_loss = 1.34404744, grad/param norm = 6.4158e-02, time/batch = 0.1137s	
1229/5250 (epoch 11.705), train_loss = 1.32611326, grad/param norm = 6.0607e-02, time/batch = 0.1143s	
1230/5250 (epoch 11.714), train_loss = 1.34875151, grad/param norm = 6.1595e-02, time/batch = 0.1144s	
1231/5250 (epoch 11.724), train_loss = 1.32192204, grad/param norm = 6.1143e-02, time/batch = 0.1147s	
1232/5250 (epoch 11.733), train_loss = 1.31179435, grad/param norm = 6.1677e-02, time/batch = 0.1138s	
1233/5250 (epoch 11.743), train_loss = 1.31259014, grad/param norm = 6.9496e-02, time/batch = 0.1140s	
1234/5250 (epoch 11.752), train_loss = 1.33645513, grad/param norm = 8.2942e-02, time/batch = 0.1142s	
1235/5250 (epoch 11.762), train_loss = 1.33693518, grad/param norm = 8.7315e-02, time/batch = 0.1142s	
1236/5250 (epoch 11.771), train_loss = 1.32982433, grad/param norm = 8.0802e-02, time/batch = 0.1143s	
1237/5250 (epoch 11.781), train_loss = 1.34192648, grad/param norm = 6.9318e-02, time/batch = 0.1142s	
1238/5250 (epoch 11.790), train_loss = 1.34307218, grad/param norm = 6.1757e-02, time/batch = 0.1135s	
1239/5250 (epoch 11.800), train_loss = 1.31817003, grad/param norm = 5.4313e-02, time/batch = 0.1144s	
1240/5250 (epoch 11.810), train_loss = 1.32414406, grad/param norm = 5.3763e-02, time/batch = 0.1142s	
1241/5250 (epoch 11.819), train_loss = 1.33217491, grad/param norm = 5.4433e-02, time/batch = 0.1151s	
1242/5250 (epoch 11.829), train_loss = 1.33493709, grad/param norm = 5.3966e-02, time/batch = 0.1137s	
1243/5250 (epoch 11.838), train_loss = 1.30457638, grad/param norm = 5.1179e-02, time/batch = 0.1140s	
1244/5250 (epoch 11.848), train_loss = 1.30708887, grad/param norm = 5.5230e-02, time/batch = 0.1143s	
1245/5250 (epoch 11.857), train_loss = 1.32089355, grad/param norm = 5.9834e-02, time/batch = 0.1142s	
1246/5250 (epoch 11.867), train_loss = 1.31821664, grad/param norm = 7.1405e-02, time/batch = 0.1143s	
1247/5250 (epoch 11.876), train_loss = 1.33173396, grad/param norm = 6.7789e-02, time/batch = 0.1142s	
1248/5250 (epoch 11.886), train_loss = 1.31336120, grad/param norm = 6.4249e-02, time/batch = 0.1136s	
1249/5250 (epoch 11.895), train_loss = 1.35162042, grad/param norm = 7.4667e-02, time/batch = 0.1145s	
1250/5250 (epoch 11.905), train_loss = 1.34378545, grad/param norm = 7.3426e-02, time/batch = 0.1143s	
1251/5250 (epoch 11.914), train_loss = 1.34961049, grad/param norm = 6.9133e-02, time/batch = 0.1151s	
1252/5250 (epoch 11.924), train_loss = 1.34809373, grad/param norm = 7.0974e-02, time/batch = 0.1138s	
1253/5250 (epoch 11.933), train_loss = 1.33242303, grad/param norm = 6.6977e-02, time/batch = 0.1139s	
1254/5250 (epoch 11.943), train_loss = 1.35876414, grad/param norm = 6.8959e-02, time/batch = 0.1143s	
1255/5250 (epoch 11.952), train_loss = 1.35593233, grad/param norm = 6.3259e-02, time/batch = 0.1143s	
1256/5250 (epoch 11.962), train_loss = 1.33371928, grad/param norm = 6.4054e-02, time/batch = 0.1143s	
1257/5250 (epoch 11.971), train_loss = 1.33500631, grad/param norm = 6.9332e-02, time/batch = 0.1141s	
1258/5250 (epoch 11.981), train_loss = 1.36191281, grad/param norm = 6.8779e-02, time/batch = 0.1137s	
1259/5250 (epoch 11.990), train_loss = 1.35397049, grad/param norm = 6.4223e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.001825346	
1260/5250 (epoch 12.000), train_loss = 1.34163580, grad/param norm = 7.2465e-02, time/batch = 0.1142s	
1261/5250 (epoch 12.010), train_loss = 1.50700117, grad/param norm = 7.9159e-02, time/batch = 0.1148s	
1262/5250 (epoch 12.019), train_loss = 1.31682944, grad/param norm = 6.2193e-02, time/batch = 0.1137s	
1263/5250 (epoch 12.029), train_loss = 1.32934148, grad/param norm = 5.4446e-02, time/batch = 0.1139s	
1264/5250 (epoch 12.038), train_loss = 1.30937921, grad/param norm = 5.6147e-02, time/batch = 0.1141s	
1265/5250 (epoch 12.048), train_loss = 1.29293188, grad/param norm = 5.6438e-02, time/batch = 0.1142s	
1266/5250 (epoch 12.057), train_loss = 1.29545714, grad/param norm = 5.2411e-02, time/batch = 0.1142s	
1267/5250 (epoch 12.067), train_loss = 1.30534100, grad/param norm = 5.1704e-02, time/batch = 0.1142s	
1268/5250 (epoch 12.076), train_loss = 1.32229652, grad/param norm = 5.6473e-02, time/batch = 0.1136s	
1269/5250 (epoch 12.086), train_loss = 1.26433411, grad/param norm = 5.5162e-02, time/batch = 0.1143s	
1270/5250 (epoch 12.095), train_loss = 1.29098359, grad/param norm = 5.6492e-02, time/batch = 0.1142s	
1271/5250 (epoch 12.105), train_loss = 1.32430133, grad/param norm = 5.7728e-02, time/batch = 0.1150s	
1272/5250 (epoch 12.114), train_loss = 1.30435782, grad/param norm = 5.9260e-02, time/batch = 0.1137s	
1273/5250 (epoch 12.124), train_loss = 1.31645549, grad/param norm = 6.3481e-02, time/batch = 0.1140s	
1274/5250 (epoch 12.133), train_loss = 1.31995722, grad/param norm = 6.8190e-02, time/batch = 0.1142s	
1275/5250 (epoch 12.143), train_loss = 1.28861083, grad/param norm = 6.4234e-02, time/batch = 0.1143s	
1276/5250 (epoch 12.152), train_loss = 1.28789141, grad/param norm = 6.8091e-02, time/batch = 0.1142s	
1277/5250 (epoch 12.162), train_loss = 1.32845588, grad/param norm = 6.0571e-02, time/batch = 0.1142s	
1278/5250 (epoch 12.171), train_loss = 1.32354453, grad/param norm = 5.9883e-02, time/batch = 0.1137s	
1279/5250 (epoch 12.181), train_loss = 1.31715203, grad/param norm = 6.2138e-02, time/batch = 0.1144s	
1280/5250 (epoch 12.190), train_loss = 1.32373451, grad/param norm = 6.1741e-02, time/batch = 0.1144s	
1281/5250 (epoch 12.200), train_loss = 1.30144097, grad/param norm = 6.0429e-02, time/batch = 0.1150s	
1282/5250 (epoch 12.210), train_loss = 1.30624587, grad/param norm = 6.3062e-02, time/batch = 0.1136s	
1283/5250 (epoch 12.219), train_loss = 1.35105893, grad/param norm = 6.9328e-02, time/batch = 0.1140s	
1284/5250 (epoch 12.229), train_loss = 1.32002522, grad/param norm = 7.6568e-02, time/batch = 0.1140s	
1285/5250 (epoch 12.238), train_loss = 1.32774289, grad/param norm = 7.7197e-02, time/batch = 0.1143s	
1286/5250 (epoch 12.248), train_loss = 1.31428016, grad/param norm = 7.1068e-02, time/batch = 0.1143s	
1287/5250 (epoch 12.257), train_loss = 1.30276282, grad/param norm = 5.9299e-02, time/batch = 0.1143s	
1288/5250 (epoch 12.267), train_loss = 1.29509411, grad/param norm = 5.5218e-02, time/batch = 0.1135s	
1289/5250 (epoch 12.276), train_loss = 1.29136810, grad/param norm = 5.4595e-02, time/batch = 0.1142s	
1290/5250 (epoch 12.286), train_loss = 1.27550857, grad/param norm = 5.4581e-02, time/batch = 0.1144s	
1291/5250 (epoch 12.295), train_loss = 1.30626319, grad/param norm = 5.4113e-02, time/batch = 0.1155s	
1292/5250 (epoch 12.305), train_loss = 1.30601007, grad/param norm = 5.4939e-02, time/batch = 0.1138s	
1293/5250 (epoch 12.314), train_loss = 1.28044936, grad/param norm = 5.2685e-02, time/batch = 0.1141s	
1294/5250 (epoch 12.324), train_loss = 1.30569696, grad/param norm = 5.4216e-02, time/batch = 0.1141s	
1295/5250 (epoch 12.333), train_loss = 1.31206904, grad/param norm = 6.3489e-02, time/batch = 0.1141s	
1296/5250 (epoch 12.343), train_loss = 1.31497639, grad/param norm = 6.7892e-02, time/batch = 0.1143s	
1297/5250 (epoch 12.352), train_loss = 1.32358426, grad/param norm = 6.7089e-02, time/batch = 0.1142s	
1298/5250 (epoch 12.362), train_loss = 1.31810826, grad/param norm = 6.6553e-02, time/batch = 0.1134s	
1299/5250 (epoch 12.371), train_loss = 1.29732152, grad/param norm = 6.3088e-02, time/batch = 0.1143s	
1300/5250 (epoch 12.381), train_loss = 1.29789233, grad/param norm = 6.8036e-02, time/batch = 0.1143s	
1301/5250 (epoch 12.390), train_loss = 1.31465521, grad/param norm = 6.6928e-02, time/batch = 0.1157s	
1302/5250 (epoch 12.400), train_loss = 1.30268468, grad/param norm = 6.5705e-02, time/batch = 0.1136s	
1303/5250 (epoch 12.410), train_loss = 1.31607860, grad/param norm = 6.7903e-02, time/batch = 0.1138s	
1304/5250 (epoch 12.419), train_loss = 1.31076953, grad/param norm = 7.1182e-02, time/batch = 0.1141s	
1305/5250 (epoch 12.429), train_loss = 1.31727700, grad/param norm = 6.6938e-02, time/batch = 0.1143s	
1306/5250 (epoch 12.438), train_loss = 1.32817561, grad/param norm = 6.2482e-02, time/batch = 0.1143s	
1307/5250 (epoch 12.448), train_loss = 1.28782266, grad/param norm = 6.1019e-02, time/batch = 0.1142s	
1308/5250 (epoch 12.457), train_loss = 1.29057062, grad/param norm = 6.2689e-02, time/batch = 0.1137s	
1309/5250 (epoch 12.467), train_loss = 1.31053410, grad/param norm = 6.3584e-02, time/batch = 0.1143s	
1310/5250 (epoch 12.476), train_loss = 1.30589139, grad/param norm = 6.6835e-02, time/batch = 0.1143s	
1311/5250 (epoch 12.486), train_loss = 1.32466065, grad/param norm = 6.9639e-02, time/batch = 0.1148s	
1312/5250 (epoch 12.495), train_loss = 1.32451874, grad/param norm = 6.3993e-02, time/batch = 0.1137s	
1313/5250 (epoch 12.505), train_loss = 1.32597150, grad/param norm = 6.0654e-02, time/batch = 0.1139s	
1314/5250 (epoch 12.514), train_loss = 1.31461498, grad/param norm = 6.1898e-02, time/batch = 0.1142s	
1315/5250 (epoch 12.524), train_loss = 1.30185627, grad/param norm = 6.0032e-02, time/batch = 0.1144s	
1316/5250 (epoch 12.533), train_loss = 1.31190158, grad/param norm = 6.5879e-02, time/batch = 0.1142s	
1317/5250 (epoch 12.543), train_loss = 1.30052286, grad/param norm = 6.3904e-02, time/batch = 0.1142s	
1318/5250 (epoch 12.552), train_loss = 1.30080863, grad/param norm = 5.8715e-02, time/batch = 0.1136s	
1319/5250 (epoch 12.562), train_loss = 1.30771348, grad/param norm = 6.0521e-02, time/batch = 0.1144s	
1320/5250 (epoch 12.571), train_loss = 1.31264164, grad/param norm = 6.6411e-02, time/batch = 0.1142s	
1321/5250 (epoch 12.581), train_loss = 1.34129636, grad/param norm = 7.2456e-02, time/batch = 0.1148s	
1322/5250 (epoch 12.590), train_loss = 1.31819669, grad/param norm = 6.3011e-02, time/batch = 0.1136s	
1323/5250 (epoch 12.600), train_loss = 1.32745408, grad/param norm = 5.6268e-02, time/batch = 0.1140s	
1324/5250 (epoch 12.610), train_loss = 1.33316726, grad/param norm = 5.9238e-02, time/batch = 0.1141s	
1325/5250 (epoch 12.619), train_loss = 1.31517069, grad/param norm = 5.8286e-02, time/batch = 0.1143s	
1326/5250 (epoch 12.629), train_loss = 1.31486783, grad/param norm = 5.7275e-02, time/batch = 0.1142s	
1327/5250 (epoch 12.638), train_loss = 1.30558424, grad/param norm = 6.0611e-02, time/batch = 0.1141s	
1328/5250 (epoch 12.648), train_loss = 1.31023721, grad/param norm = 5.9780e-02, time/batch = 0.1139s	
1329/5250 (epoch 12.657), train_loss = 1.30210620, grad/param norm = 5.6376e-02, time/batch = 0.1143s	
1330/5250 (epoch 12.667), train_loss = 1.30970691, grad/param norm = 5.8461e-02, time/batch = 0.1143s	
1331/5250 (epoch 12.676), train_loss = 1.30128440, grad/param norm = 5.7124e-02, time/batch = 0.1157s	
1332/5250 (epoch 12.686), train_loss = 1.32969847, grad/param norm = 5.6321e-02, time/batch = 0.1135s	
1333/5250 (epoch 12.695), train_loss = 1.31311529, grad/param norm = 5.4663e-02, time/batch = 0.1141s	
1334/5250 (epoch 12.705), train_loss = 1.29906562, grad/param norm = 5.8106e-02, time/batch = 0.1142s	
1335/5250 (epoch 12.714), train_loss = 1.32841078, grad/param norm = 7.2231e-02, time/batch = 0.1142s	
1336/5250 (epoch 12.724), train_loss = 1.30436675, grad/param norm = 6.0973e-02, time/batch = 0.1142s	
1337/5250 (epoch 12.733), train_loss = 1.28497508, grad/param norm = 5.3534e-02, time/batch = 0.1143s	
1338/5250 (epoch 12.743), train_loss = 1.28281290, grad/param norm = 5.4532e-02, time/batch = 0.1137s	
1339/5250 (epoch 12.752), train_loss = 1.29694180, grad/param norm = 5.4119e-02, time/batch = 0.1142s	
1340/5250 (epoch 12.762), train_loss = 1.29083688, grad/param norm = 5.3987e-02, time/batch = 0.1141s	
1341/5250 (epoch 12.771), train_loss = 1.29067122, grad/param norm = 5.9801e-02, time/batch = 0.1150s	
1342/5250 (epoch 12.781), train_loss = 1.31604033, grad/param norm = 6.4861e-02, time/batch = 0.1137s	
1343/5250 (epoch 12.790), train_loss = 1.32292343, grad/param norm = 7.1030e-02, time/batch = 0.1140s	
1344/5250 (epoch 12.800), train_loss = 1.29996162, grad/param norm = 6.0615e-02, time/batch = 0.1141s	
1345/5250 (epoch 12.810), train_loss = 1.30364735, grad/param norm = 6.0116e-02, time/batch = 0.1145s	
1346/5250 (epoch 12.819), train_loss = 1.31182440, grad/param norm = 5.9988e-02, time/batch = 0.1141s	
1347/5250 (epoch 12.829), train_loss = 1.31203164, grad/param norm = 5.9331e-02, time/batch = 0.1144s	
1348/5250 (epoch 12.838), train_loss = 1.28272768, grad/param norm = 6.1454e-02, time/batch = 0.1138s	
1349/5250 (epoch 12.848), train_loss = 1.28869421, grad/param norm = 6.3267e-02, time/batch = 0.1141s	
1350/5250 (epoch 12.857), train_loss = 1.30062509, grad/param norm = 6.2154e-02, time/batch = 0.1142s	
1351/5250 (epoch 12.867), train_loss = 1.29435891, grad/param norm = 6.4661e-02, time/batch = 0.1150s	
1352/5250 (epoch 12.876), train_loss = 1.30208591, grad/param norm = 6.5617e-02, time/batch = 0.1137s	
1353/5250 (epoch 12.886), train_loss = 1.28840307, grad/param norm = 5.7766e-02, time/batch = 0.1140s	
1354/5250 (epoch 12.895), train_loss = 1.31831840, grad/param norm = 5.9139e-02, time/batch = 0.1141s	
1355/5250 (epoch 12.905), train_loss = 1.31259841, grad/param norm = 5.7544e-02, time/batch = 0.1142s	
1356/5250 (epoch 12.914), train_loss = 1.31991745, grad/param norm = 6.1240e-02, time/batch = 0.1141s	
1357/5250 (epoch 12.924), train_loss = 1.31838435, grad/param norm = 6.3227e-02, time/batch = 0.1141s	
1358/5250 (epoch 12.933), train_loss = 1.30370492, grad/param norm = 6.1087e-02, time/batch = 0.1137s	
1359/5250 (epoch 12.943), train_loss = 1.33239507, grad/param norm = 6.5050e-02, time/batch = 0.1142s	
1360/5250 (epoch 12.952), train_loss = 1.33827332, grad/param norm = 7.4501e-02, time/batch = 0.1142s	
1361/5250 (epoch 12.962), train_loss = 1.31966287, grad/param norm = 7.3075e-02, time/batch = 0.1148s	
1362/5250 (epoch 12.971), train_loss = 1.31346333, grad/param norm = 7.0905e-02, time/batch = 0.1137s	
1363/5250 (epoch 12.981), train_loss = 1.33820019, grad/param norm = 6.8031e-02, time/batch = 0.1140s	
1364/5250 (epoch 12.990), train_loss = 1.32545978, grad/param norm = 6.4402e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00177058562	
1365/5250 (epoch 13.000), train_loss = 1.31035830, grad/param norm = 6.6482e-02, time/batch = 0.1142s	
1366/5250 (epoch 13.010), train_loss = 1.47350706, grad/param norm = 7.1886e-02, time/batch = 0.1141s	
1367/5250 (epoch 13.019), train_loss = 1.28818030, grad/param norm = 6.1263e-02, time/batch = 0.1142s	
1368/5250 (epoch 13.029), train_loss = 1.30652119, grad/param norm = 5.8456e-02, time/batch = 0.1138s	
1369/5250 (epoch 13.038), train_loss = 1.28845876, grad/param norm = 5.9332e-02, time/batch = 0.1144s	
1370/5250 (epoch 13.048), train_loss = 1.26692714, grad/param norm = 5.4979e-02, time/batch = 0.1142s	
1371/5250 (epoch 13.057), train_loss = 1.27528782, grad/param norm = 5.4382e-02, time/batch = 0.1148s	
1372/5250 (epoch 13.067), train_loss = 1.28648164, grad/param norm = 6.0763e-02, time/batch = 0.1137s	
1373/5250 (epoch 13.076), train_loss = 1.30340708, grad/param norm = 5.8262e-02, time/batch = 0.1140s	
1374/5250 (epoch 13.086), train_loss = 1.24351614, grad/param norm = 5.5901e-02, time/batch = 0.1154s	
1375/5250 (epoch 13.095), train_loss = 1.27370416, grad/param norm = 6.0782e-02, time/batch = 0.1141s	
1376/5250 (epoch 13.105), train_loss = 1.30275583, grad/param norm = 6.2676e-02, time/batch = 0.1144s	
1377/5250 (epoch 13.114), train_loss = 1.28327946, grad/param norm = 5.9069e-02, time/batch = 0.1144s	
1378/5250 (epoch 13.124), train_loss = 1.28908749, grad/param norm = 5.7959e-02, time/batch = 0.1137s	
1379/5250 (epoch 13.133), train_loss = 1.28900651, grad/param norm = 6.5152e-02, time/batch = 0.1142s	
1380/5250 (epoch 13.143), train_loss = 1.26422249, grad/param norm = 6.5509e-02, time/batch = 0.1144s	
1381/5250 (epoch 13.152), train_loss = 1.26353281, grad/param norm = 6.4413e-02, time/batch = 0.1162s	
1382/5250 (epoch 13.162), train_loss = 1.30494675, grad/param norm = 6.2935e-02, time/batch = 0.1137s	
1383/5250 (epoch 13.171), train_loss = 1.29919490, grad/param norm = 6.1041e-02, time/batch = 0.1140s	
1384/5250 (epoch 13.181), train_loss = 1.29064144, grad/param norm = 5.7777e-02, time/batch = 0.1143s	
1385/5250 (epoch 13.190), train_loss = 1.29693887, grad/param norm = 5.6325e-02, time/batch = 0.1143s	
1386/5250 (epoch 13.200), train_loss = 1.27926007, grad/param norm = 5.8036e-02, time/batch = 0.1142s	
1387/5250 (epoch 13.210), train_loss = 1.28376199, grad/param norm = 6.2474e-02, time/batch = 0.1143s	
1388/5250 (epoch 13.219), train_loss = 1.32716880, grad/param norm = 6.4770e-02, time/batch = 0.1136s	
1389/5250 (epoch 13.229), train_loss = 1.29029166, grad/param norm = 6.3369e-02, time/batch = 0.1144s	
1390/5250 (epoch 13.238), train_loss = 1.29698609, grad/param norm = 6.1827e-02, time/batch = 0.1142s	
1391/5250 (epoch 13.248), train_loss = 1.28128362, grad/param norm = 5.8327e-02, time/batch = 0.1150s	
1392/5250 (epoch 13.257), train_loss = 1.28062103, grad/param norm = 5.9991e-02, time/batch = 0.1136s	
1393/5250 (epoch 13.267), train_loss = 1.27361232, grad/param norm = 5.5820e-02, time/batch = 0.1139s	
1394/5250 (epoch 13.276), train_loss = 1.26768549, grad/param norm = 5.0844e-02, time/batch = 0.1141s	
1395/5250 (epoch 13.286), train_loss = 1.25183249, grad/param norm = 5.0156e-02, time/batch = 0.1143s	
1396/5250 (epoch 13.295), train_loss = 1.28014455, grad/param norm = 5.2445e-02, time/batch = 0.1142s	
1397/5250 (epoch 13.305), train_loss = 1.27898585, grad/param norm = 5.2504e-02, time/batch = 0.1141s	
1398/5250 (epoch 13.314), train_loss = 1.25973675, grad/param norm = 5.4597e-02, time/batch = 0.1135s	
1399/5250 (epoch 13.324), train_loss = 1.28466495, grad/param norm = 5.7725e-02, time/batch = 0.1143s	
1400/5250 (epoch 13.333), train_loss = 1.28579445, grad/param norm = 5.6330e-02, time/batch = 0.1143s	
1401/5250 (epoch 13.343), train_loss = 1.28319121, grad/param norm = 5.5136e-02, time/batch = 0.1148s	
1402/5250 (epoch 13.352), train_loss = 1.29452306, grad/param norm = 6.1280e-02, time/batch = 0.1136s	
1403/5250 (epoch 13.362), train_loss = 1.29321857, grad/param norm = 6.5641e-02, time/batch = 0.1140s	
1404/5250 (epoch 13.371), train_loss = 1.27143860, grad/param norm = 6.3733e-02, time/batch = 0.1144s	
1405/5250 (epoch 13.381), train_loss = 1.27506995, grad/param norm = 6.0309e-02, time/batch = 0.1142s	
1406/5250 (epoch 13.390), train_loss = 1.28489093, grad/param norm = 5.9992e-02, time/batch = 0.1143s	
1407/5250 (epoch 13.400), train_loss = 1.27856326, grad/param norm = 6.0685e-02, time/batch = 0.1142s	
1408/5250 (epoch 13.410), train_loss = 1.28727740, grad/param norm = 5.9564e-02, time/batch = 0.1137s	
1409/5250 (epoch 13.419), train_loss = 1.28324582, grad/param norm = 6.5758e-02, time/batch = 0.1142s	
1410/5250 (epoch 13.429), train_loss = 1.29909395, grad/param norm = 6.8904e-02, time/batch = 0.1143s	
1411/5250 (epoch 13.438), train_loss = 1.31188443, grad/param norm = 7.2063e-02, time/batch = 0.1150s	
1412/5250 (epoch 13.448), train_loss = 1.27506720, grad/param norm = 6.7894e-02, time/batch = 0.1136s	
1413/5250 (epoch 13.457), train_loss = 1.26648829, grad/param norm = 6.1852e-02, time/batch = 0.1139s	
1414/5250 (epoch 13.467), train_loss = 1.28147848, grad/param norm = 5.9924e-02, time/batch = 0.1140s	
1415/5250 (epoch 13.476), train_loss = 1.27739290, grad/param norm = 5.5025e-02, time/batch = 0.1142s	
1416/5250 (epoch 13.486), train_loss = 1.29441959, grad/param norm = 6.0084e-02, time/batch = 0.1140s	
1417/5250 (epoch 13.495), train_loss = 1.29955239, grad/param norm = 5.9491e-02, time/batch = 0.1143s	
1418/5250 (epoch 13.505), train_loss = 1.30251689, grad/param norm = 6.2945e-02, time/batch = 0.1135s	
1419/5250 (epoch 13.514), train_loss = 1.29426968, grad/param norm = 6.6979e-02, time/batch = 0.1142s	
1420/5250 (epoch 13.524), train_loss = 1.28151382, grad/param norm = 6.0596e-02, time/batch = 0.1142s	
1421/5250 (epoch 13.533), train_loss = 1.28795988, grad/param norm = 5.8099e-02, time/batch = 0.1147s	
1422/5250 (epoch 13.543), train_loss = 1.27756718, grad/param norm = 6.1949e-02, time/batch = 0.1137s	
1423/5250 (epoch 13.552), train_loss = 1.28564979, grad/param norm = 6.4690e-02, time/batch = 0.1139s	
1424/5250 (epoch 13.562), train_loss = 1.29590900, grad/param norm = 7.1508e-02, time/batch = 0.1140s	
1425/5250 (epoch 13.571), train_loss = 1.29663193, grad/param norm = 6.8091e-02, time/batch = 0.1142s	
1426/5250 (epoch 13.581), train_loss = 1.31491282, grad/param norm = 6.5493e-02, time/batch = 0.1140s	
1427/5250 (epoch 13.590), train_loss = 1.29310125, grad/param norm = 6.0417e-02, time/batch = 0.1141s	
1428/5250 (epoch 13.600), train_loss = 1.30657888, grad/param norm = 5.9579e-02, time/batch = 0.1136s	
1429/5250 (epoch 13.610), train_loss = 1.30686760, grad/param norm = 5.8271e-02, time/batch = 0.1141s	
1430/5250 (epoch 13.619), train_loss = 1.29196801, grad/param norm = 5.5321e-02, time/batch = 0.1143s	
1431/5250 (epoch 13.629), train_loss = 1.29105089, grad/param norm = 5.4833e-02, time/batch = 0.1149s	
1432/5250 (epoch 13.638), train_loss = 1.28075532, grad/param norm = 5.4035e-02, time/batch = 0.1138s	
1433/5250 (epoch 13.648), train_loss = 1.28745142, grad/param norm = 5.4410e-02, time/batch = 0.1140s	
1434/5250 (epoch 13.657), train_loss = 1.28348006, grad/param norm = 5.8516e-02, time/batch = 0.1140s	
1435/5250 (epoch 13.667), train_loss = 1.29052576, grad/param norm = 6.3338e-02, time/batch = 0.1142s	
1436/5250 (epoch 13.676), train_loss = 1.28326983, grad/param norm = 6.1920e-02, time/batch = 0.1142s	
1437/5250 (epoch 13.686), train_loss = 1.30995709, grad/param norm = 5.8214e-02, time/batch = 0.1144s	
1438/5250 (epoch 13.695), train_loss = 1.29679289, grad/param norm = 6.2818e-02, time/batch = 0.1138s	
1439/5250 (epoch 13.705), train_loss = 1.28671863, grad/param norm = 6.6897e-02, time/batch = 0.1144s	
1440/5250 (epoch 13.714), train_loss = 1.30618852, grad/param norm = 6.3594e-02, time/batch = 0.1142s	
1441/5250 (epoch 13.724), train_loss = 1.27582531, grad/param norm = 5.4165e-02, time/batch = 0.1149s	
1442/5250 (epoch 13.733), train_loss = 1.26028827, grad/param norm = 5.4623e-02, time/batch = 0.1138s	
1443/5250 (epoch 13.743), train_loss = 1.25922187, grad/param norm = 5.2913e-02, time/batch = 0.1140s	
1444/5250 (epoch 13.752), train_loss = 1.27617691, grad/param norm = 5.5316e-02, time/batch = 0.1141s	
1445/5250 (epoch 13.762), train_loss = 1.27169415, grad/param norm = 6.2659e-02, time/batch = 0.1143s	
1446/5250 (epoch 13.771), train_loss = 1.27196358, grad/param norm = 6.4089e-02, time/batch = 0.1140s	
1447/5250 (epoch 13.781), train_loss = 1.28928329, grad/param norm = 6.0553e-02, time/batch = 0.1144s	
1448/5250 (epoch 13.790), train_loss = 1.29346184, grad/param norm = 5.9834e-02, time/batch = 0.1135s	
1449/5250 (epoch 13.800), train_loss = 1.27175653, grad/param norm = 6.1595e-02, time/batch = 0.1143s	
1450/5250 (epoch 13.810), train_loss = 1.28455391, grad/param norm = 6.7678e-02, time/batch = 0.1143s	
1451/5250 (epoch 13.819), train_loss = 1.29572914, grad/param norm = 7.2584e-02, time/batch = 0.1150s	
1452/5250 (epoch 13.829), train_loss = 1.30258812, grad/param norm = 6.8225e-02, time/batch = 0.1138s	
1453/5250 (epoch 13.838), train_loss = 1.26438969, grad/param norm = 6.3751e-02, time/batch = 0.1140s	
1454/5250 (epoch 13.848), train_loss = 1.26906449, grad/param norm = 7.0784e-02, time/batch = 0.1142s	
1455/5250 (epoch 13.857), train_loss = 1.28371723, grad/param norm = 7.6067e-02, time/batch = 0.1143s	
1456/5250 (epoch 13.867), train_loss = 1.27657856, grad/param norm = 8.0440e-02, time/batch = 0.1139s	
1457/5250 (epoch 13.876), train_loss = 1.28058433, grad/param norm = 6.2553e-02, time/batch = 0.1143s	
1458/5250 (epoch 13.886), train_loss = 1.26469710, grad/param norm = 5.5037e-02, time/batch = 0.1137s	
1459/5250 (epoch 13.895), train_loss = 1.29844704, grad/param norm = 5.7861e-02, time/batch = 0.1143s	
1460/5250 (epoch 13.905), train_loss = 1.28868626, grad/param norm = 5.5807e-02, time/batch = 0.1143s	
1461/5250 (epoch 13.914), train_loss = 1.29453513, grad/param norm = 5.8100e-02, time/batch = 0.1149s	
1462/5250 (epoch 13.924), train_loss = 1.29440286, grad/param norm = 5.9381e-02, time/batch = 0.1137s	
1463/5250 (epoch 13.933), train_loss = 1.27766234, grad/param norm = 5.8014e-02, time/batch = 0.1140s	
1464/5250 (epoch 13.943), train_loss = 1.30647179, grad/param norm = 6.0256e-02, time/batch = 0.1140s	
1465/5250 (epoch 13.952), train_loss = 1.30601819, grad/param norm = 6.2534e-02, time/batch = 0.1143s	
1466/5250 (epoch 13.962), train_loss = 1.28472683, grad/param norm = 5.7207e-02, time/batch = 0.1141s	
1467/5250 (epoch 13.971), train_loss = 1.28721210, grad/param norm = 5.6555e-02, time/batch = 0.1143s	
1468/5250 (epoch 13.981), train_loss = 1.31216299, grad/param norm = 6.4300e-02, time/batch = 0.1137s	
1469/5250 (epoch 13.990), train_loss = 1.30743071, grad/param norm = 6.7737e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
1470/5250 (epoch 14.000), train_loss = 1.29059926, grad/param norm = 6.3095e-02, time/batch = 0.1143s	
1471/5250 (epoch 14.010), train_loss = 1.45204740, grad/param norm = 6.5241e-02, time/batch = 0.1150s	
1472/5250 (epoch 14.019), train_loss = 1.26630769, grad/param norm = 5.8750e-02, time/batch = 0.1138s	
1473/5250 (epoch 14.029), train_loss = 1.28558110, grad/param norm = 5.8670e-02, time/batch = 0.1141s	
1474/5250 (epoch 14.038), train_loss = 1.26531726, grad/param norm = 5.6939e-02, time/batch = 0.1140s	
1475/5250 (epoch 14.048), train_loss = 1.24236857, grad/param norm = 5.3701e-02, time/batch = 0.1153s	
1476/5250 (epoch 14.057), train_loss = 1.24822543, grad/param norm = 4.9175e-02, time/batch = 0.1142s	
1477/5250 (epoch 14.067), train_loss = 1.25947184, grad/param norm = 4.9886e-02, time/batch = 0.1143s	
1478/5250 (epoch 14.076), train_loss = 1.27592090, grad/param norm = 5.4231e-02, time/batch = 0.1136s	
1479/5250 (epoch 14.086), train_loss = 1.22240638, grad/param norm = 5.6465e-02, time/batch = 0.1143s	
1480/5250 (epoch 14.095), train_loss = 1.24747516, grad/param norm = 5.7625e-02, time/batch = 0.1142s	
1481/5250 (epoch 14.105), train_loss = 1.27812645, grad/param norm = 5.6124e-02, time/batch = 0.1155s	
1482/5250 (epoch 14.114), train_loss = 1.25826296, grad/param norm = 5.3485e-02, time/batch = 0.1136s	
1483/5250 (epoch 14.124), train_loss = 1.26563721, grad/param norm = 5.6520e-02, time/batch = 0.1140s	
1484/5250 (epoch 14.133), train_loss = 1.26428320, grad/param norm = 6.0267e-02, time/batch = 0.1141s	
1485/5250 (epoch 14.143), train_loss = 1.23508379, grad/param norm = 5.6036e-02, time/batch = 0.1146s	
1486/5250 (epoch 14.152), train_loss = 1.23837892, grad/param norm = 5.6346e-02, time/batch = 0.1142s	
1487/5250 (epoch 14.162), train_loss = 1.28205278, grad/param norm = 5.8735e-02, time/batch = 0.1142s	
1488/5250 (epoch 14.171), train_loss = 1.27417415, grad/param norm = 5.8451e-02, time/batch = 0.1137s	
1489/5250 (epoch 14.181), train_loss = 1.26957744, grad/param norm = 5.7598e-02, time/batch = 0.1144s	
1490/5250 (epoch 14.190), train_loss = 1.27744142, grad/param norm = 5.9162e-02, time/batch = 0.1144s	
1491/5250 (epoch 14.200), train_loss = 1.25847066, grad/param norm = 5.9237e-02, time/batch = 0.1149s	
1492/5250 (epoch 14.210), train_loss = 1.25787202, grad/param norm = 5.6251e-02, time/batch = 0.1137s	
1493/5250 (epoch 14.219), train_loss = 1.29956770, grad/param norm = 5.7032e-02, time/batch = 0.1141s	
1494/5250 (epoch 14.229), train_loss = 1.26549797, grad/param norm = 5.6329e-02, time/batch = 0.1142s	
1495/5250 (epoch 14.238), train_loss = 1.27539858, grad/param norm = 6.3758e-02, time/batch = 0.1142s	
1496/5250 (epoch 14.248), train_loss = 1.26856541, grad/param norm = 6.3333e-02, time/batch = 0.1142s	
1497/5250 (epoch 14.257), train_loss = 1.26598681, grad/param norm = 6.6006e-02, time/batch = 0.1140s	
1498/5250 (epoch 14.267), train_loss = 1.25614989, grad/param norm = 5.7543e-02, time/batch = 0.1137s	
1499/5250 (epoch 14.276), train_loss = 1.24802719, grad/param norm = 5.3285e-02, time/batch = 0.1143s	
1500/5250 (epoch 14.286), train_loss = 1.23430981, grad/param norm = 5.4781e-02, time/batch = 0.1142s	
1501/5250 (epoch 14.295), train_loss = 1.26147278, grad/param norm = 5.5336e-02, time/batch = 0.1149s	
1502/5250 (epoch 14.305), train_loss = 1.26088298, grad/param norm = 5.7791e-02, time/batch = 0.1138s	
1503/5250 (epoch 14.314), train_loss = 1.24399279, grad/param norm = 5.9430e-02, time/batch = 0.1141s	
1504/5250 (epoch 14.324), train_loss = 1.26609555, grad/param norm = 6.0801e-02, time/batch = 0.1142s	
1505/5250 (epoch 14.333), train_loss = 1.26571731, grad/param norm = 5.6702e-02, time/batch = 0.1142s	
1506/5250 (epoch 14.343), train_loss = 1.26224225, grad/param norm = 5.7330e-02, time/batch = 0.1142s	
1507/5250 (epoch 14.352), train_loss = 1.27321250, grad/param norm = 5.9811e-02, time/batch = 0.1142s	
1508/5250 (epoch 14.362), train_loss = 1.26703373, grad/param norm = 5.8921e-02, time/batch = 0.1136s	
1509/5250 (epoch 14.371), train_loss = 1.24724713, grad/param norm = 5.4076e-02, time/batch = 0.1143s	
1510/5250 (epoch 14.381), train_loss = 1.24793196, grad/param norm = 5.4769e-02, time/batch = 0.1143s	
1511/5250 (epoch 14.390), train_loss = 1.26180275, grad/param norm = 5.5795e-02, time/batch = 0.1148s	
1512/5250 (epoch 14.400), train_loss = 1.25767378, grad/param norm = 5.9950e-02, time/batch = 0.1138s	
1513/5250 (epoch 14.410), train_loss = 1.27429127, grad/param norm = 7.6669e-02, time/batch = 0.1139s	
1514/5250 (epoch 14.419), train_loss = 1.27758682, grad/param norm = 7.8182e-02, time/batch = 0.1143s	
1515/5250 (epoch 14.429), train_loss = 1.27746589, grad/param norm = 6.3969e-02, time/batch = 0.1143s	
1516/5250 (epoch 14.438), train_loss = 1.28026708, grad/param norm = 5.4553e-02, time/batch = 0.1143s	
1517/5250 (epoch 14.448), train_loss = 1.24164958, grad/param norm = 5.1455e-02, time/batch = 0.1141s	
1518/5250 (epoch 14.457), train_loss = 1.24366694, grad/param norm = 5.4487e-02, time/batch = 0.1136s	
1519/5250 (epoch 14.467), train_loss = 1.26068560, grad/param norm = 5.6514e-02, time/batch = 0.1143s	
1520/5250 (epoch 14.476), train_loss = 1.25653687, grad/param norm = 5.6040e-02, time/batch = 0.1144s	
1521/5250 (epoch 14.486), train_loss = 1.27366002, grad/param norm = 5.7085e-02, time/batch = 0.1148s	
1522/5250 (epoch 14.495), train_loss = 1.27594445, grad/param norm = 5.3975e-02, time/batch = 0.1136s	
1523/5250 (epoch 14.505), train_loss = 1.27881026, grad/param norm = 5.5957e-02, time/batch = 0.1140s	
1524/5250 (epoch 14.514), train_loss = 1.26968104, grad/param norm = 6.0764e-02, time/batch = 0.1142s	
1525/5250 (epoch 14.524), train_loss = 1.26302189, grad/param norm = 5.4106e-02, time/batch = 0.1143s	
1526/5250 (epoch 14.533), train_loss = 1.26806230, grad/param norm = 5.9733e-02, time/batch = 0.1142s	
1527/5250 (epoch 14.543), train_loss = 1.25670539, grad/param norm = 6.1669e-02, time/batch = 0.1142s	
1528/5250 (epoch 14.552), train_loss = 1.26175629, grad/param norm = 6.0950e-02, time/batch = 0.1137s	
1529/5250 (epoch 14.562), train_loss = 1.26818505, grad/param norm = 6.2032e-02, time/batch = 0.1141s	
1530/5250 (epoch 14.571), train_loss = 1.26990643, grad/param norm = 6.1989e-02, time/batch = 0.1142s	
1531/5250 (epoch 14.581), train_loss = 1.29146647, grad/param norm = 6.2153e-02, time/batch = 0.1147s	
1532/5250 (epoch 14.590), train_loss = 1.27107293, grad/param norm = 6.0850e-02, time/batch = 0.1135s	
1533/5250 (epoch 14.600), train_loss = 1.29111206, grad/param norm = 6.0314e-02, time/batch = 0.1140s	
1534/5250 (epoch 14.610), train_loss = 1.29289897, grad/param norm = 6.6721e-02, time/batch = 0.1143s	
1535/5250 (epoch 14.619), train_loss = 1.28037068, grad/param norm = 6.1544e-02, time/batch = 0.1144s	
1536/5250 (epoch 14.629), train_loss = 1.27035688, grad/param norm = 5.3038e-02, time/batch = 0.1142s	
1537/5250 (epoch 14.638), train_loss = 1.25937598, grad/param norm = 5.2728e-02, time/batch = 0.1142s	
1538/5250 (epoch 14.648), train_loss = 1.27058724, grad/param norm = 5.4772e-02, time/batch = 0.1137s	
1539/5250 (epoch 14.657), train_loss = 1.26177114, grad/param norm = 5.4653e-02, time/batch = 0.1142s	
1540/5250 (epoch 14.667), train_loss = 1.26739696, grad/param norm = 5.9318e-02, time/batch = 0.1143s	
1541/5250 (epoch 14.676), train_loss = 1.26210851, grad/param norm = 6.0697e-02, time/batch = 0.1147s	
1542/5250 (epoch 14.686), train_loss = 1.28847908, grad/param norm = 5.8046e-02, time/batch = 0.1137s	
1543/5250 (epoch 14.695), train_loss = 1.27187394, grad/param norm = 6.0976e-02, time/batch = 0.1140s	
1544/5250 (epoch 14.705), train_loss = 1.26336617, grad/param norm = 6.5582e-02, time/batch = 0.1143s	
1545/5250 (epoch 14.714), train_loss = 1.28523713, grad/param norm = 6.0564e-02, time/batch = 0.1141s	
1546/5250 (epoch 14.724), train_loss = 1.25891635, grad/param norm = 5.4989e-02, time/batch = 0.1150s	
1547/5250 (epoch 14.733), train_loss = 1.24594258, grad/param norm = 5.9645e-02, time/batch = 0.1142s	
1548/5250 (epoch 14.743), train_loss = 1.24306805, grad/param norm = 5.5354e-02, time/batch = 0.1136s	
1549/5250 (epoch 14.752), train_loss = 1.25843003, grad/param norm = 6.0871e-02, time/batch = 0.1144s	
1550/5250 (epoch 14.762), train_loss = 1.25433942, grad/param norm = 6.4276e-02, time/batch = 0.1141s	
1551/5250 (epoch 14.771), train_loss = 1.25219704, grad/param norm = 6.9619e-02, time/batch = 0.1156s	
1552/5250 (epoch 14.781), train_loss = 1.26838193, grad/param norm = 5.9182e-02, time/batch = 0.1137s	
1553/5250 (epoch 14.790), train_loss = 1.27282234, grad/param norm = 5.5573e-02, time/batch = 0.1140s	
1554/5250 (epoch 14.800), train_loss = 1.24950623, grad/param norm = 5.5989e-02, time/batch = 0.1141s	
1555/5250 (epoch 14.810), train_loss = 1.26174386, grad/param norm = 5.8271e-02, time/batch = 0.1142s	
1556/5250 (epoch 14.819), train_loss = 1.26643905, grad/param norm = 5.4721e-02, time/batch = 0.1142s	
1557/5250 (epoch 14.829), train_loss = 1.27043750, grad/param norm = 5.1301e-02, time/batch = 0.1141s	
1558/5250 (epoch 14.838), train_loss = 1.24109676, grad/param norm = 5.6847e-02, time/batch = 0.1137s	
1559/5250 (epoch 14.848), train_loss = 1.24756678, grad/param norm = 6.7843e-02, time/batch = 0.1141s	
1560/5250 (epoch 14.857), train_loss = 1.26302643, grad/param norm = 5.9419e-02, time/batch = 0.1143s	
1561/5250 (epoch 14.867), train_loss = 1.24778216, grad/param norm = 5.3123e-02, time/batch = 0.1150s	
1562/5250 (epoch 14.876), train_loss = 1.24908744, grad/param norm = 5.8120e-02, time/batch = 0.1137s	
1563/5250 (epoch 14.886), train_loss = 1.24655148, grad/param norm = 6.1752e-02, time/batch = 0.1142s	
1564/5250 (epoch 14.895), train_loss = 1.28363486, grad/param norm = 6.7656e-02, time/batch = 0.1141s	
1565/5250 (epoch 14.905), train_loss = 1.27294502, grad/param norm = 6.5068e-02, time/batch = 0.1141s	
1566/5250 (epoch 14.914), train_loss = 1.27925003, grad/param norm = 6.2911e-02, time/batch = 0.1143s	
1567/5250 (epoch 14.924), train_loss = 1.27503725, grad/param norm = 5.9955e-02, time/batch = 0.1144s	
1568/5250 (epoch 14.933), train_loss = 1.25970134, grad/param norm = 6.0241e-02, time/batch = 0.1137s	
1569/5250 (epoch 14.943), train_loss = 1.28991776, grad/param norm = 6.5131e-02, time/batch = 0.1144s	
1570/5250 (epoch 14.952), train_loss = 1.28846013, grad/param norm = 6.0473e-02, time/batch = 0.1143s	
1571/5250 (epoch 14.962), train_loss = 1.26517527, grad/param norm = 5.7421e-02, time/batch = 0.1149s	
1572/5250 (epoch 14.971), train_loss = 1.27117574, grad/param norm = 5.9375e-02, time/batch = 0.1137s	
1573/5250 (epoch 14.981), train_loss = 1.29197181, grad/param norm = 6.0700e-02, time/batch = 0.1140s	
1574/5250 (epoch 14.990), train_loss = 1.28446843, grad/param norm = 6.0328e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
1575/5250 (epoch 15.000), train_loss = 1.26877901, grad/param norm = 5.8528e-02, time/batch = 0.1141s	
1576/5250 (epoch 15.010), train_loss = 1.42942707, grad/param norm = 5.9837e-02, time/batch = 0.1142s	
1577/5250 (epoch 15.019), train_loss = 1.24488221, grad/param norm = 5.7069e-02, time/batch = 0.1142s	
1578/5250 (epoch 15.029), train_loss = 1.26622656, grad/param norm = 5.7663e-02, time/batch = 0.1138s	
1579/5250 (epoch 15.038), train_loss = 1.24609902, grad/param norm = 5.7578e-02, time/batch = 0.1143s	
1580/5250 (epoch 15.048), train_loss = 1.22388604, grad/param norm = 5.5166e-02, time/batch = 0.1141s	
1581/5250 (epoch 15.057), train_loss = 1.22966004, grad/param norm = 5.1638e-02, time/batch = 0.1149s	
1582/5250 (epoch 15.067), train_loss = 1.24279780, grad/param norm = 5.3699e-02, time/batch = 0.1135s	
1583/5250 (epoch 15.076), train_loss = 1.25930481, grad/param norm = 5.7660e-02, time/batch = 0.1138s	
1584/5250 (epoch 15.086), train_loss = 1.20375701, grad/param norm = 5.4904e-02, time/batch = 0.1140s	
1585/5250 (epoch 15.095), train_loss = 1.22735678, grad/param norm = 5.4083e-02, time/batch = 0.1143s	
1586/5250 (epoch 15.105), train_loss = 1.25622421, grad/param norm = 5.1468e-02, time/batch = 0.1141s	
1587/5250 (epoch 15.114), train_loss = 1.23692934, grad/param norm = 4.7926e-02, time/batch = 0.1142s	
1588/5250 (epoch 15.124), train_loss = 1.24472902, grad/param norm = 5.2226e-02, time/batch = 0.1136s	
1589/5250 (epoch 15.133), train_loss = 1.24207711, grad/param norm = 5.8288e-02, time/batch = 0.1143s	
1590/5250 (epoch 15.143), train_loss = 1.21700335, grad/param norm = 5.3608e-02, time/batch = 0.1142s	
1591/5250 (epoch 15.152), train_loss = 1.21832997, grad/param norm = 5.5813e-02, time/batch = 0.1150s	
1592/5250 (epoch 15.162), train_loss = 1.26270839, grad/param norm = 5.7867e-02, time/batch = 0.1137s	
1593/5250 (epoch 15.171), train_loss = 1.25168516, grad/param norm = 5.5397e-02, time/batch = 0.1140s	
1594/5250 (epoch 15.181), train_loss = 1.24789179, grad/param norm = 5.5076e-02, time/batch = 0.1140s	
1595/5250 (epoch 15.190), train_loss = 1.25837246, grad/param norm = 6.0485e-02, time/batch = 0.1142s	
1596/5250 (epoch 15.200), train_loss = 1.23798649, grad/param norm = 5.4330e-02, time/batch = 0.1140s	
1597/5250 (epoch 15.210), train_loss = 1.23862229, grad/param norm = 5.4172e-02, time/batch = 0.1141s	
1598/5250 (epoch 15.219), train_loss = 1.27917060, grad/param norm = 5.4945e-02, time/batch = 0.1136s	
1599/5250 (epoch 15.229), train_loss = 1.24708965, grad/param norm = 5.7925e-02, time/batch = 0.1144s	
1600/5250 (epoch 15.238), train_loss = 1.25750029, grad/param norm = 5.8525e-02, time/batch = 0.1141s	
1601/5250 (epoch 15.248), train_loss = 1.24058085, grad/param norm = 5.5923e-02, time/batch = 0.1147s	
1602/5250 (epoch 15.257), train_loss = 1.24268646, grad/param norm = 6.0617e-02, time/batch = 0.1138s	
1603/5250 (epoch 15.267), train_loss = 1.23432491, grad/param norm = 5.5286e-02, time/batch = 0.1140s	
1604/5250 (epoch 15.276), train_loss = 1.22960987, grad/param norm = 5.1657e-02, time/batch = 0.1141s	
1605/5250 (epoch 15.286), train_loss = 1.21940983, grad/param norm = 5.8011e-02, time/batch = 0.1142s	
1606/5250 (epoch 15.295), train_loss = 1.24226866, grad/param norm = 5.6106e-02, time/batch = 0.1144s	
1607/5250 (epoch 15.305), train_loss = 1.23734058, grad/param norm = 5.5815e-02, time/batch = 0.1142s	
1608/5250 (epoch 15.314), train_loss = 1.22542550, grad/param norm = 5.3816e-02, time/batch = 0.1137s	
1609/5250 (epoch 15.324), train_loss = 1.24405324, grad/param norm = 5.6134e-02, time/batch = 0.1142s	
1610/5250 (epoch 15.333), train_loss = 1.24532738, grad/param norm = 5.2481e-02, time/batch = 0.1144s	
1611/5250 (epoch 15.343), train_loss = 1.24279072, grad/param norm = 5.7673e-02, time/batch = 0.1148s	
1612/5250 (epoch 15.352), train_loss = 1.25746907, grad/param norm = 6.5774e-02, time/batch = 0.1137s	
1613/5250 (epoch 15.362), train_loss = 1.25212751, grad/param norm = 6.0692e-02, time/batch = 0.1141s	
1614/5250 (epoch 15.371), train_loss = 1.22899805, grad/param norm = 5.2727e-02, time/batch = 0.1142s	
1615/5250 (epoch 15.381), train_loss = 1.23169357, grad/param norm = 5.8675e-02, time/batch = 0.1141s	
1616/5250 (epoch 15.390), train_loss = 1.24350793, grad/param norm = 5.6419e-02, time/batch = 0.1142s	
1617/5250 (epoch 15.400), train_loss = 1.23613996, grad/param norm = 5.4262e-02, time/batch = 0.1178s	
1618/5250 (epoch 15.410), train_loss = 1.24845818, grad/param norm = 6.4632e-02, time/batch = 0.1136s	
1619/5250 (epoch 15.419), train_loss = 1.24843612, grad/param norm = 6.6225e-02, time/batch = 0.1143s	
1620/5250 (epoch 15.429), train_loss = 1.24928644, grad/param norm = 5.4438e-02, time/batch = 0.1146s	
1621/5250 (epoch 15.438), train_loss = 1.25774545, grad/param norm = 5.2743e-02, time/batch = 0.1157s	
1622/5250 (epoch 15.448), train_loss = 1.22496355, grad/param norm = 5.4663e-02, time/batch = 0.1137s	
1623/5250 (epoch 15.457), train_loss = 1.22513346, grad/param norm = 5.5485e-02, time/batch = 0.1141s	
1624/5250 (epoch 15.467), train_loss = 1.24055882, grad/param norm = 5.3117e-02, time/batch = 0.1142s	
1625/5250 (epoch 15.476), train_loss = 1.23859177, grad/param norm = 6.0715e-02, time/batch = 0.1141s	
1626/5250 (epoch 15.486), train_loss = 1.26233256, grad/param norm = 6.3521e-02, time/batch = 0.1142s	
1627/5250 (epoch 15.495), train_loss = 1.25868062, grad/param norm = 5.7004e-02, time/batch = 0.1143s	
1628/5250 (epoch 15.505), train_loss = 1.26116425, grad/param norm = 5.5461e-02, time/batch = 0.1137s	
1629/5250 (epoch 15.514), train_loss = 1.24842211, grad/param norm = 5.3847e-02, time/batch = 0.1142s	
1630/5250 (epoch 15.524), train_loss = 1.24403232, grad/param norm = 5.2427e-02, time/batch = 0.1143s	
1631/5250 (epoch 15.533), train_loss = 1.24731355, grad/param norm = 5.4360e-02, time/batch = 0.1149s	
1632/5250 (epoch 15.543), train_loss = 1.23350745, grad/param norm = 5.3756e-02, time/batch = 0.1135s	
1633/5250 (epoch 15.552), train_loss = 1.24457942, grad/param norm = 5.7689e-02, time/batch = 0.1139s	
1634/5250 (epoch 15.562), train_loss = 1.25102983, grad/param norm = 6.2359e-02, time/batch = 0.1142s	
1635/5250 (epoch 15.571), train_loss = 1.24988916, grad/param norm = 5.7133e-02, time/batch = 0.1143s	
1636/5250 (epoch 15.581), train_loss = 1.27010114, grad/param norm = 5.9518e-02, time/batch = 0.1143s	
1637/5250 (epoch 15.590), train_loss = 1.24987575, grad/param norm = 5.6297e-02, time/batch = 0.1142s	
1638/5250 (epoch 15.600), train_loss = 1.26681861, grad/param norm = 5.5806e-02, time/batch = 0.1139s	
1639/5250 (epoch 15.610), train_loss = 1.26637182, grad/param norm = 5.7048e-02, time/batch = 0.1143s	
1640/5250 (epoch 15.619), train_loss = 1.25897393, grad/param norm = 6.1872e-02, time/batch = 0.1144s	
1641/5250 (epoch 15.629), train_loss = 1.26005819, grad/param norm = 6.2753e-02, time/batch = 0.1157s	
1642/5250 (epoch 15.638), train_loss = 1.24864834, grad/param norm = 6.1708e-02, time/batch = 0.1137s	
1643/5250 (epoch 15.648), train_loss = 1.25952720, grad/param norm = 6.3506e-02, time/batch = 0.1142s	
1644/5250 (epoch 15.657), train_loss = 1.25514880, grad/param norm = 6.9344e-02, time/batch = 0.1143s	
1645/5250 (epoch 15.667), train_loss = 1.25565771, grad/param norm = 6.5690e-02, time/batch = 0.1142s	
1646/5250 (epoch 15.676), train_loss = 1.24270459, grad/param norm = 5.5359e-02, time/batch = 0.1141s	
1647/5250 (epoch 15.686), train_loss = 1.26957053, grad/param norm = 5.5851e-02, time/batch = 0.1141s	
1648/5250 (epoch 15.695), train_loss = 1.25287752, grad/param norm = 6.1310e-02, time/batch = 0.1138s	
1649/5250 (epoch 15.705), train_loss = 1.24167962, grad/param norm = 6.0110e-02, time/batch = 0.1142s	
1650/5250 (epoch 15.714), train_loss = 1.26301832, grad/param norm = 5.4541e-02, time/batch = 0.1141s	
1651/5250 (epoch 15.724), train_loss = 1.24145972, grad/param norm = 5.7508e-02, time/batch = 0.1149s	
1652/5250 (epoch 15.733), train_loss = 1.22931908, grad/param norm = 6.1941e-02, time/batch = 0.1137s	
1653/5250 (epoch 15.743), train_loss = 1.22605778, grad/param norm = 5.4720e-02, time/batch = 0.1140s	
1654/5250 (epoch 15.752), train_loss = 1.24087305, grad/param norm = 6.2832e-02, time/batch = 0.1141s	
1655/5250 (epoch 15.762), train_loss = 1.23422401, grad/param norm = 6.3334e-02, time/batch = 0.1143s	
1656/5250 (epoch 15.771), train_loss = 1.22739064, grad/param norm = 6.1673e-02, time/batch = 0.1141s	
1657/5250 (epoch 15.781), train_loss = 1.24581033, grad/param norm = 5.4672e-02, time/batch = 0.1143s	
1658/5250 (epoch 15.790), train_loss = 1.25057422, grad/param norm = 5.1975e-02, time/batch = 0.1136s	
1659/5250 (epoch 15.800), train_loss = 1.22728951, grad/param norm = 5.4287e-02, time/batch = 0.1142s	
1660/5250 (epoch 15.810), train_loss = 1.24065876, grad/param norm = 5.6978e-02, time/batch = 0.1142s	
1661/5250 (epoch 15.819), train_loss = 1.24849677, grad/param norm = 5.7715e-02, time/batch = 0.1150s	
1662/5250 (epoch 15.829), train_loss = 1.25444131, grad/param norm = 5.5896e-02, time/batch = 0.1139s	
1663/5250 (epoch 15.838), train_loss = 1.21931840, grad/param norm = 5.5105e-02, time/batch = 0.1140s	
1664/5250 (epoch 15.848), train_loss = 1.22498184, grad/param norm = 6.6047e-02, time/batch = 0.1141s	
1665/5250 (epoch 15.857), train_loss = 1.24403443, grad/param norm = 6.6546e-02, time/batch = 0.1144s	
1666/5250 (epoch 15.867), train_loss = 1.23324337, grad/param norm = 6.2573e-02, time/batch = 0.1142s	
1667/5250 (epoch 15.876), train_loss = 1.22962421, grad/param norm = 5.7903e-02, time/batch = 0.1142s	
1668/5250 (epoch 15.886), train_loss = 1.22435633, grad/param norm = 5.5069e-02, time/batch = 0.1136s	
1669/5250 (epoch 15.895), train_loss = 1.26132452, grad/param norm = 5.7309e-02, time/batch = 0.1142s	
1670/5250 (epoch 15.905), train_loss = 1.24960030, grad/param norm = 5.6590e-02, time/batch = 0.1143s	
1671/5250 (epoch 15.914), train_loss = 1.25794323, grad/param norm = 5.6787e-02, time/batch = 0.1148s	
1672/5250 (epoch 15.924), train_loss = 1.25410737, grad/param norm = 5.5663e-02, time/batch = 0.1137s	
1673/5250 (epoch 15.933), train_loss = 1.23770533, grad/param norm = 5.3171e-02, time/batch = 0.1139s	
1674/5250 (epoch 15.943), train_loss = 1.26402928, grad/param norm = 5.4717e-02, time/batch = 0.1142s	
1675/5250 (epoch 15.952), train_loss = 1.26595610, grad/param norm = 5.6942e-02, time/batch = 0.1141s	
1676/5250 (epoch 15.962), train_loss = 1.24198097, grad/param norm = 5.4275e-02, time/batch = 0.1143s	
1677/5250 (epoch 15.971), train_loss = 1.25166219, grad/param norm = 5.5814e-02, time/batch = 0.1143s	
1678/5250 (epoch 15.981), train_loss = 1.27464160, grad/param norm = 6.5429e-02, time/batch = 0.1136s	
1679/5250 (epoch 15.990), train_loss = 1.26928277, grad/param norm = 6.6619e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
1680/5250 (epoch 16.000), train_loss = 1.25246320, grad/param norm = 6.0607e-02, time/batch = 0.1143s	
1681/5250 (epoch 16.010), train_loss = 1.41603026, grad/param norm = 6.2364e-02, time/batch = 0.1156s	
1682/5250 (epoch 16.019), train_loss = 1.22649820, grad/param norm = 5.5368e-02, time/batch = 0.1137s	
1683/5250 (epoch 16.029), train_loss = 1.24592974, grad/param norm = 5.1969e-02, time/batch = 0.1140s	
1684/5250 (epoch 16.038), train_loss = 1.22716331, grad/param norm = 5.3739e-02, time/batch = 0.1142s	
1685/5250 (epoch 16.048), train_loss = 1.20359236, grad/param norm = 5.0626e-02, time/batch = 0.1142s	
1686/5250 (epoch 16.057), train_loss = 1.21140754, grad/param norm = 4.9675e-02, time/batch = 0.1143s	
1687/5250 (epoch 16.067), train_loss = 1.22296812, grad/param norm = 5.0372e-02, time/batch = 0.1143s	
1688/5250 (epoch 16.076), train_loss = 1.23894383, grad/param norm = 5.2115e-02, time/batch = 0.1137s	
1689/5250 (epoch 16.086), train_loss = 1.18383026, grad/param norm = 5.1864e-02, time/batch = 0.1144s	
1690/5250 (epoch 16.095), train_loss = 1.21042727, grad/param norm = 5.3618e-02, time/batch = 0.1142s	
1691/5250 (epoch 16.105), train_loss = 1.24003557, grad/param norm = 5.4892e-02, time/batch = 0.1150s	
1692/5250 (epoch 16.114), train_loss = 1.22290406, grad/param norm = 5.2997e-02, time/batch = 0.1136s	
1693/5250 (epoch 16.124), train_loss = 1.22996128, grad/param norm = 5.7183e-02, time/batch = 0.1141s	
1694/5250 (epoch 16.133), train_loss = 1.22833638, grad/param norm = 5.9848e-02, time/batch = 0.1139s	
1695/5250 (epoch 16.143), train_loss = 1.20101066, grad/param norm = 5.6031e-02, time/batch = 0.1143s	
1696/5250 (epoch 16.152), train_loss = 1.20191320, grad/param norm = 5.5133e-02, time/batch = 0.1140s	
1697/5250 (epoch 16.162), train_loss = 1.24273912, grad/param norm = 5.5127e-02, time/batch = 0.1141s	
1698/5250 (epoch 16.171), train_loss = 1.22896881, grad/param norm = 5.0510e-02, time/batch = 0.1141s	
1699/5250 (epoch 16.181), train_loss = 1.22619989, grad/param norm = 5.2219e-02, time/batch = 0.1143s	
1700/5250 (epoch 16.190), train_loss = 1.23515934, grad/param norm = 5.2771e-02, time/batch = 0.1143s	
1701/5250 (epoch 16.200), train_loss = 1.22027585, grad/param norm = 5.6499e-02, time/batch = 0.1148s	
1702/5250 (epoch 16.210), train_loss = 1.22114175, grad/param norm = 5.7102e-02, time/batch = 0.1136s	
1703/5250 (epoch 16.219), train_loss = 1.26436938, grad/param norm = 6.3662e-02, time/batch = 0.1139s	
1704/5250 (epoch 16.229), train_loss = 1.23433486, grad/param norm = 6.2609e-02, time/batch = 0.1141s	
1705/5250 (epoch 16.238), train_loss = 1.24797173, grad/param norm = 7.9453e-02, time/batch = 0.1144s	
1706/5250 (epoch 16.248), train_loss = 1.24124460, grad/param norm = 6.6672e-02, time/batch = 0.1142s	
1707/5250 (epoch 16.257), train_loss = 1.23079858, grad/param norm = 6.0235e-02, time/batch = 0.1141s	
1708/5250 (epoch 16.267), train_loss = 1.21659441, grad/param norm = 5.3635e-02, time/batch = 0.1137s	
1709/5250 (epoch 16.276), train_loss = 1.21267243, grad/param norm = 5.1833e-02, time/batch = 0.1143s	
1710/5250 (epoch 16.286), train_loss = 1.20038873, grad/param norm = 5.3056e-02, time/batch = 0.1141s	
1711/5250 (epoch 16.295), train_loss = 1.22078233, grad/param norm = 5.2077e-02, time/batch = 0.1157s	
1712/5250 (epoch 16.305), train_loss = 1.21852245, grad/param norm = 5.2132e-02, time/batch = 0.1138s	
1713/5250 (epoch 16.314), train_loss = 1.20630561, grad/param norm = 5.3045e-02, time/batch = 0.1139s	
1714/5250 (epoch 16.324), train_loss = 1.22599142, grad/param norm = 5.3553e-02, time/batch = 0.1141s	
1715/5250 (epoch 16.333), train_loss = 1.23055209, grad/param norm = 5.7166e-02, time/batch = 0.1141s	
1716/5250 (epoch 16.343), train_loss = 1.22706518, grad/param norm = 5.6740e-02, time/batch = 0.1141s	
1717/5250 (epoch 16.352), train_loss = 1.23579490, grad/param norm = 5.7595e-02, time/batch = 0.1142s	
1718/5250 (epoch 16.362), train_loss = 1.23259001, grad/param norm = 6.0962e-02, time/batch = 0.1137s	
1719/5250 (epoch 16.371), train_loss = 1.21758688, grad/param norm = 6.0319e-02, time/batch = 0.1144s	
1720/5250 (epoch 16.381), train_loss = 1.21479422, grad/param norm = 6.1564e-02, time/batch = 0.1145s	
1721/5250 (epoch 16.390), train_loss = 1.22572033, grad/param norm = 5.7916e-02, time/batch = 0.1150s	
1722/5250 (epoch 16.400), train_loss = 1.21864205, grad/param norm = 5.2301e-02, time/batch = 0.1137s	
1723/5250 (epoch 16.410), train_loss = 1.22567500, grad/param norm = 5.7124e-02, time/batch = 0.1139s	
1724/5250 (epoch 16.419), train_loss = 1.22536474, grad/param norm = 5.4994e-02, time/batch = 0.1141s	
1725/5250 (epoch 16.429), train_loss = 1.23140329, grad/param norm = 5.6759e-02, time/batch = 0.1143s	
1726/5250 (epoch 16.438), train_loss = 1.24704200, grad/param norm = 6.8989e-02, time/batch = 0.1142s	
1727/5250 (epoch 16.448), train_loss = 1.21612051, grad/param norm = 6.3109e-02, time/batch = 0.1142s	
1728/5250 (epoch 16.457), train_loss = 1.21038452, grad/param norm = 6.1318e-02, time/batch = 0.1137s	
1729/5250 (epoch 16.467), train_loss = 1.22659605, grad/param norm = 6.0186e-02, time/batch = 0.1144s	
1730/5250 (epoch 16.476), train_loss = 1.22065188, grad/param norm = 5.7144e-02, time/batch = 0.1142s	
1731/5250 (epoch 16.486), train_loss = 1.23889990, grad/param norm = 6.0838e-02, time/batch = 0.1149s	
1732/5250 (epoch 16.495), train_loss = 1.24208813, grad/param norm = 5.7882e-02, time/batch = 0.1140s	
1733/5250 (epoch 16.505), train_loss = 1.24112890, grad/param norm = 5.8244e-02, time/batch = 0.1142s	
1734/5250 (epoch 16.514), train_loss = 1.23533850, grad/param norm = 6.2187e-02, time/batch = 0.1142s	
1735/5250 (epoch 16.524), train_loss = 1.23401442, grad/param norm = 6.6451e-02, time/batch = 0.1143s	
1736/5250 (epoch 16.533), train_loss = 1.23910298, grad/param norm = 6.3652e-02, time/batch = 0.1144s	
1737/5250 (epoch 16.543), train_loss = 1.21940821, grad/param norm = 5.9260e-02, time/batch = 0.1143s	
1738/5250 (epoch 16.552), train_loss = 1.22655895, grad/param norm = 5.7937e-02, time/batch = 0.1136s	
1739/5250 (epoch 16.562), train_loss = 1.23025224, grad/param norm = 5.7871e-02, time/batch = 0.1143s	
1740/5250 (epoch 16.571), train_loss = 1.23122586, grad/param norm = 5.7741e-02, time/batch = 0.1142s	
1741/5250 (epoch 16.581), train_loss = 1.25193470, grad/param norm = 5.7203e-02, time/batch = 0.1150s	
1742/5250 (epoch 16.590), train_loss = 1.23170069, grad/param norm = 5.5291e-02, time/batch = 0.1136s	
1743/5250 (epoch 16.600), train_loss = 1.25319642, grad/param norm = 5.6953e-02, time/batch = 0.1142s	
1744/5250 (epoch 16.610), train_loss = 1.25093061, grad/param norm = 6.2328e-02, time/batch = 0.1142s	
1745/5250 (epoch 16.619), train_loss = 1.24095965, grad/param norm = 5.9876e-02, time/batch = 0.1145s	
1746/5250 (epoch 16.629), train_loss = 1.23400899, grad/param norm = 5.2031e-02, time/batch = 0.1143s	
1747/5250 (epoch 16.638), train_loss = 1.22377475, grad/param norm = 4.9198e-02, time/batch = 0.1143s	
1748/5250 (epoch 16.648), train_loss = 1.23471932, grad/param norm = 5.1268e-02, time/batch = 0.1137s	
1749/5250 (epoch 16.657), train_loss = 1.22404324, grad/param norm = 4.9499e-02, time/batch = 0.1143s	
1750/5250 (epoch 16.667), train_loss = 1.22580995, grad/param norm = 4.8869e-02, time/batch = 0.1143s	
1751/5250 (epoch 16.676), train_loss = 1.22210760, grad/param norm = 5.3092e-02, time/batch = 0.1147s	
1752/5250 (epoch 16.686), train_loss = 1.25630274, grad/param norm = 6.3332e-02, time/batch = 0.1136s	
1753/5250 (epoch 16.695), train_loss = 1.23625499, grad/param norm = 6.2258e-02, time/batch = 0.1141s	
1754/5250 (epoch 16.705), train_loss = 1.22339194, grad/param norm = 5.9644e-02, time/batch = 0.1142s	
1755/5250 (epoch 16.714), train_loss = 1.24840972, grad/param norm = 5.6792e-02, time/batch = 0.1143s	
1756/5250 (epoch 16.724), train_loss = 1.22257205, grad/param norm = 5.3917e-02, time/batch = 0.1142s	
1757/5250 (epoch 16.733), train_loss = 1.20825921, grad/param norm = 5.1815e-02, time/batch = 0.1142s	
1758/5250 (epoch 16.743), train_loss = 1.20896064, grad/param norm = 5.5601e-02, time/batch = 0.1137s	
1759/5250 (epoch 16.752), train_loss = 1.22253110, grad/param norm = 6.4227e-02, time/batch = 0.1145s	
1760/5250 (epoch 16.762), train_loss = 1.21520706, grad/param norm = 6.0901e-02, time/batch = 0.1143s	
1761/5250 (epoch 16.771), train_loss = 1.20729659, grad/param norm = 5.6719e-02, time/batch = 0.1151s	
1762/5250 (epoch 16.781), train_loss = 1.22651116, grad/param norm = 5.3543e-02, time/batch = 0.1135s	
1763/5250 (epoch 16.790), train_loss = 1.23407125, grad/param norm = 5.2937e-02, time/batch = 0.1138s	
1764/5250 (epoch 16.800), train_loss = 1.20984232, grad/param norm = 5.4017e-02, time/batch = 0.1141s	
1765/5250 (epoch 16.810), train_loss = 1.22127395, grad/param norm = 5.1917e-02, time/batch = 0.1143s	
1766/5250 (epoch 16.819), train_loss = 1.22936373, grad/param norm = 5.3102e-02, time/batch = 0.1143s	
1767/5250 (epoch 16.829), train_loss = 1.23568452, grad/param norm = 5.4810e-02, time/batch = 0.1142s	
1768/5250 (epoch 16.838), train_loss = 1.20203630, grad/param norm = 5.3464e-02, time/batch = 0.1136s	
1769/5250 (epoch 16.848), train_loss = 1.20503143, grad/param norm = 6.0241e-02, time/batch = 0.1145s	
1770/5250 (epoch 16.857), train_loss = 1.22366990, grad/param norm = 5.9930e-02, time/batch = 0.1141s	
1771/5250 (epoch 16.867), train_loss = 1.21505625, grad/param norm = 5.9032e-02, time/batch = 0.1148s	
1772/5250 (epoch 16.876), train_loss = 1.21031121, grad/param norm = 5.7902e-02, time/batch = 0.1138s	
1773/5250 (epoch 16.886), train_loss = 1.20912487, grad/param norm = 6.0822e-02, time/batch = 0.1141s	
1774/5250 (epoch 16.895), train_loss = 1.24685033, grad/param norm = 6.3917e-02, time/batch = 0.1141s	
1775/5250 (epoch 16.905), train_loss = 1.23311249, grad/param norm = 5.7896e-02, time/batch = 0.1142s	
1776/5250 (epoch 16.914), train_loss = 1.23987315, grad/param norm = 5.5320e-02, time/batch = 0.1143s	
1777/5250 (epoch 16.924), train_loss = 1.23623300, grad/param norm = 5.2405e-02, time/batch = 0.1141s	
1778/5250 (epoch 16.933), train_loss = 1.22008282, grad/param norm = 5.1833e-02, time/batch = 0.1135s	
1779/5250 (epoch 16.943), train_loss = 1.24485054, grad/param norm = 5.4698e-02, time/batch = 0.1143s	
1780/5250 (epoch 16.952), train_loss = 1.24644349, grad/param norm = 5.3540e-02, time/batch = 0.1143s	
1781/5250 (epoch 16.962), train_loss = 1.22268466, grad/param norm = 5.1476e-02, time/batch = 0.1149s	
1782/5250 (epoch 16.971), train_loss = 1.23506024, grad/param norm = 5.5040e-02, time/batch = 0.1137s	
1783/5250 (epoch 16.981), train_loss = 1.25473931, grad/param norm = 5.9392e-02, time/batch = 0.1141s	
1784/5250 (epoch 16.990), train_loss = 1.24869195, grad/param norm = 6.1778e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
1785/5250 (epoch 17.000), train_loss = 1.23598222, grad/param norm = 5.7824e-02, time/batch = 0.1144s	
1786/5250 (epoch 17.010), train_loss = 1.39871722, grad/param norm = 5.8649e-02, time/batch = 0.1142s	
1787/5250 (epoch 17.019), train_loss = 1.21106866, grad/param norm = 5.5373e-02, time/batch = 0.1142s	
1788/5250 (epoch 17.029), train_loss = 1.23256087, grad/param norm = 5.6379e-02, time/batch = 0.1135s	
1789/5250 (epoch 17.038), train_loss = 1.21327282, grad/param norm = 5.8622e-02, time/batch = 0.1143s	
1790/5250 (epoch 17.048), train_loss = 1.18823554, grad/param norm = 5.4746e-02, time/batch = 0.1145s	
1791/5250 (epoch 17.057), train_loss = 1.19343210, grad/param norm = 4.9692e-02, time/batch = 0.1148s	
1792/5250 (epoch 17.067), train_loss = 1.20696105, grad/param norm = 5.1248e-02, time/batch = 0.1137s	
1793/5250 (epoch 17.076), train_loss = 1.22648971, grad/param norm = 5.8619e-02, time/batch = 0.1139s	
1794/5250 (epoch 17.086), train_loss = 1.17260390, grad/param norm = 5.5501e-02, time/batch = 0.1142s	
1795/5250 (epoch 17.095), train_loss = 1.19209635, grad/param norm = 5.2573e-02, time/batch = 0.1143s	
1796/5250 (epoch 17.105), train_loss = 1.22187774, grad/param norm = 5.1617e-02, time/batch = 0.1142s	
1797/5250 (epoch 17.114), train_loss = 1.20380856, grad/param norm = 4.8992e-02, time/batch = 0.1143s	
1798/5250 (epoch 17.124), train_loss = 1.21234925, grad/param norm = 5.3609e-02, time/batch = 0.1139s	
1799/5250 (epoch 17.133), train_loss = 1.20765876, grad/param norm = 5.7012e-02, time/batch = 0.1144s	
1800/5250 (epoch 17.143), train_loss = 1.18109786, grad/param norm = 5.1727e-02, time/batch = 0.1141s	
1801/5250 (epoch 17.152), train_loss = 1.18340153, grad/param norm = 5.4629e-02, time/batch = 0.1158s	
1802/5250 (epoch 17.162), train_loss = 1.22823261, grad/param norm = 5.8101e-02, time/batch = 0.1138s	
1803/5250 (epoch 17.171), train_loss = 1.21589485, grad/param norm = 5.7206e-02, time/batch = 0.1139s	
1804/5250 (epoch 17.181), train_loss = 1.21483030, grad/param norm = 5.9744e-02, time/batch = 0.1143s	
1805/5250 (epoch 17.190), train_loss = 1.22429700, grad/param norm = 6.3602e-02, time/batch = 0.1142s	
1806/5250 (epoch 17.200), train_loss = 1.20521260, grad/param norm = 5.7193e-02, time/batch = 0.1143s	
1807/5250 (epoch 17.210), train_loss = 1.20471879, grad/param norm = 5.3591e-02, time/batch = 0.1143s	
1808/5250 (epoch 17.219), train_loss = 1.24276091, grad/param norm = 5.5470e-02, time/batch = 0.1136s	
1809/5250 (epoch 17.229), train_loss = 1.21562154, grad/param norm = 6.1047e-02, time/batch = 0.1144s	
1810/5250 (epoch 17.238), train_loss = 1.22426970, grad/param norm = 5.9116e-02, time/batch = 0.1144s	
1811/5250 (epoch 17.248), train_loss = 1.20911213, grad/param norm = 5.6297e-02, time/batch = 0.1149s	
1812/5250 (epoch 17.257), train_loss = 1.20965879, grad/param norm = 5.8541e-02, time/batch = 0.1137s	
1813/5250 (epoch 17.267), train_loss = 1.20197914, grad/param norm = 5.9770e-02, time/batch = 0.1141s	
1814/5250 (epoch 17.276), train_loss = 1.20415138, grad/param norm = 6.1234e-02, time/batch = 0.1142s	
1815/5250 (epoch 17.286), train_loss = 1.19182657, grad/param norm = 6.2953e-02, time/batch = 0.1142s	
1816/5250 (epoch 17.295), train_loss = 1.20623841, grad/param norm = 5.3535e-02, time/batch = 0.1141s	
1817/5250 (epoch 17.305), train_loss = 1.19996019, grad/param norm = 5.3445e-02, time/batch = 0.1140s	
1818/5250 (epoch 17.314), train_loss = 1.19048597, grad/param norm = 5.4145e-02, time/batch = 0.1136s	
1819/5250 (epoch 17.324), train_loss = 1.21124343, grad/param norm = 5.4963e-02, time/batch = 0.1144s	
1820/5250 (epoch 17.333), train_loss = 1.21280513, grad/param norm = 5.4633e-02, time/batch = 0.1141s	
1821/5250 (epoch 17.343), train_loss = 1.20952324, grad/param norm = 5.3753e-02, time/batch = 0.1148s	
1822/5250 (epoch 17.352), train_loss = 1.21721538, grad/param norm = 5.3647e-02, time/batch = 0.1137s	
1823/5250 (epoch 17.362), train_loss = 1.21166601, grad/param norm = 5.3075e-02, time/batch = 0.1139s	
1824/5250 (epoch 17.371), train_loss = 1.19492127, grad/param norm = 5.1897e-02, time/batch = 0.1142s	
1825/5250 (epoch 17.381), train_loss = 1.19435045, grad/param norm = 5.3509e-02, time/batch = 0.1144s	
1826/5250 (epoch 17.390), train_loss = 1.20592611, grad/param norm = 5.2297e-02, time/batch = 0.1143s	
1827/5250 (epoch 17.400), train_loss = 1.20202909, grad/param norm = 5.3042e-02, time/batch = 0.1140s	
1828/5250 (epoch 17.410), train_loss = 1.20901349, grad/param norm = 5.5399e-02, time/batch = 0.1137s	
1829/5250 (epoch 17.419), train_loss = 1.20738158, grad/param norm = 5.3388e-02, time/batch = 0.1142s	
1830/5250 (epoch 17.429), train_loss = 1.21058576, grad/param norm = 4.9819e-02, time/batch = 0.1145s	
1831/5250 (epoch 17.438), train_loss = 1.22090262, grad/param norm = 5.1658e-02, time/batch = 0.1150s	
1832/5250 (epoch 17.448), train_loss = 1.19121786, grad/param norm = 5.0325e-02, time/batch = 0.1137s	
1833/5250 (epoch 17.457), train_loss = 1.19337861, grad/param norm = 5.4562e-02, time/batch = 0.1142s	
1834/5250 (epoch 17.467), train_loss = 1.21043666, grad/param norm = 6.1029e-02, time/batch = 0.1141s	
1835/5250 (epoch 17.476), train_loss = 1.21011044, grad/param norm = 6.5454e-02, time/batch = 0.1145s	
1836/5250 (epoch 17.486), train_loss = 1.22483179, grad/param norm = 6.1514e-02, time/batch = 0.1142s	
1837/5250 (epoch 17.495), train_loss = 1.22518099, grad/param norm = 5.3921e-02, time/batch = 0.1142s	
1838/5250 (epoch 17.505), train_loss = 1.22654799, grad/param norm = 5.7094e-02, time/batch = 0.1137s	
1839/5250 (epoch 17.514), train_loss = 1.21649204, grad/param norm = 5.8875e-02, time/batch = 0.1143s	
1840/5250 (epoch 17.524), train_loss = 1.21886906, grad/param norm = 5.8465e-02, time/batch = 0.1143s	
1841/5250 (epoch 17.533), train_loss = 1.22228056, grad/param norm = 6.1541e-02, time/batch = 0.1149s	
1842/5250 (epoch 17.543), train_loss = 1.20155474, grad/param norm = 5.7731e-02, time/batch = 0.1137s	
1843/5250 (epoch 17.552), train_loss = 1.20943309, grad/param norm = 5.8582e-02, time/batch = 0.1139s	
1844/5250 (epoch 17.562), train_loss = 1.21506246, grad/param norm = 5.6719e-02, time/batch = 0.1142s	
1845/5250 (epoch 17.571), train_loss = 1.21430912, grad/param norm = 5.3551e-02, time/batch = 0.1142s	
1846/5250 (epoch 17.581), train_loss = 1.23300066, grad/param norm = 5.7654e-02, time/batch = 0.1142s	
1847/5250 (epoch 17.590), train_loss = 1.21636076, grad/param norm = 5.7103e-02, time/batch = 0.1143s	
1848/5250 (epoch 17.600), train_loss = 1.23739640, grad/param norm = 5.9876e-02, time/batch = 0.1137s	
1849/5250 (epoch 17.610), train_loss = 1.23744329, grad/param norm = 6.1796e-02, time/batch = 0.1145s	
1850/5250 (epoch 17.619), train_loss = 1.22564827, grad/param norm = 5.8663e-02, time/batch = 0.1141s	
1851/5250 (epoch 17.629), train_loss = 1.21532987, grad/param norm = 5.1376e-02, time/batch = 0.1149s	
1852/5250 (epoch 17.638), train_loss = 1.21020079, grad/param norm = 5.2300e-02, time/batch = 0.1136s	
1853/5250 (epoch 17.648), train_loss = 1.22132347, grad/param norm = 5.4811e-02, time/batch = 0.1140s	
1854/5250 (epoch 17.657), train_loss = 1.21089690, grad/param norm = 5.4489e-02, time/batch = 0.1139s	
1855/5250 (epoch 17.667), train_loss = 1.21385181, grad/param norm = 5.5212e-02, time/batch = 0.1142s	
1856/5250 (epoch 17.676), train_loss = 1.20775468, grad/param norm = 5.8158e-02, time/batch = 0.1142s	
1857/5250 (epoch 17.686), train_loss = 1.24366222, grad/param norm = 6.5456e-02, time/batch = 0.1142s	
1858/5250 (epoch 17.695), train_loss = 1.22035340, grad/param norm = 6.3381e-02, time/batch = 0.1138s	
1859/5250 (epoch 17.705), train_loss = 1.20767903, grad/param norm = 5.9560e-02, time/batch = 0.1143s	
1860/5250 (epoch 17.714), train_loss = 1.23301931, grad/param norm = 5.5755e-02, time/batch = 0.1143s	
1861/5250 (epoch 17.724), train_loss = 1.20831597, grad/param norm = 5.4403e-02, time/batch = 0.1158s	
1862/5250 (epoch 17.733), train_loss = 1.19229515, grad/param norm = 5.3240e-02, time/batch = 0.1137s	
1863/5250 (epoch 17.743), train_loss = 1.19223252, grad/param norm = 5.2441e-02, time/batch = 0.1141s	
1864/5250 (epoch 17.752), train_loss = 1.20450789, grad/param norm = 6.2856e-02, time/batch = 0.1141s	
1865/5250 (epoch 17.762), train_loss = 1.19806797, grad/param norm = 5.6150e-02, time/batch = 0.1143s	
1866/5250 (epoch 17.771), train_loss = 1.19086316, grad/param norm = 5.9694e-02, time/batch = 0.1142s	
1867/5250 (epoch 17.781), train_loss = 1.21416622, grad/param norm = 5.9090e-02, time/batch = 0.1144s	
1868/5250 (epoch 17.790), train_loss = 1.22123863, grad/param norm = 5.7925e-02, time/batch = 0.1134s	
1869/5250 (epoch 17.800), train_loss = 1.19530435, grad/param norm = 5.6988e-02, time/batch = 0.1142s	
1870/5250 (epoch 17.810), train_loss = 1.20960128, grad/param norm = 5.8573e-02, time/batch = 0.1143s	
1871/5250 (epoch 17.819), train_loss = 1.21594417, grad/param norm = 5.6578e-02, time/batch = 0.1148s	
1872/5250 (epoch 17.829), train_loss = 1.22140133, grad/param norm = 5.9123e-02, time/batch = 0.1136s	
1873/5250 (epoch 17.838), train_loss = 1.19014300, grad/param norm = 5.8684e-02, time/batch = 0.1138s	
1874/5250 (epoch 17.848), train_loss = 1.18668408, grad/param norm = 5.9598e-02, time/batch = 0.1143s	
1875/5250 (epoch 17.857), train_loss = 1.20490085, grad/param norm = 5.4595e-02, time/batch = 0.1143s	
1876/5250 (epoch 17.867), train_loss = 1.19594972, grad/param norm = 5.0833e-02, time/batch = 0.1142s	
1877/5250 (epoch 17.876), train_loss = 1.19324374, grad/param norm = 5.6056e-02, time/batch = 0.1141s	
1878/5250 (epoch 17.886), train_loss = 1.19366510, grad/param norm = 5.8396e-02, time/batch = 0.1137s	
1879/5250 (epoch 17.895), train_loss = 1.22804349, grad/param norm = 6.0131e-02, time/batch = 0.1142s	
1880/5250 (epoch 17.905), train_loss = 1.21802957, grad/param norm = 5.7834e-02, time/batch = 0.1143s	
1881/5250 (epoch 17.914), train_loss = 1.22750170, grad/param norm = 6.2968e-02, time/batch = 0.1149s	
1882/5250 (epoch 17.924), train_loss = 1.22933731, grad/param norm = 6.3340e-02, time/batch = 0.1137s	
1883/5250 (epoch 17.933), train_loss = 1.21063667, grad/param norm = 5.8703e-02, time/batch = 0.1140s	
1884/5250 (epoch 17.943), train_loss = 1.23199924, grad/param norm = 5.9517e-02, time/batch = 0.1140s	
1885/5250 (epoch 17.952), train_loss = 1.23622193, grad/param norm = 6.4445e-02, time/batch = 0.1141s	
1886/5250 (epoch 17.962), train_loss = 1.21511509, grad/param norm = 6.1144e-02, time/batch = 0.1143s	
1887/5250 (epoch 17.971), train_loss = 1.22271500, grad/param norm = 6.0871e-02, time/batch = 0.1143s	
1888/5250 (epoch 17.981), train_loss = 1.24196479, grad/param norm = 6.6371e-02, time/batch = 0.1137s	
1889/5250 (epoch 17.990), train_loss = 1.23058886, grad/param norm = 6.2187e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
1890/5250 (epoch 18.000), train_loss = 1.21536830, grad/param norm = 5.5431e-02, time/batch = 0.1142s	
1891/5250 (epoch 18.010), train_loss = 1.38376945, grad/param norm = 6.2035e-02, time/batch = 0.1157s	
1892/5250 (epoch 18.019), train_loss = 1.19659479, grad/param norm = 5.7953e-02, time/batch = 0.1137s	
1893/5250 (epoch 18.029), train_loss = 1.21721348, grad/param norm = 5.5074e-02, time/batch = 0.1140s	
1894/5250 (epoch 18.038), train_loss = 1.19813861, grad/param norm = 5.9106e-02, time/batch = 0.1144s	
1895/5250 (epoch 18.048), train_loss = 1.17233957, grad/param norm = 5.3944e-02, time/batch = 0.1144s	
1896/5250 (epoch 18.057), train_loss = 1.18102667, grad/param norm = 5.1684e-02, time/batch = 0.1142s	
1897/5250 (epoch 18.067), train_loss = 1.19299001, grad/param norm = 5.1607e-02, time/batch = 0.1142s	
1898/5250 (epoch 18.076), train_loss = 1.21010595, grad/param norm = 5.4573e-02, time/batch = 0.1136s	
1899/5250 (epoch 18.086), train_loss = 1.15346668, grad/param norm = 5.0784e-02, time/batch = 0.1144s	
1900/5250 (epoch 18.095), train_loss = 1.17559211, grad/param norm = 5.0063e-02, time/batch = 0.1147s	
1901/5250 (epoch 18.105), train_loss = 1.20498859, grad/param norm = 5.0363e-02, time/batch = 0.1148s	
1902/5250 (epoch 18.114), train_loss = 1.18765909, grad/param norm = 4.7989e-02, time/batch = 0.1137s	
1903/5250 (epoch 18.124), train_loss = 1.19446434, grad/param norm = 5.2245e-02, time/batch = 0.1139s	
1904/5250 (epoch 18.133), train_loss = 1.18889468, grad/param norm = 5.5603e-02, time/batch = 0.1143s	
1905/5250 (epoch 18.143), train_loss = 1.16723376, grad/param norm = 5.1055e-02, time/batch = 0.1143s	
1906/5250 (epoch 18.152), train_loss = 1.16486076, grad/param norm = 4.8689e-02, time/batch = 0.1141s	
1907/5250 (epoch 18.162), train_loss = 1.20862133, grad/param norm = 5.7200e-02, time/batch = 0.1142s	
1908/5250 (epoch 18.171), train_loss = 1.20228375, grad/param norm = 5.7040e-02, time/batch = 0.1139s	
1909/5250 (epoch 18.181), train_loss = 1.19627484, grad/param norm = 5.6924e-02, time/batch = 0.1144s	
1910/5250 (epoch 18.190), train_loss = 1.20395771, grad/param norm = 5.6733e-02, time/batch = 0.1145s	
1911/5250 (epoch 18.200), train_loss = 1.18921150, grad/param norm = 5.7141e-02, time/batch = 0.1148s	
1912/5250 (epoch 18.210), train_loss = 1.18831261, grad/param norm = 5.4170e-02, time/batch = 0.1139s	
1913/5250 (epoch 18.219), train_loss = 1.22725865, grad/param norm = 5.8450e-02, time/batch = 0.1141s	
1914/5250 (epoch 18.229), train_loss = 1.19923916, grad/param norm = 5.8581e-02, time/batch = 0.1142s	
1915/5250 (epoch 18.238), train_loss = 1.20872384, grad/param norm = 6.6973e-02, time/batch = 0.1144s	
1916/5250 (epoch 18.248), train_loss = 1.20108188, grad/param norm = 6.0533e-02, time/batch = 0.1142s	
1917/5250 (epoch 18.257), train_loss = 1.19492271, grad/param norm = 5.7188e-02, time/batch = 0.1144s	
1918/5250 (epoch 18.267), train_loss = 1.18500773, grad/param norm = 5.3121e-02, time/batch = 0.1139s	
1919/5250 (epoch 18.276), train_loss = 1.18382171, grad/param norm = 5.3401e-02, time/batch = 0.1144s	
1920/5250 (epoch 18.286), train_loss = 1.16869504, grad/param norm = 5.0487e-02, time/batch = 0.1143s	
1921/5250 (epoch 18.295), train_loss = 1.18858845, grad/param norm = 5.5938e-02, time/batch = 0.1147s	
1922/5250 (epoch 18.305), train_loss = 1.18994253, grad/param norm = 5.8465e-02, time/batch = 0.1136s	
1923/5250 (epoch 18.314), train_loss = 1.18053257, grad/param norm = 5.9823e-02, time/batch = 0.1139s	
1924/5250 (epoch 18.324), train_loss = 1.20072807, grad/param norm = 5.9643e-02, time/batch = 0.1143s	
1925/5250 (epoch 18.333), train_loss = 1.20131201, grad/param norm = 5.8762e-02, time/batch = 0.1141s	
1926/5250 (epoch 18.343), train_loss = 1.19413268, grad/param norm = 5.5086e-02, time/batch = 0.1142s	
1927/5250 (epoch 18.352), train_loss = 1.20432593, grad/param norm = 5.4867e-02, time/batch = 0.1142s	
1928/5250 (epoch 18.362), train_loss = 1.19909224, grad/param norm = 5.6027e-02, time/batch = 0.1138s	
1929/5250 (epoch 18.371), train_loss = 1.18181201, grad/param norm = 5.3831e-02, time/batch = 0.1143s	
1930/5250 (epoch 18.381), train_loss = 1.18041007, grad/param norm = 5.3719e-02, time/batch = 0.1143s	
1931/5250 (epoch 18.390), train_loss = 1.18968410, grad/param norm = 5.4364e-02, time/batch = 0.1157s	
1932/5250 (epoch 18.400), train_loss = 1.18711718, grad/param norm = 5.1887e-02, time/batch = 0.1136s	
1933/5250 (epoch 18.410), train_loss = 1.19179646, grad/param norm = 5.3373e-02, time/batch = 0.1141s	
1934/5250 (epoch 18.419), train_loss = 1.19309770, grad/param norm = 5.9582e-02, time/batch = 0.1141s	
1935/5250 (epoch 18.429), train_loss = 1.20527512, grad/param norm = 6.4978e-02, time/batch = 0.1142s	
1936/5250 (epoch 18.438), train_loss = 1.21493932, grad/param norm = 6.6111e-02, time/batch = 0.1142s	
1937/5250 (epoch 18.448), train_loss = 1.18235931, grad/param norm = 5.3860e-02, time/batch = 0.1140s	
1938/5250 (epoch 18.457), train_loss = 1.17776211, grad/param norm = 5.1969e-02, time/batch = 0.1137s	
1939/5250 (epoch 18.467), train_loss = 1.18787853, grad/param norm = 5.0386e-02, time/batch = 0.1143s	
1940/5250 (epoch 18.476), train_loss = 1.18750869, grad/param norm = 5.3219e-02, time/batch = 0.1145s	
1941/5250 (epoch 18.486), train_loss = 1.20581177, grad/param norm = 5.6223e-02, time/batch = 0.1157s	
1942/5250 (epoch 18.495), train_loss = 1.20877419, grad/param norm = 5.8240e-02, time/batch = 0.1137s	
1943/5250 (epoch 18.505), train_loss = 1.21214489, grad/param norm = 5.8774e-02, time/batch = 0.1139s	
1944/5250 (epoch 18.514), train_loss = 1.20200321, grad/param norm = 5.9397e-02, time/batch = 0.1140s	
1945/5250 (epoch 18.524), train_loss = 1.20390694, grad/param norm = 6.4142e-02, time/batch = 0.1144s	
1946/5250 (epoch 18.533), train_loss = 1.20768560, grad/param norm = 6.0820e-02, time/batch = 0.1143s	
1947/5250 (epoch 18.543), train_loss = 1.18679465, grad/param norm = 5.5577e-02, time/batch = 0.1142s	
1948/5250 (epoch 18.552), train_loss = 1.19132938, grad/param norm = 5.6981e-02, time/batch = 0.1137s	
1949/5250 (epoch 18.562), train_loss = 1.19794452, grad/param norm = 5.5151e-02, time/batch = 0.1143s	
1950/5250 (epoch 18.571), train_loss = 1.19972291, grad/param norm = 5.5837e-02, time/batch = 0.1143s	
1951/5250 (epoch 18.581), train_loss = 1.21707825, grad/param norm = 5.9477e-02, time/batch = 0.1148s	
1952/5250 (epoch 18.590), train_loss = 1.19911928, grad/param norm = 5.4887e-02, time/batch = 0.1136s	
1953/5250 (epoch 18.600), train_loss = 1.21940417, grad/param norm = 5.6439e-02, time/batch = 0.1139s	
1954/5250 (epoch 18.610), train_loss = 1.21628435, grad/param norm = 5.7689e-02, time/batch = 0.1143s	
1955/5250 (epoch 18.619), train_loss = 1.20560331, grad/param norm = 5.3723e-02, time/batch = 0.1143s	
1956/5250 (epoch 18.629), train_loss = 1.19876181, grad/param norm = 5.0368e-02, time/batch = 0.1143s	
1957/5250 (epoch 18.638), train_loss = 1.19480549, grad/param norm = 5.2235e-02, time/batch = 0.1142s	
1958/5250 (epoch 18.648), train_loss = 1.20636313, grad/param norm = 5.4991e-02, time/batch = 0.1137s	
1959/5250 (epoch 18.657), train_loss = 1.19671024, grad/param norm = 5.5717e-02, time/batch = 0.1143s	
1960/5250 (epoch 18.667), train_loss = 1.19818088, grad/param norm = 5.6130e-02, time/batch = 0.1143s	
1961/5250 (epoch 18.676), train_loss = 1.19033346, grad/param norm = 5.2393e-02, time/batch = 0.1148s	
1962/5250 (epoch 18.686), train_loss = 1.21920139, grad/param norm = 5.4182e-02, time/batch = 0.1136s	
1963/5250 (epoch 18.695), train_loss = 1.20374983, grad/param norm = 6.1042e-02, time/batch = 0.1141s	
1964/5250 (epoch 18.705), train_loss = 1.19422736, grad/param norm = 6.6857e-02, time/batch = 0.1141s	
1965/5250 (epoch 18.714), train_loss = 1.22061961, grad/param norm = 5.9981e-02, time/batch = 0.1142s	
1966/5250 (epoch 18.724), train_loss = 1.19711259, grad/param norm = 5.7784e-02, time/batch = 0.1141s	
1967/5250 (epoch 18.733), train_loss = 1.18213818, grad/param norm = 5.9313e-02, time/batch = 0.1144s	
1968/5250 (epoch 18.743), train_loss = 1.18064039, grad/param norm = 5.5948e-02, time/batch = 0.1136s	
1969/5250 (epoch 18.752), train_loss = 1.18779129, grad/param norm = 6.0198e-02, time/batch = 0.1145s	
1970/5250 (epoch 18.762), train_loss = 1.18565210, grad/param norm = 6.0039e-02, time/batch = 0.1142s	
1971/5250 (epoch 18.771), train_loss = 1.17530240, grad/param norm = 5.9361e-02, time/batch = 0.1155s	
1972/5250 (epoch 18.781), train_loss = 1.19481263, grad/param norm = 5.2339e-02, time/batch = 0.1137s	
1973/5250 (epoch 18.790), train_loss = 1.20271105, grad/param norm = 5.1563e-02, time/batch = 0.1139s	
1974/5250 (epoch 18.800), train_loss = 1.17944020, grad/param norm = 5.6707e-02, time/batch = 0.1142s	
1975/5250 (epoch 18.810), train_loss = 1.19134718, grad/param norm = 5.3367e-02, time/batch = 0.1142s	
1976/5250 (epoch 18.819), train_loss = 1.19953879, grad/param norm = 5.4142e-02, time/batch = 0.1141s	
1977/5250 (epoch 18.829), train_loss = 1.20224721, grad/param norm = 5.2875e-02, time/batch = 0.1141s	
1978/5250 (epoch 18.838), train_loss = 1.17071468, grad/param norm = 5.3641e-02, time/batch = 0.1139s	
1979/5250 (epoch 18.848), train_loss = 1.16767166, grad/param norm = 5.3731e-02, time/batch = 0.1144s	
1980/5250 (epoch 18.857), train_loss = 1.18509723, grad/param norm = 5.3316e-02, time/batch = 0.1143s	
1981/5250 (epoch 18.867), train_loss = 1.18269690, grad/param norm = 5.3125e-02, time/batch = 0.1148s	
1982/5250 (epoch 18.876), train_loss = 1.17874805, grad/param norm = 5.9336e-02, time/batch = 0.1137s	
1983/5250 (epoch 18.886), train_loss = 1.17963067, grad/param norm = 6.0029e-02, time/batch = 0.1140s	
1984/5250 (epoch 18.895), train_loss = 1.21619523, grad/param norm = 6.4833e-02, time/batch = 0.1142s	
1985/5250 (epoch 18.905), train_loss = 1.20814898, grad/param norm = 6.8070e-02, time/batch = 0.1142s	
1986/5250 (epoch 18.914), train_loss = 1.21536031, grad/param norm = 6.3707e-02, time/batch = 0.1142s	
1987/5250 (epoch 18.924), train_loss = 1.21318524, grad/param norm = 5.8828e-02, time/batch = 0.1140s	
1988/5250 (epoch 18.933), train_loss = 1.19371746, grad/param norm = 5.6057e-02, time/batch = 0.1137s	
1989/5250 (epoch 18.943), train_loss = 1.21026418, grad/param norm = 5.2049e-02, time/batch = 0.1141s	
1990/5250 (epoch 18.952), train_loss = 1.21547941, grad/param norm = 5.4389e-02, time/batch = 0.1143s	
1991/5250 (epoch 18.962), train_loss = 1.19210552, grad/param norm = 5.1895e-02, time/batch = 0.1156s	
1992/5250 (epoch 18.971), train_loss = 1.20306787, grad/param norm = 5.3055e-02, time/batch = 0.1139s	
1993/5250 (epoch 18.981), train_loss = 1.22054452, grad/param norm = 5.7383e-02, time/batch = 0.1139s	
1994/5250 (epoch 18.990), train_loss = 1.21256495, grad/param norm = 5.6240e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1995/5250 (epoch 19.000), train_loss = 1.20887680, grad/param norm = 6.7838e-02, time/batch = 0.1141s	
1996/5250 (epoch 19.010), train_loss = 1.38538106, grad/param norm = 7.4251e-02, time/batch = 0.1141s	
1997/5250 (epoch 19.019), train_loss = 1.18626619, grad/param norm = 5.7869e-02, time/batch = 0.1142s	
1998/5250 (epoch 19.029), train_loss = 1.20275507, grad/param norm = 5.2740e-02, time/batch = 0.1138s	
1999/5250 (epoch 19.038), train_loss = 1.18060747, grad/param norm = 5.4096e-02, time/batch = 0.1143s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch19.05_1.4114.t7	
2000/5250 (epoch 19.048), train_loss = 1.15360144, grad/param norm = 4.8688e-02, time/batch = 0.1142s	
2001/5250 (epoch 19.057), train_loss = 1.43922325, grad/param norm = 5.8213e-02, time/batch = 0.1154s	
2002/5250 (epoch 19.067), train_loss = 1.18551195, grad/param norm = 5.6648e-02, time/batch = 0.1138s	
2003/5250 (epoch 19.076), train_loss = 1.20224638, grad/param norm = 6.0713e-02, time/batch = 0.1138s	
2004/5250 (epoch 19.086), train_loss = 1.14148085, grad/param norm = 5.3595e-02, time/batch = 0.1141s	
2005/5250 (epoch 19.095), train_loss = 1.16239545, grad/param norm = 5.0865e-02, time/batch = 0.1145s	
2006/5250 (epoch 19.105), train_loss = 1.19034860, grad/param norm = 4.8789e-02, time/batch = 0.1150s	
2007/5250 (epoch 19.114), train_loss = 1.17166559, grad/param norm = 4.6855e-02, time/batch = 0.1143s	
2008/5250 (epoch 19.124), train_loss = 1.18122590, grad/param norm = 5.2245e-02, time/batch = 0.1139s	
2009/5250 (epoch 19.133), train_loss = 1.17162313, grad/param norm = 5.3683e-02, time/batch = 0.1144s	
2010/5250 (epoch 19.143), train_loss = 1.15179208, grad/param norm = 4.9558e-02, time/batch = 0.1146s	
2011/5250 (epoch 19.152), train_loss = 1.15047619, grad/param norm = 4.9339e-02, time/batch = 0.1150s	
2012/5250 (epoch 19.162), train_loss = 1.19392062, grad/param norm = 6.0511e-02, time/batch = 0.1138s	
2013/5250 (epoch 19.171), train_loss = 1.18628235, grad/param norm = 5.5117e-02, time/batch = 0.1142s	
2014/5250 (epoch 19.181), train_loss = 1.17945419, grad/param norm = 5.3449e-02, time/batch = 0.1142s	
2015/5250 (epoch 19.190), train_loss = 1.18671086, grad/param norm = 5.5695e-02, time/batch = 0.1142s	
2016/5250 (epoch 19.200), train_loss = 1.17165440, grad/param norm = 5.2179e-02, time/batch = 0.1142s	
2017/5250 (epoch 19.210), train_loss = 1.17088573, grad/param norm = 5.0032e-02, time/batch = 0.1143s	
2018/5250 (epoch 19.219), train_loss = 1.21001376, grad/param norm = 5.5842e-02, time/batch = 0.1138s	
2019/5250 (epoch 19.229), train_loss = 1.18523154, grad/param norm = 5.8557e-02, time/batch = 0.1143s	
2020/5250 (epoch 19.238), train_loss = 1.18948117, grad/param norm = 5.7981e-02, time/batch = 0.1143s	
2021/5250 (epoch 19.248), train_loss = 1.17936962, grad/param norm = 5.5298e-02, time/batch = 0.1146s	
2022/5250 (epoch 19.257), train_loss = 1.18007976, grad/param norm = 5.6442e-02, time/batch = 0.1137s	
2023/5250 (epoch 19.267), train_loss = 1.17102754, grad/param norm = 5.7095e-02, time/batch = 0.1139s	
2024/5250 (epoch 19.276), train_loss = 1.17070241, grad/param norm = 5.4949e-02, time/batch = 0.1141s	
2025/5250 (epoch 19.286), train_loss = 1.15522729, grad/param norm = 5.3997e-02, time/batch = 0.1141s	
2026/5250 (epoch 19.295), train_loss = 1.17036041, grad/param norm = 5.0161e-02, time/batch = 0.1141s	
2027/5250 (epoch 19.305), train_loss = 1.16953860, grad/param norm = 5.1866e-02, time/batch = 0.1141s	
2028/5250 (epoch 19.314), train_loss = 1.16282637, grad/param norm = 5.2046e-02, time/batch = 0.1138s	
2029/5250 (epoch 19.324), train_loss = 1.18104239, grad/param norm = 5.3069e-02, time/batch = 0.1143s	
2030/5250 (epoch 19.333), train_loss = 1.18155248, grad/param norm = 5.1439e-02, time/batch = 0.1143s	
2031/5250 (epoch 19.343), train_loss = 1.17812457, grad/param norm = 5.3785e-02, time/batch = 0.1149s	
2032/5250 (epoch 19.352), train_loss = 1.19012785, grad/param norm = 5.4628e-02, time/batch = 0.1137s	
2033/5250 (epoch 19.362), train_loss = 1.18426136, grad/param norm = 5.5605e-02, time/batch = 0.1141s	
2034/5250 (epoch 19.371), train_loss = 1.16700785, grad/param norm = 5.3270e-02, time/batch = 0.1141s	
2035/5250 (epoch 19.381), train_loss = 1.16299698, grad/param norm = 5.1185e-02, time/batch = 0.1142s	
2036/5250 (epoch 19.390), train_loss = 1.17370227, grad/param norm = 5.2888e-02, time/batch = 0.1143s	
2037/5250 (epoch 19.400), train_loss = 1.17364954, grad/param norm = 5.6039e-02, time/batch = 0.1143s	
2038/5250 (epoch 19.410), train_loss = 1.18018684, grad/param norm = 5.7700e-02, time/batch = 0.1138s	
2039/5250 (epoch 19.419), train_loss = 1.17997032, grad/param norm = 5.9422e-02, time/batch = 0.1141s	
2040/5250 (epoch 19.429), train_loss = 1.18412893, grad/param norm = 5.5011e-02, time/batch = 0.1143s	
2041/5250 (epoch 19.438), train_loss = 1.19074630, grad/param norm = 5.3657e-02, time/batch = 0.1152s	
2042/5250 (epoch 19.448), train_loss = 1.16457656, grad/param norm = 5.3754e-02, time/batch = 0.1137s	
2043/5250 (epoch 19.457), train_loss = 1.16813109, grad/param norm = 5.7642e-02, time/batch = 0.1139s	
2044/5250 (epoch 19.467), train_loss = 1.17759798, grad/param norm = 5.6204e-02, time/batch = 0.1141s	
2045/5250 (epoch 19.476), train_loss = 1.17461363, grad/param norm = 5.6672e-02, time/batch = 0.1142s	
2046/5250 (epoch 19.486), train_loss = 1.19099262, grad/param norm = 5.3883e-02, time/batch = 0.1142s	
2047/5250 (epoch 19.495), train_loss = 1.19340735, grad/param norm = 5.3063e-02, time/batch = 0.1141s	
2048/5250 (epoch 19.505), train_loss = 1.19397676, grad/param norm = 5.3945e-02, time/batch = 0.1136s	
2049/5250 (epoch 19.514), train_loss = 1.18288660, grad/param norm = 5.4294e-02, time/batch = 0.1143s	
2050/5250 (epoch 19.524), train_loss = 1.18632990, grad/param norm = 5.8510e-02, time/batch = 0.1144s	
2051/5250 (epoch 19.533), train_loss = 1.19157211, grad/param norm = 5.8085e-02, time/batch = 0.1149s	
2052/5250 (epoch 19.543), train_loss = 1.17280929, grad/param norm = 5.5395e-02, time/batch = 0.1137s	
2053/5250 (epoch 19.552), train_loss = 1.17788051, grad/param norm = 5.7910e-02, time/batch = 0.1140s	
2054/5250 (epoch 19.562), train_loss = 1.18428829, grad/param norm = 5.6098e-02, time/batch = 0.1141s	
2055/5250 (epoch 19.571), train_loss = 1.18627374, grad/param norm = 5.7597e-02, time/batch = 0.1144s	
2056/5250 (epoch 19.581), train_loss = 1.20245382, grad/param norm = 6.0466e-02, time/batch = 0.1143s	
2057/5250 (epoch 19.590), train_loss = 1.18619223, grad/param norm = 5.6549e-02, time/batch = 0.1142s	
2058/5250 (epoch 19.600), train_loss = 1.20505375, grad/param norm = 5.6016e-02, time/batch = 0.1136s	
2059/5250 (epoch 19.610), train_loss = 1.20223034, grad/param norm = 5.9672e-02, time/batch = 0.1143s	
2060/5250 (epoch 19.619), train_loss = 1.19366416, grad/param norm = 5.9464e-02, time/batch = 0.1142s	
2061/5250 (epoch 19.629), train_loss = 1.18639143, grad/param norm = 5.6955e-02, time/batch = 0.1148s	
2062/5250 (epoch 19.638), train_loss = 1.18533041, grad/param norm = 6.0511e-02, time/batch = 0.1137s	
2063/5250 (epoch 19.648), train_loss = 1.19683701, grad/param norm = 5.8469e-02, time/batch = 0.1138s	
2064/5250 (epoch 19.657), train_loss = 1.18428637, grad/param norm = 5.8113e-02, time/batch = 0.1141s	
2065/5250 (epoch 19.667), train_loss = 1.18867420, grad/param norm = 5.8608e-02, time/batch = 0.1141s	
2066/5250 (epoch 19.676), train_loss = 1.18105195, grad/param norm = 6.2264e-02, time/batch = 0.1143s	
2067/5250 (epoch 19.686), train_loss = 1.21159508, grad/param norm = 6.3171e-02, time/batch = 0.1142s	
2068/5250 (epoch 19.695), train_loss = 1.18439186, grad/param norm = 5.3775e-02, time/batch = 0.1138s	
2069/5250 (epoch 19.705), train_loss = 1.17063865, grad/param norm = 5.4229e-02, time/batch = 0.1143s	
2070/5250 (epoch 19.714), train_loss = 1.20337455, grad/param norm = 5.6562e-02, time/batch = 0.1144s	
2071/5250 (epoch 19.724), train_loss = 1.17838629, grad/param norm = 5.3834e-02, time/batch = 0.1150s	
2072/5250 (epoch 19.733), train_loss = 1.16360042, grad/param norm = 5.3360e-02, time/batch = 0.1137s	
2073/5250 (epoch 19.743), train_loss = 1.16784646, grad/param norm = 5.9241e-02, time/batch = 0.1140s	
2074/5250 (epoch 19.752), train_loss = 1.17436656, grad/param norm = 6.3636e-02, time/batch = 0.1140s	
2075/5250 (epoch 19.762), train_loss = 1.16809638, grad/param norm = 5.5428e-02, time/batch = 0.1144s	
2076/5250 (epoch 19.771), train_loss = 1.15758591, grad/param norm = 5.3423e-02, time/batch = 0.1142s	
2077/5250 (epoch 19.781), train_loss = 1.17935833, grad/param norm = 5.2857e-02, time/batch = 0.1143s	
2078/5250 (epoch 19.790), train_loss = 1.18759252, grad/param norm = 5.1818e-02, time/batch = 0.1137s	
2079/5250 (epoch 19.800), train_loss = 1.16219669, grad/param norm = 5.5438e-02, time/batch = 0.1144s	
2080/5250 (epoch 19.810), train_loss = 1.17600742, grad/param norm = 5.2924e-02, time/batch = 0.1144s	
2081/5250 (epoch 19.819), train_loss = 1.18665392, grad/param norm = 5.5966e-02, time/batch = 0.1148s	
2082/5250 (epoch 19.829), train_loss = 1.18905458, grad/param norm = 5.3449e-02, time/batch = 0.1137s	
2083/5250 (epoch 19.838), train_loss = 1.15386781, grad/param norm = 4.9509e-02, time/batch = 0.1140s	
2084/5250 (epoch 19.848), train_loss = 1.15218271, grad/param norm = 5.2744e-02, time/batch = 0.1141s	
2085/5250 (epoch 19.857), train_loss = 1.17129876, grad/param norm = 6.0285e-02, time/batch = 0.1142s	
2086/5250 (epoch 19.867), train_loss = 1.17362385, grad/param norm = 6.0466e-02, time/batch = 0.1142s	
2087/5250 (epoch 19.876), train_loss = 1.16529108, grad/param norm = 5.8069e-02, time/batch = 0.1141s	
2088/5250 (epoch 19.886), train_loss = 1.16342201, grad/param norm = 6.1739e-02, time/batch = 0.1138s	
2089/5250 (epoch 19.895), train_loss = 1.20212307, grad/param norm = 6.3846e-02, time/batch = 0.1143s	
2090/5250 (epoch 19.905), train_loss = 1.18770823, grad/param norm = 5.7256e-02, time/batch = 0.1144s	
2091/5250 (epoch 19.914), train_loss = 1.19184969, grad/param norm = 5.2347e-02, time/batch = 0.1148s	
2092/5250 (epoch 19.924), train_loss = 1.19445583, grad/param norm = 5.4482e-02, time/batch = 0.1136s	
2093/5250 (epoch 19.933), train_loss = 1.18070385, grad/param norm = 5.7740e-02, time/batch = 0.1139s	
2094/5250 (epoch 19.943), train_loss = 1.19635045, grad/param norm = 5.4467e-02, time/batch = 0.1142s	
2095/5250 (epoch 19.952), train_loss = 1.20370003, grad/param norm = 5.6361e-02, time/batch = 0.1143s	
2096/5250 (epoch 19.962), train_loss = 1.17886416, grad/param norm = 5.3463e-02, time/batch = 0.1141s	
2097/5250 (epoch 19.971), train_loss = 1.18903877, grad/param norm = 5.2798e-02, time/batch = 0.1142s	
2098/5250 (epoch 19.981), train_loss = 1.20163846, grad/param norm = 5.2480e-02, time/batch = 0.1137s	
2099/5250 (epoch 19.990), train_loss = 1.19459089, grad/param norm = 5.2955e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
2100/5250 (epoch 20.000), train_loss = 1.18902120, grad/param norm = 5.9556e-02, time/batch = 0.1141s	
2101/5250 (epoch 20.010), train_loss = 1.35979138, grad/param norm = 6.0271e-02, time/batch = 0.1148s	
2102/5250 (epoch 20.019), train_loss = 1.16658621, grad/param norm = 5.0286e-02, time/batch = 0.1136s	
2103/5250 (epoch 20.029), train_loss = 1.18794211, grad/param norm = 4.9852e-02, time/batch = 0.1138s	
2104/5250 (epoch 20.038), train_loss = 1.16677226, grad/param norm = 5.2348e-02, time/batch = 0.1143s	
2105/5250 (epoch 20.048), train_loss = 1.13967876, grad/param norm = 4.9817e-02, time/batch = 0.1143s	
2106/5250 (epoch 20.057), train_loss = 1.15477314, grad/param norm = 4.8962e-02, time/batch = 0.1143s	
2107/5250 (epoch 20.067), train_loss = 1.16369301, grad/param norm = 5.0167e-02, time/batch = 0.1143s	
2108/5250 (epoch 20.076), train_loss = 1.18405387, grad/param norm = 5.7761e-02, time/batch = 0.1137s	
2109/5250 (epoch 20.086), train_loss = 1.12874707, grad/param norm = 5.3556e-02, time/batch = 0.1142s	
2110/5250 (epoch 20.095), train_loss = 1.14844901, grad/param norm = 5.1691e-02, time/batch = 0.1145s	
2111/5250 (epoch 20.105), train_loss = 1.17768886, grad/param norm = 5.2783e-02, time/batch = 0.1149s	
2112/5250 (epoch 20.114), train_loss = 1.15949158, grad/param norm = 5.0191e-02, time/batch = 0.1137s	
2113/5250 (epoch 20.124), train_loss = 1.17025881, grad/param norm = 5.5746e-02, time/batch = 0.1139s	
2114/5250 (epoch 20.133), train_loss = 1.16017745, grad/param norm = 5.7217e-02, time/batch = 0.1139s	
2115/5250 (epoch 20.143), train_loss = 1.13913416, grad/param norm = 5.3448e-02, time/batch = 0.1142s	
2116/5250 (epoch 20.152), train_loss = 1.13908063, grad/param norm = 5.2006e-02, time/batch = 0.1142s	
2117/5250 (epoch 20.162), train_loss = 1.17752892, grad/param norm = 5.6219e-02, time/batch = 0.1141s	
2118/5250 (epoch 20.171), train_loss = 1.16896917, grad/param norm = 5.3951e-02, time/batch = 0.1136s	
2119/5250 (epoch 20.181), train_loss = 1.16311133, grad/param norm = 5.4376e-02, time/batch = 0.1141s	
2120/5250 (epoch 20.190), train_loss = 1.17320376, grad/param norm = 5.9298e-02, time/batch = 0.1144s	
2121/5250 (epoch 20.200), train_loss = 1.16017218, grad/param norm = 5.4843e-02, time/batch = 0.1148s	
2122/5250 (epoch 20.210), train_loss = 1.15897792, grad/param norm = 5.4855e-02, time/batch = 0.1136s	
2123/5250 (epoch 20.219), train_loss = 1.19790228, grad/param norm = 5.8124e-02, time/batch = 0.1141s	
2124/5250 (epoch 20.229), train_loss = 1.17273242, grad/param norm = 5.9096e-02, time/batch = 0.1141s	
2125/5250 (epoch 20.238), train_loss = 1.17509114, grad/param norm = 5.8682e-02, time/batch = 0.1143s	
2126/5250 (epoch 20.248), train_loss = 1.16505990, grad/param norm = 5.3012e-02, time/batch = 0.1141s	
2127/5250 (epoch 20.257), train_loss = 1.16491500, grad/param norm = 5.3374e-02, time/batch = 0.1143s	
2128/5250 (epoch 20.267), train_loss = 1.15410127, grad/param norm = 5.2322e-02, time/batch = 0.1136s	
2129/5250 (epoch 20.276), train_loss = 1.15562455, grad/param norm = 5.5434e-02, time/batch = 0.1144s	
2130/5250 (epoch 20.286), train_loss = 1.14088815, grad/param norm = 5.2301e-02, time/batch = 0.1144s	
2131/5250 (epoch 20.295), train_loss = 1.16032595, grad/param norm = 6.0323e-02, time/batch = 0.1151s	
2132/5250 (epoch 20.305), train_loss = 1.16275462, grad/param norm = 5.9799e-02, time/batch = 0.1137s	
2133/5250 (epoch 20.314), train_loss = 1.15316688, grad/param norm = 5.7924e-02, time/batch = 0.1140s	
2134/5250 (epoch 20.324), train_loss = 1.16996126, grad/param norm = 5.6176e-02, time/batch = 0.1140s	
2135/5250 (epoch 20.333), train_loss = 1.17190899, grad/param norm = 5.9586e-02, time/batch = 0.1142s	
2136/5250 (epoch 20.343), train_loss = 1.16770388, grad/param norm = 5.9065e-02, time/batch = 0.1142s	
2137/5250 (epoch 20.352), train_loss = 1.17785218, grad/param norm = 5.8564e-02, time/batch = 0.1141s	
2138/5250 (epoch 20.362), train_loss = 1.17274566, grad/param norm = 5.7881e-02, time/batch = 0.1137s	
2139/5250 (epoch 20.371), train_loss = 1.15428701, grad/param norm = 5.5399e-02, time/batch = 0.1143s	
2140/5250 (epoch 20.381), train_loss = 1.15274485, grad/param norm = 5.6066e-02, time/batch = 0.1144s	
2141/5250 (epoch 20.390), train_loss = 1.15932662, grad/param norm = 5.4196e-02, time/batch = 0.1149s	
2142/5250 (epoch 20.400), train_loss = 1.15683584, grad/param norm = 5.3711e-02, time/batch = 0.1137s	
2143/5250 (epoch 20.410), train_loss = 1.16815804, grad/param norm = 6.3477e-02, time/batch = 0.1140s	
2144/5250 (epoch 20.419), train_loss = 1.16812243, grad/param norm = 6.5986e-02, time/batch = 0.1141s	
2145/5250 (epoch 20.429), train_loss = 1.17336774, grad/param norm = 5.8601e-02, time/batch = 0.1143s	
2146/5250 (epoch 20.438), train_loss = 1.18173116, grad/param norm = 6.1195e-02, time/batch = 0.1143s	
2147/5250 (epoch 20.448), train_loss = 1.15231590, grad/param norm = 5.7717e-02, time/batch = 0.1140s	
2148/5250 (epoch 20.457), train_loss = 1.15422693, grad/param norm = 5.5186e-02, time/batch = 0.1137s	
2149/5250 (epoch 20.467), train_loss = 1.15917938, grad/param norm = 5.3369e-02, time/batch = 0.1143s	
2150/5250 (epoch 20.476), train_loss = 1.16244780, grad/param norm = 5.9124e-02, time/batch = 0.1143s	
2151/5250 (epoch 20.486), train_loss = 1.18084594, grad/param norm = 5.6508e-02, time/batch = 0.1149s	
2152/5250 (epoch 20.495), train_loss = 1.17698768, grad/param norm = 5.4486e-02, time/batch = 0.1136s	
2153/5250 (epoch 20.505), train_loss = 1.18068037, grad/param norm = 5.2761e-02, time/batch = 0.1139s	
2154/5250 (epoch 20.514), train_loss = 1.16937187, grad/param norm = 5.3323e-02, time/batch = 0.1140s	
2155/5250 (epoch 20.524), train_loss = 1.17369445, grad/param norm = 6.2370e-02, time/batch = 0.1143s	
2156/5250 (epoch 20.533), train_loss = 1.17944835, grad/param norm = 5.7265e-02, time/batch = 0.1141s	
2157/5250 (epoch 20.543), train_loss = 1.15613549, grad/param norm = 5.3503e-02, time/batch = 0.1140s	
2158/5250 (epoch 20.552), train_loss = 1.16101315, grad/param norm = 5.6678e-02, time/batch = 0.1136s	
2159/5250 (epoch 20.562), train_loss = 1.16773153, grad/param norm = 5.3522e-02, time/batch = 0.1142s	
2160/5250 (epoch 20.571), train_loss = 1.16980366, grad/param norm = 5.2982e-02, time/batch = 0.1145s	
2161/5250 (epoch 20.581), train_loss = 1.18351509, grad/param norm = 5.8344e-02, time/batch = 0.1147s	
2162/5250 (epoch 20.590), train_loss = 1.16896556, grad/param norm = 5.2939e-02, time/batch = 0.1136s	
2163/5250 (epoch 20.600), train_loss = 1.18805376, grad/param norm = 5.4671e-02, time/batch = 0.1139s	
2164/5250 (epoch 20.610), train_loss = 1.18622077, grad/param norm = 5.8100e-02, time/batch = 0.1141s	
2165/5250 (epoch 20.619), train_loss = 1.18055496, grad/param norm = 6.0647e-02, time/batch = 0.1143s	
2166/5250 (epoch 20.629), train_loss = 1.17567582, grad/param norm = 5.8882e-02, time/batch = 0.1142s	
2167/5250 (epoch 20.638), train_loss = 1.17160281, grad/param norm = 5.7078e-02, time/batch = 0.1141s	
2168/5250 (epoch 20.648), train_loss = 1.18059571, grad/param norm = 5.7478e-02, time/batch = 0.1137s	
2169/5250 (epoch 20.657), train_loss = 1.17108712, grad/param norm = 5.8724e-02, time/batch = 0.1142s	
2170/5250 (epoch 20.667), train_loss = 1.17134761, grad/param norm = 5.5510e-02, time/batch = 0.1146s	
2171/5250 (epoch 20.676), train_loss = 1.16076641, grad/param norm = 5.0414e-02, time/batch = 0.1150s	
2172/5250 (epoch 20.686), train_loss = 1.18995404, grad/param norm = 5.2993e-02, time/batch = 0.1137s	
2173/5250 (epoch 20.695), train_loss = 1.17312595, grad/param norm = 5.9571e-02, time/batch = 0.1140s	
2174/5250 (epoch 20.705), train_loss = 1.16002974, grad/param norm = 6.2210e-02, time/batch = 0.1142s	
2175/5250 (epoch 20.714), train_loss = 1.18781891, grad/param norm = 5.5717e-02, time/batch = 0.1142s	
2176/5250 (epoch 20.724), train_loss = 1.16529454, grad/param norm = 5.3442e-02, time/batch = 0.1142s	
2177/5250 (epoch 20.733), train_loss = 1.15184588, grad/param norm = 5.7514e-02, time/batch = 0.1142s	
2178/5250 (epoch 20.743), train_loss = 1.15124095, grad/param norm = 5.5928e-02, time/batch = 0.1137s	
2179/5250 (epoch 20.752), train_loss = 1.15718437, grad/param norm = 5.7833e-02, time/batch = 0.1143s	
2180/5250 (epoch 20.762), train_loss = 1.15629316, grad/param norm = 5.8640e-02, time/batch = 0.1143s	
2181/5250 (epoch 20.771), train_loss = 1.14612950, grad/param norm = 5.8288e-02, time/batch = 0.1148s	
2182/5250 (epoch 20.781), train_loss = 1.16735706, grad/param norm = 5.4824e-02, time/batch = 0.1135s	
2183/5250 (epoch 20.790), train_loss = 1.17477879, grad/param norm = 5.3929e-02, time/batch = 0.1140s	
2184/5250 (epoch 20.800), train_loss = 1.14903344, grad/param norm = 5.6344e-02, time/batch = 0.1142s	
2185/5250 (epoch 20.810), train_loss = 1.16345791, grad/param norm = 5.5113e-02, time/batch = 0.1143s	
2186/5250 (epoch 20.819), train_loss = 1.17211691, grad/param norm = 5.4302e-02, time/batch = 0.1142s	
2187/5250 (epoch 20.829), train_loss = 1.17300159, grad/param norm = 5.2345e-02, time/batch = 0.1143s	
2188/5250 (epoch 20.838), train_loss = 1.14146690, grad/param norm = 5.2359e-02, time/batch = 0.1136s	
2189/5250 (epoch 20.848), train_loss = 1.13821328, grad/param norm = 5.4740e-02, time/batch = 0.1143s	
2190/5250 (epoch 20.857), train_loss = 1.15558895, grad/param norm = 5.7250e-02, time/batch = 0.1144s	
2191/5250 (epoch 20.867), train_loss = 1.15603147, grad/param norm = 5.5087e-02, time/batch = 0.1149s	
2192/5250 (epoch 20.876), train_loss = 1.14818660, grad/param norm = 5.6171e-02, time/batch = 0.1135s	
2193/5250 (epoch 20.886), train_loss = 1.14789452, grad/param norm = 6.1232e-02, time/batch = 0.1139s	
2194/5250 (epoch 20.895), train_loss = 1.18797769, grad/param norm = 6.5202e-02, time/batch = 0.1139s	
2195/5250 (epoch 20.905), train_loss = 1.17293677, grad/param norm = 5.6901e-02, time/batch = 0.1143s	
2196/5250 (epoch 20.914), train_loss = 1.17876838, grad/param norm = 5.7283e-02, time/batch = 0.1142s	
2197/5250 (epoch 20.924), train_loss = 1.18424112, grad/param norm = 5.7961e-02, time/batch = 0.1142s	
2198/5250 (epoch 20.933), train_loss = 1.16651347, grad/param norm = 5.5671e-02, time/batch = 0.1137s	
2199/5250 (epoch 20.943), train_loss = 1.18225462, grad/param norm = 5.5791e-02, time/batch = 0.1144s	
2200/5250 (epoch 20.952), train_loss = 1.19434331, grad/param norm = 6.5513e-02, time/batch = 0.1143s	
2201/5250 (epoch 20.962), train_loss = 1.16717233, grad/param norm = 5.6121e-02, time/batch = 0.1148s	
2202/5250 (epoch 20.971), train_loss = 1.17668544, grad/param norm = 5.5187e-02, time/batch = 0.1137s	
2203/5250 (epoch 20.981), train_loss = 1.19116838, grad/param norm = 6.1819e-02, time/batch = 0.1140s	
2204/5250 (epoch 20.990), train_loss = 1.18515470, grad/param norm = 5.8443e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
2205/5250 (epoch 21.000), train_loss = 1.17172624, grad/param norm = 5.3478e-02, time/batch = 0.1144s	
2206/5250 (epoch 21.010), train_loss = 1.34411770, grad/param norm = 5.9152e-02, time/batch = 0.1142s	
2207/5250 (epoch 21.019), train_loss = 1.15629180, grad/param norm = 5.9829e-02, time/batch = 0.1143s	
2208/5250 (epoch 21.029), train_loss = 1.18146998, grad/param norm = 5.9325e-02, time/batch = 0.1138s	
2209/5250 (epoch 21.038), train_loss = 1.15841514, grad/param norm = 5.8613e-02, time/batch = 0.1142s	
2210/5250 (epoch 21.048), train_loss = 1.12886736, grad/param norm = 5.2913e-02, time/batch = 0.1145s	
2211/5250 (epoch 21.057), train_loss = 1.14077110, grad/param norm = 5.0487e-02, time/batch = 0.1149s	
2212/5250 (epoch 21.067), train_loss = 1.14935979, grad/param norm = 4.9944e-02, time/batch = 0.1137s	
2213/5250 (epoch 21.076), train_loss = 1.16729580, grad/param norm = 5.3583e-02, time/batch = 0.1139s	
2214/5250 (epoch 21.086), train_loss = 1.11190419, grad/param norm = 5.0266e-02, time/batch = 0.1140s	
2215/5250 (epoch 21.095), train_loss = 1.13333248, grad/param norm = 5.0632e-02, time/batch = 0.1144s	
2216/5250 (epoch 21.105), train_loss = 1.16226121, grad/param norm = 5.0783e-02, time/batch = 0.1140s	
2217/5250 (epoch 21.114), train_loss = 1.14476142, grad/param norm = 4.9428e-02, time/batch = 0.1141s	
2218/5250 (epoch 21.124), train_loss = 1.15692448, grad/param norm = 5.5075e-02, time/batch = 0.1136s	
2219/5250 (epoch 21.133), train_loss = 1.14426909, grad/param norm = 5.5008e-02, time/batch = 0.1142s	
2220/5250 (epoch 21.143), train_loss = 1.12504785, grad/param norm = 5.1376e-02, time/batch = 0.1145s	
2221/5250 (epoch 21.152), train_loss = 1.12434114, grad/param norm = 5.0039e-02, time/batch = 0.1148s	
2222/5250 (epoch 21.162), train_loss = 1.16289809, grad/param norm = 5.9885e-02, time/batch = 0.1136s	
2223/5250 (epoch 21.171), train_loss = 1.15621020, grad/param norm = 5.3730e-02, time/batch = 0.1142s	
2224/5250 (epoch 21.181), train_loss = 1.15016847, grad/param norm = 5.4500e-02, time/batch = 0.1142s	
2225/5250 (epoch 21.190), train_loss = 1.15803967, grad/param norm = 5.7499e-02, time/batch = 0.1142s	
2226/5250 (epoch 21.200), train_loss = 1.14608988, grad/param norm = 5.4372e-02, time/batch = 0.1142s	
2227/5250 (epoch 21.210), train_loss = 1.14517205, grad/param norm = 5.3756e-02, time/batch = 0.1143s	
2228/5250 (epoch 21.219), train_loss = 1.18359622, grad/param norm = 5.8916e-02, time/batch = 0.1135s	
2229/5250 (epoch 21.229), train_loss = 1.15853505, grad/param norm = 5.6983e-02, time/batch = 0.1141s	
2230/5250 (epoch 21.238), train_loss = 1.16009255, grad/param norm = 5.8951e-02, time/batch = 0.1143s	
2231/5250 (epoch 21.248), train_loss = 1.15470725, grad/param norm = 6.1164e-02, time/batch = 0.1149s	
2232/5250 (epoch 21.257), train_loss = 1.15606654, grad/param norm = 5.9141e-02, time/batch = 0.1136s	
2233/5250 (epoch 21.267), train_loss = 1.14264770, grad/param norm = 5.2957e-02, time/batch = 0.1139s	
2234/5250 (epoch 21.276), train_loss = 1.14004095, grad/param norm = 5.2728e-02, time/batch = 0.1139s	
2235/5250 (epoch 21.286), train_loss = 1.12606085, grad/param norm = 5.1193e-02, time/batch = 0.1141s	
2236/5250 (epoch 21.295), train_loss = 1.14294761, grad/param norm = 5.3134e-02, time/batch = 0.1142s	
2237/5250 (epoch 21.305), train_loss = 1.14509151, grad/param norm = 5.3604e-02, time/batch = 0.1142s	
2238/5250 (epoch 21.314), train_loss = 1.13806586, grad/param norm = 5.3598e-02, time/batch = 0.1137s	
2239/5250 (epoch 21.324), train_loss = 1.15558395, grad/param norm = 5.6576e-02, time/batch = 0.1144s	
2240/5250 (epoch 21.333), train_loss = 1.15809952, grad/param norm = 5.8974e-02, time/batch = 0.1143s	
2241/5250 (epoch 21.343), train_loss = 1.15535499, grad/param norm = 5.9403e-02, time/batch = 0.1149s	
2242/5250 (epoch 21.352), train_loss = 1.16249523, grad/param norm = 5.6182e-02, time/batch = 0.1137s	
2243/5250 (epoch 21.362), train_loss = 1.15853761, grad/param norm = 5.6170e-02, time/batch = 0.1140s	
2244/5250 (epoch 21.371), train_loss = 1.13914551, grad/param norm = 5.3871e-02, time/batch = 0.1142s	
2245/5250 (epoch 21.381), train_loss = 1.13856651, grad/param norm = 5.5595e-02, time/batch = 0.1142s	
2246/5250 (epoch 21.390), train_loss = 1.14644127, grad/param norm = 5.6924e-02, time/batch = 0.1142s	
2247/5250 (epoch 21.400), train_loss = 1.14763762, grad/param norm = 5.9974e-02, time/batch = 0.1144s	
2248/5250 (epoch 21.410), train_loss = 1.15547632, grad/param norm = 6.1726e-02, time/batch = 0.1138s	
2249/5250 (epoch 21.419), train_loss = 1.15355303, grad/param norm = 5.9855e-02, time/batch = 0.1143s	
2250/5250 (epoch 21.429), train_loss = 1.15637918, grad/param norm = 5.5772e-02, time/batch = 0.1143s	
2251/5250 (epoch 21.438), train_loss = 1.16410870, grad/param norm = 5.7541e-02, time/batch = 0.1156s	
2252/5250 (epoch 21.448), train_loss = 1.13606955, grad/param norm = 5.3455e-02, time/batch = 0.1138s	
2253/5250 (epoch 21.457), train_loss = 1.14247444, grad/param norm = 5.5711e-02, time/batch = 0.1140s	
2254/5250 (epoch 21.467), train_loss = 1.14654035, grad/param norm = 5.3430e-02, time/batch = 0.1144s	
2255/5250 (epoch 21.476), train_loss = 1.14738107, grad/param norm = 5.6127e-02, time/batch = 0.1140s	
2256/5250 (epoch 21.486), train_loss = 1.16742649, grad/param norm = 5.6690e-02, time/batch = 0.1143s	
2257/5250 (epoch 21.495), train_loss = 1.16689527, grad/param norm = 5.6035e-02, time/batch = 0.1141s	
2258/5250 (epoch 21.505), train_loss = 1.16685022, grad/param norm = 5.5098e-02, time/batch = 0.1136s	
2259/5250 (epoch 21.514), train_loss = 1.15799294, grad/param norm = 5.7605e-02, time/batch = 0.1144s	
2260/5250 (epoch 21.524), train_loss = 1.15920121, grad/param norm = 6.1922e-02, time/batch = 0.1142s	
2261/5250 (epoch 21.533), train_loss = 1.16397915, grad/param norm = 5.2610e-02, time/batch = 0.1151s	
2262/5250 (epoch 21.543), train_loss = 1.14358633, grad/param norm = 5.2543e-02, time/batch = 0.1136s	
2263/5250 (epoch 21.552), train_loss = 1.14491495, grad/param norm = 5.4886e-02, time/batch = 0.1140s	
2264/5250 (epoch 21.562), train_loss = 1.15397883, grad/param norm = 5.2599e-02, time/batch = 0.1142s	
2265/5250 (epoch 21.571), train_loss = 1.15773010, grad/param norm = 5.5598e-02, time/batch = 0.1144s	
2266/5250 (epoch 21.581), train_loss = 1.16924635, grad/param norm = 5.9427e-02, time/batch = 0.1143s	
2267/5250 (epoch 21.590), train_loss = 1.15685430, grad/param norm = 5.4000e-02, time/batch = 0.1142s	
2268/5250 (epoch 21.600), train_loss = 1.17491936, grad/param norm = 5.4976e-02, time/batch = 0.1138s	
2269/5250 (epoch 21.610), train_loss = 1.17116349, grad/param norm = 5.7231e-02, time/batch = 0.1141s	
2270/5250 (epoch 21.619), train_loss = 1.16202807, grad/param norm = 5.2415e-02, time/batch = 0.1144s	
2271/5250 (epoch 21.629), train_loss = 1.15685329, grad/param norm = 5.4390e-02, time/batch = 0.1147s	
2272/5250 (epoch 21.638), train_loss = 1.15514933, grad/param norm = 5.5005e-02, time/batch = 0.1135s	
2273/5250 (epoch 21.648), train_loss = 1.16653551, grad/param norm = 5.9513e-02, time/batch = 0.1138s	
2274/5250 (epoch 21.657), train_loss = 1.15526487, grad/param norm = 5.4535e-02, time/batch = 0.1141s	
2275/5250 (epoch 21.667), train_loss = 1.15596563, grad/param norm = 5.2407e-02, time/batch = 0.1142s	
2276/5250 (epoch 21.676), train_loss = 1.14987246, grad/param norm = 5.5271e-02, time/batch = 0.1143s	
2277/5250 (epoch 21.686), train_loss = 1.17906154, grad/param norm = 5.8823e-02, time/batch = 0.1143s	
2278/5250 (epoch 21.695), train_loss = 1.15882818, grad/param norm = 5.7168e-02, time/batch = 0.1137s	
2279/5250 (epoch 21.705), train_loss = 1.14430964, grad/param norm = 5.7679e-02, time/batch = 0.1143s	
2280/5250 (epoch 21.714), train_loss = 1.17482992, grad/param norm = 5.7284e-02, time/batch = 0.1143s	
2281/5250 (epoch 21.724), train_loss = 1.15248686, grad/param norm = 5.4347e-02, time/batch = 0.1150s	
2282/5250 (epoch 21.733), train_loss = 1.13765221, grad/param norm = 5.6628e-02, time/batch = 0.1137s	
2283/5250 (epoch 21.743), train_loss = 1.14442255, grad/param norm = 6.3015e-02, time/batch = 0.1141s	
2284/5250 (epoch 21.752), train_loss = 1.14716816, grad/param norm = 6.2171e-02, time/batch = 0.1142s	
2285/5250 (epoch 21.762), train_loss = 1.14377941, grad/param norm = 5.7150e-02, time/batch = 0.1141s	
2286/5250 (epoch 21.771), train_loss = 1.13214873, grad/param norm = 5.4824e-02, time/batch = 0.1142s	
2287/5250 (epoch 21.781), train_loss = 1.15194671, grad/param norm = 5.3348e-02, time/batch = 0.1143s	
2288/5250 (epoch 21.790), train_loss = 1.16074315, grad/param norm = 5.5064e-02, time/batch = 0.1136s	
2289/5250 (epoch 21.800), train_loss = 1.13626984, grad/param norm = 5.8666e-02, time/batch = 0.1143s	
2290/5250 (epoch 21.810), train_loss = 1.14863642, grad/param norm = 5.5225e-02, time/batch = 0.1144s	
2291/5250 (epoch 21.819), train_loss = 1.16257831, grad/param norm = 5.9393e-02, time/batch = 0.1150s	
2292/5250 (epoch 21.829), train_loss = 1.16184366, grad/param norm = 5.7050e-02, time/batch = 0.1135s	
2293/5250 (epoch 21.838), train_loss = 1.12883881, grad/param norm = 5.3875e-02, time/batch = 0.1141s	
2294/5250 (epoch 21.848), train_loss = 1.12481519, grad/param norm = 5.5027e-02, time/batch = 0.1142s	
2295/5250 (epoch 21.857), train_loss = 1.14189728, grad/param norm = 5.7562e-02, time/batch = 0.1143s	
2296/5250 (epoch 21.867), train_loss = 1.14334001, grad/param norm = 5.5404e-02, time/batch = 0.1140s	
2297/5250 (epoch 21.876), train_loss = 1.13688644, grad/param norm = 6.1028e-02, time/batch = 0.1142s	
2298/5250 (epoch 21.886), train_loss = 1.13926093, grad/param norm = 6.9878e-02, time/batch = 0.1137s	
2299/5250 (epoch 21.895), train_loss = 1.17449356, grad/param norm = 6.4428e-02, time/batch = 0.1144s	
2300/5250 (epoch 21.905), train_loss = 1.15782276, grad/param norm = 5.4276e-02, time/batch = 0.1145s	
2301/5250 (epoch 21.914), train_loss = 1.16573165, grad/param norm = 6.1346e-02, time/batch = 0.1148s	
2302/5250 (epoch 21.924), train_loss = 1.17460548, grad/param norm = 6.0594e-02, time/batch = 0.1137s	
2303/5250 (epoch 21.933), train_loss = 1.15691988, grad/param norm = 5.9114e-02, time/batch = 0.1139s	
2304/5250 (epoch 21.943), train_loss = 1.17107167, grad/param norm = 5.8269e-02, time/batch = 0.1142s	
2305/5250 (epoch 21.952), train_loss = 1.17950621, grad/param norm = 6.3346e-02, time/batch = 0.1142s	
2306/5250 (epoch 21.962), train_loss = 1.15261187, grad/param norm = 5.3340e-02, time/batch = 0.1142s	
2307/5250 (epoch 21.971), train_loss = 1.16194452, grad/param norm = 5.3205e-02, time/batch = 0.1143s	
2308/5250 (epoch 21.981), train_loss = 1.17409979, grad/param norm = 5.6916e-02, time/batch = 0.1137s	
2309/5250 (epoch 21.990), train_loss = 1.16890001, grad/param norm = 5.5518e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
2310/5250 (epoch 22.000), train_loss = 1.16174320, grad/param norm = 6.1136e-02, time/batch = 0.1143s	
2311/5250 (epoch 22.010), train_loss = 1.33846615, grad/param norm = 6.5660e-02, time/batch = 0.1149s	
2312/5250 (epoch 22.019), train_loss = 1.14372726, grad/param norm = 5.7259e-02, time/batch = 0.1136s	
2313/5250 (epoch 22.029), train_loss = 1.16513254, grad/param norm = 5.3994e-02, time/batch = 0.1140s	
2314/5250 (epoch 22.038), train_loss = 1.14237159, grad/param norm = 5.5889e-02, time/batch = 0.1140s	
2315/5250 (epoch 22.048), train_loss = 1.11418486, grad/param norm = 5.1496e-02, time/batch = 0.1143s	
2316/5250 (epoch 22.057), train_loss = 1.12772525, grad/param norm = 5.1055e-02, time/batch = 0.1142s	
2317/5250 (epoch 22.067), train_loss = 1.13767387, grad/param norm = 5.1881e-02, time/batch = 0.1142s	
2318/5250 (epoch 22.076), train_loss = 1.15710955, grad/param norm = 5.4296e-02, time/batch = 0.1137s	
2319/5250 (epoch 22.086), train_loss = 1.09918212, grad/param norm = 5.0408e-02, time/batch = 0.1144s	
2320/5250 (epoch 22.095), train_loss = 1.12143505, grad/param norm = 5.0807e-02, time/batch = 0.1144s	
2321/5250 (epoch 22.105), train_loss = 1.14875948, grad/param norm = 5.1103e-02, time/batch = 0.1149s	
2322/5250 (epoch 22.114), train_loss = 1.13204119, grad/param norm = 5.0430e-02, time/batch = 0.1158s	
2323/5250 (epoch 22.124), train_loss = 1.14692775, grad/param norm = 5.7667e-02, time/batch = 0.1141s	
2324/5250 (epoch 22.133), train_loss = 1.13128354, grad/param norm = 5.5021e-02, time/batch = 0.1143s	
2325/5250 (epoch 22.143), train_loss = 1.11261928, grad/param norm = 5.3247e-02, time/batch = 0.1157s	
2326/5250 (epoch 22.152), train_loss = 1.11206223, grad/param norm = 5.1155e-02, time/batch = 0.1143s	
2327/5250 (epoch 22.162), train_loss = 1.14818860, grad/param norm = 5.6557e-02, time/batch = 0.1141s	
2328/5250 (epoch 22.171), train_loss = 1.14187632, grad/param norm = 5.2134e-02, time/batch = 0.1138s	
2329/5250 (epoch 22.181), train_loss = 1.13660249, grad/param norm = 5.4993e-02, time/batch = 0.1144s	
2330/5250 (epoch 22.190), train_loss = 1.14338781, grad/param norm = 5.6249e-02, time/batch = 0.1145s	
2331/5250 (epoch 22.200), train_loss = 1.13204467, grad/param norm = 5.2816e-02, time/batch = 0.1150s	
2332/5250 (epoch 22.210), train_loss = 1.13330064, grad/param norm = 5.5100e-02, time/batch = 0.1141s	
2333/5250 (epoch 22.219), train_loss = 1.16976765, grad/param norm = 5.8053e-02, time/batch = 0.1138s	
2334/5250 (epoch 22.229), train_loss = 1.14465027, grad/param norm = 5.4624e-02, time/batch = 0.1142s	
2335/5250 (epoch 22.238), train_loss = 1.14297414, grad/param norm = 5.5424e-02, time/batch = 0.1141s	
2336/5250 (epoch 22.248), train_loss = 1.13600379, grad/param norm = 5.3369e-02, time/batch = 0.1142s	
2337/5250 (epoch 22.257), train_loss = 1.13921533, grad/param norm = 5.2668e-02, time/batch = 0.1141s	
2338/5250 (epoch 22.267), train_loss = 1.12906220, grad/param norm = 5.2379e-02, time/batch = 0.1136s	
2339/5250 (epoch 22.276), train_loss = 1.12505960, grad/param norm = 5.1451e-02, time/batch = 0.1143s	
2340/5250 (epoch 22.286), train_loss = 1.11115132, grad/param norm = 5.1390e-02, time/batch = 0.1145s	
2341/5250 (epoch 22.295), train_loss = 1.13093788, grad/param norm = 5.6332e-02, time/batch = 0.1150s	
2342/5250 (epoch 22.305), train_loss = 1.13231911, grad/param norm = 5.4613e-02, time/batch = 0.1137s	
2343/5250 (epoch 22.314), train_loss = 1.12934881, grad/param norm = 5.5462e-02, time/batch = 0.1140s	
2344/5250 (epoch 22.324), train_loss = 1.14284806, grad/param norm = 5.7198e-02, time/batch = 0.1140s	
2345/5250 (epoch 22.333), train_loss = 1.14326096, grad/param norm = 5.4362e-02, time/batch = 0.1142s	
2346/5250 (epoch 22.343), train_loss = 1.13711056, grad/param norm = 5.1734e-02, time/batch = 0.1141s	
2347/5250 (epoch 22.352), train_loss = 1.14883911, grad/param norm = 5.7541e-02, time/batch = 0.1143s	
2348/5250 (epoch 22.362), train_loss = 1.14786534, grad/param norm = 6.0784e-02, time/batch = 0.1137s	
2349/5250 (epoch 22.371), train_loss = 1.12911507, grad/param norm = 6.2001e-02, time/batch = 0.1143s	
2350/5250 (epoch 22.381), train_loss = 1.13261717, grad/param norm = 6.2922e-02, time/batch = 0.1145s	
2351/5250 (epoch 22.390), train_loss = 1.13558372, grad/param norm = 5.9857e-02, time/batch = 0.1148s	
2352/5250 (epoch 22.400), train_loss = 1.13259666, grad/param norm = 5.8863e-02, time/batch = 0.1135s	
2353/5250 (epoch 22.410), train_loss = 1.14470193, grad/param norm = 6.5277e-02, time/batch = 0.1139s	
2354/5250 (epoch 22.419), train_loss = 1.13945980, grad/param norm = 5.7763e-02, time/batch = 0.1141s	
2355/5250 (epoch 22.429), train_loss = 1.14340125, grad/param norm = 5.7613e-02, time/batch = 0.1141s	
2356/5250 (epoch 22.438), train_loss = 1.15492692, grad/param norm = 6.1412e-02, time/batch = 0.1141s	
2357/5250 (epoch 22.448), train_loss = 1.12386687, grad/param norm = 5.7625e-02, time/batch = 0.1141s	
2358/5250 (epoch 22.457), train_loss = 1.13120033, grad/param norm = 5.4536e-02, time/batch = 0.1137s	
2359/5250 (epoch 22.467), train_loss = 1.13318702, grad/param norm = 5.4664e-02, time/batch = 0.1141s	
2360/5250 (epoch 22.476), train_loss = 1.13896774, grad/param norm = 6.5590e-02, time/batch = 0.1144s	
2361/5250 (epoch 22.486), train_loss = 1.15936795, grad/param norm = 6.0450e-02, time/batch = 0.1148s	
2362/5250 (epoch 22.495), train_loss = 1.15137888, grad/param norm = 5.3107e-02, time/batch = 0.1138s	
2363/5250 (epoch 22.505), train_loss = 1.15439241, grad/param norm = 5.4013e-02, time/batch = 0.1139s	
2364/5250 (epoch 22.514), train_loss = 1.14325715, grad/param norm = 5.6174e-02, time/batch = 0.1141s	
2365/5250 (epoch 22.524), train_loss = 1.14496444, grad/param norm = 6.0101e-02, time/batch = 0.1144s	
2366/5250 (epoch 22.533), train_loss = 1.15297353, grad/param norm = 5.6401e-02, time/batch = 0.1142s	
2367/5250 (epoch 22.543), train_loss = 1.13421281, grad/param norm = 5.6237e-02, time/batch = 0.1144s	
2368/5250 (epoch 22.552), train_loss = 1.13313735, grad/param norm = 5.6611e-02, time/batch = 0.1136s	
2369/5250 (epoch 22.562), train_loss = 1.14205593, grad/param norm = 5.5785e-02, time/batch = 0.1142s	
2370/5250 (epoch 22.571), train_loss = 1.14616911, grad/param norm = 5.6856e-02, time/batch = 0.1144s	
2371/5250 (epoch 22.581), train_loss = 1.15294477, grad/param norm = 5.7750e-02, time/batch = 0.1147s	
2372/5250 (epoch 22.590), train_loss = 1.14441548, grad/param norm = 5.5544e-02, time/batch = 0.1136s	
2373/5250 (epoch 22.600), train_loss = 1.16251360, grad/param norm = 5.7071e-02, time/batch = 0.1139s	
2374/5250 (epoch 22.610), train_loss = 1.15735320, grad/param norm = 5.8450e-02, time/batch = 0.1140s	
2375/5250 (epoch 22.619), train_loss = 1.14990761, grad/param norm = 5.3144e-02, time/batch = 0.1141s	
2376/5250 (epoch 22.629), train_loss = 1.14304517, grad/param norm = 5.3667e-02, time/batch = 0.1142s	
2377/5250 (epoch 22.638), train_loss = 1.14110257, grad/param norm = 5.3684e-02, time/batch = 0.1142s	
2378/5250 (epoch 22.648), train_loss = 1.15170034, grad/param norm = 5.3330e-02, time/batch = 0.1137s	
2379/5250 (epoch 22.657), train_loss = 1.14111785, grad/param norm = 5.4508e-02, time/batch = 0.1142s	
2380/5250 (epoch 22.667), train_loss = 1.14756827, grad/param norm = 5.9928e-02, time/batch = 0.1143s	
2381/5250 (epoch 22.676), train_loss = 1.14362423, grad/param norm = 6.7778e-02, time/batch = 0.1149s	
2382/5250 (epoch 22.686), train_loss = 1.17106010, grad/param norm = 6.6221e-02, time/batch = 0.1137s	
2383/5250 (epoch 22.695), train_loss = 1.14622856, grad/param norm = 5.8143e-02, time/batch = 0.1140s	
2384/5250 (epoch 22.705), train_loss = 1.13207537, grad/param norm = 6.2718e-02, time/batch = 0.1138s	
2385/5250 (epoch 22.714), train_loss = 1.16590988, grad/param norm = 6.1982e-02, time/batch = 0.1142s	
2386/5250 (epoch 22.724), train_loss = 1.14131878, grad/param norm = 5.6854e-02, time/batch = 0.1142s	
2387/5250 (epoch 22.733), train_loss = 1.12523414, grad/param norm = 5.6877e-02, time/batch = 0.1141s	
2388/5250 (epoch 22.743), train_loss = 1.12698803, grad/param norm = 5.5879e-02, time/batch = 0.1135s	
2389/5250 (epoch 22.752), train_loss = 1.12902357, grad/param norm = 5.5451e-02, time/batch = 0.1144s	
2390/5250 (epoch 22.762), train_loss = 1.12823150, grad/param norm = 5.6216e-02, time/batch = 0.1144s	
2391/5250 (epoch 22.771), train_loss = 1.12245130, grad/param norm = 5.7769e-02, time/batch = 0.1147s	
2392/5250 (epoch 22.781), train_loss = 1.14205113, grad/param norm = 5.8460e-02, time/batch = 0.1136s	
2393/5250 (epoch 22.790), train_loss = 1.14833543, grad/param norm = 5.5597e-02, time/batch = 0.1171s	
2394/5250 (epoch 22.800), train_loss = 1.11957587, grad/param norm = 5.4146e-02, time/batch = 0.1141s	
2395/5250 (epoch 22.810), train_loss = 1.13615577, grad/param norm = 5.7156e-02, time/batch = 0.1143s	
2396/5250 (epoch 22.819), train_loss = 1.14940352, grad/param norm = 6.1698e-02, time/batch = 0.1143s	
2397/5250 (epoch 22.829), train_loss = 1.14774727, grad/param norm = 5.5604e-02, time/batch = 0.1142s	
2398/5250 (epoch 22.838), train_loss = 1.11392493, grad/param norm = 5.2099e-02, time/batch = 0.1134s	
2399/5250 (epoch 22.848), train_loss = 1.11091732, grad/param norm = 5.2907e-02, time/batch = 0.1143s	
2400/5250 (epoch 22.857), train_loss = 1.12633379, grad/param norm = 5.4291e-02, time/batch = 0.1143s	
2401/5250 (epoch 22.867), train_loss = 1.12707380, grad/param norm = 5.2807e-02, time/batch = 0.1148s	
2402/5250 (epoch 22.876), train_loss = 1.11986963, grad/param norm = 5.5365e-02, time/batch = 0.1139s	
2403/5250 (epoch 22.886), train_loss = 1.11840147, grad/param norm = 5.8081e-02, time/batch = 0.1142s	
2404/5250 (epoch 22.895), train_loss = 1.15426846, grad/param norm = 5.9427e-02, time/batch = 0.1140s	
2405/5250 (epoch 22.905), train_loss = 1.14409165, grad/param norm = 5.6390e-02, time/batch = 0.1142s	
2406/5250 (epoch 22.914), train_loss = 1.15133709, grad/param norm = 5.9074e-02, time/batch = 0.1141s	
2407/5250 (epoch 22.924), train_loss = 1.15810086, grad/param norm = 5.5995e-02, time/batch = 0.1143s	
2408/5250 (epoch 22.933), train_loss = 1.14119915, grad/param norm = 5.4839e-02, time/batch = 0.1137s	
2409/5250 (epoch 22.943), train_loss = 1.15450125, grad/param norm = 5.6029e-02, time/batch = 0.1143s	
2410/5250 (epoch 22.952), train_loss = 1.16474742, grad/param norm = 5.8327e-02, time/batch = 0.1145s	
2411/5250 (epoch 22.962), train_loss = 1.14150324, grad/param norm = 5.8049e-02, time/batch = 0.1147s	
2412/5250 (epoch 22.971), train_loss = 1.15433957, grad/param norm = 6.0130e-02, time/batch = 0.1136s	
2413/5250 (epoch 22.981), train_loss = 1.16238344, grad/param norm = 6.1435e-02, time/batch = 0.1140s	
2414/5250 (epoch 22.990), train_loss = 1.15705536, grad/param norm = 5.7359e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
2415/5250 (epoch 23.000), train_loss = 1.14766067, grad/param norm = 5.7612e-02, time/batch = 0.1142s	
2416/5250 (epoch 23.010), train_loss = 1.32145892, grad/param norm = 5.8722e-02, time/batch = 0.1141s	
2417/5250 (epoch 23.019), train_loss = 1.12873685, grad/param norm = 5.2684e-02, time/batch = 0.1142s	
2418/5250 (epoch 23.029), train_loss = 1.15361057, grad/param norm = 5.3306e-02, time/batch = 0.1137s	
2419/5250 (epoch 23.038), train_loss = 1.13061747, grad/param norm = 5.5095e-02, time/batch = 0.1143s	
2420/5250 (epoch 23.048), train_loss = 1.10261502, grad/param norm = 5.2509e-02, time/batch = 0.1145s	
2421/5250 (epoch 23.057), train_loss = 1.11601764, grad/param norm = 5.2334e-02, time/batch = 0.1148s	
2422/5250 (epoch 23.067), train_loss = 1.12636767, grad/param norm = 5.2593e-02, time/batch = 0.1136s	
2423/5250 (epoch 23.076), train_loss = 1.14526091, grad/param norm = 5.5246e-02, time/batch = 0.1140s	
2424/5250 (epoch 23.086), train_loss = 1.08756463, grad/param norm = 5.0378e-02, time/batch = 0.1142s	
2425/5250 (epoch 23.095), train_loss = 1.10865036, grad/param norm = 5.1044e-02, time/batch = 0.1143s	
2426/5250 (epoch 23.105), train_loss = 1.13718473, grad/param norm = 5.2000e-02, time/batch = 0.1143s	
2427/5250 (epoch 23.114), train_loss = 1.11997039, grad/param norm = 5.1526e-02, time/batch = 0.1142s	
2428/5250 (epoch 23.124), train_loss = 1.13535155, grad/param norm = 5.7403e-02, time/batch = 0.1136s	
2429/5250 (epoch 23.133), train_loss = 1.11870632, grad/param norm = 5.4554e-02, time/batch = 0.1142s	
2430/5250 (epoch 23.143), train_loss = 1.10124517, grad/param norm = 5.3150e-02, time/batch = 0.1144s	
2431/5250 (epoch 23.152), train_loss = 1.10231363, grad/param norm = 5.4766e-02, time/batch = 0.1149s	
2432/5250 (epoch 23.162), train_loss = 1.13602322, grad/param norm = 5.6805e-02, time/batch = 0.1135s	
2433/5250 (epoch 23.171), train_loss = 1.12785376, grad/param norm = 5.2354e-02, time/batch = 0.1139s	
2434/5250 (epoch 23.181), train_loss = 1.12478514, grad/param norm = 5.7392e-02, time/batch = 0.1140s	
2435/5250 (epoch 23.190), train_loss = 1.13230725, grad/param norm = 6.2661e-02, time/batch = 0.1142s	
2436/5250 (epoch 23.200), train_loss = 1.12175857, grad/param norm = 5.4991e-02, time/batch = 0.1142s	
2437/5250 (epoch 23.210), train_loss = 1.12185740, grad/param norm = 5.5540e-02, time/batch = 0.1142s	
2438/5250 (epoch 23.219), train_loss = 1.15858271, grad/param norm = 5.9536e-02, time/batch = 0.1139s	
2439/5250 (epoch 23.229), train_loss = 1.13538133, grad/param norm = 5.8890e-02, time/batch = 0.1144s	
2440/5250 (epoch 23.238), train_loss = 1.13007119, grad/param norm = 5.4250e-02, time/batch = 0.1143s	
2441/5250 (epoch 23.248), train_loss = 1.12314761, grad/param norm = 5.5407e-02, time/batch = 0.1149s	
2442/5250 (epoch 23.257), train_loss = 1.13109058, grad/param norm = 5.7815e-02, time/batch = 0.1138s	
2443/5250 (epoch 23.267), train_loss = 1.11743102, grad/param norm = 5.5429e-02, time/batch = 0.1140s	
2444/5250 (epoch 23.276), train_loss = 1.11318908, grad/param norm = 5.2568e-02, time/batch = 0.1142s	
2445/5250 (epoch 23.286), train_loss = 1.09802380, grad/param norm = 5.2994e-02, time/batch = 0.1142s	
2446/5250 (epoch 23.295), train_loss = 1.11668038, grad/param norm = 5.1960e-02, time/batch = 0.1143s	
2447/5250 (epoch 23.305), train_loss = 1.11713774, grad/param norm = 5.3162e-02, time/batch = 0.1142s	
2448/5250 (epoch 23.314), train_loss = 1.11611537, grad/param norm = 5.6540e-02, time/batch = 0.1138s	
2449/5250 (epoch 23.324), train_loss = 1.13024274, grad/param norm = 5.8331e-02, time/batch = 0.1143s	
2450/5250 (epoch 23.333), train_loss = 1.13215963, grad/param norm = 5.8554e-02, time/batch = 0.1145s	
2451/5250 (epoch 23.343), train_loss = 1.12777782, grad/param norm = 5.6142e-02, time/batch = 0.1148s	
2452/5250 (epoch 23.352), train_loss = 1.13442691, grad/param norm = 5.6740e-02, time/batch = 0.1137s	
2453/5250 (epoch 23.362), train_loss = 1.13304206, grad/param norm = 5.5025e-02, time/batch = 0.1140s	
2454/5250 (epoch 23.371), train_loss = 1.11205115, grad/param norm = 5.4459e-02, time/batch = 0.1140s	
2455/5250 (epoch 23.381), train_loss = 1.11404557, grad/param norm = 5.7133e-02, time/batch = 0.1143s	
2456/5250 (epoch 23.390), train_loss = 1.12180184, grad/param norm = 5.7245e-02, time/batch = 0.1142s	
2457/5250 (epoch 23.400), train_loss = 1.12123885, grad/param norm = 6.1911e-02, time/batch = 0.1141s	
2458/5250 (epoch 23.410), train_loss = 1.13330946, grad/param norm = 6.5107e-02, time/batch = 0.1136s	
2459/5250 (epoch 23.419), train_loss = 1.13077789, grad/param norm = 6.2968e-02, time/batch = 0.1143s	
2460/5250 (epoch 23.429), train_loss = 1.13522550, grad/param norm = 6.5035e-02, time/batch = 0.1143s	
2461/5250 (epoch 23.438), train_loss = 1.14466495, grad/param norm = 6.1330e-02, time/batch = 0.1150s	
2462/5250 (epoch 23.448), train_loss = 1.11171194, grad/param norm = 5.5690e-02, time/batch = 0.1137s	
2463/5250 (epoch 23.457), train_loss = 1.11969803, grad/param norm = 5.5415e-02, time/batch = 0.1139s	
2464/5250 (epoch 23.467), train_loss = 1.12067943, grad/param norm = 5.4156e-02, time/batch = 0.1141s	
2465/5250 (epoch 23.476), train_loss = 1.12460639, grad/param norm = 6.3431e-02, time/batch = 0.1143s	
2466/5250 (epoch 23.486), train_loss = 1.14326629, grad/param norm = 5.5726e-02, time/batch = 0.1141s	
2467/5250 (epoch 23.495), train_loss = 1.14066682, grad/param norm = 5.5010e-02, time/batch = 0.1144s	
2468/5250 (epoch 23.505), train_loss = 1.14167055, grad/param norm = 5.8446e-02, time/batch = 0.1135s	
2469/5250 (epoch 23.514), train_loss = 1.13268723, grad/param norm = 5.8409e-02, time/batch = 0.1142s	
2470/5250 (epoch 23.524), train_loss = 1.13078019, grad/param norm = 5.8119e-02, time/batch = 0.1144s	
2471/5250 (epoch 23.533), train_loss = 1.13965336, grad/param norm = 5.5185e-02, time/batch = 0.1149s	
2472/5250 (epoch 23.543), train_loss = 1.12416798, grad/param norm = 5.7610e-02, time/batch = 0.1136s	
2473/5250 (epoch 23.552), train_loss = 1.11848973, grad/param norm = 5.4445e-02, time/batch = 0.1140s	
2474/5250 (epoch 23.562), train_loss = 1.13081220, grad/param norm = 5.8363e-02, time/batch = 0.1142s	
2475/5250 (epoch 23.571), train_loss = 1.13821708, grad/param norm = 6.1614e-02, time/batch = 0.1141s	
2476/5250 (epoch 23.581), train_loss = 1.14082570, grad/param norm = 6.0383e-02, time/batch = 0.1142s	
2477/5250 (epoch 23.590), train_loss = 1.13166975, grad/param norm = 5.7541e-02, time/batch = 0.1143s	
2478/5250 (epoch 23.600), train_loss = 1.15200693, grad/param norm = 5.9397e-02, time/batch = 0.1137s	
2479/5250 (epoch 23.610), train_loss = 1.14278920, grad/param norm = 5.5571e-02, time/batch = 0.1143s	
2480/5250 (epoch 23.619), train_loss = 1.13731456, grad/param norm = 5.6574e-02, time/batch = 0.1144s	
2481/5250 (epoch 23.629), train_loss = 1.13549583, grad/param norm = 5.8522e-02, time/batch = 0.1148s	
2482/5250 (epoch 23.638), train_loss = 1.12907843, grad/param norm = 5.2973e-02, time/batch = 0.1137s	
2483/5250 (epoch 23.648), train_loss = 1.13748777, grad/param norm = 5.4750e-02, time/batch = 0.1138s	
2484/5250 (epoch 23.657), train_loss = 1.12867492, grad/param norm = 5.4286e-02, time/batch = 0.1141s	
2485/5250 (epoch 23.667), train_loss = 1.13040174, grad/param norm = 5.3243e-02, time/batch = 0.1144s	
2486/5250 (epoch 23.676), train_loss = 1.12272201, grad/param norm = 5.1530e-02, time/batch = 0.1143s	
2487/5250 (epoch 23.686), train_loss = 1.15185851, grad/param norm = 5.7253e-02, time/batch = 0.1143s	
2488/5250 (epoch 23.695), train_loss = 1.13886994, grad/param norm = 6.4702e-02, time/batch = 0.1138s	
2489/5250 (epoch 23.705), train_loss = 1.12195986, grad/param norm = 6.6017e-02, time/batch = 0.1143s	
2490/5250 (epoch 23.714), train_loss = 1.14835937, grad/param norm = 5.4207e-02, time/batch = 0.1143s	
2491/5250 (epoch 23.724), train_loss = 1.12611000, grad/param norm = 5.2701e-02, time/batch = 0.1148s	
2492/5250 (epoch 23.733), train_loss = 1.11279097, grad/param norm = 5.7491e-02, time/batch = 0.1135s	
2493/5250 (epoch 23.743), train_loss = 1.11309727, grad/param norm = 5.5554e-02, time/batch = 0.1142s	
2494/5250 (epoch 23.752), train_loss = 1.11843019, grad/param norm = 5.6409e-02, time/batch = 0.1139s	
2495/5250 (epoch 23.762), train_loss = 1.12246804, grad/param norm = 6.8140e-02, time/batch = 0.1144s	
2496/5250 (epoch 23.771), train_loss = 1.11247402, grad/param norm = 6.0719e-02, time/batch = 0.1141s	
2497/5250 (epoch 23.781), train_loss = 1.12893381, grad/param norm = 5.4020e-02, time/batch = 0.1142s	
2498/5250 (epoch 23.790), train_loss = 1.13693098, grad/param norm = 6.2831e-02, time/batch = 0.1136s	
2499/5250 (epoch 23.800), train_loss = 1.11408526, grad/param norm = 6.5033e-02, time/batch = 0.1142s	
2500/5250 (epoch 23.810), train_loss = 1.12396529, grad/param norm = 5.8280e-02, time/batch = 0.1144s	
2501/5250 (epoch 23.819), train_loss = 1.13462184, grad/param norm = 5.6245e-02, time/batch = 0.1147s	
2502/5250 (epoch 23.829), train_loss = 1.13436340, grad/param norm = 5.5433e-02, time/batch = 0.1136s	
2503/5250 (epoch 23.838), train_loss = 1.10598178, grad/param norm = 5.9730e-02, time/batch = 0.1140s	
2504/5250 (epoch 23.848), train_loss = 1.10057375, grad/param norm = 5.8057e-02, time/batch = 0.1141s	
2505/5250 (epoch 23.857), train_loss = 1.11466044, grad/param norm = 5.6620e-02, time/batch = 0.1143s	
2506/5250 (epoch 23.867), train_loss = 1.11858311, grad/param norm = 6.4329e-02, time/batch = 0.1140s	
2507/5250 (epoch 23.876), train_loss = 1.11579624, grad/param norm = 6.7163e-02, time/batch = 0.1143s	
2508/5250 (epoch 23.886), train_loss = 1.10826296, grad/param norm = 6.0564e-02, time/batch = 0.1138s	
2509/5250 (epoch 23.895), train_loss = 1.14313149, grad/param norm = 6.0711e-02, time/batch = 0.1142s	
2510/5250 (epoch 23.905), train_loss = 1.13145729, grad/param norm = 5.5200e-02, time/batch = 0.1144s	
2511/5250 (epoch 23.914), train_loss = 1.13802851, grad/param norm = 5.8539e-02, time/batch = 0.1149s	
2512/5250 (epoch 23.924), train_loss = 1.14673002, grad/param norm = 5.7577e-02, time/batch = 0.1137s	
2513/5250 (epoch 23.933), train_loss = 1.12887341, grad/param norm = 5.3819e-02, time/batch = 0.1139s	
2514/5250 (epoch 23.943), train_loss = 1.14117371, grad/param norm = 5.5404e-02, time/batch = 0.1140s	
2515/5250 (epoch 23.952), train_loss = 1.15153124, grad/param norm = 5.9498e-02, time/batch = 0.1142s	
2516/5250 (epoch 23.962), train_loss = 1.12641864, grad/param norm = 5.3033e-02, time/batch = 0.1143s	
2517/5250 (epoch 23.971), train_loss = 1.13659161, grad/param norm = 5.1671e-02, time/batch = 0.1143s	
2518/5250 (epoch 23.981), train_loss = 1.14455430, grad/param norm = 5.6039e-02, time/batch = 0.1139s	
2519/5250 (epoch 23.990), train_loss = 1.14252865, grad/param norm = 5.2632e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
2520/5250 (epoch 24.000), train_loss = 1.13233834, grad/param norm = 5.4719e-02, time/batch = 0.1144s	
2521/5250 (epoch 24.010), train_loss = 1.31079801, grad/param norm = 6.4561e-02, time/batch = 0.1150s	
2522/5250 (epoch 24.019), train_loss = 1.12181102, grad/param norm = 6.3550e-02, time/batch = 0.1136s	
2523/5250 (epoch 24.029), train_loss = 1.14697523, grad/param norm = 6.0181e-02, time/batch = 0.1139s	
2524/5250 (epoch 24.038), train_loss = 1.12087775, grad/param norm = 5.7747e-02, time/batch = 0.1141s	
2525/5250 (epoch 24.048), train_loss = 1.09179802, grad/param norm = 5.3691e-02, time/batch = 0.1142s	
2526/5250 (epoch 24.057), train_loss = 1.10160946, grad/param norm = 5.0212e-02, time/batch = 0.1143s	
2527/5250 (epoch 24.067), train_loss = 1.11339113, grad/param norm = 5.3171e-02, time/batch = 0.1143s	
2528/5250 (epoch 24.076), train_loss = 1.13399010, grad/param norm = 5.6624e-02, time/batch = 0.1137s	
2529/5250 (epoch 24.086), train_loss = 1.07582162, grad/param norm = 5.0825e-02, time/batch = 0.1143s	
2530/5250 (epoch 24.095), train_loss = 1.09619755, grad/param norm = 5.0998e-02, time/batch = 0.1143s	
2531/5250 (epoch 24.105), train_loss = 1.12528996, grad/param norm = 5.3726e-02, time/batch = 0.1149s	
2532/5250 (epoch 24.114), train_loss = 1.10890622, grad/param norm = 5.3117e-02, time/batch = 0.1135s	
2533/5250 (epoch 24.124), train_loss = 1.12588102, grad/param norm = 5.7771e-02, time/batch = 0.1138s	
2534/5250 (epoch 24.133), train_loss = 1.10655112, grad/param norm = 5.4001e-02, time/batch = 0.1142s	
2535/5250 (epoch 24.143), train_loss = 1.08845526, grad/param norm = 5.3649e-02, time/batch = 0.1143s	
2536/5250 (epoch 24.152), train_loss = 1.08912109, grad/param norm = 5.3196e-02, time/batch = 0.1143s	
2537/5250 (epoch 24.162), train_loss = 1.12180191, grad/param norm = 5.6177e-02, time/batch = 0.1141s	
2538/5250 (epoch 24.171), train_loss = 1.11576349, grad/param norm = 5.2971e-02, time/batch = 0.1139s	
2539/5250 (epoch 24.181), train_loss = 1.11219712, grad/param norm = 5.5356e-02, time/batch = 0.1144s	
2540/5250 (epoch 24.190), train_loss = 1.11739795, grad/param norm = 5.9320e-02, time/batch = 0.1144s	
2541/5250 (epoch 24.200), train_loss = 1.11169431, grad/param norm = 5.9775e-02, time/batch = 0.1148s	
2542/5250 (epoch 24.210), train_loss = 1.11205831, grad/param norm = 5.6361e-02, time/batch = 0.1136s	
2543/5250 (epoch 24.219), train_loss = 1.14438763, grad/param norm = 5.5158e-02, time/batch = 0.1139s	
2544/5250 (epoch 24.229), train_loss = 1.11950545, grad/param norm = 5.4350e-02, time/batch = 0.1142s	
2545/5250 (epoch 24.238), train_loss = 1.11705743, grad/param norm = 5.6586e-02, time/batch = 0.1143s	
2546/5250 (epoch 24.248), train_loss = 1.11177095, grad/param norm = 5.9078e-02, time/batch = 0.1143s	
2547/5250 (epoch 24.257), train_loss = 1.11901358, grad/param norm = 5.6477e-02, time/batch = 0.1143s	
2548/5250 (epoch 24.267), train_loss = 1.10653417, grad/param norm = 5.4462e-02, time/batch = 0.1135s	
2549/5250 (epoch 24.276), train_loss = 1.10084174, grad/param norm = 5.5071e-02, time/batch = 0.1143s	
2550/5250 (epoch 24.286), train_loss = 1.08577137, grad/param norm = 5.3633e-02, time/batch = 0.1144s	
2551/5250 (epoch 24.295), train_loss = 1.10578727, grad/param norm = 5.8790e-02, time/batch = 0.1148s	
2552/5250 (epoch 24.305), train_loss = 1.10945006, grad/param norm = 5.7283e-02, time/batch = 0.1136s	
2553/5250 (epoch 24.314), train_loss = 1.10488821, grad/param norm = 5.7268e-02, time/batch = 0.1140s	
2554/5250 (epoch 24.324), train_loss = 1.11677778, grad/param norm = 5.6259e-02, time/batch = 0.1141s	
2555/5250 (epoch 24.333), train_loss = 1.12028482, grad/param norm = 6.0867e-02, time/batch = 0.1140s	
2556/5250 (epoch 24.343), train_loss = 1.11716587, grad/param norm = 5.6444e-02, time/batch = 0.1143s	
2557/5250 (epoch 24.352), train_loss = 1.12176492, grad/param norm = 5.7651e-02, time/batch = 0.1141s	
2558/5250 (epoch 24.362), train_loss = 1.12124822, grad/param norm = 5.7801e-02, time/batch = 0.1138s	
2559/5250 (epoch 24.371), train_loss = 1.10227527, grad/param norm = 5.8479e-02, time/batch = 0.1143s	
2560/5250 (epoch 24.381), train_loss = 1.10500042, grad/param norm = 6.1706e-02, time/batch = 0.1144s	
2561/5250 (epoch 24.390), train_loss = 1.10950822, grad/param norm = 5.8038e-02, time/batch = 0.1149s	
2562/5250 (epoch 24.400), train_loss = 1.10543960, grad/param norm = 5.6387e-02, time/batch = 0.1138s	
2563/5250 (epoch 24.410), train_loss = 1.11779992, grad/param norm = 6.2787e-02, time/batch = 0.1140s	
2564/5250 (epoch 24.419), train_loss = 1.11338644, grad/param norm = 5.4364e-02, time/batch = 0.1143s	
2565/5250 (epoch 24.429), train_loss = 1.11733896, grad/param norm = 5.6210e-02, time/batch = 0.1144s	
2566/5250 (epoch 24.438), train_loss = 1.12917246, grad/param norm = 6.1206e-02, time/batch = 0.1142s	
2567/5250 (epoch 24.448), train_loss = 1.10221013, grad/param norm = 6.2245e-02, time/batch = 0.1142s	
2568/5250 (epoch 24.457), train_loss = 1.10888458, grad/param norm = 5.7863e-02, time/batch = 0.1136s	
2569/5250 (epoch 24.467), train_loss = 1.11150243, grad/param norm = 5.7180e-02, time/batch = 0.1144s	
2570/5250 (epoch 24.476), train_loss = 1.11429409, grad/param norm = 6.5657e-02, time/batch = 0.1141s	
2571/5250 (epoch 24.486), train_loss = 1.13188691, grad/param norm = 5.5648e-02, time/batch = 0.1149s	
2572/5250 (epoch 24.495), train_loss = 1.12830504, grad/param norm = 5.4196e-02, time/batch = 0.1137s	
2573/5250 (epoch 24.505), train_loss = 1.12806464, grad/param norm = 5.6648e-02, time/batch = 0.1139s	
2574/5250 (epoch 24.514), train_loss = 1.11833939, grad/param norm = 5.7439e-02, time/batch = 0.1142s	
2575/5250 (epoch 24.524), train_loss = 1.11834950, grad/param norm = 5.9473e-02, time/batch = 0.1144s	
2576/5250 (epoch 24.533), train_loss = 1.12739778, grad/param norm = 5.6040e-02, time/batch = 0.1141s	
2577/5250 (epoch 24.543), train_loss = 1.10988728, grad/param norm = 5.5379e-02, time/batch = 0.1143s	
2578/5250 (epoch 24.552), train_loss = 1.10693453, grad/param norm = 5.4971e-02, time/batch = 0.1139s	
2579/5250 (epoch 24.562), train_loss = 1.11892612, grad/param norm = 5.8796e-02, time/batch = 0.1144s	
2580/5250 (epoch 24.571), train_loss = 1.12297626, grad/param norm = 5.5729e-02, time/batch = 0.1144s	
2581/5250 (epoch 24.581), train_loss = 1.12327924, grad/param norm = 5.4920e-02, time/batch = 0.1149s	
2582/5250 (epoch 24.590), train_loss = 1.12033257, grad/param norm = 6.3008e-02, time/batch = 0.1137s	
2583/5250 (epoch 24.600), train_loss = 1.14494724, grad/param norm = 6.4682e-02, time/batch = 0.1142s	
2584/5250 (epoch 24.610), train_loss = 1.13067554, grad/param norm = 5.6434e-02, time/batch = 0.1140s	
2585/5250 (epoch 24.619), train_loss = 1.12391687, grad/param norm = 5.3113e-02, time/batch = 0.1143s	
2586/5250 (epoch 24.629), train_loss = 1.12054469, grad/param norm = 5.7813e-02, time/batch = 0.1142s	
2587/5250 (epoch 24.638), train_loss = 1.11711260, grad/param norm = 5.4555e-02, time/batch = 0.1142s	
2588/5250 (epoch 24.648), train_loss = 1.12690936, grad/param norm = 5.9961e-02, time/batch = 0.1136s	
2589/5250 (epoch 24.657), train_loss = 1.11759431, grad/param norm = 5.5869e-02, time/batch = 0.1142s	
2590/5250 (epoch 24.667), train_loss = 1.11830838, grad/param norm = 5.3925e-02, time/batch = 0.1144s	
2591/5250 (epoch 24.676), train_loss = 1.11285696, grad/param norm = 5.6587e-02, time/batch = 0.1148s	
2592/5250 (epoch 24.686), train_loss = 1.14026954, grad/param norm = 5.8410e-02, time/batch = 0.1136s	
2593/5250 (epoch 24.695), train_loss = 1.12287825, grad/param norm = 5.6705e-02, time/batch = 0.1141s	
2594/5250 (epoch 24.705), train_loss = 1.10540849, grad/param norm = 5.7960e-02, time/batch = 0.1141s	
2595/5250 (epoch 24.714), train_loss = 1.13717872, grad/param norm = 5.8654e-02, time/batch = 0.1143s	
2596/5250 (epoch 24.724), train_loss = 1.11667673, grad/param norm = 5.8432e-02, time/batch = 0.1142s	
2597/5250 (epoch 24.733), train_loss = 1.10180888, grad/param norm = 5.9666e-02, time/batch = 0.1142s	
2598/5250 (epoch 24.743), train_loss = 1.10654590, grad/param norm = 6.1831e-02, time/batch = 0.1139s	
2599/5250 (epoch 24.752), train_loss = 1.10851771, grad/param norm = 5.8881e-02, time/batch = 0.1142s	
2600/5250 (epoch 24.762), train_loss = 1.10433276, grad/param norm = 5.7106e-02, time/batch = 0.1142s	
2601/5250 (epoch 24.771), train_loss = 1.09873128, grad/param norm = 5.7101e-02, time/batch = 0.1150s	
2602/5250 (epoch 24.781), train_loss = 1.11925471, grad/param norm = 5.9758e-02, time/batch = 0.1135s	
2603/5250 (epoch 24.790), train_loss = 1.12466290, grad/param norm = 6.1753e-02, time/batch = 0.1139s	
2604/5250 (epoch 24.800), train_loss = 1.09844134, grad/param norm = 5.8821e-02, time/batch = 0.1142s	
2605/5250 (epoch 24.810), train_loss = 1.11297490, grad/param norm = 6.0910e-02, time/batch = 0.1141s	
2606/5250 (epoch 24.819), train_loss = 1.12686172, grad/param norm = 6.4074e-02, time/batch = 0.1141s	
2607/5250 (epoch 24.829), train_loss = 1.12196349, grad/param norm = 5.6961e-02, time/batch = 0.1143s	
2608/5250 (epoch 24.838), train_loss = 1.09049138, grad/param norm = 5.3090e-02, time/batch = 0.1136s	
2609/5250 (epoch 24.848), train_loss = 1.08491978, grad/param norm = 5.4958e-02, time/batch = 0.1144s	
2610/5250 (epoch 24.857), train_loss = 1.10251467, grad/param norm = 5.7671e-02, time/batch = 0.1143s	
2611/5250 (epoch 24.867), train_loss = 1.10389919, grad/param norm = 5.6553e-02, time/batch = 0.1148s	
2612/5250 (epoch 24.876), train_loss = 1.09740730, grad/param norm = 5.9019e-02, time/batch = 0.1133s	
2613/5250 (epoch 24.886), train_loss = 1.09723490, grad/param norm = 6.3178e-02, time/batch = 0.1140s	
2614/5250 (epoch 24.895), train_loss = 1.13157440, grad/param norm = 6.6549e-02, time/batch = 0.1140s	
2615/5250 (epoch 24.905), train_loss = 1.12226599, grad/param norm = 5.8566e-02, time/batch = 0.1143s	
2616/5250 (epoch 24.914), train_loss = 1.12656998, grad/param norm = 5.8647e-02, time/batch = 0.1142s	
2617/5250 (epoch 24.924), train_loss = 1.13296547, grad/param norm = 5.7669e-02, time/batch = 0.1140s	
2618/5250 (epoch 24.933), train_loss = 1.11876054, grad/param norm = 5.7204e-02, time/batch = 0.1138s	
2619/5250 (epoch 24.943), train_loss = 1.12908958, grad/param norm = 5.5757e-02, time/batch = 0.1144s	
2620/5250 (epoch 24.952), train_loss = 1.13954179, grad/param norm = 5.8152e-02, time/batch = 0.1143s	
2621/5250 (epoch 24.962), train_loss = 1.11645486, grad/param norm = 5.4482e-02, time/batch = 0.1148s	
2622/5250 (epoch 24.971), train_loss = 1.12535937, grad/param norm = 5.3016e-02, time/batch = 0.1137s	
2623/5250 (epoch 24.981), train_loss = 1.13312953, grad/param norm = 5.6435e-02, time/batch = 0.1141s	
2624/5250 (epoch 24.990), train_loss = 1.13139915, grad/param norm = 5.6342e-02, time/batch = 0.1140s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
2625/5250 (epoch 25.000), train_loss = 1.12448641, grad/param norm = 6.4813e-02, time/batch = 0.1143s	
2626/5250 (epoch 25.010), train_loss = 1.30400514, grad/param norm = 6.7278e-02, time/batch = 0.1143s	
2627/5250 (epoch 25.019), train_loss = 1.10966192, grad/param norm = 6.0593e-02, time/batch = 0.1141s	
2628/5250 (epoch 25.029), train_loss = 1.13408352, grad/param norm = 5.8928e-02, time/batch = 0.1139s	
2629/5250 (epoch 25.038), train_loss = 1.10953320, grad/param norm = 6.1882e-02, time/batch = 0.1142s	
2630/5250 (epoch 25.048), train_loss = 1.08145023, grad/param norm = 5.6359e-02, time/batch = 0.1142s	
2631/5250 (epoch 25.057), train_loss = 1.09265874, grad/param norm = 5.3974e-02, time/batch = 0.1149s	
2632/5250 (epoch 25.067), train_loss = 1.10379765, grad/param norm = 5.4725e-02, time/batch = 0.1136s	
2633/5250 (epoch 25.076), train_loss = 1.12319722, grad/param norm = 5.5151e-02, time/batch = 0.1139s	
2634/5250 (epoch 25.086), train_loss = 1.06451815, grad/param norm = 5.1428e-02, time/batch = 0.1142s	
2635/5250 (epoch 25.095), train_loss = 1.08436519, grad/param norm = 5.1859e-02, time/batch = 0.1142s	
2636/5250 (epoch 25.105), train_loss = 1.11326982, grad/param norm = 5.2764e-02, time/batch = 0.1143s	
2637/5250 (epoch 25.114), train_loss = 1.09797423, grad/param norm = 5.3797e-02, time/batch = 0.1142s	
2638/5250 (epoch 25.124), train_loss = 1.11304361, grad/param norm = 5.6254e-02, time/batch = 0.1136s	
2639/5250 (epoch 25.133), train_loss = 1.09447681, grad/param norm = 5.3200e-02, time/batch = 0.1143s	
2640/5250 (epoch 25.143), train_loss = 1.07839707, grad/param norm = 5.6649e-02, time/batch = 0.1144s	
2641/5250 (epoch 25.152), train_loss = 1.08023836, grad/param norm = 5.6376e-02, time/batch = 0.1148s	
2642/5250 (epoch 25.162), train_loss = 1.10999920, grad/param norm = 5.5373e-02, time/batch = 0.1136s	
2643/5250 (epoch 25.171), train_loss = 1.10383039, grad/param norm = 5.4284e-02, time/batch = 0.1141s	
2644/5250 (epoch 25.181), train_loss = 1.10181771, grad/param norm = 5.7521e-02, time/batch = 0.1153s	
2645/5250 (epoch 25.190), train_loss = 1.10580980, grad/param norm = 5.9643e-02, time/batch = 0.1143s	
2646/5250 (epoch 25.200), train_loss = 1.10055053, grad/param norm = 6.0684e-02, time/batch = 0.1140s	
2647/5250 (epoch 25.210), train_loss = 1.10330263, grad/param norm = 5.9171e-02, time/batch = 0.1142s	
2648/5250 (epoch 25.219), train_loss = 1.13498615, grad/param norm = 5.8589e-02, time/batch = 0.1139s	
2649/5250 (epoch 25.229), train_loss = 1.10802795, grad/param norm = 5.6175e-02, time/batch = 0.1144s	
2650/5250 (epoch 25.238), train_loss = 1.10441297, grad/param norm = 5.4956e-02, time/batch = 0.1144s	
2651/5250 (epoch 25.248), train_loss = 1.09835178, grad/param norm = 5.6543e-02, time/batch = 0.1149s	
2652/5250 (epoch 25.257), train_loss = 1.10566158, grad/param norm = 5.5804e-02, time/batch = 0.1134s	
2653/5250 (epoch 25.267), train_loss = 1.09565497, grad/param norm = 5.5693e-02, time/batch = 0.1140s	
2654/5250 (epoch 25.276), train_loss = 1.08877195, grad/param norm = 5.4134e-02, time/batch = 0.1140s	
2655/5250 (epoch 25.286), train_loss = 1.07251149, grad/param norm = 5.4589e-02, time/batch = 0.1142s	
2656/5250 (epoch 25.295), train_loss = 1.09282292, grad/param norm = 5.5047e-02, time/batch = 0.1140s	
2657/5250 (epoch 25.305), train_loss = 1.09515784, grad/param norm = 5.6409e-02, time/batch = 0.1144s	
2658/5250 (epoch 25.314), train_loss = 1.09653798, grad/param norm = 5.9197e-02, time/batch = 0.1137s	
2659/5250 (epoch 25.324), train_loss = 1.10671071, grad/param norm = 5.9898e-02, time/batch = 0.1141s	
2660/5250 (epoch 25.333), train_loss = 1.10606616, grad/param norm = 5.4696e-02, time/batch = 0.1142s	
2661/5250 (epoch 25.343), train_loss = 1.10438963, grad/param norm = 5.7468e-02, time/batch = 0.1150s	
2662/5250 (epoch 25.352), train_loss = 1.11186571, grad/param norm = 5.9837e-02, time/batch = 0.1136s	
2663/5250 (epoch 25.362), train_loss = 1.10892131, grad/param norm = 5.7435e-02, time/batch = 0.1139s	
2664/5250 (epoch 25.371), train_loss = 1.09077215, grad/param norm = 5.8428e-02, time/batch = 0.1141s	
2665/5250 (epoch 25.381), train_loss = 1.09249263, grad/param norm = 6.0126e-02, time/batch = 0.1143s	
2666/5250 (epoch 25.390), train_loss = 1.09849893, grad/param norm = 5.8350e-02, time/batch = 0.1140s	
2667/5250 (epoch 25.400), train_loss = 1.09653373, grad/param norm = 6.1624e-02, time/batch = 0.1143s	
2668/5250 (epoch 25.410), train_loss = 1.10722399, grad/param norm = 6.4330e-02, time/batch = 0.1138s	
2669/5250 (epoch 25.419), train_loss = 1.10641425, grad/param norm = 6.0981e-02, time/batch = 0.1143s	
2670/5250 (epoch 25.429), train_loss = 1.11081535, grad/param norm = 6.2039e-02, time/batch = 0.1144s	
2671/5250 (epoch 25.438), train_loss = 1.11512918, grad/param norm = 5.9048e-02, time/batch = 0.1151s	
2672/5250 (epoch 25.448), train_loss = 1.08889482, grad/param norm = 5.6959e-02, time/batch = 0.1136s	
2673/5250 (epoch 25.457), train_loss = 1.09820682, grad/param norm = 5.7915e-02, time/batch = 0.1138s	
2674/5250 (epoch 25.467), train_loss = 1.09864233, grad/param norm = 5.5437e-02, time/batch = 0.1142s	
2675/5250 (epoch 25.476), train_loss = 1.09919547, grad/param norm = 5.6960e-02, time/batch = 0.1144s	
2676/5250 (epoch 25.486), train_loss = 1.11751144, grad/param norm = 5.5554e-02, time/batch = 0.1142s	
2677/5250 (epoch 25.495), train_loss = 1.11931942, grad/param norm = 5.7079e-02, time/batch = 0.1143s	
2678/5250 (epoch 25.505), train_loss = 1.11595932, grad/param norm = 5.7779e-02, time/batch = 0.1138s	
2679/5250 (epoch 25.514), train_loss = 1.10679958, grad/param norm = 5.8639e-02, time/batch = 0.1143s	
2680/5250 (epoch 25.524), train_loss = 1.10592392, grad/param norm = 5.7681e-02, time/batch = 0.1143s	
2681/5250 (epoch 25.533), train_loss = 1.11606745, grad/param norm = 5.7180e-02, time/batch = 0.1149s	
2682/5250 (epoch 25.543), train_loss = 1.09991840, grad/param norm = 5.7535e-02, time/batch = 0.1137s	
2683/5250 (epoch 25.552), train_loss = 1.09510442, grad/param norm = 5.5136e-02, time/batch = 0.1140s	
2684/5250 (epoch 25.562), train_loss = 1.10833379, grad/param norm = 6.1097e-02, time/batch = 0.1141s	
2685/5250 (epoch 25.571), train_loss = 1.11449192, grad/param norm = 6.0139e-02, time/batch = 0.1143s	
2686/5250 (epoch 25.581), train_loss = 1.11198806, grad/param norm = 5.7757e-02, time/batch = 0.1142s	
2687/5250 (epoch 25.590), train_loss = 1.10884261, grad/param norm = 6.4060e-02, time/batch = 0.1142s	
2688/5250 (epoch 25.600), train_loss = 1.13143651, grad/param norm = 6.0843e-02, time/batch = 0.1136s	
2689/5250 (epoch 25.610), train_loss = 1.11660385, grad/param norm = 5.5023e-02, time/batch = 0.1144s	
2690/5250 (epoch 25.619), train_loss = 1.11307474, grad/param norm = 5.7379e-02, time/batch = 0.1142s	
2691/5250 (epoch 25.629), train_loss = 1.11119558, grad/param norm = 5.8367e-02, time/batch = 0.1149s	
2692/5250 (epoch 25.638), train_loss = 1.10492259, grad/param norm = 5.2699e-02, time/batch = 0.1134s	
2693/5250 (epoch 25.648), train_loss = 1.11155485, grad/param norm = 5.4099e-02, time/batch = 0.1142s	
2694/5250 (epoch 25.657), train_loss = 1.10347609, grad/param norm = 5.4723e-02, time/batch = 0.1139s	
2695/5250 (epoch 25.667), train_loss = 1.10744620, grad/param norm = 5.6686e-02, time/batch = 0.1143s	
2696/5250 (epoch 25.676), train_loss = 1.10071777, grad/param norm = 5.8027e-02, time/batch = 0.1142s	
2697/5250 (epoch 25.686), train_loss = 1.12926371, grad/param norm = 6.1615e-02, time/batch = 0.1141s	
2698/5250 (epoch 25.695), train_loss = 1.11589616, grad/param norm = 6.3706e-02, time/batch = 0.1139s	
2699/5250 (epoch 25.705), train_loss = 1.09657435, grad/param norm = 6.4264e-02, time/batch = 0.1142s	
2700/5250 (epoch 25.714), train_loss = 1.12787005, grad/param norm = 6.2697e-02, time/batch = 0.1143s	
2701/5250 (epoch 25.724), train_loss = 1.10521533, grad/param norm = 5.9182e-02, time/batch = 0.1147s	
2702/5250 (epoch 25.733), train_loss = 1.08904651, grad/param norm = 5.7601e-02, time/batch = 0.1137s	
2703/5250 (epoch 25.743), train_loss = 1.08927769, grad/param norm = 5.4751e-02, time/batch = 0.1140s	
2704/5250 (epoch 25.752), train_loss = 1.09544265, grad/param norm = 6.0101e-02, time/batch = 0.1141s	
2705/5250 (epoch 25.762), train_loss = 1.09138382, grad/param norm = 5.7499e-02, time/batch = 0.1142s	
2706/5250 (epoch 25.771), train_loss = 1.08761965, grad/param norm = 5.8850e-02, time/batch = 0.1143s	
2707/5250 (epoch 25.781), train_loss = 1.10830154, grad/param norm = 5.9009e-02, time/batch = 0.1144s	
2708/5250 (epoch 25.790), train_loss = 1.11064174, grad/param norm = 5.8908e-02, time/batch = 0.1137s	
2709/5250 (epoch 25.800), train_loss = 1.08364540, grad/param norm = 5.4986e-02, time/batch = 0.1143s	
2710/5250 (epoch 25.810), train_loss = 1.10033284, grad/param norm = 5.9523e-02, time/batch = 0.1143s	
2711/5250 (epoch 25.819), train_loss = 1.11049794, grad/param norm = 5.6828e-02, time/batch = 0.1150s	
2712/5250 (epoch 25.829), train_loss = 1.10834272, grad/param norm = 5.5255e-02, time/batch = 0.1136s	
2713/5250 (epoch 25.838), train_loss = 1.08086199, grad/param norm = 5.6798e-02, time/batch = 0.1138s	
2714/5250 (epoch 25.848), train_loss = 1.07348200, grad/param norm = 5.4715e-02, time/batch = 0.1141s	
2715/5250 (epoch 25.857), train_loss = 1.08858575, grad/param norm = 5.5102e-02, time/batch = 0.1143s	
2716/5250 (epoch 25.867), train_loss = 1.09385136, grad/param norm = 6.0987e-02, time/batch = 0.1143s	
2717/5250 (epoch 25.876), train_loss = 1.08666309, grad/param norm = 6.2846e-02, time/batch = 0.1142s	
2718/5250 (epoch 25.886), train_loss = 1.08364590, grad/param norm = 6.0466e-02, time/batch = 0.1137s	
2719/5250 (epoch 25.895), train_loss = 1.11746610, grad/param norm = 5.9809e-02, time/batch = 0.1142s	
2720/5250 (epoch 25.905), train_loss = 1.10689701, grad/param norm = 5.5741e-02, time/batch = 0.1142s	
2721/5250 (epoch 25.914), train_loss = 1.11507319, grad/param norm = 6.0211e-02, time/batch = 0.1149s	
2722/5250 (epoch 25.924), train_loss = 1.12308092, grad/param norm = 6.2157e-02, time/batch = 0.1138s	
2723/5250 (epoch 25.933), train_loss = 1.10812162, grad/param norm = 5.7012e-02, time/batch = 0.1140s	
2724/5250 (epoch 25.943), train_loss = 1.11671763, grad/param norm = 5.7145e-02, time/batch = 0.1140s	
2725/5250 (epoch 25.952), train_loss = 1.12776995, grad/param norm = 6.1005e-02, time/batch = 0.1145s	
2726/5250 (epoch 25.962), train_loss = 1.10718231, grad/param norm = 5.8904e-02, time/batch = 0.1142s	
2727/5250 (epoch 25.971), train_loss = 1.11626588, grad/param norm = 5.5792e-02, time/batch = 0.1141s	
2728/5250 (epoch 25.981), train_loss = 1.12251150, grad/param norm = 5.8747e-02, time/batch = 0.1136s	
2729/5250 (epoch 25.990), train_loss = 1.11842252, grad/param norm = 5.4469e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
2730/5250 (epoch 26.000), train_loss = 1.10789034, grad/param norm = 5.5103e-02, time/batch = 0.1143s	
2731/5250 (epoch 26.010), train_loss = 1.28592134, grad/param norm = 6.1035e-02, time/batch = 0.1149s	
2732/5250 (epoch 26.019), train_loss = 1.09504327, grad/param norm = 5.7137e-02, time/batch = 0.1135s	
2733/5250 (epoch 26.029), train_loss = 1.12305430, grad/param norm = 5.7622e-02, time/batch = 0.1141s	
2734/5250 (epoch 26.038), train_loss = 1.09678943, grad/param norm = 5.8172e-02, time/batch = 0.1142s	
2735/5250 (epoch 26.048), train_loss = 1.07059542, grad/param norm = 5.5440e-02, time/batch = 0.1143s	
2736/5250 (epoch 26.057), train_loss = 1.08094070, grad/param norm = 5.3919e-02, time/batch = 0.1141s	
2737/5250 (epoch 26.067), train_loss = 1.09379188, grad/param norm = 5.6613e-02, time/batch = 0.1142s	
2738/5250 (epoch 26.076), train_loss = 1.11268502, grad/param norm = 5.5988e-02, time/batch = 0.1136s	
2739/5250 (epoch 26.086), train_loss = 1.05345289, grad/param norm = 5.1485e-02, time/batch = 0.1142s	
2740/5250 (epoch 26.095), train_loss = 1.07452108, grad/param norm = 5.2662e-02, time/batch = 0.1143s	
2741/5250 (epoch 26.105), train_loss = 1.10276980, grad/param norm = 5.4319e-02, time/batch = 0.1149s	
2742/5250 (epoch 26.114), train_loss = 1.08688890, grad/param norm = 5.4004e-02, time/batch = 0.1136s	
2743/5250 (epoch 26.124), train_loss = 1.10270163, grad/param norm = 5.7055e-02, time/batch = 0.1139s	
2744/5250 (epoch 26.133), train_loss = 1.08421899, grad/param norm = 5.4754e-02, time/batch = 0.1141s	
2745/5250 (epoch 26.143), train_loss = 1.06692987, grad/param norm = 5.5408e-02, time/batch = 0.1143s	
2746/5250 (epoch 26.152), train_loss = 1.06869469, grad/param norm = 5.5875e-02, time/batch = 0.1142s	
2747/5250 (epoch 26.162), train_loss = 1.09824457, grad/param norm = 5.6000e-02, time/batch = 0.1156s	
2748/5250 (epoch 26.171), train_loss = 1.09087590, grad/param norm = 5.3170e-02, time/batch = 0.1138s	
2749/5250 (epoch 26.181), train_loss = 1.09013823, grad/param norm = 5.6907e-02, time/batch = 0.1142s	
2750/5250 (epoch 26.190), train_loss = 1.09230560, grad/param norm = 5.9696e-02, time/batch = 0.1144s	
2751/5250 (epoch 26.200), train_loss = 1.08735140, grad/param norm = 5.5503e-02, time/batch = 0.1149s	
2752/5250 (epoch 26.210), train_loss = 1.09215617, grad/param norm = 5.8894e-02, time/batch = 0.1139s	
2753/5250 (epoch 26.219), train_loss = 1.12523370, grad/param norm = 6.0522e-02, time/batch = 0.1140s	
2754/5250 (epoch 26.229), train_loss = 1.09894591, grad/param norm = 5.9057e-02, time/batch = 0.1141s	
2755/5250 (epoch 26.238), train_loss = 1.09262550, grad/param norm = 5.6813e-02, time/batch = 0.1142s	
2756/5250 (epoch 26.248), train_loss = 1.08797298, grad/param norm = 5.6463e-02, time/batch = 0.1140s	
2757/5250 (epoch 26.257), train_loss = 1.09764881, grad/param norm = 6.1643e-02, time/batch = 0.1142s	
2758/5250 (epoch 26.267), train_loss = 1.08831323, grad/param norm = 6.0592e-02, time/batch = 0.1136s	
2759/5250 (epoch 26.276), train_loss = 1.07798930, grad/param norm = 5.7519e-02, time/batch = 0.1143s	
2760/5250 (epoch 26.286), train_loss = 1.06116229, grad/param norm = 5.7208e-02, time/batch = 0.1145s	
2761/5250 (epoch 26.295), train_loss = 1.08357758, grad/param norm = 5.5634e-02, time/batch = 0.1147s	
2762/5250 (epoch 26.305), train_loss = 1.08450669, grad/param norm = 5.9116e-02, time/batch = 0.1137s	
2763/5250 (epoch 26.314), train_loss = 1.08574611, grad/param norm = 6.0247e-02, time/batch = 0.1140s	
2764/5250 (epoch 26.324), train_loss = 1.09390957, grad/param norm = 5.7307e-02, time/batch = 0.1141s	
2765/5250 (epoch 26.333), train_loss = 1.09645594, grad/param norm = 6.1259e-02, time/batch = 0.1142s	
2766/5250 (epoch 26.343), train_loss = 1.09502146, grad/param norm = 5.6508e-02, time/batch = 0.1142s	
2767/5250 (epoch 26.352), train_loss = 1.09696397, grad/param norm = 5.4870e-02, time/batch = 0.1142s	
2768/5250 (epoch 26.362), train_loss = 1.09788668, grad/param norm = 5.9474e-02, time/batch = 0.1136s	
2769/5250 (epoch 26.371), train_loss = 1.08149716, grad/param norm = 6.0648e-02, time/batch = 0.1142s	
2770/5250 (epoch 26.381), train_loss = 1.08163109, grad/param norm = 5.9026e-02, time/batch = 0.1143s	
2771/5250 (epoch 26.390), train_loss = 1.08703441, grad/param norm = 6.2929e-02, time/batch = 0.1149s	
2772/5250 (epoch 26.400), train_loss = 1.08812965, grad/param norm = 6.2716e-02, time/batch = 0.1136s	
2773/5250 (epoch 26.410), train_loss = 1.09569708, grad/param norm = 6.6720e-02, time/batch = 0.1140s	
2774/5250 (epoch 26.419), train_loss = 1.09370916, grad/param norm = 5.5448e-02, time/batch = 0.1141s	
2775/5250 (epoch 26.429), train_loss = 1.09794731, grad/param norm = 6.0000e-02, time/batch = 0.1142s	
2776/5250 (epoch 26.438), train_loss = 1.10530535, grad/param norm = 6.1691e-02, time/batch = 0.1142s	
2777/5250 (epoch 26.448), train_loss = 1.08080958, grad/param norm = 6.1884e-02, time/batch = 0.1140s	
2778/5250 (epoch 26.457), train_loss = 1.08666267, grad/param norm = 5.4804e-02, time/batch = 0.1137s	
2779/5250 (epoch 26.467), train_loss = 1.08641486, grad/param norm = 5.6950e-02, time/batch = 0.1142s	
2780/5250 (epoch 26.476), train_loss = 1.09219213, grad/param norm = 6.4504e-02, time/batch = 0.1142s	
2781/5250 (epoch 26.486), train_loss = 1.10852343, grad/param norm = 5.9777e-02, time/batch = 0.1149s	
2782/5250 (epoch 26.495), train_loss = 1.10777314, grad/param norm = 5.6721e-02, time/batch = 0.1136s	
2783/5250 (epoch 26.505), train_loss = 1.10419215, grad/param norm = 5.5371e-02, time/batch = 0.1141s	
2784/5250 (epoch 26.514), train_loss = 1.09209873, grad/param norm = 5.5027e-02, time/batch = 0.1141s	
2785/5250 (epoch 26.524), train_loss = 1.09545410, grad/param norm = 5.7019e-02, time/batch = 0.1140s	
2786/5250 (epoch 26.533), train_loss = 1.10510005, grad/param norm = 6.0202e-02, time/batch = 0.1143s	
2787/5250 (epoch 26.543), train_loss = 1.08752907, grad/param norm = 5.6920e-02, time/batch = 0.1143s	
2788/5250 (epoch 26.552), train_loss = 1.08409780, grad/param norm = 5.5128e-02, time/batch = 0.1135s	
2789/5250 (epoch 26.562), train_loss = 1.09591807, grad/param norm = 6.0933e-02, time/batch = 0.1144s	
2790/5250 (epoch 26.571), train_loss = 1.10112680, grad/param norm = 5.5322e-02, time/batch = 0.1143s	
2791/5250 (epoch 26.581), train_loss = 1.10017068, grad/param norm = 5.9703e-02, time/batch = 0.1149s	
2792/5250 (epoch 26.590), train_loss = 1.10139572, grad/param norm = 7.2477e-02, time/batch = 0.1138s	
2793/5250 (epoch 26.600), train_loss = 1.12175535, grad/param norm = 6.1650e-02, time/batch = 0.1140s	
2794/5250 (epoch 26.610), train_loss = 1.10489581, grad/param norm = 5.4743e-02, time/batch = 0.1143s	
2795/5250 (epoch 26.619), train_loss = 1.10135238, grad/param norm = 5.6936e-02, time/batch = 0.1143s	
2796/5250 (epoch 26.629), train_loss = 1.09723281, grad/param norm = 5.5470e-02, time/batch = 0.1142s	
2797/5250 (epoch 26.638), train_loss = 1.09397149, grad/param norm = 5.3393e-02, time/batch = 0.1143s	
2798/5250 (epoch 26.648), train_loss = 1.10218593, grad/param norm = 5.5156e-02, time/batch = 0.1138s	
2799/5250 (epoch 26.657), train_loss = 1.09153755, grad/param norm = 5.5836e-02, time/batch = 0.1144s	
2800/5250 (epoch 26.667), train_loss = 1.09710647, grad/param norm = 5.8250e-02, time/batch = 0.1141s	
2801/5250 (epoch 26.676), train_loss = 1.09093368, grad/param norm = 6.2018e-02, time/batch = 0.1147s	
2802/5250 (epoch 26.686), train_loss = 1.11722634, grad/param norm = 6.2172e-02, time/batch = 0.1137s	
2803/5250 (epoch 26.695), train_loss = 1.10170496, grad/param norm = 5.9003e-02, time/batch = 0.1139s	
2804/5250 (epoch 26.705), train_loss = 1.08351332, grad/param norm = 6.0092e-02, time/batch = 0.1141s	
2805/5250 (epoch 26.714), train_loss = 1.11551882, grad/param norm = 6.2244e-02, time/batch = 0.1142s	
2806/5250 (epoch 26.724), train_loss = 1.09380506, grad/param norm = 6.0189e-02, time/batch = 0.1143s	
2807/5250 (epoch 26.733), train_loss = 1.08018131, grad/param norm = 6.0880e-02, time/batch = 0.1143s	
2808/5250 (epoch 26.743), train_loss = 1.08075881, grad/param norm = 5.9644e-02, time/batch = 0.1137s	
2809/5250 (epoch 26.752), train_loss = 1.08484392, grad/param norm = 5.7706e-02, time/batch = 0.1144s	
2810/5250 (epoch 26.762), train_loss = 1.08282601, grad/param norm = 6.2208e-02, time/batch = 0.1143s	
2811/5250 (epoch 26.771), train_loss = 1.07674197, grad/param norm = 5.7502e-02, time/batch = 0.1149s	
2812/5250 (epoch 26.781), train_loss = 1.09703689, grad/param norm = 5.7671e-02, time/batch = 0.1138s	
2813/5250 (epoch 26.790), train_loss = 1.10366153, grad/param norm = 6.9357e-02, time/batch = 0.1139s	
2814/5250 (epoch 26.800), train_loss = 1.07909107, grad/param norm = 6.7458e-02, time/batch = 0.1142s	
2815/5250 (epoch 26.810), train_loss = 1.08989846, grad/param norm = 5.9973e-02, time/batch = 0.1142s	
2816/5250 (epoch 26.819), train_loss = 1.09930328, grad/param norm = 5.7481e-02, time/batch = 0.1143s	
2817/5250 (epoch 26.829), train_loss = 1.09785669, grad/param norm = 5.8593e-02, time/batch = 0.1143s	
2818/5250 (epoch 26.838), train_loss = 1.07015507, grad/param norm = 5.9125e-02, time/batch = 0.1168s	
2819/5250 (epoch 26.848), train_loss = 1.06368201, grad/param norm = 5.6799e-02, time/batch = 0.1146s	
2820/5250 (epoch 26.857), train_loss = 1.07693833, grad/param norm = 5.7350e-02, time/batch = 0.1143s	
2821/5250 (epoch 26.867), train_loss = 1.08220843, grad/param norm = 5.6774e-02, time/batch = 0.1148s	
2822/5250 (epoch 26.876), train_loss = 1.07070028, grad/param norm = 5.6442e-02, time/batch = 0.1136s	
2823/5250 (epoch 26.886), train_loss = 1.07164298, grad/param norm = 5.8310e-02, time/batch = 0.1140s	
2824/5250 (epoch 26.895), train_loss = 1.10371180, grad/param norm = 6.1124e-02, time/batch = 0.1142s	
2825/5250 (epoch 26.905), train_loss = 1.09558271, grad/param norm = 5.6043e-02, time/batch = 0.1143s	
2826/5250 (epoch 26.914), train_loss = 1.10137851, grad/param norm = 5.8666e-02, time/batch = 0.1141s	
2827/5250 (epoch 26.924), train_loss = 1.10858210, grad/param norm = 5.7832e-02, time/batch = 0.1142s	
2828/5250 (epoch 26.933), train_loss = 1.09535612, grad/param norm = 5.5445e-02, time/batch = 0.1137s	
2829/5250 (epoch 26.943), train_loss = 1.10477376, grad/param norm = 5.6387e-02, time/batch = 0.1144s	
2830/5250 (epoch 26.952), train_loss = 1.11713299, grad/param norm = 6.2549e-02, time/batch = 0.1143s	
2831/5250 (epoch 26.962), train_loss = 1.09511801, grad/param norm = 5.5913e-02, time/batch = 0.1149s	
2832/5250 (epoch 26.971), train_loss = 1.10535715, grad/param norm = 5.6312e-02, time/batch = 0.1137s	
2833/5250 (epoch 26.981), train_loss = 1.11447696, grad/param norm = 6.3987e-02, time/batch = 0.1143s	
2834/5250 (epoch 26.990), train_loss = 1.11008099, grad/param norm = 5.8830e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
2835/5250 (epoch 27.000), train_loss = 1.09876548, grad/param norm = 6.0719e-02, time/batch = 0.1142s	
2836/5250 (epoch 27.010), train_loss = 1.27742518, grad/param norm = 6.3110e-02, time/batch = 0.1142s	
2837/5250 (epoch 27.019), train_loss = 1.08506596, grad/param norm = 5.7824e-02, time/batch = 0.1143s	
2838/5250 (epoch 27.029), train_loss = 1.11105242, grad/param norm = 5.6355e-02, time/batch = 0.1136s	
2839/5250 (epoch 27.038), train_loss = 1.08394563, grad/param norm = 5.6809e-02, time/batch = 0.1144s	
2840/5250 (epoch 27.048), train_loss = 1.05891090, grad/param norm = 5.5894e-02, time/batch = 0.1145s	
2841/5250 (epoch 27.057), train_loss = 1.06869257, grad/param norm = 5.2620e-02, time/batch = 0.1148s	
2842/5250 (epoch 27.067), train_loss = 1.08387707, grad/param norm = 5.8656e-02, time/batch = 0.1137s	
2843/5250 (epoch 27.076), train_loss = 1.10455048, grad/param norm = 6.1091e-02, time/batch = 0.1139s	
2844/5250 (epoch 27.086), train_loss = 1.04445619, grad/param norm = 5.2784e-02, time/batch = 0.1141s	
2845/5250 (epoch 27.095), train_loss = 1.06183367, grad/param norm = 5.3068e-02, time/batch = 0.1143s	
2846/5250 (epoch 27.105), train_loss = 1.09269974, grad/param norm = 5.6274e-02, time/batch = 0.1142s	
2847/5250 (epoch 27.114), train_loss = 1.07647604, grad/param norm = 5.4414e-02, time/batch = 0.1143s	
2848/5250 (epoch 27.124), train_loss = 1.09184220, grad/param norm = 5.5397e-02, time/batch = 0.1137s	
2849/5250 (epoch 27.133), train_loss = 1.07281001, grad/param norm = 5.4849e-02, time/batch = 0.1144s	
2850/5250 (epoch 27.143), train_loss = 1.05509788, grad/param norm = 5.6057e-02, time/batch = 0.1141s	
2851/5250 (epoch 27.152), train_loss = 1.05898374, grad/param norm = 5.7039e-02, time/batch = 0.1149s	
2852/5250 (epoch 27.162), train_loss = 1.08672375, grad/param norm = 5.6251e-02, time/batch = 0.1136s	
2853/5250 (epoch 27.171), train_loss = 1.08088980, grad/param norm = 5.7167e-02, time/batch = 0.1138s	
2854/5250 (epoch 27.181), train_loss = 1.08123672, grad/param norm = 5.7687e-02, time/batch = 0.1142s	
2855/5250 (epoch 27.190), train_loss = 1.08159345, grad/param norm = 6.0052e-02, time/batch = 0.1143s	
2856/5250 (epoch 27.200), train_loss = 1.07903497, grad/param norm = 6.1020e-02, time/batch = 0.1143s	
2857/5250 (epoch 27.210), train_loss = 1.08321360, grad/param norm = 5.7152e-02, time/batch = 0.1143s	
2858/5250 (epoch 27.219), train_loss = 1.11315395, grad/param norm = 5.6920e-02, time/batch = 0.1135s	
2859/5250 (epoch 27.229), train_loss = 1.08641775, grad/param norm = 5.8154e-02, time/batch = 0.1143s	
2860/5250 (epoch 27.238), train_loss = 1.08268353, grad/param norm = 6.0169e-02, time/batch = 0.1144s	
2861/5250 (epoch 27.248), train_loss = 1.08091019, grad/param norm = 6.4162e-02, time/batch = 0.1147s	
2862/5250 (epoch 27.257), train_loss = 1.08663190, grad/param norm = 6.0094e-02, time/batch = 0.1136s	
2863/5250 (epoch 27.267), train_loss = 1.07557635, grad/param norm = 5.6649e-02, time/batch = 0.1140s	
2864/5250 (epoch 27.276), train_loss = 1.06722104, grad/param norm = 5.8621e-02, time/batch = 0.1140s	
2865/5250 (epoch 27.286), train_loss = 1.05039684, grad/param norm = 6.1611e-02, time/batch = 0.1143s	
2866/5250 (epoch 27.295), train_loss = 1.07396897, grad/param norm = 6.0755e-02, time/batch = 0.1144s	
2867/5250 (epoch 27.305), train_loss = 1.07951570, grad/param norm = 7.0760e-02, time/batch = 0.1144s	
2868/5250 (epoch 27.314), train_loss = 1.07549188, grad/param norm = 6.3054e-02, time/batch = 0.1138s	
2869/5250 (epoch 27.324), train_loss = 1.08288269, grad/param norm = 5.6799e-02, time/batch = 0.1143s	
2870/5250 (epoch 27.333), train_loss = 1.08371190, grad/param norm = 6.0999e-02, time/batch = 0.1142s	
2871/5250 (epoch 27.343), train_loss = 1.08425058, grad/param norm = 5.7849e-02, time/batch = 0.1148s	
2872/5250 (epoch 27.352), train_loss = 1.08529011, grad/param norm = 5.5218e-02, time/batch = 0.1136s	
2873/5250 (epoch 27.362), train_loss = 1.08425580, grad/param norm = 5.5633e-02, time/batch = 0.1139s	
2874/5250 (epoch 27.371), train_loss = 1.06672593, grad/param norm = 5.4827e-02, time/batch = 0.1142s	
2875/5250 (epoch 27.381), train_loss = 1.07071493, grad/param norm = 5.8340e-02, time/batch = 0.1143s	
2876/5250 (epoch 27.390), train_loss = 1.07568821, grad/param norm = 6.5910e-02, time/batch = 0.1144s	
2877/5250 (epoch 27.400), train_loss = 1.08063547, grad/param norm = 6.4171e-02, time/batch = 0.1145s	
2878/5250 (epoch 27.410), train_loss = 1.08532749, grad/param norm = 6.3070e-02, time/batch = 0.1136s	
2879/5250 (epoch 27.419), train_loss = 1.08768081, grad/param norm = 7.1138e-02, time/batch = 0.1143s	
2880/5250 (epoch 27.429), train_loss = 1.09587007, grad/param norm = 6.7558e-02, time/batch = 0.1143s	
2881/5250 (epoch 27.438), train_loss = 1.09166261, grad/param norm = 6.0144e-02, time/batch = 0.1149s	
2882/5250 (epoch 27.448), train_loss = 1.07184052, grad/param norm = 6.1474e-02, time/batch = 0.1137s	
2883/5250 (epoch 27.457), train_loss = 1.07920306, grad/param norm = 5.8529e-02, time/batch = 0.1140s	
2884/5250 (epoch 27.467), train_loss = 1.07565424, grad/param norm = 5.5802e-02, time/batch = 0.1143s	
2885/5250 (epoch 27.476), train_loss = 1.07906612, grad/param norm = 5.9955e-02, time/batch = 0.1142s	
2886/5250 (epoch 27.486), train_loss = 1.09588640, grad/param norm = 5.8364e-02, time/batch = 0.1142s	
2887/5250 (epoch 27.495), train_loss = 1.09572224, grad/param norm = 5.7420e-02, time/batch = 0.1143s	
2888/5250 (epoch 27.505), train_loss = 1.09309422, grad/param norm = 5.5089e-02, time/batch = 0.1136s	
2889/5250 (epoch 27.514), train_loss = 1.08135588, grad/param norm = 5.5495e-02, time/batch = 0.1151s	
2890/5250 (epoch 27.524), train_loss = 1.08573988, grad/param norm = 5.9536e-02, time/batch = 0.1144s	
2891/5250 (epoch 27.533), train_loss = 1.09281781, grad/param norm = 6.0221e-02, time/batch = 0.1150s	
2892/5250 (epoch 27.543), train_loss = 1.07747949, grad/param norm = 5.7719e-02, time/batch = 0.1138s	
2893/5250 (epoch 27.552), train_loss = 1.07562865, grad/param norm = 5.6905e-02, time/batch = 0.1140s	
2894/5250 (epoch 27.562), train_loss = 1.08545699, grad/param norm = 6.0614e-02, time/batch = 0.1141s	
2895/5250 (epoch 27.571), train_loss = 1.09140873, grad/param norm = 5.7641e-02, time/batch = 0.1142s	
2896/5250 (epoch 27.581), train_loss = 1.09016751, grad/param norm = 6.2155e-02, time/batch = 0.1144s	
2897/5250 (epoch 27.590), train_loss = 1.08881471, grad/param norm = 6.7057e-02, time/batch = 0.1143s	
2898/5250 (epoch 27.600), train_loss = 1.11004680, grad/param norm = 6.1125e-02, time/batch = 0.1136s	
2899/5250 (epoch 27.610), train_loss = 1.09731317, grad/param norm = 6.2022e-02, time/batch = 0.1144s	
2900/5250 (epoch 27.619), train_loss = 1.09357710, grad/param norm = 6.2324e-02, time/batch = 0.1143s	
2901/5250 (epoch 27.629), train_loss = 1.08962543, grad/param norm = 5.8077e-02, time/batch = 0.1150s	
2902/5250 (epoch 27.638), train_loss = 1.08341230, grad/param norm = 5.3082e-02, time/batch = 0.1135s	
2903/5250 (epoch 27.648), train_loss = 1.09092687, grad/param norm = 5.4789e-02, time/batch = 0.1139s	
2904/5250 (epoch 27.657), train_loss = 1.07868100, grad/param norm = 5.3921e-02, time/batch = 0.1142s	
2905/5250 (epoch 27.667), train_loss = 1.08376439, grad/param norm = 5.4577e-02, time/batch = 0.1142s	
2906/5250 (epoch 27.676), train_loss = 1.07692959, grad/param norm = 5.5934e-02, time/batch = 0.1142s	
2907/5250 (epoch 27.686), train_loss = 1.10374193, grad/param norm = 6.0668e-02, time/batch = 0.1142s	
2908/5250 (epoch 27.695), train_loss = 1.09458486, grad/param norm = 6.2714e-02, time/batch = 0.1136s	
2909/5250 (epoch 27.705), train_loss = 1.07211352, grad/param norm = 6.2185e-02, time/batch = 0.1143s	
2910/5250 (epoch 27.714), train_loss = 1.10074429, grad/param norm = 5.6394e-02, time/batch = 0.1143s	
2911/5250 (epoch 27.724), train_loss = 1.08004236, grad/param norm = 5.6575e-02, time/batch = 0.1149s	
2912/5250 (epoch 27.733), train_loss = 1.06813548, grad/param norm = 5.9918e-02, time/batch = 0.1138s	
2913/5250 (epoch 27.743), train_loss = 1.06576832, grad/param norm = 5.5261e-02, time/batch = 0.1138s	
2914/5250 (epoch 27.752), train_loss = 1.07462203, grad/param norm = 6.0778e-02, time/batch = 0.1140s	
2915/5250 (epoch 27.762), train_loss = 1.06967505, grad/param norm = 5.8136e-02, time/batch = 0.1144s	
2916/5250 (epoch 27.771), train_loss = 1.06570002, grad/param norm = 5.9372e-02, time/batch = 0.1143s	
2917/5250 (epoch 27.781), train_loss = 1.08886350, grad/param norm = 6.0150e-02, time/batch = 0.1142s	
2918/5250 (epoch 27.790), train_loss = 1.08736398, grad/param norm = 5.8510e-02, time/batch = 0.1136s	
2919/5250 (epoch 27.800), train_loss = 1.06227001, grad/param norm = 5.6395e-02, time/batch = 0.1144s	
2920/5250 (epoch 27.810), train_loss = 1.08280950, grad/param norm = 6.8429e-02, time/batch = 0.1146s	
2921/5250 (epoch 27.819), train_loss = 1.09082131, grad/param norm = 6.2052e-02, time/batch = 0.1155s	
2922/5250 (epoch 27.829), train_loss = 1.08615329, grad/param norm = 5.9304e-02, time/batch = 0.1141s	
2923/5250 (epoch 27.838), train_loss = 1.05984928, grad/param norm = 5.8116e-02, time/batch = 0.1145s	
2924/5250 (epoch 27.848), train_loss = 1.05280371, grad/param norm = 5.9538e-02, time/batch = 0.1147s	
2925/5250 (epoch 27.857), train_loss = 1.06924052, grad/param norm = 6.1948e-02, time/batch = 0.1147s	
2926/5250 (epoch 27.867), train_loss = 1.07282711, grad/param norm = 6.1545e-02, time/batch = 0.1147s	
2927/5250 (epoch 27.876), train_loss = 1.06096034, grad/param norm = 5.9609e-02, time/batch = 0.1148s	
2928/5250 (epoch 27.886), train_loss = 1.06348585, grad/param norm = 6.4716e-02, time/batch = 0.1143s	
2929/5250 (epoch 27.895), train_loss = 1.09641565, grad/param norm = 6.7946e-02, time/batch = 0.1150s	
2930/5250 (epoch 27.905), train_loss = 1.08814759, grad/param norm = 6.0756e-02, time/batch = 0.1148s	
2931/5250 (epoch 27.914), train_loss = 1.09207545, grad/param norm = 5.9184e-02, time/batch = 0.1156s	
2932/5250 (epoch 27.924), train_loss = 1.09838814, grad/param norm = 6.0205e-02, time/batch = 0.1145s	
2933/5250 (epoch 27.933), train_loss = 1.08481993, grad/param norm = 5.6885e-02, time/batch = 0.1148s	
2934/5250 (epoch 27.943), train_loss = 1.09334947, grad/param norm = 5.7452e-02, time/batch = 0.1149s	
2935/5250 (epoch 27.952), train_loss = 1.10422617, grad/param norm = 5.8861e-02, time/batch = 0.1148s	
2936/5250 (epoch 27.962), train_loss = 1.08391518, grad/param norm = 5.7760e-02, time/batch = 0.1147s	
2937/5250 (epoch 27.971), train_loss = 1.09514920, grad/param norm = 5.5904e-02, time/batch = 0.1150s	
2938/5250 (epoch 27.981), train_loss = 1.10140193, grad/param norm = 6.1219e-02, time/batch = 0.1142s	
2939/5250 (epoch 27.990), train_loss = 1.09738724, grad/param norm = 5.5981e-02, time/batch = 0.1148s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
2940/5250 (epoch 28.000), train_loss = 1.08606992, grad/param norm = 5.6632e-02, time/batch = 0.1153s	
2941/5250 (epoch 28.010), train_loss = 1.26516803, grad/param norm = 6.3991e-02, time/batch = 0.1154s	
2942/5250 (epoch 28.019), train_loss = 1.07650889, grad/param norm = 6.1296e-02, time/batch = 0.1143s	
2943/5250 (epoch 28.029), train_loss = 1.10222800, grad/param norm = 5.9257e-02, time/batch = 0.1147s	
2944/5250 (epoch 28.038), train_loss = 1.07341425, grad/param norm = 5.8132e-02, time/batch = 0.1148s	
2945/5250 (epoch 28.048), train_loss = 1.04909048, grad/param norm = 5.6459e-02, time/batch = 0.1151s	
2946/5250 (epoch 28.057), train_loss = 1.05800349, grad/param norm = 5.4018e-02, time/batch = 0.1147s	
2947/5250 (epoch 28.067), train_loss = 1.07291214, grad/param norm = 5.7644e-02, time/batch = 0.1148s	
2948/5250 (epoch 28.076), train_loss = 1.09151514, grad/param norm = 5.5643e-02, time/batch = 0.1144s	
2949/5250 (epoch 28.086), train_loss = 1.03393112, grad/param norm = 5.4690e-02, time/batch = 0.1149s	
2950/5250 (epoch 28.095), train_loss = 1.05399893, grad/param norm = 5.5364e-02, time/batch = 0.1148s	
2951/5250 (epoch 28.105), train_loss = 1.08192488, grad/param norm = 5.5066e-02, time/batch = 0.1152s	
2952/5250 (epoch 28.114), train_loss = 1.06669638, grad/param norm = 5.6097e-02, time/batch = 0.1141s	
2953/5250 (epoch 28.124), train_loss = 1.08159243, grad/param norm = 5.7153e-02, time/batch = 0.1146s	
2954/5250 (epoch 28.133), train_loss = 1.06289191, grad/param norm = 5.5782e-02, time/batch = 0.1151s	
2955/5250 (epoch 28.143), train_loss = 1.04592053, grad/param norm = 5.7991e-02, time/batch = 0.1147s	
2956/5250 (epoch 28.152), train_loss = 1.04964695, grad/param norm = 5.9671e-02, time/batch = 0.1148s	
2957/5250 (epoch 28.162), train_loss = 1.07656244, grad/param norm = 5.7352e-02, time/batch = 0.1148s	
2958/5250 (epoch 28.171), train_loss = 1.07080646, grad/param norm = 5.9183e-02, time/batch = 0.1142s	
2959/5250 (epoch 28.181), train_loss = 1.07089427, grad/param norm = 6.1699e-02, time/batch = 0.1151s	
2960/5250 (epoch 28.190), train_loss = 1.07413869, grad/param norm = 6.4504e-02, time/batch = 0.1170s	
2961/5250 (epoch 28.200), train_loss = 1.07072423, grad/param norm = 6.4639e-02, time/batch = 0.1156s	
2962/5250 (epoch 28.210), train_loss = 1.07542755, grad/param norm = 5.7956e-02, time/batch = 0.1142s	
2963/5250 (epoch 28.219), train_loss = 1.10404050, grad/param norm = 5.7526e-02, time/batch = 0.1148s	
2964/5250 (epoch 28.229), train_loss = 1.07450442, grad/param norm = 5.6899e-02, time/batch = 0.1148s	
2965/5250 (epoch 28.238), train_loss = 1.07034483, grad/param norm = 5.6739e-02, time/batch = 0.1151s	
2966/5250 (epoch 28.248), train_loss = 1.06710060, grad/param norm = 5.6521e-02, time/batch = 0.1149s	
2967/5250 (epoch 28.257), train_loss = 1.07452911, grad/param norm = 5.8290e-02, time/batch = 0.1148s	
2968/5250 (epoch 28.267), train_loss = 1.06614008, grad/param norm = 5.9162e-02, time/batch = 0.1142s	
2969/5250 (epoch 28.276), train_loss = 1.05578460, grad/param norm = 5.8011e-02, time/batch = 0.1151s	
2970/5250 (epoch 28.286), train_loss = 1.03745186, grad/param norm = 5.7711e-02, time/batch = 0.1147s	
2971/5250 (epoch 28.295), train_loss = 1.06138192, grad/param norm = 5.7286e-02, time/batch = 0.1154s	
2972/5250 (epoch 28.305), train_loss = 1.06137202, grad/param norm = 5.6194e-02, time/batch = 0.1140s	
2973/5250 (epoch 28.314), train_loss = 1.06469644, grad/param norm = 6.1790e-02, time/batch = 0.1148s	
2974/5250 (epoch 28.324), train_loss = 1.07650991, grad/param norm = 6.6612e-02, time/batch = 0.1147s	
2975/5250 (epoch 28.333), train_loss = 1.07780613, grad/param norm = 6.9721e-02, time/batch = 0.1151s	
2976/5250 (epoch 28.343), train_loss = 1.07606188, grad/param norm = 6.3344e-02, time/batch = 0.1149s	
2977/5250 (epoch 28.352), train_loss = 1.08090529, grad/param norm = 6.2477e-02, time/batch = 0.1149s	
2978/5250 (epoch 28.362), train_loss = 1.07592379, grad/param norm = 6.1256e-02, time/batch = 0.1142s	
2979/5250 (epoch 28.371), train_loss = 1.05668563, grad/param norm = 5.7330e-02, time/batch = 0.1150s	
2980/5250 (epoch 28.381), train_loss = 1.06005973, grad/param norm = 5.8303e-02, time/batch = 0.1147s	
2981/5250 (epoch 28.390), train_loss = 1.06408511, grad/param norm = 6.4726e-02, time/batch = 0.1154s	
2982/5250 (epoch 28.400), train_loss = 1.06606560, grad/param norm = 5.6813e-02, time/batch = 0.1143s	
2983/5250 (epoch 28.410), train_loss = 1.07048031, grad/param norm = 5.8485e-02, time/batch = 0.1147s	
2984/5250 (epoch 28.419), train_loss = 1.07141195, grad/param norm = 5.9389e-02, time/batch = 0.1147s	
2985/5250 (epoch 28.429), train_loss = 1.08212054, grad/param norm = 6.1943e-02, time/batch = 0.1147s	
2986/5250 (epoch 28.438), train_loss = 1.07943981, grad/param norm = 5.9052e-02, time/batch = 0.1149s	
2987/5250 (epoch 28.448), train_loss = 1.05887458, grad/param norm = 6.0208e-02, time/batch = 0.1149s	
2988/5250 (epoch 28.457), train_loss = 1.06913670, grad/param norm = 5.7448e-02, time/batch = 0.1142s	
2989/5250 (epoch 28.467), train_loss = 1.06490796, grad/param norm = 5.8624e-02, time/batch = 0.1149s	
2990/5250 (epoch 28.476), train_loss = 1.07100027, grad/param norm = 6.3386e-02, time/batch = 0.1148s	
2991/5250 (epoch 28.486), train_loss = 1.09045423, grad/param norm = 6.9776e-02, time/batch = 0.1163s	
2992/5250 (epoch 28.495), train_loss = 1.08938301, grad/param norm = 6.2408e-02, time/batch = 0.1140s	
2993/5250 (epoch 28.505), train_loss = 1.08281508, grad/param norm = 5.6271e-02, time/batch = 0.1140s	
2994/5250 (epoch 28.514), train_loss = 1.07118459, grad/param norm = 5.7092e-02, time/batch = 0.1142s	
2995/5250 (epoch 28.524), train_loss = 1.07461630, grad/param norm = 5.9163e-02, time/batch = 0.1143s	
2996/5250 (epoch 28.533), train_loss = 1.07994346, grad/param norm = 5.5883e-02, time/batch = 0.1141s	
2997/5250 (epoch 28.543), train_loss = 1.06433995, grad/param norm = 5.6945e-02, time/batch = 0.1143s	
2998/5250 (epoch 28.552), train_loss = 1.06759040, grad/param norm = 5.9144e-02, time/batch = 0.1136s	
2999/5250 (epoch 28.562), train_loss = 1.07498054, grad/param norm = 6.1918e-02, time/batch = 0.1144s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch28.57_1.4850.t7	
3000/5250 (epoch 28.571), train_loss = 1.07984170, grad/param norm = 5.7598e-02, time/batch = 0.1143s	
3001/5250 (epoch 28.581), train_loss = 1.44162763, grad/param norm = 8.1127e-02, time/batch = 0.1152s	
3002/5250 (epoch 28.590), train_loss = 1.08601462, grad/param norm = 6.6434e-02, time/batch = 0.1135s	
3003/5250 (epoch 28.600), train_loss = 1.09834433, grad/param norm = 6.3144e-02, time/batch = 0.1140s	
3004/5250 (epoch 28.610), train_loss = 1.08996016, grad/param norm = 6.1931e-02, time/batch = 0.1142s	
3005/5250 (epoch 28.619), train_loss = 1.07995126, grad/param norm = 5.8724e-02, time/batch = 0.1142s	
3006/5250 (epoch 28.629), train_loss = 1.07717712, grad/param norm = 5.8178e-02, time/batch = 0.1141s	
3007/5250 (epoch 28.638), train_loss = 1.07510409, grad/param norm = 5.6451e-02, time/batch = 0.1144s	
3008/5250 (epoch 28.648), train_loss = 1.08223271, grad/param norm = 5.5707e-02, time/batch = 0.1138s	
3009/5250 (epoch 28.657), train_loss = 1.07085873, grad/param norm = 5.8257e-02, time/batch = 0.1145s	
3010/5250 (epoch 28.667), train_loss = 1.07510369, grad/param norm = 5.7720e-02, time/batch = 0.1144s	
3011/5250 (epoch 28.676), train_loss = 1.06597174, grad/param norm = 5.5953e-02, time/batch = 0.1148s	
3012/5250 (epoch 28.686), train_loss = 1.09183996, grad/param norm = 5.9879e-02, time/batch = 0.1135s	
3013/5250 (epoch 28.695), train_loss = 1.08440642, grad/param norm = 6.2318e-02, time/batch = 0.1139s	
3014/5250 (epoch 28.705), train_loss = 1.06209494, grad/param norm = 6.2513e-02, time/batch = 0.1141s	
3015/5250 (epoch 28.714), train_loss = 1.08993940, grad/param norm = 5.7741e-02, time/batch = 0.1145s	
3016/5250 (epoch 28.724), train_loss = 1.06931495, grad/param norm = 5.5896e-02, time/batch = 0.1143s	
3017/5250 (epoch 28.733), train_loss = 1.05620314, grad/param norm = 5.7466e-02, time/batch = 0.1142s	
3018/5250 (epoch 28.743), train_loss = 1.05434399, grad/param norm = 5.4375e-02, time/batch = 0.1136s	
3019/5250 (epoch 28.752), train_loss = 1.06243832, grad/param norm = 5.9014e-02, time/batch = 0.1142s	
3020/5250 (epoch 28.762), train_loss = 1.05636740, grad/param norm = 5.5530e-02, time/batch = 0.1143s	
3021/5250 (epoch 28.771), train_loss = 1.05404887, grad/param norm = 6.0186e-02, time/batch = 0.1149s	
3022/5250 (epoch 28.781), train_loss = 1.07864457, grad/param norm = 5.8782e-02, time/batch = 0.1136s	
3023/5250 (epoch 28.790), train_loss = 1.07700608, grad/param norm = 6.0541e-02, time/batch = 0.1141s	
3024/5250 (epoch 28.800), train_loss = 1.05238187, grad/param norm = 5.9693e-02, time/batch = 0.1141s	
3025/5250 (epoch 28.810), train_loss = 1.06819778, grad/param norm = 6.0234e-02, time/batch = 0.1141s	
3026/5250 (epoch 28.819), train_loss = 1.07703531, grad/param norm = 5.7967e-02, time/batch = 0.1142s	
3027/5250 (epoch 28.829), train_loss = 1.07670095, grad/param norm = 6.2730e-02, time/batch = 0.1166s	
3028/5250 (epoch 28.838), train_loss = 1.04951819, grad/param norm = 5.9585e-02, time/batch = 0.1136s	
3029/5250 (epoch 28.848), train_loss = 1.04088200, grad/param norm = 5.8190e-02, time/batch = 0.1144s	
3030/5250 (epoch 28.857), train_loss = 1.05595008, grad/param norm = 6.0860e-02, time/batch = 0.1143s	
3031/5250 (epoch 28.867), train_loss = 1.06201053, grad/param norm = 6.0457e-02, time/batch = 0.1150s	
3032/5250 (epoch 28.876), train_loss = 1.05000118, grad/param norm = 6.1566e-02, time/batch = 0.1135s	
3033/5250 (epoch 28.886), train_loss = 1.05346060, grad/param norm = 6.4279e-02, time/batch = 0.1141s	
3034/5250 (epoch 28.895), train_loss = 1.08198643, grad/param norm = 6.1931e-02, time/batch = 0.1142s	
3035/5250 (epoch 28.905), train_loss = 1.07571149, grad/param norm = 6.3062e-02, time/batch = 0.1142s	
3036/5250 (epoch 28.914), train_loss = 1.08558854, grad/param norm = 6.7087e-02, time/batch = 0.1141s	
3037/5250 (epoch 28.924), train_loss = 1.08939812, grad/param norm = 6.4391e-02, time/batch = 0.1145s	
3038/5250 (epoch 28.933), train_loss = 1.07679384, grad/param norm = 5.6412e-02, time/batch = 0.1139s	
3039/5250 (epoch 28.943), train_loss = 1.08287870, grad/param norm = 5.7438e-02, time/batch = 0.1142s	
3040/5250 (epoch 28.952), train_loss = 1.09383538, grad/param norm = 6.0891e-02, time/batch = 0.1141s	
3041/5250 (epoch 28.962), train_loss = 1.07444870, grad/param norm = 5.6577e-02, time/batch = 0.1150s	
3042/5250 (epoch 28.971), train_loss = 1.08508905, grad/param norm = 5.7019e-02, time/batch = 0.1137s	
3043/5250 (epoch 28.981), train_loss = 1.09079238, grad/param norm = 6.1014e-02, time/batch = 0.1140s	
3044/5250 (epoch 28.990), train_loss = 1.08587803, grad/param norm = 5.6583e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
3045/5250 (epoch 29.000), train_loss = 1.07491718, grad/param norm = 5.7511e-02, time/batch = 0.1140s	
3046/5250 (epoch 29.010), train_loss = 1.25420671, grad/param norm = 6.2823e-02, time/batch = 0.1143s	
3047/5250 (epoch 29.019), train_loss = 1.06517345, grad/param norm = 5.8377e-02, time/batch = 0.1142s	
3048/5250 (epoch 29.029), train_loss = 1.09023252, grad/param norm = 5.6874e-02, time/batch = 0.1136s	
3049/5250 (epoch 29.038), train_loss = 1.06280880, grad/param norm = 5.7563e-02, time/batch = 0.1145s	
3050/5250 (epoch 29.048), train_loss = 1.03947312, grad/param norm = 5.9266e-02, time/batch = 0.1141s	
3051/5250 (epoch 29.057), train_loss = 1.04869212, grad/param norm = 5.5647e-02, time/batch = 0.1149s	
3052/5250 (epoch 29.067), train_loss = 1.06389865, grad/param norm = 6.1328e-02, time/batch = 0.1137s	
3053/5250 (epoch 29.076), train_loss = 1.08383232, grad/param norm = 6.0293e-02, time/batch = 0.1140s	
3054/5250 (epoch 29.086), train_loss = 1.02424905, grad/param norm = 5.3745e-02, time/batch = 0.1143s	
3055/5250 (epoch 29.095), train_loss = 1.04408834, grad/param norm = 5.4727e-02, time/batch = 0.1143s	
3056/5250 (epoch 29.105), train_loss = 1.07251998, grad/param norm = 5.7972e-02, time/batch = 0.1142s	
3057/5250 (epoch 29.114), train_loss = 1.05614788, grad/param norm = 5.6219e-02, time/batch = 0.1141s	
3058/5250 (epoch 29.124), train_loss = 1.07087390, grad/param norm = 5.6750e-02, time/batch = 0.1137s	
3059/5250 (epoch 29.133), train_loss = 1.05277301, grad/param norm = 5.7007e-02, time/batch = 0.1141s	
3060/5250 (epoch 29.143), train_loss = 1.03478981, grad/param norm = 5.7368e-02, time/batch = 0.1143s	
3061/5250 (epoch 29.152), train_loss = 1.03972840, grad/param norm = 5.9514e-02, time/batch = 0.1148s	
3062/5250 (epoch 29.162), train_loss = 1.06544736, grad/param norm = 5.8215e-02, time/batch = 0.1138s	
3063/5250 (epoch 29.171), train_loss = 1.05947610, grad/param norm = 5.6289e-02, time/batch = 0.1142s	
3064/5250 (epoch 29.181), train_loss = 1.05909989, grad/param norm = 5.9149e-02, time/batch = 0.1143s	
3065/5250 (epoch 29.190), train_loss = 1.06143627, grad/param norm = 6.5848e-02, time/batch = 0.1144s	
3066/5250 (epoch 29.200), train_loss = 1.05908901, grad/param norm = 6.3659e-02, time/batch = 0.1141s	
3067/5250 (epoch 29.210), train_loss = 1.06972875, grad/param norm = 6.7541e-02, time/batch = 0.1143s	
3068/5250 (epoch 29.219), train_loss = 1.09814914, grad/param norm = 6.3931e-02, time/batch = 0.1136s	
3069/5250 (epoch 29.229), train_loss = 1.06457933, grad/param norm = 5.8847e-02, time/batch = 0.1143s	
3070/5250 (epoch 29.238), train_loss = 1.06015118, grad/param norm = 5.8255e-02, time/batch = 0.1145s	
3071/5250 (epoch 29.248), train_loss = 1.05814352, grad/param norm = 5.8441e-02, time/batch = 0.1157s	
3072/5250 (epoch 29.257), train_loss = 1.06523347, grad/param norm = 6.1781e-02, time/batch = 0.1139s	
3073/5250 (epoch 29.267), train_loss = 1.05674934, grad/param norm = 5.8342e-02, time/batch = 0.1141s	
3074/5250 (epoch 29.276), train_loss = 1.04460690, grad/param norm = 6.0034e-02, time/batch = 0.1144s	
3075/5250 (epoch 29.286), train_loss = 1.02781601, grad/param norm = 5.9451e-02, time/batch = 0.1144s	
3076/5250 (epoch 29.295), train_loss = 1.05092397, grad/param norm = 5.5802e-02, time/batch = 0.1143s	
3077/5250 (epoch 29.305), train_loss = 1.05297757, grad/param norm = 6.4742e-02, time/batch = 0.1143s	
3078/5250 (epoch 29.314), train_loss = 1.05220385, grad/param norm = 6.0949e-02, time/batch = 0.1137s	
3079/5250 (epoch 29.324), train_loss = 1.06177108, grad/param norm = 5.7260e-02, time/batch = 0.1144s	
3080/5250 (epoch 29.333), train_loss = 1.06194905, grad/param norm = 6.0276e-02, time/batch = 0.1146s	
3081/5250 (epoch 29.343), train_loss = 1.06218002, grad/param norm = 5.7956e-02, time/batch = 0.1156s	
3082/5250 (epoch 29.352), train_loss = 1.06696072, grad/param norm = 5.7246e-02, time/batch = 0.1136s	
3083/5250 (epoch 29.362), train_loss = 1.06421580, grad/param norm = 6.0445e-02, time/batch = 0.1139s	
3084/5250 (epoch 29.371), train_loss = 1.04593231, grad/param norm = 6.1244e-02, time/batch = 0.1142s	
3085/5250 (epoch 29.381), train_loss = 1.05367046, grad/param norm = 6.4601e-02, time/batch = 0.1143s	
3086/5250 (epoch 29.390), train_loss = 1.05389171, grad/param norm = 6.5742e-02, time/batch = 0.1144s	
3087/5250 (epoch 29.400), train_loss = 1.05859240, grad/param norm = 6.9872e-02, time/batch = 0.1141s	
3088/5250 (epoch 29.410), train_loss = 1.06481511, grad/param norm = 6.7532e-02, time/batch = 0.1136s	
3089/5250 (epoch 29.419), train_loss = 1.06503976, grad/param norm = 6.8750e-02, time/batch = 0.1142s	
3090/5250 (epoch 29.429), train_loss = 1.07218836, grad/param norm = 6.1739e-02, time/batch = 0.1143s	
3091/5250 (epoch 29.438), train_loss = 1.06658244, grad/param norm = 5.7294e-02, time/batch = 0.1146s	
3092/5250 (epoch 29.448), train_loss = 1.05097693, grad/param norm = 6.2599e-02, time/batch = 0.1137s	
3093/5250 (epoch 29.457), train_loss = 1.06120125, grad/param norm = 5.8601e-02, time/batch = 0.1140s	
3094/5250 (epoch 29.467), train_loss = 1.05434111, grad/param norm = 5.6795e-02, time/batch = 0.1141s	
3095/5250 (epoch 29.476), train_loss = 1.05858675, grad/param norm = 6.1804e-02, time/batch = 0.1142s	
3096/5250 (epoch 29.486), train_loss = 1.07604378, grad/param norm = 5.9251e-02, time/batch = 0.1143s	
3097/5250 (epoch 29.495), train_loss = 1.07513509, grad/param norm = 5.7021e-02, time/batch = 0.1140s	
3098/5250 (epoch 29.505), train_loss = 1.07278172, grad/param norm = 5.5432e-02, time/batch = 0.1162s	
3099/5250 (epoch 29.514), train_loss = 1.06081487, grad/param norm = 5.7964e-02, time/batch = 0.1141s	
3100/5250 (epoch 29.524), train_loss = 1.06795822, grad/param norm = 6.3665e-02, time/batch = 0.1143s	
3101/5250 (epoch 29.533), train_loss = 1.07247725, grad/param norm = 6.1741e-02, time/batch = 0.1148s	
3102/5250 (epoch 29.543), train_loss = 1.05610437, grad/param norm = 5.8621e-02, time/batch = 0.1138s	
3103/5250 (epoch 29.552), train_loss = 1.05793980, grad/param norm = 5.6806e-02, time/batch = 0.1139s	
3104/5250 (epoch 29.562), train_loss = 1.06406352, grad/param norm = 5.8221e-02, time/batch = 0.1140s	
3105/5250 (epoch 29.571), train_loss = 1.07027109, grad/param norm = 6.2010e-02, time/batch = 0.1141s	
3106/5250 (epoch 29.581), train_loss = 1.08328032, grad/param norm = 6.6619e-02, time/batch = 0.1141s	
3107/5250 (epoch 29.590), train_loss = 1.06985555, grad/param norm = 6.4420e-02, time/batch = 0.1140s	
3108/5250 (epoch 29.600), train_loss = 1.08857356, grad/param norm = 6.2494e-02, time/batch = 0.1137s	
3109/5250 (epoch 29.610), train_loss = 1.07738395, grad/param norm = 6.0259e-02, time/batch = 0.1143s	
3110/5250 (epoch 29.619), train_loss = 1.06990294, grad/param norm = 5.7050e-02, time/batch = 0.1143s	
3111/5250 (epoch 29.629), train_loss = 1.06822775, grad/param norm = 6.2847e-02, time/batch = 0.1150s	
3112/5250 (epoch 29.638), train_loss = 1.06545123, grad/param norm = 5.8076e-02, time/batch = 0.1136s	
3113/5250 (epoch 29.648), train_loss = 1.07256507, grad/param norm = 5.8813e-02, time/batch = 0.1138s	
3114/5250 (epoch 29.657), train_loss = 1.05931876, grad/param norm = 5.5292e-02, time/batch = 0.1142s	
3115/5250 (epoch 29.667), train_loss = 1.06363111, grad/param norm = 5.6178e-02, time/batch = 0.1143s	
3116/5250 (epoch 29.676), train_loss = 1.06014078, grad/param norm = 6.2665e-02, time/batch = 0.1141s	
3117/5250 (epoch 29.686), train_loss = 1.08216389, grad/param norm = 6.5689e-02, time/batch = 0.1141s	
3118/5250 (epoch 29.695), train_loss = 1.07610174, grad/param norm = 6.3875e-02, time/batch = 0.1136s	
3119/5250 (epoch 29.705), train_loss = 1.05182474, grad/param norm = 6.1957e-02, time/batch = 0.1139s	
3120/5250 (epoch 29.714), train_loss = 1.08307702, grad/param norm = 6.8033e-02, time/batch = 0.1143s	
3121/5250 (epoch 29.724), train_loss = 1.06277870, grad/param norm = 6.1109e-02, time/batch = 0.1148s	
3122/5250 (epoch 29.733), train_loss = 1.04587548, grad/param norm = 5.8064e-02, time/batch = 0.1136s	
3123/5250 (epoch 29.743), train_loss = 1.04662385, grad/param norm = 5.8446e-02, time/batch = 0.1139s	
3124/5250 (epoch 29.752), train_loss = 1.05384614, grad/param norm = 5.9462e-02, time/batch = 0.1142s	
3125/5250 (epoch 29.762), train_loss = 1.04890094, grad/param norm = 5.9267e-02, time/batch = 0.1143s	
3126/5250 (epoch 29.771), train_loss = 1.04479780, grad/param norm = 5.7771e-02, time/batch = 0.1140s	
3127/5250 (epoch 29.781), train_loss = 1.06849350, grad/param norm = 6.0505e-02, time/batch = 0.1143s	
3128/5250 (epoch 29.790), train_loss = 1.06967887, grad/param norm = 6.4657e-02, time/batch = 0.1135s	
3129/5250 (epoch 29.800), train_loss = 1.04174670, grad/param norm = 6.2541e-02, time/batch = 0.1144s	
3130/5250 (epoch 29.810), train_loss = 1.06152499, grad/param norm = 6.4415e-02, time/batch = 0.1143s	
3131/5250 (epoch 29.819), train_loss = 1.06696648, grad/param norm = 5.9220e-02, time/batch = 0.1149s	
3132/5250 (epoch 29.829), train_loss = 1.06567252, grad/param norm = 6.2397e-02, time/batch = 0.1136s	
3133/5250 (epoch 29.838), train_loss = 1.03771196, grad/param norm = 5.7503e-02, time/batch = 0.1139s	
3134/5250 (epoch 29.848), train_loss = 1.03116183, grad/param norm = 5.8062e-02, time/batch = 0.1142s	
3135/5250 (epoch 29.857), train_loss = 1.04474736, grad/param norm = 6.0149e-02, time/batch = 0.1143s	
3136/5250 (epoch 29.867), train_loss = 1.05108345, grad/param norm = 5.9906e-02, time/batch = 0.1142s	
3137/5250 (epoch 29.876), train_loss = 1.03807267, grad/param norm = 6.0213e-02, time/batch = 0.1141s	
3138/5250 (epoch 29.886), train_loss = 1.03983338, grad/param norm = 6.0393e-02, time/batch = 0.1135s	
3139/5250 (epoch 29.895), train_loss = 1.07167125, grad/param norm = 6.6192e-02, time/batch = 0.1141s	
3140/5250 (epoch 29.905), train_loss = 1.06500481, grad/param norm = 6.1635e-02, time/batch = 0.1143s	
3141/5250 (epoch 29.914), train_loss = 1.07132566, grad/param norm = 6.0558e-02, time/batch = 0.1155s	
3142/5250 (epoch 29.924), train_loss = 1.07774887, grad/param norm = 6.1606e-02, time/batch = 0.1137s	
3143/5250 (epoch 29.933), train_loss = 1.06799792, grad/param norm = 6.1827e-02, time/batch = 0.1140s	
3144/5250 (epoch 29.943), train_loss = 1.07522009, grad/param norm = 6.1213e-02, time/batch = 0.1143s	
3145/5250 (epoch 29.952), train_loss = 1.08454424, grad/param norm = 6.2155e-02, time/batch = 0.1142s	
3146/5250 (epoch 29.962), train_loss = 1.06366852, grad/param norm = 5.8200e-02, time/batch = 0.1141s	
3147/5250 (epoch 29.971), train_loss = 1.07726594, grad/param norm = 5.9975e-02, time/batch = 0.1140s	
3148/5250 (epoch 29.981), train_loss = 1.08243388, grad/param norm = 6.2757e-02, time/batch = 0.1137s	
3149/5250 (epoch 29.990), train_loss = 1.07755756, grad/param norm = 6.0293e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
3150/5250 (epoch 30.000), train_loss = 1.06670581, grad/param norm = 6.2435e-02, time/batch = 0.1143s	
3151/5250 (epoch 30.010), train_loss = 1.24603738, grad/param norm = 6.6549e-02, time/batch = 0.1155s	
3152/5250 (epoch 30.019), train_loss = 1.05711068, grad/param norm = 6.1689e-02, time/batch = 0.1138s	
3153/5250 (epoch 30.029), train_loss = 1.08131872, grad/param norm = 5.9466e-02, time/batch = 0.1138s	
3154/5250 (epoch 30.038), train_loss = 1.05291349, grad/param norm = 5.9344e-02, time/batch = 0.1142s	
3155/5250 (epoch 30.048), train_loss = 1.02979825, grad/param norm = 5.7399e-02, time/batch = 0.1143s	
3156/5250 (epoch 30.057), train_loss = 1.03814399, grad/param norm = 5.5463e-02, time/batch = 0.1143s	
3157/5250 (epoch 30.067), train_loss = 1.05288570, grad/param norm = 5.9952e-02, time/batch = 0.1143s	
3158/5250 (epoch 30.076), train_loss = 1.07204569, grad/param norm = 5.7600e-02, time/batch = 0.1136s	
3159/5250 (epoch 30.086), train_loss = 1.01615576, grad/param norm = 5.7212e-02, time/batch = 0.1145s	
3160/5250 (epoch 30.095), train_loss = 1.03609301, grad/param norm = 5.6299e-02, time/batch = 0.1142s	
3161/5250 (epoch 30.105), train_loss = 1.06178631, grad/param norm = 5.6555e-02, time/batch = 0.1149s	
3162/5250 (epoch 30.114), train_loss = 1.04524805, grad/param norm = 5.6517e-02, time/batch = 0.1137s	
3163/5250 (epoch 30.124), train_loss = 1.06101330, grad/param norm = 5.7552e-02, time/batch = 0.1138s	
3164/5250 (epoch 30.133), train_loss = 1.04435847, grad/param norm = 5.7998e-02, time/batch = 0.1141s	
3165/5250 (epoch 30.143), train_loss = 1.02640318, grad/param norm = 5.9634e-02, time/batch = 0.1143s	
3166/5250 (epoch 30.152), train_loss = 1.03052862, grad/param norm = 6.2358e-02, time/batch = 0.1143s	
3167/5250 (epoch 30.162), train_loss = 1.05632531, grad/param norm = 5.8899e-02, time/batch = 0.1140s	
3168/5250 (epoch 30.171), train_loss = 1.05070486, grad/param norm = 6.0872e-02, time/batch = 0.1138s	
3169/5250 (epoch 30.181), train_loss = 1.04915198, grad/param norm = 5.9445e-02, time/batch = 0.1154s	
3170/5250 (epoch 30.190), train_loss = 1.05162435, grad/param norm = 6.3386e-02, time/batch = 0.1141s	
3171/5250 (epoch 30.200), train_loss = 1.05021136, grad/param norm = 6.4531e-02, time/batch = 0.1149s	
3172/5250 (epoch 30.210), train_loss = 1.05809924, grad/param norm = 6.0834e-02, time/batch = 0.1137s	
3173/5250 (epoch 30.219), train_loss = 1.08656887, grad/param norm = 6.1168e-02, time/batch = 0.1138s	
3174/5250 (epoch 30.229), train_loss = 1.05583240, grad/param norm = 6.1728e-02, time/batch = 0.1140s	
3175/5250 (epoch 30.238), train_loss = 1.05277175, grad/param norm = 6.5347e-02, time/batch = 0.1142s	
3176/5250 (epoch 30.248), train_loss = 1.05310267, grad/param norm = 6.5566e-02, time/batch = 0.1141s	
3177/5250 (epoch 30.257), train_loss = 1.05555107, grad/param norm = 5.9728e-02, time/batch = 0.1143s	
3178/5250 (epoch 30.267), train_loss = 1.04649284, grad/param norm = 5.8667e-02, time/batch = 0.1134s	
3179/5250 (epoch 30.276), train_loss = 1.03725095, grad/param norm = 6.3735e-02, time/batch = 0.1142s	
3180/5250 (epoch 30.286), train_loss = 1.01798765, grad/param norm = 6.0034e-02, time/batch = 0.1143s	
3181/5250 (epoch 30.295), train_loss = 1.04244419, grad/param norm = 5.9612e-02, time/batch = 0.1149s	
3182/5250 (epoch 30.305), train_loss = 1.04411137, grad/param norm = 6.3681e-02, time/batch = 0.1137s	
3183/5250 (epoch 30.314), train_loss = 1.04003594, grad/param norm = 5.9345e-02, time/batch = 0.1139s	
3184/5250 (epoch 30.324), train_loss = 1.05355551, grad/param norm = 6.3067e-02, time/batch = 0.1142s	
3185/5250 (epoch 30.333), train_loss = 1.05486004, grad/param norm = 6.8580e-02, time/batch = 0.1143s	
3186/5250 (epoch 30.343), train_loss = 1.05243556, grad/param norm = 5.8648e-02, time/batch = 0.1143s	
3187/5250 (epoch 30.352), train_loss = 1.05729884, grad/param norm = 5.7305e-02, time/batch = 0.1141s	
3188/5250 (epoch 30.362), train_loss = 1.05195722, grad/param norm = 5.7191e-02, time/batch = 0.1136s	
3189/5250 (epoch 30.371), train_loss = 1.03349871, grad/param norm = 5.6379e-02, time/batch = 0.1144s	
3190/5250 (epoch 30.381), train_loss = 1.04053086, grad/param norm = 5.8719e-02, time/batch = 0.1142s	
3191/5250 (epoch 30.390), train_loss = 1.04128287, grad/param norm = 5.9410e-02, time/batch = 0.1149s	
3192/5250 (epoch 30.400), train_loss = 1.04334304, grad/param norm = 5.8947e-02, time/batch = 0.1135s	
3193/5250 (epoch 30.410), train_loss = 1.05208096, grad/param norm = 6.5048e-02, time/batch = 0.1140s	
3194/5250 (epoch 30.419), train_loss = 1.05138057, grad/param norm = 5.9634e-02, time/batch = 0.1141s	
3195/5250 (epoch 30.429), train_loss = 1.06217105, grad/param norm = 6.2267e-02, time/batch = 0.1143s	
3196/5250 (epoch 30.438), train_loss = 1.06068317, grad/param norm = 6.3966e-02, time/batch = 0.1141s	
3197/5250 (epoch 30.448), train_loss = 1.04314249, grad/param norm = 6.7927e-02, time/batch = 0.1142s	
3198/5250 (epoch 30.457), train_loss = 1.05219248, grad/param norm = 5.8196e-02, time/batch = 0.1137s	
3199/5250 (epoch 30.467), train_loss = 1.04583024, grad/param norm = 5.9501e-02, time/batch = 0.1144s	
3200/5250 (epoch 30.476), train_loss = 1.05085327, grad/param norm = 6.4439e-02, time/batch = 0.1143s	
3201/5250 (epoch 30.486), train_loss = 1.06991612, grad/param norm = 6.7329e-02, time/batch = 0.1156s	
3202/5250 (epoch 30.495), train_loss = 1.06629344, grad/param norm = 5.9321e-02, time/batch = 0.1136s	
3203/5250 (epoch 30.505), train_loss = 1.06189959, grad/param norm = 5.5073e-02, time/batch = 0.1139s	
3204/5250 (epoch 30.514), train_loss = 1.05032008, grad/param norm = 5.7324e-02, time/batch = 0.1140s	
3205/5250 (epoch 30.524), train_loss = 1.05569053, grad/param norm = 6.0041e-02, time/batch = 0.1141s	
3206/5250 (epoch 30.533), train_loss = 1.05934730, grad/param norm = 5.7860e-02, time/batch = 0.1141s	
3207/5250 (epoch 30.543), train_loss = 1.04434521, grad/param norm = 5.9574e-02, time/batch = 0.1140s	
3208/5250 (epoch 30.552), train_loss = 1.05212877, grad/param norm = 6.2520e-02, time/batch = 0.1134s	
3209/5250 (epoch 30.562), train_loss = 1.05597294, grad/param norm = 6.2780e-02, time/batch = 0.1141s	
3210/5250 (epoch 30.571), train_loss = 1.05941648, grad/param norm = 5.9213e-02, time/batch = 0.1143s	
3211/5250 (epoch 30.581), train_loss = 1.06535873, grad/param norm = 6.0144e-02, time/batch = 0.1160s	
3212/5250 (epoch 30.590), train_loss = 1.05690054, grad/param norm = 5.9895e-02, time/batch = 0.1140s	
3213/5250 (epoch 30.600), train_loss = 1.07759623, grad/param norm = 6.6703e-02, time/batch = 0.1138s	
3214/5250 (epoch 30.610), train_loss = 1.06909534, grad/param norm = 6.3343e-02, time/batch = 0.1140s	
3215/5250 (epoch 30.619), train_loss = 1.06131011, grad/param norm = 6.0291e-02, time/batch = 0.1143s	
3216/5250 (epoch 30.629), train_loss = 1.05573919, grad/param norm = 5.9045e-02, time/batch = 0.1141s	
3217/5250 (epoch 30.638), train_loss = 1.05500156, grad/param norm = 5.6459e-02, time/batch = 0.1143s	
3218/5250 (epoch 30.648), train_loss = 1.06276782, grad/param norm = 5.6800e-02, time/batch = 0.1136s	
3219/5250 (epoch 30.657), train_loss = 1.05192767, grad/param norm = 6.1342e-02, time/batch = 0.1144s	
3220/5250 (epoch 30.667), train_loss = 1.05672184, grad/param norm = 6.2017e-02, time/batch = 0.1144s	
3221/5250 (epoch 30.676), train_loss = 1.04747259, grad/param norm = 6.0372e-02, time/batch = 0.1156s	
3222/5250 (epoch 30.686), train_loss = 1.07195806, grad/param norm = 6.5401e-02, time/batch = 0.1135s	
3223/5250 (epoch 30.695), train_loss = 1.06973173, grad/param norm = 7.1121e-02, time/batch = 0.1139s	
3224/5250 (epoch 30.705), train_loss = 1.04676214, grad/param norm = 7.1719e-02, time/batch = 0.1142s	
3225/5250 (epoch 30.714), train_loss = 1.07548396, grad/param norm = 6.8874e-02, time/batch = 0.1142s	
3226/5250 (epoch 30.724), train_loss = 1.05284015, grad/param norm = 6.2212e-02, time/batch = 0.1142s	
3227/5250 (epoch 30.733), train_loss = 1.03821131, grad/param norm = 6.0631e-02, time/batch = 0.1142s	
3228/5250 (epoch 30.743), train_loss = 1.03834603, grad/param norm = 6.2592e-02, time/batch = 0.1138s	
3229/5250 (epoch 30.752), train_loss = 1.04562285, grad/param norm = 6.6518e-02, time/batch = 0.1146s	
3230/5250 (epoch 30.762), train_loss = 1.03550936, grad/param norm = 5.6010e-02, time/batch = 0.1142s	
3231/5250 (epoch 30.771), train_loss = 1.03447835, grad/param norm = 6.0990e-02, time/batch = 0.1147s	
3232/5250 (epoch 30.781), train_loss = 1.06009410, grad/param norm = 6.0970e-02, time/batch = 0.1137s	
3233/5250 (epoch 30.790), train_loss = 1.05690057, grad/param norm = 5.9883e-02, time/batch = 0.1137s	
3234/5250 (epoch 30.800), train_loss = 1.03080937, grad/param norm = 6.0734e-02, time/batch = 0.1142s	
3235/5250 (epoch 30.810), train_loss = 1.05326838, grad/param norm = 6.7818e-02, time/batch = 0.1143s	
3236/5250 (epoch 30.819), train_loss = 1.05757948, grad/param norm = 5.9858e-02, time/batch = 0.1141s	
3237/5250 (epoch 30.829), train_loss = 1.05890518, grad/param norm = 7.4476e-02, time/batch = 0.1141s	
3238/5250 (epoch 30.838), train_loss = 1.03379457, grad/param norm = 6.5625e-02, time/batch = 0.1136s	
3239/5250 (epoch 30.848), train_loss = 1.02256988, grad/param norm = 6.0802e-02, time/batch = 0.1145s	
3240/5250 (epoch 30.857), train_loss = 1.03445443, grad/param norm = 6.0363e-02, time/batch = 0.1154s	
3241/5250 (epoch 30.867), train_loss = 1.04263454, grad/param norm = 6.1578e-02, time/batch = 0.1158s	
3242/5250 (epoch 30.876), train_loss = 1.02810411, grad/param norm = 6.0095e-02, time/batch = 0.1136s	
3243/5250 (epoch 30.886), train_loss = 1.03013544, grad/param norm = 6.1813e-02, time/batch = 0.1139s	
3244/5250 (epoch 30.895), train_loss = 1.05979090, grad/param norm = 6.1913e-02, time/batch = 0.1141s	
3245/5250 (epoch 30.905), train_loss = 1.05331838, grad/param norm = 6.3397e-02, time/batch = 0.1141s	
3246/5250 (epoch 30.914), train_loss = 1.06333537, grad/param norm = 6.2721e-02, time/batch = 0.1140s	
3247/5250 (epoch 30.924), train_loss = 1.06621176, grad/param norm = 6.1265e-02, time/batch = 0.1142s	
3248/5250 (epoch 30.933), train_loss = 1.05680624, grad/param norm = 5.8026e-02, time/batch = 0.1137s	
3249/5250 (epoch 30.943), train_loss = 1.06383522, grad/param norm = 5.9536e-02, time/batch = 0.1142s	
3250/5250 (epoch 30.952), train_loss = 1.07192932, grad/param norm = 6.2598e-02, time/batch = 0.1143s	
3251/5250 (epoch 30.962), train_loss = 1.05425962, grad/param norm = 5.9178e-02, time/batch = 0.1149s	
3252/5250 (epoch 30.971), train_loss = 1.06851966, grad/param norm = 6.3067e-02, time/batch = 0.1137s	
3253/5250 (epoch 30.981), train_loss = 1.07351496, grad/param norm = 6.5655e-02, time/batch = 0.1140s	
3254/5250 (epoch 30.990), train_loss = 1.06720320, grad/param norm = 5.8869e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
3255/5250 (epoch 31.000), train_loss = 1.05388480, grad/param norm = 5.7479e-02, time/batch = 0.1142s	
3256/5250 (epoch 31.010), train_loss = 1.23600883, grad/param norm = 6.7188e-02, time/batch = 0.1141s	
3257/5250 (epoch 31.019), train_loss = 1.04898760, grad/param norm = 6.3508e-02, time/batch = 0.1138s	
3258/5250 (epoch 31.029), train_loss = 1.07145899, grad/param norm = 5.9535e-02, time/batch = 0.1136s	
3259/5250 (epoch 31.038), train_loss = 1.04402250, grad/param norm = 5.8490e-02, time/batch = 0.1143s	
3260/5250 (epoch 31.048), train_loss = 1.02183217, grad/param norm = 6.2355e-02, time/batch = 0.1142s	
3261/5250 (epoch 31.057), train_loss = 1.03065921, grad/param norm = 5.8771e-02, time/batch = 0.1148s	
3262/5250 (epoch 31.067), train_loss = 1.04267151, grad/param norm = 6.1007e-02, time/batch = 0.1137s	
3263/5250 (epoch 31.076), train_loss = 1.06291849, grad/param norm = 5.8809e-02, time/batch = 0.1139s	
3264/5250 (epoch 31.086), train_loss = 1.00810031, grad/param norm = 5.6514e-02, time/batch = 0.1140s	
3265/5250 (epoch 31.095), train_loss = 1.02734031, grad/param norm = 5.6604e-02, time/batch = 0.1142s	
3266/5250 (epoch 31.105), train_loss = 1.05334296, grad/param norm = 5.9053e-02, time/batch = 0.1142s	
3267/5250 (epoch 31.114), train_loss = 1.03465065, grad/param norm = 5.6322e-02, time/batch = 0.1142s	
3268/5250 (epoch 31.124), train_loss = 1.05201507, grad/param norm = 5.8618e-02, time/batch = 0.1136s	
3269/5250 (epoch 31.133), train_loss = 1.03561452, grad/param norm = 5.9109e-02, time/batch = 0.1144s	
3270/5250 (epoch 31.143), train_loss = 1.01626451, grad/param norm = 5.8350e-02, time/batch = 0.1143s	
3271/5250 (epoch 31.152), train_loss = 1.02100435, grad/param norm = 6.2300e-02, time/batch = 0.1148s	
3272/5250 (epoch 31.162), train_loss = 1.04657162, grad/param norm = 6.0073e-02, time/batch = 0.1138s	
3273/5250 (epoch 31.171), train_loss = 1.04085347, grad/param norm = 5.7256e-02, time/batch = 0.1140s	
3274/5250 (epoch 31.181), train_loss = 1.03989247, grad/param norm = 6.2056e-02, time/batch = 0.1142s	
3275/5250 (epoch 31.190), train_loss = 1.04296624, grad/param norm = 7.0777e-02, time/batch = 0.1143s	
3276/5250 (epoch 31.200), train_loss = 1.04098599, grad/param norm = 6.4854e-02, time/batch = 0.1142s	
3277/5250 (epoch 31.210), train_loss = 1.05211576, grad/param norm = 6.6112e-02, time/batch = 0.1143s	
3278/5250 (epoch 31.219), train_loss = 1.07822250, grad/param norm = 6.2958e-02, time/batch = 0.1146s	
3279/5250 (epoch 31.229), train_loss = 1.04462496, grad/param norm = 5.9642e-02, time/batch = 0.1141s	
3280/5250 (epoch 31.238), train_loss = 1.04114470, grad/param norm = 6.1221e-02, time/batch = 0.1142s	
3281/5250 (epoch 31.248), train_loss = 1.04176062, grad/param norm = 5.9411e-02, time/batch = 0.1147s	
3282/5250 (epoch 31.257), train_loss = 1.04593200, grad/param norm = 6.0665e-02, time/batch = 0.1137s	
3283/5250 (epoch 31.267), train_loss = 1.03912111, grad/param norm = 6.4148e-02, time/batch = 0.1141s	
3284/5250 (epoch 31.276), train_loss = 1.02708234, grad/param norm = 6.1722e-02, time/batch = 0.1141s	
3285/5250 (epoch 31.286), train_loss = 1.00689682, grad/param norm = 5.8203e-02, time/batch = 0.1146s	
3286/5250 (epoch 31.295), train_loss = 1.03164605, grad/param norm = 5.9100e-02, time/batch = 0.1142s	
3287/5250 (epoch 31.305), train_loss = 1.03246443, grad/param norm = 6.0658e-02, time/batch = 0.1141s	
3288/5250 (epoch 31.314), train_loss = 1.03471624, grad/param norm = 6.6139e-02, time/batch = 0.1136s	
3289/5250 (epoch 31.324), train_loss = 1.04629699, grad/param norm = 6.8647e-02, time/batch = 0.1142s	
3290/5250 (epoch 31.333), train_loss = 1.04440575, grad/param norm = 6.2946e-02, time/batch = 0.1142s	
3291/5250 (epoch 31.343), train_loss = 1.04299957, grad/param norm = 6.1144e-02, time/batch = 0.1148s	
3292/5250 (epoch 31.352), train_loss = 1.05185161, grad/param norm = 6.1900e-02, time/batch = 0.1137s	
3293/5250 (epoch 31.362), train_loss = 1.04298922, grad/param norm = 6.0037e-02, time/batch = 0.1141s	
3294/5250 (epoch 31.371), train_loss = 1.02393120, grad/param norm = 5.8903e-02, time/batch = 0.1140s	
3295/5250 (epoch 31.381), train_loss = 1.03153341, grad/param norm = 6.0873e-02, time/batch = 0.1142s	
3296/5250 (epoch 31.390), train_loss = 1.03177024, grad/param norm = 5.9266e-02, time/batch = 0.1143s	
3297/5250 (epoch 31.400), train_loss = 1.03359586, grad/param norm = 6.1338e-02, time/batch = 0.1142s	
3298/5250 (epoch 31.410), train_loss = 1.04025768, grad/param norm = 6.1201e-02, time/batch = 0.1136s	
3299/5250 (epoch 31.419), train_loss = 1.04215460, grad/param norm = 6.3206e-02, time/batch = 0.1143s	
3300/5250 (epoch 31.429), train_loss = 1.05148237, grad/param norm = 6.2546e-02, time/batch = 0.1144s	
3301/5250 (epoch 31.438), train_loss = 1.04727009, grad/param norm = 5.8241e-02, time/batch = 0.1148s	
3302/5250 (epoch 31.448), train_loss = 1.03006459, grad/param norm = 6.0768e-02, time/batch = 0.1138s	
3303/5250 (epoch 31.457), train_loss = 1.04547134, grad/param norm = 6.5378e-02, time/batch = 0.1139s	
3304/5250 (epoch 31.467), train_loss = 1.04002838, grad/param norm = 6.1249e-02, time/batch = 0.1140s	
3305/5250 (epoch 31.476), train_loss = 1.04048925, grad/param norm = 6.6011e-02, time/batch = 0.1143s	
3306/5250 (epoch 31.486), train_loss = 1.06232025, grad/param norm = 6.7096e-02, time/batch = 0.1141s	
3307/5250 (epoch 31.495), train_loss = 1.05613440, grad/param norm = 6.1606e-02, time/batch = 0.1140s	
3308/5250 (epoch 31.505), train_loss = 1.05503741, grad/param norm = 5.8085e-02, time/batch = 0.1136s	
3309/5250 (epoch 31.514), train_loss = 1.04218609, grad/param norm = 5.9251e-02, time/batch = 0.1144s	
3310/5250 (epoch 31.524), train_loss = 1.04668395, grad/param norm = 6.2066e-02, time/batch = 0.1141s	
3311/5250 (epoch 31.533), train_loss = 1.05149889, grad/param norm = 6.0836e-02, time/batch = 0.1148s	
3312/5250 (epoch 31.543), train_loss = 1.03576126, grad/param norm = 5.9156e-02, time/batch = 0.1139s	
3313/5250 (epoch 31.552), train_loss = 1.04256235, grad/param norm = 5.9626e-02, time/batch = 0.1141s	
3314/5250 (epoch 31.562), train_loss = 1.04648834, grad/param norm = 6.0668e-02, time/batch = 0.1142s	
3315/5250 (epoch 31.571), train_loss = 1.05243199, grad/param norm = 6.5796e-02, time/batch = 0.1142s	
3316/5250 (epoch 31.581), train_loss = 1.05830444, grad/param norm = 6.4084e-02, time/batch = 0.1143s	
3317/5250 (epoch 31.590), train_loss = 1.04612896, grad/param norm = 5.9868e-02, time/batch = 0.1140s	
3318/5250 (epoch 31.600), train_loss = 1.06681592, grad/param norm = 6.4212e-02, time/batch = 0.1136s	
3319/5250 (epoch 31.610), train_loss = 1.05888730, grad/param norm = 6.1116e-02, time/batch = 0.1142s	
3320/5250 (epoch 31.619), train_loss = 1.04998896, grad/param norm = 6.0263e-02, time/batch = 0.1141s	
3321/5250 (epoch 31.629), train_loss = 1.04618191, grad/param norm = 6.2430e-02, time/batch = 0.1147s	
3322/5250 (epoch 31.638), train_loss = 1.04591418, grad/param norm = 5.8105e-02, time/batch = 0.1137s	
3323/5250 (epoch 31.648), train_loss = 1.05293196, grad/param norm = 5.7327e-02, time/batch = 0.1139s	
3324/5250 (epoch 31.657), train_loss = 1.03956302, grad/param norm = 5.7510e-02, time/batch = 0.1142s	
3325/5250 (epoch 31.667), train_loss = 1.04345619, grad/param norm = 5.6957e-02, time/batch = 0.1143s	
3326/5250 (epoch 31.676), train_loss = 1.03663327, grad/param norm = 5.8516e-02, time/batch = 0.1142s	
3327/5250 (epoch 31.686), train_loss = 1.05923103, grad/param norm = 6.3689e-02, time/batch = 0.1142s	
3328/5250 (epoch 31.695), train_loss = 1.05773752, grad/param norm = 6.4212e-02, time/batch = 0.1135s	
3329/5250 (epoch 31.705), train_loss = 1.03172149, grad/param norm = 6.2771e-02, time/batch = 0.1143s	
3330/5250 (epoch 31.714), train_loss = 1.06043874, grad/param norm = 6.4355e-02, time/batch = 0.1140s	
3331/5250 (epoch 31.724), train_loss = 1.04281791, grad/param norm = 6.2679e-02, time/batch = 0.1149s	
3332/5250 (epoch 31.733), train_loss = 1.02762374, grad/param norm = 6.2621e-02, time/batch = 0.1138s	
3333/5250 (epoch 31.743), train_loss = 1.02828363, grad/param norm = 6.1392e-02, time/batch = 0.1141s	
3334/5250 (epoch 31.752), train_loss = 1.03676510, grad/param norm = 6.2921e-02, time/batch = 0.1143s	
3335/5250 (epoch 31.762), train_loss = 1.03194862, grad/param norm = 6.9309e-02, time/batch = 0.1144s	
3336/5250 (epoch 31.771), train_loss = 1.02579987, grad/param norm = 6.1226e-02, time/batch = 0.1143s	
3337/5250 (epoch 31.781), train_loss = 1.05026050, grad/param norm = 6.0116e-02, time/batch = 0.1141s	
3338/5250 (epoch 31.790), train_loss = 1.05035488, grad/param norm = 6.5495e-02, time/batch = 0.1138s	
3339/5250 (epoch 31.800), train_loss = 1.02176957, grad/param norm = 6.1907e-02, time/batch = 0.1142s	
3340/5250 (epoch 31.810), train_loss = 1.04164374, grad/param norm = 6.4093e-02, time/batch = 0.1143s	
3341/5250 (epoch 31.819), train_loss = 1.04708861, grad/param norm = 5.8576e-02, time/batch = 0.1148s	
3342/5250 (epoch 31.829), train_loss = 1.04648026, grad/param norm = 6.8536e-02, time/batch = 0.1137s	
3343/5250 (epoch 31.838), train_loss = 1.01946849, grad/param norm = 5.8529e-02, time/batch = 0.1138s	
3344/5250 (epoch 31.848), train_loss = 1.01387295, grad/param norm = 6.2296e-02, time/batch = 0.1140s	
3345/5250 (epoch 31.857), train_loss = 1.02513026, grad/param norm = 6.3409e-02, time/batch = 0.1143s	
3346/5250 (epoch 31.867), train_loss = 1.03294384, grad/param norm = 6.2852e-02, time/batch = 0.1142s	
3347/5250 (epoch 31.876), train_loss = 1.01923020, grad/param norm = 6.4818e-02, time/batch = 0.1141s	
3348/5250 (epoch 31.886), train_loss = 1.02296703, grad/param norm = 6.6852e-02, time/batch = 0.1137s	
3349/5250 (epoch 31.895), train_loss = 1.05051780, grad/param norm = 6.6930e-02, time/batch = 0.1143s	
3350/5250 (epoch 31.905), train_loss = 1.04296248, grad/param norm = 6.1525e-02, time/batch = 0.1142s	
3351/5250 (epoch 31.914), train_loss = 1.05539897, grad/param norm = 6.8830e-02, time/batch = 0.1148s	
3352/5250 (epoch 31.924), train_loss = 1.06069847, grad/param norm = 6.4541e-02, time/batch = 0.1138s	
3353/5250 (epoch 31.933), train_loss = 1.04927374, grad/param norm = 6.3637e-02, time/batch = 0.1139s	
3354/5250 (epoch 31.943), train_loss = 1.05722623, grad/param norm = 6.3420e-02, time/batch = 0.1143s	
3355/5250 (epoch 31.952), train_loss = 1.06415987, grad/param norm = 6.2860e-02, time/batch = 0.1142s	
3356/5250 (epoch 31.962), train_loss = 1.04517421, grad/param norm = 5.9549e-02, time/batch = 0.1141s	
3357/5250 (epoch 31.971), train_loss = 1.05989728, grad/param norm = 6.1626e-02, time/batch = 0.1141s	
3358/5250 (epoch 31.981), train_loss = 1.06172970, grad/param norm = 6.1577e-02, time/batch = 0.1138s	
3359/5250 (epoch 31.990), train_loss = 1.05803929, grad/param norm = 6.2520e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
3360/5250 (epoch 32.000), train_loss = 1.04712043, grad/param norm = 6.2797e-02, time/batch = 0.1142s	
3361/5250 (epoch 32.010), train_loss = 1.22678588, grad/param norm = 6.8690e-02, time/batch = 0.1148s	
3362/5250 (epoch 32.019), train_loss = 1.03870704, grad/param norm = 6.1623e-02, time/batch = 0.1138s	
3363/5250 (epoch 32.029), train_loss = 1.06216089, grad/param norm = 6.1283e-02, time/batch = 0.1141s	
3364/5250 (epoch 32.038), train_loss = 1.03599353, grad/param norm = 6.0987e-02, time/batch = 0.1140s	
3365/5250 (epoch 32.048), train_loss = 1.01273879, grad/param norm = 6.0980e-02, time/batch = 0.1142s	
3366/5250 (epoch 32.057), train_loss = 1.02064914, grad/param norm = 5.7177e-02, time/batch = 0.1142s	
3367/5250 (epoch 32.067), train_loss = 1.03374554, grad/param norm = 6.1558e-02, time/batch = 0.1143s	
3368/5250 (epoch 32.076), train_loss = 1.05367672, grad/param norm = 5.9954e-02, time/batch = 0.1137s	
3369/5250 (epoch 32.086), train_loss = 0.99927863, grad/param norm = 5.8682e-02, time/batch = 0.1144s	
3370/5250 (epoch 32.095), train_loss = 1.01867015, grad/param norm = 5.7196e-02, time/batch = 0.1142s	
3371/5250 (epoch 32.105), train_loss = 1.04323320, grad/param norm = 5.8414e-02, time/batch = 0.1150s	
3372/5250 (epoch 32.114), train_loss = 1.02478659, grad/param norm = 5.7602e-02, time/batch = 0.1135s	
3373/5250 (epoch 32.124), train_loss = 1.04352286, grad/param norm = 5.9047e-02, time/batch = 0.1140s	
3374/5250 (epoch 32.133), train_loss = 1.02621686, grad/param norm = 5.8583e-02, time/batch = 0.1141s	
3375/5250 (epoch 32.143), train_loss = 1.00797821, grad/param norm = 5.8762e-02, time/batch = 0.1144s	
3376/5250 (epoch 32.152), train_loss = 1.01236495, grad/param norm = 6.3050e-02, time/batch = 0.1141s	
3377/5250 (epoch 32.162), train_loss = 1.03752808, grad/param norm = 5.9609e-02, time/batch = 0.1142s	
3378/5250 (epoch 32.171), train_loss = 1.03183160, grad/param norm = 5.9827e-02, time/batch = 0.1137s	
3379/5250 (epoch 32.181), train_loss = 1.03058756, grad/param norm = 6.2136e-02, time/batch = 0.1143s	
3380/5250 (epoch 32.190), train_loss = 1.03355578, grad/param norm = 6.7862e-02, time/batch = 0.1142s	
3381/5250 (epoch 32.200), train_loss = 1.03114668, grad/param norm = 6.2208e-02, time/batch = 0.1154s	
3382/5250 (epoch 32.210), train_loss = 1.03978782, grad/param norm = 6.0502e-02, time/batch = 0.1138s	
3383/5250 (epoch 32.219), train_loss = 1.06989997, grad/param norm = 6.3858e-02, time/batch = 0.1140s	
3384/5250 (epoch 32.229), train_loss = 1.03729396, grad/param norm = 6.4319e-02, time/batch = 0.1143s	
3385/5250 (epoch 32.238), train_loss = 1.03385435, grad/param norm = 6.5772e-02, time/batch = 0.1143s	
3386/5250 (epoch 32.248), train_loss = 1.03500730, grad/param norm = 6.3109e-02, time/batch = 0.1140s	
3387/5250 (epoch 32.257), train_loss = 1.03590035, grad/param norm = 5.9062e-02, time/batch = 0.1141s	
3388/5250 (epoch 32.267), train_loss = 1.02799345, grad/param norm = 6.0305e-02, time/batch = 0.1137s	
3389/5250 (epoch 32.276), train_loss = 1.01775707, grad/param norm = 6.2724e-02, time/batch = 0.1141s	
3390/5250 (epoch 32.286), train_loss = 0.99855051, grad/param norm = 6.3268e-02, time/batch = 0.1143s	
3391/5250 (epoch 32.295), train_loss = 1.02386316, grad/param norm = 6.0458e-02, time/batch = 0.1155s	
3392/5250 (epoch 32.305), train_loss = 1.02311121, grad/param norm = 6.3190e-02, time/batch = 0.1137s	
3393/5250 (epoch 32.314), train_loss = 1.02106663, grad/param norm = 5.9976e-02, time/batch = 0.1141s	
3394/5250 (epoch 32.324), train_loss = 1.03398722, grad/param norm = 6.2023e-02, time/batch = 0.1143s	
3395/5250 (epoch 32.333), train_loss = 1.03576092, grad/param norm = 6.6261e-02, time/batch = 0.1142s	
3396/5250 (epoch 32.343), train_loss = 1.03363808, grad/param norm = 6.2547e-02, time/batch = 0.1139s	
3397/5250 (epoch 32.352), train_loss = 1.04105721, grad/param norm = 6.2927e-02, time/batch = 0.1143s	
3398/5250 (epoch 32.362), train_loss = 1.03539306, grad/param norm = 6.3300e-02, time/batch = 0.1136s	
3399/5250 (epoch 32.371), train_loss = 1.01568217, grad/param norm = 6.1399e-02, time/batch = 0.1143s	
3400/5250 (epoch 32.381), train_loss = 1.02376294, grad/param norm = 6.1627e-02, time/batch = 0.1142s	
3401/5250 (epoch 32.390), train_loss = 1.02276822, grad/param norm = 6.0657e-02, time/batch = 0.1148s	
3402/5250 (epoch 32.400), train_loss = 1.02392966, grad/param norm = 6.1231e-02, time/batch = 0.1136s	
3403/5250 (epoch 32.410), train_loss = 1.03009486, grad/param norm = 6.2655e-02, time/batch = 0.1139s	
3404/5250 (epoch 32.419), train_loss = 1.03306761, grad/param norm = 6.0683e-02, time/batch = 0.1142s	
3405/5250 (epoch 32.429), train_loss = 1.04355323, grad/param norm = 6.8214e-02, time/batch = 0.1143s	
3406/5250 (epoch 32.438), train_loss = 1.04270906, grad/param norm = 6.4968e-02, time/batch = 0.1141s	
3407/5250 (epoch 32.448), train_loss = 1.02329735, grad/param norm = 6.5173e-02, time/batch = 0.1143s	
3408/5250 (epoch 32.457), train_loss = 1.03412242, grad/param norm = 5.9140e-02, time/batch = 0.1137s	
3409/5250 (epoch 32.467), train_loss = 1.03014971, grad/param norm = 6.1849e-02, time/batch = 0.1143s	
3410/5250 (epoch 32.476), train_loss = 1.03206257, grad/param norm = 6.7779e-02, time/batch = 0.1142s	
3411/5250 (epoch 32.486), train_loss = 1.05208149, grad/param norm = 7.0388e-02, time/batch = 0.1148s	
3412/5250 (epoch 32.495), train_loss = 1.04775567, grad/param norm = 6.0407e-02, time/batch = 0.1136s	
3413/5250 (epoch 32.505), train_loss = 1.04429357, grad/param norm = 5.9011e-02, time/batch = 0.1139s	
3414/5250 (epoch 32.514), train_loss = 1.03359224, grad/param norm = 6.0796e-02, time/batch = 0.1141s	
3415/5250 (epoch 32.524), train_loss = 1.03824930, grad/param norm = 6.2583e-02, time/batch = 0.1144s	
3416/5250 (epoch 32.533), train_loss = 1.04156933, grad/param norm = 6.1686e-02, time/batch = 0.1141s	
3417/5250 (epoch 32.543), train_loss = 1.02738445, grad/param norm = 6.2834e-02, time/batch = 0.1143s	
3418/5250 (epoch 32.552), train_loss = 1.03500871, grad/param norm = 6.1992e-02, time/batch = 0.1136s	
3419/5250 (epoch 32.562), train_loss = 1.03716926, grad/param norm = 6.2405e-02, time/batch = 0.1143s	
3420/5250 (epoch 32.571), train_loss = 1.04190430, grad/param norm = 6.2547e-02, time/batch = 0.1144s	
3421/5250 (epoch 32.581), train_loss = 1.04425031, grad/param norm = 6.1722e-02, time/batch = 0.1148s	
3422/5250 (epoch 32.590), train_loss = 1.03851668, grad/param norm = 6.2518e-02, time/batch = 0.1139s	
3423/5250 (epoch 32.600), train_loss = 1.05880362, grad/param norm = 7.3595e-02, time/batch = 0.1140s	
3424/5250 (epoch 32.610), train_loss = 1.05111039, grad/param norm = 6.2980e-02, time/batch = 0.1141s	
3425/5250 (epoch 32.619), train_loss = 1.04005754, grad/param norm = 6.0541e-02, time/batch = 0.1142s	
3426/5250 (epoch 32.629), train_loss = 1.03549191, grad/param norm = 6.1876e-02, time/batch = 0.1145s	
3427/5250 (epoch 32.638), train_loss = 1.03708036, grad/param norm = 5.8707e-02, time/batch = 0.1144s	
3428/5250 (epoch 32.648), train_loss = 1.04422472, grad/param norm = 5.8270e-02, time/batch = 0.1136s	
3429/5250 (epoch 32.657), train_loss = 1.02957921, grad/param norm = 5.6752e-02, time/batch = 0.1142s	
3430/5250 (epoch 32.667), train_loss = 1.03466228, grad/param norm = 5.8438e-02, time/batch = 0.1142s	
3431/5250 (epoch 32.676), train_loss = 1.02962299, grad/param norm = 6.2928e-02, time/batch = 0.1149s	
3432/5250 (epoch 32.686), train_loss = 1.04920992, grad/param norm = 6.2434e-02, time/batch = 0.1137s	
3433/5250 (epoch 32.695), train_loss = 1.04574994, grad/param norm = 6.2287e-02, time/batch = 0.1141s	
3434/5250 (epoch 32.705), train_loss = 1.02227473, grad/param norm = 6.2303e-02, time/batch = 0.1142s	
3435/5250 (epoch 32.714), train_loss = 1.05318791, grad/param norm = 7.0334e-02, time/batch = 0.1142s	
3436/5250 (epoch 32.724), train_loss = 1.03274129, grad/param norm = 6.0802e-02, time/batch = 0.1143s	
3437/5250 (epoch 32.733), train_loss = 1.01651401, grad/param norm = 5.8322e-02, time/batch = 0.1142s	
3438/5250 (epoch 32.743), train_loss = 1.01848027, grad/param norm = 6.1633e-02, time/batch = 0.1136s	
3439/5250 (epoch 32.752), train_loss = 1.02703177, grad/param norm = 6.5138e-02, time/batch = 0.1143s	
3440/5250 (epoch 32.762), train_loss = 1.01705989, grad/param norm = 5.7635e-02, time/batch = 0.1143s	
3441/5250 (epoch 32.771), train_loss = 1.01711035, grad/param norm = 6.3204e-02, time/batch = 0.1146s	
3442/5250 (epoch 32.781), train_loss = 1.04237703, grad/param norm = 6.4299e-02, time/batch = 0.1137s	
3443/5250 (epoch 32.790), train_loss = 1.03835727, grad/param norm = 5.9710e-02, time/batch = 0.1137s	
3444/5250 (epoch 32.800), train_loss = 1.01304001, grad/param norm = 6.5789e-02, time/batch = 0.1142s	
3445/5250 (epoch 32.810), train_loss = 1.03793141, grad/param norm = 7.3293e-02, time/batch = 0.1141s	
3446/5250 (epoch 32.819), train_loss = 1.03889761, grad/param norm = 5.9946e-02, time/batch = 0.1142s	
3447/5250 (epoch 32.829), train_loss = 1.03541059, grad/param norm = 6.3909e-02, time/batch = 0.1142s	
3448/5250 (epoch 32.838), train_loss = 1.00943506, grad/param norm = 5.9099e-02, time/batch = 0.1137s	
3449/5250 (epoch 32.848), train_loss = 1.00540422, grad/param norm = 6.6341e-02, time/batch = 0.1144s	
3450/5250 (epoch 32.857), train_loss = 1.01703226, grad/param norm = 6.5829e-02, time/batch = 0.1142s	
3451/5250 (epoch 32.867), train_loss = 1.02556047, grad/param norm = 6.7186e-02, time/batch = 0.1150s	
3452/5250 (epoch 32.876), train_loss = 1.01197710, grad/param norm = 6.2865e-02, time/batch = 0.1137s	
3453/5250 (epoch 32.886), train_loss = 1.01268810, grad/param norm = 6.5279e-02, time/batch = 0.1140s	
3454/5250 (epoch 32.895), train_loss = 1.04190362, grad/param norm = 6.5173e-02, time/batch = 0.1141s	
3455/5250 (epoch 32.905), train_loss = 1.03309103, grad/param norm = 6.5019e-02, time/batch = 0.1143s	
3456/5250 (epoch 32.914), train_loss = 1.04546580, grad/param norm = 6.5239e-02, time/batch = 0.1141s	
3457/5250 (epoch 32.924), train_loss = 1.05120026, grad/param norm = 6.5901e-02, time/batch = 0.1142s	
3458/5250 (epoch 32.933), train_loss = 1.04245656, grad/param norm = 6.7280e-02, time/batch = 0.1137s	
3459/5250 (epoch 32.943), train_loss = 1.05044776, grad/param norm = 6.6118e-02, time/batch = 0.1144s	
3460/5250 (epoch 32.952), train_loss = 1.05384027, grad/param norm = 6.3201e-02, time/batch = 0.1143s	
3461/5250 (epoch 32.962), train_loss = 1.03742770, grad/param norm = 6.6671e-02, time/batch = 0.1148s	
3462/5250 (epoch 32.971), train_loss = 1.05320879, grad/param norm = 6.2754e-02, time/batch = 0.1139s	
3463/5250 (epoch 32.981), train_loss = 1.05149582, grad/param norm = 6.2636e-02, time/batch = 0.1140s	
3464/5250 (epoch 32.990), train_loss = 1.04996652, grad/param norm = 6.4218e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
3465/5250 (epoch 33.000), train_loss = 1.03784056, grad/param norm = 6.1210e-02, time/batch = 0.1141s	
3466/5250 (epoch 33.010), train_loss = 1.21671374, grad/param norm = 6.7853e-02, time/batch = 0.1142s	
3467/5250 (epoch 33.019), train_loss = 1.02945535, grad/param norm = 6.2148e-02, time/batch = 0.1142s	
3468/5250 (epoch 33.029), train_loss = 1.05326644, grad/param norm = 6.0450e-02, time/batch = 0.1136s	
3469/5250 (epoch 33.038), train_loss = 1.02706375, grad/param norm = 6.0174e-02, time/batch = 0.1144s	
3470/5250 (epoch 33.048), train_loss = 1.00438855, grad/param norm = 6.2447e-02, time/batch = 0.1142s	
3471/5250 (epoch 33.057), train_loss = 1.01223431, grad/param norm = 5.8118e-02, time/batch = 0.1154s	
3472/5250 (epoch 33.067), train_loss = 1.02404877, grad/param norm = 6.1385e-02, time/batch = 0.1137s	
3473/5250 (epoch 33.076), train_loss = 1.04421685, grad/param norm = 6.1000e-02, time/batch = 0.1141s	
3474/5250 (epoch 33.086), train_loss = 0.99249007, grad/param norm = 5.8896e-02, time/batch = 0.1141s	
3475/5250 (epoch 33.095), train_loss = 1.01071386, grad/param norm = 5.8417e-02, time/batch = 0.1143s	
3476/5250 (epoch 33.105), train_loss = 1.03535176, grad/param norm = 6.1003e-02, time/batch = 0.1141s	
3477/5250 (epoch 33.114), train_loss = 1.01521366, grad/param norm = 5.8019e-02, time/batch = 0.1142s	
3478/5250 (epoch 33.124), train_loss = 1.03516476, grad/param norm = 6.1566e-02, time/batch = 0.1136s	
3479/5250 (epoch 33.133), train_loss = 1.01925395, grad/param norm = 6.1028e-02, time/batch = 0.1142s	
3480/5250 (epoch 33.143), train_loss = 0.99898512, grad/param norm = 5.9455e-02, time/batch = 0.1143s	
3481/5250 (epoch 33.152), train_loss = 1.00367478, grad/param norm = 6.3237e-02, time/batch = 0.1156s	
3482/5250 (epoch 33.162), train_loss = 1.02816742, grad/param norm = 6.1209e-02, time/batch = 0.1137s	
3483/5250 (epoch 33.171), train_loss = 1.02391149, grad/param norm = 5.8931e-02, time/batch = 0.1140s	
3484/5250 (epoch 33.181), train_loss = 1.02158391, grad/param norm = 6.3733e-02, time/batch = 0.1140s	
3485/5250 (epoch 33.190), train_loss = 1.02340618, grad/param norm = 6.9100e-02, time/batch = 0.1143s	
3486/5250 (epoch 33.200), train_loss = 1.02261539, grad/param norm = 6.3137e-02, time/batch = 0.1140s	
3487/5250 (epoch 33.210), train_loss = 1.03186425, grad/param norm = 6.3664e-02, time/batch = 0.1142s	
3488/5250 (epoch 33.219), train_loss = 1.05978097, grad/param norm = 6.1314e-02, time/batch = 0.1137s	
3489/5250 (epoch 33.229), train_loss = 1.02710218, grad/param norm = 6.2052e-02, time/batch = 0.1142s	
3490/5250 (epoch 33.238), train_loss = 1.02420813, grad/param norm = 6.7272e-02, time/batch = 0.1144s	
3491/5250 (epoch 33.248), train_loss = 1.02597400, grad/param norm = 5.9142e-02, time/batch = 0.1149s	
3492/5250 (epoch 33.257), train_loss = 1.02827357, grad/param norm = 6.3141e-02, time/batch = 0.1137s	
3493/5250 (epoch 33.267), train_loss = 1.02216717, grad/param norm = 6.7962e-02, time/batch = 0.1140s	
3494/5250 (epoch 33.276), train_loss = 1.00920059, grad/param norm = 6.2846e-02, time/batch = 0.1141s	
3495/5250 (epoch 33.286), train_loss = 0.98893330, grad/param norm = 5.9544e-02, time/batch = 0.1143s	
3496/5250 (epoch 33.295), train_loss = 1.01561324, grad/param norm = 6.4675e-02, time/batch = 0.1142s	
3497/5250 (epoch 33.305), train_loss = 1.01630096, grad/param norm = 6.5615e-02, time/batch = 0.1143s	
3498/5250 (epoch 33.314), train_loss = 1.01736812, grad/param norm = 7.0950e-02, time/batch = 0.1137s	
3499/5250 (epoch 33.324), train_loss = 1.02732699, grad/param norm = 6.6590e-02, time/batch = 0.1142s	
3500/5250 (epoch 33.333), train_loss = 1.02775339, grad/param norm = 6.5764e-02, time/batch = 0.1143s	
3501/5250 (epoch 33.343), train_loss = 1.02289247, grad/param norm = 5.9262e-02, time/batch = 0.1156s	
3502/5250 (epoch 33.352), train_loss = 1.03283447, grad/param norm = 6.3243e-02, time/batch = 0.1137s	
3503/5250 (epoch 33.362), train_loss = 1.02590435, grad/param norm = 6.2711e-02, time/batch = 0.1139s	
3504/5250 (epoch 33.371), train_loss = 1.00613126, grad/param norm = 5.9800e-02, time/batch = 0.1141s	
3505/5250 (epoch 33.381), train_loss = 1.01417501, grad/param norm = 6.2508e-02, time/batch = 0.1143s	
3506/5250 (epoch 33.390), train_loss = 1.01497503, grad/param norm = 6.4505e-02, time/batch = 0.1141s	
3507/5250 (epoch 33.400), train_loss = 1.01519545, grad/param norm = 6.1658e-02, time/batch = 0.1143s	
3508/5250 (epoch 33.410), train_loss = 1.02110888, grad/param norm = 6.5434e-02, time/batch = 0.1136s	
3509/5250 (epoch 33.419), train_loss = 1.02373407, grad/param norm = 6.1561e-02, time/batch = 0.1143s	
3510/5250 (epoch 33.429), train_loss = 1.03254005, grad/param norm = 6.5834e-02, time/batch = 0.1140s	
3511/5250 (epoch 33.438), train_loss = 1.03090253, grad/param norm = 6.1251e-02, time/batch = 0.1149s	
3512/5250 (epoch 33.448), train_loss = 1.01372207, grad/param norm = 6.2021e-02, time/batch = 0.1136s	
3513/5250 (epoch 33.457), train_loss = 1.02758808, grad/param norm = 6.6127e-02, time/batch = 0.1138s	
3514/5250 (epoch 33.467), train_loss = 1.02378645, grad/param norm = 6.2197e-02, time/batch = 0.1141s	
3515/5250 (epoch 33.476), train_loss = 1.02192626, grad/param norm = 6.3982e-02, time/batch = 0.1141s	
3516/5250 (epoch 33.486), train_loss = 1.04137190, grad/param norm = 6.6010e-02, time/batch = 0.1141s	
3517/5250 (epoch 33.495), train_loss = 1.03873545, grad/param norm = 6.3038e-02, time/batch = 0.1143s	
3518/5250 (epoch 33.505), train_loss = 1.03714372, grad/param norm = 5.9727e-02, time/batch = 0.1136s	
3519/5250 (epoch 33.514), train_loss = 1.02497002, grad/param norm = 6.1786e-02, time/batch = 0.1142s	
3520/5250 (epoch 33.524), train_loss = 1.03044175, grad/param norm = 6.3202e-02, time/batch = 0.1141s	
3521/5250 (epoch 33.533), train_loss = 1.03422697, grad/param norm = 6.5180e-02, time/batch = 0.1155s	
3522/5250 (epoch 33.543), train_loss = 1.02015186, grad/param norm = 6.2321e-02, time/batch = 0.1136s	
3523/5250 (epoch 33.552), train_loss = 1.02485867, grad/param norm = 6.1730e-02, time/batch = 0.1140s	
3524/5250 (epoch 33.562), train_loss = 1.02927120, grad/param norm = 6.3806e-02, time/batch = 0.1143s	
3525/5250 (epoch 33.571), train_loss = 1.03447936, grad/param norm = 6.7133e-02, time/batch = 0.1143s	
3526/5250 (epoch 33.581), train_loss = 1.03618593, grad/param norm = 6.2932e-02, time/batch = 0.1142s	
3527/5250 (epoch 33.590), train_loss = 1.02848588, grad/param norm = 6.2939e-02, time/batch = 0.1142s	
3528/5250 (epoch 33.600), train_loss = 1.04617472, grad/param norm = 6.4720e-02, time/batch = 0.1137s	
3529/5250 (epoch 33.610), train_loss = 1.03847269, grad/param norm = 5.9856e-02, time/batch = 0.1143s	
3530/5250 (epoch 33.619), train_loss = 1.03105931, grad/param norm = 6.0046e-02, time/batch = 0.1145s	
3531/5250 (epoch 33.629), train_loss = 1.02755739, grad/param norm = 6.6372e-02, time/batch = 0.1147s	
3532/5250 (epoch 33.638), train_loss = 1.02833047, grad/param norm = 6.1052e-02, time/batch = 0.1138s	
3533/5250 (epoch 33.648), train_loss = 1.03579392, grad/param norm = 6.0836e-02, time/batch = 0.1139s	
3534/5250 (epoch 33.657), train_loss = 1.02036226, grad/param norm = 5.7983e-02, time/batch = 0.1141s	
3535/5250 (epoch 33.667), train_loss = 1.02707782, grad/param norm = 6.0893e-02, time/batch = 0.1141s	
3536/5250 (epoch 33.676), train_loss = 1.02066958, grad/param norm = 6.2794e-02, time/batch = 0.1141s	
3537/5250 (epoch 33.686), train_loss = 1.03876418, grad/param norm = 6.5240e-02, time/batch = 0.1142s	
3538/5250 (epoch 33.695), train_loss = 1.03900890, grad/param norm = 6.5800e-02, time/batch = 0.1137s	
3539/5250 (epoch 33.705), train_loss = 1.01277475, grad/param norm = 6.5153e-02, time/batch = 0.1144s	
3540/5250 (epoch 33.714), train_loss = 1.04135060, grad/param norm = 6.1895e-02, time/batch = 0.1143s	
3541/5250 (epoch 33.724), train_loss = 1.02326277, grad/param norm = 6.5830e-02, time/batch = 0.1155s	
3542/5250 (epoch 33.733), train_loss = 1.01247314, grad/param norm = 6.6225e-02, time/batch = 0.1135s	
3543/5250 (epoch 33.743), train_loss = 1.00983625, grad/param norm = 6.2895e-02, time/batch = 0.1138s	
3544/5250 (epoch 33.752), train_loss = 1.01728516, grad/param norm = 6.4410e-02, time/batch = 0.1140s	
3545/5250 (epoch 33.762), train_loss = 1.00891127, grad/param norm = 6.1253e-02, time/batch = 0.1142s	
3546/5250 (epoch 33.771), train_loss = 1.00536779, grad/param norm = 6.0374e-02, time/batch = 0.1141s	
3547/5250 (epoch 33.781), train_loss = 1.03223948, grad/param norm = 6.1946e-02, time/batch = 0.1143s	
3548/5250 (epoch 33.790), train_loss = 1.03082750, grad/param norm = 6.4070e-02, time/batch = 0.1135s	
3549/5250 (epoch 33.800), train_loss = 1.00418370, grad/param norm = 6.5058e-02, time/batch = 0.1143s	
3550/5250 (epoch 33.810), train_loss = 1.02513112, grad/param norm = 6.3860e-02, time/batch = 0.1144s	
3551/5250 (epoch 33.819), train_loss = 1.03086100, grad/param norm = 6.4179e-02, time/batch = 0.1148s	
3552/5250 (epoch 33.829), train_loss = 1.02838976, grad/param norm = 7.4613e-02, time/batch = 0.1136s	
3553/5250 (epoch 33.838), train_loss = 1.00299717, grad/param norm = 6.3839e-02, time/batch = 0.1139s	
3554/5250 (epoch 33.848), train_loss = 0.99602360, grad/param norm = 6.3282e-02, time/batch = 0.1141s	
3555/5250 (epoch 33.857), train_loss = 1.00495044, grad/param norm = 6.1855e-02, time/batch = 0.1141s	
3556/5250 (epoch 33.867), train_loss = 1.01558731, grad/param norm = 7.0392e-02, time/batch = 0.1141s	
3557/5250 (epoch 33.876), train_loss = 1.00610606, grad/param norm = 6.9723e-02, time/batch = 0.1141s	
3558/5250 (epoch 33.886), train_loss = 1.00613821, grad/param norm = 7.0533e-02, time/batch = 0.1136s	
3559/5250 (epoch 33.895), train_loss = 1.03378490, grad/param norm = 6.8903e-02, time/batch = 0.1144s	
3560/5250 (epoch 33.905), train_loss = 1.02470774, grad/param norm = 6.2955e-02, time/batch = 0.1143s	
3561/5250 (epoch 33.914), train_loss = 1.03512506, grad/param norm = 6.4623e-02, time/batch = 0.1147s	
3562/5250 (epoch 33.924), train_loss = 1.04184067, grad/param norm = 6.2312e-02, time/batch = 0.1138s	
3563/5250 (epoch 33.933), train_loss = 1.03071039, grad/param norm = 6.2095e-02, time/batch = 0.1139s	
3564/5250 (epoch 33.943), train_loss = 1.03884613, grad/param norm = 6.3417e-02, time/batch = 0.1142s	
3565/5250 (epoch 33.952), train_loss = 1.04612194, grad/param norm = 6.4942e-02, time/batch = 0.1142s	
3566/5250 (epoch 33.962), train_loss = 1.02850706, grad/param norm = 6.4010e-02, time/batch = 0.1141s	
3567/5250 (epoch 33.971), train_loss = 1.04275747, grad/param norm = 6.4248e-02, time/batch = 0.1144s	
3568/5250 (epoch 33.981), train_loss = 1.04316211, grad/param norm = 6.3952e-02, time/batch = 0.1137s	
3569/5250 (epoch 33.990), train_loss = 1.04054381, grad/param norm = 6.5212e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
3570/5250 (epoch 34.000), train_loss = 1.02867527, grad/param norm = 6.1625e-02, time/batch = 0.1143s	
3571/5250 (epoch 34.010), train_loss = 1.20773558, grad/param norm = 6.7677e-02, time/batch = 0.1149s	
3572/5250 (epoch 34.019), train_loss = 1.02149339, grad/param norm = 6.1744e-02, time/batch = 0.1137s	
3573/5250 (epoch 34.029), train_loss = 1.04427770, grad/param norm = 6.2082e-02, time/batch = 0.1140s	
3574/5250 (epoch 34.038), train_loss = 1.01920891, grad/param norm = 6.1997e-02, time/batch = 0.1139s	
3575/5250 (epoch 34.048), train_loss = 0.99595094, grad/param norm = 6.2725e-02, time/batch = 0.1141s	
3576/5250 (epoch 34.057), train_loss = 1.00439110, grad/param norm = 5.9647e-02, time/batch = 0.1142s	
3577/5250 (epoch 34.067), train_loss = 1.01544285, grad/param norm = 6.2615e-02, time/batch = 0.1142s	
3578/5250 (epoch 34.076), train_loss = 1.03496726, grad/param norm = 6.0555e-02, time/batch = 0.1137s	
3579/5250 (epoch 34.086), train_loss = 0.98471222, grad/param norm = 6.0976e-02, time/batch = 0.1144s	
3580/5250 (epoch 34.095), train_loss = 1.00296652, grad/param norm = 5.9015e-02, time/batch = 0.1143s	
3581/5250 (epoch 34.105), train_loss = 1.02589272, grad/param norm = 6.0507e-02, time/batch = 0.1150s	
3582/5250 (epoch 34.114), train_loss = 1.00561947, grad/param norm = 5.9298e-02, time/batch = 0.1137s	
3583/5250 (epoch 34.124), train_loss = 1.02763645, grad/param norm = 6.1599e-02, time/batch = 0.1139s	
3584/5250 (epoch 34.133), train_loss = 1.01011445, grad/param norm = 6.0213e-02, time/batch = 0.1140s	
3585/5250 (epoch 34.143), train_loss = 0.99114875, grad/param norm = 6.0231e-02, time/batch = 0.1144s	
3586/5250 (epoch 34.152), train_loss = 0.99520883, grad/param norm = 6.3876e-02, time/batch = 0.1143s	
3587/5250 (epoch 34.162), train_loss = 1.01860728, grad/param norm = 6.0765e-02, time/batch = 0.1142s	
3588/5250 (epoch 34.171), train_loss = 1.01583446, grad/param norm = 6.2435e-02, time/batch = 0.1137s	
3589/5250 (epoch 34.181), train_loss = 1.01321914, grad/param norm = 6.5148e-02, time/batch = 0.1142s	
3590/5250 (epoch 34.190), train_loss = 1.01444592, grad/param norm = 6.7332e-02, time/batch = 0.1141s	
3591/5250 (epoch 34.200), train_loss = 1.01463052, grad/param norm = 6.3796e-02, time/batch = 0.1149s	
3592/5250 (epoch 34.210), train_loss = 1.02241045, grad/param norm = 6.1781e-02, time/batch = 0.1136s	
3593/5250 (epoch 34.219), train_loss = 1.05320670, grad/param norm = 6.6179e-02, time/batch = 0.1140s	
3594/5250 (epoch 34.229), train_loss = 1.02107016, grad/param norm = 6.6942e-02, time/batch = 0.1142s	
3595/5250 (epoch 34.238), train_loss = 1.01495939, grad/param norm = 6.4206e-02, time/batch = 0.1141s	
3596/5250 (epoch 34.248), train_loss = 1.01749323, grad/param norm = 6.2214e-02, time/batch = 0.1142s	
3597/5250 (epoch 34.257), train_loss = 1.01909649, grad/param norm = 6.1672e-02, time/batch = 0.1152s	
3598/5250 (epoch 34.267), train_loss = 1.01006620, grad/param norm = 6.0576e-02, time/batch = 0.1138s	
3599/5250 (epoch 34.276), train_loss = 1.00361084, grad/param norm = 7.1464e-02, time/batch = 0.1144s	
3600/5250 (epoch 34.286), train_loss = 0.98524837, grad/param norm = 7.8157e-02, time/batch = 0.1144s	
3601/5250 (epoch 34.295), train_loss = 1.01061681, grad/param norm = 6.4379e-02, time/batch = 0.1149s	
3602/5250 (epoch 34.305), train_loss = 1.00652909, grad/param norm = 6.8773e-02, time/batch = 0.1137s	
3603/5250 (epoch 34.314), train_loss = 1.00649345, grad/param norm = 6.5288e-02, time/batch = 0.1140s	
3604/5250 (epoch 34.324), train_loss = 1.01704287, grad/param norm = 6.5450e-02, time/batch = 0.1145s	
3605/5250 (epoch 34.333), train_loss = 1.01975925, grad/param norm = 6.6662e-02, time/batch = 0.1143s	
3606/5250 (epoch 34.343), train_loss = 1.01683407, grad/param norm = 6.6721e-02, time/batch = 0.1143s	
3607/5250 (epoch 34.352), train_loss = 1.02453092, grad/param norm = 6.3912e-02, time/batch = 0.1144s	
3608/5250 (epoch 34.362), train_loss = 1.01659894, grad/param norm = 6.0876e-02, time/batch = 0.1139s	
3609/5250 (epoch 34.371), train_loss = 0.99747857, grad/param norm = 6.2747e-02, time/batch = 0.1142s	
3610/5250 (epoch 34.381), train_loss = 1.00585716, grad/param norm = 6.2157e-02, time/batch = 0.1142s	
3611/5250 (epoch 34.390), train_loss = 1.00536801, grad/param norm = 6.2245e-02, time/batch = 0.1147s	
3612/5250 (epoch 34.400), train_loss = 1.00619317, grad/param norm = 6.4725e-02, time/batch = 0.1137s	
3613/5250 (epoch 34.410), train_loss = 1.01115959, grad/param norm = 6.3547e-02, time/batch = 0.1140s	
3614/5250 (epoch 34.419), train_loss = 1.01586788, grad/param norm = 6.7623e-02, time/batch = 0.1141s	
3615/5250 (epoch 34.429), train_loss = 1.02217464, grad/param norm = 6.4368e-02, time/batch = 0.1141s	
3616/5250 (epoch 34.438), train_loss = 1.02053634, grad/param norm = 6.3913e-02, time/batch = 0.1142s	
3617/5250 (epoch 34.448), train_loss = 1.00844372, grad/param norm = 6.9035e-02, time/batch = 0.1142s	
3618/5250 (epoch 34.457), train_loss = 1.01914953, grad/param norm = 6.5566e-02, time/batch = 0.1138s	
3619/5250 (epoch 34.467), train_loss = 1.01508193, grad/param norm = 6.0959e-02, time/batch = 0.1143s	
3620/5250 (epoch 34.476), train_loss = 1.01291707, grad/param norm = 6.4383e-02, time/batch = 0.1142s	
3621/5250 (epoch 34.486), train_loss = 1.03201315, grad/param norm = 6.7102e-02, time/batch = 0.1156s	
3622/5250 (epoch 34.495), train_loss = 1.02810461, grad/param norm = 5.9827e-02, time/batch = 0.1136s	
3623/5250 (epoch 34.505), train_loss = 1.02794458, grad/param norm = 6.0098e-02, time/batch = 0.1137s	
3624/5250 (epoch 34.514), train_loss = 1.01506944, grad/param norm = 6.0463e-02, time/batch = 0.1142s	
3625/5250 (epoch 34.524), train_loss = 1.02257400, grad/param norm = 6.2484e-02, time/batch = 0.1142s	
3626/5250 (epoch 34.533), train_loss = 1.02480907, grad/param norm = 6.3709e-02, time/batch = 0.1140s	
3627/5250 (epoch 34.543), train_loss = 1.00989038, grad/param norm = 6.3206e-02, time/batch = 0.1143s	
3628/5250 (epoch 34.552), train_loss = 1.02133980, grad/param norm = 6.5132e-02, time/batch = 0.1136s	
3629/5250 (epoch 34.562), train_loss = 1.01942380, grad/param norm = 6.3535e-02, time/batch = 0.1144s	
3630/5250 (epoch 34.571), train_loss = 1.02401607, grad/param norm = 6.2136e-02, time/batch = 0.1144s	
3631/5250 (epoch 34.581), train_loss = 1.02662023, grad/param norm = 6.5056e-02, time/batch = 0.1149s	
3632/5250 (epoch 34.590), train_loss = 1.02197687, grad/param norm = 6.6406e-02, time/batch = 0.1137s	
3633/5250 (epoch 34.600), train_loss = 1.03894873, grad/param norm = 6.8576e-02, time/batch = 0.1138s	
3634/5250 (epoch 34.610), train_loss = 1.03043661, grad/param norm = 6.4760e-02, time/batch = 0.1140s	
3635/5250 (epoch 34.619), train_loss = 1.02369532, grad/param norm = 6.3979e-02, time/batch = 0.1142s	
3636/5250 (epoch 34.629), train_loss = 1.01767750, grad/param norm = 6.3514e-02, time/batch = 0.1142s	
3637/5250 (epoch 34.638), train_loss = 1.02158581, grad/param norm = 6.5055e-02, time/batch = 0.1140s	
3638/5250 (epoch 34.648), train_loss = 1.03076132, grad/param norm = 6.1370e-02, time/batch = 0.1137s	
3639/5250 (epoch 34.657), train_loss = 1.01343333, grad/param norm = 6.3512e-02, time/batch = 0.1142s	
3640/5250 (epoch 34.667), train_loss = 1.01983160, grad/param norm = 6.3558e-02, time/batch = 0.1142s	
3641/5250 (epoch 34.676), train_loss = 1.01096073, grad/param norm = 6.1876e-02, time/batch = 0.1147s	
3642/5250 (epoch 34.686), train_loss = 1.03063676, grad/param norm = 6.8835e-02, time/batch = 0.1136s	
3643/5250 (epoch 34.695), train_loss = 1.03375113, grad/param norm = 7.2729e-02, time/batch = 0.1140s	
3644/5250 (epoch 34.705), train_loss = 1.00652963, grad/param norm = 6.8037e-02, time/batch = 0.1143s	
3645/5250 (epoch 34.714), train_loss = 1.03606786, grad/param norm = 7.1649e-02, time/batch = 0.1144s	
3646/5250 (epoch 34.724), train_loss = 1.01413958, grad/param norm = 6.4711e-02, time/batch = 0.1141s	
3647/5250 (epoch 34.733), train_loss = 0.99995499, grad/param norm = 6.0184e-02, time/batch = 0.1142s	
3648/5250 (epoch 34.743), train_loss = 1.00164373, grad/param norm = 6.3508e-02, time/batch = 0.1134s	
3649/5250 (epoch 34.752), train_loss = 1.00663754, grad/param norm = 6.6355e-02, time/batch = 0.1140s	
3650/5250 (epoch 34.762), train_loss = 1.00337747, grad/param norm = 6.8784e-02, time/batch = 0.1142s	
3651/5250 (epoch 34.771), train_loss = 0.99780446, grad/param norm = 6.2690e-02, time/batch = 0.1148s	
3652/5250 (epoch 34.781), train_loss = 1.02271164, grad/param norm = 6.1506e-02, time/batch = 0.1137s	
3653/5250 (epoch 34.790), train_loss = 1.02205790, grad/param norm = 6.3148e-02, time/batch = 0.1139s	
3654/5250 (epoch 34.800), train_loss = 0.99566665, grad/param norm = 6.5535e-02, time/batch = 0.1141s	
3655/5250 (epoch 34.810), train_loss = 1.01749180, grad/param norm = 6.6986e-02, time/batch = 0.1139s	
3656/5250 (epoch 34.819), train_loss = 1.02199630, grad/param norm = 6.2514e-02, time/batch = 0.1142s	
3657/5250 (epoch 34.829), train_loss = 1.01742452, grad/param norm = 6.7200e-02, time/batch = 0.1143s	
3658/5250 (epoch 34.838), train_loss = 0.99253812, grad/param norm = 6.1335e-02, time/batch = 0.1137s	
3659/5250 (epoch 34.848), train_loss = 0.98930930, grad/param norm = 6.9176e-02, time/batch = 0.1142s	
3660/5250 (epoch 34.857), train_loss = 0.99965453, grad/param norm = 6.7925e-02, time/batch = 0.1142s	
3661/5250 (epoch 34.867), train_loss = 1.00798018, grad/param norm = 7.1550e-02, time/batch = 0.1154s	
3662/5250 (epoch 34.876), train_loss = 0.99716658, grad/param norm = 6.8189e-02, time/batch = 0.1135s	
3663/5250 (epoch 34.886), train_loss = 0.99505435, grad/param norm = 6.5422e-02, time/batch = 0.1140s	
3664/5250 (epoch 34.895), train_loss = 1.02385197, grad/param norm = 7.0237e-02, time/batch = 0.1141s	
3665/5250 (epoch 34.905), train_loss = 1.01599549, grad/param norm = 6.3940e-02, time/batch = 0.1142s	
3666/5250 (epoch 34.914), train_loss = 1.02572290, grad/param norm = 6.7973e-02, time/batch = 0.1140s	
3667/5250 (epoch 34.924), train_loss = 1.03373026, grad/param norm = 6.6115e-02, time/batch = 0.1142s	
3668/5250 (epoch 34.933), train_loss = 1.02213157, grad/param norm = 6.3643e-02, time/batch = 0.1136s	
3669/5250 (epoch 34.943), train_loss = 1.02989370, grad/param norm = 6.4490e-02, time/batch = 0.1140s	
3670/5250 (epoch 34.952), train_loss = 1.03533219, grad/param norm = 6.2530e-02, time/batch = 0.1143s	
3671/5250 (epoch 34.962), train_loss = 1.01804371, grad/param norm = 6.2028e-02, time/batch = 0.1148s	
3672/5250 (epoch 34.971), train_loss = 1.03204427, grad/param norm = 5.9521e-02, time/batch = 0.1136s	
3673/5250 (epoch 34.981), train_loss = 1.03271904, grad/param norm = 6.3459e-02, time/batch = 0.1140s	
3674/5250 (epoch 34.990), train_loss = 1.03188341, grad/param norm = 6.3408e-02, time/batch = 0.1140s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
3675/5250 (epoch 35.000), train_loss = 1.01847602, grad/param norm = 6.0721e-02, time/batch = 0.1142s	
3676/5250 (epoch 35.010), train_loss = 1.19893103, grad/param norm = 7.0700e-02, time/batch = 0.1141s	
3677/5250 (epoch 35.019), train_loss = 1.01399759, grad/param norm = 6.5430e-02, time/batch = 0.1142s	
3678/5250 (epoch 35.029), train_loss = 1.03679336, grad/param norm = 6.4163e-02, time/batch = 0.1136s	
3679/5250 (epoch 35.038), train_loss = 1.01115675, grad/param norm = 6.3264e-02, time/batch = 0.1142s	
3680/5250 (epoch 35.048), train_loss = 0.98803776, grad/param norm = 6.0808e-02, time/batch = 0.1143s	
3681/5250 (epoch 35.057), train_loss = 0.99531851, grad/param norm = 6.1820e-02, time/batch = 0.1148s	
3682/5250 (epoch 35.067), train_loss = 1.00737298, grad/param norm = 6.2916e-02, time/batch = 0.1135s	
3683/5250 (epoch 35.076), train_loss = 1.02756409, grad/param norm = 6.3011e-02, time/batch = 0.1138s	
3684/5250 (epoch 35.086), train_loss = 0.97912402, grad/param norm = 6.3930e-02, time/batch = 0.1142s	
3685/5250 (epoch 35.095), train_loss = 0.99553369, grad/param norm = 6.0141e-02, time/batch = 0.1140s	
3686/5250 (epoch 35.105), train_loss = 1.01755223, grad/param norm = 6.1360e-02, time/batch = 0.1139s	
3687/5250 (epoch 35.114), train_loss = 0.99651804, grad/param norm = 6.0288e-02, time/batch = 0.1141s	
3688/5250 (epoch 35.124), train_loss = 1.01991510, grad/param norm = 6.2134e-02, time/batch = 0.1136s	
3689/5250 (epoch 35.133), train_loss = 1.00295417, grad/param norm = 6.1639e-02, time/batch = 0.1144s	
3690/5250 (epoch 35.143), train_loss = 0.98296536, grad/param norm = 6.0817e-02, time/batch = 0.1141s	
3691/5250 (epoch 35.152), train_loss = 0.98698123, grad/param norm = 6.4758e-02, time/batch = 0.1149s	
3692/5250 (epoch 35.162), train_loss = 1.01022756, grad/param norm = 6.2707e-02, time/batch = 0.1137s	
3693/5250 (epoch 35.171), train_loss = 1.00815135, grad/param norm = 6.0351e-02, time/batch = 0.1140s	
3694/5250 (epoch 35.181), train_loss = 1.00442828, grad/param norm = 6.4356e-02, time/batch = 0.1140s	
3695/5250 (epoch 35.190), train_loss = 1.00452825, grad/param norm = 6.7173e-02, time/batch = 0.1141s	
3696/5250 (epoch 35.200), train_loss = 1.00551509, grad/param norm = 6.4045e-02, time/batch = 0.1140s	
3697/5250 (epoch 35.210), train_loss = 1.01420266, grad/param norm = 6.3659e-02, time/batch = 0.1142s	
3698/5250 (epoch 35.219), train_loss = 1.04360713, grad/param norm = 6.4442e-02, time/batch = 0.1137s	
3699/5250 (epoch 35.229), train_loss = 1.01138494, grad/param norm = 6.3597e-02, time/batch = 0.1143s	
3700/5250 (epoch 35.238), train_loss = 1.00610140, grad/param norm = 6.4708e-02, time/batch = 0.1142s	
3701/5250 (epoch 35.248), train_loss = 1.00978782, grad/param norm = 6.2900e-02, time/batch = 0.1148s	
3702/5250 (epoch 35.257), train_loss = 1.01351848, grad/param norm = 6.6552e-02, time/batch = 0.1136s	
3703/5250 (epoch 35.267), train_loss = 1.00389367, grad/param norm = 6.5820e-02, time/batch = 0.1140s	
3704/5250 (epoch 35.276), train_loss = 0.99251448, grad/param norm = 6.3584e-02, time/batch = 0.1142s	
3705/5250 (epoch 35.286), train_loss = 0.97165962, grad/param norm = 6.1892e-02, time/batch = 0.1143s	
3706/5250 (epoch 35.295), train_loss = 1.00131650, grad/param norm = 6.9419e-02, time/batch = 0.1141s	
3707/5250 (epoch 35.305), train_loss = 1.00042828, grad/param norm = 6.8965e-02, time/batch = 0.1142s	
3708/5250 (epoch 35.314), train_loss = 0.99936602, grad/param norm = 7.1233e-02, time/batch = 0.1138s	
3709/5250 (epoch 35.324), train_loss = 1.00971905, grad/param norm = 6.7200e-02, time/batch = 0.1143s	
3710/5250 (epoch 35.333), train_loss = 1.01261340, grad/param norm = 7.1072e-02, time/batch = 0.1143s	
3711/5250 (epoch 35.343), train_loss = 1.00616791, grad/param norm = 6.0204e-02, time/batch = 0.1147s	
3712/5250 (epoch 35.352), train_loss = 1.01550163, grad/param norm = 6.4814e-02, time/batch = 0.1135s	
3713/5250 (epoch 35.362), train_loss = 1.01046216, grad/param norm = 6.4236e-02, time/batch = 0.1138s	
3714/5250 (epoch 35.371), train_loss = 0.98919024, grad/param norm = 6.1117e-02, time/batch = 0.1141s	
3715/5250 (epoch 35.381), train_loss = 0.99712502, grad/param norm = 6.3308e-02, time/batch = 0.1141s	
3716/5250 (epoch 35.390), train_loss = 0.99859568, grad/param norm = 6.7440e-02, time/batch = 0.1142s	
3717/5250 (epoch 35.400), train_loss = 0.99734852, grad/param norm = 6.3718e-02, time/batch = 0.1144s	
3718/5250 (epoch 35.410), train_loss = 1.00346638, grad/param norm = 6.8706e-02, time/batch = 0.1135s	
3719/5250 (epoch 35.419), train_loss = 1.00783012, grad/param norm = 6.6289e-02, time/batch = 0.1141s	
3720/5250 (epoch 35.429), train_loss = 1.01733994, grad/param norm = 7.0999e-02, time/batch = 0.1140s	
3721/5250 (epoch 35.438), train_loss = 1.01390263, grad/param norm = 6.5833e-02, time/batch = 0.1148s	
3722/5250 (epoch 35.448), train_loss = 0.99781102, grad/param norm = 6.3103e-02, time/batch = 0.1138s	
3723/5250 (epoch 35.457), train_loss = 1.01129493, grad/param norm = 6.4682e-02, time/batch = 0.1140s	
3724/5250 (epoch 35.467), train_loss = 1.00802121, grad/param norm = 6.7701e-02, time/batch = 0.1140s	
3725/5250 (epoch 35.476), train_loss = 1.00870038, grad/param norm = 7.1015e-02, time/batch = 0.1143s	
3726/5250 (epoch 35.486), train_loss = 1.02684072, grad/param norm = 7.2877e-02, time/batch = 0.1142s	
3727/5250 (epoch 35.495), train_loss = 1.02042206, grad/param norm = 6.1472e-02, time/batch = 0.1142s	
3728/5250 (epoch 35.505), train_loss = 1.02053983, grad/param norm = 6.2157e-02, time/batch = 0.1136s	
3729/5250 (epoch 35.514), train_loss = 1.00801612, grad/param norm = 6.1450e-02, time/batch = 0.1142s	
3730/5250 (epoch 35.524), train_loss = 1.01402314, grad/param norm = 6.3429e-02, time/batch = 0.1142s	
3731/5250 (epoch 35.533), train_loss = 1.01681805, grad/param norm = 6.4040e-02, time/batch = 0.1150s	
3732/5250 (epoch 35.543), train_loss = 1.00091782, grad/param norm = 6.3333e-02, time/batch = 0.1136s	
3733/5250 (epoch 35.552), train_loss = 1.01197833, grad/param norm = 6.2619e-02, time/batch = 0.1139s	
3734/5250 (epoch 35.562), train_loss = 1.01088742, grad/param norm = 6.2645e-02, time/batch = 0.1143s	
3735/5250 (epoch 35.571), train_loss = 1.01778316, grad/param norm = 6.9657e-02, time/batch = 0.1141s	
3736/5250 (epoch 35.581), train_loss = 1.01975069, grad/param norm = 6.6190e-02, time/batch = 0.1142s	
3737/5250 (epoch 35.590), train_loss = 1.01141020, grad/param norm = 6.3802e-02, time/batch = 0.1143s	
3738/5250 (epoch 35.600), train_loss = 1.02915829, grad/param norm = 6.5196e-02, time/batch = 0.1136s	
3739/5250 (epoch 35.610), train_loss = 1.02171003, grad/param norm = 6.4904e-02, time/batch = 0.1141s	
3740/5250 (epoch 35.619), train_loss = 1.01621436, grad/param norm = 6.5502e-02, time/batch = 0.1143s	
3741/5250 (epoch 35.629), train_loss = 1.00986761, grad/param norm = 6.5900e-02, time/batch = 0.1147s	
3742/5250 (epoch 35.638), train_loss = 1.01211539, grad/param norm = 6.2048e-02, time/batch = 0.1137s	
3743/5250 (epoch 35.648), train_loss = 1.02152967, grad/param norm = 6.4444e-02, time/batch = 0.1138s	
3744/5250 (epoch 35.657), train_loss = 1.00562729, grad/param norm = 6.4129e-02, time/batch = 0.1142s	
3745/5250 (epoch 35.667), train_loss = 1.00978649, grad/param norm = 6.6461e-02, time/batch = 0.1143s	
3746/5250 (epoch 35.676), train_loss = 1.00567645, grad/param norm = 6.7159e-02, time/batch = 0.1142s	
3747/5250 (epoch 35.686), train_loss = 1.02198864, grad/param norm = 7.2350e-02, time/batch = 0.1142s	
3748/5250 (epoch 35.695), train_loss = 1.02384537, grad/param norm = 7.1207e-02, time/batch = 0.1138s	
3749/5250 (epoch 35.705), train_loss = 0.99765867, grad/param norm = 6.9582e-02, time/batch = 0.1144s	
3750/5250 (epoch 35.714), train_loss = 1.02519567, grad/param norm = 6.8846e-02, time/batch = 0.1142s	
3751/5250 (epoch 35.724), train_loss = 1.00792951, grad/param norm = 6.8401e-02, time/batch = 0.1148s	
3752/5250 (epoch 35.733), train_loss = 0.99487356, grad/param norm = 6.8253e-02, time/batch = 0.1137s	
3753/5250 (epoch 35.743), train_loss = 0.99390384, grad/param norm = 6.6294e-02, time/batch = 0.1141s	
3754/5250 (epoch 35.752), train_loss = 0.99875221, grad/param norm = 6.4851e-02, time/batch = 0.1141s	
3755/5250 (epoch 35.762), train_loss = 0.99479488, grad/param norm = 6.7930e-02, time/batch = 0.1142s	
3756/5250 (epoch 35.771), train_loss = 0.98870695, grad/param norm = 6.0649e-02, time/batch = 0.1140s	
3757/5250 (epoch 35.781), train_loss = 1.01436533, grad/param norm = 6.5170e-02, time/batch = 0.1142s	
3758/5250 (epoch 35.790), train_loss = 1.01486970, grad/param norm = 6.5333e-02, time/batch = 0.1137s	
3759/5250 (epoch 35.800), train_loss = 0.98582489, grad/param norm = 6.4735e-02, time/batch = 0.1141s	
3760/5250 (epoch 35.810), train_loss = 1.00934665, grad/param norm = 6.6716e-02, time/batch = 0.1143s	
3761/5250 (epoch 35.819), train_loss = 1.01455626, grad/param norm = 6.5303e-02, time/batch = 0.1149s	
3762/5250 (epoch 35.829), train_loss = 1.00822752, grad/param norm = 6.6318e-02, time/batch = 0.1137s	
3763/5250 (epoch 35.838), train_loss = 0.98579068, grad/param norm = 6.6703e-02, time/batch = 0.1142s	
3764/5250 (epoch 35.848), train_loss = 0.98195770, grad/param norm = 6.8109e-02, time/batch = 0.1141s	
3765/5250 (epoch 35.857), train_loss = 0.98890027, grad/param norm = 6.3380e-02, time/batch = 0.1143s	
3766/5250 (epoch 35.867), train_loss = 0.99712814, grad/param norm = 6.8525e-02, time/batch = 0.1141s	
3767/5250 (epoch 35.876), train_loss = 0.98684022, grad/param norm = 6.4807e-02, time/batch = 0.1141s	
3768/5250 (epoch 35.886), train_loss = 0.98768514, grad/param norm = 6.8424e-02, time/batch = 0.1135s	
3769/5250 (epoch 35.895), train_loss = 1.01432737, grad/param norm = 6.8782e-02, time/batch = 0.1144s	
3770/5250 (epoch 35.905), train_loss = 1.00588226, grad/param norm = 6.3129e-02, time/batch = 0.1142s	
3771/5250 (epoch 35.914), train_loss = 1.01662355, grad/param norm = 6.6652e-02, time/batch = 0.1149s	
3772/5250 (epoch 35.924), train_loss = 1.02434381, grad/param norm = 6.3707e-02, time/batch = 0.1136s	
3773/5250 (epoch 35.933), train_loss = 1.01334450, grad/param norm = 6.1354e-02, time/batch = 0.1140s	
3774/5250 (epoch 35.943), train_loss = 1.02100465, grad/param norm = 6.5146e-02, time/batch = 0.1141s	
3775/5250 (epoch 35.952), train_loss = 1.02738299, grad/param norm = 6.2926e-02, time/batch = 0.1142s	
3776/5250 (epoch 35.962), train_loss = 1.01080551, grad/param norm = 6.3719e-02, time/batch = 0.1142s	
3777/5250 (epoch 35.971), train_loss = 1.02262213, grad/param norm = 6.0445e-02, time/batch = 0.1142s	
3778/5250 (epoch 35.981), train_loss = 1.02278250, grad/param norm = 6.3547e-02, time/batch = 0.1135s	
3779/5250 (epoch 35.990), train_loss = 1.02328167, grad/param norm = 6.4253e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
3780/5250 (epoch 36.000), train_loss = 1.00948261, grad/param norm = 6.0905e-02, time/batch = 0.1143s	
3781/5250 (epoch 36.010), train_loss = 1.19047299, grad/param norm = 6.9760e-02, time/batch = 0.1150s	
3782/5250 (epoch 36.019), train_loss = 1.00465209, grad/param norm = 6.3490e-02, time/batch = 0.1138s	
3783/5250 (epoch 36.029), train_loss = 1.02801679, grad/param norm = 6.3858e-02, time/batch = 0.1140s	
3784/5250 (epoch 36.038), train_loss = 1.00322803, grad/param norm = 6.3207e-02, time/batch = 0.1142s	
3785/5250 (epoch 36.048), train_loss = 0.98009891, grad/param norm = 6.4442e-02, time/batch = 0.1144s	
3786/5250 (epoch 36.057), train_loss = 0.98813083, grad/param norm = 6.1188e-02, time/batch = 0.1143s	
3787/5250 (epoch 36.067), train_loss = 0.99895071, grad/param norm = 6.3101e-02, time/batch = 0.1142s	
3788/5250 (epoch 36.076), train_loss = 1.01837917, grad/param norm = 6.1702e-02, time/batch = 0.1137s	
3789/5250 (epoch 36.086), train_loss = 0.96946078, grad/param norm = 6.1269e-02, time/batch = 0.1143s	
3790/5250 (epoch 36.095), train_loss = 0.98742566, grad/param norm = 6.1245e-02, time/batch = 0.1143s	
3791/5250 (epoch 36.105), train_loss = 1.01104914, grad/param norm = 6.4423e-02, time/batch = 0.1157s	
3792/5250 (epoch 36.114), train_loss = 0.98804134, grad/param norm = 6.0909e-02, time/batch = 0.1133s	
3793/5250 (epoch 36.124), train_loss = 1.01263570, grad/param norm = 6.3306e-02, time/batch = 0.1140s	
3794/5250 (epoch 36.133), train_loss = 0.99520798, grad/param norm = 6.2108e-02, time/batch = 0.1142s	
3795/5250 (epoch 36.143), train_loss = 0.97492845, grad/param norm = 6.1471e-02, time/batch = 0.1143s	
3796/5250 (epoch 36.152), train_loss = 0.97935098, grad/param norm = 6.6087e-02, time/batch = 0.1139s	
3797/5250 (epoch 36.162), train_loss = 1.00145200, grad/param norm = 6.3693e-02, time/batch = 0.1141s	
3798/5250 (epoch 36.171), train_loss = 1.00055759, grad/param norm = 6.1625e-02, time/batch = 0.1137s	
3799/5250 (epoch 36.181), train_loss = 0.99675673, grad/param norm = 6.5817e-02, time/batch = 0.1142s	
3800/5250 (epoch 36.190), train_loss = 0.99597183, grad/param norm = 6.6922e-02, time/batch = 0.1142s	
3801/5250 (epoch 36.200), train_loss = 0.99741681, grad/param norm = 6.5331e-02, time/batch = 0.1149s	
3802/5250 (epoch 36.210), train_loss = 1.00602574, grad/param norm = 6.3695e-02, time/batch = 0.1137s	
3803/5250 (epoch 36.219), train_loss = 1.03676460, grad/param norm = 6.7281e-02, time/batch = 0.1140s	
3804/5250 (epoch 36.229), train_loss = 1.00255720, grad/param norm = 6.4734e-02, time/batch = 0.1140s	
3805/5250 (epoch 36.238), train_loss = 0.99706671, grad/param norm = 6.3477e-02, time/batch = 0.1142s	
3806/5250 (epoch 36.248), train_loss = 1.00188870, grad/param norm = 6.4606e-02, time/batch = 0.1141s	
3807/5250 (epoch 36.257), train_loss = 1.00364705, grad/param norm = 6.3138e-02, time/batch = 0.1145s	
3808/5250 (epoch 36.267), train_loss = 0.99416676, grad/param norm = 6.1778e-02, time/batch = 0.1135s	
3809/5250 (epoch 36.276), train_loss = 0.98669371, grad/param norm = 7.1518e-02, time/batch = 0.1143s	
3810/5250 (epoch 36.286), train_loss = 0.96566743, grad/param norm = 7.2453e-02, time/batch = 0.1141s	
3811/5250 (epoch 36.295), train_loss = 0.99247746, grad/param norm = 6.3574e-02, time/batch = 0.1151s	
3812/5250 (epoch 36.305), train_loss = 0.98992951, grad/param norm = 6.9376e-02, time/batch = 0.1136s	
3813/5250 (epoch 36.314), train_loss = 0.98789682, grad/param norm = 6.4292e-02, time/batch = 0.1140s	
3814/5250 (epoch 36.324), train_loss = 0.99984459, grad/param norm = 6.7631e-02, time/batch = 0.1144s	
3815/5250 (epoch 36.333), train_loss = 1.00466447, grad/param norm = 7.0419e-02, time/batch = 0.1142s	
3816/5250 (epoch 36.343), train_loss = 1.00119111, grad/param norm = 7.0537e-02, time/batch = 0.1141s	
3817/5250 (epoch 36.352), train_loss = 1.00889867, grad/param norm = 6.5514e-02, time/batch = 0.1141s	
3818/5250 (epoch 36.362), train_loss = 1.00039952, grad/param norm = 6.2256e-02, time/batch = 0.1135s	
3819/5250 (epoch 36.371), train_loss = 0.98158650, grad/param norm = 6.5304e-02, time/batch = 0.1143s	
3820/5250 (epoch 36.381), train_loss = 0.98916664, grad/param norm = 6.3604e-02, time/batch = 0.1141s	
3821/5250 (epoch 36.390), train_loss = 0.99002193, grad/param norm = 6.4538e-02, time/batch = 0.1148s	
3822/5250 (epoch 36.400), train_loss = 0.98928663, grad/param norm = 6.5833e-02, time/batch = 0.1136s	
3823/5250 (epoch 36.410), train_loss = 0.99450397, grad/param norm = 6.7292e-02, time/batch = 0.1140s	
3824/5250 (epoch 36.419), train_loss = 0.99971926, grad/param norm = 7.2846e-02, time/batch = 0.1141s	
3825/5250 (epoch 36.429), train_loss = 1.00629281, grad/param norm = 6.8096e-02, time/batch = 0.1143s	
3826/5250 (epoch 36.438), train_loss = 1.00421336, grad/param norm = 6.8042e-02, time/batch = 0.1141s	
3827/5250 (epoch 36.448), train_loss = 0.99426506, grad/param norm = 7.1814e-02, time/batch = 0.1142s	
3828/5250 (epoch 36.457), train_loss = 1.00432345, grad/param norm = 6.6577e-02, time/batch = 0.1136s	
3829/5250 (epoch 36.467), train_loss = 0.99989945, grad/param norm = 6.2537e-02, time/batch = 0.1145s	
3830/5250 (epoch 36.476), train_loss = 0.99837294, grad/param norm = 6.8141e-02, time/batch = 0.1142s	
3831/5250 (epoch 36.486), train_loss = 1.01789067, grad/param norm = 6.9232e-02, time/batch = 0.1148s	
3832/5250 (epoch 36.495), train_loss = 1.01254397, grad/param norm = 6.6649e-02, time/batch = 0.1137s	
3833/5250 (epoch 36.505), train_loss = 1.01433969, grad/param norm = 6.5113e-02, time/batch = 0.1142s	
3834/5250 (epoch 36.514), train_loss = 1.00022360, grad/param norm = 6.3288e-02, time/batch = 0.1140s	
3835/5250 (epoch 36.524), train_loss = 1.00591932, grad/param norm = 6.4539e-02, time/batch = 0.1142s	
3836/5250 (epoch 36.533), train_loss = 1.00965834, grad/param norm = 6.4409e-02, time/batch = 0.1142s	
3837/5250 (epoch 36.543), train_loss = 0.99483595, grad/param norm = 6.6673e-02, time/batch = 0.1141s	
3838/5250 (epoch 36.552), train_loss = 1.00381669, grad/param norm = 6.3100e-02, time/batch = 0.1136s	
3839/5250 (epoch 36.562), train_loss = 1.00271526, grad/param norm = 6.2445e-02, time/batch = 0.1143s	
3840/5250 (epoch 36.571), train_loss = 1.00851061, grad/param norm = 6.7556e-02, time/batch = 0.1142s	
3841/5250 (epoch 36.581), train_loss = 1.01000949, grad/param norm = 6.4207e-02, time/batch = 0.1147s	
3842/5250 (epoch 36.590), train_loss = 1.00262823, grad/param norm = 6.4536e-02, time/batch = 0.1138s	
3843/5250 (epoch 36.600), train_loss = 1.02148391, grad/param norm = 7.0480e-02, time/batch = 0.1139s	
3844/5250 (epoch 36.610), train_loss = 1.01426359, grad/param norm = 6.5455e-02, time/batch = 0.1141s	
3845/5250 (epoch 36.619), train_loss = 1.00568375, grad/param norm = 6.2617e-02, time/batch = 0.1144s	
3846/5250 (epoch 36.629), train_loss = 1.00039481, grad/param norm = 6.2459e-02, time/batch = 0.1142s	
3847/5250 (epoch 36.638), train_loss = 1.00536500, grad/param norm = 6.5075e-02, time/batch = 0.1141s	
3848/5250 (epoch 36.648), train_loss = 1.01451298, grad/param norm = 6.1842e-02, time/batch = 0.1137s	
3849/5250 (epoch 36.657), train_loss = 0.99553059, grad/param norm = 6.1475e-02, time/batch = 0.1141s	
3850/5250 (epoch 36.667), train_loss = 1.00126813, grad/param norm = 6.4495e-02, time/batch = 0.1142s	
3851/5250 (epoch 36.676), train_loss = 0.99521921, grad/param norm = 6.4086e-02, time/batch = 0.1155s	
3852/5250 (epoch 36.686), train_loss = 1.01295748, grad/param norm = 6.8943e-02, time/batch = 0.1137s	
3853/5250 (epoch 36.695), train_loss = 1.01580106, grad/param norm = 7.7207e-02, time/batch = 0.1139s	
3854/5250 (epoch 36.705), train_loss = 0.99536727, grad/param norm = 7.4286e-02, time/batch = 0.1141s	
3855/5250 (epoch 36.714), train_loss = 1.01918862, grad/param norm = 7.3640e-02, time/batch = 0.1141s	
3856/5250 (epoch 36.724), train_loss = 0.99872064, grad/param norm = 6.7510e-02, time/batch = 0.1142s	
3857/5250 (epoch 36.733), train_loss = 0.98623202, grad/param norm = 6.5079e-02, time/batch = 0.1143s	
3858/5250 (epoch 36.743), train_loss = 0.98677959, grad/param norm = 6.5588e-02, time/batch = 0.1134s	
3859/5250 (epoch 36.752), train_loss = 0.98912029, grad/param norm = 6.4977e-02, time/batch = 0.1142s	
3860/5250 (epoch 36.762), train_loss = 0.98472351, grad/param norm = 6.3185e-02, time/batch = 0.1141s	
3861/5250 (epoch 36.771), train_loss = 0.98298659, grad/param norm = 6.4544e-02, time/batch = 0.1155s	
3862/5250 (epoch 36.781), train_loss = 1.00667917, grad/param norm = 6.6163e-02, time/batch = 0.1137s	
3863/5250 (epoch 36.790), train_loss = 1.00517697, grad/param norm = 6.2322e-02, time/batch = 0.1138s	
3864/5250 (epoch 36.800), train_loss = 0.97883131, grad/param norm = 6.7354e-02, time/batch = 0.1140s	
3865/5250 (epoch 36.810), train_loss = 1.00258987, grad/param norm = 7.0753e-02, time/batch = 0.1144s	
3866/5250 (epoch 36.819), train_loss = 1.00601663, grad/param norm = 6.3778e-02, time/batch = 0.1141s	
3867/5250 (epoch 36.829), train_loss = 0.99969513, grad/param norm = 6.7772e-02, time/batch = 0.1143s	
3868/5250 (epoch 36.838), train_loss = 0.97660713, grad/param norm = 6.5852e-02, time/batch = 0.1137s	
3869/5250 (epoch 36.848), train_loss = 0.97200599, grad/param norm = 6.6588e-02, time/batch = 0.1144s	
3870/5250 (epoch 36.857), train_loss = 0.98206621, grad/param norm = 6.7092e-02, time/batch = 0.1142s	
3871/5250 (epoch 36.867), train_loss = 0.99018383, grad/param norm = 7.5542e-02, time/batch = 0.1147s	
3872/5250 (epoch 36.876), train_loss = 0.98097571, grad/param norm = 6.7240e-02, time/batch = 0.1137s	
3873/5250 (epoch 36.886), train_loss = 0.97946565, grad/param norm = 6.7267e-02, time/batch = 0.1141s	
3874/5250 (epoch 36.895), train_loss = 1.00533276, grad/param norm = 6.6273e-02, time/batch = 0.1141s	
3875/5250 (epoch 36.905), train_loss = 0.99697986, grad/param norm = 6.3570e-02, time/batch = 0.1141s	
3876/5250 (epoch 36.914), train_loss = 1.00795642, grad/param norm = 6.5327e-02, time/batch = 0.1142s	
3877/5250 (epoch 36.924), train_loss = 1.01526349, grad/param norm = 6.4467e-02, time/batch = 0.1140s	
3878/5250 (epoch 36.933), train_loss = 1.00468156, grad/param norm = 6.3592e-02, time/batch = 0.1135s	
3879/5250 (epoch 36.943), train_loss = 1.01240128, grad/param norm = 6.4540e-02, time/batch = 0.1144s	
3880/5250 (epoch 36.952), train_loss = 1.01760768, grad/param norm = 6.1753e-02, time/batch = 0.1142s	
3881/5250 (epoch 36.962), train_loss = 1.00260246, grad/param norm = 6.4935e-02, time/batch = 0.1155s	
3882/5250 (epoch 36.971), train_loss = 1.01433368, grad/param norm = 6.0499e-02, time/batch = 0.1136s	
3883/5250 (epoch 36.981), train_loss = 1.01379454, grad/param norm = 6.4518e-02, time/batch = 0.1139s	
3884/5250 (epoch 36.990), train_loss = 1.01494973, grad/param norm = 6.3474e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
3885/5250 (epoch 37.000), train_loss = 1.00102055, grad/param norm = 6.0935e-02, time/batch = 0.1141s	
3886/5250 (epoch 37.010), train_loss = 1.18212029, grad/param norm = 7.0589e-02, time/batch = 0.1142s	
3887/5250 (epoch 37.019), train_loss = 0.99705244, grad/param norm = 6.3713e-02, time/batch = 0.1142s	
3888/5250 (epoch 37.029), train_loss = 1.02005532, grad/param norm = 6.6918e-02, time/batch = 0.1135s	
3889/5250 (epoch 37.038), train_loss = 0.99644915, grad/param norm = 6.4032e-02, time/batch = 0.1144s	
3890/5250 (epoch 37.048), train_loss = 0.97223993, grad/param norm = 6.4021e-02, time/batch = 0.1144s	
3891/5250 (epoch 37.057), train_loss = 0.97982764, grad/param norm = 6.2258e-02, time/batch = 0.1149s	
3892/5250 (epoch 37.067), train_loss = 0.99107487, grad/param norm = 6.4413e-02, time/batch = 0.1137s	
3893/5250 (epoch 37.076), train_loss = 1.01076544, grad/param norm = 6.3356e-02, time/batch = 0.1141s	
3894/5250 (epoch 37.086), train_loss = 0.96269184, grad/param norm = 6.1818e-02, time/batch = 0.1142s	
3895/5250 (epoch 37.095), train_loss = 0.97860070, grad/param norm = 6.1300e-02, time/batch = 0.1144s	
3896/5250 (epoch 37.105), train_loss = 1.00266550, grad/param norm = 6.4140e-02, time/batch = 0.1142s	
3897/5250 (epoch 37.114), train_loss = 0.97929201, grad/param norm = 6.1779e-02, time/batch = 0.1140s	
3898/5250 (epoch 37.124), train_loss = 1.00503570, grad/param norm = 6.3649e-02, time/batch = 0.1138s	
3899/5250 (epoch 37.133), train_loss = 0.98803193, grad/param norm = 6.2925e-02, time/batch = 0.1143s	
3900/5250 (epoch 37.143), train_loss = 0.96650075, grad/param norm = 6.2343e-02, time/batch = 0.1142s	
3901/5250 (epoch 37.152), train_loss = 0.97173931, grad/param norm = 6.7812e-02, time/batch = 0.1147s	
3902/5250 (epoch 37.162), train_loss = 0.99468684, grad/param norm = 6.5142e-02, time/batch = 0.1137s	
3903/5250 (epoch 37.171), train_loss = 0.99282159, grad/param norm = 6.2983e-02, time/batch = 0.1139s	
3904/5250 (epoch 37.181), train_loss = 0.98952828, grad/param norm = 6.6127e-02, time/batch = 0.1141s	
3905/5250 (epoch 37.190), train_loss = 0.98800258, grad/param norm = 6.8142e-02, time/batch = 0.1143s	
3906/5250 (epoch 37.200), train_loss = 0.99062401, grad/param norm = 6.7392e-02, time/batch = 0.1141s	
3907/5250 (epoch 37.210), train_loss = 0.99778403, grad/param norm = 6.3880e-02, time/batch = 0.1141s	
3908/5250 (epoch 37.219), train_loss = 1.03091288, grad/param norm = 7.0769e-02, time/batch = 0.1134s	
3909/5250 (epoch 37.229), train_loss = 0.99550241, grad/param norm = 6.4936e-02, time/batch = 0.1144s	
3910/5250 (epoch 37.238), train_loss = 0.99014168, grad/param norm = 6.5122e-02, time/batch = 0.1142s	
3911/5250 (epoch 37.248), train_loss = 0.99460216, grad/param norm = 6.7458e-02, time/batch = 0.1149s	
3912/5250 (epoch 37.257), train_loss = 0.99700281, grad/param norm = 6.5567e-02, time/batch = 0.1135s	
3913/5250 (epoch 37.267), train_loss = 0.98724112, grad/param norm = 6.3851e-02, time/batch = 0.1139s	
3914/5250 (epoch 37.276), train_loss = 0.97630968, grad/param norm = 6.6132e-02, time/batch = 0.1141s	
3915/5250 (epoch 37.286), train_loss = 0.95400970, grad/param norm = 6.2940e-02, time/batch = 0.1141s	
3916/5250 (epoch 37.295), train_loss = 0.98378754, grad/param norm = 6.5420e-02, time/batch = 0.1145s	
3917/5250 (epoch 37.305), train_loss = 0.98150022, grad/param norm = 6.7239e-02, time/batch = 0.1140s	
3918/5250 (epoch 37.314), train_loss = 0.98112354, grad/param norm = 6.7362e-02, time/batch = 0.1135s	
3919/5250 (epoch 37.324), train_loss = 0.99013352, grad/param norm = 6.7473e-02, time/batch = 0.1143s	
3920/5250 (epoch 37.333), train_loss = 0.99530469, grad/param norm = 6.9540e-02, time/batch = 0.1144s	
3921/5250 (epoch 37.343), train_loss = 0.99183288, grad/param norm = 6.4684e-02, time/batch = 0.1150s	
3922/5250 (epoch 37.352), train_loss = 1.00217977, grad/param norm = 6.9234e-02, time/batch = 0.1136s	
3923/5250 (epoch 37.362), train_loss = 0.99612397, grad/param norm = 6.7515e-02, time/batch = 0.1143s	
3924/5250 (epoch 37.371), train_loss = 0.97545221, grad/param norm = 6.4896e-02, time/batch = 0.1141s	
3925/5250 (epoch 37.381), train_loss = 0.98190943, grad/param norm = 6.6118e-02, time/batch = 0.1143s	
3926/5250 (epoch 37.390), train_loss = 0.98457291, grad/param norm = 7.1277e-02, time/batch = 0.1142s	
3927/5250 (epoch 37.400), train_loss = 0.98151925, grad/param norm = 6.6339e-02, time/batch = 0.1143s	
3928/5250 (epoch 37.410), train_loss = 0.98667739, grad/param norm = 6.9029e-02, time/batch = 0.1138s	
3929/5250 (epoch 37.419), train_loss = 0.98981670, grad/param norm = 6.4340e-02, time/batch = 0.1145s	
3930/5250 (epoch 37.429), train_loss = 1.00020675, grad/param norm = 7.1182e-02, time/batch = 0.1143s	
3931/5250 (epoch 37.438), train_loss = 0.99683078, grad/param norm = 6.8548e-02, time/batch = 0.1147s	
3932/5250 (epoch 37.448), train_loss = 0.98358019, grad/param norm = 6.6938e-02, time/batch = 0.1136s	
3933/5250 (epoch 37.457), train_loss = 0.99855493, grad/param norm = 6.8240e-02, time/batch = 0.1140s	
3934/5250 (epoch 37.467), train_loss = 0.99323559, grad/param norm = 6.8050e-02, time/batch = 0.1142s	
3935/5250 (epoch 37.476), train_loss = 0.99223105, grad/param norm = 7.0180e-02, time/batch = 0.1143s	
3936/5250 (epoch 37.486), train_loss = 1.01093789, grad/param norm = 7.3141e-02, time/batch = 0.1142s	
3937/5250 (epoch 37.495), train_loss = 1.00359443, grad/param norm = 6.3231e-02, time/batch = 0.1142s	
3938/5250 (epoch 37.505), train_loss = 1.00570775, grad/param norm = 6.5129e-02, time/batch = 0.1136s	
3939/5250 (epoch 37.514), train_loss = 0.99356213, grad/param norm = 6.4484e-02, time/batch = 0.1143s	
3940/5250 (epoch 37.524), train_loss = 0.99913268, grad/param norm = 6.5883e-02, time/batch = 0.1142s	
3941/5250 (epoch 37.533), train_loss = 1.00305745, grad/param norm = 6.7208e-02, time/batch = 0.1148s	
3942/5250 (epoch 37.543), train_loss = 0.98526948, grad/param norm = 6.4674e-02, time/batch = 0.1138s	
3943/5250 (epoch 37.552), train_loss = 0.99633314, grad/param norm = 6.3707e-02, time/batch = 0.1140s	
3944/5250 (epoch 37.562), train_loss = 0.99527970, grad/param norm = 6.2466e-02, time/batch = 0.1143s	
3945/5250 (epoch 37.571), train_loss = 0.99991538, grad/param norm = 6.6511e-02, time/batch = 0.1142s	
3946/5250 (epoch 37.581), train_loss = 1.00088315, grad/param norm = 6.6860e-02, time/batch = 0.1142s	
3947/5250 (epoch 37.590), train_loss = 0.99644415, grad/param norm = 6.8458e-02, time/batch = 0.1142s	
3948/5250 (epoch 37.600), train_loss = 1.01232093, grad/param norm = 6.8715e-02, time/batch = 0.1138s	
3949/5250 (epoch 37.610), train_loss = 1.00503229, grad/param norm = 6.4132e-02, time/batch = 0.1143s	
3950/5250 (epoch 37.619), train_loss = 0.99844418, grad/param norm = 6.3197e-02, time/batch = 0.1143s	
3951/5250 (epoch 37.629), train_loss = 0.99310817, grad/param norm = 6.7751e-02, time/batch = 0.1147s	
3952/5250 (epoch 37.638), train_loss = 0.99750998, grad/param norm = 6.4019e-02, time/batch = 0.1137s	
3953/5250 (epoch 37.648), train_loss = 1.00640744, grad/param norm = 6.2318e-02, time/batch = 0.1138s	
3954/5250 (epoch 37.657), train_loss = 0.98753298, grad/param norm = 6.2741e-02, time/batch = 0.1142s	
3955/5250 (epoch 37.667), train_loss = 0.99326434, grad/param norm = 6.4371e-02, time/batch = 0.1142s	
3956/5250 (epoch 37.676), train_loss = 0.98572253, grad/param norm = 6.1803e-02, time/batch = 0.1142s	
3957/5250 (epoch 37.686), train_loss = 1.00412336, grad/param norm = 6.6045e-02, time/batch = 0.1142s	
3958/5250 (epoch 37.695), train_loss = 1.00321396, grad/param norm = 6.3607e-02, time/batch = 0.1137s	
3959/5250 (epoch 37.705), train_loss = 0.98162716, grad/param norm = 6.7117e-02, time/batch = 0.1142s	
3960/5250 (epoch 37.714), train_loss = 1.00771020, grad/param norm = 6.4554e-02, time/batch = 0.1143s	
3961/5250 (epoch 37.724), train_loss = 0.99072150, grad/param norm = 7.0402e-02, time/batch = 0.1147s	
3962/5250 (epoch 37.733), train_loss = 0.97973053, grad/param norm = 6.8019e-02, time/batch = 0.1137s	
3963/5250 (epoch 37.743), train_loss = 0.97718806, grad/param norm = 6.3756e-02, time/batch = 0.1139s	
3964/5250 (epoch 37.752), train_loss = 0.97985757, grad/param norm = 6.4037e-02, time/batch = 0.1140s	
3965/5250 (epoch 37.762), train_loss = 0.97758549, grad/param norm = 6.7847e-02, time/batch = 0.1144s	
3966/5250 (epoch 37.771), train_loss = 0.97323339, grad/param norm = 6.2687e-02, time/batch = 0.1142s	
3967/5250 (epoch 37.781), train_loss = 0.99817298, grad/param norm = 6.6934e-02, time/batch = 0.1143s	
3968/5250 (epoch 37.790), train_loss = 0.99823222, grad/param norm = 6.5672e-02, time/batch = 0.1137s	
3969/5250 (epoch 37.800), train_loss = 0.96834986, grad/param norm = 6.2982e-02, time/batch = 0.1141s	
3970/5250 (epoch 37.810), train_loss = 0.99326600, grad/param norm = 6.9458e-02, time/batch = 0.1142s	
3971/5250 (epoch 37.819), train_loss = 1.00171366, grad/param norm = 7.2280e-02, time/batch = 0.1155s	
3972/5250 (epoch 37.829), train_loss = 0.99295859, grad/param norm = 7.0474e-02, time/batch = 0.1139s	
3973/5250 (epoch 37.838), train_loss = 0.96916135, grad/param norm = 6.5140e-02, time/batch = 0.1140s	
3974/5250 (epoch 37.848), train_loss = 0.96315648, grad/param norm = 6.4080e-02, time/batch = 0.1141s	
3975/5250 (epoch 37.857), train_loss = 0.97321149, grad/param norm = 6.6710e-02, time/batch = 0.1144s	
3976/5250 (epoch 37.867), train_loss = 0.98145603, grad/param norm = 7.1695e-02, time/batch = 0.1142s	
3977/5250 (epoch 37.876), train_loss = 0.97241195, grad/param norm = 6.8658e-02, time/batch = 0.1143s	
3978/5250 (epoch 37.886), train_loss = 0.97389321, grad/param norm = 6.9496e-02, time/batch = 0.1137s	
3979/5250 (epoch 37.895), train_loss = 0.99750423, grad/param norm = 7.0771e-02, time/batch = 0.1144s	
3980/5250 (epoch 37.905), train_loss = 0.99252790, grad/param norm = 6.9029e-02, time/batch = 0.1143s	
3981/5250 (epoch 37.914), train_loss = 1.00246635, grad/param norm = 7.4919e-02, time/batch = 0.1155s	
3982/5250 (epoch 37.924), train_loss = 1.00948514, grad/param norm = 6.8368e-02, time/batch = 0.1136s	
3983/5250 (epoch 37.933), train_loss = 0.99749174, grad/param norm = 6.5113e-02, time/batch = 0.1141s	
3984/5250 (epoch 37.943), train_loss = 1.00399902, grad/param norm = 6.5660e-02, time/batch = 0.1143s	
3985/5250 (epoch 37.952), train_loss = 1.01069870, grad/param norm = 6.3771e-02, time/batch = 0.1143s	
3986/5250 (epoch 37.962), train_loss = 0.99446983, grad/param norm = 6.5031e-02, time/batch = 0.1142s	
3987/5250 (epoch 37.971), train_loss = 1.00531439, grad/param norm = 6.2393e-02, time/batch = 0.1144s	
3988/5250 (epoch 37.981), train_loss = 1.00571089, grad/param norm = 6.4469e-02, time/batch = 0.1138s	
3989/5250 (epoch 37.990), train_loss = 1.00770491, grad/param norm = 6.5069e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
3990/5250 (epoch 38.000), train_loss = 0.99259359, grad/param norm = 6.1793e-02, time/batch = 0.1143s	
3991/5250 (epoch 38.010), train_loss = 1.17374775, grad/param norm = 7.0114e-02, time/batch = 0.1148s	
3992/5250 (epoch 38.019), train_loss = 0.98921770, grad/param norm = 6.3485e-02, time/batch = 0.1137s	
3993/5250 (epoch 38.029), train_loss = 1.01158474, grad/param norm = 6.5727e-02, time/batch = 0.1138s	
3994/5250 (epoch 38.038), train_loss = 0.98845217, grad/param norm = 6.4318e-02, time/batch = 0.1143s	
3995/5250 (epoch 38.048), train_loss = 0.96418547, grad/param norm = 6.3355e-02, time/batch = 0.1144s	
3996/5250 (epoch 38.057), train_loss = 0.97216858, grad/param norm = 6.3081e-02, time/batch = 0.1141s	
3997/5250 (epoch 38.067), train_loss = 0.98357449, grad/param norm = 6.4204e-02, time/batch = 0.1141s	
3998/5250 (epoch 38.076), train_loss = 1.00336122, grad/param norm = 6.6586e-02, time/batch = 0.1134s	
3999/5250 (epoch 38.086), train_loss = 0.95705253, grad/param norm = 6.5526e-02, time/batch = 0.1143s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch38.10_1.5723.t7	
4000/5250 (epoch 38.095), train_loss = 0.97111443, grad/param norm = 6.1379e-02, time/batch = 0.1145s	
4001/5250 (epoch 38.105), train_loss = 1.44655582, grad/param norm = 9.1706e-02, time/batch = 0.1155s	
4002/5250 (epoch 38.114), train_loss = 0.98453676, grad/param norm = 6.9288e-02, time/batch = 0.1139s	
4003/5250 (epoch 38.124), train_loss = 1.00153760, grad/param norm = 6.9480e-02, time/batch = 0.1139s	
4004/5250 (epoch 38.133), train_loss = 0.98447166, grad/param norm = 6.3913e-02, time/batch = 0.1143s	
4005/5250 (epoch 38.143), train_loss = 0.96016213, grad/param norm = 6.3170e-02, time/batch = 0.1145s	
4006/5250 (epoch 38.152), train_loss = 0.96568942, grad/param norm = 6.9809e-02, time/batch = 0.1142s	
4007/5250 (epoch 38.162), train_loss = 0.98844612, grad/param norm = 6.6499e-02, time/batch = 0.1141s	
4008/5250 (epoch 38.171), train_loss = 0.98699924, grad/param norm = 6.9097e-02, time/batch = 0.1139s	
4009/5250 (epoch 38.181), train_loss = 0.98329653, grad/param norm = 6.9162e-02, time/batch = 0.1143s	
4010/5250 (epoch 38.190), train_loss = 0.98079893, grad/param norm = 6.5166e-02, time/batch = 0.1145s	
4011/5250 (epoch 38.200), train_loss = 0.98578131, grad/param norm = 7.2942e-02, time/batch = 0.1149s	
4012/5250 (epoch 38.210), train_loss = 0.99219698, grad/param norm = 6.6091e-02, time/batch = 0.1137s	
4013/5250 (epoch 38.219), train_loss = 1.02161008, grad/param norm = 6.8145e-02, time/batch = 0.1139s	
4014/5250 (epoch 38.229), train_loss = 0.98872380, grad/param norm = 6.5372e-02, time/batch = 0.1140s	
4015/5250 (epoch 38.238), train_loss = 0.98348804, grad/param norm = 7.0998e-02, time/batch = 0.1143s	
4016/5250 (epoch 38.248), train_loss = 0.98535640, grad/param norm = 6.2521e-02, time/batch = 0.1140s	
4017/5250 (epoch 38.257), train_loss = 0.98823641, grad/param norm = 6.5216e-02, time/batch = 0.1141s	
4018/5250 (epoch 38.267), train_loss = 0.98320249, grad/param norm = 6.6626e-02, time/batch = 0.1137s	
4019/5250 (epoch 38.276), train_loss = 0.97011379, grad/param norm = 6.8600e-02, time/batch = 0.1143s	
4020/5250 (epoch 38.286), train_loss = 0.94718793, grad/param norm = 6.3927e-02, time/batch = 0.1146s	
4021/5250 (epoch 38.295), train_loss = 0.97666417, grad/param norm = 6.6006e-02, time/batch = 0.1149s	
4022/5250 (epoch 38.305), train_loss = 0.97322399, grad/param norm = 6.8277e-02, time/batch = 0.1136s	
4023/5250 (epoch 38.314), train_loss = 0.97214207, grad/param norm = 6.4857e-02, time/batch = 0.1138s	
4024/5250 (epoch 38.324), train_loss = 0.98175869, grad/param norm = 6.4746e-02, time/batch = 0.1141s	
4025/5250 (epoch 38.333), train_loss = 0.98648571, grad/param norm = 6.6911e-02, time/batch = 0.1141s	
4026/5250 (epoch 38.343), train_loss = 0.98304621, grad/param norm = 6.4144e-02, time/batch = 0.1141s	
4027/5250 (epoch 38.352), train_loss = 0.99221544, grad/param norm = 6.2945e-02, time/batch = 0.1142s	
4028/5250 (epoch 38.362), train_loss = 0.98583927, grad/param norm = 6.3075e-02, time/batch = 0.1138s	
4029/5250 (epoch 38.371), train_loss = 0.96695909, grad/param norm = 6.5882e-02, time/batch = 0.1142s	
4030/5250 (epoch 38.381), train_loss = 0.97407407, grad/param norm = 6.5667e-02, time/batch = 0.1143s	
4031/5250 (epoch 38.390), train_loss = 0.97586680, grad/param norm = 6.6524e-02, time/batch = 0.1149s	
4032/5250 (epoch 38.400), train_loss = 0.97365468, grad/param norm = 6.7644e-02, time/batch = 0.1139s	
4033/5250 (epoch 38.410), train_loss = 0.97900074, grad/param norm = 6.8712e-02, time/batch = 0.1140s	
4034/5250 (epoch 38.419), train_loss = 0.98285690, grad/param norm = 7.2590e-02, time/batch = 0.1140s	
4035/5250 (epoch 38.429), train_loss = 0.99032654, grad/param norm = 6.8576e-02, time/batch = 0.1144s	
4036/5250 (epoch 38.438), train_loss = 0.98647573, grad/param norm = 6.7479e-02, time/batch = 0.1140s	
4037/5250 (epoch 38.448), train_loss = 0.97715161, grad/param norm = 6.9927e-02, time/batch = 0.1142s	
4038/5250 (epoch 38.457), train_loss = 0.99090105, grad/param norm = 6.9742e-02, time/batch = 0.1137s	
4039/5250 (epoch 38.467), train_loss = 0.98581122, grad/param norm = 6.4065e-02, time/batch = 0.1142s	
4040/5250 (epoch 38.476), train_loss = 0.98255026, grad/param norm = 7.0416e-02, time/batch = 0.1145s	
4041/5250 (epoch 38.486), train_loss = 1.00329360, grad/param norm = 6.8836e-02, time/batch = 0.1149s	
4042/5250 (epoch 38.495), train_loss = 0.99589639, grad/param norm = 6.7721e-02, time/batch = 0.1137s	
4043/5250 (epoch 38.505), train_loss = 1.00002604, grad/param norm = 6.7399e-02, time/batch = 0.1139s	
4044/5250 (epoch 38.514), train_loss = 0.98556262, grad/param norm = 6.3662e-02, time/batch = 0.1141s	
4045/5250 (epoch 38.524), train_loss = 0.98970555, grad/param norm = 6.4388e-02, time/batch = 0.1141s	
4046/5250 (epoch 38.533), train_loss = 0.99470209, grad/param norm = 6.5025e-02, time/batch = 0.1142s	
4047/5250 (epoch 38.543), train_loss = 0.97863460, grad/param norm = 6.7886e-02, time/batch = 0.1143s	
4048/5250 (epoch 38.552), train_loss = 0.98878290, grad/param norm = 6.4713e-02, time/batch = 0.1138s	
4049/5250 (epoch 38.562), train_loss = 0.98863129, grad/param norm = 6.4528e-02, time/batch = 0.1143s	
4050/5250 (epoch 38.571), train_loss = 0.99332488, grad/param norm = 6.8322e-02, time/batch = 0.1143s	
4051/5250 (epoch 38.581), train_loss = 0.99253457, grad/param norm = 6.5683e-02, time/batch = 0.1147s	
4052/5250 (epoch 38.590), train_loss = 0.98676519, grad/param norm = 6.5281e-02, time/batch = 0.1136s	
4053/5250 (epoch 38.600), train_loss = 1.00447552, grad/param norm = 6.9121e-02, time/batch = 0.1139s	
4054/5250 (epoch 38.610), train_loss = 0.99832696, grad/param norm = 6.9345e-02, time/batch = 0.1141s	
4055/5250 (epoch 38.619), train_loss = 0.99090829, grad/param norm = 6.3782e-02, time/batch = 0.1142s	
4056/5250 (epoch 38.629), train_loss = 0.98424501, grad/param norm = 6.4601e-02, time/batch = 0.1140s	
4057/5250 (epoch 38.638), train_loss = 0.99035499, grad/param norm = 6.5570e-02, time/batch = 0.1142s	
4058/5250 (epoch 38.648), train_loss = 0.99970994, grad/param norm = 6.2667e-02, time/batch = 0.1137s	
4059/5250 (epoch 38.657), train_loss = 0.98036844, grad/param norm = 6.5762e-02, time/batch = 0.1142s	
4060/5250 (epoch 38.667), train_loss = 0.98650704, grad/param norm = 6.6363e-02, time/batch = 0.1144s	
4061/5250 (epoch 38.676), train_loss = 0.97914766, grad/param norm = 6.3777e-02, time/batch = 0.1150s	
4062/5250 (epoch 38.686), train_loss = 0.99640258, grad/param norm = 6.7515e-02, time/batch = 0.1137s	
4063/5250 (epoch 38.695), train_loss = 0.99704170, grad/param norm = 6.8825e-02, time/batch = 0.1140s	
4064/5250 (epoch 38.705), train_loss = 0.97428514, grad/param norm = 7.0065e-02, time/batch = 0.1142s	
4065/5250 (epoch 38.714), train_loss = 1.00152540, grad/param norm = 7.1214e-02, time/batch = 0.1142s	
4066/5250 (epoch 38.724), train_loss = 0.98113182, grad/param norm = 6.7136e-02, time/batch = 0.1142s	
4067/5250 (epoch 38.733), train_loss = 0.96955142, grad/param norm = 6.2879e-02, time/batch = 0.1143s	
4068/5250 (epoch 38.743), train_loss = 0.97438609, grad/param norm = 7.1998e-02, time/batch = 0.1136s	
4069/5250 (epoch 38.752), train_loss = 0.97245899, grad/param norm = 7.1633e-02, time/batch = 0.1142s	
4070/5250 (epoch 38.762), train_loss = 0.97177508, grad/param norm = 6.8742e-02, time/batch = 0.1142s	
4071/5250 (epoch 38.771), train_loss = 0.96678929, grad/param norm = 6.5662e-02, time/batch = 0.1150s	
4072/5250 (epoch 38.781), train_loss = 0.99055546, grad/param norm = 6.5438e-02, time/batch = 0.1136s	
4073/5250 (epoch 38.790), train_loss = 0.99085846, grad/param norm = 6.5713e-02, time/batch = 0.1140s	
4074/5250 (epoch 38.800), train_loss = 0.96282831, grad/param norm = 6.7400e-02, time/batch = 0.1141s	
4075/5250 (epoch 38.810), train_loss = 0.98672894, grad/param norm = 7.2961e-02, time/batch = 0.1141s	
4076/5250 (epoch 38.819), train_loss = 0.99306058, grad/param norm = 6.6772e-02, time/batch = 0.1141s	
4077/5250 (epoch 38.829), train_loss = 0.98400765, grad/param norm = 6.8446e-02, time/batch = 0.1142s	
4078/5250 (epoch 38.838), train_loss = 0.96247252, grad/param norm = 7.1195e-02, time/batch = 0.1136s	
4079/5250 (epoch 38.848), train_loss = 0.95794319, grad/param norm = 7.1642e-02, time/batch = 0.1143s	
4080/5250 (epoch 38.857), train_loss = 0.96813861, grad/param norm = 7.0450e-02, time/batch = 0.1142s	
4081/5250 (epoch 38.867), train_loss = 0.97309705, grad/param norm = 7.1055e-02, time/batch = 0.1149s	
4082/5250 (epoch 38.876), train_loss = 0.96431868, grad/param norm = 6.6964e-02, time/batch = 0.1138s	
4083/5250 (epoch 38.886), train_loss = 0.96603574, grad/param norm = 7.2006e-02, time/batch = 0.1140s	
4084/5250 (epoch 38.895), train_loss = 0.99134922, grad/param norm = 7.2317e-02, time/batch = 0.1141s	
4085/5250 (epoch 38.905), train_loss = 0.98281813, grad/param norm = 6.7400e-02, time/batch = 0.1144s	
4086/5250 (epoch 38.914), train_loss = 0.99256965, grad/param norm = 6.6993e-02, time/batch = 0.1142s	
4087/5250 (epoch 38.924), train_loss = 1.00042375, grad/param norm = 6.8260e-02, time/batch = 0.1140s	
4088/5250 (epoch 38.933), train_loss = 0.98925649, grad/param norm = 6.6483e-02, time/batch = 0.1136s	
4089/5250 (epoch 38.943), train_loss = 0.99860860, grad/param norm = 7.2512e-02, time/batch = 0.1143s	
4090/5250 (epoch 38.952), train_loss = 1.00416131, grad/param norm = 6.7957e-02, time/batch = 0.1144s	
4091/5250 (epoch 38.962), train_loss = 0.98848422, grad/param norm = 7.0211e-02, time/batch = 0.1146s	
4092/5250 (epoch 38.971), train_loss = 0.99890747, grad/param norm = 6.2390e-02, time/batch = 0.1137s	
4093/5250 (epoch 38.981), train_loss = 0.99658846, grad/param norm = 6.5943e-02, time/batch = 0.1139s	
4094/5250 (epoch 38.990), train_loss = 1.00095262, grad/param norm = 6.6724e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
4095/5250 (epoch 39.000), train_loss = 0.98576759, grad/param norm = 6.4304e-02, time/batch = 0.1141s	
4096/5250 (epoch 39.010), train_loss = 1.16787686, grad/param norm = 7.3444e-02, time/batch = 0.1142s	
4097/5250 (epoch 39.019), train_loss = 0.98222094, grad/param norm = 6.6876e-02, time/batch = 0.1142s	
4098/5250 (epoch 39.029), train_loss = 1.00399468, grad/param norm = 6.6151e-02, time/batch = 0.1135s	
4099/5250 (epoch 39.038), train_loss = 0.98156797, grad/param norm = 6.4548e-02, time/batch = 0.1143s	
4100/5250 (epoch 39.048), train_loss = 0.95640405, grad/param norm = 6.2967e-02, time/batch = 0.1142s	
4101/5250 (epoch 39.057), train_loss = 0.96444476, grad/param norm = 6.5576e-02, time/batch = 0.1146s	
4102/5250 (epoch 39.067), train_loss = 0.97691814, grad/param norm = 6.5569e-02, time/batch = 0.1135s	
4103/5250 (epoch 39.076), train_loss = 0.99560515, grad/param norm = 6.4705e-02, time/batch = 0.1138s	
4104/5250 (epoch 39.086), train_loss = 0.94978914, grad/param norm = 6.4158e-02, time/batch = 0.1142s	
4105/5250 (epoch 39.095), train_loss = 0.96374588, grad/param norm = 6.2690e-02, time/batch = 0.1141s	
4106/5250 (epoch 39.105), train_loss = 0.99932911, grad/param norm = 6.6709e-02, time/batch = 0.1142s	
4107/5250 (epoch 39.114), train_loss = 0.96664373, grad/param norm = 6.4009e-02, time/batch = 0.1142s	
4108/5250 (epoch 39.124), train_loss = 0.99283797, grad/param norm = 6.4732e-02, time/batch = 0.1136s	
4109/5250 (epoch 39.133), train_loss = 0.97401729, grad/param norm = 6.3851e-02, time/batch = 0.1143s	
4110/5250 (epoch 39.143), train_loss = 0.95365787, grad/param norm = 6.5452e-02, time/batch = 0.1144s	
4111/5250 (epoch 39.152), train_loss = 0.95675649, grad/param norm = 6.8358e-02, time/batch = 0.1148s	
4112/5250 (epoch 39.162), train_loss = 0.98006190, grad/param norm = 6.6153e-02, time/batch = 0.1137s	
4113/5250 (epoch 39.171), train_loss = 0.97947345, grad/param norm = 6.4683e-02, time/batch = 0.1140s	
4114/5250 (epoch 39.181), train_loss = 0.97647742, grad/param norm = 7.0163e-02, time/batch = 0.1141s	
4115/5250 (epoch 39.190), train_loss = 0.97252934, grad/param norm = 6.8123e-02, time/batch = 0.1141s	
4116/5250 (epoch 39.200), train_loss = 0.97658095, grad/param norm = 6.9031e-02, time/batch = 0.1140s	
4117/5250 (epoch 39.210), train_loss = 0.98466461, grad/param norm = 6.7504e-02, time/batch = 0.1141s	
4118/5250 (epoch 39.219), train_loss = 1.01798068, grad/param norm = 7.3482e-02, time/batch = 0.1137s	
4119/5250 (epoch 39.229), train_loss = 0.98063334, grad/param norm = 6.4784e-02, time/batch = 0.1143s	
4120/5250 (epoch 39.238), train_loss = 0.97590827, grad/param norm = 6.8205e-02, time/batch = 0.1145s	
4121/5250 (epoch 39.248), train_loss = 0.98143569, grad/param norm = 7.1903e-02, time/batch = 0.1148s	
4122/5250 (epoch 39.257), train_loss = 0.98254701, grad/param norm = 6.7306e-02, time/batch = 0.1138s	
4123/5250 (epoch 39.267), train_loss = 0.97416535, grad/param norm = 6.5302e-02, time/batch = 0.1138s	
4124/5250 (epoch 39.276), train_loss = 0.96435960, grad/param norm = 7.6241e-02, time/batch = 0.1141s	
4125/5250 (epoch 39.286), train_loss = 0.94166727, grad/param norm = 7.2957e-02, time/batch = 0.1141s	
4126/5250 (epoch 39.295), train_loss = 0.96999453, grad/param norm = 6.5180e-02, time/batch = 0.1140s	
4127/5250 (epoch 39.305), train_loss = 0.96711147, grad/param norm = 7.0430e-02, time/batch = 0.1143s	
4128/5250 (epoch 39.314), train_loss = 0.96649432, grad/param norm = 6.7792e-02, time/batch = 0.1137s	
4129/5250 (epoch 39.324), train_loss = 0.97673768, grad/param norm = 6.9404e-02, time/batch = 0.1143s	
4130/5250 (epoch 39.333), train_loss = 0.97987853, grad/param norm = 6.6419e-02, time/batch = 0.1143s	
4131/5250 (epoch 39.343), train_loss = 0.97597214, grad/param norm = 6.6964e-02, time/batch = 0.1149s	
4132/5250 (epoch 39.352), train_loss = 0.98607621, grad/param norm = 6.5420e-02, time/batch = 0.1136s	
4133/5250 (epoch 39.362), train_loss = 0.97915064, grad/param norm = 6.3309e-02, time/batch = 0.1139s	
4134/5250 (epoch 39.371), train_loss = 0.95901282, grad/param norm = 6.4520e-02, time/batch = 0.1142s	
4135/5250 (epoch 39.381), train_loss = 0.96664265, grad/param norm = 6.3984e-02, time/batch = 0.1142s	
4136/5250 (epoch 39.390), train_loss = 0.96799239, grad/param norm = 6.6874e-02, time/batch = 0.1142s	
4137/5250 (epoch 39.400), train_loss = 0.96441161, grad/param norm = 6.3760e-02, time/batch = 0.1141s	
4138/5250 (epoch 39.410), train_loss = 0.96943834, grad/param norm = 6.6488e-02, time/batch = 0.1138s	
4139/5250 (epoch 39.419), train_loss = 0.97239796, grad/param norm = 6.3908e-02, time/batch = 0.1143s	
4140/5250 (epoch 39.429), train_loss = 0.98278063, grad/param norm = 6.9100e-02, time/batch = 0.1142s	
4141/5250 (epoch 39.438), train_loss = 0.97962414, grad/param norm = 6.8287e-02, time/batch = 0.1148s	
4142/5250 (epoch 39.448), train_loss = 0.96835120, grad/param norm = 6.8451e-02, time/batch = 0.1137s	
4143/5250 (epoch 39.457), train_loss = 0.98466226, grad/param norm = 7.0411e-02, time/batch = 0.1138s	
4144/5250 (epoch 39.467), train_loss = 0.97927996, grad/param norm = 7.0493e-02, time/batch = 0.1140s	
4145/5250 (epoch 39.476), train_loss = 0.97751945, grad/param norm = 7.3220e-02, time/batch = 0.1140s	
4146/5250 (epoch 39.486), train_loss = 0.99554300, grad/param norm = 7.2467e-02, time/batch = 0.1143s	
4147/5250 (epoch 39.495), train_loss = 0.98796407, grad/param norm = 6.4993e-02, time/batch = 0.1142s	
4148/5250 (epoch 39.505), train_loss = 0.99110923, grad/param norm = 6.7370e-02, time/batch = 0.1138s	
4149/5250 (epoch 39.514), train_loss = 0.97905979, grad/param norm = 6.5955e-02, time/batch = 0.1142s	
4150/5250 (epoch 39.524), train_loss = 0.98227825, grad/param norm = 6.6114e-02, time/batch = 0.1143s	
4151/5250 (epoch 39.533), train_loss = 0.98751782, grad/param norm = 6.5561e-02, time/batch = 0.1148s	
4152/5250 (epoch 39.543), train_loss = 0.97021835, grad/param norm = 6.7466e-02, time/batch = 0.1136s	
4153/5250 (epoch 39.552), train_loss = 0.98277035, grad/param norm = 6.5313e-02, time/batch = 0.1140s	
4154/5250 (epoch 39.562), train_loss = 0.98101895, grad/param norm = 6.3094e-02, time/batch = 0.1141s	
4155/5250 (epoch 39.571), train_loss = 0.98482543, grad/param norm = 6.7364e-02, time/batch = 0.1142s	
4156/5250 (epoch 39.581), train_loss = 0.98423589, grad/param norm = 6.9033e-02, time/batch = 0.1142s	
4157/5250 (epoch 39.590), train_loss = 0.98077045, grad/param norm = 6.9819e-02, time/batch = 0.1144s	
4158/5250 (epoch 39.600), train_loss = 0.99636789, grad/param norm = 6.8847e-02, time/batch = 0.1137s	
4159/5250 (epoch 39.610), train_loss = 0.98914302, grad/param norm = 6.5200e-02, time/batch = 0.1143s	
4160/5250 (epoch 39.619), train_loss = 0.98474486, grad/param norm = 6.5542e-02, time/batch = 0.1143s	
4161/5250 (epoch 39.629), train_loss = 0.97862053, grad/param norm = 7.0922e-02, time/batch = 0.1148s	
4162/5250 (epoch 39.638), train_loss = 0.98317269, grad/param norm = 6.6320e-02, time/batch = 0.1136s	
4163/5250 (epoch 39.648), train_loss = 0.99300522, grad/param norm = 6.3095e-02, time/batch = 0.1141s	
4164/5250 (epoch 39.657), train_loss = 0.97214110, grad/param norm = 6.4748e-02, time/batch = 0.1143s	
4165/5250 (epoch 39.667), train_loss = 0.97689593, grad/param norm = 6.5452e-02, time/batch = 0.1142s	
4166/5250 (epoch 39.676), train_loss = 0.97115163, grad/param norm = 6.5093e-02, time/batch = 0.1143s	
4167/5250 (epoch 39.686), train_loss = 0.98922001, grad/param norm = 6.9149e-02, time/batch = 0.1143s	
4168/5250 (epoch 39.695), train_loss = 0.98944966, grad/param norm = 6.7832e-02, time/batch = 0.1137s	
4169/5250 (epoch 39.705), train_loss = 0.96783219, grad/param norm = 7.2193e-02, time/batch = 0.1144s	
4170/5250 (epoch 39.714), train_loss = 0.99337078, grad/param norm = 7.0090e-02, time/batch = 0.1145s	
4171/5250 (epoch 39.724), train_loss = 0.97806633, grad/param norm = 7.4319e-02, time/batch = 0.1148s	
4172/5250 (epoch 39.733), train_loss = 0.96422247, grad/param norm = 7.0078e-02, time/batch = 0.1138s	
4173/5250 (epoch 39.743), train_loss = 0.96363655, grad/param norm = 6.6678e-02, time/batch = 0.1138s	
4174/5250 (epoch 39.752), train_loss = 0.96322180, grad/param norm = 6.5572e-02, time/batch = 0.1141s	
4175/5250 (epoch 39.762), train_loss = 0.96638192, grad/param norm = 7.5538e-02, time/batch = 0.1141s	
4176/5250 (epoch 39.771), train_loss = 0.96327927, grad/param norm = 7.1720e-02, time/batch = 0.1141s	
4177/5250 (epoch 39.781), train_loss = 0.98503031, grad/param norm = 7.4746e-02, time/batch = 0.1143s	
4178/5250 (epoch 39.790), train_loss = 0.98631598, grad/param norm = 6.8593e-02, time/batch = 0.1138s	
4179/5250 (epoch 39.800), train_loss = 0.95442072, grad/param norm = 6.9052e-02, time/batch = 0.1142s	
4180/5250 (epoch 39.810), train_loss = 0.97935991, grad/param norm = 7.0929e-02, time/batch = 0.1145s	
4181/5250 (epoch 39.819), train_loss = 0.98606863, grad/param norm = 7.2877e-02, time/batch = 0.1147s	
4182/5250 (epoch 39.829), train_loss = 0.97781404, grad/param norm = 6.9573e-02, time/batch = 0.1138s	
4183/5250 (epoch 39.838), train_loss = 0.95548025, grad/param norm = 7.4634e-02, time/batch = 0.1139s	
4184/5250 (epoch 39.848), train_loss = 0.95218354, grad/param norm = 7.1326e-02, time/batch = 0.1140s	
4185/5250 (epoch 39.857), train_loss = 0.96177856, grad/param norm = 7.0920e-02, time/batch = 0.1143s	
4186/5250 (epoch 39.867), train_loss = 0.96551171, grad/param norm = 7.2581e-02, time/batch = 0.1140s	
4187/5250 (epoch 39.876), train_loss = 0.95629858, grad/param norm = 7.0741e-02, time/batch = 0.1142s	
4188/5250 (epoch 39.886), train_loss = 0.96023092, grad/param norm = 7.3794e-02, time/batch = 0.1137s	
4189/5250 (epoch 39.895), train_loss = 0.98126074, grad/param norm = 6.9640e-02, time/batch = 0.1143s	
4190/5250 (epoch 39.905), train_loss = 0.97636055, grad/param norm = 6.7273e-02, time/batch = 0.1142s	
4191/5250 (epoch 39.914), train_loss = 0.98545293, grad/param norm = 6.9250e-02, time/batch = 0.1148s	
4192/5250 (epoch 39.924), train_loss = 0.99264156, grad/param norm = 6.5437e-02, time/batch = 0.1137s	
4193/5250 (epoch 39.933), train_loss = 0.98022444, grad/param norm = 6.4405e-02, time/batch = 0.1141s	
4194/5250 (epoch 39.943), train_loss = 0.98970228, grad/param norm = 6.9850e-02, time/batch = 0.1142s	
4195/5250 (epoch 39.952), train_loss = 0.99596490, grad/param norm = 6.6152e-02, time/batch = 0.1142s	
4196/5250 (epoch 39.962), train_loss = 0.98082262, grad/param norm = 6.7172e-02, time/batch = 0.1143s	
4197/5250 (epoch 39.971), train_loss = 0.99014805, grad/param norm = 6.6420e-02, time/batch = 0.1143s	
4198/5250 (epoch 39.981), train_loss = 0.99031029, grad/param norm = 6.7367e-02, time/batch = 0.1137s	
4199/5250 (epoch 39.990), train_loss = 0.99393927, grad/param norm = 6.6339e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
4200/5250 (epoch 40.000), train_loss = 0.97850085, grad/param norm = 6.3307e-02, time/batch = 0.1143s	
4201/5250 (epoch 40.010), train_loss = 1.16003497, grad/param norm = 7.2079e-02, time/batch = 0.1149s	
4202/5250 (epoch 40.019), train_loss = 0.97504946, grad/param norm = 6.5802e-02, time/batch = 0.1135s	
4203/5250 (epoch 40.029), train_loss = 0.99636038, grad/param norm = 6.9074e-02, time/batch = 0.1141s	
4204/5250 (epoch 40.038), train_loss = 0.97509687, grad/param norm = 6.6464e-02, time/batch = 0.1139s	
4205/5250 (epoch 40.048), train_loss = 0.94923240, grad/param norm = 6.4628e-02, time/batch = 0.1143s	
4206/5250 (epoch 40.057), train_loss = 0.95770395, grad/param norm = 6.4639e-02, time/batch = 0.1142s	
4207/5250 (epoch 40.067), train_loss = 0.96898905, grad/param norm = 6.6172e-02, time/batch = 0.1142s	
4208/5250 (epoch 40.076), train_loss = 0.98887249, grad/param norm = 6.6259e-02, time/batch = 0.1137s	
4209/5250 (epoch 40.086), train_loss = 0.94267310, grad/param norm = 6.5221e-02, time/batch = 0.1143s	
4210/5250 (epoch 40.095), train_loss = 0.95789855, grad/param norm = 6.3275e-02, time/batch = 0.1144s	
4211/5250 (epoch 40.105), train_loss = 0.98966011, grad/param norm = 6.6969e-02, time/batch = 0.1149s	
4212/5250 (epoch 40.114), train_loss = 0.95934410, grad/param norm = 6.5447e-02, time/batch = 0.1137s	
4213/5250 (epoch 40.124), train_loss = 0.98671560, grad/param norm = 6.6006e-02, time/batch = 0.1141s	
4214/5250 (epoch 40.133), train_loss = 0.96671088, grad/param norm = 6.4736e-02, time/batch = 0.1142s	
4215/5250 (epoch 40.143), train_loss = 0.94580353, grad/param norm = 6.4606e-02, time/batch = 0.1143s	
4216/5250 (epoch 40.152), train_loss = 0.94911139, grad/param norm = 6.8305e-02, time/batch = 0.1142s	
4217/5250 (epoch 40.162), train_loss = 0.97272508, grad/param norm = 6.9716e-02, time/batch = 0.1144s	
4218/5250 (epoch 40.171), train_loss = 0.97229791, grad/param norm = 6.5210e-02, time/batch = 0.1136s	
4219/5250 (epoch 40.181), train_loss = 0.96796491, grad/param norm = 6.7933e-02, time/batch = 0.1144s	
4220/5250 (epoch 40.190), train_loss = 0.96521170, grad/param norm = 6.6876e-02, time/batch = 0.1144s	
4221/5250 (epoch 40.200), train_loss = 0.97036020, grad/param norm = 7.3044e-02, time/batch = 0.1148s	
4222/5250 (epoch 40.210), train_loss = 0.97792166, grad/param norm = 6.6924e-02, time/batch = 0.1139s	
4223/5250 (epoch 40.219), train_loss = 1.00905998, grad/param norm = 7.2663e-02, time/batch = 0.1138s	
4224/5250 (epoch 40.229), train_loss = 0.97457810, grad/param norm = 6.7720e-02, time/batch = 0.1141s	
4225/5250 (epoch 40.238), train_loss = 0.96795780, grad/param norm = 7.1412e-02, time/batch = 0.1141s	
4226/5250 (epoch 40.248), train_loss = 0.97143386, grad/param norm = 6.4056e-02, time/batch = 0.1140s	
4227/5250 (epoch 40.257), train_loss = 0.97314389, grad/param norm = 6.6804e-02, time/batch = 0.1143s	
4228/5250 (epoch 40.267), train_loss = 0.97027157, grad/param norm = 6.8979e-02, time/batch = 0.1137s	
4229/5250 (epoch 40.276), train_loss = 0.95611948, grad/param norm = 7.0066e-02, time/batch = 0.1144s	
4230/5250 (epoch 40.286), train_loss = 0.93284226, grad/param norm = 6.5876e-02, time/batch = 0.1145s	
4231/5250 (epoch 40.295), train_loss = 0.96400684, grad/param norm = 7.4333e-02, time/batch = 0.1153s	
4232/5250 (epoch 40.305), train_loss = 0.96150439, grad/param norm = 7.2968e-02, time/batch = 0.1136s	
4233/5250 (epoch 40.314), train_loss = 0.95953790, grad/param norm = 6.9006e-02, time/batch = 0.1140s	
4234/5250 (epoch 40.324), train_loss = 0.96828757, grad/param norm = 6.7239e-02, time/batch = 0.1141s	
4235/5250 (epoch 40.333), train_loss = 0.97326597, grad/param norm = 7.2372e-02, time/batch = 0.1144s	
4236/5250 (epoch 40.343), train_loss = 0.96982538, grad/param norm = 6.5785e-02, time/batch = 0.1142s	
4237/5250 (epoch 40.352), train_loss = 0.98029854, grad/param norm = 6.8817e-02, time/batch = 0.1143s	
4238/5250 (epoch 40.362), train_loss = 0.97385671, grad/param norm = 6.6529e-02, time/batch = 0.1140s	
4239/5250 (epoch 40.371), train_loss = 0.95301503, grad/param norm = 6.5492e-02, time/batch = 0.1142s	
4240/5250 (epoch 40.381), train_loss = 0.96044519, grad/param norm = 6.6984e-02, time/batch = 0.1143s	
4241/5250 (epoch 40.390), train_loss = 0.96274660, grad/param norm = 6.8554e-02, time/batch = 0.1149s	
4242/5250 (epoch 40.400), train_loss = 0.95684838, grad/param norm = 6.4876e-02, time/batch = 0.1138s	
4243/5250 (epoch 40.410), train_loss = 0.96210756, grad/param norm = 6.5878e-02, time/batch = 0.1140s	
4244/5250 (epoch 40.419), train_loss = 0.96546089, grad/param norm = 6.5384e-02, time/batch = 0.1141s	
4245/5250 (epoch 40.429), train_loss = 0.97481085, grad/param norm = 6.8048e-02, time/batch = 0.1144s	
4246/5250 (epoch 40.438), train_loss = 0.97018592, grad/param norm = 6.4340e-02, time/batch = 0.1142s	
4247/5250 (epoch 40.448), train_loss = 0.95950399, grad/param norm = 6.7571e-02, time/batch = 0.1143s	
4248/5250 (epoch 40.457), train_loss = 0.97674977, grad/param norm = 7.0516e-02, time/batch = 0.1138s	
4249/5250 (epoch 40.467), train_loss = 0.97143408, grad/param norm = 6.5645e-02, time/batch = 0.1144s	
4250/5250 (epoch 40.476), train_loss = 0.96746200, grad/param norm = 7.0997e-02, time/batch = 0.1145s	
4251/5250 (epoch 40.486), train_loss = 0.98890076, grad/param norm = 7.0194e-02, time/batch = 0.1148s	
4252/5250 (epoch 40.495), train_loss = 0.98047785, grad/param norm = 6.8854e-02, time/batch = 0.1135s	
4253/5250 (epoch 40.505), train_loss = 0.98535766, grad/param norm = 6.8097e-02, time/batch = 0.1141s	
4254/5250 (epoch 40.514), train_loss = 0.97165197, grad/param norm = 6.6669e-02, time/batch = 0.1139s	
4255/5250 (epoch 40.524), train_loss = 0.97542338, grad/param norm = 6.6379e-02, time/batch = 0.1142s	
4256/5250 (epoch 40.533), train_loss = 0.98059899, grad/param norm = 6.8520e-02, time/batch = 0.1144s	
4257/5250 (epoch 40.543), train_loss = 0.96409438, grad/param norm = 6.8090e-02, time/batch = 0.1142s	
4258/5250 (epoch 40.552), train_loss = 0.97432770, grad/param norm = 6.5957e-02, time/batch = 0.1138s	
4259/5250 (epoch 40.562), train_loss = 0.97550528, grad/param norm = 6.6164e-02, time/batch = 0.1143s	
4260/5250 (epoch 40.571), train_loss = 0.97894609, grad/param norm = 7.0732e-02, time/batch = 0.1143s	
4261/5250 (epoch 40.581), train_loss = 0.97633097, grad/param norm = 6.7614e-02, time/batch = 0.1147s	
4262/5250 (epoch 40.590), train_loss = 0.97115268, grad/param norm = 6.5775e-02, time/batch = 0.1138s	
4263/5250 (epoch 40.600), train_loss = 0.98938600, grad/param norm = 6.9336e-02, time/batch = 0.1140s	
4264/5250 (epoch 40.610), train_loss = 0.98368239, grad/param norm = 7.1869e-02, time/batch = 0.1141s	
4265/5250 (epoch 40.619), train_loss = 0.97751395, grad/param norm = 6.5202e-02, time/batch = 0.1142s	
4266/5250 (epoch 40.629), train_loss = 0.96944532, grad/param norm = 6.6604e-02, time/batch = 0.1141s	
4267/5250 (epoch 40.638), train_loss = 0.97713216, grad/param norm = 6.7470e-02, time/batch = 0.1141s	
4268/5250 (epoch 40.648), train_loss = 0.98658728, grad/param norm = 6.5484e-02, time/batch = 0.1136s	
4269/5250 (epoch 40.657), train_loss = 0.96648745, grad/param norm = 6.9449e-02, time/batch = 0.1142s	
4270/5250 (epoch 40.667), train_loss = 0.96943662, grad/param norm = 6.6509e-02, time/batch = 0.1145s	
4271/5250 (epoch 40.676), train_loss = 0.96427938, grad/param norm = 6.3932e-02, time/batch = 0.1149s	
4272/5250 (epoch 40.686), train_loss = 0.98123600, grad/param norm = 6.9020e-02, time/batch = 0.1136s	
4273/5250 (epoch 40.695), train_loss = 0.98318418, grad/param norm = 6.8603e-02, time/batch = 0.1139s	
4274/5250 (epoch 40.705), train_loss = 0.95876107, grad/param norm = 6.8712e-02, time/batch = 0.1141s	
4275/5250 (epoch 40.714), train_loss = 0.98535932, grad/param norm = 7.0913e-02, time/batch = 0.1142s	
4276/5250 (epoch 40.724), train_loss = 0.96821546, grad/param norm = 7.0843e-02, time/batch = 0.1143s	
4277/5250 (epoch 40.733), train_loss = 0.95667936, grad/param norm = 6.6127e-02, time/batch = 0.1142s	
4278/5250 (epoch 40.743), train_loss = 0.95996638, grad/param norm = 7.3585e-02, time/batch = 0.1137s	
4279/5250 (epoch 40.752), train_loss = 0.95689536, grad/param norm = 6.9895e-02, time/batch = 0.1142s	
4280/5250 (epoch 40.762), train_loss = 0.95527810, grad/param norm = 6.6023e-02, time/batch = 0.1144s	
4281/5250 (epoch 40.771), train_loss = 0.95546824, grad/param norm = 7.1560e-02, time/batch = 0.1149s	
4282/5250 (epoch 40.781), train_loss = 0.97767397, grad/param norm = 6.9305e-02, time/batch = 0.1136s	
4283/5250 (epoch 40.790), train_loss = 0.97707363, grad/param norm = 7.2626e-02, time/batch = 0.1140s	
4284/5250 (epoch 40.800), train_loss = 0.95046081, grad/param norm = 7.1992e-02, time/batch = 0.1140s	
4285/5250 (epoch 40.810), train_loss = 0.97269937, grad/param norm = 7.7112e-02, time/batch = 0.1142s	
4286/5250 (epoch 40.819), train_loss = 0.98242553, grad/param norm = 7.4915e-02, time/batch = 0.1143s	
4287/5250 (epoch 40.829), train_loss = 0.97202880, grad/param norm = 7.3807e-02, time/batch = 0.1142s	
4288/5250 (epoch 40.838), train_loss = 0.94761776, grad/param norm = 7.0578e-02, time/batch = 0.1137s	
4289/5250 (epoch 40.848), train_loss = 0.94229623, grad/param norm = 6.8302e-02, time/batch = 0.1144s	
4290/5250 (epoch 40.857), train_loss = 0.95568626, grad/param norm = 7.4410e-02, time/batch = 0.1143s	
4291/5250 (epoch 40.867), train_loss = 0.96049642, grad/param norm = 7.5010e-02, time/batch = 0.1149s	
4292/5250 (epoch 40.876), train_loss = 0.95045560, grad/param norm = 7.2602e-02, time/batch = 0.1137s	
4293/5250 (epoch 40.886), train_loss = 0.95365925, grad/param norm = 7.1044e-02, time/batch = 0.1140s	
4294/5250 (epoch 40.895), train_loss = 0.97520310, grad/param norm = 6.9793e-02, time/batch = 0.1140s	
4295/5250 (epoch 40.905), train_loss = 0.96932267, grad/param norm = 7.1568e-02, time/batch = 0.1142s	
4296/5250 (epoch 40.914), train_loss = 0.97924602, grad/param norm = 7.0072e-02, time/batch = 0.1143s	
4297/5250 (epoch 40.924), train_loss = 0.98624682, grad/param norm = 7.3082e-02, time/batch = 0.1140s	
4298/5250 (epoch 40.933), train_loss = 0.97356214, grad/param norm = 6.6730e-02, time/batch = 0.1137s	
4299/5250 (epoch 40.943), train_loss = 0.98282848, grad/param norm = 7.0495e-02, time/batch = 0.1145s	
4300/5250 (epoch 40.952), train_loss = 0.98957181, grad/param norm = 6.6383e-02, time/batch = 0.1143s	
4301/5250 (epoch 40.962), train_loss = 0.97330412, grad/param norm = 6.9155e-02, time/batch = 0.1149s	
4302/5250 (epoch 40.971), train_loss = 0.98213190, grad/param norm = 6.2573e-02, time/batch = 0.1137s	
4303/5250 (epoch 40.981), train_loss = 0.98183331, grad/param norm = 6.6918e-02, time/batch = 0.1139s	
4304/5250 (epoch 40.990), train_loss = 0.98669278, grad/param norm = 6.7388e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
4305/5250 (epoch 41.000), train_loss = 0.97115605, grad/param norm = 6.4269e-02, time/batch = 0.1143s	
4306/5250 (epoch 41.010), train_loss = 1.15311518, grad/param norm = 7.2368e-02, time/batch = 0.1141s	
4307/5250 (epoch 41.019), train_loss = 0.96769716, grad/param norm = 6.6872e-02, time/batch = 0.1142s	
4308/5250 (epoch 41.029), train_loss = 0.99008363, grad/param norm = 6.8061e-02, time/batch = 0.1137s	
4309/5250 (epoch 41.038), train_loss = 0.96715169, grad/param norm = 6.6546e-02, time/batch = 0.1143s	
4310/5250 (epoch 41.048), train_loss = 0.94245070, grad/param norm = 6.4847e-02, time/batch = 0.1143s	
4311/5250 (epoch 41.057), train_loss = 0.95048950, grad/param norm = 6.9272e-02, time/batch = 0.1149s	
4312/5250 (epoch 41.067), train_loss = 0.96313834, grad/param norm = 6.6717e-02, time/batch = 0.1135s	
4313/5250 (epoch 41.076), train_loss = 0.98259533, grad/param norm = 6.8731e-02, time/batch = 0.1140s	
4314/5250 (epoch 41.086), train_loss = 0.93781341, grad/param norm = 6.7181e-02, time/batch = 0.1142s	
4315/5250 (epoch 41.095), train_loss = 0.95045401, grad/param norm = 6.4113e-02, time/batch = 0.1142s	
4316/5250 (epoch 41.105), train_loss = 0.98167613, grad/param norm = 6.7582e-02, time/batch = 0.1141s	
4317/5250 (epoch 41.114), train_loss = 0.95194478, grad/param norm = 6.7246e-02, time/batch = 0.1142s	
4318/5250 (epoch 41.124), train_loss = 0.98004070, grad/param norm = 6.6389e-02, time/batch = 0.1138s	
4319/5250 (epoch 41.133), train_loss = 0.95983415, grad/param norm = 6.5889e-02, time/batch = 0.1144s	
4320/5250 (epoch 41.143), train_loss = 0.93834509, grad/param norm = 6.5425e-02, time/batch = 0.1143s	
4321/5250 (epoch 41.152), train_loss = 0.94316927, grad/param norm = 7.0611e-02, time/batch = 0.1149s	
4322/5250 (epoch 41.162), train_loss = 0.96543579, grad/param norm = 6.9638e-02, time/batch = 0.1137s	
4323/5250 (epoch 41.171), train_loss = 0.96512783, grad/param norm = 6.4626e-02, time/batch = 0.1139s	
4324/5250 (epoch 41.181), train_loss = 0.96241850, grad/param norm = 6.8604e-02, time/batch = 0.1142s	
4325/5250 (epoch 41.190), train_loss = 0.95824653, grad/param norm = 7.0246e-02, time/batch = 0.1143s	
4326/5250 (epoch 41.200), train_loss = 0.96293044, grad/param norm = 7.2252e-02, time/batch = 0.1141s	
4327/5250 (epoch 41.210), train_loss = 0.97163068, grad/param norm = 6.9206e-02, time/batch = 0.1144s	
4328/5250 (epoch 41.219), train_loss = 1.00530916, grad/param norm = 7.7657e-02, time/batch = 0.1137s	
4329/5250 (epoch 41.229), train_loss = 0.96699519, grad/param norm = 6.6010e-02, time/batch = 0.1144s	
4330/5250 (epoch 41.238), train_loss = 0.96151826, grad/param norm = 6.9601e-02, time/batch = 0.1143s	
4331/5250 (epoch 41.248), train_loss = 0.96718615, grad/param norm = 7.2768e-02, time/batch = 0.1149s	
4332/5250 (epoch 41.257), train_loss = 0.96767719, grad/param norm = 6.8289e-02, time/batch = 0.1136s	
4333/5250 (epoch 41.267), train_loss = 0.96139315, grad/param norm = 6.6713e-02, time/batch = 0.1139s	
4334/5250 (epoch 41.276), train_loss = 0.94966879, grad/param norm = 7.3098e-02, time/batch = 0.1140s	
4335/5250 (epoch 41.286), train_loss = 0.92619143, grad/param norm = 7.1635e-02, time/batch = 0.1142s	
4336/5250 (epoch 41.295), train_loss = 0.95581820, grad/param norm = 6.7337e-02, time/batch = 0.1143s	
4337/5250 (epoch 41.305), train_loss = 0.95278038, grad/param norm = 7.2457e-02, time/batch = 0.1142s	
4338/5250 (epoch 41.314), train_loss = 0.95374746, grad/param norm = 6.9223e-02, time/batch = 0.1137s	
4339/5250 (epoch 41.324), train_loss = 0.96205937, grad/param norm = 6.9411e-02, time/batch = 0.1143s	
4340/5250 (epoch 41.333), train_loss = 0.96492334, grad/param norm = 6.8829e-02, time/batch = 0.1144s	
4341/5250 (epoch 41.343), train_loss = 0.96403941, grad/param norm = 7.4381e-02, time/batch = 0.1149s	
4342/5250 (epoch 41.352), train_loss = 0.97297725, grad/param norm = 6.6467e-02, time/batch = 0.1135s	
4343/5250 (epoch 41.362), train_loss = 0.96662598, grad/param norm = 6.6735e-02, time/batch = 0.1140s	
4344/5250 (epoch 41.371), train_loss = 0.94799239, grad/param norm = 7.0242e-02, time/batch = 0.1143s	
4345/5250 (epoch 41.381), train_loss = 0.95325194, grad/param norm = 6.6541e-02, time/batch = 0.1141s	
4346/5250 (epoch 41.390), train_loss = 0.95619987, grad/param norm = 6.8393e-02, time/batch = 0.1142s	
4347/5250 (epoch 41.400), train_loss = 0.95032353, grad/param norm = 6.6632e-02, time/batch = 0.1141s	
4348/5250 (epoch 41.410), train_loss = 0.95579461, grad/param norm = 6.8723e-02, time/batch = 0.1137s	
4349/5250 (epoch 41.419), train_loss = 0.95893391, grad/param norm = 7.0109e-02, time/batch = 0.1144s	
4350/5250 (epoch 41.429), train_loss = 0.96661117, grad/param norm = 6.7308e-02, time/batch = 0.1142s	
4351/5250 (epoch 41.438), train_loss = 0.96284603, grad/param norm = 6.5177e-02, time/batch = 0.1148s	
4352/5250 (epoch 41.448), train_loss = 0.95114192, grad/param norm = 6.8634e-02, time/batch = 0.1137s	
4353/5250 (epoch 41.457), train_loss = 0.97016301, grad/param norm = 7.1942e-02, time/batch = 0.1139s	
4354/5250 (epoch 41.467), train_loss = 0.96552641, grad/param norm = 6.7036e-02, time/batch = 0.1142s	
4355/5250 (epoch 41.476), train_loss = 0.95887947, grad/param norm = 7.0478e-02, time/batch = 0.1142s	
4356/5250 (epoch 41.486), train_loss = 0.98182405, grad/param norm = 7.1183e-02, time/batch = 0.1141s	
4357/5250 (epoch 41.495), train_loss = 0.97246515, grad/param norm = 6.7411e-02, time/batch = 0.1142s	
4358/5250 (epoch 41.505), train_loss = 0.97761371, grad/param norm = 6.7798e-02, time/batch = 0.1136s	
4359/5250 (epoch 41.514), train_loss = 0.96509879, grad/param norm = 6.7815e-02, time/batch = 0.1143s	
4360/5250 (epoch 41.524), train_loss = 0.96721481, grad/param norm = 6.6405e-02, time/batch = 0.1143s	
4361/5250 (epoch 41.533), train_loss = 0.97284742, grad/param norm = 6.6655e-02, time/batch = 0.1148s	
4362/5250 (epoch 41.543), train_loss = 0.95603024, grad/param norm = 6.8996e-02, time/batch = 0.1136s	
4363/5250 (epoch 41.552), train_loss = 0.96881161, grad/param norm = 6.7382e-02, time/batch = 0.1138s	
4364/5250 (epoch 41.562), train_loss = 0.96881170, grad/param norm = 6.7074e-02, time/batch = 0.1142s	
4365/5250 (epoch 41.571), train_loss = 0.97152078, grad/param norm = 6.8864e-02, time/batch = 0.1143s	
4366/5250 (epoch 41.581), train_loss = 0.96891981, grad/param norm = 7.1228e-02, time/batch = 0.1143s	
4367/5250 (epoch 41.590), train_loss = 0.96619976, grad/param norm = 6.9965e-02, time/batch = 0.1140s	
4368/5250 (epoch 41.600), train_loss = 0.98214411, grad/param norm = 7.0239e-02, time/batch = 0.1134s	
4369/5250 (epoch 41.610), train_loss = 0.97555244, grad/param norm = 6.7978e-02, time/batch = 0.1143s	
4370/5250 (epoch 41.619), train_loss = 0.97016406, grad/param norm = 6.6040e-02, time/batch = 0.1144s	
4371/5250 (epoch 41.629), train_loss = 0.96399524, grad/param norm = 6.9963e-02, time/batch = 0.1147s	
4372/5250 (epoch 41.638), train_loss = 0.96993377, grad/param norm = 7.0122e-02, time/batch = 0.1137s	
4373/5250 (epoch 41.648), train_loss = 0.98087570, grad/param norm = 6.4938e-02, time/batch = 0.1139s	
4374/5250 (epoch 41.657), train_loss = 0.95797710, grad/param norm = 6.6222e-02, time/batch = 0.1140s	
4375/5250 (epoch 41.667), train_loss = 0.96117356, grad/param norm = 6.5385e-02, time/batch = 0.1142s	
4376/5250 (epoch 41.676), train_loss = 0.95698428, grad/param norm = 6.6270e-02, time/batch = 0.1142s	
4377/5250 (epoch 41.686), train_loss = 0.97397600, grad/param norm = 6.8337e-02, time/batch = 0.1141s	
4378/5250 (epoch 41.695), train_loss = 0.97548089, grad/param norm = 6.8838e-02, time/batch = 0.1137s	
4379/5250 (epoch 41.705), train_loss = 0.95476279, grad/param norm = 7.3861e-02, time/batch = 0.1144s	
4380/5250 (epoch 41.714), train_loss = 0.97896246, grad/param norm = 7.2395e-02, time/batch = 0.1143s	
4381/5250 (epoch 41.724), train_loss = 0.96495218, grad/param norm = 7.5545e-02, time/batch = 0.1146s	
4382/5250 (epoch 41.733), train_loss = 0.95094689, grad/param norm = 7.2697e-02, time/batch = 0.1136s	
4383/5250 (epoch 41.743), train_loss = 0.95090855, grad/param norm = 7.0032e-02, time/batch = 0.1140s	
4384/5250 (epoch 41.752), train_loss = 0.94783599, grad/param norm = 6.6758e-02, time/batch = 0.1142s	
4385/5250 (epoch 41.762), train_loss = 0.95060467, grad/param norm = 7.2365e-02, time/batch = 0.1144s	
4386/5250 (epoch 41.771), train_loss = 0.94751486, grad/param norm = 6.9147e-02, time/batch = 0.1142s	
4387/5250 (epoch 41.781), train_loss = 0.96909946, grad/param norm = 7.3211e-02, time/batch = 0.1143s	
4388/5250 (epoch 41.790), train_loss = 0.97141845, grad/param norm = 6.9819e-02, time/batch = 0.1136s	
4389/5250 (epoch 41.800), train_loss = 0.93997931, grad/param norm = 6.8251e-02, time/batch = 0.1143s	
4390/5250 (epoch 41.810), train_loss = 0.96507603, grad/param norm = 7.0999e-02, time/batch = 0.1144s	
4391/5250 (epoch 41.819), train_loss = 0.97364632, grad/param norm = 7.5224e-02, time/batch = 0.1149s	
4392/5250 (epoch 41.829), train_loss = 0.96409277, grad/param norm = 6.9567e-02, time/batch = 0.1136s	
4393/5250 (epoch 41.838), train_loss = 0.94020778, grad/param norm = 7.4387e-02, time/batch = 0.1141s	
4394/5250 (epoch 41.848), train_loss = 0.93720957, grad/param norm = 7.0660e-02, time/batch = 0.1143s	
4395/5250 (epoch 41.857), train_loss = 0.94820018, grad/param norm = 7.1218e-02, time/batch = 0.1143s	
4396/5250 (epoch 41.867), train_loss = 0.95054563, grad/param norm = 7.0234e-02, time/batch = 0.1139s	
4397/5250 (epoch 41.876), train_loss = 0.94219289, grad/param norm = 7.8420e-02, time/batch = 0.1143s	
4398/5250 (epoch 41.886), train_loss = 0.94844905, grad/param norm = 7.7637e-02, time/batch = 0.1137s	
4399/5250 (epoch 41.895), train_loss = 0.96878614, grad/param norm = 7.2810e-02, time/batch = 0.1143s	
4400/5250 (epoch 41.905), train_loss = 0.96348673, grad/param norm = 7.4131e-02, time/batch = 0.1146s	
4401/5250 (epoch 41.914), train_loss = 0.97310169, grad/param norm = 7.4249e-02, time/batch = 0.1148s	
4402/5250 (epoch 41.924), train_loss = 0.97821385, grad/param norm = 6.7514e-02, time/batch = 0.1138s	
4403/5250 (epoch 41.933), train_loss = 0.96651485, grad/param norm = 6.9279e-02, time/batch = 0.1139s	
4404/5250 (epoch 41.943), train_loss = 0.97755248, grad/param norm = 7.3464e-02, time/batch = 0.1141s	
4405/5250 (epoch 41.952), train_loss = 0.98379101, grad/param norm = 7.4166e-02, time/batch = 0.1144s	
4406/5250 (epoch 41.962), train_loss = 0.96928947, grad/param norm = 7.1821e-02, time/batch = 0.1141s	
4407/5250 (epoch 41.971), train_loss = 0.97559135, grad/param norm = 6.8900e-02, time/batch = 0.1142s	
4408/5250 (epoch 41.981), train_loss = 0.97624037, grad/param norm = 6.8359e-02, time/batch = 0.1136s	
4409/5250 (epoch 41.990), train_loss = 0.98014639, grad/param norm = 6.7657e-02, time/batch = 0.1143s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
4410/5250 (epoch 42.000), train_loss = 0.96527887, grad/param norm = 6.5112e-02, time/batch = 0.1141s	
4411/5250 (epoch 42.010), train_loss = 1.14739678, grad/param norm = 7.4875e-02, time/batch = 0.1149s	
4412/5250 (epoch 42.019), train_loss = 0.96088310, grad/param norm = 6.7535e-02, time/batch = 0.1139s	
4413/5250 (epoch 42.029), train_loss = 0.98199190, grad/param norm = 6.7563e-02, time/batch = 0.1139s	
4414/5250 (epoch 42.038), train_loss = 0.96014391, grad/param norm = 6.6679e-02, time/batch = 0.1142s	
4415/5250 (epoch 42.048), train_loss = 0.93538503, grad/param norm = 6.5687e-02, time/batch = 0.1143s	
4416/5250 (epoch 42.057), train_loss = 0.94333742, grad/param norm = 6.6088e-02, time/batch = 0.1142s	
4417/5250 (epoch 42.067), train_loss = 0.95547314, grad/param norm = 6.8601e-02, time/batch = 0.1143s	
4418/5250 (epoch 42.076), train_loss = 0.97632166, grad/param norm = 6.8033e-02, time/batch = 0.1137s	
4419/5250 (epoch 42.086), train_loss = 0.93027800, grad/param norm = 6.6050e-02, time/batch = 0.1142s	
4420/5250 (epoch 42.095), train_loss = 0.94624429, grad/param norm = 6.5345e-02, time/batch = 0.1145s	
4421/5250 (epoch 42.105), train_loss = 0.97451592, grad/param norm = 6.8144e-02, time/batch = 0.1148s	
4422/5250 (epoch 42.114), train_loss = 0.94523610, grad/param norm = 6.6923e-02, time/batch = 0.1136s	
4423/5250 (epoch 42.124), train_loss = 0.97398029, grad/param norm = 6.7302e-02, time/batch = 0.1140s	
4424/5250 (epoch 42.133), train_loss = 0.95310309, grad/param norm = 6.5215e-02, time/batch = 0.1142s	
4425/5250 (epoch 42.143), train_loss = 0.93116230, grad/param norm = 6.5829e-02, time/batch = 0.1142s	
4426/5250 (epoch 42.152), train_loss = 0.93592879, grad/param norm = 7.1627e-02, time/batch = 0.1143s	
4427/5250 (epoch 42.162), train_loss = 0.95887844, grad/param norm = 7.0399e-02, time/batch = 0.1141s	
4428/5250 (epoch 42.171), train_loss = 0.95879610, grad/param norm = 6.8940e-02, time/batch = 0.1137s	
4429/5250 (epoch 42.181), train_loss = 0.95544369, grad/param norm = 6.8683e-02, time/batch = 0.1143s	
4430/5250 (epoch 42.190), train_loss = 0.95116444, grad/param norm = 6.8695e-02, time/batch = 0.1142s	
4431/5250 (epoch 42.200), train_loss = 0.95644491, grad/param norm = 7.5609e-02, time/batch = 0.1149s	
4432/5250 (epoch 42.210), train_loss = 0.96442487, grad/param norm = 6.8372e-02, time/batch = 0.1136s	
4433/5250 (epoch 42.219), train_loss = 0.99632906, grad/param norm = 7.4483e-02, time/batch = 0.1139s	
4434/5250 (epoch 42.229), train_loss = 0.96044628, grad/param norm = 6.8922e-02, time/batch = 0.1141s	
4435/5250 (epoch 42.238), train_loss = 0.95378799, grad/param norm = 7.1680e-02, time/batch = 0.1142s	
4436/5250 (epoch 42.248), train_loss = 0.95772992, grad/param norm = 6.5487e-02, time/batch = 0.1141s	
4437/5250 (epoch 42.257), train_loss = 0.95956692, grad/param norm = 7.0333e-02, time/batch = 0.1142s	
4438/5250 (epoch 42.267), train_loss = 0.95849081, grad/param norm = 7.0038e-02, time/batch = 0.1136s	
4439/5250 (epoch 42.276), train_loss = 0.94205534, grad/param norm = 6.9182e-02, time/batch = 0.1141s	
4440/5250 (epoch 42.286), train_loss = 0.91960459, grad/param norm = 6.8337e-02, time/batch = 0.1143s	
4441/5250 (epoch 42.295), train_loss = 0.95034099, grad/param norm = 7.6001e-02, time/batch = 0.1149s	
4442/5250 (epoch 42.305), train_loss = 0.94713335, grad/param norm = 7.2604e-02, time/batch = 0.1136s	
4443/5250 (epoch 42.314), train_loss = 0.94496691, grad/param norm = 6.7770e-02, time/batch = 0.1139s	
4444/5250 (epoch 42.324), train_loss = 0.95468090, grad/param norm = 6.9119e-02, time/batch = 0.1143s	
4445/5250 (epoch 42.333), train_loss = 0.95926641, grad/param norm = 7.2034e-02, time/batch = 0.1141s	
4446/5250 (epoch 42.343), train_loss = 0.95604422, grad/param norm = 6.8365e-02, time/batch = 0.1142s	
4447/5250 (epoch 42.352), train_loss = 0.96805366, grad/param norm = 7.0870e-02, time/batch = 0.1142s	
4448/5250 (epoch 42.362), train_loss = 0.96157225, grad/param norm = 6.7994e-02, time/batch = 0.1135s	
4449/5250 (epoch 42.371), train_loss = 0.94017635, grad/param norm = 6.6755e-02, time/batch = 0.1144s	
4450/5250 (epoch 42.381), train_loss = 0.94855607, grad/param norm = 6.9739e-02, time/batch = 0.1144s	
4451/5250 (epoch 42.390), train_loss = 0.95097252, grad/param norm = 7.2941e-02, time/batch = 0.1149s	
4452/5250 (epoch 42.400), train_loss = 0.94388722, grad/param norm = 6.8419e-02, time/batch = 0.1136s	
4453/5250 (epoch 42.410), train_loss = 0.94839991, grad/param norm = 6.8800e-02, time/batch = 0.1138s	
4454/5250 (epoch 42.419), train_loss = 0.95230974, grad/param norm = 6.7231e-02, time/batch = 0.1142s	
4455/5250 (epoch 42.429), train_loss = 0.96203025, grad/param norm = 7.3864e-02, time/batch = 0.1141s	
4456/5250 (epoch 42.438), train_loss = 0.95726601, grad/param norm = 6.8989e-02, time/batch = 0.1142s	
4457/5250 (epoch 42.448), train_loss = 0.94580747, grad/param norm = 6.8084e-02, time/batch = 0.1142s	
4458/5250 (epoch 42.457), train_loss = 0.96321562, grad/param norm = 7.0940e-02, time/batch = 0.1137s	
4459/5250 (epoch 42.467), train_loss = 0.95795514, grad/param norm = 6.9581e-02, time/batch = 0.1142s	
4460/5250 (epoch 42.476), train_loss = 0.95224514, grad/param norm = 7.1712e-02, time/batch = 0.1145s	
4461/5250 (epoch 42.486), train_loss = 0.97415467, grad/param norm = 7.2483e-02, time/batch = 0.1148s	
4462/5250 (epoch 42.495), train_loss = 0.96736355, grad/param norm = 6.9163e-02, time/batch = 0.1135s	
4463/5250 (epoch 42.505), train_loss = 0.97079550, grad/param norm = 6.9252e-02, time/batch = 0.1139s	
4464/5250 (epoch 42.514), train_loss = 0.95846283, grad/param norm = 6.9174e-02, time/batch = 0.1140s	
4465/5250 (epoch 42.524), train_loss = 0.96144984, grad/param norm = 6.6614e-02, time/batch = 0.1144s	
4466/5250 (epoch 42.533), train_loss = 0.96600139, grad/param norm = 6.6924e-02, time/batch = 0.1142s	
4467/5250 (epoch 42.543), train_loss = 0.94845236, grad/param norm = 6.8215e-02, time/batch = 0.1141s	
4468/5250 (epoch 42.552), train_loss = 0.96061771, grad/param norm = 6.6462e-02, time/batch = 0.1137s	
4469/5250 (epoch 42.562), train_loss = 0.96229698, grad/param norm = 6.5710e-02, time/batch = 0.1140s	
4470/5250 (epoch 42.571), train_loss = 0.96441341, grad/param norm = 6.9843e-02, time/batch = 0.1144s	
4471/5250 (epoch 42.581), train_loss = 0.96156391, grad/param norm = 7.0438e-02, time/batch = 0.1149s	
4472/5250 (epoch 42.590), train_loss = 0.95760529, grad/param norm = 6.7891e-02, time/batch = 0.1136s	
4473/5250 (epoch 42.600), train_loss = 0.97550821, grad/param norm = 7.1232e-02, time/batch = 0.1139s	
4474/5250 (epoch 42.610), train_loss = 0.96982141, grad/param norm = 7.3747e-02, time/batch = 0.1141s	
4475/5250 (epoch 42.619), train_loss = 0.96528178, grad/param norm = 6.7507e-02, time/batch = 0.1140s	
4476/5250 (epoch 42.629), train_loss = 0.95575209, grad/param norm = 6.7048e-02, time/batch = 0.1142s	
4477/5250 (epoch 42.638), train_loss = 0.96228412, grad/param norm = 6.8413e-02, time/batch = 0.1142s	
4478/5250 (epoch 42.648), train_loss = 0.97361576, grad/param norm = 6.8216e-02, time/batch = 0.1135s	
4479/5250 (epoch 42.657), train_loss = 0.95297171, grad/param norm = 7.0290e-02, time/batch = 0.1143s	
4480/5250 (epoch 42.667), train_loss = 0.95318641, grad/param norm = 6.5489e-02, time/batch = 0.1144s	
4481/5250 (epoch 42.676), train_loss = 0.95051287, grad/param norm = 6.5504e-02, time/batch = 0.1149s	
4482/5250 (epoch 42.686), train_loss = 0.96791044, grad/param norm = 6.8883e-02, time/batch = 0.1137s	
4483/5250 (epoch 42.695), train_loss = 0.96919393, grad/param norm = 6.8230e-02, time/batch = 0.1140s	
4484/5250 (epoch 42.705), train_loss = 0.94487510, grad/param norm = 6.8634e-02, time/batch = 0.1140s	
4485/5250 (epoch 42.714), train_loss = 0.97070142, grad/param norm = 6.9175e-02, time/batch = 0.1142s	
4486/5250 (epoch 42.724), train_loss = 0.95520916, grad/param norm = 7.4972e-02, time/batch = 0.1143s	
4487/5250 (epoch 42.733), train_loss = 0.94388391, grad/param norm = 6.8574e-02, time/batch = 0.1144s	
4488/5250 (epoch 42.743), train_loss = 0.94564871, grad/param norm = 7.2256e-02, time/batch = 0.1136s	
4489/5250 (epoch 42.752), train_loss = 0.94222327, grad/param norm = 6.9941e-02, time/batch = 0.1142s	
4490/5250 (epoch 42.762), train_loss = 0.94089177, grad/param norm = 6.6023e-02, time/batch = 0.1144s	
4491/5250 (epoch 42.771), train_loss = 0.94180749, grad/param norm = 7.1638e-02, time/batch = 0.1148s	
4492/5250 (epoch 42.781), train_loss = 0.96297807, grad/param norm = 6.9394e-02, time/batch = 0.1138s	
4493/5250 (epoch 42.790), train_loss = 0.96236905, grad/param norm = 7.0409e-02, time/batch = 0.1140s	
4494/5250 (epoch 42.800), train_loss = 0.93527114, grad/param norm = 7.2021e-02, time/batch = 0.1140s	
4495/5250 (epoch 42.810), train_loss = 0.95824592, grad/param norm = 7.5521e-02, time/batch = 0.1144s	
4496/5250 (epoch 42.819), train_loss = 0.96714776, grad/param norm = 7.0545e-02, time/batch = 0.1142s	
4497/5250 (epoch 42.829), train_loss = 0.95657154, grad/param norm = 7.2632e-02, time/batch = 0.1142s	
4498/5250 (epoch 42.838), train_loss = 0.93384054, grad/param norm = 7.2642e-02, time/batch = 0.1137s	
4499/5250 (epoch 42.848), train_loss = 0.92774825, grad/param norm = 7.0047e-02, time/batch = 0.1141s	
4500/5250 (epoch 42.857), train_loss = 0.94332588, grad/param norm = 7.4900e-02, time/batch = 0.1143s	
4501/5250 (epoch 42.867), train_loss = 0.94570085, grad/param norm = 7.4155e-02, time/batch = 0.1149s	
4502/5250 (epoch 42.876), train_loss = 0.93560612, grad/param norm = 7.3994e-02, time/batch = 0.1137s	
4503/5250 (epoch 42.886), train_loss = 0.93991666, grad/param norm = 7.2908e-02, time/batch = 0.1139s	
4504/5250 (epoch 42.895), train_loss = 0.96171072, grad/param norm = 7.1433e-02, time/batch = 0.1142s	
4505/5250 (epoch 42.905), train_loss = 0.95603783, grad/param norm = 7.4395e-02, time/batch = 0.1142s	
4506/5250 (epoch 42.914), train_loss = 0.96576073, grad/param norm = 7.2218e-02, time/batch = 0.1142s	
4507/5250 (epoch 42.924), train_loss = 0.97188579, grad/param norm = 7.4112e-02, time/batch = 0.1140s	
4508/5250 (epoch 42.933), train_loss = 0.95965649, grad/param norm = 6.7839e-02, time/batch = 0.1137s	
4509/5250 (epoch 42.943), train_loss = 0.96976922, grad/param norm = 7.3864e-02, time/batch = 0.1141s	
4510/5250 (epoch 42.952), train_loss = 0.97718782, grad/param norm = 6.9914e-02, time/batch = 0.1144s	
4511/5250 (epoch 42.962), train_loss = 0.96048647, grad/param norm = 7.1669e-02, time/batch = 0.1148s	
4512/5250 (epoch 42.971), train_loss = 0.97041769, grad/param norm = 6.6929e-02, time/batch = 0.1136s	
4513/5250 (epoch 42.981), train_loss = 0.96789685, grad/param norm = 7.0023e-02, time/batch = 0.1138s	
4514/5250 (epoch 42.990), train_loss = 0.97518122, grad/param norm = 6.9726e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
4515/5250 (epoch 43.000), train_loss = 0.95884035, grad/param norm = 6.6044e-02, time/batch = 0.1143s	
4516/5250 (epoch 43.010), train_loss = 1.14128632, grad/param norm = 7.2880e-02, time/batch = 0.1142s	
4517/5250 (epoch 43.019), train_loss = 0.95521849, grad/param norm = 6.7345e-02, time/batch = 0.1141s	
4518/5250 (epoch 43.029), train_loss = 0.97678243, grad/param norm = 6.9573e-02, time/batch = 0.1136s	
4519/5250 (epoch 43.038), train_loss = 0.95397810, grad/param norm = 6.7207e-02, time/batch = 0.1142s	
4520/5250 (epoch 43.048), train_loss = 0.92916229, grad/param norm = 6.5450e-02, time/batch = 0.1143s	
4521/5250 (epoch 43.057), train_loss = 0.93673321, grad/param norm = 6.9821e-02, time/batch = 0.1148s	
4522/5250 (epoch 43.067), train_loss = 0.94962282, grad/param norm = 6.7388e-02, time/batch = 0.1137s	
4523/5250 (epoch 43.076), train_loss = 0.96996846, grad/param norm = 6.9054e-02, time/batch = 0.1139s	
4524/5250 (epoch 43.086), train_loss = 0.92534522, grad/param norm = 6.8335e-02, time/batch = 0.1140s	
4525/5250 (epoch 43.095), train_loss = 0.93928630, grad/param norm = 6.6404e-02, time/batch = 0.1143s	
4526/5250 (epoch 43.105), train_loss = 0.96791220, grad/param norm = 6.8754e-02, time/batch = 0.1142s	
4527/5250 (epoch 43.114), train_loss = 0.93859490, grad/param norm = 6.9658e-02, time/batch = 0.1140s	
4528/5250 (epoch 43.124), train_loss = 0.96774166, grad/param norm = 6.7762e-02, time/batch = 0.1138s	
4529/5250 (epoch 43.133), train_loss = 0.94633567, grad/param norm = 6.7007e-02, time/batch = 0.1142s	
4530/5250 (epoch 43.143), train_loss = 0.92464643, grad/param norm = 6.6844e-02, time/batch = 0.1144s	
4531/5250 (epoch 43.152), train_loss = 0.92920956, grad/param norm = 7.0114e-02, time/batch = 0.1147s	
4532/5250 (epoch 43.162), train_loss = 0.95226686, grad/param norm = 7.0216e-02, time/batch = 0.1137s	
4533/5250 (epoch 43.171), train_loss = 0.95308552, grad/param norm = 6.8006e-02, time/batch = 0.1138s	
4534/5250 (epoch 43.181), train_loss = 0.95012925, grad/param norm = 6.9772e-02, time/batch = 0.1142s	
4535/5250 (epoch 43.190), train_loss = 0.94459719, grad/param norm = 7.0566e-02, time/batch = 0.1143s	
4536/5250 (epoch 43.200), train_loss = 0.94891992, grad/param norm = 7.2825e-02, time/batch = 0.1142s	
4537/5250 (epoch 43.210), train_loss = 0.95808190, grad/param norm = 6.9728e-02, time/batch = 0.1142s	
4538/5250 (epoch 43.219), train_loss = 0.99145252, grad/param norm = 7.6046e-02, time/batch = 0.1136s	
4539/5250 (epoch 43.229), train_loss = 0.95310954, grad/param norm = 6.7778e-02, time/batch = 0.1142s	
4540/5250 (epoch 43.238), train_loss = 0.94889828, grad/param norm = 7.1823e-02, time/batch = 0.1145s	
4541/5250 (epoch 43.248), train_loss = 0.95317307, grad/param norm = 7.2113e-02, time/batch = 0.1150s	
4542/5250 (epoch 43.257), train_loss = 0.95324149, grad/param norm = 6.9996e-02, time/batch = 0.1138s	
4543/5250 (epoch 43.267), train_loss = 0.95056531, grad/param norm = 6.7722e-02, time/batch = 0.1139s	
4544/5250 (epoch 43.276), train_loss = 0.93636604, grad/param norm = 7.3263e-02, time/batch = 0.1139s	
4545/5250 (epoch 43.286), train_loss = 0.91406107, grad/param norm = 7.4573e-02, time/batch = 0.1143s	
4546/5250 (epoch 43.295), train_loss = 0.94276540, grad/param norm = 6.9438e-02, time/batch = 0.1140s	
4547/5250 (epoch 43.305), train_loss = 0.94021515, grad/param norm = 7.5068e-02, time/batch = 0.1144s	
4548/5250 (epoch 43.314), train_loss = 0.94056154, grad/param norm = 7.0761e-02, time/batch = 0.1136s	
4549/5250 (epoch 43.324), train_loss = 0.94985663, grad/param norm = 7.1402e-02, time/batch = 0.1144s	
4550/5250 (epoch 43.333), train_loss = 0.95138053, grad/param norm = 6.9727e-02, time/batch = 0.1148s	
4551/5250 (epoch 43.343), train_loss = 0.95040580, grad/param norm = 7.5579e-02, time/batch = 0.1150s	
4552/5250 (epoch 43.352), train_loss = 0.96001511, grad/param norm = 6.6673e-02, time/batch = 0.1139s	
4553/5250 (epoch 43.362), train_loss = 0.95436016, grad/param norm = 6.8700e-02, time/batch = 0.1139s	
4554/5250 (epoch 43.371), train_loss = 0.93533974, grad/param norm = 7.0510e-02, time/batch = 0.1142s	
4555/5250 (epoch 43.381), train_loss = 0.94078357, grad/param norm = 6.7107e-02, time/batch = 0.1141s	
4556/5250 (epoch 43.390), train_loss = 0.94341792, grad/param norm = 6.8984e-02, time/batch = 0.1142s	
4557/5250 (epoch 43.400), train_loss = 0.93705174, grad/param norm = 6.9165e-02, time/batch = 0.1142s	
4558/5250 (epoch 43.410), train_loss = 0.94304859, grad/param norm = 7.1828e-02, time/batch = 0.1138s	
4559/5250 (epoch 43.419), train_loss = 0.94698143, grad/param norm = 7.2982e-02, time/batch = 0.1143s	
4560/5250 (epoch 43.429), train_loss = 0.95402533, grad/param norm = 6.9956e-02, time/batch = 0.1143s	
4561/5250 (epoch 43.438), train_loss = 0.94985532, grad/param norm = 6.8460e-02, time/batch = 0.1150s	
4562/5250 (epoch 43.448), train_loss = 0.93837913, grad/param norm = 7.1415e-02, time/batch = 0.1137s	
4563/5250 (epoch 43.457), train_loss = 0.95786242, grad/param norm = 7.6227e-02, time/batch = 0.1138s	
4564/5250 (epoch 43.467), train_loss = 0.95245640, grad/param norm = 6.9395e-02, time/batch = 0.1142s	
4565/5250 (epoch 43.476), train_loss = 0.94523057, grad/param norm = 7.1710e-02, time/batch = 0.1142s	
4566/5250 (epoch 43.486), train_loss = 0.97023747, grad/param norm = 7.5152e-02, time/batch = 0.1141s	
4567/5250 (epoch 43.495), train_loss = 0.95964375, grad/param norm = 7.0944e-02, time/batch = 0.1140s	
4568/5250 (epoch 43.505), train_loss = 0.96477176, grad/param norm = 6.8668e-02, time/batch = 0.1137s	
4569/5250 (epoch 43.514), train_loss = 0.95187068, grad/param norm = 7.0633e-02, time/batch = 0.1143s	
4570/5250 (epoch 43.524), train_loss = 0.95430975, grad/param norm = 6.8637e-02, time/batch = 0.1145s	
4571/5250 (epoch 43.533), train_loss = 0.95945032, grad/param norm = 6.9230e-02, time/batch = 0.1148s	
4572/5250 (epoch 43.543), train_loss = 0.94254668, grad/param norm = 6.9409e-02, time/batch = 0.1138s	
4573/5250 (epoch 43.552), train_loss = 0.95411810, grad/param norm = 6.6803e-02, time/batch = 0.1140s	
4574/5250 (epoch 43.562), train_loss = 0.95588011, grad/param norm = 6.6488e-02, time/batch = 0.1142s	
4575/5250 (epoch 43.571), train_loss = 0.95711984, grad/param norm = 6.9628e-02, time/batch = 0.1143s	
4576/5250 (epoch 43.581), train_loss = 0.95424842, grad/param norm = 7.0926e-02, time/batch = 0.1141s	
4577/5250 (epoch 43.590), train_loss = 0.95058398, grad/param norm = 6.8399e-02, time/batch = 0.1143s	
4578/5250 (epoch 43.600), train_loss = 0.96774538, grad/param norm = 7.0520e-02, time/batch = 0.1138s	
4579/5250 (epoch 43.610), train_loss = 0.96243817, grad/param norm = 7.0432e-02, time/batch = 0.1144s	
4580/5250 (epoch 43.619), train_loss = 0.95820338, grad/param norm = 7.0115e-02, time/batch = 0.1144s	
4581/5250 (epoch 43.629), train_loss = 0.95118000, grad/param norm = 7.1799e-02, time/batch = 0.1148s	
4582/5250 (epoch 43.638), train_loss = 0.95731917, grad/param norm = 7.3683e-02, time/batch = 0.1138s	
4583/5250 (epoch 43.648), train_loss = 0.96832014, grad/param norm = 6.6555e-02, time/batch = 0.1139s	
4584/5250 (epoch 43.657), train_loss = 0.94528093, grad/param norm = 6.8139e-02, time/batch = 0.1143s	
4585/5250 (epoch 43.667), train_loss = 0.94750868, grad/param norm = 6.7963e-02, time/batch = 0.1139s	
4586/5250 (epoch 43.676), train_loss = 0.94518372, grad/param norm = 6.8193e-02, time/batch = 0.1143s	
4587/5250 (epoch 43.686), train_loss = 0.96119267, grad/param norm = 6.8580e-02, time/batch = 0.1142s	
4588/5250 (epoch 43.695), train_loss = 0.96209262, grad/param norm = 7.2178e-02, time/batch = 0.1138s	
4589/5250 (epoch 43.705), train_loss = 0.94180782, grad/param norm = 7.2813e-02, time/batch = 0.1143s	
4590/5250 (epoch 43.714), train_loss = 0.96465243, grad/param norm = 7.2648e-02, time/batch = 0.1144s	
4591/5250 (epoch 43.724), train_loss = 0.94970497, grad/param norm = 7.4288e-02, time/batch = 0.1147s	
4592/5250 (epoch 43.733), train_loss = 0.93656828, grad/param norm = 6.9507e-02, time/batch = 0.1137s	
4593/5250 (epoch 43.743), train_loss = 0.93863346, grad/param norm = 7.3180e-02, time/batch = 0.1139s	
4594/5250 (epoch 43.752), train_loss = 0.93293648, grad/param norm = 6.7183e-02, time/batch = 0.1140s	
4595/5250 (epoch 43.762), train_loss = 0.93558187, grad/param norm = 6.9659e-02, time/batch = 0.1142s	
4596/5250 (epoch 43.771), train_loss = 0.93320152, grad/param norm = 6.6037e-02, time/batch = 0.1143s	
4597/5250 (epoch 43.781), train_loss = 0.95511833, grad/param norm = 7.0525e-02, time/batch = 0.1141s	
4598/5250 (epoch 43.790), train_loss = 0.95709804, grad/param norm = 7.2641e-02, time/batch = 0.1137s	
4599/5250 (epoch 43.800), train_loss = 0.92679706, grad/param norm = 6.7963e-02, time/batch = 0.1144s	
4600/5250 (epoch 43.810), train_loss = 0.95069468, grad/param norm = 7.2462e-02, time/batch = 0.1143s	
4601/5250 (epoch 43.819), train_loss = 0.95958482, grad/param norm = 7.4097e-02, time/batch = 0.1149s	
4602/5250 (epoch 43.829), train_loss = 0.94918759, grad/param norm = 6.9546e-02, time/batch = 0.1136s	
4603/5250 (epoch 43.838), train_loss = 0.92571425, grad/param norm = 7.1831e-02, time/batch = 0.1141s	
4604/5250 (epoch 43.848), train_loss = 0.92191101, grad/param norm = 7.0135e-02, time/batch = 0.1141s	
4605/5250 (epoch 43.857), train_loss = 0.93577405, grad/param norm = 7.4392e-02, time/batch = 0.1143s	
4606/5250 (epoch 43.867), train_loss = 0.93826243, grad/param norm = 8.2506e-02, time/batch = 0.1142s	
4607/5250 (epoch 43.876), train_loss = 0.93126625, grad/param norm = 8.6031e-02, time/batch = 0.1142s	
4608/5250 (epoch 43.886), train_loss = 0.93770227, grad/param norm = 7.6390e-02, time/batch = 0.1135s	
4609/5250 (epoch 43.895), train_loss = 0.95564516, grad/param norm = 7.2384e-02, time/batch = 0.1142s	
4610/5250 (epoch 43.905), train_loss = 0.95066960, grad/param norm = 7.2933e-02, time/batch = 0.1143s	
4611/5250 (epoch 43.914), train_loss = 0.95723805, grad/param norm = 7.1151e-02, time/batch = 0.1147s	
4612/5250 (epoch 43.924), train_loss = 0.96469357, grad/param norm = 6.8617e-02, time/batch = 0.1137s	
4613/5250 (epoch 43.933), train_loss = 0.95301115, grad/param norm = 7.0553e-02, time/batch = 0.1138s	
4614/5250 (epoch 43.943), train_loss = 0.96482933, grad/param norm = 7.4409e-02, time/batch = 0.1142s	
4615/5250 (epoch 43.952), train_loss = 0.97067771, grad/param norm = 7.2274e-02, time/batch = 0.1142s	
4616/5250 (epoch 43.962), train_loss = 0.95560452, grad/param norm = 7.0658e-02, time/batch = 0.1142s	
4617/5250 (epoch 43.971), train_loss = 0.96210193, grad/param norm = 6.9233e-02, time/batch = 0.1142s	
4618/5250 (epoch 43.981), train_loss = 0.96199284, grad/param norm = 6.9023e-02, time/batch = 0.1138s	
4619/5250 (epoch 43.990), train_loss = 0.96873954, grad/param norm = 6.9911e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
4620/5250 (epoch 44.000), train_loss = 0.95355647, grad/param norm = 6.6803e-02, time/batch = 0.1142s	
4621/5250 (epoch 44.010), train_loss = 1.13594169, grad/param norm = 7.5094e-02, time/batch = 0.1149s	
4622/5250 (epoch 44.019), train_loss = 0.94895678, grad/param norm = 6.9159e-02, time/batch = 0.1137s	
4623/5250 (epoch 44.029), train_loss = 0.96985807, grad/param norm = 7.0506e-02, time/batch = 0.1139s	
4624/5250 (epoch 44.038), train_loss = 0.94724737, grad/param norm = 6.8111e-02, time/batch = 0.1141s	
4625/5250 (epoch 44.048), train_loss = 0.92286503, grad/param norm = 6.6044e-02, time/batch = 0.1142s	
4626/5250 (epoch 44.057), train_loss = 0.93023797, grad/param norm = 6.8676e-02, time/batch = 0.1143s	
4627/5250 (epoch 44.067), train_loss = 0.94295474, grad/param norm = 6.9165e-02, time/batch = 0.1143s	
4628/5250 (epoch 44.076), train_loss = 0.96354136, grad/param norm = 6.8821e-02, time/batch = 0.1137s	
4629/5250 (epoch 44.086), train_loss = 0.91932397, grad/param norm = 6.7432e-02, time/batch = 0.1141s	
4630/5250 (epoch 44.095), train_loss = 0.93466434, grad/param norm = 6.6433e-02, time/batch = 0.1142s	
4631/5250 (epoch 44.105), train_loss = 0.96112434, grad/param norm = 6.9542e-02, time/batch = 0.1154s	
4632/5250 (epoch 44.114), train_loss = 0.93229884, grad/param norm = 6.8683e-02, time/batch = 0.1136s	
4633/5250 (epoch 44.124), train_loss = 0.96160540, grad/param norm = 6.9311e-02, time/batch = 0.1140s	
4634/5250 (epoch 44.133), train_loss = 0.94010220, grad/param norm = 6.6943e-02, time/batch = 0.1142s	
4635/5250 (epoch 44.143), train_loss = 0.91793819, grad/param norm = 6.7374e-02, time/batch = 0.1143s	
4636/5250 (epoch 44.152), train_loss = 0.92285164, grad/param norm = 7.1828e-02, time/batch = 0.1144s	
4637/5250 (epoch 44.162), train_loss = 0.94657106, grad/param norm = 7.1642e-02, time/batch = 0.1141s	
4638/5250 (epoch 44.171), train_loss = 0.94706869, grad/param norm = 6.8569e-02, time/batch = 0.1137s	
4639/5250 (epoch 44.181), train_loss = 0.94326633, grad/param norm = 6.9977e-02, time/batch = 0.1144s	
4640/5250 (epoch 44.190), train_loss = 0.93824623, grad/param norm = 6.9920e-02, time/batch = 0.1145s	
4641/5250 (epoch 44.200), train_loss = 0.94384579, grad/param norm = 7.6262e-02, time/batch = 0.1147s	
4642/5250 (epoch 44.210), train_loss = 0.95286603, grad/param norm = 7.1701e-02, time/batch = 0.1136s	
4643/5250 (epoch 44.219), train_loss = 0.98302919, grad/param norm = 7.4366e-02, time/batch = 0.1138s	
4644/5250 (epoch 44.229), train_loss = 0.94788830, grad/param norm = 7.0557e-02, time/batch = 0.1141s	
4645/5250 (epoch 44.238), train_loss = 0.94162713, grad/param norm = 7.0718e-02, time/batch = 0.1143s	
4646/5250 (epoch 44.248), train_loss = 0.94541356, grad/param norm = 6.8752e-02, time/batch = 0.1143s	
4647/5250 (epoch 44.257), train_loss = 0.94664006, grad/param norm = 7.1124e-02, time/batch = 0.1141s	
4648/5250 (epoch 44.267), train_loss = 0.94660820, grad/param norm = 7.1055e-02, time/batch = 0.1137s	
4649/5250 (epoch 44.276), train_loss = 0.92985620, grad/param norm = 7.2079e-02, time/batch = 0.1144s	
4650/5250 (epoch 44.286), train_loss = 0.90671025, grad/param norm = 6.8865e-02, time/batch = 0.1145s	
4651/5250 (epoch 44.295), train_loss = 0.93552637, grad/param norm = 7.2919e-02, time/batch = 0.1148s	
4652/5250 (epoch 44.305), train_loss = 0.93367197, grad/param norm = 7.4070e-02, time/batch = 0.1137s	
4653/5250 (epoch 44.314), train_loss = 0.93147581, grad/param norm = 6.6717e-02, time/batch = 0.1139s	
4654/5250 (epoch 44.324), train_loss = 0.94286916, grad/param norm = 7.0563e-02, time/batch = 0.1141s	
4655/5250 (epoch 44.333), train_loss = 0.94584619, grad/param norm = 7.2964e-02, time/batch = 0.1142s	
4656/5250 (epoch 44.343), train_loss = 0.94275815, grad/param norm = 6.9887e-02, time/batch = 0.1143s	
4657/5250 (epoch 44.352), train_loss = 0.95617339, grad/param norm = 7.2585e-02, time/batch = 0.1143s	
4658/5250 (epoch 44.362), train_loss = 0.94984428, grad/param norm = 7.0834e-02, time/batch = 0.1135s	
4659/5250 (epoch 44.371), train_loss = 0.92801777, grad/param norm = 6.8548e-02, time/batch = 0.1142s	
4660/5250 (epoch 44.381), train_loss = 0.93600189, grad/param norm = 7.0675e-02, time/batch = 0.1142s	
4661/5250 (epoch 44.390), train_loss = 0.93820836, grad/param norm = 7.3016e-02, time/batch = 0.1149s	
4662/5250 (epoch 44.400), train_loss = 0.93026814, grad/param norm = 6.8129e-02, time/batch = 0.1135s	
4663/5250 (epoch 44.410), train_loss = 0.93477218, grad/param norm = 6.9733e-02, time/batch = 0.1138s	
4664/5250 (epoch 44.419), train_loss = 0.93881632, grad/param norm = 6.6833e-02, time/batch = 0.1140s	
4665/5250 (epoch 44.429), train_loss = 0.94964419, grad/param norm = 7.6084e-02, time/batch = 0.1140s	
4666/5250 (epoch 44.438), train_loss = 0.94456900, grad/param norm = 7.0500e-02, time/batch = 0.1141s	
4667/5250 (epoch 44.448), train_loss = 0.93280126, grad/param norm = 6.9566e-02, time/batch = 0.1143s	
4668/5250 (epoch 44.457), train_loss = 0.95241261, grad/param norm = 7.4038e-02, time/batch = 0.1138s	
4669/5250 (epoch 44.467), train_loss = 0.94478807, grad/param norm = 7.1240e-02, time/batch = 0.1143s	
4670/5250 (epoch 44.476), train_loss = 0.93939350, grad/param norm = 7.2448e-02, time/batch = 0.1143s	
4671/5250 (epoch 44.486), train_loss = 0.96330761, grad/param norm = 7.8124e-02, time/batch = 0.1147s	
4672/5250 (epoch 44.495), train_loss = 0.95519597, grad/param norm = 7.1540e-02, time/batch = 0.1138s	
4673/5250 (epoch 44.505), train_loss = 0.95835643, grad/param norm = 7.0190e-02, time/batch = 0.1141s	
4674/5250 (epoch 44.514), train_loss = 0.94567411, grad/param norm = 7.1761e-02, time/batch = 0.1142s	
4675/5250 (epoch 44.524), train_loss = 0.94899382, grad/param norm = 6.8612e-02, time/batch = 0.1140s	
4676/5250 (epoch 44.533), train_loss = 0.95331661, grad/param norm = 6.9542e-02, time/batch = 0.1141s	
4677/5250 (epoch 44.543), train_loss = 0.93565817, grad/param norm = 7.0157e-02, time/batch = 0.1143s	
4678/5250 (epoch 44.552), train_loss = 0.94782986, grad/param norm = 6.8654e-02, time/batch = 0.1137s	
4679/5250 (epoch 44.562), train_loss = 0.95119983, grad/param norm = 6.8589e-02, time/batch = 0.1143s	
4680/5250 (epoch 44.571), train_loss = 0.95179198, grad/param norm = 7.0100e-02, time/batch = 0.1142s	
4681/5250 (epoch 44.581), train_loss = 0.94822384, grad/param norm = 7.4008e-02, time/batch = 0.1149s	
4682/5250 (epoch 44.590), train_loss = 0.94643373, grad/param norm = 7.0719e-02, time/batch = 0.1137s	
4683/5250 (epoch 44.600), train_loss = 0.96121338, grad/param norm = 7.2204e-02, time/batch = 0.1140s	
4684/5250 (epoch 44.610), train_loss = 0.95584695, grad/param norm = 6.9388e-02, time/batch = 0.1141s	
4685/5250 (epoch 44.619), train_loss = 0.95135782, grad/param norm = 6.9313e-02, time/batch = 0.1141s	
4686/5250 (epoch 44.629), train_loss = 0.94358201, grad/param norm = 6.8342e-02, time/batch = 0.1143s	
4687/5250 (epoch 44.638), train_loss = 0.95011746, grad/param norm = 7.3046e-02, time/batch = 0.1140s	
4688/5250 (epoch 44.648), train_loss = 0.96276106, grad/param norm = 7.0392e-02, time/batch = 0.1138s	
4689/5250 (epoch 44.657), train_loss = 0.94038160, grad/param norm = 7.0142e-02, time/batch = 0.1141s	
4690/5250 (epoch 44.667), train_loss = 0.93974040, grad/param norm = 6.7235e-02, time/batch = 0.1141s	
4691/5250 (epoch 44.676), train_loss = 0.93886854, grad/param norm = 6.7695e-02, time/batch = 0.1147s	
4692/5250 (epoch 44.686), train_loss = 0.95635398, grad/param norm = 7.0008e-02, time/batch = 0.1138s	
4693/5250 (epoch 44.695), train_loss = 0.95528918, grad/param norm = 6.8479e-02, time/batch = 0.1140s	
4694/5250 (epoch 44.705), train_loss = 0.93294226, grad/param norm = 7.2485e-02, time/batch = 0.1142s	
4695/5250 (epoch 44.714), train_loss = 0.95925878, grad/param norm = 7.3821e-02, time/batch = 0.1143s	
4696/5250 (epoch 44.724), train_loss = 0.94181663, grad/param norm = 7.5579e-02, time/batch = 0.1142s	
4697/5250 (epoch 44.733), train_loss = 0.93063092, grad/param norm = 6.8971e-02, time/batch = 0.1143s	
4698/5250 (epoch 44.743), train_loss = 0.93403666, grad/param norm = 7.4171e-02, time/batch = 0.1135s	
4699/5250 (epoch 44.752), train_loss = 0.92688306, grad/param norm = 6.9576e-02, time/batch = 0.1142s	
4700/5250 (epoch 44.762), train_loss = 0.92827055, grad/param norm = 6.9138e-02, time/batch = 0.1144s	
4701/5250 (epoch 44.771), train_loss = 0.92955816, grad/param norm = 7.2546e-02, time/batch = 0.1148s	
4702/5250 (epoch 44.781), train_loss = 0.94905526, grad/param norm = 7.0946e-02, time/batch = 0.1136s	
4703/5250 (epoch 44.790), train_loss = 0.94838501, grad/param norm = 6.7219e-02, time/batch = 0.1139s	
4704/5250 (epoch 44.800), train_loss = 0.92060422, grad/param norm = 7.4751e-02, time/batch = 0.1141s	
4705/5250 (epoch 44.810), train_loss = 0.94601612, grad/param norm = 7.5019e-02, time/batch = 0.1142s	
4706/5250 (epoch 44.819), train_loss = 0.95272142, grad/param norm = 7.2409e-02, time/batch = 0.1144s	
4707/5250 (epoch 44.829), train_loss = 0.94373056, grad/param norm = 7.4550e-02, time/batch = 0.1142s	
4708/5250 (epoch 44.838), train_loss = 0.92139117, grad/param norm = 7.6651e-02, time/batch = 0.1137s	
4709/5250 (epoch 44.848), train_loss = 0.91461244, grad/param norm = 7.0227e-02, time/batch = 0.1145s	
4710/5250 (epoch 44.857), train_loss = 0.93058287, grad/param norm = 7.2169e-02, time/batch = 0.1143s	
4711/5250 (epoch 44.867), train_loss = 0.93232812, grad/param norm = 7.4176e-02, time/batch = 0.1151s	
4712/5250 (epoch 44.876), train_loss = 0.92275540, grad/param norm = 7.6229e-02, time/batch = 0.1136s	
4713/5250 (epoch 44.886), train_loss = 0.92647853, grad/param norm = 7.4058e-02, time/batch = 0.1139s	
4714/5250 (epoch 44.895), train_loss = 0.94848281, grad/param norm = 7.2619e-02, time/batch = 0.1143s	
4715/5250 (epoch 44.905), train_loss = 0.94269509, grad/param norm = 7.2993e-02, time/batch = 0.1142s	
4716/5250 (epoch 44.914), train_loss = 0.95116148, grad/param norm = 7.4134e-02, time/batch = 0.1142s	
4717/5250 (epoch 44.924), train_loss = 0.95771234, grad/param norm = 7.2091e-02, time/batch = 0.1143s	
4718/5250 (epoch 44.933), train_loss = 0.94622375, grad/param norm = 6.8499e-02, time/batch = 0.1137s	
4719/5250 (epoch 44.943), train_loss = 0.95770707, grad/param norm = 7.5913e-02, time/batch = 0.1142s	
4720/5250 (epoch 44.952), train_loss = 0.96432974, grad/param norm = 7.0828e-02, time/batch = 0.1144s	
4721/5250 (epoch 44.962), train_loss = 0.94769309, grad/param norm = 7.2404e-02, time/batch = 0.1148s	
4722/5250 (epoch 44.971), train_loss = 0.95716956, grad/param norm = 6.8141e-02, time/batch = 0.1136s	
4723/5250 (epoch 44.981), train_loss = 0.95500397, grad/param norm = 7.0295e-02, time/batch = 0.1140s	
4724/5250 (epoch 44.990), train_loss = 0.96294900, grad/param norm = 7.1569e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
4725/5250 (epoch 45.000), train_loss = 0.94683947, grad/param norm = 6.7652e-02, time/batch = 0.1142s	
4726/5250 (epoch 45.010), train_loss = 1.13019561, grad/param norm = 7.4363e-02, time/batch = 0.1142s	
4727/5250 (epoch 45.019), train_loss = 0.94398660, grad/param norm = 7.0139e-02, time/batch = 0.1142s	
4728/5250 (epoch 45.029), train_loss = 0.96378528, grad/param norm = 7.0421e-02, time/batch = 0.1136s	
4729/5250 (epoch 45.038), train_loss = 0.94095454, grad/param norm = 6.8998e-02, time/batch = 0.1144s	
4730/5250 (epoch 45.048), train_loss = 0.91709550, grad/param norm = 6.7259e-02, time/batch = 0.1144s	
4731/5250 (epoch 45.057), train_loss = 0.92382679, grad/param norm = 7.0442e-02, time/batch = 0.1146s	
4732/5250 (epoch 45.067), train_loss = 0.93775376, grad/param norm = 6.9757e-02, time/batch = 0.1137s	
4733/5250 (epoch 45.076), train_loss = 0.95811575, grad/param norm = 7.1530e-02, time/batch = 0.1138s	
4734/5250 (epoch 45.086), train_loss = 0.91362005, grad/param norm = 6.7912e-02, time/batch = 0.1140s	
4735/5250 (epoch 45.095), train_loss = 0.92893719, grad/param norm = 6.7758e-02, time/batch = 0.1142s	
4736/5250 (epoch 45.105), train_loss = 0.95497008, grad/param norm = 7.0261e-02, time/batch = 0.1143s	
4737/5250 (epoch 45.114), train_loss = 0.92562629, grad/param norm = 7.0030e-02, time/batch = 0.1144s	
4738/5250 (epoch 45.124), train_loss = 0.95554906, grad/param norm = 6.8973e-02, time/batch = 0.1137s	
4739/5250 (epoch 45.133), train_loss = 0.93323472, grad/param norm = 6.7949e-02, time/batch = 0.1142s	
4740/5250 (epoch 45.143), train_loss = 0.91170088, grad/param norm = 6.7857e-02, time/batch = 0.1145s	
4741/5250 (epoch 45.152), train_loss = 0.91649481, grad/param norm = 7.1183e-02, time/batch = 0.1150s	
4742/5250 (epoch 45.162), train_loss = 0.93997554, grad/param norm = 7.2056e-02, time/batch = 0.1137s	
4743/5250 (epoch 45.171), train_loss = 0.94078507, grad/param norm = 6.8605e-02, time/batch = 0.1139s	
4744/5250 (epoch 45.181), train_loss = 0.93834297, grad/param norm = 7.2004e-02, time/batch = 0.1140s	
4745/5250 (epoch 45.190), train_loss = 0.93187870, grad/param norm = 7.0485e-02, time/batch = 0.1142s	
4746/5250 (epoch 45.200), train_loss = 0.93676697, grad/param norm = 7.3779e-02, time/batch = 0.1143s	
4747/5250 (epoch 45.210), train_loss = 0.94651388, grad/param norm = 7.1678e-02, time/batch = 0.1143s	
4748/5250 (epoch 45.219), train_loss = 0.97912374, grad/param norm = 7.6412e-02, time/batch = 0.1138s	
4749/5250 (epoch 45.229), train_loss = 0.94087636, grad/param norm = 7.0190e-02, time/batch = 0.1144s	
4750/5250 (epoch 45.238), train_loss = 0.93700024, grad/param norm = 7.1808e-02, time/batch = 0.1144s	
4751/5250 (epoch 45.248), train_loss = 0.94099947, grad/param norm = 7.5603e-02, time/batch = 0.1148s	
4752/5250 (epoch 45.257), train_loss = 0.94080650, grad/param norm = 7.1480e-02, time/batch = 0.1136s	
4753/5250 (epoch 45.267), train_loss = 0.94061922, grad/param norm = 6.9661e-02, time/batch = 0.1138s	
4754/5250 (epoch 45.276), train_loss = 0.92469688, grad/param norm = 7.5792e-02, time/batch = 0.1142s	
4755/5250 (epoch 45.286), train_loss = 0.90155408, grad/param norm = 7.3942e-02, time/batch = 0.1143s	
4756/5250 (epoch 45.295), train_loss = 0.92864362, grad/param norm = 6.9088e-02, time/batch = 0.1141s	
4757/5250 (epoch 45.305), train_loss = 0.92687648, grad/param norm = 7.4614e-02, time/batch = 0.1141s	
4758/5250 (epoch 45.314), train_loss = 0.92701552, grad/param norm = 7.0914e-02, time/batch = 0.1137s	
4759/5250 (epoch 45.324), train_loss = 0.93689498, grad/param norm = 7.0412e-02, time/batch = 0.1143s	
4760/5250 (epoch 45.333), train_loss = 0.93788067, grad/param norm = 6.9500e-02, time/batch = 0.1141s	
4761/5250 (epoch 45.343), train_loss = 0.93638211, grad/param norm = 7.3947e-02, time/batch = 0.1149s	
4762/5250 (epoch 45.352), train_loss = 0.94960348, grad/param norm = 7.0803e-02, time/batch = 0.1136s	
4763/5250 (epoch 45.362), train_loss = 0.94293728, grad/param norm = 7.0869e-02, time/batch = 0.1141s	
4764/5250 (epoch 45.371), train_loss = 0.92344510, grad/param norm = 7.1301e-02, time/batch = 0.1142s	
4765/5250 (epoch 45.381), train_loss = 0.92930196, grad/param norm = 6.8841e-02, time/batch = 0.1142s	
4766/5250 (epoch 45.390), train_loss = 0.93197829, grad/param norm = 7.1166e-02, time/batch = 0.1143s	
4767/5250 (epoch 45.400), train_loss = 0.92438966, grad/param norm = 7.1069e-02, time/batch = 0.1142s	
4768/5250 (epoch 45.410), train_loss = 0.93052794, grad/param norm = 7.2442e-02, time/batch = 0.1137s	
4769/5250 (epoch 45.419), train_loss = 0.93352998, grad/param norm = 7.2030e-02, time/batch = 0.1143s	
4770/5250 (epoch 45.429), train_loss = 0.94161428, grad/param norm = 7.1742e-02, time/batch = 0.1145s	
4771/5250 (epoch 45.438), train_loss = 0.93718159, grad/param norm = 7.0543e-02, time/batch = 0.1148s	
4772/5250 (epoch 45.448), train_loss = 0.92664480, grad/param norm = 7.3950e-02, time/batch = 0.1137s	
4773/5250 (epoch 45.457), train_loss = 0.94607500, grad/param norm = 7.5931e-02, time/batch = 0.1140s	
4774/5250 (epoch 45.467), train_loss = 0.93945572, grad/param norm = 7.1558e-02, time/batch = 0.1143s	
4775/5250 (epoch 45.476), train_loss = 0.93249742, grad/param norm = 7.2112e-02, time/batch = 0.1141s	
4776/5250 (epoch 45.486), train_loss = 0.95814504, grad/param norm = 7.5625e-02, time/batch = 0.1141s	
4777/5250 (epoch 45.495), train_loss = 0.94755717, grad/param norm = 7.4493e-02, time/batch = 0.1145s	
4778/5250 (epoch 45.505), train_loss = 0.95325754, grad/param norm = 6.9777e-02, time/batch = 0.1135s	
4779/5250 (epoch 45.514), train_loss = 0.93949530, grad/param norm = 7.3683e-02, time/batch = 0.1144s	
4780/5250 (epoch 45.524), train_loss = 0.94225420, grad/param norm = 7.0613e-02, time/batch = 0.1144s	
4781/5250 (epoch 45.533), train_loss = 0.94689395, grad/param norm = 7.0615e-02, time/batch = 0.1147s	
4782/5250 (epoch 45.543), train_loss = 0.93020057, grad/param norm = 7.0651e-02, time/batch = 0.1137s	
4783/5250 (epoch 45.552), train_loss = 0.94108852, grad/param norm = 6.8776e-02, time/batch = 0.1140s	
4784/5250 (epoch 45.562), train_loss = 0.94526360, grad/param norm = 6.8064e-02, time/batch = 0.1142s	
4785/5250 (epoch 45.571), train_loss = 0.94549091, grad/param norm = 7.1619e-02, time/batch = 0.1144s	
4786/5250 (epoch 45.581), train_loss = 0.94114576, grad/param norm = 7.2398e-02, time/batch = 0.1142s	
4787/5250 (epoch 45.590), train_loss = 0.93873935, grad/param norm = 6.9480e-02, time/batch = 0.1142s	
4788/5250 (epoch 45.600), train_loss = 0.95503457, grad/param norm = 7.3427e-02, time/batch = 0.1137s	
4789/5250 (epoch 45.610), train_loss = 0.95095270, grad/param norm = 7.5273e-02, time/batch = 0.1141s	
4790/5250 (epoch 45.619), train_loss = 0.94606127, grad/param norm = 6.9916e-02, time/batch = 0.1145s	
4791/5250 (epoch 45.629), train_loss = 0.93675797, grad/param norm = 6.8144e-02, time/batch = 0.1149s	
4792/5250 (epoch 45.638), train_loss = 0.94361321, grad/param norm = 7.1963e-02, time/batch = 0.1138s	
4793/5250 (epoch 45.648), train_loss = 0.95563772, grad/param norm = 6.8731e-02, time/batch = 0.1142s	
4794/5250 (epoch 45.657), train_loss = 0.93365445, grad/param norm = 6.8782e-02, time/batch = 0.1143s	
4795/5250 (epoch 45.667), train_loss = 0.93438089, grad/param norm = 7.0017e-02, time/batch = 0.1143s	
4796/5250 (epoch 45.676), train_loss = 0.93392948, grad/param norm = 6.8453e-02, time/batch = 0.1142s	
4797/5250 (epoch 45.686), train_loss = 0.94968325, grad/param norm = 6.9742e-02, time/batch = 0.1142s	
4798/5250 (epoch 45.695), train_loss = 0.94976948, grad/param norm = 7.1614e-02, time/batch = 0.1138s	
4799/5250 (epoch 45.705), train_loss = 0.92631121, grad/param norm = 7.1342e-02, time/batch = 0.1144s	
4800/5250 (epoch 45.714), train_loss = 0.95142130, grad/param norm = 7.0454e-02, time/batch = 0.1143s	
4801/5250 (epoch 45.724), train_loss = 0.93444390, grad/param norm = 7.3965e-02, time/batch = 0.1149s	
4802/5250 (epoch 45.733), train_loss = 0.92348323, grad/param norm = 6.8872e-02, time/batch = 0.1135s	
4803/5250 (epoch 45.743), train_loss = 0.92663342, grad/param norm = 7.3123e-02, time/batch = 0.1140s	
4804/5250 (epoch 45.752), train_loss = 0.92037448, grad/param norm = 6.9731e-02, time/batch = 0.1140s	
4805/5250 (epoch 45.762), train_loss = 0.92310908, grad/param norm = 7.1272e-02, time/batch = 0.1141s	
4806/5250 (epoch 45.771), train_loss = 0.92240272, grad/param norm = 6.7934e-02, time/batch = 0.1143s	
4807/5250 (epoch 45.781), train_loss = 0.94308114, grad/param norm = 7.3356e-02, time/batch = 0.1140s	
4808/5250 (epoch 45.790), train_loss = 0.94519213, grad/param norm = 7.7781e-02, time/batch = 0.1136s	
4809/5250 (epoch 45.800), train_loss = 0.91674648, grad/param norm = 7.2280e-02, time/batch = 0.1142s	
4810/5250 (epoch 45.810), train_loss = 0.93887314, grad/param norm = 7.6298e-02, time/batch = 0.1144s	
4811/5250 (epoch 45.819), train_loss = 0.94797916, grad/param norm = 7.4369e-02, time/batch = 0.1147s	
4812/5250 (epoch 45.829), train_loss = 0.93705248, grad/param norm = 7.4918e-02, time/batch = 0.1136s	
4813/5250 (epoch 45.838), train_loss = 0.91321861, grad/param norm = 6.9269e-02, time/batch = 0.1139s	
4814/5250 (epoch 45.848), train_loss = 0.90823486, grad/param norm = 7.2531e-02, time/batch = 0.1143s	
4815/5250 (epoch 45.857), train_loss = 0.92552107, grad/param norm = 7.8420e-02, time/batch = 0.1142s	
4816/5250 (epoch 45.867), train_loss = 0.92717119, grad/param norm = 7.3002e-02, time/batch = 0.1141s	
4817/5250 (epoch 45.876), train_loss = 0.91515258, grad/param norm = 7.3199e-02, time/batch = 0.1141s	
4818/5250 (epoch 45.886), train_loss = 0.91994765, grad/param norm = 7.4100e-02, time/batch = 0.1136s	
4819/5250 (epoch 45.895), train_loss = 0.94119968, grad/param norm = 7.2145e-02, time/batch = 0.1141s	
4820/5250 (epoch 45.905), train_loss = 0.93596631, grad/param norm = 7.2310e-02, time/batch = 0.1143s	
4821/5250 (epoch 45.914), train_loss = 0.94408726, grad/param norm = 7.4137e-02, time/batch = 0.1148s	
4822/5250 (epoch 45.924), train_loss = 0.95124155, grad/param norm = 6.9896e-02, time/batch = 0.1138s	
4823/5250 (epoch 45.933), train_loss = 0.94099720, grad/param norm = 7.2480e-02, time/batch = 0.1140s	
4824/5250 (epoch 45.943), train_loss = 0.95115842, grad/param norm = 7.3230e-02, time/batch = 0.1142s	
4825/5250 (epoch 45.952), train_loss = 0.95791795, grad/param norm = 7.1485e-02, time/batch = 0.1144s	
4826/5250 (epoch 45.962), train_loss = 0.94232821, grad/param norm = 7.0854e-02, time/batch = 0.1143s	
4827/5250 (epoch 45.971), train_loss = 0.95053498, grad/param norm = 7.1656e-02, time/batch = 0.1143s	
4828/5250 (epoch 45.981), train_loss = 0.94858252, grad/param norm = 6.9770e-02, time/batch = 0.1136s	
4829/5250 (epoch 45.990), train_loss = 0.95590986, grad/param norm = 7.0457e-02, time/batch = 0.1144s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
4830/5250 (epoch 46.000), train_loss = 0.94257143, grad/param norm = 6.8228e-02, time/batch = 0.1143s	
4831/5250 (epoch 46.010), train_loss = 1.12504479, grad/param norm = 7.4192e-02, time/batch = 0.1148s	
4832/5250 (epoch 46.019), train_loss = 0.93784354, grad/param norm = 7.0142e-02, time/batch = 0.1136s	
4833/5250 (epoch 46.029), train_loss = 0.95716802, grad/param norm = 7.0383e-02, time/batch = 0.1139s	
4834/5250 (epoch 46.038), train_loss = 0.93470384, grad/param norm = 6.8994e-02, time/batch = 0.1140s	
4835/5250 (epoch 46.048), train_loss = 0.91129199, grad/param norm = 6.7830e-02, time/batch = 0.1142s	
4836/5250 (epoch 46.057), train_loss = 0.91755153, grad/param norm = 6.9578e-02, time/batch = 0.1141s	
4837/5250 (epoch 46.067), train_loss = 0.93180464, grad/param norm = 7.2879e-02, time/batch = 0.1143s	
4838/5250 (epoch 46.076), train_loss = 0.95155700, grad/param norm = 6.9534e-02, time/batch = 0.1137s	
4839/5250 (epoch 46.086), train_loss = 0.90779065, grad/param norm = 6.8703e-02, time/batch = 0.1142s	
4840/5250 (epoch 46.095), train_loss = 0.92479971, grad/param norm = 6.8745e-02, time/batch = 0.1145s	
4841/5250 (epoch 46.105), train_loss = 0.94888866, grad/param norm = 7.1241e-02, time/batch = 0.1147s	
4842/5250 (epoch 46.114), train_loss = 0.91965959, grad/param norm = 7.0468e-02, time/batch = 0.1137s	
4843/5250 (epoch 46.124), train_loss = 0.95020020, grad/param norm = 7.0378e-02, time/batch = 0.1139s	
4844/5250 (epoch 46.133), train_loss = 0.92756829, grad/param norm = 6.7987e-02, time/batch = 0.1142s	
4845/5250 (epoch 46.143), train_loss = 0.90580122, grad/param norm = 6.9114e-02, time/batch = 0.1142s	
4846/5250 (epoch 46.152), train_loss = 0.91076234, grad/param norm = 7.1862e-02, time/batch = 0.1144s	
4847/5250 (epoch 46.162), train_loss = 0.93405430, grad/param norm = 7.3133e-02, time/batch = 0.1142s	
4848/5250 (epoch 46.171), train_loss = 0.93492767, grad/param norm = 6.9692e-02, time/batch = 0.1136s	
4849/5250 (epoch 46.181), train_loss = 0.93238426, grad/param norm = 7.0940e-02, time/batch = 0.1145s	
4850/5250 (epoch 46.190), train_loss = 0.92658071, grad/param norm = 7.1610e-02, time/batch = 0.1143s	
4851/5250 (epoch 46.200), train_loss = 0.93167649, grad/param norm = 7.6739e-02, time/batch = 0.1148s	
4852/5250 (epoch 46.210), train_loss = 0.94077531, grad/param norm = 7.2154e-02, time/batch = 0.1136s	
4853/5250 (epoch 46.219), train_loss = 0.97240625, grad/param norm = 7.5429e-02, time/batch = 0.1141s	
4854/5250 (epoch 46.229), train_loss = 0.93510198, grad/param norm = 7.1238e-02, time/batch = 0.1142s	
4855/5250 (epoch 46.238), train_loss = 0.92971793, grad/param norm = 7.0738e-02, time/batch = 0.1144s	
4856/5250 (epoch 46.248), train_loss = 0.93339423, grad/param norm = 7.1043e-02, time/batch = 0.1143s	
4857/5250 (epoch 46.257), train_loss = 0.93438449, grad/param norm = 7.2927e-02, time/batch = 0.1143s	
4858/5250 (epoch 46.267), train_loss = 0.93585970, grad/param norm = 7.2820e-02, time/batch = 0.1136s	
4859/5250 (epoch 46.276), train_loss = 0.91826132, grad/param norm = 7.2303e-02, time/batch = 0.1144s	
4860/5250 (epoch 46.286), train_loss = 0.89540805, grad/param norm = 7.2041e-02, time/batch = 0.1143s	
4861/5250 (epoch 46.295), train_loss = 0.92367771, grad/param norm = 7.6706e-02, time/batch = 0.1147s	
4862/5250 (epoch 46.305), train_loss = 0.92230572, grad/param norm = 7.5675e-02, time/batch = 0.1136s	
4863/5250 (epoch 46.314), train_loss = 0.92026618, grad/param norm = 6.9382e-02, time/batch = 0.1139s	
4864/5250 (epoch 46.324), train_loss = 0.93139414, grad/param norm = 7.1575e-02, time/batch = 0.1140s	
4865/5250 (epoch 46.333), train_loss = 0.93300215, grad/param norm = 7.3215e-02, time/batch = 0.1144s	
4866/5250 (epoch 46.343), train_loss = 0.92976522, grad/param norm = 7.0872e-02, time/batch = 0.1144s	
4867/5250 (epoch 46.352), train_loss = 0.94473802, grad/param norm = 7.4179e-02, time/batch = 0.1140s	
4868/5250 (epoch 46.362), train_loss = 0.93813072, grad/param norm = 7.0561e-02, time/batch = 0.1137s	
4869/5250 (epoch 46.371), train_loss = 0.91715674, grad/param norm = 7.0415e-02, time/batch = 0.1155s	
4870/5250 (epoch 46.381), train_loss = 0.92446612, grad/param norm = 7.0171e-02, time/batch = 0.1141s	
4871/5250 (epoch 46.390), train_loss = 0.92572248, grad/param norm = 7.2251e-02, time/batch = 0.1155s	
4872/5250 (epoch 46.400), train_loss = 0.91797046, grad/param norm = 6.8348e-02, time/batch = 0.1137s	
4873/5250 (epoch 46.410), train_loss = 0.92265248, grad/param norm = 7.0069e-02, time/batch = 0.1140s	
4874/5250 (epoch 46.419), train_loss = 0.92656506, grad/param norm = 6.7810e-02, time/batch = 0.1141s	
4875/5250 (epoch 46.429), train_loss = 0.93816462, grad/param norm = 7.7562e-02, time/batch = 0.1143s	
4876/5250 (epoch 46.438), train_loss = 0.93262564, grad/param norm = 7.1708e-02, time/batch = 0.1145s	
4877/5250 (epoch 46.448), train_loss = 0.92012049, grad/param norm = 7.1001e-02, time/batch = 0.1141s	
4878/5250 (epoch 46.457), train_loss = 0.94141419, grad/param norm = 7.6615e-02, time/batch = 0.1138s	
4879/5250 (epoch 46.467), train_loss = 0.93334529, grad/param norm = 7.3774e-02, time/batch = 0.1145s	
4880/5250 (epoch 46.476), train_loss = 0.92678928, grad/param norm = 7.3359e-02, time/batch = 0.1144s	
4881/5250 (epoch 46.486), train_loss = 0.95303779, grad/param norm = 8.1577e-02, time/batch = 0.1148s	
4882/5250 (epoch 46.495), train_loss = 0.94251502, grad/param norm = 7.3052e-02, time/batch = 0.1136s	
4883/5250 (epoch 46.505), train_loss = 0.94732176, grad/param norm = 7.0690e-02, time/batch = 0.1141s	
4884/5250 (epoch 46.514), train_loss = 0.93411680, grad/param norm = 7.4549e-02, time/batch = 0.1141s	
4885/5250 (epoch 46.524), train_loss = 0.93676996, grad/param norm = 7.0483e-02, time/batch = 0.1143s	
4886/5250 (epoch 46.533), train_loss = 0.94144760, grad/param norm = 7.1360e-02, time/batch = 0.1143s	
4887/5250 (epoch 46.543), train_loss = 0.92378516, grad/param norm = 7.0430e-02, time/batch = 0.1140s	
4888/5250 (epoch 46.552), train_loss = 0.93506772, grad/param norm = 7.0609e-02, time/batch = 0.1137s	
4889/5250 (epoch 46.562), train_loss = 0.94046887, grad/param norm = 7.0820e-02, time/batch = 0.1143s	
4890/5250 (epoch 46.571), train_loss = 0.94165745, grad/param norm = 7.4242e-02, time/batch = 0.1143s	
4891/5250 (epoch 46.581), train_loss = 0.93514038, grad/param norm = 7.7179e-02, time/batch = 0.1148s	
4892/5250 (epoch 46.590), train_loss = 0.93556662, grad/param norm = 7.1598e-02, time/batch = 0.1136s	
4893/5250 (epoch 46.600), train_loss = 0.94840558, grad/param norm = 7.3038e-02, time/batch = 0.1139s	
4894/5250 (epoch 46.610), train_loss = 0.94367742, grad/param norm = 7.2999e-02, time/batch = 0.1141s	
4895/5250 (epoch 46.619), train_loss = 0.94083248, grad/param norm = 7.1438e-02, time/batch = 0.1143s	
4896/5250 (epoch 46.629), train_loss = 0.93153037, grad/param norm = 7.0012e-02, time/batch = 0.1143s	
4897/5250 (epoch 46.638), train_loss = 0.93796577, grad/param norm = 7.4080e-02, time/batch = 0.1144s	
4898/5250 (epoch 46.648), train_loss = 0.95128864, grad/param norm = 6.8745e-02, time/batch = 0.1137s	
4899/5250 (epoch 46.657), train_loss = 0.92833281, grad/param norm = 7.2122e-02, time/batch = 0.1143s	
4900/5250 (epoch 46.667), train_loss = 0.92846369, grad/param norm = 7.1408e-02, time/batch = 0.1144s	
4901/5250 (epoch 46.676), train_loss = 0.92878352, grad/param norm = 6.9529e-02, time/batch = 0.1148s	
4902/5250 (epoch 46.686), train_loss = 0.94418489, grad/param norm = 7.0814e-02, time/batch = 0.1136s	
4903/5250 (epoch 46.695), train_loss = 0.94331006, grad/param norm = 7.0190e-02, time/batch = 0.1139s	
4904/5250 (epoch 46.705), train_loss = 0.91936862, grad/param norm = 7.0871e-02, time/batch = 0.1140s	
4905/5250 (epoch 46.714), train_loss = 0.94578021, grad/param norm = 7.5881e-02, time/batch = 0.1141s	
4906/5250 (epoch 46.724), train_loss = 0.92842659, grad/param norm = 7.2395e-02, time/batch = 0.1142s	
4907/5250 (epoch 46.733), train_loss = 0.91818369, grad/param norm = 6.9936e-02, time/batch = 0.1143s	
4908/5250 (epoch 46.743), train_loss = 0.92293848, grad/param norm = 7.6979e-02, time/batch = 0.1136s	
4909/5250 (epoch 46.752), train_loss = 0.91456886, grad/param norm = 7.0354e-02, time/batch = 0.1143s	
4910/5250 (epoch 46.762), train_loss = 0.91537905, grad/param norm = 6.8235e-02, time/batch = 0.1145s	
4911/5250 (epoch 46.771), train_loss = 0.91824949, grad/param norm = 7.3059e-02, time/batch = 0.1147s	
4912/5250 (epoch 46.781), train_loss = 0.93612707, grad/param norm = 7.0713e-02, time/batch = 0.1137s	
4913/5250 (epoch 46.790), train_loss = 0.93619119, grad/param norm = 6.9379e-02, time/batch = 0.1139s	
4914/5250 (epoch 46.800), train_loss = 0.90985178, grad/param norm = 7.7605e-02, time/batch = 0.1141s	
4915/5250 (epoch 46.810), train_loss = 0.93528203, grad/param norm = 7.7582e-02, time/batch = 0.1143s	
4916/5250 (epoch 46.819), train_loss = 0.94124030, grad/param norm = 7.6238e-02, time/batch = 0.1141s	
4917/5250 (epoch 46.829), train_loss = 0.93146107, grad/param norm = 7.4866e-02, time/batch = 0.1142s	
4918/5250 (epoch 46.838), train_loss = 0.90878913, grad/param norm = 7.6370e-02, time/batch = 0.1138s	
4919/5250 (epoch 46.848), train_loss = 0.90289770, grad/param norm = 7.2622e-02, time/batch = 0.1144s	
4920/5250 (epoch 46.857), train_loss = 0.91853214, grad/param norm = 7.2029e-02, time/batch = 0.1144s	
4921/5250 (epoch 46.867), train_loss = 0.91990625, grad/param norm = 7.5757e-02, time/batch = 0.1148s	
4922/5250 (epoch 46.876), train_loss = 0.91025242, grad/param norm = 7.7821e-02, time/batch = 0.1137s	
4923/5250 (epoch 46.886), train_loss = 0.91338990, grad/param norm = 7.4069e-02, time/batch = 0.1139s	
4924/5250 (epoch 46.895), train_loss = 0.93390376, grad/param norm = 7.0559e-02, time/batch = 0.1143s	
4925/5250 (epoch 46.905), train_loss = 0.92965702, grad/param norm = 7.1434e-02, time/batch = 0.1143s	
4926/5250 (epoch 46.914), train_loss = 0.93688251, grad/param norm = 7.3627e-02, time/batch = 0.1144s	
4927/5250 (epoch 46.924), train_loss = 0.94507169, grad/param norm = 7.2059e-02, time/batch = 0.1142s	
4928/5250 (epoch 46.933), train_loss = 0.93352842, grad/param norm = 7.0491e-02, time/batch = 0.1137s	
4929/5250 (epoch 46.943), train_loss = 0.94510651, grad/param norm = 7.3006e-02, time/batch = 0.1143s	
4930/5250 (epoch 46.952), train_loss = 0.95168040, grad/param norm = 7.1429e-02, time/batch = 0.1143s	
4931/5250 (epoch 46.962), train_loss = 0.93540218, grad/param norm = 7.2607e-02, time/batch = 0.1149s	
4932/5250 (epoch 46.971), train_loss = 0.94549490, grad/param norm = 7.0910e-02, time/batch = 0.1136s	
4933/5250 (epoch 46.981), train_loss = 0.94210408, grad/param norm = 7.0455e-02, time/batch = 0.1139s	
4934/5250 (epoch 46.990), train_loss = 0.95153746, grad/param norm = 7.2510e-02, time/batch = 0.1141s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
4935/5250 (epoch 47.000), train_loss = 0.93607372, grad/param norm = 6.9375e-02, time/batch = 0.1143s	
4936/5250 (epoch 47.010), train_loss = 1.11979002, grad/param norm = 7.5390e-02, time/batch = 0.1143s	
4937/5250 (epoch 47.019), train_loss = 0.93256469, grad/param norm = 7.1771e-02, time/batch = 0.1141s	
4938/5250 (epoch 47.029), train_loss = 0.95230260, grad/param norm = 7.2181e-02, time/batch = 0.1136s	
4939/5250 (epoch 47.038), train_loss = 0.92927611, grad/param norm = 7.0288e-02, time/batch = 0.1141s	
4940/5250 (epoch 47.048), train_loss = 0.90593783, grad/param norm = 6.7851e-02, time/batch = 0.1142s	
4941/5250 (epoch 47.057), train_loss = 0.91182860, grad/param norm = 7.1585e-02, time/batch = 0.1148s	
4942/5250 (epoch 47.067), train_loss = 0.92571133, grad/param norm = 7.1005e-02, time/batch = 0.1137s	
4943/5250 (epoch 47.076), train_loss = 0.94598308, grad/param norm = 7.0939e-02, time/batch = 0.1141s	
4944/5250 (epoch 47.086), train_loss = 0.90288999, grad/param norm = 7.0527e-02, time/batch = 0.1140s	
4945/5250 (epoch 47.095), train_loss = 0.91949097, grad/param norm = 6.8555e-02, time/batch = 0.1145s	
4946/5250 (epoch 47.105), train_loss = 0.94265118, grad/param norm = 7.1883e-02, time/batch = 0.1143s	
4947/5250 (epoch 47.114), train_loss = 0.91407569, grad/param norm = 7.2596e-02, time/batch = 0.1143s	
4948/5250 (epoch 47.124), train_loss = 0.94527061, grad/param norm = 7.0912e-02, time/batch = 0.1135s	
4949/5250 (epoch 47.133), train_loss = 0.92111668, grad/param norm = 6.9156e-02, time/batch = 0.1142s	
4950/5250 (epoch 47.143), train_loss = 0.89950132, grad/param norm = 6.9412e-02, time/batch = 0.1144s	
4951/5250 (epoch 47.152), train_loss = 0.90433367, grad/param norm = 7.1004e-02, time/batch = 0.1149s	
4952/5250 (epoch 47.162), train_loss = 0.92799734, grad/param norm = 7.4169e-02, time/batch = 0.1139s	
4953/5250 (epoch 47.171), train_loss = 0.92922433, grad/param norm = 7.0089e-02, time/batch = 0.1141s	
4954/5250 (epoch 47.181), train_loss = 0.92703603, grad/param norm = 7.2882e-02, time/batch = 0.1143s	
4955/5250 (epoch 47.190), train_loss = 0.92089757, grad/param norm = 7.1642e-02, time/batch = 0.1143s	
4956/5250 (epoch 47.200), train_loss = 0.92530239, grad/param norm = 7.5245e-02, time/batch = 0.1141s	
4957/5250 (epoch 47.210), train_loss = 0.93467589, grad/param norm = 7.2223e-02, time/batch = 0.1141s	
4958/5250 (epoch 47.219), train_loss = 0.96805065, grad/param norm = 7.6316e-02, time/batch = 0.1136s	
4959/5250 (epoch 47.229), train_loss = 0.92961485, grad/param norm = 7.1579e-02, time/batch = 0.1143s	
4960/5250 (epoch 47.238), train_loss = 0.92474218, grad/param norm = 7.1331e-02, time/batch = 0.1144s	
4961/5250 (epoch 47.248), train_loss = 0.92816246, grad/param norm = 7.4231e-02, time/batch = 0.1151s	
4962/5250 (epoch 47.257), train_loss = 0.92850513, grad/param norm = 7.2296e-02, time/batch = 0.1138s	
4963/5250 (epoch 47.267), train_loss = 0.93070820, grad/param norm = 7.1282e-02, time/batch = 0.1138s	
4964/5250 (epoch 47.276), train_loss = 0.91335095, grad/param norm = 7.6740e-02, time/batch = 0.1141s	
4965/5250 (epoch 47.286), train_loss = 0.89018640, grad/param norm = 7.3550e-02, time/batch = 0.1143s	
4966/5250 (epoch 47.295), train_loss = 0.91603928, grad/param norm = 6.9261e-02, time/batch = 0.1141s	
4967/5250 (epoch 47.305), train_loss = 0.91643191, grad/param norm = 8.2125e-02, time/batch = 0.1142s	
4968/5250 (epoch 47.314), train_loss = 0.91746487, grad/param norm = 7.6442e-02, time/batch = 0.1139s	
4969/5250 (epoch 47.324), train_loss = 0.92655840, grad/param norm = 7.2900e-02, time/batch = 0.1145s	
4970/5250 (epoch 47.333), train_loss = 0.92699207, grad/param norm = 7.3024e-02, time/batch = 0.1145s	
4971/5250 (epoch 47.343), train_loss = 0.92423724, grad/param norm = 7.6611e-02, time/batch = 0.1148s	
4972/5250 (epoch 47.352), train_loss = 0.93854886, grad/param norm = 7.0921e-02, time/batch = 0.1138s	
4973/5250 (epoch 47.362), train_loss = 0.93157577, grad/param norm = 7.2805e-02, time/batch = 0.1140s	
4974/5250 (epoch 47.371), train_loss = 0.91334524, grad/param norm = 7.4131e-02, time/batch = 0.1143s	
4975/5250 (epoch 47.381), train_loss = 0.91969399, grad/param norm = 7.0455e-02, time/batch = 0.1141s	
4976/5250 (epoch 47.390), train_loss = 0.92061293, grad/param norm = 7.2692e-02, time/batch = 0.1142s	
4977/5250 (epoch 47.400), train_loss = 0.91295051, grad/param norm = 7.1636e-02, time/batch = 0.1140s	
4978/5250 (epoch 47.410), train_loss = 0.91793128, grad/param norm = 7.1156e-02, time/batch = 0.1135s	
4979/5250 (epoch 47.419), train_loss = 0.92103831, grad/param norm = 7.1297e-02, time/batch = 0.1143s	
4980/5250 (epoch 47.429), train_loss = 0.93107924, grad/param norm = 7.3354e-02, time/batch = 0.1145s	
4981/5250 (epoch 47.438), train_loss = 0.92585323, grad/param norm = 7.1079e-02, time/batch = 0.1148s	
4982/5250 (epoch 47.448), train_loss = 0.91464985, grad/param norm = 7.4577e-02, time/batch = 0.1135s	
4983/5250 (epoch 47.457), train_loss = 0.93514691, grad/param norm = 7.7433e-02, time/batch = 0.1140s	
4984/5250 (epoch 47.467), train_loss = 0.92772136, grad/param norm = 7.3091e-02, time/batch = 0.1142s	
4985/5250 (epoch 47.476), train_loss = 0.92075990, grad/param norm = 7.2354e-02, time/batch = 0.1143s	
4986/5250 (epoch 47.486), train_loss = 0.94786926, grad/param norm = 7.9188e-02, time/batch = 0.1141s	
4987/5250 (epoch 47.495), train_loss = 0.93615173, grad/param norm = 7.6481e-02, time/batch = 0.1142s	
4988/5250 (epoch 47.505), train_loss = 0.94251714, grad/param norm = 7.0503e-02, time/batch = 0.1137s	
4989/5250 (epoch 47.514), train_loss = 0.92830293, grad/param norm = 7.5814e-02, time/batch = 0.1143s	
4990/5250 (epoch 47.524), train_loss = 0.93076607, grad/param norm = 7.1237e-02, time/batch = 0.1144s	
4991/5250 (epoch 47.533), train_loss = 0.93476281, grad/param norm = 7.1560e-02, time/batch = 0.1148s	
4992/5250 (epoch 47.543), train_loss = 0.91897056, grad/param norm = 7.2281e-02, time/batch = 0.1135s	
4993/5250 (epoch 47.552), train_loss = 0.92906376, grad/param norm = 6.9343e-02, time/batch = 0.1140s	
4994/5250 (epoch 47.562), train_loss = 0.93496462, grad/param norm = 7.0756e-02, time/batch = 0.1142s	
4995/5250 (epoch 47.571), train_loss = 0.93507799, grad/param norm = 7.3093e-02, time/batch = 0.1142s	
4996/5250 (epoch 47.581), train_loss = 0.92837923, grad/param norm = 7.3269e-02, time/batch = 0.1140s	
4997/5250 (epoch 47.590), train_loss = 0.92792342, grad/param norm = 7.2516e-02, time/batch = 0.1142s	
4998/5250 (epoch 47.600), train_loss = 0.94351280, grad/param norm = 7.5693e-02, time/batch = 0.1136s	
4999/5250 (epoch 47.610), train_loss = 0.93858901, grad/param norm = 7.6226e-02, time/batch = 0.1143s	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch47.62_1.6624.t7	
5000/5250 (epoch 47.619), train_loss = 0.93464298, grad/param norm = 7.0407e-02, time/batch = 0.1143s	
5001/5250 (epoch 47.629), train_loss = 1.47172444, grad/param norm = 1.1114e-01, time/batch = 0.1153s	
5002/5250 (epoch 47.638), train_loss = 0.94811417, grad/param norm = 8.6070e-02, time/batch = 0.1136s	
5003/5250 (epoch 47.648), train_loss = 0.95146270, grad/param norm = 7.6915e-02, time/batch = 0.1140s	
5004/5250 (epoch 47.657), train_loss = 0.92769864, grad/param norm = 7.1150e-02, time/batch = 0.1143s	
5005/5250 (epoch 47.667), train_loss = 0.92580529, grad/param norm = 7.2667e-02, time/batch = 0.1144s	
5006/5250 (epoch 47.676), train_loss = 0.92627678, grad/param norm = 6.9853e-02, time/batch = 0.1143s	
5007/5250 (epoch 47.686), train_loss = 0.93974133, grad/param norm = 7.2122e-02, time/batch = 0.1142s	
5008/5250 (epoch 47.695), train_loss = 0.93962613, grad/param norm = 7.4353e-02, time/batch = 0.1138s	
5009/5250 (epoch 47.705), train_loss = 0.91511029, grad/param norm = 7.2255e-02, time/batch = 0.1145s	
5010/5250 (epoch 47.714), train_loss = 0.94136657, grad/param norm = 7.3267e-02, time/batch = 0.1145s	
5011/5250 (epoch 47.724), train_loss = 0.92466723, grad/param norm = 7.5651e-02, time/batch = 0.1150s	
5012/5250 (epoch 47.733), train_loss = 0.91227172, grad/param norm = 6.9840e-02, time/batch = 0.1136s	
5013/5250 (epoch 47.743), train_loss = 0.91550553, grad/param norm = 7.2223e-02, time/batch = 0.1139s	
5014/5250 (epoch 47.752), train_loss = 0.90986017, grad/param norm = 7.2556e-02, time/batch = 0.1142s	
5015/5250 (epoch 47.762), train_loss = 0.91186762, grad/param norm = 7.3547e-02, time/batch = 0.1143s	
5016/5250 (epoch 47.771), train_loss = 0.91385709, grad/param norm = 7.2202e-02, time/batch = 0.1143s	
5017/5250 (epoch 47.781), train_loss = 0.93047426, grad/param norm = 7.2415e-02, time/batch = 0.1142s	
5018/5250 (epoch 47.790), train_loss = 0.93089910, grad/param norm = 7.0160e-02, time/batch = 0.1137s	
5019/5250 (epoch 47.800), train_loss = 0.90415407, grad/param norm = 7.3516e-02, time/batch = 0.1143s	
5020/5250 (epoch 47.810), train_loss = 0.92786523, grad/param norm = 7.3850e-02, time/batch = 0.1144s	
5021/5250 (epoch 47.819), train_loss = 0.93433521, grad/param norm = 7.2105e-02, time/batch = 0.1149s	
5022/5250 (epoch 47.829), train_loss = 0.92454247, grad/param norm = 7.4137e-02, time/batch = 0.1136s	
5023/5250 (epoch 47.838), train_loss = 0.90119887, grad/param norm = 6.9313e-02, time/batch = 0.1139s	
5024/5250 (epoch 47.848), train_loss = 0.89534821, grad/param norm = 7.3455e-02, time/batch = 0.1140s	
5025/5250 (epoch 47.857), train_loss = 0.91378474, grad/param norm = 7.6339e-02, time/batch = 0.1141s	
5026/5250 (epoch 47.867), train_loss = 0.91481101, grad/param norm = 7.3839e-02, time/batch = 0.1141s	
5027/5250 (epoch 47.876), train_loss = 0.90331659, grad/param norm = 7.3390e-02, time/batch = 0.1140s	
5028/5250 (epoch 47.886), train_loss = 0.90743531, grad/param norm = 7.5815e-02, time/batch = 0.1137s	
5029/5250 (epoch 47.895), train_loss = 0.92980290, grad/param norm = 7.5441e-02, time/batch = 0.1143s	
5030/5250 (epoch 47.905), train_loss = 0.92421579, grad/param norm = 7.5140e-02, time/batch = 0.1142s	
5031/5250 (epoch 47.914), train_loss = 0.93125214, grad/param norm = 7.4832e-02, time/batch = 0.1148s	
5032/5250 (epoch 47.924), train_loss = 0.93822098, grad/param norm = 7.1682e-02, time/batch = 0.1137s	
5033/5250 (epoch 47.933), train_loss = 0.92749618, grad/param norm = 6.9927e-02, time/batch = 0.1138s	
5034/5250 (epoch 47.943), train_loss = 0.93924010, grad/param norm = 7.7195e-02, time/batch = 0.1142s	
5035/5250 (epoch 47.952), train_loss = 0.94631998, grad/param norm = 6.9595e-02, time/batch = 0.1142s	
5036/5250 (epoch 47.962), train_loss = 0.92913972, grad/param norm = 7.1693e-02, time/batch = 0.1142s	
5037/5250 (epoch 47.971), train_loss = 0.94002165, grad/param norm = 7.2724e-02, time/batch = 0.1141s	
5038/5250 (epoch 47.981), train_loss = 0.93601350, grad/param norm = 7.0458e-02, time/batch = 0.1135s	
5039/5250 (epoch 47.990), train_loss = 0.94483585, grad/param norm = 7.2331e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
5040/5250 (epoch 48.000), train_loss = 0.93241980, grad/param norm = 6.9757e-02, time/batch = 0.1143s	
5041/5250 (epoch 48.010), train_loss = 1.11324771, grad/param norm = 7.4364e-02, time/batch = 0.1150s	
5042/5250 (epoch 48.019), train_loss = 0.92704185, grad/param norm = 7.2637e-02, time/batch = 0.1137s	
5043/5250 (epoch 48.029), train_loss = 0.94596713, grad/param norm = 7.1033e-02, time/batch = 0.1140s	
5044/5250 (epoch 48.038), train_loss = 0.92373138, grad/param norm = 7.0168e-02, time/batch = 0.1142s	
5045/5250 (epoch 48.048), train_loss = 0.90029714, grad/param norm = 6.9402e-02, time/batch = 0.1142s	
5046/5250 (epoch 48.057), train_loss = 0.90563847, grad/param norm = 7.0291e-02, time/batch = 0.1142s	
5047/5250 (epoch 48.067), train_loss = 0.92026575, grad/param norm = 7.5354e-02, time/batch = 0.1142s	
5048/5250 (epoch 48.076), train_loss = 0.94097476, grad/param norm = 7.1664e-02, time/batch = 0.1137s	
5049/5250 (epoch 48.086), train_loss = 0.89669923, grad/param norm = 6.9184e-02, time/batch = 0.1144s	
5050/5250 (epoch 48.095), train_loss = 0.91450920, grad/param norm = 7.0346e-02, time/batch = 0.1141s	
5051/5250 (epoch 48.105), train_loss = 0.93748724, grad/param norm = 7.2148e-02, time/batch = 0.1150s	
5052/5250 (epoch 48.114), train_loss = 0.90735332, grad/param norm = 7.1442e-02, time/batch = 0.1136s	
5053/5250 (epoch 48.124), train_loss = 0.93961294, grad/param norm = 7.2410e-02, time/batch = 0.1140s	
5054/5250 (epoch 48.133), train_loss = 0.91668056, grad/param norm = 6.9914e-02, time/batch = 0.1140s	
5055/5250 (epoch 48.143), train_loss = 0.89455516, grad/param norm = 7.1419e-02, time/batch = 0.1142s	
5056/5250 (epoch 48.152), train_loss = 0.89930445, grad/param norm = 7.3792e-02, time/batch = 0.1141s	
5057/5250 (epoch 48.162), train_loss = 0.92205231, grad/param norm = 7.4039e-02, time/batch = 0.1143s	
5058/5250 (epoch 48.171), train_loss = 0.92321773, grad/param norm = 7.0401e-02, time/batch = 0.1137s	
5059/5250 (epoch 48.181), train_loss = 0.92150785, grad/param norm = 7.2602e-02, time/batch = 0.1141s	
5060/5250 (epoch 48.190), train_loss = 0.91575473, grad/param norm = 7.3367e-02, time/batch = 0.1141s	
5061/5250 (epoch 48.200), train_loss = 0.91962631, grad/param norm = 7.6691e-02, time/batch = 0.1149s	
5062/5250 (epoch 48.210), train_loss = 0.92969607, grad/param norm = 7.3290e-02, time/batch = 0.1138s	
5063/5250 (epoch 48.219), train_loss = 0.96250005, grad/param norm = 7.6481e-02, time/batch = 0.1138s	
5064/5250 (epoch 48.229), train_loss = 0.92400834, grad/param norm = 7.3069e-02, time/batch = 0.1141s	
5065/5250 (epoch 48.238), train_loss = 0.91851582, grad/param norm = 7.1558e-02, time/batch = 0.1142s	
5066/5250 (epoch 48.248), train_loss = 0.92158988, grad/param norm = 7.3297e-02, time/batch = 0.1142s	
5067/5250 (epoch 48.257), train_loss = 0.92303219, grad/param norm = 7.3621e-02, time/batch = 0.1142s	
5068/5250 (epoch 48.267), train_loss = 0.92429852, grad/param norm = 7.2224e-02, time/batch = 0.1136s	
5069/5250 (epoch 48.276), train_loss = 0.90787559, grad/param norm = 7.5309e-02, time/batch = 0.1143s	
5070/5250 (epoch 48.286), train_loss = 0.88405285, grad/param norm = 7.3009e-02, time/batch = 0.1143s	
5071/5250 (epoch 48.295), train_loss = 0.91100689, grad/param norm = 7.5054e-02, time/batch = 0.1148s	
5072/5250 (epoch 48.305), train_loss = 0.91035523, grad/param norm = 7.6396e-02, time/batch = 0.1137s	
5073/5250 (epoch 48.314), train_loss = 0.90929950, grad/param norm = 7.0463e-02, time/batch = 0.1139s	
5074/5250 (epoch 48.324), train_loss = 0.91993903, grad/param norm = 7.2384e-02, time/batch = 0.1142s	
5075/5250 (epoch 48.333), train_loss = 0.92187146, grad/param norm = 7.5437e-02, time/batch = 0.1143s	
5076/5250 (epoch 48.343), train_loss = 0.91793778, grad/param norm = 7.1710e-02, time/batch = 0.1142s	
5077/5250 (epoch 48.352), train_loss = 0.93409656, grad/param norm = 7.8680e-02, time/batch = 0.1143s	
5078/5250 (epoch 48.362), train_loss = 0.92787512, grad/param norm = 7.2556e-02, time/batch = 0.1137s	
5079/5250 (epoch 48.371), train_loss = 0.90662407, grad/param norm = 7.1885e-02, time/batch = 0.1144s	
5080/5250 (epoch 48.381), train_loss = 0.91506845, grad/param norm = 7.2623e-02, time/batch = 0.1142s	
5081/5250 (epoch 48.390), train_loss = 0.91481841, grad/param norm = 7.4076e-02, time/batch = 0.1155s	
5082/5250 (epoch 48.400), train_loss = 0.90697375, grad/param norm = 6.9610e-02, time/batch = 0.1138s	
5083/5250 (epoch 48.410), train_loss = 0.91207701, grad/param norm = 7.1697e-02, time/batch = 0.1139s	
5084/5250 (epoch 48.419), train_loss = 0.91557989, grad/param norm = 7.0690e-02, time/batch = 0.1142s	
5085/5250 (epoch 48.429), train_loss = 0.92730720, grad/param norm = 7.9128e-02, time/batch = 0.1141s	
5086/5250 (epoch 48.438), train_loss = 0.92191773, grad/param norm = 7.2805e-02, time/batch = 0.1141s	
5087/5250 (epoch 48.448), train_loss = 0.90747171, grad/param norm = 7.1373e-02, time/batch = 0.1141s	
5088/5250 (epoch 48.457), train_loss = 0.93075824, grad/param norm = 7.7573e-02, time/batch = 0.1136s	
5089/5250 (epoch 48.467), train_loss = 0.92248982, grad/param norm = 7.6760e-02, time/batch = 0.1143s	
5090/5250 (epoch 48.476), train_loss = 0.91534253, grad/param norm = 7.3785e-02, time/batch = 0.1144s	
5091/5250 (epoch 48.486), train_loss = 0.94256068, grad/param norm = 8.1345e-02, time/batch = 0.1154s	
5092/5250 (epoch 48.495), train_loss = 0.93105174, grad/param norm = 7.5664e-02, time/batch = 0.1136s	
5093/5250 (epoch 48.505), train_loss = 0.93666943, grad/param norm = 7.1120e-02, time/batch = 0.1138s	
5094/5250 (epoch 48.514), train_loss = 0.92361077, grad/param norm = 7.6815e-02, time/batch = 0.1142s	
5095/5250 (epoch 48.524), train_loss = 0.92560661, grad/param norm = 7.0995e-02, time/batch = 0.1142s	
5096/5250 (epoch 48.533), train_loss = 0.92919787, grad/param norm = 7.1981e-02, time/batch = 0.1142s	
5097/5250 (epoch 48.543), train_loss = 0.91270287, grad/param norm = 7.1753e-02, time/batch = 0.1143s	
5098/5250 (epoch 48.552), train_loss = 0.92319384, grad/param norm = 7.0100e-02, time/batch = 0.1137s	
5099/5250 (epoch 48.562), train_loss = 0.92920134, grad/param norm = 6.9666e-02, time/batch = 0.1144s	
5100/5250 (epoch 48.571), train_loss = 0.92975848, grad/param norm = 7.3091e-02, time/batch = 0.1142s	
5101/5250 (epoch 48.581), train_loss = 0.92225157, grad/param norm = 7.5279e-02, time/batch = 0.1149s	
5102/5250 (epoch 48.590), train_loss = 0.92315994, grad/param norm = 7.3554e-02, time/batch = 0.1139s	
5103/5250 (epoch 48.600), train_loss = 0.93591331, grad/param norm = 7.3536e-02, time/batch = 0.1141s	
5104/5250 (epoch 48.610), train_loss = 0.93139574, grad/param norm = 7.2586e-02, time/batch = 0.1142s	
5105/5250 (epoch 48.619), train_loss = 0.92999601, grad/param norm = 7.3906e-02, time/batch = 0.1144s	
5106/5250 (epoch 48.629), train_loss = 0.93311067, grad/param norm = 7.2340e-02, time/batch = 0.1141s	
5107/5250 (epoch 48.638), train_loss = 0.92980478, grad/param norm = 7.6559e-02, time/batch = 0.1141s	
5108/5250 (epoch 48.648), train_loss = 0.94163839, grad/param norm = 6.9853e-02, time/batch = 0.1138s	
5109/5250 (epoch 48.657), train_loss = 0.91906586, grad/param norm = 7.2624e-02, time/batch = 0.1143s	
5110/5250 (epoch 48.667), train_loss = 0.91724776, grad/param norm = 7.2412e-02, time/batch = 0.1143s	
5111/5250 (epoch 48.676), train_loss = 0.91919132, grad/param norm = 6.9928e-02, time/batch = 0.1148s	
5112/5250 (epoch 48.686), train_loss = 0.93516923, grad/param norm = 7.3767e-02, time/batch = 0.1138s	
5113/5250 (epoch 48.695), train_loss = 0.93337225, grad/param norm = 7.1916e-02, time/batch = 0.1139s	
5114/5250 (epoch 48.705), train_loss = 0.90851172, grad/param norm = 7.1785e-02, time/batch = 0.1142s	
5115/5250 (epoch 48.714), train_loss = 0.93417678, grad/param norm = 7.5359e-02, time/batch = 0.1142s	
5116/5250 (epoch 48.724), train_loss = 0.91745680, grad/param norm = 7.2340e-02, time/batch = 0.1140s	
5117/5250 (epoch 48.733), train_loss = 0.90700067, grad/param norm = 7.0327e-02, time/batch = 0.1142s	
5118/5250 (epoch 48.743), train_loss = 0.91090591, grad/param norm = 7.3614e-02, time/batch = 0.1135s	
5119/5250 (epoch 48.752), train_loss = 0.90364829, grad/param norm = 7.1231e-02, time/batch = 0.1143s	
5120/5250 (epoch 48.762), train_loss = 0.90384799, grad/param norm = 7.0391e-02, time/batch = 0.1142s	
5121/5250 (epoch 48.771), train_loss = 0.90789913, grad/param norm = 7.2940e-02, time/batch = 0.1147s	
5122/5250 (epoch 48.781), train_loss = 0.92435000, grad/param norm = 7.1720e-02, time/batch = 0.1136s	
5123/5250 (epoch 48.790), train_loss = 0.92473543, grad/param norm = 7.1528e-02, time/batch = 0.1138s	
5124/5250 (epoch 48.800), train_loss = 0.89778619, grad/param norm = 7.2323e-02, time/batch = 0.1144s	
5125/5250 (epoch 48.810), train_loss = 0.92164899, grad/param norm = 7.4204e-02, time/batch = 0.1143s	
5126/5250 (epoch 48.819), train_loss = 0.92768509, grad/param norm = 7.1904e-02, time/batch = 0.1143s	
5127/5250 (epoch 48.829), train_loss = 0.91859011, grad/param norm = 7.4880e-02, time/batch = 0.1144s	
5128/5250 (epoch 48.838), train_loss = 0.89565061, grad/param norm = 7.0869e-02, time/batch = 0.1136s	
5129/5250 (epoch 48.848), train_loss = 0.88915982, grad/param norm = 7.2596e-02, time/batch = 0.1142s	
5130/5250 (epoch 48.857), train_loss = 0.90723302, grad/param norm = 7.2453e-02, time/batch = 0.1144s	
5131/5250 (epoch 48.867), train_loss = 0.90914866, grad/param norm = 7.6098e-02, time/batch = 0.1150s	
5132/5250 (epoch 48.876), train_loss = 0.89767204, grad/param norm = 7.6721e-02, time/batch = 0.1136s	
5133/5250 (epoch 48.886), train_loss = 0.90170978, grad/param norm = 7.5191e-02, time/batch = 0.1140s	
5134/5250 (epoch 48.895), train_loss = 0.92207388, grad/param norm = 7.1334e-02, time/batch = 0.1142s	
5135/5250 (epoch 48.905), train_loss = 0.91757965, grad/param norm = 7.2865e-02, time/batch = 0.1143s	
5136/5250 (epoch 48.914), train_loss = 0.92527533, grad/param norm = 7.7347e-02, time/batch = 0.1142s	
5137/5250 (epoch 48.924), train_loss = 0.93433673, grad/param norm = 7.5152e-02, time/batch = 0.1142s	
5138/5250 (epoch 48.933), train_loss = 0.92198833, grad/param norm = 7.4287e-02, time/batch = 0.1136s	
5139/5250 (epoch 48.943), train_loss = 0.93408202, grad/param norm = 7.5960e-02, time/batch = 0.1144s	
5140/5250 (epoch 48.952), train_loss = 0.94093890, grad/param norm = 7.4220e-02, time/batch = 0.1144s	
5141/5250 (epoch 48.962), train_loss = 0.92387992, grad/param norm = 7.1501e-02, time/batch = 0.1154s	
5142/5250 (epoch 48.971), train_loss = 0.93400054, grad/param norm = 7.3601e-02, time/batch = 0.1137s	
5143/5250 (epoch 48.981), train_loss = 0.93177688, grad/param norm = 7.1757e-02, time/batch = 0.1138s	
5144/5250 (epoch 48.990), train_loss = 0.93966795, grad/param norm = 7.3670e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
5145/5250 (epoch 49.000), train_loss = 0.92671623, grad/param norm = 7.1526e-02, time/batch = 0.1142s	
5146/5250 (epoch 49.010), train_loss = 1.10990484, grad/param norm = 7.8322e-02, time/batch = 0.1143s	
5147/5250 (epoch 49.019), train_loss = 0.92145908, grad/param norm = 7.2627e-02, time/batch = 0.1143s	
5148/5250 (epoch 49.029), train_loss = 0.94153772, grad/param norm = 7.5403e-02, time/batch = 0.1137s	
5149/5250 (epoch 49.038), train_loss = 0.91881497, grad/param norm = 7.0926e-02, time/batch = 0.1144s	
5150/5250 (epoch 49.048), train_loss = 0.89523953, grad/param norm = 6.9925e-02, time/batch = 0.1141s	
5151/5250 (epoch 49.057), train_loss = 0.90070336, grad/param norm = 7.3218e-02, time/batch = 0.1149s	
5152/5250 (epoch 49.067), train_loss = 0.91503199, grad/param norm = 7.2750e-02, time/batch = 0.1137s	
5153/5250 (epoch 49.076), train_loss = 0.93499614, grad/param norm = 7.1063e-02, time/batch = 0.1139s	
5154/5250 (epoch 49.086), train_loss = 0.89304712, grad/param norm = 7.2279e-02, time/batch = 0.1141s	
5155/5250 (epoch 49.095), train_loss = 0.90998198, grad/param norm = 7.0510e-02, time/batch = 0.1143s	
5156/5250 (epoch 49.105), train_loss = 0.93142527, grad/param norm = 7.2703e-02, time/batch = 0.1141s	
5157/5250 (epoch 49.114), train_loss = 0.90262459, grad/param norm = 7.3578e-02, time/batch = 0.1142s	
5158/5250 (epoch 49.124), train_loss = 0.93437764, grad/param norm = 7.2486e-02, time/batch = 0.1135s	
5159/5250 (epoch 49.133), train_loss = 0.91043032, grad/param norm = 6.9906e-02, time/batch = 0.1142s	
5160/5250 (epoch 49.143), train_loss = 0.88830313, grad/param norm = 7.1208e-02, time/batch = 0.1142s	
5161/5250 (epoch 49.152), train_loss = 0.89387837, grad/param norm = 7.1763e-02, time/batch = 0.1149s	
5162/5250 (epoch 49.162), train_loss = 0.91734838, grad/param norm = 7.6193e-02, time/batch = 0.1137s	
5163/5250 (epoch 49.171), train_loss = 0.91844752, grad/param norm = 7.2304e-02, time/batch = 0.1140s	
5164/5250 (epoch 49.181), train_loss = 0.91640621, grad/param norm = 7.3069e-02, time/batch = 0.1143s	
5165/5250 (epoch 49.190), train_loss = 0.91100399, grad/param norm = 7.5231e-02, time/batch = 0.1143s	
5166/5250 (epoch 49.200), train_loss = 0.91435276, grad/param norm = 7.6410e-02, time/batch = 0.1143s	
5167/5250 (epoch 49.210), train_loss = 0.92384774, grad/param norm = 7.3826e-02, time/batch = 0.1142s	
5168/5250 (epoch 49.219), train_loss = 0.95878317, grad/param norm = 7.8506e-02, time/batch = 0.1137s	
5169/5250 (epoch 49.229), train_loss = 0.91948231, grad/param norm = 7.3610e-02, time/batch = 0.1145s	
5170/5250 (epoch 49.238), train_loss = 0.91413511, grad/param norm = 7.2639e-02, time/batch = 0.1144s	
5171/5250 (epoch 49.248), train_loss = 0.91676230, grad/param norm = 7.5334e-02, time/batch = 0.1157s	
5172/5250 (epoch 49.257), train_loss = 0.91808506, grad/param norm = 7.4150e-02, time/batch = 0.1138s	
5173/5250 (epoch 49.267), train_loss = 0.91953158, grad/param norm = 7.2731e-02, time/batch = 0.1140s	
5174/5250 (epoch 49.276), train_loss = 0.90306554, grad/param norm = 7.6804e-02, time/batch = 0.1141s	
5175/5250 (epoch 49.286), train_loss = 0.87928627, grad/param norm = 7.2918e-02, time/batch = 0.1141s	
5176/5250 (epoch 49.295), train_loss = 0.90484882, grad/param norm = 7.1425e-02, time/batch = 0.1144s	
5177/5250 (epoch 49.305), train_loss = 0.90487781, grad/param norm = 7.8608e-02, time/batch = 0.1142s	
5178/5250 (epoch 49.314), train_loss = 0.90460037, grad/param norm = 7.3361e-02, time/batch = 0.1137s	
5179/5250 (epoch 49.324), train_loss = 0.91399143, grad/param norm = 7.1688e-02, time/batch = 0.1143s	
5180/5250 (epoch 49.333), train_loss = 0.91514211, grad/param norm = 7.2432e-02, time/batch = 0.1143s	
5181/5250 (epoch 49.343), train_loss = 0.91148191, grad/param norm = 7.3257e-02, time/batch = 0.1148s	
5182/5250 (epoch 49.352), train_loss = 0.92717115, grad/param norm = 7.2059e-02, time/batch = 0.1138s	
5183/5250 (epoch 49.362), train_loss = 0.92052920, grad/param norm = 7.4096e-02, time/batch = 0.1149s	
5184/5250 (epoch 49.371), train_loss = 0.90304316, grad/param norm = 7.5933e-02, time/batch = 0.1141s	
5185/5250 (epoch 49.381), train_loss = 0.91059204, grad/param norm = 7.2241e-02, time/batch = 0.1142s	
5186/5250 (epoch 49.390), train_loss = 0.91056686, grad/param norm = 7.5412e-02, time/batch = 0.1141s	
5187/5250 (epoch 49.400), train_loss = 0.90278428, grad/param norm = 7.5019e-02, time/batch = 0.1141s	
5188/5250 (epoch 49.410), train_loss = 0.90798821, grad/param norm = 7.3197e-02, time/batch = 0.1136s	
5189/5250 (epoch 49.419), train_loss = 0.91035659, grad/param norm = 7.4901e-02, time/batch = 0.1144s	
5190/5250 (epoch 49.429), train_loss = 0.92085234, grad/param norm = 7.4430e-02, time/batch = 0.1146s	
5191/5250 (epoch 49.438), train_loss = 0.91571132, grad/param norm = 7.2301e-02, time/batch = 0.1155s	
5192/5250 (epoch 49.448), train_loss = 0.90249191, grad/param norm = 7.5333e-02, time/batch = 0.1136s	
5193/5250 (epoch 49.457), train_loss = 0.92448103, grad/param norm = 7.8139e-02, time/batch = 0.1139s	
5194/5250 (epoch 49.467), train_loss = 0.91715112, grad/param norm = 7.5693e-02, time/batch = 0.1140s	
5195/5250 (epoch 49.476), train_loss = 0.90930883, grad/param norm = 7.3559e-02, time/batch = 0.1144s	
5196/5250 (epoch 49.486), train_loss = 0.93872693, grad/param norm = 8.0391e-02, time/batch = 0.1142s	
5197/5250 (epoch 49.495), train_loss = 0.92574493, grad/param norm = 7.9876e-02, time/batch = 0.1141s	
5198/5250 (epoch 49.505), train_loss = 0.93233176, grad/param norm = 7.1311e-02, time/batch = 0.1137s	
5199/5250 (epoch 49.514), train_loss = 0.91830870, grad/param norm = 7.7376e-02, time/batch = 0.1142s	
5200/5250 (epoch 49.524), train_loss = 0.92024280, grad/param norm = 7.3383e-02, time/batch = 0.1142s	
5201/5250 (epoch 49.533), train_loss = 0.92361264, grad/param norm = 7.2724e-02, time/batch = 0.1146s	
5202/5250 (epoch 49.543), train_loss = 0.90819673, grad/param norm = 7.1967e-02, time/batch = 0.1136s	
5203/5250 (epoch 49.552), train_loss = 0.91825128, grad/param norm = 7.0951e-02, time/batch = 0.1139s	
5204/5250 (epoch 49.562), train_loss = 0.92430587, grad/param norm = 7.0923e-02, time/batch = 0.1142s	
5205/5250 (epoch 49.571), train_loss = 0.92399866, grad/param norm = 7.2692e-02, time/batch = 0.1143s	
5206/5250 (epoch 49.581), train_loss = 0.91714237, grad/param norm = 7.4352e-02, time/batch = 0.1141s	
5207/5250 (epoch 49.590), train_loss = 0.91776323, grad/param norm = 7.4094e-02, time/batch = 0.1142s	
5208/5250 (epoch 49.600), train_loss = 0.93037372, grad/param norm = 7.4681e-02, time/batch = 0.1137s	
5209/5250 (epoch 49.610), train_loss = 0.92612929, grad/param norm = 7.4831e-02, time/batch = 0.1142s	
5210/5250 (epoch 49.619), train_loss = 0.92307505, grad/param norm = 7.1486e-02, time/batch = 0.1142s	
5211/5250 (epoch 49.629), train_loss = 0.92438509, grad/param norm = 7.0942e-02, time/batch = 0.1147s	
5212/5250 (epoch 49.638), train_loss = 0.92370827, grad/param norm = 7.5991e-02, time/batch = 0.1136s	
5213/5250 (epoch 49.648), train_loss = 0.93565228, grad/param norm = 7.0081e-02, time/batch = 0.1138s	
5214/5250 (epoch 49.657), train_loss = 0.91358009, grad/param norm = 7.0604e-02, time/batch = 0.1140s	
5215/5250 (epoch 49.667), train_loss = 0.91115668, grad/param norm = 7.0988e-02, time/batch = 0.1142s	
5216/5250 (epoch 49.676), train_loss = 0.91426518, grad/param norm = 6.9894e-02, time/batch = 0.1139s	
5217/5250 (epoch 49.686), train_loss = 0.92950725, grad/param norm = 7.4818e-02, time/batch = 0.1143s	
5218/5250 (epoch 49.695), train_loss = 0.92891095, grad/param norm = 7.4672e-02, time/batch = 0.1138s	
5219/5250 (epoch 49.705), train_loss = 0.90301102, grad/param norm = 7.4619e-02, time/batch = 0.1141s	
5220/5250 (epoch 49.714), train_loss = 0.92973087, grad/param norm = 7.4609e-02, time/batch = 0.1142s	
5221/5250 (epoch 49.724), train_loss = 0.91188538, grad/param norm = 7.5862e-02, time/batch = 0.1155s	
5222/5250 (epoch 49.733), train_loss = 0.90177133, grad/param norm = 7.0584e-02, time/batch = 0.1136s	
5223/5250 (epoch 49.743), train_loss = 0.90460708, grad/param norm = 7.2040e-02, time/batch = 0.1141s	
5224/5250 (epoch 49.752), train_loss = 0.89964034, grad/param norm = 7.4176e-02, time/batch = 0.1141s	
5225/5250 (epoch 49.762), train_loss = 0.89941362, grad/param norm = 7.3493e-02, time/batch = 0.1143s	
5226/5250 (epoch 49.771), train_loss = 0.90329814, grad/param norm = 7.2429e-02, time/batch = 0.1142s	
5227/5250 (epoch 49.781), train_loss = 0.91893723, grad/param norm = 7.3401e-02, time/batch = 0.1144s	
5228/5250 (epoch 49.790), train_loss = 0.91972041, grad/param norm = 7.1211e-02, time/batch = 0.1137s	
5229/5250 (epoch 49.800), train_loss = 0.89207040, grad/param norm = 7.5484e-02, time/batch = 0.1144s	
5230/5250 (epoch 49.810), train_loss = 0.91776870, grad/param norm = 7.5718e-02, time/batch = 0.1143s	
5231/5250 (epoch 49.819), train_loss = 0.92246403, grad/param norm = 7.3598e-02, time/batch = 0.1147s	
5232/5250 (epoch 49.829), train_loss = 0.91196753, grad/param norm = 7.4497e-02, time/batch = 0.1138s	
5233/5250 (epoch 49.838), train_loss = 0.89044501, grad/param norm = 7.2824e-02, time/batch = 0.1140s	
5234/5250 (epoch 49.848), train_loss = 0.88417273, grad/param norm = 7.3282e-02, time/batch = 0.1141s	
5235/5250 (epoch 49.857), train_loss = 0.90177672, grad/param norm = 7.2222e-02, time/batch = 0.1143s	
5236/5250 (epoch 49.867), train_loss = 0.90388582, grad/param norm = 7.7994e-02, time/batch = 0.1141s	
5237/5250 (epoch 49.876), train_loss = 0.89267273, grad/param norm = 7.7795e-02, time/batch = 0.1140s	
5238/5250 (epoch 49.886), train_loss = 0.89536054, grad/param norm = 7.6915e-02, time/batch = 0.1137s	
5239/5250 (epoch 49.895), train_loss = 0.91668801, grad/param norm = 7.2668e-02, time/batch = 0.1140s	
5240/5250 (epoch 49.905), train_loss = 0.91171198, grad/param norm = 7.3753e-02, time/batch = 0.1143s	
5241/5250 (epoch 49.914), train_loss = 0.91865001, grad/param norm = 7.7035e-02, time/batch = 0.1147s	
5242/5250 (epoch 49.924), train_loss = 0.92803639, grad/param norm = 7.2492e-02, time/batch = 0.1136s	
5243/5250 (epoch 49.933), train_loss = 0.91578503, grad/param norm = 7.1658e-02, time/batch = 0.1140s	
5244/5250 (epoch 49.943), train_loss = 0.92774947, grad/param norm = 7.6705e-02, time/batch = 0.1141s	
5245/5250 (epoch 49.952), train_loss = 0.93545710, grad/param norm = 7.1048e-02, time/batch = 0.1141s	
5246/5250 (epoch 49.962), train_loss = 0.91809510, grad/param norm = 7.3759e-02, time/batch = 0.1141s	
5247/5250 (epoch 49.971), train_loss = 0.92992948, grad/param norm = 7.4520e-02, time/batch = 0.1142s	
5248/5250 (epoch 49.981), train_loss = 0.92511467, grad/param norm = 7.1867e-02, time/batch = 0.1137s	
5249/5250 (epoch 49.990), train_loss = 0.93388560, grad/param norm = 7.2916e-02, time/batch = 0.1142s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/6...	
2/6...	
3/6...	
4/6...	
5/6...	
6/6...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.6799.t7	
5250/5250 (epoch 50.000), train_loss = 0.92187457, grad/param norm = 7.1845e-02, time/batch = 0.1142s	
