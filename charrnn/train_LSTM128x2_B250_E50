using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 84, val: 5, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 240321	
cloning rnn	
cloning criterion	
1/4200 (epoch 0.012), train_loss = 4.16677623, grad/param norm = 5.3628e-01, time/batch = 0.2693s	
2/4200 (epoch 0.024), train_loss = 3.86103387, grad/param norm = 1.4247e+00, time/batch = 0.0831s	
3/4200 (epoch 0.036), train_loss = 3.42249799, grad/param norm = 9.0989e-01, time/batch = 0.0812s	
4/4200 (epoch 0.048), train_loss = 3.36358999, grad/param norm = 4.9162e-01, time/batch = 0.0818s	
5/4200 (epoch 0.060), train_loss = 3.33887241, grad/param norm = 3.7628e-01, time/batch = 0.0824s	
6/4200 (epoch 0.071), train_loss = 3.34990922, grad/param norm = 3.1536e-01, time/batch = 0.0805s	
7/4200 (epoch 0.083), train_loss = 3.30258152, grad/param norm = 3.2194e-01, time/batch = 0.0804s	
8/4200 (epoch 0.095), train_loss = 3.36173158, grad/param norm = 4.3460e-01, time/batch = 0.0800s	
9/4200 (epoch 0.107), train_loss = 3.30529114, grad/param norm = 5.1048e-01, time/batch = 0.0804s	
10/4200 (epoch 0.119), train_loss = 3.32982420, grad/param norm = 4.6318e-01, time/batch = 0.0796s	
11/4200 (epoch 0.131), train_loss = 3.32552471, grad/param norm = 4.5336e-01, time/batch = 0.0800s	
12/4200 (epoch 0.143), train_loss = 3.32431447, grad/param norm = 4.0610e-01, time/batch = 0.0792s	
13/4200 (epoch 0.155), train_loss = 3.33664302, grad/param norm = 3.5835e-01, time/batch = 0.0786s	
14/4200 (epoch 0.167), train_loss = 3.31943812, grad/param norm = 3.5459e-01, time/batch = 0.0786s	
15/4200 (epoch 0.179), train_loss = 3.31554053, grad/param norm = 2.5131e-01, time/batch = 0.0789s	
16/4200 (epoch 0.190), train_loss = 3.30301273, grad/param norm = 2.3603e-01, time/batch = 0.0783s	
17/4200 (epoch 0.202), train_loss = 3.31727358, grad/param norm = 3.0865e-01, time/batch = 0.0791s	
18/4200 (epoch 0.214), train_loss = 3.31765083, grad/param norm = 3.1814e-01, time/batch = 0.0783s	
19/4200 (epoch 0.226), train_loss = 3.27744280, grad/param norm = 2.2614e-01, time/batch = 0.0788s	
20/4200 (epoch 0.238), train_loss = 3.30488720, grad/param norm = 1.7372e-01, time/batch = 0.0801s	
21/4200 (epoch 0.250), train_loss = 3.28857831, grad/param norm = 1.4645e-01, time/batch = 0.0802s	
22/4200 (epoch 0.262), train_loss = 3.35244706, grad/param norm = 2.3467e-01, time/batch = 0.0789s	
23/4200 (epoch 0.274), train_loss = 3.31894353, grad/param norm = 2.4038e-01, time/batch = 0.0788s	
24/4200 (epoch 0.286), train_loss = 3.30935989, grad/param norm = 1.8153e-01, time/batch = 0.0787s	
25/4200 (epoch 0.298), train_loss = 3.30055093, grad/param norm = 2.5409e-01, time/batch = 0.0789s	
26/4200 (epoch 0.310), train_loss = 3.29833432, grad/param norm = 2.2730e-01, time/batch = 0.0783s	
27/4200 (epoch 0.321), train_loss = 3.33023543, grad/param norm = 2.3644e-01, time/batch = 0.0789s	
28/4200 (epoch 0.333), train_loss = 3.31654631, grad/param norm = 2.5628e-01, time/batch = 0.0790s	
29/4200 (epoch 0.345), train_loss = 3.30977020, grad/param norm = 1.6306e-01, time/batch = 0.0788s	
30/4200 (epoch 0.357), train_loss = 3.29413081, grad/param norm = 2.2191e-01, time/batch = 0.0786s	
31/4200 (epoch 0.369), train_loss = 3.28045997, grad/param norm = 3.0594e-01, time/batch = 0.0803s	
32/4200 (epoch 0.381), train_loss = 3.32156231, grad/param norm = 3.8009e-01, time/batch = 0.0784s	
33/4200 (epoch 0.393), train_loss = 3.26443172, grad/param norm = 3.2655e-01, time/batch = 0.0792s	
34/4200 (epoch 0.405), train_loss = 3.32758947, grad/param norm = 2.8417e-01, time/batch = 0.0787s	
35/4200 (epoch 0.417), train_loss = 3.30119347, grad/param norm = 2.2353e-01, time/batch = 0.0787s	
36/4200 (epoch 0.429), train_loss = 3.32049293, grad/param norm = 2.6644e-01, time/batch = 0.0782s	
37/4200 (epoch 0.440), train_loss = 3.30783601, grad/param norm = 3.0524e-01, time/batch = 0.0788s	
38/4200 (epoch 0.452), train_loss = 3.34085232, grad/param norm = 4.2891e-01, time/batch = 0.0786s	
39/4200 (epoch 0.464), train_loss = 3.30867565, grad/param norm = 4.8649e-01, time/batch = 0.0789s	
40/4200 (epoch 0.476), train_loss = 3.30988859, grad/param norm = 4.3292e-01, time/batch = 0.0785s	
41/4200 (epoch 0.488), train_loss = 3.31082127, grad/param norm = 3.2781e-01, time/batch = 0.0802s	
42/4200 (epoch 0.500), train_loss = 3.31375465, grad/param norm = 2.1044e-01, time/batch = 0.0786s	
43/4200 (epoch 0.512), train_loss = 3.30365958, grad/param norm = 5.1087e-01, time/batch = 0.0791s	
44/4200 (epoch 0.524), train_loss = 3.34470523, grad/param norm = 4.9222e-01, time/batch = 0.0786s	
45/4200 (epoch 0.536), train_loss = 3.31473103, grad/param norm = 2.8240e-01, time/batch = 0.0788s	
46/4200 (epoch 0.548), train_loss = 3.30819135, grad/param norm = 1.7812e-01, time/batch = 0.0785s	
47/4200 (epoch 0.560), train_loss = 3.29437592, grad/param norm = 2.3358e-01, time/batch = 0.0789s	
48/4200 (epoch 0.571), train_loss = 3.31406625, grad/param norm = 2.9042e-01, time/batch = 0.0783s	
49/4200 (epoch 0.583), train_loss = 3.36114346, grad/param norm = 8.7340e-01, time/batch = 0.0794s	
50/4200 (epoch 0.595), train_loss = 3.33818837, grad/param norm = 4.7474e-01, time/batch = 0.0786s	
51/4200 (epoch 0.607), train_loss = 3.29257123, grad/param norm = 2.1509e-01, time/batch = 0.0802s	
52/4200 (epoch 0.619), train_loss = 3.27594256, grad/param norm = 1.3344e-01, time/batch = 0.0786s	
53/4200 (epoch 0.631), train_loss = 3.28208086, grad/param norm = 1.3746e-01, time/batch = 0.0786s	
54/4200 (epoch 0.643), train_loss = 3.28806361, grad/param norm = 3.1201e-01, time/batch = 0.0792s	
55/4200 (epoch 0.655), train_loss = 3.28982568, grad/param norm = 7.4442e-01, time/batch = 0.0788s	
56/4200 (epoch 0.667), train_loss = 3.28503614, grad/param norm = 5.0446e-01, time/batch = 0.0788s	
57/4200 (epoch 0.679), train_loss = 3.25684745, grad/param norm = 2.7289e-01, time/batch = 0.0790s	
58/4200 (epoch 0.690), train_loss = 3.24452243, grad/param norm = 1.9306e-01, time/batch = 0.0785s	
59/4200 (epoch 0.702), train_loss = 3.24769881, grad/param norm = 2.3498e-01, time/batch = 0.0793s	
60/4200 (epoch 0.714), train_loss = 3.22133813, grad/param norm = 2.9549e-01, time/batch = 0.0786s	
61/4200 (epoch 0.726), train_loss = 3.24969746, grad/param norm = 1.2505e+00, time/batch = 0.0801s	
62/4200 (epoch 0.738), train_loss = 3.36023337, grad/param norm = 6.5379e-01, time/batch = 0.0784s	
63/4200 (epoch 0.750), train_loss = 3.27564125, grad/param norm = 4.7809e-01, time/batch = 0.0788s	
64/4200 (epoch 0.762), train_loss = 3.24225404, grad/param norm = 2.8748e-01, time/batch = 0.0791s	
65/4200 (epoch 0.774), train_loss = 3.18974457, grad/param norm = 2.3498e-01, time/batch = 0.0787s	
66/4200 (epoch 0.786), train_loss = 3.20780149, grad/param norm = 2.6736e-01, time/batch = 0.0785s	
67/4200 (epoch 0.798), train_loss = 3.18714076, grad/param norm = 3.5566e-01, time/batch = 0.0790s	
68/4200 (epoch 0.810), train_loss = 3.18004552, grad/param norm = 5.0414e-01, time/batch = 0.0783s	
69/4200 (epoch 0.821), train_loss = 3.19287994, grad/param norm = 7.3796e-01, time/batch = 0.0788s	
70/4200 (epoch 0.833), train_loss = 3.21536780, grad/param norm = 8.1887e-01, time/batch = 0.0793s	
71/4200 (epoch 0.845), train_loss = 3.21142198, grad/param norm = 5.2473e-01, time/batch = 0.0800s	
72/4200 (epoch 0.857), train_loss = 3.16105704, grad/param norm = 3.2680e-01, time/batch = 0.0784s	
73/4200 (epoch 0.869), train_loss = 3.14661601, grad/param norm = 2.5522e-01, time/batch = 0.0788s	
74/4200 (epoch 0.881), train_loss = 3.15501983, grad/param norm = 3.0403e-01, time/batch = 0.0789s	
75/4200 (epoch 0.893), train_loss = 3.15609566, grad/param norm = 4.1596e-01, time/batch = 0.0793s	
76/4200 (epoch 0.905), train_loss = 3.15272317, grad/param norm = 6.1877e-01, time/batch = 0.0783s	
77/4200 (epoch 0.917), train_loss = 3.16467036, grad/param norm = 7.9523e-01, time/batch = 0.0788s	
78/4200 (epoch 0.929), train_loss = 3.15433268, grad/param norm = 6.4731e-01, time/batch = 0.0782s	
79/4200 (epoch 0.940), train_loss = 3.13092354, grad/param norm = 4.0444e-01, time/batch = 0.0788s	
80/4200 (epoch 0.952), train_loss = 3.12800996, grad/param norm = 6.4161e-01, time/batch = 0.0791s	
81/4200 (epoch 0.964), train_loss = 3.18289359, grad/param norm = 1.3209e+00, time/batch = 0.0801s	
82/4200 (epoch 0.976), train_loss = 3.22875011, grad/param norm = 1.1473e+00, time/batch = 0.0784s	
83/4200 (epoch 0.988), train_loss = 3.12737055, grad/param norm = 3.6831e-01, time/batch = 0.0786s	
84/4200 (epoch 1.000), train_loss = 3.08729350, grad/param norm = 1.8852e-01, time/batch = 0.0786s	
85/4200 (epoch 1.012), train_loss = 3.11130007, grad/param norm = 2.0854e-01, time/batch = 0.0788s	
86/4200 (epoch 1.024), train_loss = 3.07916418, grad/param norm = 2.4602e-01, time/batch = 0.0784s	
87/4200 (epoch 1.036), train_loss = 3.07725349, grad/param norm = 3.7444e-01, time/batch = 0.0786s	
88/4200 (epoch 1.048), train_loss = 3.08110404, grad/param norm = 6.6273e-01, time/batch = 0.0784s	
89/4200 (epoch 1.060), train_loss = 3.10556211, grad/param norm = 8.7218e-01, time/batch = 0.0789s	
90/4200 (epoch 1.071), train_loss = 3.08340776, grad/param norm = 6.6386e-01, time/batch = 0.0786s	
91/4200 (epoch 1.083), train_loss = 3.05758790, grad/param norm = 5.0525e-01, time/batch = 0.0806s	
92/4200 (epoch 1.095), train_loss = 3.04826802, grad/param norm = 3.4916e-01, time/batch = 0.0785s	
93/4200 (epoch 1.107), train_loss = 3.01778650, grad/param norm = 3.7576e-01, time/batch = 0.0786s	
94/4200 (epoch 1.119), train_loss = 3.02717585, grad/param norm = 4.6376e-01, time/batch = 0.0786s	
95/4200 (epoch 1.131), train_loss = 3.02918597, grad/param norm = 7.7887e-01, time/batch = 0.0788s	
96/4200 (epoch 1.143), train_loss = 3.07692506, grad/param norm = 1.3926e+00, time/batch = 0.0786s	
97/4200 (epoch 1.155), train_loss = 3.17285776, grad/param norm = 1.4781e+00, time/batch = 0.0788s	
98/4200 (epoch 1.167), train_loss = 3.02444286, grad/param norm = 5.5833e-01, time/batch = 0.0782s	
99/4200 (epoch 1.179), train_loss = 2.98850361, grad/param norm = 2.9360e-01, time/batch = 0.0787s	
100/4200 (epoch 1.190), train_loss = 2.96739382, grad/param norm = 3.0299e-01, time/batch = 0.0785s	
101/4200 (epoch 1.202), train_loss = 2.96226599, grad/param norm = 5.1907e-01, time/batch = 0.0807s	
102/4200 (epoch 1.214), train_loss = 2.98784727, grad/param norm = 8.6236e-01, time/batch = 0.0784s	
103/4200 (epoch 1.226), train_loss = 2.97437777, grad/param norm = 8.5193e-01, time/batch = 0.0786s	
104/4200 (epoch 1.238), train_loss = 2.94910605, grad/param norm = 6.2047e-01, time/batch = 0.0786s	
105/4200 (epoch 1.250), train_loss = 2.92626937, grad/param norm = 5.6829e-01, time/batch = 0.0790s	
106/4200 (epoch 1.262), train_loss = 2.93478576, grad/param norm = 5.3225e-01, time/batch = 0.0783s	
107/4200 (epoch 1.274), train_loss = 2.92434775, grad/param norm = 5.5976e-01, time/batch = 0.0792s	
108/4200 (epoch 1.286), train_loss = 2.91065469, grad/param norm = 6.3560e-01, time/batch = 0.0782s	
109/4200 (epoch 1.298), train_loss = 2.90351942, grad/param norm = 7.4917e-01, time/batch = 0.0788s	
110/4200 (epoch 1.310), train_loss = 2.90698679, grad/param norm = 7.2906e-01, time/batch = 0.0794s	
111/4200 (epoch 1.321), train_loss = 2.89339185, grad/param norm = 7.2410e-01, time/batch = 0.0802s	
112/4200 (epoch 1.333), train_loss = 2.89328288, grad/param norm = 6.8964e-01, time/batch = 0.0793s	
113/4200 (epoch 1.345), train_loss = 2.86980951, grad/param norm = 7.7587e-01, time/batch = 0.0788s	
114/4200 (epoch 1.357), train_loss = 2.88688369, grad/param norm = 9.1429e-01, time/batch = 0.0787s	
115/4200 (epoch 1.369), train_loss = 2.89797964, grad/param norm = 9.8213e-01, time/batch = 0.0787s	
116/4200 (epoch 1.381), train_loss = 2.88059362, grad/param norm = 7.2737e-01, time/batch = 0.0782s	
117/4200 (epoch 1.393), train_loss = 2.82426320, grad/param norm = 4.2933e-01, time/batch = 0.0792s	
118/4200 (epoch 1.405), train_loss = 2.81650769, grad/param norm = 3.0021e-01, time/batch = 0.0783s	
119/4200 (epoch 1.417), train_loss = 2.79300333, grad/param norm = 3.3141e-01, time/batch = 0.0787s	
120/4200 (epoch 1.429), train_loss = 2.80278301, grad/param norm = 4.3090e-01, time/batch = 0.0787s	
121/4200 (epoch 1.440), train_loss = 2.81271446, grad/param norm = 5.5006e-01, time/batch = 0.0801s	
122/4200 (epoch 1.452), train_loss = 2.82292289, grad/param norm = 6.2759e-01, time/batch = 0.0791s	
123/4200 (epoch 1.464), train_loss = 2.81415321, grad/param norm = 6.9384e-01, time/batch = 0.0787s	
124/4200 (epoch 1.476), train_loss = 2.83660520, grad/param norm = 1.1331e+00, time/batch = 0.0786s	
125/4200 (epoch 1.488), train_loss = 2.90405071, grad/param norm = 1.6553e+00, time/batch = 0.0787s	
126/4200 (epoch 1.500), train_loss = 2.84996251, grad/param norm = 1.0512e+00, time/batch = 0.0783s	
127/4200 (epoch 1.512), train_loss = 2.78795445, grad/param norm = 6.5740e-01, time/batch = 0.0788s	
128/4200 (epoch 1.524), train_loss = 2.73874896, grad/param norm = 3.9424e-01, time/batch = 0.0787s	
129/4200 (epoch 1.536), train_loss = 2.74933706, grad/param norm = 6.6479e-01, time/batch = 0.0787s	
130/4200 (epoch 1.548), train_loss = 2.81250989, grad/param norm = 1.1361e+00, time/batch = 0.0786s	
131/4200 (epoch 1.560), train_loss = 2.80926060, grad/param norm = 9.9238e-01, time/batch = 0.0802s	
132/4200 (epoch 1.571), train_loss = 2.76806955, grad/param norm = 5.5331e-01, time/batch = 0.0785s	
133/4200 (epoch 1.583), train_loss = 2.73515186, grad/param norm = 2.9218e-01, time/batch = 0.0791s	
134/4200 (epoch 1.595), train_loss = 2.70596998, grad/param norm = 1.9678e-01, time/batch = 0.0786s	
135/4200 (epoch 1.607), train_loss = 2.69126018, grad/param norm = 1.9645e-01, time/batch = 0.0787s	
136/4200 (epoch 1.619), train_loss = 2.68558796, grad/param norm = 2.3423e-01, time/batch = 0.0785s	
137/4200 (epoch 1.631), train_loss = 2.69511763, grad/param norm = 3.2308e-01, time/batch = 0.0790s	
138/4200 (epoch 1.643), train_loss = 2.70063001, grad/param norm = 5.9354e-01, time/batch = 0.0787s	
139/4200 (epoch 1.655), train_loss = 2.72721378, grad/param norm = 1.0586e+00, time/batch = 0.0788s	
140/4200 (epoch 1.667), train_loss = 2.78383142, grad/param norm = 1.1047e+00, time/batch = 0.0784s	
141/4200 (epoch 1.679), train_loss = 2.71106962, grad/param norm = 6.8044e-01, time/batch = 0.0803s	
142/4200 (epoch 1.690), train_loss = 2.68008993, grad/param norm = 3.4132e-01, time/batch = 0.0786s	
143/4200 (epoch 1.702), train_loss = 2.65736661, grad/param norm = 2.3153e-01, time/batch = 0.0791s	
144/4200 (epoch 1.714), train_loss = 2.67269299, grad/param norm = 2.0461e-01, time/batch = 0.0787s	
145/4200 (epoch 1.726), train_loss = 2.64868906, grad/param norm = 2.3225e-01, time/batch = 0.0787s	
146/4200 (epoch 1.738), train_loss = 2.63594145, grad/param norm = 3.6819e-01, time/batch = 0.0784s	
147/4200 (epoch 1.750), train_loss = 2.66015677, grad/param norm = 9.4003e-01, time/batch = 0.0789s	
148/4200 (epoch 1.762), train_loss = 2.78642973, grad/param norm = 1.7075e+00, time/batch = 0.0782s	
149/4200 (epoch 1.774), train_loss = 2.85775831, grad/param norm = 1.4842e+00, time/batch = 0.0794s	
150/4200 (epoch 1.786), train_loss = 2.68804689, grad/param norm = 5.6872e-01, time/batch = 0.0786s	
151/4200 (epoch 1.798), train_loss = 2.64830393, grad/param norm = 2.7808e-01, time/batch = 0.0802s	
152/4200 (epoch 1.810), train_loss = 2.61481174, grad/param norm = 2.1376e-01, time/batch = 0.0786s	
153/4200 (epoch 1.821), train_loss = 2.61399046, grad/param norm = 2.0816e-01, time/batch = 0.0786s	
154/4200 (epoch 1.833), train_loss = 2.61020748, grad/param norm = 2.5645e-01, time/batch = 0.0791s	
155/4200 (epoch 1.845), train_loss = 2.64145859, grad/param norm = 4.2853e-01, time/batch = 0.0787s	
156/4200 (epoch 1.857), train_loss = 2.64847595, grad/param norm = 7.7961e-01, time/batch = 0.0783s	
157/4200 (epoch 1.869), train_loss = 2.67438529, grad/param norm = 1.0512e+00, time/batch = 0.0788s	
158/4200 (epoch 1.881), train_loss = 2.66525250, grad/param norm = 8.7340e-01, time/batch = 0.0782s	
159/4200 (epoch 1.893), train_loss = 2.62366160, grad/param norm = 4.6884e-01, time/batch = 0.0791s	
160/4200 (epoch 1.905), train_loss = 2.58258227, grad/param norm = 2.8148e-01, time/batch = 0.0786s	
161/4200 (epoch 1.917), train_loss = 2.58876487, grad/param norm = 2.1251e-01, time/batch = 0.0802s	
162/4200 (epoch 1.929), train_loss = 2.58027008, grad/param norm = 2.1298e-01, time/batch = 0.0786s	
163/4200 (epoch 1.940), train_loss = 2.57706223, grad/param norm = 2.2829e-01, time/batch = 0.0788s	
164/4200 (epoch 1.952), train_loss = 2.55541282, grad/param norm = 4.1722e-01, time/batch = 0.0788s	
165/4200 (epoch 1.964), train_loss = 2.59487354, grad/param norm = 8.7830e-01, time/batch = 0.0790s	
166/4200 (epoch 1.976), train_loss = 2.66173261, grad/param norm = 1.3399e+00, time/batch = 0.0784s	
167/4200 (epoch 1.988), train_loss = 2.67092213, grad/param norm = 9.8912e-01, time/batch = 0.0789s	
168/4200 (epoch 2.000), train_loss = 2.58957963, grad/param norm = 4.6951e-01, time/batch = 0.0783s	
169/4200 (epoch 2.012), train_loss = 2.59643915, grad/param norm = 4.3570e-01, time/batch = 0.0787s	
170/4200 (epoch 2.024), train_loss = 2.55462338, grad/param norm = 5.2518e-01, time/batch = 0.0791s	
171/4200 (epoch 2.036), train_loss = 2.56518830, grad/param norm = 5.1050e-01, time/batch = 0.0802s	
172/4200 (epoch 2.048), train_loss = 2.54955346, grad/param norm = 5.0738e-01, time/batch = 0.0785s	
173/4200 (epoch 2.060), train_loss = 2.54721533, grad/param norm = 5.1873e-01, time/batch = 0.0788s	
174/4200 (epoch 2.071), train_loss = 2.56165083, grad/param norm = 5.2417e-01, time/batch = 0.0786s	
175/4200 (epoch 2.083), train_loss = 2.55791339, grad/param norm = 6.6414e-01, time/batch = 0.0792s	
176/4200 (epoch 2.095), train_loss = 2.57326179, grad/param norm = 8.8178e-01, time/batch = 0.0784s	
177/4200 (epoch 2.107), train_loss = 2.58476238, grad/param norm = 8.8179e-01, time/batch = 0.0788s	
178/4200 (epoch 2.119), train_loss = 2.57979003, grad/param norm = 6.0421e-01, time/batch = 0.0782s	
179/4200 (epoch 2.131), train_loss = 2.52528896, grad/param norm = 3.3576e-01, time/batch = 0.0788s	
180/4200 (epoch 2.143), train_loss = 2.51419923, grad/param norm = 2.7478e-01, time/batch = 0.0786s	
181/4200 (epoch 2.155), train_loss = 2.51665764, grad/param norm = 3.7566e-01, time/batch = 0.0802s	
182/4200 (epoch 2.167), train_loss = 2.51560539, grad/param norm = 5.7979e-01, time/batch = 0.0784s	
183/4200 (epoch 2.179), train_loss = 2.55254709, grad/param norm = 8.1922e-01, time/batch = 0.0787s	
184/4200 (epoch 2.190), train_loss = 2.56142331, grad/param norm = 9.9833e-01, time/batch = 0.0786s	
185/4200 (epoch 2.202), train_loss = 2.56978456, grad/param norm = 7.8282e-01, time/batch = 0.0787s	
186/4200 (epoch 2.214), train_loss = 2.51829010, grad/param norm = 4.7190e-01, time/batch = 0.0790s	
187/4200 (epoch 2.226), train_loss = 2.48796922, grad/param norm = 4.0988e-01, time/batch = 0.0788s	
188/4200 (epoch 2.238), train_loss = 2.47930725, grad/param norm = 4.3975e-01, time/batch = 0.0782s	
189/4200 (epoch 2.250), train_loss = 2.48437950, grad/param norm = 5.6038e-01, time/batch = 0.0789s	
190/4200 (epoch 2.262), train_loss = 2.52162273, grad/param norm = 7.1482e-01, time/batch = 0.0785s	
191/4200 (epoch 2.274), train_loss = 2.52639137, grad/param norm = 6.8141e-01, time/batch = 0.0806s	
192/4200 (epoch 2.286), train_loss = 2.49750863, grad/param norm = 5.2539e-01, time/batch = 0.0784s	
193/4200 (epoch 2.298), train_loss = 2.48378211, grad/param norm = 5.5669e-01, time/batch = 0.0787s	
194/4200 (epoch 2.310), train_loss = 2.50227942, grad/param norm = 6.5323e-01, time/batch = 0.0788s	
195/4200 (epoch 2.321), train_loss = 2.49811900, grad/param norm = 6.9712e-01, time/batch = 0.0788s	
196/4200 (epoch 2.333), train_loss = 2.51032882, grad/param norm = 5.9006e-01, time/batch = 0.0787s	
197/4200 (epoch 2.345), train_loss = 2.46214805, grad/param norm = 4.4738e-01, time/batch = 0.0790s	
198/4200 (epoch 2.357), train_loss = 2.45981456, grad/param norm = 3.7423e-01, time/batch = 0.0782s	
199/4200 (epoch 2.369), train_loss = 2.45573568, grad/param norm = 4.6295e-01, time/batch = 0.0789s	
200/4200 (epoch 2.381), train_loss = 2.48597469, grad/param norm = 7.4940e-01, time/batch = 0.0785s	
201/4200 (epoch 2.393), train_loss = 2.52005291, grad/param norm = 1.0454e+00, time/batch = 0.0808s	
202/4200 (epoch 2.405), train_loss = 2.53715125, grad/param norm = 8.4156e-01, time/batch = 0.0786s	
203/4200 (epoch 2.417), train_loss = 2.46014470, grad/param norm = 4.5154e-01, time/batch = 0.0785s	
204/4200 (epoch 2.429), train_loss = 2.45394282, grad/param norm = 3.2114e-01, time/batch = 0.0786s	
205/4200 (epoch 2.440), train_loss = 2.45279725, grad/param norm = 3.2537e-01, time/batch = 0.0787s	
206/4200 (epoch 2.452), train_loss = 2.45703753, grad/param norm = 3.3710e-01, time/batch = 0.0784s	
207/4200 (epoch 2.464), train_loss = 2.44438400, grad/param norm = 3.8987e-01, time/batch = 0.0794s	
208/4200 (epoch 2.476), train_loss = 2.45763906, grad/param norm = 4.5424e-01, time/batch = 0.0784s	
209/4200 (epoch 2.488), train_loss = 2.44174599, grad/param norm = 4.6671e-01, time/batch = 0.0790s	
210/4200 (epoch 2.500), train_loss = 2.44346174, grad/param norm = 5.0302e-01, time/batch = 0.0788s	
211/4200 (epoch 2.512), train_loss = 2.43974090, grad/param norm = 5.8053e-01, time/batch = 0.0802s	
212/4200 (epoch 2.524), train_loss = 2.44348057, grad/param norm = 7.4891e-01, time/batch = 0.0790s	
213/4200 (epoch 2.536), train_loss = 2.46270619, grad/param norm = 7.6530e-01, time/batch = 0.0786s	
214/4200 (epoch 2.548), train_loss = 2.45965509, grad/param norm = 6.7160e-01, time/batch = 0.0787s	
215/4200 (epoch 2.560), train_loss = 2.45394203, grad/param norm = 5.0194e-01, time/batch = 0.0796s	
216/4200 (epoch 2.571), train_loss = 2.44149728, grad/param norm = 3.8537e-01, time/batch = 0.0786s	
217/4200 (epoch 2.583), train_loss = 2.43361382, grad/param norm = 3.4380e-01, time/batch = 0.0795s	
218/4200 (epoch 2.595), train_loss = 2.40818953, grad/param norm = 2.8641e-01, time/batch = 0.0784s	
219/4200 (epoch 2.607), train_loss = 2.39990254, grad/param norm = 2.6623e-01, time/batch = 0.0789s	
220/4200 (epoch 2.619), train_loss = 2.40204167, grad/param norm = 3.2283e-01, time/batch = 0.0787s	
221/4200 (epoch 2.631), train_loss = 2.42008039, grad/param norm = 6.1104e-01, time/batch = 0.0802s	
222/4200 (epoch 2.643), train_loss = 2.47076411, grad/param norm = 9.5065e-01, time/batch = 0.0789s	
223/4200 (epoch 2.655), train_loss = 2.46377326, grad/param norm = 8.3280e-01, time/batch = 0.0787s	
224/4200 (epoch 2.667), train_loss = 2.46218273, grad/param norm = 9.3256e-01, time/batch = 0.0786s	
225/4200 (epoch 2.679), train_loss = 2.48407967, grad/param norm = 7.4078e-01, time/batch = 0.0788s	
226/4200 (epoch 2.690), train_loss = 2.43742049, grad/param norm = 4.6627e-01, time/batch = 0.0784s	
227/4200 (epoch 2.702), train_loss = 2.40479537, grad/param norm = 3.8572e-01, time/batch = 0.0788s	
228/4200 (epoch 2.714), train_loss = 2.42293444, grad/param norm = 3.4696e-01, time/batch = 0.0789s	
229/4200 (epoch 2.726), train_loss = 2.40098511, grad/param norm = 3.5186e-01, time/batch = 0.0788s	
230/4200 (epoch 2.738), train_loss = 2.39046191, grad/param norm = 3.9430e-01, time/batch = 0.0786s	
231/4200 (epoch 2.750), train_loss = 2.39541983, grad/param norm = 4.4884e-01, time/batch = 0.0801s	
232/4200 (epoch 2.762), train_loss = 2.40775374, grad/param norm = 5.1637e-01, time/batch = 0.0785s	
233/4200 (epoch 2.774), train_loss = 2.40177247, grad/param norm = 5.3985e-01, time/batch = 0.0792s	
234/4200 (epoch 2.786), train_loss = 2.39685665, grad/param norm = 5.4910e-01, time/batch = 0.0788s	
235/4200 (epoch 2.798), train_loss = 2.42188349, grad/param norm = 6.0347e-01, time/batch = 0.0789s	
236/4200 (epoch 2.810), train_loss = 2.39681115, grad/param norm = 5.7870e-01, time/batch = 0.0785s	
237/4200 (epoch 2.821), train_loss = 2.39825355, grad/param norm = 5.1565e-01, time/batch = 0.0789s	
238/4200 (epoch 2.833), train_loss = 2.39471954, grad/param norm = 4.4961e-01, time/batch = 0.0788s	
239/4200 (epoch 2.845), train_loss = 2.41639534, grad/param norm = 3.8307e-01, time/batch = 0.0788s	
240/4200 (epoch 2.857), train_loss = 2.39004117, grad/param norm = 3.2740e-01, time/batch = 0.0785s	
241/4200 (epoch 2.869), train_loss = 2.38176859, grad/param norm = 3.4143e-01, time/batch = 0.0801s	
242/4200 (epoch 2.881), train_loss = 2.38181282, grad/param norm = 4.5385e-01, time/batch = 0.0785s	
243/4200 (epoch 2.893), train_loss = 2.39650989, grad/param norm = 5.3749e-01, time/batch = 0.0786s	
244/4200 (epoch 2.905), train_loss = 2.36959212, grad/param norm = 5.7284e-01, time/batch = 0.0786s	
245/4200 (epoch 2.917), train_loss = 2.39013637, grad/param norm = 6.6105e-01, time/batch = 0.0788s	
246/4200 (epoch 2.929), train_loss = 2.40092794, grad/param norm = 7.2096e-01, time/batch = 0.0783s	
247/4200 (epoch 2.940), train_loss = 2.40340647, grad/param norm = 6.3338e-01, time/batch = 0.0789s	
248/4200 (epoch 2.952), train_loss = 2.37277441, grad/param norm = 6.2057e-01, time/batch = 0.0782s	
249/4200 (epoch 2.964), train_loss = 2.38736670, grad/param norm = 5.4486e-01, time/batch = 0.0792s	
250/4200 (epoch 2.976), train_loss = 2.36535814, grad/param norm = 4.4169e-01, time/batch = 0.0787s	
251/4200 (epoch 2.988), train_loss = 2.36504603, grad/param norm = 4.0065e-01, time/batch = 0.0801s	
252/4200 (epoch 3.000), train_loss = 2.37050469, grad/param norm = 3.1562e-01, time/batch = 0.0785s	
253/4200 (epoch 3.012), train_loss = 2.37833754, grad/param norm = 2.7061e-01, time/batch = 0.0786s	
254/4200 (epoch 3.024), train_loss = 2.32097441, grad/param norm = 2.6264e-01, time/batch = 0.0791s	
255/4200 (epoch 3.036), train_loss = 2.33432623, grad/param norm = 3.0307e-01, time/batch = 0.0787s	
256/4200 (epoch 3.048), train_loss = 2.32736885, grad/param norm = 4.7742e-01, time/batch = 0.0785s	
257/4200 (epoch 3.060), train_loss = 2.35165201, grad/param norm = 6.5511e-01, time/batch = 0.0790s	
258/4200 (epoch 3.071), train_loss = 2.37939746, grad/param norm = 6.8948e-01, time/batch = 0.0782s	
259/4200 (epoch 3.083), train_loss = 2.36911619, grad/param norm = 5.8472e-01, time/batch = 0.0795s	
260/4200 (epoch 3.095), train_loss = 2.33822745, grad/param norm = 4.4080e-01, time/batch = 0.0792s	
261/4200 (epoch 3.107), train_loss = 2.32444230, grad/param norm = 4.5816e-01, time/batch = 0.0802s	
262/4200 (epoch 3.119), train_loss = 2.34524713, grad/param norm = 4.6525e-01, time/batch = 0.0785s	
263/4200 (epoch 3.131), train_loss = 2.33568615, grad/param norm = 4.4877e-01, time/batch = 0.0787s	
264/4200 (epoch 3.143), train_loss = 2.33144767, grad/param norm = 3.9884e-01, time/batch = 0.0787s	
265/4200 (epoch 3.155), train_loss = 2.32741075, grad/param norm = 3.5871e-01, time/batch = 0.0791s	
266/4200 (epoch 3.167), train_loss = 2.32629437, grad/param norm = 3.5959e-01, time/batch = 0.0783s	
267/4200 (epoch 3.179), train_loss = 2.33637546, grad/param norm = 3.4040e-01, time/batch = 0.0788s	
268/4200 (epoch 3.190), train_loss = 2.31195922, grad/param norm = 3.6946e-01, time/batch = 0.0783s	
269/4200 (epoch 3.202), train_loss = 2.32329150, grad/param norm = 5.6059e-01, time/batch = 0.0790s	
270/4200 (epoch 3.214), train_loss = 2.34400075, grad/param norm = 6.4837e-01, time/batch = 0.0791s	
271/4200 (epoch 3.226), train_loss = 2.31687918, grad/param norm = 5.6941e-01, time/batch = 0.0802s	
272/4200 (epoch 3.238), train_loss = 2.30563512, grad/param norm = 5.1887e-01, time/batch = 0.0785s	
273/4200 (epoch 3.250), train_loss = 2.29247788, grad/param norm = 4.0495e-01, time/batch = 0.0786s	
274/4200 (epoch 3.262), train_loss = 2.30932907, grad/param norm = 3.5023e-01, time/batch = 0.0787s	
275/4200 (epoch 3.274), train_loss = 2.31048965, grad/param norm = 4.2631e-01, time/batch = 0.0796s	
276/4200 (epoch 3.286), train_loss = 2.33127294, grad/param norm = 6.5723e-01, time/batch = 0.0789s	
277/4200 (epoch 3.298), train_loss = 2.37565865, grad/param norm = 8.7485e-01, time/batch = 0.0791s	
278/4200 (epoch 3.310), train_loss = 2.38429695, grad/param norm = 8.4524e-01, time/batch = 0.0784s	
279/4200 (epoch 3.321), train_loss = 2.31613811, grad/param norm = 4.5382e-01, time/batch = 0.0789s	
280/4200 (epoch 3.333), train_loss = 2.31708596, grad/param norm = 3.0750e-01, time/batch = 0.0788s	
281/4200 (epoch 3.345), train_loss = 2.27556705, grad/param norm = 3.2048e-01, time/batch = 0.0802s	
282/4200 (epoch 3.357), train_loss = 2.28725464, grad/param norm = 3.8425e-01, time/batch = 0.0785s	
283/4200 (epoch 3.369), train_loss = 2.28860800, grad/param norm = 4.6436e-01, time/batch = 0.0786s	
284/4200 (epoch 3.381), train_loss = 2.31175928, grad/param norm = 5.3033e-01, time/batch = 0.0786s	
285/4200 (epoch 3.393), train_loss = 2.30498627, grad/param norm = 5.8268e-01, time/batch = 0.0787s	
286/4200 (epoch 3.405), train_loss = 2.30918686, grad/param norm = 5.2677e-01, time/batch = 0.0788s	
287/4200 (epoch 3.417), train_loss = 2.27847871, grad/param norm = 4.0034e-01, time/batch = 0.0790s	
288/4200 (epoch 3.429), train_loss = 2.27842774, grad/param norm = 3.1364e-01, time/batch = 0.0784s	
289/4200 (epoch 3.440), train_loss = 2.27893501, grad/param norm = 2.9338e-01, time/batch = 0.0789s	
290/4200 (epoch 3.452), train_loss = 2.28830241, grad/param norm = 3.0719e-01, time/batch = 0.0785s	
291/4200 (epoch 3.464), train_loss = 2.27166405, grad/param norm = 3.3417e-01, time/batch = 0.0807s	
292/4200 (epoch 3.476), train_loss = 2.29124631, grad/param norm = 3.4905e-01, time/batch = 0.0784s	
293/4200 (epoch 3.488), train_loss = 2.27070890, grad/param norm = 3.1601e-01, time/batch = 0.0786s	
294/4200 (epoch 3.500), train_loss = 2.25962524, grad/param norm = 2.6646e-01, time/batch = 0.0786s	
295/4200 (epoch 3.512), train_loss = 2.25531684, grad/param norm = 2.3024e-01, time/batch = 0.0788s	
296/4200 (epoch 3.524), train_loss = 2.24084417, grad/param norm = 2.3104e-01, time/batch = 0.0788s	
297/4200 (epoch 3.536), train_loss = 2.25214906, grad/param norm = 2.7794e-01, time/batch = 0.0788s	
298/4200 (epoch 3.548), train_loss = 2.25546360, grad/param norm = 4.1192e-01, time/batch = 0.0782s	
299/4200 (epoch 3.560), train_loss = 2.28423971, grad/param norm = 6.3150e-01, time/batch = 0.0789s	
300/4200 (epoch 3.571), train_loss = 2.31403578, grad/param norm = 7.8522e-01, time/batch = 0.0787s	
301/4200 (epoch 3.583), train_loss = 2.31888109, grad/param norm = 6.3594e-01, time/batch = 0.0805s	
302/4200 (epoch 3.595), train_loss = 2.25156071, grad/param norm = 3.7263e-01, time/batch = 0.0786s	
303/4200 (epoch 3.607), train_loss = 2.23843193, grad/param norm = 3.3620e-01, time/batch = 0.0786s	
304/4200 (epoch 3.619), train_loss = 2.24777377, grad/param norm = 3.4740e-01, time/batch = 0.0787s	
305/4200 (epoch 3.631), train_loss = 2.24547444, grad/param norm = 3.6331e-01, time/batch = 0.0789s	
306/4200 (epoch 3.643), train_loss = 2.25158549, grad/param norm = 3.4782e-01, time/batch = 0.0785s	
307/4200 (epoch 3.655), train_loss = 2.22894390, grad/param norm = 3.1306e-01, time/batch = 0.0793s	
308/4200 (epoch 3.667), train_loss = 2.22413010, grad/param norm = 2.8168e-01, time/batch = 0.0782s	
309/4200 (epoch 3.679), train_loss = 2.22054630, grad/param norm = 2.6452e-01, time/batch = 0.0789s	
310/4200 (epoch 3.690), train_loss = 2.23586813, grad/param norm = 2.4050e-01, time/batch = 0.0786s	
311/4200 (epoch 3.702), train_loss = 2.22856230, grad/param norm = 2.3607e-01, time/batch = 0.0801s	
312/4200 (epoch 3.714), train_loss = 2.25122684, grad/param norm = 2.5123e-01, time/batch = 0.0791s	
313/4200 (epoch 3.726), train_loss = 2.23476227, grad/param norm = 2.8435e-01, time/batch = 0.0785s	
314/4200 (epoch 3.738), train_loss = 2.24405183, grad/param norm = 3.8126e-01, time/batch = 0.0787s	
315/4200 (epoch 3.750), train_loss = 2.24854585, grad/param norm = 4.0838e-01, time/batch = 0.0787s	
316/4200 (epoch 3.762), train_loss = 2.24584508, grad/param norm = 4.3113e-01, time/batch = 0.0783s	
317/4200 (epoch 3.774), train_loss = 2.24849921, grad/param norm = 4.6317e-01, time/batch = 0.0793s	
318/4200 (epoch 3.786), train_loss = 2.23595670, grad/param norm = 5.0881e-01, time/batch = 0.0782s	
319/4200 (epoch 3.798), train_loss = 2.27335621, grad/param norm = 6.2692e-01, time/batch = 0.0788s	
320/4200 (epoch 3.810), train_loss = 2.26246135, grad/param norm = 6.5058e-01, time/batch = 0.0796s	
321/4200 (epoch 3.821), train_loss = 2.24910758, grad/param norm = 5.4578e-01, time/batch = 0.0801s	
322/4200 (epoch 3.833), train_loss = 2.22745717, grad/param norm = 3.7860e-01, time/batch = 0.0787s	
323/4200 (epoch 3.845), train_loss = 2.24178079, grad/param norm = 2.4846e-01, time/batch = 0.0788s	
324/4200 (epoch 3.857), train_loss = 2.22005358, grad/param norm = 2.1335e-01, time/batch = 0.0787s	
325/4200 (epoch 3.869), train_loss = 2.21834995, grad/param norm = 1.8528e-01, time/batch = 0.0788s	
326/4200 (epoch 3.881), train_loss = 2.20679943, grad/param norm = 1.8981e-01, time/batch = 0.0782s	
327/4200 (epoch 3.893), train_loss = 2.21597116, grad/param norm = 1.9364e-01, time/batch = 0.0788s	
328/4200 (epoch 3.905), train_loss = 2.18274149, grad/param norm = 2.2464e-01, time/batch = 0.0788s	
329/4200 (epoch 3.917), train_loss = 2.21666374, grad/param norm = 3.2327e-01, time/batch = 0.0789s	
330/4200 (epoch 3.929), train_loss = 2.22598016, grad/param norm = 3.6890e-01, time/batch = 0.0785s	
331/4200 (epoch 3.940), train_loss = 2.22599156, grad/param norm = 3.2750e-01, time/batch = 0.0801s	
332/4200 (epoch 3.952), train_loss = 2.19710823, grad/param norm = 3.2692e-01, time/batch = 0.0824s	
333/4200 (epoch 3.964), train_loss = 2.20734614, grad/param norm = 4.1666e-01, time/batch = 0.0800s	
334/4200 (epoch 3.976), train_loss = 2.22019585, grad/param norm = 5.6248e-01, time/batch = 0.0785s	
335/4200 (epoch 3.988), train_loss = 2.23158544, grad/param norm = 5.6261e-01, time/batch = 0.0784s	
336/4200 (epoch 4.000), train_loss = 2.23570738, grad/param norm = 4.9708e-01, time/batch = 0.0780s	
337/4200 (epoch 4.012), train_loss = 2.25026354, grad/param norm = 4.1051e-01, time/batch = 0.0784s	
338/4200 (epoch 4.024), train_loss = 2.17422561, grad/param norm = 3.4616e-01, time/batch = 0.0778s	
339/4200 (epoch 4.036), train_loss = 2.18975427, grad/param norm = 3.0890e-01, time/batch = 0.0783s	
340/4200 (epoch 4.048), train_loss = 2.16725460, grad/param norm = 2.8395e-01, time/batch = 0.0782s	
341/4200 (epoch 4.060), train_loss = 2.18377646, grad/param norm = 3.0637e-01, time/batch = 0.0800s	
342/4200 (epoch 4.071), train_loss = 2.18787700, grad/param norm = 3.2321e-01, time/batch = 0.0782s	
343/4200 (epoch 4.083), train_loss = 2.19163577, grad/param norm = 3.0855e-01, time/batch = 0.0782s	
344/4200 (epoch 4.095), train_loss = 2.16739594, grad/param norm = 2.3754e-01, time/batch = 0.0789s	
345/4200 (epoch 4.107), train_loss = 2.14791108, grad/param norm = 1.9419e-01, time/batch = 0.0783s	
346/4200 (epoch 4.119), train_loss = 2.16577015, grad/param norm = 2.4813e-01, time/batch = 0.0779s	
347/4200 (epoch 4.131), train_loss = 2.17356412, grad/param norm = 3.6332e-01, time/batch = 0.0784s	
348/4200 (epoch 4.143), train_loss = 2.18341424, grad/param norm = 4.0635e-01, time/batch = 0.0777s	
349/4200 (epoch 4.155), train_loss = 2.17909109, grad/param norm = 4.6324e-01, time/batch = 0.0789s	
350/4200 (epoch 4.167), train_loss = 2.19722968, grad/param norm = 5.3286e-01, time/batch = 0.0781s	
351/4200 (epoch 4.179), train_loss = 2.20349998, grad/param norm = 4.7928e-01, time/batch = 0.0798s	
352/4200 (epoch 4.190), train_loss = 2.16582630, grad/param norm = 3.7316e-01, time/batch = 0.0782s	
353/4200 (epoch 4.202), train_loss = 2.16354923, grad/param norm = 3.0763e-01, time/batch = 0.0784s	
354/4200 (epoch 4.214), train_loss = 2.16600122, grad/param norm = 3.0272e-01, time/batch = 0.0787s	
355/4200 (epoch 4.226), train_loss = 2.15022755, grad/param norm = 3.1861e-01, time/batch = 0.0785s	
356/4200 (epoch 4.238), train_loss = 2.14490877, grad/param norm = 3.0420e-01, time/batch = 0.0780s	
357/4200 (epoch 4.250), train_loss = 2.13308773, grad/param norm = 2.7956e-01, time/batch = 0.0786s	
358/4200 (epoch 4.262), train_loss = 2.14541226, grad/param norm = 2.3071e-01, time/batch = 0.0779s	
359/4200 (epoch 4.274), train_loss = 2.14446047, grad/param norm = 2.1627e-01, time/batch = 0.0784s	
360/4200 (epoch 4.286), train_loss = 2.13843568, grad/param norm = 2.6904e-01, time/batch = 0.0785s	
361/4200 (epoch 4.298), train_loss = 2.15795682, grad/param norm = 3.4339e-01, time/batch = 0.0799s	
362/4200 (epoch 4.310), train_loss = 2.16905352, grad/param norm = 3.2163e-01, time/batch = 0.0783s	
363/4200 (epoch 4.321), train_loss = 2.13735833, grad/param norm = 3.1398e-01, time/batch = 0.0784s	
364/4200 (epoch 4.333), train_loss = 2.18284763, grad/param norm = 3.9250e-01, time/batch = 0.0782s	
365/4200 (epoch 4.345), train_loss = 2.15572356, grad/param norm = 5.3814e-01, time/batch = 0.0789s	
366/4200 (epoch 4.357), train_loss = 2.18126000, grad/param norm = 5.6717e-01, time/batch = 0.0779s	
367/4200 (epoch 4.369), train_loss = 2.16013987, grad/param norm = 4.4962e-01, time/batch = 0.0783s	
368/4200 (epoch 4.381), train_loss = 2.15978981, grad/param norm = 3.1169e-01, time/batch = 0.0778s	
369/4200 (epoch 4.393), train_loss = 2.12898427, grad/param norm = 2.5828e-01, time/batch = 0.0783s	
370/4200 (epoch 4.405), train_loss = 2.12854786, grad/param norm = 2.3181e-01, time/batch = 0.0785s	
371/4200 (epoch 4.417), train_loss = 2.11115212, grad/param norm = 2.3379e-01, time/batch = 0.0799s	
372/4200 (epoch 4.429), train_loss = 2.11807567, grad/param norm = 2.4961e-01, time/batch = 0.0781s	
373/4200 (epoch 4.440), train_loss = 2.13968490, grad/param norm = 3.1355e-01, time/batch = 0.0784s	
374/4200 (epoch 4.452), train_loss = 2.15737288, grad/param norm = 3.4476e-01, time/batch = 0.0784s	
375/4200 (epoch 4.464), train_loss = 2.12341748, grad/param norm = 2.9754e-01, time/batch = 0.0793s	
376/4200 (epoch 4.476), train_loss = 2.14054237, grad/param norm = 2.7201e-01, time/batch = 0.0798s	
377/4200 (epoch 4.488), train_loss = 2.12605493, grad/param norm = 2.6899e-01, time/batch = 0.0787s	
378/4200 (epoch 4.500), train_loss = 2.10949017, grad/param norm = 2.5559e-01, time/batch = 0.0780s	
379/4200 (epoch 4.512), train_loss = 2.11832231, grad/param norm = 3.3594e-01, time/batch = 0.0785s	
380/4200 (epoch 4.524), train_loss = 2.11899761, grad/param norm = 4.0918e-01, time/batch = 0.0781s	
381/4200 (epoch 4.536), train_loss = 2.12799526, grad/param norm = 3.9539e-01, time/batch = 0.0798s	
382/4200 (epoch 4.548), train_loss = 2.12007085, grad/param norm = 3.9023e-01, time/batch = 0.0781s	
383/4200 (epoch 4.560), train_loss = 2.12750453, grad/param norm = 3.5524e-01, time/batch = 0.0783s	
384/4200 (epoch 4.571), train_loss = 2.10808192, grad/param norm = 3.0655e-01, time/batch = 0.0782s	
385/4200 (epoch 4.583), train_loss = 2.12107934, grad/param norm = 2.8678e-01, time/batch = 0.0783s	
386/4200 (epoch 4.595), train_loss = 2.09807675, grad/param norm = 3.1839e-01, time/batch = 0.0789s	
387/4200 (epoch 4.607), train_loss = 2.11107168, grad/param norm = 3.7046e-01, time/batch = 0.0791s	
388/4200 (epoch 4.619), train_loss = 2.12003420, grad/param norm = 3.5395e-01, time/batch = 0.0779s	
389/4200 (epoch 4.631), train_loss = 2.10284222, grad/param norm = 2.9799e-01, time/batch = 0.0785s	
390/4200 (epoch 4.643), train_loss = 2.09506618, grad/param norm = 2.2310e-01, time/batch = 0.0781s	
391/4200 (epoch 4.655), train_loss = 2.07939229, grad/param norm = 2.3404e-01, time/batch = 0.0802s	
392/4200 (epoch 4.667), train_loss = 2.08253992, grad/param norm = 2.8848e-01, time/batch = 0.0781s	
393/4200 (epoch 4.679), train_loss = 2.08853887, grad/param norm = 3.5357e-01, time/batch = 0.0784s	
394/4200 (epoch 4.690), train_loss = 2.11411859, grad/param norm = 3.9255e-01, time/batch = 0.0784s	
395/4200 (epoch 4.702), train_loss = 2.10863796, grad/param norm = 3.7493e-01, time/batch = 0.0783s	
396/4200 (epoch 4.714), train_loss = 2.12335517, grad/param norm = 2.8376e-01, time/batch = 0.0780s	
397/4200 (epoch 4.726), train_loss = 2.09045319, grad/param norm = 2.0246e-01, time/batch = 0.0785s	
398/4200 (epoch 4.738), train_loss = 2.08853892, grad/param norm = 1.9192e-01, time/batch = 0.0778s	
399/4200 (epoch 4.750), train_loss = 2.09536480, grad/param norm = 2.4986e-01, time/batch = 0.0784s	
400/4200 (epoch 4.762), train_loss = 2.10512956, grad/param norm = 3.0649e-01, time/batch = 0.0782s	
401/4200 (epoch 4.774), train_loss = 2.10797398, grad/param norm = 3.1041e-01, time/batch = 0.0799s	
402/4200 (epoch 4.786), train_loss = 2.09053735, grad/param norm = 2.9530e-01, time/batch = 0.0785s	
403/4200 (epoch 4.798), train_loss = 2.11019277, grad/param norm = 2.9080e-01, time/batch = 0.0784s	
404/4200 (epoch 4.810), train_loss = 2.08644456, grad/param norm = 3.7870e-01, time/batch = 0.0784s	
405/4200 (epoch 4.821), train_loss = 2.11121951, grad/param norm = 4.6858e-01, time/batch = 0.0785s	
406/4200 (epoch 4.833), train_loss = 2.09438075, grad/param norm = 3.9218e-01, time/batch = 0.0781s	
407/4200 (epoch 4.845), train_loss = 2.11548841, grad/param norm = 3.1204e-01, time/batch = 0.0789s	
408/4200 (epoch 4.857), train_loss = 2.09585185, grad/param norm = 2.8655e-01, time/batch = 0.0779s	
409/4200 (epoch 4.869), train_loss = 2.10005733, grad/param norm = 2.8661e-01, time/batch = 0.0784s	
410/4200 (epoch 4.881), train_loss = 2.09278053, grad/param norm = 3.1893e-01, time/batch = 0.0782s	
411/4200 (epoch 4.893), train_loss = 2.10791264, grad/param norm = 3.1276e-01, time/batch = 0.0798s	
412/4200 (epoch 4.905), train_loss = 2.06634895, grad/param norm = 2.9011e-01, time/batch = 0.0784s	
413/4200 (epoch 4.917), train_loss = 2.08980155, grad/param norm = 2.9102e-01, time/batch = 0.0782s	
414/4200 (epoch 4.929), train_loss = 2.07552998, grad/param norm = 2.9324e-01, time/batch = 0.0783s	
415/4200 (epoch 4.940), train_loss = 2.08960567, grad/param norm = 3.1499e-01, time/batch = 0.0784s	
416/4200 (epoch 4.952), train_loss = 2.07831171, grad/param norm = 3.5630e-01, time/batch = 0.0779s	
417/4200 (epoch 4.964), train_loss = 2.09175668, grad/param norm = 3.3052e-01, time/batch = 0.0784s	
418/4200 (epoch 4.976), train_loss = 2.08191613, grad/param norm = 2.7527e-01, time/batch = 0.0783s	
419/4200 (epoch 4.988), train_loss = 2.06414100, grad/param norm = 2.5634e-01, time/batch = 0.0785s	
420/4200 (epoch 5.000), train_loss = 2.08810923, grad/param norm = 2.8288e-01, time/batch = 0.0783s	
421/4200 (epoch 5.012), train_loss = 2.13131890, grad/param norm = 2.9337e-01, time/batch = 0.0798s	
422/4200 (epoch 5.024), train_loss = 2.04551707, grad/param norm = 2.5856e-01, time/batch = 0.0781s	
423/4200 (epoch 5.036), train_loss = 2.05366694, grad/param norm = 1.9997e-01, time/batch = 0.0787s	
424/4200 (epoch 5.048), train_loss = 2.03039075, grad/param norm = 1.8112e-01, time/batch = 0.0782s	
425/4200 (epoch 5.060), train_loss = 2.04778036, grad/param norm = 1.9503e-01, time/batch = 0.0783s	
426/4200 (epoch 5.071), train_loss = 2.04518150, grad/param norm = 2.1689e-01, time/batch = 0.0788s	
427/4200 (epoch 5.083), train_loss = 2.05745290, grad/param norm = 2.5723e-01, time/batch = 0.0787s	
428/4200 (epoch 5.095), train_loss = 2.04230541, grad/param norm = 3.5014e-01, time/batch = 0.0785s	
429/4200 (epoch 5.107), train_loss = 2.05108303, grad/param norm = 4.0187e-01, time/batch = 0.0786s	
430/4200 (epoch 5.119), train_loss = 2.06463078, grad/param norm = 4.2142e-01, time/batch = 0.0782s	
431/4200 (epoch 5.131), train_loss = 2.07844223, grad/param norm = 3.7357e-01, time/batch = 0.0799s	
432/4200 (epoch 5.143), train_loss = 2.06154153, grad/param norm = 3.0221e-01, time/batch = 0.0780s	
433/4200 (epoch 5.155), train_loss = 2.04473258, grad/param norm = 2.4123e-01, time/batch = 0.0786s	
434/4200 (epoch 5.167), train_loss = 2.04093283, grad/param norm = 1.8564e-01, time/batch = 0.0783s	
435/4200 (epoch 5.179), train_loss = 2.04561663, grad/param norm = 1.6823e-01, time/batch = 0.0783s	
436/4200 (epoch 5.190), train_loss = 2.02066447, grad/param norm = 1.6922e-01, time/batch = 0.0779s	
437/4200 (epoch 5.202), train_loss = 2.03320295, grad/param norm = 1.8973e-01, time/batch = 0.0783s	
438/4200 (epoch 5.214), train_loss = 2.04180084, grad/param norm = 2.3758e-01, time/batch = 0.0813s	
439/4200 (epoch 5.226), train_loss = 2.02662398, grad/param norm = 2.5690e-01, time/batch = 0.0800s	
440/4200 (epoch 5.238), train_loss = 2.02254534, grad/param norm = 2.7309e-01, time/batch = 0.0786s	
441/4200 (epoch 5.250), train_loss = 2.01960021, grad/param norm = 2.6686e-01, time/batch = 0.0800s	
442/4200 (epoch 5.262), train_loss = 2.03758015, grad/param norm = 2.6300e-01, time/batch = 0.0781s	
443/4200 (epoch 5.274), train_loss = 2.04253207, grad/param norm = 2.5657e-01, time/batch = 0.0783s	
444/4200 (epoch 5.286), train_loss = 2.02180922, grad/param norm = 2.3181e-01, time/batch = 0.0787s	
445/4200 (epoch 5.298), train_loss = 2.03015154, grad/param norm = 2.2899e-01, time/batch = 0.0783s	
446/4200 (epoch 5.310), train_loss = 2.03329781, grad/param norm = 2.4894e-01, time/batch = 0.0781s	
447/4200 (epoch 5.321), train_loss = 2.00452598, grad/param norm = 2.9342e-01, time/batch = 0.0787s	
448/4200 (epoch 5.333), train_loss = 2.05033357, grad/param norm = 2.6677e-01, time/batch = 0.0779s	
449/4200 (epoch 5.345), train_loss = 2.00561650, grad/param norm = 2.0902e-01, time/batch = 0.0789s	
450/4200 (epoch 5.357), train_loss = 2.01403580, grad/param norm = 2.0165e-01, time/batch = 0.0783s	
451/4200 (epoch 5.369), train_loss = 2.01307859, grad/param norm = 2.2654e-01, time/batch = 0.0799s	
452/4200 (epoch 5.381), train_loss = 2.04056133, grad/param norm = 3.0786e-01, time/batch = 0.0780s	
453/4200 (epoch 5.393), train_loss = 2.02994140, grad/param norm = 3.8346e-01, time/batch = 0.0782s	
454/4200 (epoch 5.405), train_loss = 2.05334707, grad/param norm = 4.3347e-01, time/batch = 0.0783s	
455/4200 (epoch 5.417), train_loss = 2.03542994, grad/param norm = 4.3126e-01, time/batch = 0.0783s	
456/4200 (epoch 5.429), train_loss = 2.03792624, grad/param norm = 3.6651e-01, time/batch = 0.0779s	
457/4200 (epoch 5.440), train_loss = 2.03615905, grad/param norm = 2.6725e-01, time/batch = 0.0786s	
458/4200 (epoch 5.452), train_loss = 2.02832495, grad/param norm = 2.0060e-01, time/batch = 0.0777s	
459/4200 (epoch 5.464), train_loss = 1.99546816, grad/param norm = 1.6417e-01, time/batch = 0.0784s	
460/4200 (epoch 5.476), train_loss = 2.01036844, grad/param norm = 1.4246e-01, time/batch = 0.0785s	
461/4200 (epoch 5.488), train_loss = 2.00835005, grad/param norm = 1.8044e-01, time/batch = 0.0800s	
462/4200 (epoch 5.500), train_loss = 1.99759288, grad/param norm = 2.5050e-01, time/batch = 0.0782s	
463/4200 (epoch 5.512), train_loss = 2.02400982, grad/param norm = 3.6805e-01, time/batch = 0.0784s	
464/4200 (epoch 5.524), train_loss = 2.01310477, grad/param norm = 3.5419e-01, time/batch = 0.0782s	
465/4200 (epoch 5.536), train_loss = 2.01109189, grad/param norm = 2.8273e-01, time/batch = 0.0786s	
466/4200 (epoch 5.548), train_loss = 1.99609419, grad/param norm = 2.6386e-01, time/batch = 0.0778s	
467/4200 (epoch 5.560), train_loss = 2.00301505, grad/param norm = 2.7707e-01, time/batch = 0.0784s	
468/4200 (epoch 5.571), train_loss = 1.98524799, grad/param norm = 2.6852e-01, time/batch = 0.0780s	
469/4200 (epoch 5.583), train_loss = 2.00381462, grad/param norm = 2.3693e-01, time/batch = 0.0783s	
470/4200 (epoch 5.595), train_loss = 1.97750488, grad/param norm = 2.2500e-01, time/batch = 0.0783s	
471/4200 (epoch 5.607), train_loss = 1.98352599, grad/param norm = 2.6325e-01, time/batch = 0.0799s	
472/4200 (epoch 5.619), train_loss = 2.00690812, grad/param norm = 2.9482e-01, time/batch = 0.0783s	
473/4200 (epoch 5.631), train_loss = 1.98708426, grad/param norm = 3.0511e-01, time/batch = 0.0784s	
474/4200 (epoch 5.643), train_loss = 1.99872568, grad/param norm = 2.6981e-01, time/batch = 0.0783s	
475/4200 (epoch 5.655), train_loss = 1.97715103, grad/param norm = 2.0897e-01, time/batch = 0.0781s	
476/4200 (epoch 5.667), train_loss = 1.97188867, grad/param norm = 1.7579e-01, time/batch = 0.0784s	
477/4200 (epoch 5.679), train_loss = 1.97058124, grad/param norm = 1.6891e-01, time/batch = 0.0782s	
478/4200 (epoch 5.690), train_loss = 1.98426374, grad/param norm = 2.0148e-01, time/batch = 0.0778s	
479/4200 (epoch 5.702), train_loss = 1.98550072, grad/param norm = 2.4570e-01, time/batch = 0.0784s	
480/4200 (epoch 5.714), train_loss = 2.01864218, grad/param norm = 2.5616e-01, time/batch = 0.0782s	
481/4200 (epoch 5.726), train_loss = 1.99157413, grad/param norm = 2.2055e-01, time/batch = 0.0805s	
482/4200 (epoch 5.738), train_loss = 1.98784896, grad/param norm = 2.1954e-01, time/batch = 0.0783s	
483/4200 (epoch 5.750), train_loss = 1.98891373, grad/param norm = 2.4600e-01, time/batch = 0.0783s	
484/4200 (epoch 5.762), train_loss = 1.98842786, grad/param norm = 2.9214e-01, time/batch = 0.0783s	
485/4200 (epoch 5.774), train_loss = 2.00095566, grad/param norm = 3.0182e-01, time/batch = 0.0782s	
486/4200 (epoch 5.786), train_loss = 1.97642653, grad/param norm = 2.7128e-01, time/batch = 0.0781s	
487/4200 (epoch 5.798), train_loss = 1.99567484, grad/param norm = 2.5511e-01, time/batch = 0.0783s	
488/4200 (epoch 5.810), train_loss = 1.97677955, grad/param norm = 3.2492e-01, time/batch = 0.0778s	
489/4200 (epoch 5.821), train_loss = 2.00033782, grad/param norm = 3.9154e-01, time/batch = 0.0785s	
490/4200 (epoch 5.833), train_loss = 1.99008357, grad/param norm = 3.4884e-01, time/batch = 0.0780s	
491/4200 (epoch 5.845), train_loss = 2.01891115, grad/param norm = 2.9792e-01, time/batch = 0.0803s	
492/4200 (epoch 5.857), train_loss = 2.00375066, grad/param norm = 2.8248e-01, time/batch = 0.0782s	
493/4200 (epoch 5.869), train_loss = 2.00688817, grad/param norm = 2.3670e-01, time/batch = 0.0783s	
494/4200 (epoch 5.881), train_loss = 1.97990508, grad/param norm = 2.0606e-01, time/batch = 0.0781s	
495/4200 (epoch 5.893), train_loss = 1.99446772, grad/param norm = 1.8375e-01, time/batch = 0.0782s	
496/4200 (epoch 5.905), train_loss = 1.94961257, grad/param norm = 1.6851e-01, time/batch = 0.0779s	
497/4200 (epoch 5.917), train_loss = 1.97612986, grad/param norm = 1.7011e-01, time/batch = 0.0789s	
498/4200 (epoch 5.929), train_loss = 1.96020069, grad/param norm = 1.7851e-01, time/batch = 0.0777s	
499/4200 (epoch 5.940), train_loss = 1.97870366, grad/param norm = 2.0827e-01, time/batch = 0.0786s	
500/4200 (epoch 5.952), train_loss = 1.96839419, grad/param norm = 2.3606e-01, time/batch = 0.0782s	
501/4200 (epoch 5.964), train_loss = 1.98772596, grad/param norm = 2.4179e-01, time/batch = 0.0801s	
502/4200 (epoch 5.976), train_loss = 1.97892414, grad/param norm = 2.3157e-01, time/batch = 0.0791s	
503/4200 (epoch 5.988), train_loss = 1.95992802, grad/param norm = 2.2526e-01, time/batch = 0.0785s	
504/4200 (epoch 6.000), train_loss = 1.98386531, grad/param norm = 2.6058e-01, time/batch = 0.0783s	
505/4200 (epoch 6.012), train_loss = 2.03628932, grad/param norm = 2.6764e-01, time/batch = 0.0784s	
506/4200 (epoch 6.024), train_loss = 1.94185413, grad/param norm = 2.6776e-01, time/batch = 0.0780s	
507/4200 (epoch 6.036), train_loss = 1.96457210, grad/param norm = 2.7607e-01, time/batch = 0.0787s	
508/4200 (epoch 6.048), train_loss = 1.94715216, grad/param norm = 2.7544e-01, time/batch = 0.0779s	
509/4200 (epoch 6.060), train_loss = 1.96375871, grad/param norm = 2.5213e-01, time/batch = 0.0784s	
510/4200 (epoch 6.071), train_loss = 1.94831233, grad/param norm = 2.0819e-01, time/batch = 0.0783s	
511/4200 (epoch 6.083), train_loss = 1.95591258, grad/param norm = 1.9044e-01, time/batch = 0.0798s	
512/4200 (epoch 6.095), train_loss = 1.92829396, grad/param norm = 1.8299e-01, time/batch = 0.0783s	
513/4200 (epoch 6.107), train_loss = 1.93048038, grad/param norm = 1.8728e-01, time/batch = 0.0783s	
514/4200 (epoch 6.119), train_loss = 1.94191784, grad/param norm = 2.1041e-01, time/batch = 0.0781s	
515/4200 (epoch 6.131), train_loss = 1.95310395, grad/param norm = 2.2847e-01, time/batch = 0.0782s	
516/4200 (epoch 6.143), train_loss = 1.96139696, grad/param norm = 2.3631e-01, time/batch = 0.0778s	
517/4200 (epoch 6.155), train_loss = 1.94470252, grad/param norm = 2.3569e-01, time/batch = 0.0784s	
518/4200 (epoch 6.167), train_loss = 1.95708228, grad/param norm = 2.1610e-01, time/batch = 0.0782s	
519/4200 (epoch 6.179), train_loss = 1.95571213, grad/param norm = 1.9993e-01, time/batch = 0.0784s	
520/4200 (epoch 6.190), train_loss = 1.92758621, grad/param norm = 1.7903e-01, time/batch = 0.0781s	
521/4200 (epoch 6.202), train_loss = 1.93430501, grad/param norm = 1.5872e-01, time/batch = 0.0799s	
522/4200 (epoch 6.214), train_loss = 1.94438129, grad/param norm = 1.7832e-01, time/batch = 0.0780s	
523/4200 (epoch 6.226), train_loss = 1.93213831, grad/param norm = 2.2781e-01, time/batch = 0.0787s	
524/4200 (epoch 6.238), train_loss = 1.93219921, grad/param norm = 2.3445e-01, time/batch = 0.0782s	
525/4200 (epoch 6.250), train_loss = 1.91793711, grad/param norm = 2.7181e-01, time/batch = 0.0784s	
526/4200 (epoch 6.262), train_loss = 1.94258502, grad/param norm = 3.0887e-01, time/batch = 0.0779s	
527/4200 (epoch 6.274), train_loss = 1.95275633, grad/param norm = 3.0703e-01, time/batch = 0.0784s	
528/4200 (epoch 6.286), train_loss = 1.94214097, grad/param norm = 3.0062e-01, time/batch = 0.0778s	
529/4200 (epoch 6.298), train_loss = 1.94446476, grad/param norm = 2.9605e-01, time/batch = 0.0789s	
530/4200 (epoch 6.310), train_loss = 1.95105087, grad/param norm = 3.0916e-01, time/batch = 0.0780s	
531/4200 (epoch 6.321), train_loss = 1.91965208, grad/param norm = 3.4267e-01, time/batch = 0.0808s	
532/4200 (epoch 6.333), train_loss = 1.94999582, grad/param norm = 2.7224e-01, time/batch = 0.0783s	
533/4200 (epoch 6.345), train_loss = 1.91443502, grad/param norm = 2.0035e-01, time/batch = 0.0785s	
534/4200 (epoch 6.357), train_loss = 1.91088933, grad/param norm = 1.5305e-01, time/batch = 0.0787s	
535/4200 (epoch 6.369), train_loss = 1.91433463, grad/param norm = 1.2107e-01, time/batch = 0.0782s	
536/4200 (epoch 6.381), train_loss = 1.93292935, grad/param norm = 1.1737e-01, time/batch = 0.0778s	
537/4200 (epoch 6.393), train_loss = 1.91526700, grad/param norm = 1.2006e-01, time/batch = 0.0785s	
538/4200 (epoch 6.405), train_loss = 1.91608254, grad/param norm = 1.3775e-01, time/batch = 0.0778s	
539/4200 (epoch 6.417), train_loss = 1.89182865, grad/param norm = 1.6607e-01, time/batch = 0.0787s	
540/4200 (epoch 6.429), train_loss = 1.91037637, grad/param norm = 2.0702e-01, time/batch = 0.0782s	
541/4200 (epoch 6.440), train_loss = 1.93520398, grad/param norm = 2.2776e-01, time/batch = 0.0798s	
542/4200 (epoch 6.452), train_loss = 1.94106070, grad/param norm = 2.4869e-01, time/batch = 0.0781s	
543/4200 (epoch 6.464), train_loss = 1.91718419, grad/param norm = 2.6332e-01, time/batch = 0.0782s	
544/4200 (epoch 6.476), train_loss = 1.92639902, grad/param norm = 2.6525e-01, time/batch = 0.0814s	
545/4200 (epoch 6.488), train_loss = 1.92979897, grad/param norm = 2.3195e-01, time/batch = 0.0784s	
546/4200 (epoch 6.500), train_loss = 1.90361782, grad/param norm = 2.0663e-01, time/batch = 0.0779s	
547/4200 (epoch 6.512), train_loss = 1.91654819, grad/param norm = 2.1658e-01, time/batch = 0.0784s	
548/4200 (epoch 6.524), train_loss = 1.89736423, grad/param norm = 2.2067e-01, time/batch = 0.0778s	
549/4200 (epoch 6.536), train_loss = 1.90317480, grad/param norm = 2.0294e-01, time/batch = 0.0786s	
550/4200 (epoch 6.548), train_loss = 1.89250242, grad/param norm = 1.9035e-01, time/batch = 0.0787s	
551/4200 (epoch 6.560), train_loss = 1.90570563, grad/param norm = 1.9494e-01, time/batch = 0.0800s	
552/4200 (epoch 6.571), train_loss = 1.88683806, grad/param norm = 2.2344e-01, time/batch = 0.0782s	
553/4200 (epoch 6.583), train_loss = 1.92940138, grad/param norm = 2.5435e-01, time/batch = 0.0784s	
554/4200 (epoch 6.595), train_loss = 1.91085329, grad/param norm = 2.4754e-01, time/batch = 0.0784s	
555/4200 (epoch 6.607), train_loss = 1.90085793, grad/param norm = 2.2559e-01, time/batch = 0.0788s	
556/4200 (epoch 6.619), train_loss = 1.91328213, grad/param norm = 2.3809e-01, time/batch = 0.0779s	
557/4200 (epoch 6.631), train_loss = 1.89002181, grad/param norm = 2.5371e-01, time/batch = 0.0783s	
558/4200 (epoch 6.643), train_loss = 1.89564151, grad/param norm = 2.4221e-01, time/batch = 0.0778s	
559/4200 (epoch 6.655), train_loss = 1.88433152, grad/param norm = 2.4269e-01, time/batch = 0.0785s	
560/4200 (epoch 6.667), train_loss = 1.89791550, grad/param norm = 2.8438e-01, time/batch = 0.0785s	
561/4200 (epoch 6.679), train_loss = 1.90866487, grad/param norm = 3.1607e-01, time/batch = 0.0799s	
562/4200 (epoch 6.690), train_loss = 1.90669967, grad/param norm = 3.1116e-01, time/batch = 0.0781s	
563/4200 (epoch 6.702), train_loss = 1.89505420, grad/param norm = 2.4741e-01, time/batch = 0.0782s	
564/4200 (epoch 6.714), train_loss = 1.91039217, grad/param norm = 1.6691e-01, time/batch = 0.0782s	
565/4200 (epoch 6.726), train_loss = 1.89064358, grad/param norm = 1.4213e-01, time/batch = 0.0789s	
566/4200 (epoch 6.738), train_loss = 1.88797559, grad/param norm = 1.3606e-01, time/batch = 0.0781s	
567/4200 (epoch 6.750), train_loss = 1.88643388, grad/param norm = 1.4220e-01, time/batch = 0.0785s	
568/4200 (epoch 6.762), train_loss = 1.88425171, grad/param norm = 1.6117e-01, time/batch = 0.0780s	
569/4200 (epoch 6.774), train_loss = 1.90117480, grad/param norm = 1.9510e-01, time/batch = 0.0783s	
570/4200 (epoch 6.786), train_loss = 1.88774590, grad/param norm = 2.2469e-01, time/batch = 0.0782s	
571/4200 (epoch 6.798), train_loss = 1.91319503, grad/param norm = 2.1368e-01, time/batch = 0.0800s	
572/4200 (epoch 6.810), train_loss = 1.88842407, grad/param norm = 1.8443e-01, time/batch = 0.0780s	
573/4200 (epoch 6.821), train_loss = 1.88627033, grad/param norm = 1.9223e-01, time/batch = 0.0783s	
574/4200 (epoch 6.833), train_loss = 1.89091924, grad/param norm = 1.8545e-01, time/batch = 0.0782s	
575/4200 (epoch 6.845), train_loss = 1.91686700, grad/param norm = 1.7254e-01, time/batch = 0.0783s	
576/4200 (epoch 6.857), train_loss = 1.90022192, grad/param norm = 2.1345e-01, time/batch = 0.0786s	
577/4200 (epoch 6.869), train_loss = 1.92073565, grad/param norm = 2.6160e-01, time/batch = 0.0784s	
578/4200 (epoch 6.881), train_loss = 1.90444114, grad/param norm = 3.2737e-01, time/batch = 0.0779s	
579/4200 (epoch 6.893), train_loss = 1.93278868, grad/param norm = 2.9993e-01, time/batch = 0.0783s	
580/4200 (epoch 6.905), train_loss = 1.87453723, grad/param norm = 2.3321e-01, time/batch = 0.0781s	
581/4200 (epoch 6.917), train_loss = 1.90243680, grad/param norm = 2.1906e-01, time/batch = 0.0803s	
582/4200 (epoch 6.929), train_loss = 1.87855137, grad/param norm = 1.9301e-01, time/batch = 0.0781s	
583/4200 (epoch 6.940), train_loss = 1.88616258, grad/param norm = 1.5938e-01, time/batch = 0.0782s	
584/4200 (epoch 6.952), train_loss = 1.87261173, grad/param norm = 1.6022e-01, time/batch = 0.0783s	
585/4200 (epoch 6.964), train_loss = 1.89445193, grad/param norm = 1.6623e-01, time/batch = 0.0784s	
586/4200 (epoch 6.976), train_loss = 1.88558133, grad/param norm = 1.7437e-01, time/batch = 0.0781s	
587/4200 (epoch 6.988), train_loss = 1.87633882, grad/param norm = 1.9621e-01, time/batch = 0.0786s	
588/4200 (epoch 7.000), train_loss = 1.90652992, grad/param norm = 2.5714e-01, time/batch = 0.0778s	
589/4200 (epoch 7.012), train_loss = 1.98253719, grad/param norm = 2.7267e-01, time/batch = 0.0783s	
590/4200 (epoch 7.024), train_loss = 1.86384395, grad/param norm = 2.3340e-01, time/batch = 0.0781s	
591/4200 (epoch 7.036), train_loss = 1.87644093, grad/param norm = 2.0063e-01, time/batch = 0.0798s	
592/4200 (epoch 7.048), train_loss = 1.84780283, grad/param norm = 1.6850e-01, time/batch = 0.0786s	
593/4200 (epoch 7.060), train_loss = 1.86411400, grad/param norm = 1.5280e-01, time/batch = 0.0780s	
594/4200 (epoch 7.071), train_loss = 1.85838946, grad/param norm = 1.6074e-01, time/batch = 0.0784s	
595/4200 (epoch 7.083), train_loss = 1.87527154, grad/param norm = 1.8099e-01, time/batch = 0.0784s	
596/4200 (epoch 7.095), train_loss = 1.84424858, grad/param norm = 1.7878e-01, time/batch = 0.0778s	
597/4200 (epoch 7.107), train_loss = 1.84420372, grad/param norm = 1.5650e-01, time/batch = 0.0788s	
598/4200 (epoch 7.119), train_loss = 1.84868700, grad/param norm = 1.7801e-01, time/batch = 0.0778s	
599/4200 (epoch 7.131), train_loss = 1.86009135, grad/param norm = 2.0711e-01, time/batch = 0.0784s	
600/4200 (epoch 7.143), train_loss = 1.86928004, grad/param norm = 2.2790e-01, time/batch = 0.0781s	
601/4200 (epoch 7.155), train_loss = 1.85927911, grad/param norm = 2.5251e-01, time/batch = 0.0799s	
602/4200 (epoch 7.167), train_loss = 1.87446952, grad/param norm = 2.6822e-01, time/batch = 0.0785s	
603/4200 (epoch 7.179), train_loss = 1.87924713, grad/param norm = 2.4587e-01, time/batch = 0.0782s	
604/4200 (epoch 7.190), train_loss = 1.84977515, grad/param norm = 2.2632e-01, time/batch = 0.0782s	
605/4200 (epoch 7.202), train_loss = 1.85998358, grad/param norm = 2.1435e-01, time/batch = 0.0782s	
606/4200 (epoch 7.214), train_loss = 1.86685502, grad/param norm = 2.2171e-01, time/batch = 0.0777s	
607/4200 (epoch 7.226), train_loss = 1.85358883, grad/param norm = 2.3030e-01, time/batch = 0.0784s	
608/4200 (epoch 7.238), train_loss = 1.85321028, grad/param norm = 2.2998e-01, time/batch = 0.0784s	
609/4200 (epoch 7.250), train_loss = 1.83546232, grad/param norm = 2.0529e-01, time/batch = 0.0784s	
610/4200 (epoch 7.262), train_loss = 1.83838458, grad/param norm = 1.8645e-01, time/batch = 0.0783s	
611/4200 (epoch 7.274), train_loss = 1.86042762, grad/param norm = 1.9149e-01, time/batch = 0.0810s	
612/4200 (epoch 7.286), train_loss = 1.84518145, grad/param norm = 2.0819e-01, time/batch = 0.0783s	
613/4200 (epoch 7.298), train_loss = 1.85947436, grad/param norm = 1.9788e-01, time/batch = 0.0788s	
614/4200 (epoch 7.310), train_loss = 1.85465009, grad/param norm = 1.7233e-01, time/batch = 0.0780s	
615/4200 (epoch 7.321), train_loss = 1.80580150, grad/param norm = 1.5081e-01, time/batch = 0.0785s	
616/4200 (epoch 7.333), train_loss = 1.84530257, grad/param norm = 1.5617e-01, time/batch = 0.0780s	
617/4200 (epoch 7.345), train_loss = 1.82996027, grad/param norm = 1.6242e-01, time/batch = 0.0784s	
618/4200 (epoch 7.357), train_loss = 1.83317106, grad/param norm = 1.6966e-01, time/batch = 0.0784s	
619/4200 (epoch 7.369), train_loss = 1.84704148, grad/param norm = 1.7506e-01, time/batch = 0.0785s	
620/4200 (epoch 7.381), train_loss = 1.86411546, grad/param norm = 1.7428e-01, time/batch = 0.0781s	
621/4200 (epoch 7.393), train_loss = 1.84845605, grad/param norm = 1.8902e-01, time/batch = 0.0798s	
622/4200 (epoch 7.405), train_loss = 1.85357910, grad/param norm = 2.2535e-01, time/batch = 0.0780s	
623/4200 (epoch 7.417), train_loss = 1.82953651, grad/param norm = 2.6651e-01, time/batch = 0.0787s	
624/4200 (epoch 7.429), train_loss = 1.84325688, grad/param norm = 2.6301e-01, time/batch = 0.0780s	
625/4200 (epoch 7.440), train_loss = 1.85702953, grad/param norm = 2.2488e-01, time/batch = 0.0783s	
626/4200 (epoch 7.452), train_loss = 1.86197772, grad/param norm = 2.0485e-01, time/batch = 0.0778s	
627/4200 (epoch 7.464), train_loss = 1.82754851, grad/param norm = 1.8356e-01, time/batch = 0.0783s	
628/4200 (epoch 7.476), train_loss = 1.84328228, grad/param norm = 1.7432e-01, time/batch = 0.0778s	
629/4200 (epoch 7.488), train_loss = 1.85230120, grad/param norm = 2.1835e-01, time/batch = 0.0789s	
630/4200 (epoch 7.500), train_loss = 1.83476592, grad/param norm = 2.3497e-01, time/batch = 0.0780s	
631/4200 (epoch 7.512), train_loss = 1.84357454, grad/param norm = 2.2509e-01, time/batch = 0.0798s	
632/4200 (epoch 7.524), train_loss = 1.81736297, grad/param norm = 1.9836e-01, time/batch = 0.0782s	
633/4200 (epoch 7.536), train_loss = 1.82088698, grad/param norm = 1.7555e-01, time/batch = 0.0782s	
634/4200 (epoch 7.548), train_loss = 1.81490524, grad/param norm = 1.9941e-01, time/batch = 0.0786s	
635/4200 (epoch 7.560), train_loss = 1.83691419, grad/param norm = 2.2644e-01, time/batch = 0.0782s	
636/4200 (epoch 7.571), train_loss = 1.80091617, grad/param norm = 1.9599e-01, time/batch = 0.0779s	
637/4200 (epoch 7.583), train_loss = 1.83337877, grad/param norm = 1.4879e-01, time/batch = 0.0793s	
638/4200 (epoch 7.595), train_loss = 1.80634012, grad/param norm = 1.2389e-01, time/batch = 0.0779s	
639/4200 (epoch 7.607), train_loss = 1.81311534, grad/param norm = 1.3710e-01, time/batch = 0.0788s	
640/4200 (epoch 7.619), train_loss = 1.81910671, grad/param norm = 1.4388e-01, time/batch = 0.0782s	
641/4200 (epoch 7.631), train_loss = 1.80261207, grad/param norm = 1.2325e-01, time/batch = 0.0798s	
642/4200 (epoch 7.643), train_loss = 1.80125403, grad/param norm = 1.1863e-01, time/batch = 0.0781s	
643/4200 (epoch 7.655), train_loss = 1.79483154, grad/param norm = 1.3122e-01, time/batch = 0.0779s	
644/4200 (epoch 7.667), train_loss = 1.80973967, grad/param norm = 1.6460e-01, time/batch = 0.0782s	
645/4200 (epoch 7.679), train_loss = 1.82160105, grad/param norm = 2.0801e-01, time/batch = 0.0784s	
646/4200 (epoch 7.690), train_loss = 1.82637211, grad/param norm = 2.6310e-01, time/batch = 0.0779s	
647/4200 (epoch 7.702), train_loss = 1.82765094, grad/param norm = 2.3949e-01, time/batch = 0.0784s	
648/4200 (epoch 7.714), train_loss = 1.84366267, grad/param norm = 2.1504e-01, time/batch = 0.0777s	
649/4200 (epoch 7.726), train_loss = 1.83511415, grad/param norm = 2.2626e-01, time/batch = 0.0823s	
650/4200 (epoch 7.738), train_loss = 1.83128732, grad/param norm = 2.2172e-01, time/batch = 0.0807s	
651/4200 (epoch 7.750), train_loss = 1.82602759, grad/param norm = 2.2197e-01, time/batch = 0.0800s	
652/4200 (epoch 7.762), train_loss = 1.81559437, grad/param norm = 1.9651e-01, time/batch = 0.0780s	
653/4200 (epoch 7.774), train_loss = 1.82447468, grad/param norm = 1.7070e-01, time/batch = 0.0782s	
654/4200 (epoch 7.786), train_loss = 1.79787967, grad/param norm = 1.5883e-01, time/batch = 0.0782s	
655/4200 (epoch 7.798), train_loss = 1.82541510, grad/param norm = 1.4934e-01, time/batch = 0.0786s	
656/4200 (epoch 7.810), train_loss = 1.80286706, grad/param norm = 1.5691e-01, time/batch = 0.0777s	
657/4200 (epoch 7.821), train_loss = 1.81050113, grad/param norm = 1.9447e-01, time/batch = 0.0783s	
658/4200 (epoch 7.833), train_loss = 1.81673048, grad/param norm = 2.0878e-01, time/batch = 0.0780s	
659/4200 (epoch 7.845), train_loss = 1.85142305, grad/param norm = 2.1308e-01, time/batch = 0.0784s	
660/4200 (epoch 7.857), train_loss = 1.83771920, grad/param norm = 2.1911e-01, time/batch = 0.0782s	
661/4200 (epoch 7.869), train_loss = 1.85172301, grad/param norm = 2.0652e-01, time/batch = 0.0799s	
662/4200 (epoch 7.881), train_loss = 1.82937087, grad/param norm = 2.1758e-01, time/batch = 0.0781s	
663/4200 (epoch 7.893), train_loss = 1.84709605, grad/param norm = 2.0044e-01, time/batch = 0.0782s	
664/4200 (epoch 7.905), train_loss = 1.80470349, grad/param norm = 1.7984e-01, time/batch = 0.0782s	
665/4200 (epoch 7.917), train_loss = 1.82776626, grad/param norm = 1.5193e-01, time/batch = 0.0783s	
666/4200 (epoch 7.929), train_loss = 1.80430155, grad/param norm = 1.3536e-01, time/batch = 0.0784s	
667/4200 (epoch 7.940), train_loss = 1.80894251, grad/param norm = 1.3050e-01, time/batch = 0.0783s	
668/4200 (epoch 7.952), train_loss = 1.80049932, grad/param norm = 1.4018e-01, time/batch = 0.0776s	
669/4200 (epoch 7.964), train_loss = 1.82555871, grad/param norm = 1.8409e-01, time/batch = 0.0783s	
670/4200 (epoch 7.976), train_loss = 1.83005511, grad/param norm = 2.2372e-01, time/batch = 0.0782s	
671/4200 (epoch 7.988), train_loss = 1.81719752, grad/param norm = 2.5825e-01, time/batch = 0.0804s	
672/4200 (epoch 8.000), train_loss = 1.84421204, grad/param norm = 2.3732e-01, time/batch = 0.0781s	
673/4200 (epoch 8.012), train_loss = 1.89993814, grad/param norm = 2.0797e-01, time/batch = 0.0782s	
674/4200 (epoch 8.024), train_loss = 1.77960211, grad/param norm = 1.7977e-01, time/batch = 0.0782s	
675/4200 (epoch 8.036), train_loss = 1.79220439, grad/param norm = 1.6817e-01, time/batch = 0.0784s	
676/4200 (epoch 8.048), train_loss = 1.77470477, grad/param norm = 1.7678e-01, time/batch = 0.0784s	
677/4200 (epoch 8.060), train_loss = 1.80129269, grad/param norm = 1.8602e-01, time/batch = 0.0783s	
678/4200 (epoch 8.071), train_loss = 1.79061135, grad/param norm = 1.6950e-01, time/batch = 0.0777s	
679/4200 (epoch 8.083), train_loss = 1.80475827, grad/param norm = 1.5342e-01, time/batch = 0.0785s	
680/4200 (epoch 8.095), train_loss = 1.76913942, grad/param norm = 1.5329e-01, time/batch = 0.0783s	
681/4200 (epoch 8.107), train_loss = 1.77541282, grad/param norm = 1.3326e-01, time/batch = 0.0804s	
682/4200 (epoch 8.119), train_loss = 1.77473950, grad/param norm = 1.3503e-01, time/batch = 0.0782s	
683/4200 (epoch 8.131), train_loss = 1.78124900, grad/param norm = 1.3402e-01, time/batch = 0.0782s	
684/4200 (epoch 8.143), train_loss = 1.78686080, grad/param norm = 1.2084e-01, time/batch = 0.0783s	
685/4200 (epoch 8.155), train_loss = 1.76657968, grad/param norm = 1.2347e-01, time/batch = 0.0783s	
686/4200 (epoch 8.167), train_loss = 1.78636456, grad/param norm = 1.4558e-01, time/batch = 0.0780s	
687/4200 (epoch 8.179), train_loss = 1.80043875, grad/param norm = 1.5467e-01, time/batch = 0.0790s	
688/4200 (epoch 8.190), train_loss = 1.77194741, grad/param norm = 1.4861e-01, time/batch = 0.0778s	
689/4200 (epoch 8.202), train_loss = 1.78603596, grad/param norm = 1.4863e-01, time/batch = 0.0788s	
690/4200 (epoch 8.214), train_loss = 1.79319479, grad/param norm = 1.6209e-01, time/batch = 0.0784s	
691/4200 (epoch 8.226), train_loss = 1.78354711, grad/param norm = 2.0003e-01, time/batch = 0.0799s	
692/4200 (epoch 8.238), train_loss = 1.78555774, grad/param norm = 2.0845e-01, time/batch = 0.0789s	
693/4200 (epoch 8.250), train_loss = 1.76957572, grad/param norm = 2.2038e-01, time/batch = 0.0782s	
694/4200 (epoch 8.262), train_loss = 1.76927302, grad/param norm = 2.0005e-01, time/batch = 0.0782s	
695/4200 (epoch 8.274), train_loss = 1.78891102, grad/param norm = 1.5565e-01, time/batch = 0.0784s	
696/4200 (epoch 8.286), train_loss = 1.77197271, grad/param norm = 1.4238e-01, time/batch = 0.0779s	
697/4200 (epoch 8.298), train_loss = 1.77164878, grad/param norm = 1.3742e-01, time/batch = 0.0789s	
698/4200 (epoch 8.310), train_loss = 1.78424901, grad/param norm = 1.5206e-01, time/batch = 0.0778s	
699/4200 (epoch 8.321), train_loss = 1.74536267, grad/param norm = 2.0548e-01, time/batch = 0.0785s	
700/4200 (epoch 8.333), train_loss = 1.80653150, grad/param norm = 2.6428e-01, time/batch = 0.0783s	
701/4200 (epoch 8.345), train_loss = 1.80243729, grad/param norm = 2.8406e-01, time/batch = 0.0799s	
702/4200 (epoch 8.357), train_loss = 1.78881467, grad/param norm = 2.4051e-01, time/batch = 0.0780s	
703/4200 (epoch 8.369), train_loss = 1.78856573, grad/param norm = 1.7109e-01, time/batch = 0.0783s	
704/4200 (epoch 8.381), train_loss = 1.78821711, grad/param norm = 1.2978e-01, time/batch = 0.0783s	
705/4200 (epoch 8.393), train_loss = 1.77635060, grad/param norm = 1.2462e-01, time/batch = 0.0783s	
706/4200 (epoch 8.405), train_loss = 1.77525700, grad/param norm = 1.3562e-01, time/batch = 0.0779s	
707/4200 (epoch 8.417), train_loss = 1.74311108, grad/param norm = 1.6116e-01, time/batch = 0.0783s	
708/4200 (epoch 8.429), train_loss = 1.76468112, grad/param norm = 1.9031e-01, time/batch = 0.0781s	
709/4200 (epoch 8.440), train_loss = 1.78978707, grad/param norm = 1.9712e-01, time/batch = 0.0783s	
710/4200 (epoch 8.452), train_loss = 1.80008572, grad/param norm = 1.8273e-01, time/batch = 0.0782s	
711/4200 (epoch 8.464), train_loss = 1.76357222, grad/param norm = 1.6103e-01, time/batch = 0.0797s	
712/4200 (epoch 8.476), train_loss = 1.77881355, grad/param norm = 1.5806e-01, time/batch = 0.0781s	
713/4200 (epoch 8.488), train_loss = 1.79246955, grad/param norm = 1.8744e-01, time/batch = 0.0786s	
714/4200 (epoch 8.500), train_loss = 1.76589823, grad/param norm = 1.7327e-01, time/batch = 0.0781s	
715/4200 (epoch 8.512), train_loss = 1.77081342, grad/param norm = 1.5013e-01, time/batch = 0.0783s	
716/4200 (epoch 8.524), train_loss = 1.74255848, grad/param norm = 1.2586e-01, time/batch = 0.0778s	
717/4200 (epoch 8.536), train_loss = 1.75023674, grad/param norm = 1.1356e-01, time/batch = 0.0782s	
718/4200 (epoch 8.548), train_loss = 1.74274931, grad/param norm = 1.2260e-01, time/batch = 0.0777s	
719/4200 (epoch 8.560), train_loss = 1.75535687, grad/param norm = 1.3306e-01, time/batch = 0.0788s	
720/4200 (epoch 8.571), train_loss = 1.72478765, grad/param norm = 1.2821e-01, time/batch = 0.0781s	
721/4200 (epoch 8.583), train_loss = 1.76378777, grad/param norm = 1.3856e-01, time/batch = 0.0799s	
722/4200 (epoch 8.595), train_loss = 1.75195899, grad/param norm = 1.6283e-01, time/batch = 0.0781s	
723/4200 (epoch 8.607), train_loss = 1.75640262, grad/param norm = 1.8747e-01, time/batch = 0.0782s	
724/4200 (epoch 8.619), train_loss = 1.76719346, grad/param norm = 2.1173e-01, time/batch = 0.0788s	
725/4200 (epoch 8.631), train_loss = 1.75937099, grad/param norm = 2.3657e-01, time/batch = 0.0784s	
726/4200 (epoch 8.643), train_loss = 1.76411224, grad/param norm = 2.2319e-01, time/batch = 0.0777s	
727/4200 (epoch 8.655), train_loss = 1.75203970, grad/param norm = 2.0358e-01, time/batch = 0.0784s	
728/4200 (epoch 8.667), train_loss = 1.75952592, grad/param norm = 1.7377e-01, time/batch = 0.0776s	
729/4200 (epoch 8.679), train_loss = 1.75009043, grad/param norm = 1.3233e-01, time/batch = 0.0787s	
730/4200 (epoch 8.690), train_loss = 1.73764096, grad/param norm = 1.1906e-01, time/batch = 0.0780s	
731/4200 (epoch 8.702), train_loss = 1.73989365, grad/param norm = 1.2230e-01, time/batch = 0.0798s	
732/4200 (epoch 8.714), train_loss = 1.76494546, grad/param norm = 1.2509e-01, time/batch = 0.0780s	
733/4200 (epoch 8.726), train_loss = 1.75621647, grad/param norm = 1.2958e-01, time/batch = 0.0782s	
734/4200 (epoch 8.738), train_loss = 1.75650432, grad/param norm = 1.5379e-01, time/batch = 0.0787s	
735/4200 (epoch 8.750), train_loss = 1.75730372, grad/param norm = 1.7072e-01, time/batch = 0.0785s	
736/4200 (epoch 8.762), train_loss = 1.75253638, grad/param norm = 1.6483e-01, time/batch = 0.0779s	
737/4200 (epoch 8.774), train_loss = 1.76659142, grad/param norm = 1.6362e-01, time/batch = 0.0783s	
738/4200 (epoch 8.786), train_loss = 1.74551136, grad/param norm = 1.8920e-01, time/batch = 0.0776s	
739/4200 (epoch 8.798), train_loss = 1.77668908, grad/param norm = 2.1223e-01, time/batch = 0.0784s	
740/4200 (epoch 8.810), train_loss = 1.76247887, grad/param norm = 1.9415e-01, time/batch = 0.0785s	
741/4200 (epoch 8.821), train_loss = 1.74793018, grad/param norm = 1.6751e-01, time/batch = 0.0798s	
742/4200 (epoch 8.833), train_loss = 1.75612124, grad/param norm = 1.3237e-01, time/batch = 0.0790s	
743/4200 (epoch 8.845), train_loss = 1.77416659, grad/param norm = 1.1771e-01, time/batch = 0.0784s	
744/4200 (epoch 8.857), train_loss = 1.76024137, grad/param norm = 1.2790e-01, time/batch = 0.0784s	
745/4200 (epoch 8.869), train_loss = 1.77966223, grad/param norm = 1.3632e-01, time/batch = 0.0791s	
746/4200 (epoch 8.881), train_loss = 1.75569530, grad/param norm = 1.6175e-01, time/batch = 0.0778s	
747/4200 (epoch 8.893), train_loss = 1.78186573, grad/param norm = 1.6811e-01, time/batch = 0.0786s	
748/4200 (epoch 8.905), train_loss = 1.74132900, grad/param norm = 1.6520e-01, time/batch = 0.0776s	
749/4200 (epoch 8.917), train_loss = 1.77246812, grad/param norm = 1.7950e-01, time/batch = 0.0782s	
750/4200 (epoch 8.929), train_loss = 1.75306984, grad/param norm = 1.8047e-01, time/batch = 0.0785s	
751/4200 (epoch 8.940), train_loss = 1.75285721, grad/param norm = 1.6618e-01, time/batch = 0.0797s	
752/4200 (epoch 8.952), train_loss = 1.75100605, grad/param norm = 1.8031e-01, time/batch = 0.0778s	
753/4200 (epoch 8.964), train_loss = 1.77531039, grad/param norm = 1.9656e-01, time/batch = 0.0783s	
754/4200 (epoch 8.976), train_loss = 1.76082078, grad/param norm = 1.7967e-01, time/batch = 0.0782s	
755/4200 (epoch 8.988), train_loss = 1.74679677, grad/param norm = 1.6416e-01, time/batch = 0.0831s	
756/4200 (epoch 9.000), train_loss = 1.77410371, grad/param norm = 1.7017e-01, time/batch = 0.0784s	
757/4200 (epoch 9.012), train_loss = 1.84953667, grad/param norm = 1.6686e-01, time/batch = 0.0786s	
758/4200 (epoch 9.024), train_loss = 1.72350311, grad/param norm = 1.5570e-01, time/batch = 0.0778s	
759/4200 (epoch 9.036), train_loss = 1.73560616, grad/param norm = 1.4577e-01, time/batch = 0.0785s	
760/4200 (epoch 9.048), train_loss = 1.70847739, grad/param norm = 1.2677e-01, time/batch = 0.0781s	
761/4200 (epoch 9.060), train_loss = 1.72986589, grad/param norm = 1.0963e-01, time/batch = 0.0799s	
762/4200 (epoch 9.071), train_loss = 1.71732867, grad/param norm = 1.0948e-01, time/batch = 0.0781s	
763/4200 (epoch 9.083), train_loss = 1.73886099, grad/param norm = 1.3508e-01, time/batch = 0.0783s	
764/4200 (epoch 9.095), train_loss = 1.70550407, grad/param norm = 1.4067e-01, time/batch = 0.0782s	
765/4200 (epoch 9.107), train_loss = 1.71354231, grad/param norm = 1.0886e-01, time/batch = 0.0783s	
766/4200 (epoch 9.119), train_loss = 1.71102854, grad/param norm = 1.0865e-01, time/batch = 0.0787s	
767/4200 (epoch 9.131), train_loss = 1.71801453, grad/param norm = 1.1616e-01, time/batch = 0.0784s	
768/4200 (epoch 9.143), train_loss = 1.72870020, grad/param norm = 1.1797e-01, time/batch = 0.0778s	
769/4200 (epoch 9.155), train_loss = 1.71059115, grad/param norm = 1.4167e-01, time/batch = 0.0784s	
770/4200 (epoch 9.167), train_loss = 1.74407971, grad/param norm = 1.7869e-01, time/batch = 0.0779s	
771/4200 (epoch 9.179), train_loss = 1.76294340, grad/param norm = 2.0052e-01, time/batch = 0.0801s	
772/4200 (epoch 9.190), train_loss = 1.73680343, grad/param norm = 1.8512e-01, time/batch = 0.0781s	
773/4200 (epoch 9.202), train_loss = 1.73992734, grad/param norm = 1.6019e-01, time/batch = 0.0782s	
774/4200 (epoch 9.214), train_loss = 1.74032884, grad/param norm = 1.6277e-01, time/batch = 0.0783s	
775/4200 (epoch 9.226), train_loss = 1.73213243, grad/param norm = 1.8136e-01, time/batch = 0.0783s	
776/4200 (epoch 9.238), train_loss = 1.73437287, grad/param norm = 2.2243e-01, time/batch = 0.0779s	
777/4200 (epoch 9.250), train_loss = 1.72021695, grad/param norm = 2.1622e-01, time/batch = 0.0786s	
778/4200 (epoch 9.262), train_loss = 1.70558465, grad/param norm = 1.8491e-01, time/batch = 0.0778s	
779/4200 (epoch 9.274), train_loss = 1.73849852, grad/param norm = 1.6631e-01, time/batch = 0.0783s	
780/4200 (epoch 9.286), train_loss = 1.71905728, grad/param norm = 1.5337e-01, time/batch = 0.0779s	
781/4200 (epoch 9.298), train_loss = 1.71578961, grad/param norm = 1.4060e-01, time/batch = 0.0799s	
782/4200 (epoch 9.310), train_loss = 1.72992556, grad/param norm = 1.4808e-01, time/batch = 0.0785s	
783/4200 (epoch 9.321), train_loss = 1.67874517, grad/param norm = 1.2539e-01, time/batch = 0.0783s	
784/4200 (epoch 9.333), train_loss = 1.71662508, grad/param norm = 1.0813e-01, time/batch = 0.0783s	
785/4200 (epoch 9.345), train_loss = 1.69839957, grad/param norm = 1.0073e-01, time/batch = 0.0785s	
786/4200 (epoch 9.357), train_loss = 1.69999043, grad/param norm = 1.0470e-01, time/batch = 0.0779s	
787/4200 (epoch 9.369), train_loss = 1.72236636, grad/param norm = 1.1749e-01, time/batch = 0.0788s	
788/4200 (epoch 9.381), train_loss = 1.73310464, grad/param norm = 1.3148e-01, time/batch = 0.0777s	
789/4200 (epoch 9.393), train_loss = 1.72620709, grad/param norm = 1.2381e-01, time/batch = 0.0783s	
790/4200 (epoch 9.405), train_loss = 1.72415448, grad/param norm = 1.4142e-01, time/batch = 0.0781s	
791/4200 (epoch 9.417), train_loss = 1.69744988, grad/param norm = 1.6872e-01, time/batch = 0.0799s	
792/4200 (epoch 9.429), train_loss = 1.71701978, grad/param norm = 1.9942e-01, time/batch = 0.0784s	
793/4200 (epoch 9.440), train_loss = 1.74656947, grad/param norm = 2.0602e-01, time/batch = 0.0781s	
794/4200 (epoch 9.452), train_loss = 1.74688769, grad/param norm = 1.7822e-01, time/batch = 0.0783s	
795/4200 (epoch 9.464), train_loss = 1.71354207, grad/param norm = 1.5315e-01, time/batch = 0.0784s	
796/4200 (epoch 9.476), train_loss = 1.72501811, grad/param norm = 1.4707e-01, time/batch = 0.0779s	
797/4200 (epoch 9.488), train_loss = 1.73425313, grad/param norm = 1.3829e-01, time/batch = 0.0785s	
798/4200 (epoch 9.500), train_loss = 1.70986409, grad/param norm = 1.5237e-01, time/batch = 0.0784s	
799/4200 (epoch 9.512), train_loss = 1.72234203, grad/param norm = 1.6884e-01, time/batch = 0.0783s	
800/4200 (epoch 9.524), train_loss = 1.69141704, grad/param norm = 1.7798e-01, time/batch = 0.0782s	
801/4200 (epoch 9.536), train_loss = 1.70729474, grad/param norm = 1.7502e-01, time/batch = 0.0799s	
802/4200 (epoch 9.548), train_loss = 1.69291554, grad/param norm = 1.6571e-01, time/batch = 0.0781s	
803/4200 (epoch 9.560), train_loss = 1.70945481, grad/param norm = 1.6048e-01, time/batch = 0.0787s	
804/4200 (epoch 9.571), train_loss = 1.66931951, grad/param norm = 1.5777e-01, time/batch = 0.0782s	
805/4200 (epoch 9.583), train_loss = 1.71449322, grad/param norm = 1.5202e-01, time/batch = 0.0784s	
806/4200 (epoch 9.595), train_loss = 1.69791810, grad/param norm = 1.5969e-01, time/batch = 0.0781s	
807/4200 (epoch 9.607), train_loss = 1.70356230, grad/param norm = 1.5671e-01, time/batch = 0.0783s	
808/4200 (epoch 9.619), train_loss = 1.69865830, grad/param norm = 1.4713e-01, time/batch = 0.0782s	
809/4200 (epoch 9.631), train_loss = 1.69414599, grad/param norm = 1.4072e-01, time/batch = 0.0784s	
810/4200 (epoch 9.643), train_loss = 1.69149147, grad/param norm = 1.3689e-01, time/batch = 0.0780s	
811/4200 (epoch 9.655), train_loss = 1.68351019, grad/param norm = 1.2052e-01, time/batch = 0.0800s	
812/4200 (epoch 9.667), train_loss = 1.69708290, grad/param norm = 1.2503e-01, time/batch = 0.0780s	
813/4200 (epoch 9.679), train_loss = 1.70309267, grad/param norm = 1.4680e-01, time/batch = 0.0787s	
814/4200 (epoch 9.690), train_loss = 1.69674741, grad/param norm = 1.6880e-01, time/batch = 0.0782s	
815/4200 (epoch 9.702), train_loss = 1.70397060, grad/param norm = 1.6109e-01, time/batch = 0.0782s	
816/4200 (epoch 9.714), train_loss = 1.72443101, grad/param norm = 1.5495e-01, time/batch = 0.0779s	
817/4200 (epoch 9.726), train_loss = 1.71978361, grad/param norm = 1.5994e-01, time/batch = 0.0784s	
818/4200 (epoch 9.738), train_loss = 1.71653415, grad/param norm = 1.4721e-01, time/batch = 0.0778s	
819/4200 (epoch 9.750), train_loss = 1.69712551, grad/param norm = 1.3161e-01, time/batch = 0.0789s	
820/4200 (epoch 9.762), train_loss = 1.69239780, grad/param norm = 1.1350e-01, time/batch = 0.0781s	
821/4200 (epoch 9.774), train_loss = 1.70543983, grad/param norm = 1.0814e-01, time/batch = 0.0798s	
822/4200 (epoch 9.786), train_loss = 1.68249423, grad/param norm = 1.2060e-01, time/batch = 0.0782s	
823/4200 (epoch 9.798), train_loss = 1.71008939, grad/param norm = 1.3655e-01, time/batch = 0.0782s	
824/4200 (epoch 9.810), train_loss = 1.69387547, grad/param norm = 1.1774e-01, time/batch = 0.0784s	
825/4200 (epoch 9.821), train_loss = 1.68614925, grad/param norm = 1.2597e-01, time/batch = 0.0783s	
826/4200 (epoch 9.833), train_loss = 1.71080432, grad/param norm = 1.6055e-01, time/batch = 0.0778s	
827/4200 (epoch 9.845), train_loss = 1.74110727, grad/param norm = 1.6940e-01, time/batch = 0.0785s	
828/4200 (epoch 9.857), train_loss = 1.72147691, grad/param norm = 1.5199e-01, time/batch = 0.0777s	
829/4200 (epoch 9.869), train_loss = 1.73221805, grad/param norm = 1.4304e-01, time/batch = 0.0783s	
830/4200 (epoch 9.881), train_loss = 1.70708925, grad/param norm = 1.6335e-01, time/batch = 0.0784s	
831/4200 (epoch 9.893), train_loss = 1.73135949, grad/param norm = 1.7018e-01, time/batch = 0.0799s	
832/4200 (epoch 9.905), train_loss = 1.69319058, grad/param norm = 1.6944e-01, time/batch = 0.0780s	
833/4200 (epoch 9.917), train_loss = 1.72476326, grad/param norm = 1.8039e-01, time/batch = 0.0782s	
834/4200 (epoch 9.929), train_loss = 1.70436085, grad/param norm = 1.6858e-01, time/batch = 0.0781s	
835/4200 (epoch 9.940), train_loss = 1.70102180, grad/param norm = 1.4769e-01, time/batch = 0.0786s	
836/4200 (epoch 9.952), train_loss = 1.69943978, grad/param norm = 1.5550e-01, time/batch = 0.0778s	
837/4200 (epoch 9.964), train_loss = 1.72432050, grad/param norm = 1.6403e-01, time/batch = 0.0783s	
838/4200 (epoch 9.976), train_loss = 1.70707403, grad/param norm = 1.4400e-01, time/batch = 0.0778s	
839/4200 (epoch 9.988), train_loss = 1.69814869, grad/param norm = 1.3486e-01, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.00194	
840/4200 (epoch 10.000), train_loss = 1.72620815, grad/param norm = 1.5226e-01, time/batch = 0.0785s	
841/4200 (epoch 10.012), train_loss = 1.81063828, grad/param norm = 1.4398e-01, time/batch = 0.0799s	
842/4200 (epoch 10.024), train_loss = 1.66757963, grad/param norm = 1.1406e-01, time/batch = 0.0781s	
843/4200 (epoch 10.036), train_loss = 1.68376507, grad/param norm = 1.1373e-01, time/batch = 0.0783s	
844/4200 (epoch 10.048), train_loss = 1.65787373, grad/param norm = 1.1275e-01, time/batch = 0.0782s	
845/4200 (epoch 10.060), train_loss = 1.68362843, grad/param norm = 1.2220e-01, time/batch = 0.0788s	
846/4200 (epoch 10.071), train_loss = 1.67007607, grad/param norm = 1.2536e-01, time/batch = 0.0779s	
847/4200 (epoch 10.083), train_loss = 1.69015205, grad/param norm = 1.2934e-01, time/batch = 0.0783s	
848/4200 (epoch 10.095), train_loss = 1.64894848, grad/param norm = 1.2123e-01, time/batch = 0.0786s	
849/4200 (epoch 10.107), train_loss = 1.66691516, grad/param norm = 1.2266e-01, time/batch = 0.0785s	
850/4200 (epoch 10.119), train_loss = 1.66670440, grad/param norm = 1.4997e-01, time/batch = 0.0784s	
851/4200 (epoch 10.131), train_loss = 1.68399158, grad/param norm = 1.6043e-01, time/batch = 0.0800s	
852/4200 (epoch 10.143), train_loss = 1.68777003, grad/param norm = 1.5535e-01, time/batch = 0.0782s	
853/4200 (epoch 10.155), train_loss = 1.66756808, grad/param norm = 1.5286e-01, time/batch = 0.0781s	
854/4200 (epoch 10.167), train_loss = 1.69007996, grad/param norm = 1.5668e-01, time/batch = 0.0781s	
855/4200 (epoch 10.179), train_loss = 1.69962192, grad/param norm = 1.5502e-01, time/batch = 0.0782s	
856/4200 (epoch 10.190), train_loss = 1.66908900, grad/param norm = 1.3430e-01, time/batch = 0.0785s	
857/4200 (epoch 10.202), train_loss = 1.67895626, grad/param norm = 1.0414e-01, time/batch = 0.0785s	
858/4200 (epoch 10.214), train_loss = 1.67987562, grad/param norm = 1.0191e-01, time/batch = 0.0777s	
859/4200 (epoch 10.226), train_loss = 1.66960534, grad/param norm = 1.2052e-01, time/batch = 0.0784s	
860/4200 (epoch 10.238), train_loss = 1.66971498, grad/param norm = 1.3518e-01, time/batch = 0.0781s	
861/4200 (epoch 10.250), train_loss = 1.65525369, grad/param norm = 1.6547e-01, time/batch = 0.0812s	
862/4200 (epoch 10.262), train_loss = 1.65131944, grad/param norm = 1.6501e-01, time/batch = 0.0782s	
863/4200 (epoch 10.274), train_loss = 1.68978895, grad/param norm = 1.4534e-01, time/batch = 0.0782s	
864/4200 (epoch 10.286), train_loss = 1.67691862, grad/param norm = 1.3678e-01, time/batch = 0.0781s	
865/4200 (epoch 10.298), train_loss = 1.66581978, grad/param norm = 1.4172e-01, time/batch = 0.0784s	
866/4200 (epoch 10.310), train_loss = 1.69352747, grad/param norm = 1.6890e-01, time/batch = 0.0784s	
867/4200 (epoch 10.321), train_loss = 1.65108995, grad/param norm = 1.8348e-01, time/batch = 0.0784s	
868/4200 (epoch 10.333), train_loss = 1.68890368, grad/param norm = 1.6675e-01, time/batch = 0.0779s	
869/4200 (epoch 10.345), train_loss = 1.66285746, grad/param norm = 1.4479e-01, time/batch = 0.0785s	
870/4200 (epoch 10.357), train_loss = 1.65831005, grad/param norm = 1.2345e-01, time/batch = 0.0781s	
871/4200 (epoch 10.369), train_loss = 1.67444626, grad/param norm = 1.0211e-01, time/batch = 0.0804s	
872/4200 (epoch 10.381), train_loss = 1.68119457, grad/param norm = 1.1354e-01, time/batch = 0.0782s	
873/4200 (epoch 10.393), train_loss = 1.68276219, grad/param norm = 1.3871e-01, time/batch = 0.0782s	
874/4200 (epoch 10.405), train_loss = 1.68148777, grad/param norm = 1.4046e-01, time/batch = 0.0783s	
875/4200 (epoch 10.417), train_loss = 1.64203761, grad/param norm = 1.3439e-01, time/batch = 0.0782s	
876/4200 (epoch 10.429), train_loss = 1.65717923, grad/param norm = 1.4340e-01, time/batch = 0.0779s	
877/4200 (epoch 10.440), train_loss = 1.67863395, grad/param norm = 1.4504e-01, time/batch = 0.0790s	
878/4200 (epoch 10.452), train_loss = 1.68955880, grad/param norm = 1.3833e-01, time/batch = 0.0778s	
879/4200 (epoch 10.464), train_loss = 1.66534659, grad/param norm = 1.3109e-01, time/batch = 0.0784s	
880/4200 (epoch 10.476), train_loss = 1.68431028, grad/param norm = 1.3257e-01, time/batch = 0.0780s	
881/4200 (epoch 10.488), train_loss = 1.69160538, grad/param norm = 1.2702e-01, time/batch = 0.0798s	
882/4200 (epoch 10.500), train_loss = 1.65951768, grad/param norm = 1.1138e-01, time/batch = 0.0785s	
883/4200 (epoch 10.512), train_loss = 1.66730214, grad/param norm = 1.0692e-01, time/batch = 0.0784s	
884/4200 (epoch 10.524), train_loss = 1.63737078, grad/param norm = 1.0902e-01, time/batch = 0.0780s	
885/4200 (epoch 10.536), train_loss = 1.65062305, grad/param norm = 9.9888e-02, time/batch = 0.0782s	
886/4200 (epoch 10.548), train_loss = 1.63686240, grad/param norm = 9.1211e-02, time/batch = 0.0778s	
887/4200 (epoch 10.560), train_loss = 1.65643411, grad/param norm = 1.1022e-01, time/batch = 0.0789s	
888/4200 (epoch 10.571), train_loss = 1.62181437, grad/param norm = 1.2704e-01, time/batch = 0.0778s	
889/4200 (epoch 10.583), train_loss = 1.66559644, grad/param norm = 1.3064e-01, time/batch = 0.0784s	
890/4200 (epoch 10.595), train_loss = 1.65359974, grad/param norm = 1.4869e-01, time/batch = 0.0783s	
891/4200 (epoch 10.607), train_loss = 1.66003318, grad/param norm = 1.6314e-01, time/batch = 0.0798s	
892/4200 (epoch 10.619), train_loss = 1.65665043, grad/param norm = 1.7820e-01, time/batch = 0.0780s	
893/4200 (epoch 10.631), train_loss = 1.66722703, grad/param norm = 1.9226e-01, time/batch = 0.0783s	
894/4200 (epoch 10.643), train_loss = 1.66392479, grad/param norm = 1.9917e-01, time/batch = 0.0782s	
895/4200 (epoch 10.655), train_loss = 1.65832272, grad/param norm = 1.5801e-01, time/batch = 0.0783s	
896/4200 (epoch 10.667), train_loss = 1.65703328, grad/param norm = 1.2074e-01, time/batch = 0.0778s	
897/4200 (epoch 10.679), train_loss = 1.65401737, grad/param norm = 1.2010e-01, time/batch = 0.0784s	
898/4200 (epoch 10.690), train_loss = 1.64637111, grad/param norm = 1.3388e-01, time/batch = 0.0782s	
899/4200 (epoch 10.702), train_loss = 1.65055284, grad/param norm = 1.3456e-01, time/batch = 0.0783s	
900/4200 (epoch 10.714), train_loss = 1.67587459, grad/param norm = 1.4326e-01, time/batch = 0.0780s	
901/4200 (epoch 10.726), train_loss = 1.67023844, grad/param norm = 1.4004e-01, time/batch = 0.0799s	
902/4200 (epoch 10.738), train_loss = 1.66332079, grad/param norm = 1.2730e-01, time/batch = 0.0781s	
903/4200 (epoch 10.750), train_loss = 1.65010718, grad/param norm = 1.1633e-01, time/batch = 0.0788s	
904/4200 (epoch 10.762), train_loss = 1.64604426, grad/param norm = 1.0905e-01, time/batch = 0.0782s	
905/4200 (epoch 10.774), train_loss = 1.66328600, grad/param norm = 1.1563e-01, time/batch = 0.0783s	
906/4200 (epoch 10.786), train_loss = 1.64109376, grad/param norm = 1.2381e-01, time/batch = 0.0778s	
907/4200 (epoch 10.798), train_loss = 1.66681852, grad/param norm = 1.2946e-01, time/batch = 0.0784s	
908/4200 (epoch 10.810), train_loss = 1.65403138, grad/param norm = 1.2169e-01, time/batch = 0.0778s	
909/4200 (epoch 10.821), train_loss = 1.64369636, grad/param norm = 1.3772e-01, time/batch = 0.0784s	
910/4200 (epoch 10.833), train_loss = 1.67030351, grad/param norm = 1.6430e-01, time/batch = 0.0781s	
911/4200 (epoch 10.845), train_loss = 1.69408419, grad/param norm = 1.6447e-01, time/batch = 0.0800s	
912/4200 (epoch 10.857), train_loss = 1.67833064, grad/param norm = 1.5918e-01, time/batch = 0.0780s	
913/4200 (epoch 10.869), train_loss = 1.69622491, grad/param norm = 1.5322e-01, time/batch = 0.0780s	
914/4200 (epoch 10.881), train_loss = 1.66515422, grad/param norm = 1.5916e-01, time/batch = 0.0788s	
915/4200 (epoch 10.893), train_loss = 1.68895256, grad/param norm = 1.4337e-01, time/batch = 0.0784s	
916/4200 (epoch 10.905), train_loss = 1.64637784, grad/param norm = 1.2427e-01, time/batch = 0.0779s	
917/4200 (epoch 10.917), train_loss = 1.67260134, grad/param norm = 1.1601e-01, time/batch = 0.0784s	
918/4200 (epoch 10.929), train_loss = 1.65259208, grad/param norm = 1.0660e-01, time/batch = 0.0774s	
919/4200 (epoch 10.940), train_loss = 1.65098917, grad/param norm = 9.6115e-02, time/batch = 0.0788s	
920/4200 (epoch 10.952), train_loss = 1.65266034, grad/param norm = 9.7721e-02, time/batch = 0.0781s	
921/4200 (epoch 10.964), train_loss = 1.67160655, grad/param norm = 1.2197e-01, time/batch = 0.0799s	
922/4200 (epoch 10.976), train_loss = 1.66712722, grad/param norm = 1.2985e-01, time/batch = 0.0781s	
923/4200 (epoch 10.988), train_loss = 1.65932046, grad/param norm = 1.3101e-01, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.0018818	
924/4200 (epoch 11.000), train_loss = 1.69013425, grad/param norm = 1.2921e-01, time/batch = 0.0786s	
925/4200 (epoch 11.012), train_loss = 1.77562746, grad/param norm = 1.1717e-01, time/batch = 0.0782s	
926/4200 (epoch 11.024), train_loss = 1.62310517, grad/param norm = 9.2022e-02, time/batch = 0.0778s	
927/4200 (epoch 11.036), train_loss = 1.63744950, grad/param norm = 8.3245e-02, time/batch = 0.0785s	
928/4200 (epoch 11.048), train_loss = 1.61182705, grad/param norm = 8.8082e-02, time/batch = 0.0789s	
929/4200 (epoch 11.060), train_loss = 1.63747337, grad/param norm = 9.5662e-02, time/batch = 0.0785s	
930/4200 (epoch 11.071), train_loss = 1.62581557, grad/param norm = 1.0881e-01, time/batch = 0.0786s	
931/4200 (epoch 11.083), train_loss = 1.64688868, grad/param norm = 1.4074e-01, time/batch = 0.0799s	
932/4200 (epoch 11.095), train_loss = 1.61448075, grad/param norm = 1.3973e-01, time/batch = 0.0782s	
933/4200 (epoch 11.107), train_loss = 1.62829076, grad/param norm = 1.1783e-01, time/batch = 0.0782s	
934/4200 (epoch 11.119), train_loss = 1.62601479, grad/param norm = 1.2298e-01, time/batch = 0.0782s	
935/4200 (epoch 11.131), train_loss = 1.63298726, grad/param norm = 1.3265e-01, time/batch = 0.0787s	
936/4200 (epoch 11.143), train_loss = 1.64877488, grad/param norm = 1.4627e-01, time/batch = 0.0777s	
937/4200 (epoch 11.155), train_loss = 1.62502745, grad/param norm = 1.6673e-01, time/batch = 0.0783s	
938/4200 (epoch 11.167), train_loss = 1.64752361, grad/param norm = 1.4833e-01, time/batch = 0.0779s	
939/4200 (epoch 11.179), train_loss = 1.64958620, grad/param norm = 1.3787e-01, time/batch = 0.0784s	
940/4200 (epoch 11.190), train_loss = 1.62422928, grad/param norm = 1.3346e-01, time/batch = 0.0784s	
941/4200 (epoch 11.202), train_loss = 1.64521770, grad/param norm = 1.2810e-01, time/batch = 0.0798s	
942/4200 (epoch 11.214), train_loss = 1.64622239, grad/param norm = 1.4610e-01, time/batch = 0.0781s	
943/4200 (epoch 11.226), train_loss = 1.64101171, grad/param norm = 1.4298e-01, time/batch = 0.0782s	
944/4200 (epoch 11.238), train_loss = 1.62955296, grad/param norm = 1.1852e-01, time/batch = 0.0782s	
945/4200 (epoch 11.250), train_loss = 1.61088304, grad/param norm = 1.2699e-01, time/batch = 0.0787s	
946/4200 (epoch 11.262), train_loss = 1.59986256, grad/param norm = 1.2473e-01, time/batch = 0.0776s	
947/4200 (epoch 11.274), train_loss = 1.64617492, grad/param norm = 1.1061e-01, time/batch = 0.0785s	
948/4200 (epoch 11.286), train_loss = 1.63415398, grad/param norm = 1.0306e-01, time/batch = 0.0776s	
949/4200 (epoch 11.298), train_loss = 1.61904485, grad/param norm = 1.1132e-01, time/batch = 0.0782s	
950/4200 (epoch 11.310), train_loss = 1.64960907, grad/param norm = 1.3682e-01, time/batch = 0.0779s	
951/4200 (epoch 11.321), train_loss = 1.60382881, grad/param norm = 1.4686e-01, time/batch = 0.0799s	
952/4200 (epoch 11.333), train_loss = 1.64602328, grad/param norm = 1.4215e-01, time/batch = 0.0781s	
953/4200 (epoch 11.345), train_loss = 1.62169117, grad/param norm = 1.3025e-01, time/batch = 0.0783s	
954/4200 (epoch 11.357), train_loss = 1.61994290, grad/param norm = 1.1808e-01, time/batch = 0.0785s	
955/4200 (epoch 11.369), train_loss = 1.63767933, grad/param norm = 1.0076e-01, time/batch = 0.0785s	
956/4200 (epoch 11.381), train_loss = 1.63901708, grad/param norm = 1.1026e-01, time/batch = 0.0787s	
957/4200 (epoch 11.393), train_loss = 1.64332801, grad/param norm = 1.2482e-01, time/batch = 0.0784s	
958/4200 (epoch 11.405), train_loss = 1.63695811, grad/param norm = 1.2369e-01, time/batch = 0.0777s	
959/4200 (epoch 11.417), train_loss = 1.59716492, grad/param norm = 1.1463e-01, time/batch = 0.0784s	
960/4200 (epoch 11.429), train_loss = 1.61320400, grad/param norm = 1.1937e-01, time/batch = 0.0780s	
961/4200 (epoch 11.440), train_loss = 1.63372688, grad/param norm = 1.2617e-01, time/batch = 0.0803s	
962/4200 (epoch 11.452), train_loss = 1.64793776, grad/param norm = 1.2986e-01, time/batch = 0.0780s	
963/4200 (epoch 11.464), train_loss = 1.62532589, grad/param norm = 1.2174e-01, time/batch = 0.0782s	
964/4200 (epoch 11.476), train_loss = 1.64715775, grad/param norm = 1.1648e-01, time/batch = 0.0782s	
965/4200 (epoch 11.488), train_loss = 1.65403203, grad/param norm = 1.3316e-01, time/batch = 0.0783s	
966/4200 (epoch 11.500), train_loss = 1.63100261, grad/param norm = 1.4076e-01, time/batch = 0.0800s	
967/4200 (epoch 11.512), train_loss = 1.63423826, grad/param norm = 1.2323e-01, time/batch = 0.0799s	
968/4200 (epoch 11.524), train_loss = 1.59675741, grad/param norm = 9.2550e-02, time/batch = 0.0778s	
969/4200 (epoch 11.536), train_loss = 1.60746342, grad/param norm = 7.9786e-02, time/batch = 0.0785s	
970/4200 (epoch 11.548), train_loss = 1.59670460, grad/param norm = 9.8575e-02, time/batch = 0.0783s	
971/4200 (epoch 11.560), train_loss = 1.62030910, grad/param norm = 1.3089e-01, time/batch = 0.0798s	
972/4200 (epoch 11.571), train_loss = 1.58878016, grad/param norm = 1.5575e-01, time/batch = 0.0786s	
973/4200 (epoch 11.583), train_loss = 1.63718288, grad/param norm = 1.7882e-01, time/batch = 0.0782s	
974/4200 (epoch 11.595), train_loss = 1.63603276, grad/param norm = 1.8950e-01, time/batch = 0.0783s	
975/4200 (epoch 11.607), train_loss = 1.62753302, grad/param norm = 1.6196e-01, time/batch = 0.0784s	
976/4200 (epoch 11.619), train_loss = 1.61069715, grad/param norm = 1.2537e-01, time/batch = 0.0778s	
977/4200 (epoch 11.631), train_loss = 1.60428390, grad/param norm = 1.0107e-01, time/batch = 0.0788s	
978/4200 (epoch 11.643), train_loss = 1.60360895, grad/param norm = 8.9653e-02, time/batch = 0.0776s	
979/4200 (epoch 11.655), train_loss = 1.59990485, grad/param norm = 8.2698e-02, time/batch = 0.0783s	
980/4200 (epoch 11.667), train_loss = 1.61402694, grad/param norm = 8.2589e-02, time/batch = 0.0781s	
981/4200 (epoch 11.679), train_loss = 1.61120124, grad/param norm = 9.1235e-02, time/batch = 0.0798s	
982/4200 (epoch 11.690), train_loss = 1.60653043, grad/param norm = 9.9627e-02, time/batch = 0.0783s	
983/4200 (epoch 11.702), train_loss = 1.60746844, grad/param norm = 1.0068e-01, time/batch = 0.0781s	
984/4200 (epoch 11.714), train_loss = 1.63300607, grad/param norm = 1.0542e-01, time/batch = 0.0781s	
985/4200 (epoch 11.726), train_loss = 1.62622286, grad/param norm = 1.0901e-01, time/batch = 0.0782s	
986/4200 (epoch 11.738), train_loss = 1.62592933, grad/param norm = 1.0741e-01, time/batch = 0.0777s	
987/4200 (epoch 11.750), train_loss = 1.61073895, grad/param norm = 1.0437e-01, time/batch = 0.0784s	
988/4200 (epoch 11.762), train_loss = 1.61169804, grad/param norm = 9.8595e-02, time/batch = 0.0782s	
989/4200 (epoch 11.774), train_loss = 1.62744426, grad/param norm = 1.1256e-01, time/batch = 0.0785s	
990/4200 (epoch 11.786), train_loss = 1.61479293, grad/param norm = 1.4203e-01, time/batch = 0.0781s	
991/4200 (epoch 11.798), train_loss = 1.63701848, grad/param norm = 1.4616e-01, time/batch = 0.0799s	
992/4200 (epoch 11.810), train_loss = 1.61995833, grad/param norm = 1.1827e-01, time/batch = 0.0779s	
993/4200 (epoch 11.821), train_loss = 1.60014700, grad/param norm = 9.9024e-02, time/batch = 0.0788s	
994/4200 (epoch 11.833), train_loss = 1.61643655, grad/param norm = 1.0053e-01, time/batch = 0.0782s	
995/4200 (epoch 11.845), train_loss = 1.64176397, grad/param norm = 1.0880e-01, time/batch = 0.0783s	
996/4200 (epoch 11.857), train_loss = 1.63659989, grad/param norm = 1.4359e-01, time/batch = 0.0781s	
997/4200 (epoch 11.869), train_loss = 1.66514247, grad/param norm = 1.4602e-01, time/batch = 0.0784s	
998/4200 (epoch 11.881), train_loss = 1.62878296, grad/param norm = 1.4452e-01, time/batch = 0.0781s	
999/4200 (epoch 11.893), train_loss = 1.65447415, grad/param norm = 1.4118e-01, time/batch = 0.0784s	
evaluating loss over split index 2	
1/5...	
2/5...	
3/5...	
4/5...	
5/5...	
saving checkpoint to cv/lm_lstm_epoch11.90_1.6549.t7	
1000/4200 (epoch 11.905), train_loss = 1.61475394, grad/param norm = 1.3367e-01, time/batch = 0.0781s	
1001/4200 (epoch 11.917), train_loss = 1.77374538, grad/param norm = 1.3784e-01, time/batch = 0.0811s	
1002/4200 (epoch 11.929), train_loss = 1.62062700, grad/param norm = 1.1396e-01, time/batch = 0.0781s	
1003/4200 (epoch 11.940), train_loss = 1.61790005, grad/param norm = 9.5146e-02, time/batch = 0.0782s	
1004/4200 (epoch 11.952), train_loss = 1.61897280, grad/param norm = 1.0404e-01, time/batch = 0.0784s	
1005/4200 (epoch 11.964), train_loss = 1.63750697, grad/param norm = 1.1650e-01, time/batch = 0.0794s	
1006/4200 (epoch 11.976), train_loss = 1.62741167, grad/param norm = 1.3042e-01, time/batch = 0.0796s	
1007/4200 (epoch 11.988), train_loss = 1.62537403, grad/param norm = 1.4104e-01, time/batch = 0.0791s	
decayed learning rate by a factor 0.97 to 0.001825346	
1008/4200 (epoch 12.000), train_loss = 1.65558487, grad/param norm = 1.4658e-01, time/batch = 0.0787s	
1009/4200 (epoch 12.012), train_loss = 1.74415073, grad/param norm = 1.3653e-01, time/batch = 0.0791s	
1010/4200 (epoch 12.024), train_loss = 1.58798098, grad/param norm = 1.0795e-01, time/batch = 0.0788s	
1011/4200 (epoch 12.036), train_loss = 1.60309316, grad/param norm = 9.9910e-02, time/batch = 0.0805s	
1012/4200 (epoch 12.048), train_loss = 1.57691371, grad/param norm = 1.0793e-01, time/batch = 0.0779s	
1013/4200 (epoch 12.060), train_loss = 1.60609751, grad/param norm = 1.2394e-01, time/batch = 0.0781s	
1014/4200 (epoch 12.071), train_loss = 1.60186306, grad/param norm = 1.4456e-01, time/batch = 0.0783s	
1015/4200 (epoch 12.083), train_loss = 1.61723475, grad/param norm = 1.5726e-01, time/batch = 0.0784s	
1016/4200 (epoch 12.095), train_loss = 1.57804858, grad/param norm = 1.2793e-01, time/batch = 0.0778s	
1017/4200 (epoch 12.107), train_loss = 1.58927689, grad/param norm = 9.4633e-02, time/batch = 0.0789s	
1018/4200 (epoch 12.119), train_loss = 1.58538776, grad/param norm = 1.0075e-01, time/batch = 0.0778s	
1019/4200 (epoch 12.131), train_loss = 1.59549372, grad/param norm = 1.0299e-01, time/batch = 0.0783s	
1020/4200 (epoch 12.143), train_loss = 1.60592695, grad/param norm = 1.0390e-01, time/batch = 0.0781s	
1021/4200 (epoch 12.155), train_loss = 1.58158118, grad/param norm = 1.0977e-01, time/batch = 0.0800s	
1022/4200 (epoch 12.167), train_loss = 1.60378640, grad/param norm = 1.2429e-01, time/batch = 0.0784s	
1023/4200 (epoch 12.179), train_loss = 1.61692203, grad/param norm = 1.2322e-01, time/batch = 0.0782s	
1024/4200 (epoch 12.190), train_loss = 1.59116828, grad/param norm = 1.2381e-01, time/batch = 0.0783s	
1025/4200 (epoch 12.202), train_loss = 1.61508385, grad/param norm = 1.2377e-01, time/batch = 0.0783s	
1026/4200 (epoch 12.214), train_loss = 1.60675879, grad/param norm = 1.1529e-01, time/batch = 0.0777s	
1027/4200 (epoch 12.226), train_loss = 1.59822688, grad/param norm = 1.0981e-01, time/batch = 0.0787s	
1028/4200 (epoch 12.238), train_loss = 1.59395793, grad/param norm = 1.1181e-01, time/batch = 0.0777s	
1029/4200 (epoch 12.250), train_loss = 1.57509318, grad/param norm = 1.0692e-01, time/batch = 0.0782s	
1030/4200 (epoch 12.262), train_loss = 1.55755689, grad/param norm = 1.0070e-01, time/batch = 0.0781s	
1031/4200 (epoch 12.274), train_loss = 1.60953783, grad/param norm = 9.6959e-02, time/batch = 0.0798s	
1032/4200 (epoch 12.286), train_loss = 1.59795783, grad/param norm = 9.1851e-02, time/batch = 0.0784s	
1033/4200 (epoch 12.298), train_loss = 1.57747036, grad/param norm = 8.8587e-02, time/batch = 0.0782s	
1034/4200 (epoch 12.310), train_loss = 1.60853350, grad/param norm = 1.0860e-01, time/batch = 0.0782s	
1035/4200 (epoch 12.321), train_loss = 1.55988516, grad/param norm = 1.1370e-01, time/batch = 0.0784s	
1036/4200 (epoch 12.333), train_loss = 1.60166099, grad/param norm = 1.1686e-01, time/batch = 0.0779s	
1037/4200 (epoch 12.345), train_loss = 1.58518207, grad/param norm = 1.1078e-01, time/batch = 0.0784s	
1038/4200 (epoch 12.357), train_loss = 1.58611336, grad/param norm = 1.2184e-01, time/batch = 0.0781s	
1039/4200 (epoch 12.369), train_loss = 1.61747416, grad/param norm = 1.3591e-01, time/batch = 0.0783s	
1040/4200 (epoch 12.381), train_loss = 1.61350060, grad/param norm = 1.4157e-01, time/batch = 0.0780s	
1041/4200 (epoch 12.393), train_loss = 1.61799049, grad/param norm = 1.2577e-01, time/batch = 0.0799s	
1042/4200 (epoch 12.405), train_loss = 1.60428792, grad/param norm = 1.1446e-01, time/batch = 0.0782s	
1043/4200 (epoch 12.417), train_loss = 1.56423584, grad/param norm = 9.8955e-02, time/batch = 0.0786s	
1044/4200 (epoch 12.429), train_loss = 1.57826262, grad/param norm = 1.0429e-01, time/batch = 0.0782s	
1045/4200 (epoch 12.440), train_loss = 1.59897789, grad/param norm = 1.1902e-01, time/batch = 0.0783s	
1046/4200 (epoch 12.452), train_loss = 1.61609493, grad/param norm = 1.2569e-01, time/batch = 0.0779s	
1047/4200 (epoch 12.464), train_loss = 1.59473750, grad/param norm = 1.2791e-01, time/batch = 0.0782s	
1048/4200 (epoch 12.476), train_loss = 1.61871685, grad/param norm = 1.2307e-01, time/batch = 0.0777s	
1049/4200 (epoch 12.488), train_loss = 1.61709239, grad/param norm = 1.0258e-01, time/batch = 0.0782s	
1050/4200 (epoch 12.500), train_loss = 1.58558404, grad/param norm = 9.5665e-02, time/batch = 0.0779s	
1051/4200 (epoch 12.512), train_loss = 1.59183862, grad/param norm = 9.4643e-02, time/batch = 0.0798s	
1052/4200 (epoch 12.524), train_loss = 1.55937030, grad/param norm = 1.0193e-01, time/batch = 0.0778s	
1053/4200 (epoch 12.536), train_loss = 1.58109518, grad/param norm = 1.1136e-01, time/batch = 0.0782s	
1054/4200 (epoch 12.548), train_loss = 1.56922041, grad/param norm = 1.1624e-01, time/batch = 0.0786s	
1055/4200 (epoch 12.560), train_loss = 1.59252860, grad/param norm = 1.2247e-01, time/batch = 0.0782s	
1056/4200 (epoch 12.571), train_loss = 1.55354641, grad/param norm = 1.3438e-01, time/batch = 0.0781s	
1057/4200 (epoch 12.583), train_loss = 1.59818559, grad/param norm = 1.3688e-01, time/batch = 0.0787s	
1058/4200 (epoch 12.595), train_loss = 1.58635500, grad/param norm = 1.4590e-01, time/batch = 0.0777s	
1059/4200 (epoch 12.607), train_loss = 1.58866331, grad/param norm = 1.3974e-01, time/batch = 0.0789s	
1060/4200 (epoch 12.619), train_loss = 1.57636354, grad/param norm = 1.3520e-01, time/batch = 0.0782s	
1061/4200 (epoch 12.631), train_loss = 1.58216697, grad/param norm = 1.3585e-01, time/batch = 0.0798s	
1062/4200 (epoch 12.643), train_loss = 1.57813525, grad/param norm = 1.2141e-01, time/batch = 0.0781s	
1063/4200 (epoch 12.655), train_loss = 1.57333986, grad/param norm = 9.4764e-02, time/batch = 0.0783s	
1064/4200 (epoch 12.667), train_loss = 1.58451239, grad/param norm = 8.9518e-02, time/batch = 0.0787s	
1065/4200 (epoch 12.679), train_loss = 1.57978912, grad/param norm = 9.1984e-02, time/batch = 0.0785s	
1066/4200 (epoch 12.690), train_loss = 1.57197198, grad/param norm = 1.0161e-01, time/batch = 0.0780s	
1067/4200 (epoch 12.702), train_loss = 1.57536565, grad/param norm = 1.0451e-01, time/batch = 0.0784s	
1068/4200 (epoch 12.714), train_loss = 1.59939918, grad/param norm = 1.1374e-01, time/batch = 0.0775s	
1069/4200 (epoch 12.726), train_loss = 1.59669651, grad/param norm = 1.1156e-01, time/batch = 0.0789s	
1070/4200 (epoch 12.738), train_loss = 1.58927426, grad/param norm = 9.9573e-02, time/batch = 0.0809s	
1071/4200 (epoch 12.750), train_loss = 1.57736535, grad/param norm = 9.4248e-02, time/batch = 0.0800s	
1072/4200 (epoch 12.762), train_loss = 1.57797591, grad/param norm = 9.7938e-02, time/batch = 0.0780s	
1073/4200 (epoch 12.774), train_loss = 1.59512249, grad/param norm = 1.1383e-01, time/batch = 0.0782s	
1074/4200 (epoch 12.786), train_loss = 1.57804001, grad/param norm = 1.1903e-01, time/batch = 0.0784s	
1075/4200 (epoch 12.798), train_loss = 1.59504940, grad/param norm = 1.0891e-01, time/batch = 0.0788s	
1076/4200 (epoch 12.810), train_loss = 1.58228480, grad/param norm = 8.4729e-02, time/batch = 0.0778s	
1077/4200 (epoch 12.821), train_loss = 1.56604660, grad/param norm = 9.0390e-02, time/batch = 0.0785s	
1078/4200 (epoch 12.833), train_loss = 1.58888375, grad/param norm = 1.1180e-01, time/batch = 0.0780s	
1079/4200 (epoch 12.845), train_loss = 1.61319168, grad/param norm = 1.2334e-01, time/batch = 0.0783s	
1080/4200 (epoch 12.857), train_loss = 1.60755628, grad/param norm = 1.4125e-01, time/batch = 0.0792s	
1081/4200 (epoch 12.869), train_loss = 1.62920806, grad/param norm = 1.4640e-01, time/batch = 0.0801s	
1082/4200 (epoch 12.881), train_loss = 1.59745489, grad/param norm = 1.5275e-01, time/batch = 0.0780s	
1083/4200 (epoch 12.893), train_loss = 1.61985858, grad/param norm = 1.3252e-01, time/batch = 0.0783s	
1084/4200 (epoch 12.905), train_loss = 1.57992283, grad/param norm = 1.1228e-01, time/batch = 0.0783s	
1085/4200 (epoch 12.917), train_loss = 1.60638085, grad/param norm = 1.0794e-01, time/batch = 0.0788s	
1086/4200 (epoch 12.929), train_loss = 1.58401663, grad/param norm = 9.0494e-02, time/batch = 0.0777s	
1087/4200 (epoch 12.940), train_loss = 1.58533263, grad/param norm = 7.7464e-02, time/batch = 0.0783s	
1088/4200 (epoch 12.952), train_loss = 1.58401874, grad/param norm = 7.8927e-02, time/batch = 0.0779s	
1089/4200 (epoch 12.964), train_loss = 1.60041413, grad/param norm = 9.0862e-02, time/batch = 0.0783s	
1090/4200 (epoch 12.976), train_loss = 1.59465648, grad/param norm = 1.1554e-01, time/batch = 0.0781s	
1091/4200 (epoch 12.988), train_loss = 1.59399306, grad/param norm = 1.2865e-01, time/batch = 0.0799s	
decayed learning rate by a factor 0.97 to 0.00177058562	
1092/4200 (epoch 13.000), train_loss = 1.62239808, grad/param norm = 1.1743e-01, time/batch = 0.0780s	
1093/4200 (epoch 13.012), train_loss = 1.71485654, grad/param norm = 1.1163e-01, time/batch = 0.0783s	
1094/4200 (epoch 13.024), train_loss = 1.55880154, grad/param norm = 9.9014e-02, time/batch = 0.0783s	
1095/4200 (epoch 13.036), train_loss = 1.57577457, grad/param norm = 9.3151e-02, time/batch = 0.0782s	
1096/4200 (epoch 13.048), train_loss = 1.54755620, grad/param norm = 9.2593e-02, time/batch = 0.0782s	
1097/4200 (epoch 13.060), train_loss = 1.57215510, grad/param norm = 9.2358e-02, time/batch = 0.0784s	
1098/4200 (epoch 13.071), train_loss = 1.56100034, grad/param norm = 1.0075e-01, time/batch = 0.0778s	
1099/4200 (epoch 13.083), train_loss = 1.57618976, grad/param norm = 1.2439e-01, time/batch = 0.0787s	
1100/4200 (epoch 13.095), train_loss = 1.54479885, grad/param norm = 1.1980e-01, time/batch = 0.0780s	
1101/4200 (epoch 13.107), train_loss = 1.56104274, grad/param norm = 1.0720e-01, time/batch = 0.0804s	
1102/4200 (epoch 13.119), train_loss = 1.55779717, grad/param norm = 1.2196e-01, time/batch = 0.0779s	
1103/4200 (epoch 13.131), train_loss = 1.57173763, grad/param norm = 1.3002e-01, time/batch = 0.0782s	
1104/4200 (epoch 13.143), train_loss = 1.58001256, grad/param norm = 1.2801e-01, time/batch = 0.0780s	
1105/4200 (epoch 13.155), train_loss = 1.55588399, grad/param norm = 1.2701e-01, time/batch = 0.0782s	
1106/4200 (epoch 13.167), train_loss = 1.57657241, grad/param norm = 1.3528e-01, time/batch = 0.0778s	
1107/4200 (epoch 13.179), train_loss = 1.58849854, grad/param norm = 1.2875e-01, time/batch = 0.0783s	
1108/4200 (epoch 13.190), train_loss = 1.56203840, grad/param norm = 1.2374e-01, time/batch = 0.0777s	
1109/4200 (epoch 13.202), train_loss = 1.58529451, grad/param norm = 1.1942e-01, time/batch = 0.0783s	
1110/4200 (epoch 13.214), train_loss = 1.57565073, grad/param norm = 1.0779e-01, time/batch = 0.0780s	
1111/4200 (epoch 13.226), train_loss = 1.56772640, grad/param norm = 1.0160e-01, time/batch = 0.0801s	
1112/4200 (epoch 13.238), train_loss = 1.56397467, grad/param norm = 1.0958e-01, time/batch = 0.0785s	
1113/4200 (epoch 13.250), train_loss = 1.54447721, grad/param norm = 1.0972e-01, time/batch = 0.0781s	
1114/4200 (epoch 13.262), train_loss = 1.52682257, grad/param norm = 1.0170e-01, time/batch = 0.0781s	
1115/4200 (epoch 13.274), train_loss = 1.57799130, grad/param norm = 8.3744e-02, time/batch = 0.0784s	
1116/4200 (epoch 13.286), train_loss = 1.56737560, grad/param norm = 7.4676e-02, time/batch = 0.0780s	
1117/4200 (epoch 13.298), train_loss = 1.54568597, grad/param norm = 7.5889e-02, time/batch = 0.0788s	
1118/4200 (epoch 13.310), train_loss = 1.57935920, grad/param norm = 9.5434e-02, time/batch = 0.0775s	
1119/4200 (epoch 13.321), train_loss = 1.52783178, grad/param norm = 8.6971e-02, time/batch = 0.0782s	
1120/4200 (epoch 13.333), train_loss = 1.56722899, grad/param norm = 8.1976e-02, time/batch = 0.0781s	
1121/4200 (epoch 13.345), train_loss = 1.55413915, grad/param norm = 9.1692e-02, time/batch = 0.0799s	
1122/4200 (epoch 13.357), train_loss = 1.55670683, grad/param norm = 1.0487e-01, time/batch = 0.0785s	
1123/4200 (epoch 13.369), train_loss = 1.58163680, grad/param norm = 1.0925e-01, time/batch = 0.0781s	
1124/4200 (epoch 13.381), train_loss = 1.57821163, grad/param norm = 1.0695e-01, time/batch = 0.0781s	
1125/4200 (epoch 13.393), train_loss = 1.58491229, grad/param norm = 1.0634e-01, time/batch = 0.0785s	
1126/4200 (epoch 13.405), train_loss = 1.57877383, grad/param norm = 1.1483e-01, time/batch = 0.0780s	
1127/4200 (epoch 13.417), train_loss = 1.54346820, grad/param norm = 1.2046e-01, time/batch = 0.0783s	
1128/4200 (epoch 13.429), train_loss = 1.55437921, grad/param norm = 1.1106e-01, time/batch = 0.0781s	
1129/4200 (epoch 13.440), train_loss = 1.56815585, grad/param norm = 1.0414e-01, time/batch = 0.0783s	
1130/4200 (epoch 13.452), train_loss = 1.58225734, grad/param norm = 1.1050e-01, time/batch = 0.0780s	
1131/4200 (epoch 13.464), train_loss = 1.56189380, grad/param norm = 1.0949e-01, time/batch = 0.0798s	
1132/4200 (epoch 13.476), train_loss = 1.58653353, grad/param norm = 1.0635e-01, time/batch = 0.0779s	
1133/4200 (epoch 13.488), train_loss = 1.59205919, grad/param norm = 1.2705e-01, time/batch = 0.0787s	
1134/4200 (epoch 13.500), train_loss = 1.56439175, grad/param norm = 1.2479e-01, time/batch = 0.0783s	
1135/4200 (epoch 13.512), train_loss = 1.56617831, grad/param norm = 1.0707e-01, time/batch = 0.0782s	
1136/4200 (epoch 13.524), train_loss = 1.53278881, grad/param norm = 1.0900e-01, time/batch = 0.0777s	
1137/4200 (epoch 13.536), train_loss = 1.55799775, grad/param norm = 1.2035e-01, time/batch = 0.0783s	
1138/4200 (epoch 13.548), train_loss = 1.54516610, grad/param norm = 1.2134e-01, time/batch = 0.0782s	
1139/4200 (epoch 13.560), train_loss = 1.57015601, grad/param norm = 1.2633e-01, time/batch = 0.0783s	
1140/4200 (epoch 13.571), train_loss = 1.52383073, grad/param norm = 1.0730e-01, time/batch = 0.0780s	
1141/4200 (epoch 13.583), train_loss = 1.55862474, grad/param norm = 8.5065e-02, time/batch = 0.0800s	
1142/4200 (epoch 13.595), train_loss = 1.55189284, grad/param norm = 9.3503e-02, time/batch = 0.0779s	
1143/4200 (epoch 13.607), train_loss = 1.54863318, grad/param norm = 1.0226e-01, time/batch = 0.0788s	
1144/4200 (epoch 13.619), train_loss = 1.54362008, grad/param norm = 1.0182e-01, time/batch = 0.0783s	
1145/4200 (epoch 13.631), train_loss = 1.54154817, grad/param norm = 9.1571e-02, time/batch = 0.0784s	
1146/4200 (epoch 13.643), train_loss = 1.54276702, grad/param norm = 8.1130e-02, time/batch = 0.0777s	
1147/4200 (epoch 13.655), train_loss = 1.54277190, grad/param norm = 7.7694e-02, time/batch = 0.0784s	
1148/4200 (epoch 13.667), train_loss = 1.55800173, grad/param norm = 8.8834e-02, time/batch = 0.0777s	
1149/4200 (epoch 13.679), train_loss = 1.55165036, grad/param norm = 9.1383e-02, time/batch = 0.0789s	
1150/4200 (epoch 13.690), train_loss = 1.54262125, grad/param norm = 8.9891e-02, time/batch = 0.0780s	
1151/4200 (epoch 13.702), train_loss = 1.54431326, grad/param norm = 9.2191e-02, time/batch = 0.0800s	
1152/4200 (epoch 13.714), train_loss = 1.56949154, grad/param norm = 9.8795e-02, time/batch = 0.0779s	
1153/4200 (epoch 13.726), train_loss = 1.56772815, grad/param norm = 1.0975e-01, time/batch = 0.0783s	
1154/4200 (epoch 13.738), train_loss = 1.56705389, grad/param norm = 1.1737e-01, time/batch = 0.0789s	
1155/4200 (epoch 13.750), train_loss = 1.55544163, grad/param norm = 1.2259e-01, time/batch = 0.0783s	
1156/4200 (epoch 13.762), train_loss = 1.55868644, grad/param norm = 1.2405e-01, time/batch = 0.0777s	
1157/4200 (epoch 13.774), train_loss = 1.57061092, grad/param norm = 1.2240e-01, time/batch = 0.0784s	
1158/4200 (epoch 13.786), train_loss = 1.55089233, grad/param norm = 1.2958e-01, time/batch = 0.0777s	
1159/4200 (epoch 13.798), train_loss = 1.56977019, grad/param norm = 1.2367e-01, time/batch = 0.0788s	
1160/4200 (epoch 13.810), train_loss = 1.55621395, grad/param norm = 1.0563e-01, time/batch = 0.0781s	
1161/4200 (epoch 13.821), train_loss = 1.54168162, grad/param norm = 9.7793e-02, time/batch = 0.0802s	
1162/4200 (epoch 13.833), train_loss = 1.55697769, grad/param norm = 8.5997e-02, time/batch = 0.0787s	
1163/4200 (epoch 13.845), train_loss = 1.57916353, grad/param norm = 7.7350e-02, time/batch = 0.0783s	
1164/4200 (epoch 13.857), train_loss = 1.57146204, grad/param norm = 8.7506e-02, time/batch = 0.0787s	
1165/4200 (epoch 13.869), train_loss = 1.58859830, grad/param norm = 8.4943e-02, time/batch = 0.0786s	
1166/4200 (epoch 13.881), train_loss = 1.55629050, grad/param norm = 9.3396e-02, time/batch = 0.0778s	
1167/4200 (epoch 13.893), train_loss = 1.58478329, grad/param norm = 1.0920e-01, time/batch = 0.0782s	
1168/4200 (epoch 13.905), train_loss = 1.55813622, grad/param norm = 1.2697e-01, time/batch = 0.0778s	
1169/4200 (epoch 13.917), train_loss = 1.59044586, grad/param norm = 1.3466e-01, time/batch = 0.0783s	
1170/4200 (epoch 13.929), train_loss = 1.56529402, grad/param norm = 1.2229e-01, time/batch = 0.0785s	
1171/4200 (epoch 13.940), train_loss = 1.56743176, grad/param norm = 1.0270e-01, time/batch = 0.0799s	
1172/4200 (epoch 13.952), train_loss = 1.56184226, grad/param norm = 9.9029e-02, time/batch = 0.0778s	
1173/4200 (epoch 13.964), train_loss = 1.57724604, grad/param norm = 1.0174e-01, time/batch = 0.0783s	
1174/4200 (epoch 13.976), train_loss = 1.56816192, grad/param norm = 1.1486e-01, time/batch = 0.0783s	
1175/4200 (epoch 13.988), train_loss = 1.56604163, grad/param norm = 1.2782e-01, time/batch = 0.0820s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
1176/4200 (epoch 14.000), train_loss = 1.60222010, grad/param norm = 1.3048e-01, time/batch = 0.0782s	
1177/4200 (epoch 14.012), train_loss = 1.69577292, grad/param norm = 1.0500e-01, time/batch = 0.0784s	
1178/4200 (epoch 14.024), train_loss = 1.53123855, grad/param norm = 8.2661e-02, time/batch = 0.0778s	
1179/4200 (epoch 14.036), train_loss = 1.54479125, grad/param norm = 7.6054e-02, time/batch = 0.0783s	
1180/4200 (epoch 14.048), train_loss = 1.51439261, grad/param norm = 7.1614e-02, time/batch = 0.0784s	
1181/4200 (epoch 14.060), train_loss = 1.53976357, grad/param norm = 6.9517e-02, time/batch = 0.0800s	
1182/4200 (epoch 14.071), train_loss = 1.52906836, grad/param norm = 8.1777e-02, time/batch = 0.0780s	
1183/4200 (epoch 14.083), train_loss = 1.54214470, grad/param norm = 1.0297e-01, time/batch = 0.0784s	
1184/4200 (epoch 14.095), train_loss = 1.51551689, grad/param norm = 1.0252e-01, time/batch = 0.0783s	
1185/4200 (epoch 14.107), train_loss = 1.53428466, grad/param norm = 9.4014e-02, time/batch = 0.0784s	
1186/4200 (epoch 14.119), train_loss = 1.53038771, grad/param norm = 1.0246e-01, time/batch = 0.0783s	
1187/4200 (epoch 14.131), train_loss = 1.54276937, grad/param norm = 1.0405e-01, time/batch = 0.0783s	
1188/4200 (epoch 14.143), train_loss = 1.55084183, grad/param norm = 1.0375e-01, time/batch = 0.0779s	
1189/4200 (epoch 14.155), train_loss = 1.52453079, grad/param norm = 1.0386e-01, time/batch = 0.0784s	
1190/4200 (epoch 14.167), train_loss = 1.54630298, grad/param norm = 1.1113e-01, time/batch = 0.0781s	
1191/4200 (epoch 14.179), train_loss = 1.55837368, grad/param norm = 1.1404e-01, time/batch = 0.0805s	
1192/4200 (epoch 14.190), train_loss = 1.53611091, grad/param norm = 1.2511e-01, time/batch = 0.0780s	
1193/4200 (epoch 14.202), train_loss = 1.56660620, grad/param norm = 1.3556e-01, time/batch = 0.0779s	
1194/4200 (epoch 14.214), train_loss = 1.55283300, grad/param norm = 1.2108e-01, time/batch = 0.0782s	
1195/4200 (epoch 14.226), train_loss = 1.54489654, grad/param norm = 1.0979e-01, time/batch = 0.0782s	
1196/4200 (epoch 14.238), train_loss = 1.54144420, grad/param norm = 1.1285e-01, time/batch = 0.0785s	
1197/4200 (epoch 14.250), train_loss = 1.51982544, grad/param norm = 1.0935e-01, time/batch = 0.0784s	
1198/4200 (epoch 14.262), train_loss = 1.50001016, grad/param norm = 9.5757e-02, time/batch = 0.0778s	
1199/4200 (epoch 14.274), train_loss = 1.55057496, grad/param norm = 7.4817e-02, time/batch = 0.0784s	
1200/4200 (epoch 14.286), train_loss = 1.54095200, grad/param norm = 6.5231e-02, time/batch = 0.0782s	
1201/4200 (epoch 14.298), train_loss = 1.51724400, grad/param norm = 6.7550e-02, time/batch = 0.0803s	
1202/4200 (epoch 14.310), train_loss = 1.55080943, grad/param norm = 7.5106e-02, time/batch = 0.0778s	
1203/4200 (epoch 14.321), train_loss = 1.49852040, grad/param norm = 7.0347e-02, time/batch = 0.0781s	
1204/4200 (epoch 14.333), train_loss = 1.54042994, grad/param norm = 7.3353e-02, time/batch = 0.0783s	
1205/4200 (epoch 14.345), train_loss = 1.52524132, grad/param norm = 7.6957e-02, time/batch = 0.0784s	
1206/4200 (epoch 14.357), train_loss = 1.52659331, grad/param norm = 8.6014e-02, time/batch = 0.0780s	
1207/4200 (epoch 14.369), train_loss = 1.55368340, grad/param norm = 9.5683e-02, time/batch = 0.0791s	
1208/4200 (epoch 14.381), train_loss = 1.54943645, grad/param norm = 9.7635e-02, time/batch = 0.0777s	
1209/4200 (epoch 14.393), train_loss = 1.55684975, grad/param norm = 9.3034e-02, time/batch = 0.0786s	
1210/4200 (epoch 14.405), train_loss = 1.54680832, grad/param norm = 8.9777e-02, time/batch = 0.0783s	
1211/4200 (epoch 14.417), train_loss = 1.50969019, grad/param norm = 9.0374e-02, time/batch = 0.0798s	
1212/4200 (epoch 14.429), train_loss = 1.52841455, grad/param norm = 1.0675e-01, time/batch = 0.0783s	
1213/4200 (epoch 14.440), train_loss = 1.54740877, grad/param norm = 1.1507e-01, time/batch = 0.0781s	
1214/4200 (epoch 14.452), train_loss = 1.55861238, grad/param norm = 1.1230e-01, time/batch = 0.0781s	
1215/4200 (epoch 14.464), train_loss = 1.54378655, grad/param norm = 1.0886e-01, time/batch = 0.0784s	
1216/4200 (epoch 14.476), train_loss = 1.56453715, grad/param norm = 1.1682e-01, time/batch = 0.0777s	
1217/4200 (epoch 14.488), train_loss = 1.56596615, grad/param norm = 1.0630e-01, time/batch = 0.0791s	
1218/4200 (epoch 14.500), train_loss = 1.53108073, grad/param norm = 1.0383e-01, time/batch = 0.0781s	
1219/4200 (epoch 14.512), train_loss = 1.54138218, grad/param norm = 1.1095e-01, time/batch = 0.0783s	
1220/4200 (epoch 14.524), train_loss = 1.51022687, grad/param norm = 1.2907e-01, time/batch = 0.0782s	
1221/4200 (epoch 14.536), train_loss = 1.53682644, grad/param norm = 1.4108e-01, time/batch = 0.0799s	
1222/4200 (epoch 14.548), train_loss = 1.52256309, grad/param norm = 1.3310e-01, time/batch = 0.0779s	
1223/4200 (epoch 14.560), train_loss = 1.54189518, grad/param norm = 1.1529e-01, time/batch = 0.0780s	
1224/4200 (epoch 14.571), train_loss = 1.49536604, grad/param norm = 9.4107e-02, time/batch = 0.0781s	
1225/4200 (epoch 14.583), train_loss = 1.53240864, grad/param norm = 8.4840e-02, time/batch = 0.0786s	
1226/4200 (epoch 14.595), train_loss = 1.52630432, grad/param norm = 8.5018e-02, time/batch = 0.0780s	
1227/4200 (epoch 14.607), train_loss = 1.51873249, grad/param norm = 8.7956e-02, time/batch = 0.0783s	
1228/4200 (epoch 14.619), train_loss = 1.51315100, grad/param norm = 8.2139e-02, time/batch = 0.0785s	
1229/4200 (epoch 14.631), train_loss = 1.51333300, grad/param norm = 8.0365e-02, time/batch = 0.0784s	
1230/4200 (epoch 14.643), train_loss = 1.51874174, grad/param norm = 7.9934e-02, time/batch = 0.0783s	
1231/4200 (epoch 14.655), train_loss = 1.51972358, grad/param norm = 7.5374e-02, time/batch = 0.0801s	
1232/4200 (epoch 14.667), train_loss = 1.53408066, grad/param norm = 8.3474e-02, time/batch = 0.0778s	
1233/4200 (epoch 14.679), train_loss = 1.52519947, grad/param norm = 7.8159e-02, time/batch = 0.0785s	
1234/4200 (epoch 14.690), train_loss = 1.51459917, grad/param norm = 7.4357e-02, time/batch = 0.0783s	
1235/4200 (epoch 14.702), train_loss = 1.51640187, grad/param norm = 7.5570e-02, time/batch = 0.0783s	
1236/4200 (epoch 14.714), train_loss = 1.53934053, grad/param norm = 8.1744e-02, time/batch = 0.0779s	
1237/4200 (epoch 14.726), train_loss = 1.53871138, grad/param norm = 9.1104e-02, time/batch = 0.0784s	
1238/4200 (epoch 14.738), train_loss = 1.53671551, grad/param norm = 9.2659e-02, time/batch = 0.0778s	
1239/4200 (epoch 14.750), train_loss = 1.52808261, grad/param norm = 9.0848e-02, time/batch = 0.0786s	
1240/4200 (epoch 14.762), train_loss = 1.52764553, grad/param norm = 9.5792e-02, time/batch = 0.0781s	
1241/4200 (epoch 14.774), train_loss = 1.54819231, grad/param norm = 1.1467e-01, time/batch = 0.0799s	
1242/4200 (epoch 14.786), train_loss = 1.52988027, grad/param norm = 1.3339e-01, time/batch = 0.0780s	
1243/4200 (epoch 14.798), train_loss = 1.55001081, grad/param norm = 1.1460e-01, time/batch = 0.0782s	
1244/4200 (epoch 14.810), train_loss = 1.53284855, grad/param norm = 9.2817e-02, time/batch = 0.0789s	
1245/4200 (epoch 14.821), train_loss = 1.51855748, grad/param norm = 1.0069e-01, time/batch = 0.0784s	
1246/4200 (epoch 14.833), train_loss = 1.54138094, grad/param norm = 1.2741e-01, time/batch = 0.0780s	
1247/4200 (epoch 14.845), train_loss = 1.57000348, grad/param norm = 1.4702e-01, time/batch = 0.0784s	
1248/4200 (epoch 14.857), train_loss = 1.56695493, grad/param norm = 1.6210e-01, time/batch = 0.0776s	
1249/4200 (epoch 14.869), train_loss = 1.58289929, grad/param norm = 1.4153e-01, time/batch = 0.0787s	
1250/4200 (epoch 14.881), train_loss = 1.53909176, grad/param norm = 1.2226e-01, time/batch = 0.0782s	
1251/4200 (epoch 14.893), train_loss = 1.56132256, grad/param norm = 1.0766e-01, time/batch = 0.0800s	
1252/4200 (epoch 14.905), train_loss = 1.52909662, grad/param norm = 1.0098e-01, time/batch = 0.0779s	
1253/4200 (epoch 14.917), train_loss = 1.55668953, grad/param norm = 1.0127e-01, time/batch = 0.0781s	
1254/4200 (epoch 14.929), train_loss = 1.53447936, grad/param norm = 9.0515e-02, time/batch = 0.0786s	
1255/4200 (epoch 14.940), train_loss = 1.53963939, grad/param norm = 8.2399e-02, time/batch = 0.0783s	
1256/4200 (epoch 14.952), train_loss = 1.53700627, grad/param norm = 8.1216e-02, time/batch = 0.0776s	
1257/4200 (epoch 14.964), train_loss = 1.55107387, grad/param norm = 9.3411e-02, time/batch = 0.0783s	
1258/4200 (epoch 14.976), train_loss = 1.54387440, grad/param norm = 1.0096e-01, time/batch = 0.0778s	
1259/4200 (epoch 14.988), train_loss = 1.53642984, grad/param norm = 9.9784e-02, time/batch = 0.0784s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
1260/4200 (epoch 15.000), train_loss = 1.57040496, grad/param norm = 8.6177e-02, time/batch = 0.0789s	
1261/4200 (epoch 15.012), train_loss = 1.66958026, grad/param norm = 8.3196e-02, time/batch = 0.0800s	
1262/4200 (epoch 15.024), train_loss = 1.50588697, grad/param norm = 7.7659e-02, time/batch = 0.0780s	
1263/4200 (epoch 15.036), train_loss = 1.52100423, grad/param norm = 7.1714e-02, time/batch = 0.0783s	
1264/4200 (epoch 15.048), train_loss = 1.49302274, grad/param norm = 7.7291e-02, time/batch = 0.0781s	
1265/4200 (epoch 15.060), train_loss = 1.52124634, grad/param norm = 9.3347e-02, time/batch = 0.0788s	
1266/4200 (epoch 15.071), train_loss = 1.51182773, grad/param norm = 9.3562e-02, time/batch = 0.0777s	
1267/4200 (epoch 15.083), train_loss = 1.51686746, grad/param norm = 9.5888e-02, time/batch = 0.0783s	
1268/4200 (epoch 15.095), train_loss = 1.48998471, grad/param norm = 8.2884e-02, time/batch = 0.0787s	
1269/4200 (epoch 15.107), train_loss = 1.50757879, grad/param norm = 7.6987e-02, time/batch = 0.0783s	
1270/4200 (epoch 15.119), train_loss = 1.50290829, grad/param norm = 7.7985e-02, time/batch = 0.0789s	
1271/4200 (epoch 15.131), train_loss = 1.51326587, grad/param norm = 7.7504e-02, time/batch = 0.0800s	
1272/4200 (epoch 15.143), train_loss = 1.52424954, grad/param norm = 7.9070e-02, time/batch = 0.0778s	
1273/4200 (epoch 15.155), train_loss = 1.49880977, grad/param norm = 9.1320e-02, time/batch = 0.0781s	
1274/4200 (epoch 15.167), train_loss = 1.52668986, grad/param norm = 1.0692e-01, time/batch = 0.0782s	
1275/4200 (epoch 15.179), train_loss = 1.53486957, grad/param norm = 1.1100e-01, time/batch = 0.0787s	
1276/4200 (epoch 15.190), train_loss = 1.50962300, grad/param norm = 1.0001e-01, time/batch = 0.0778s	
1277/4200 (epoch 15.202), train_loss = 1.53472296, grad/param norm = 8.9933e-02, time/batch = 0.0783s	
1278/4200 (epoch 15.214), train_loss = 1.52248252, grad/param norm = 8.5258e-02, time/batch = 0.0777s	
1279/4200 (epoch 15.226), train_loss = 1.51933661, grad/param norm = 8.4946e-02, time/batch = 0.0784s	
1280/4200 (epoch 15.238), train_loss = 1.51317673, grad/param norm = 8.4822e-02, time/batch = 0.0781s	
1281/4200 (epoch 15.250), train_loss = 1.49206563, grad/param norm = 8.3582e-02, time/batch = 0.0803s	
1282/4200 (epoch 15.262), train_loss = 1.47227545, grad/param norm = 8.4233e-02, time/batch = 0.0779s	
1283/4200 (epoch 15.274), train_loss = 1.52814389, grad/param norm = 8.1867e-02, time/batch = 0.0782s	
1284/4200 (epoch 15.286), train_loss = 1.52160569, grad/param norm = 7.7812e-02, time/batch = 0.0782s	
1285/4200 (epoch 15.298), train_loss = 1.49612797, grad/param norm = 7.6865e-02, time/batch = 0.0782s	
1286/4200 (epoch 15.310), train_loss = 1.53357389, grad/param norm = 1.0190e-01, time/batch = 0.0784s	
1287/4200 (epoch 15.321), train_loss = 1.48404061, grad/param norm = 1.0300e-01, time/batch = 0.0782s	
1288/4200 (epoch 15.333), train_loss = 1.52256428, grad/param norm = 1.0030e-01, time/batch = 0.0779s	
1289/4200 (epoch 15.345), train_loss = 1.51075382, grad/param norm = 1.0079e-01, time/batch = 0.0783s	
1290/4200 (epoch 15.357), train_loss = 1.51047645, grad/param norm = 1.1361e-01, time/batch = 0.0780s	
1291/4200 (epoch 15.369), train_loss = 1.54043003, grad/param norm = 1.3862e-01, time/batch = 0.0803s	
1292/4200 (epoch 15.381), train_loss = 1.54095016, grad/param norm = 1.4981e-01, time/batch = 0.0780s	
1293/4200 (epoch 15.393), train_loss = 1.54666139, grad/param norm = 1.3169e-01, time/batch = 0.0782s	
1294/4200 (epoch 15.405), train_loss = 1.53178231, grad/param norm = 1.0885e-01, time/batch = 0.0783s	
1295/4200 (epoch 15.417), train_loss = 1.49017317, grad/param norm = 8.8151e-02, time/batch = 0.0782s	
1296/4200 (epoch 15.429), train_loss = 1.50173014, grad/param norm = 8.5806e-02, time/batch = 0.0782s	
1297/4200 (epoch 15.440), train_loss = 1.51793527, grad/param norm = 8.7997e-02, time/batch = 0.0784s	
1298/4200 (epoch 15.452), train_loss = 1.52851690, grad/param norm = 8.6009e-02, time/batch = 0.0776s	
1299/4200 (epoch 15.464), train_loss = 1.51371316, grad/param norm = 7.7489e-02, time/batch = 0.0783s	
1300/4200 (epoch 15.476), train_loss = 1.53399986, grad/param norm = 7.4605e-02, time/batch = 0.0781s	
1301/4200 (epoch 15.488), train_loss = 1.53632059, grad/param norm = 7.6786e-02, time/batch = 0.0799s	
1302/4200 (epoch 15.500), train_loss = 1.50679020, grad/param norm = 7.9692e-02, time/batch = 0.0782s	
1303/4200 (epoch 15.512), train_loss = 1.51374950, grad/param norm = 7.9176e-02, time/batch = 0.0782s	
1304/4200 (epoch 15.524), train_loss = 1.47735642, grad/param norm = 7.1700e-02, time/batch = 0.0780s	
1305/4200 (epoch 15.536), train_loss = 1.50036407, grad/param norm = 7.3346e-02, time/batch = 0.0783s	
1306/4200 (epoch 15.548), train_loss = 1.49375404, grad/param norm = 9.0319e-02, time/batch = 0.0778s	
1307/4200 (epoch 15.560), train_loss = 1.51949884, grad/param norm = 1.0720e-01, time/batch = 0.0789s	
1308/4200 (epoch 15.571), train_loss = 1.48000736, grad/param norm = 1.0708e-01, time/batch = 0.0777s	
1309/4200 (epoch 15.583), train_loss = 1.51720361, grad/param norm = 1.0482e-01, time/batch = 0.0783s	
1310/4200 (epoch 15.595), train_loss = 1.51461310, grad/param norm = 1.0935e-01, time/batch = 0.0783s	
1311/4200 (epoch 15.607), train_loss = 1.50453433, grad/param norm = 1.1311e-01, time/batch = 0.0799s	
1312/4200 (epoch 15.619), train_loss = 1.49795399, grad/param norm = 1.0284e-01, time/batch = 0.0785s	
1313/4200 (epoch 15.631), train_loss = 1.49309321, grad/param norm = 8.6051e-02, time/batch = 0.0782s	
1314/4200 (epoch 15.643), train_loss = 1.49783543, grad/param norm = 8.3630e-02, time/batch = 0.0781s	
1315/4200 (epoch 15.655), train_loss = 1.50153219, grad/param norm = 9.1597e-02, time/batch = 0.0783s	
1316/4200 (epoch 15.667), train_loss = 1.51441426, grad/param norm = 9.6825e-02, time/batch = 0.0777s	
1317/4200 (epoch 15.679), train_loss = 1.50491730, grad/param norm = 7.9193e-02, time/batch = 0.0784s	
1318/4200 (epoch 15.690), train_loss = 1.49397268, grad/param norm = 7.4921e-02, time/batch = 0.0776s	
1319/4200 (epoch 15.702), train_loss = 1.49528038, grad/param norm = 8.4514e-02, time/batch = 0.0782s	
1320/4200 (epoch 15.714), train_loss = 1.51959328, grad/param norm = 9.0584e-02, time/batch = 0.0788s	
1321/4200 (epoch 15.726), train_loss = 1.51625729, grad/param norm = 8.5612e-02, time/batch = 0.0800s	
1322/4200 (epoch 15.738), train_loss = 1.51215595, grad/param norm = 7.8443e-02, time/batch = 0.0780s	
1323/4200 (epoch 15.750), train_loss = 1.50427024, grad/param norm = 7.1608e-02, time/batch = 0.0806s	
1324/4200 (epoch 15.762), train_loss = 1.50242480, grad/param norm = 7.5155e-02, time/batch = 0.0784s	
1325/4200 (epoch 15.774), train_loss = 1.51836786, grad/param norm = 8.6382e-02, time/batch = 0.0783s	
1326/4200 (epoch 15.786), train_loss = 1.49933584, grad/param norm = 9.9028e-02, time/batch = 0.0778s	
1327/4200 (epoch 15.798), train_loss = 1.51917837, grad/param norm = 9.4262e-02, time/batch = 0.0783s	
1328/4200 (epoch 15.810), train_loss = 1.50919881, grad/param norm = 8.3430e-02, time/batch = 0.0780s	
1329/4200 (epoch 15.821), train_loss = 1.49556744, grad/param norm = 9.2618e-02, time/batch = 0.0782s	
1330/4200 (epoch 15.833), train_loss = 1.51866028, grad/param norm = 1.2550e-01, time/batch = 0.0782s	
1331/4200 (epoch 15.845), train_loss = 1.55133685, grad/param norm = 1.4791e-01, time/batch = 0.0799s	
1332/4200 (epoch 15.857), train_loss = 1.54784746, grad/param norm = 1.6797e-01, time/batch = 0.0777s	
1333/4200 (epoch 15.869), train_loss = 1.56424448, grad/param norm = 1.4361e-01, time/batch = 0.0786s	
1334/4200 (epoch 15.881), train_loss = 1.51741056, grad/param norm = 1.1059e-01, time/batch = 0.0794s	
1335/4200 (epoch 15.893), train_loss = 1.53569443, grad/param norm = 9.3591e-02, time/batch = 0.0782s	
1336/4200 (epoch 15.905), train_loss = 1.50924114, grad/param norm = 9.4377e-02, time/batch = 0.0779s	
1337/4200 (epoch 15.917), train_loss = 1.53519247, grad/param norm = 1.0250e-01, time/batch = 0.0783s	
1338/4200 (epoch 15.929), train_loss = 1.51566709, grad/param norm = 8.9527e-02, time/batch = 0.0777s	
1339/4200 (epoch 15.940), train_loss = 1.51631959, grad/param norm = 7.3055e-02, time/batch = 0.0790s	
1340/4200 (epoch 15.952), train_loss = 1.51701044, grad/param norm = 7.3881e-02, time/batch = 0.0780s	
1341/4200 (epoch 15.964), train_loss = 1.52668509, grad/param norm = 7.3116e-02, time/batch = 0.0800s	
1342/4200 (epoch 15.976), train_loss = 1.51788996, grad/param norm = 7.4109e-02, time/batch = 0.0781s	
1343/4200 (epoch 15.988), train_loss = 1.51122701, grad/param norm = 8.1336e-02, time/batch = 0.0781s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
1344/4200 (epoch 16.000), train_loss = 1.54815121, grad/param norm = 8.1046e-02, time/batch = 0.0786s	
1345/4200 (epoch 16.012), train_loss = 1.65437255, grad/param norm = 9.5213e-02, time/batch = 0.0784s	
1346/4200 (epoch 16.024), train_loss = 1.48847018, grad/param norm = 8.7471e-02, time/batch = 0.0779s	
1347/4200 (epoch 16.036), train_loss = 1.50317786, grad/param norm = 7.5472e-02, time/batch = 0.0785s	
1348/4200 (epoch 16.048), train_loss = 1.47303491, grad/param norm = 7.4402e-02, time/batch = 0.0777s	
1349/4200 (epoch 16.060), train_loss = 1.49845631, grad/param norm = 7.8868e-02, time/batch = 0.0785s	
1350/4200 (epoch 16.071), train_loss = 1.48835027, grad/param norm = 7.5212e-02, time/batch = 0.0782s	
1351/4200 (epoch 16.083), train_loss = 1.49269273, grad/param norm = 8.0225e-02, time/batch = 0.0800s	
1352/4200 (epoch 16.095), train_loss = 1.46696345, grad/param norm = 6.6599e-02, time/batch = 0.0779s	
1353/4200 (epoch 16.107), train_loss = 1.48359315, grad/param norm = 6.0742e-02, time/batch = 0.0779s	
1354/4200 (epoch 16.119), train_loss = 1.47951816, grad/param norm = 6.6220e-02, time/batch = 0.0783s	
1355/4200 (epoch 16.131), train_loss = 1.49057843, grad/param norm = 7.0319e-02, time/batch = 0.0784s	
1356/4200 (epoch 16.143), train_loss = 1.50078752, grad/param norm = 6.8944e-02, time/batch = 0.0777s	
1357/4200 (epoch 16.155), train_loss = 1.47322262, grad/param norm = 6.4773e-02, time/batch = 0.0782s	
1358/4200 (epoch 16.167), train_loss = 1.50103784, grad/param norm = 8.2819e-02, time/batch = 0.0776s	
1359/4200 (epoch 16.179), train_loss = 1.51097217, grad/param norm = 9.2307e-02, time/batch = 0.0783s	
1360/4200 (epoch 16.190), train_loss = 1.49001129, grad/param norm = 1.0615e-01, time/batch = 0.0785s	
1361/4200 (epoch 16.202), train_loss = 1.52296766, grad/param norm = 1.2376e-01, time/batch = 0.0799s	
1362/4200 (epoch 16.214), train_loss = 1.51209012, grad/param norm = 1.3050e-01, time/batch = 0.0779s	
1363/4200 (epoch 16.226), train_loss = 1.51140012, grad/param norm = 1.2994e-01, time/batch = 0.0783s	
1364/4200 (epoch 16.238), train_loss = 1.50581283, grad/param norm = 1.3079e-01, time/batch = 0.0781s	
1365/4200 (epoch 16.250), train_loss = 1.48145447, grad/param norm = 1.1018e-01, time/batch = 0.0788s	
1366/4200 (epoch 16.262), train_loss = 1.45425227, grad/param norm = 8.6236e-02, time/batch = 0.0780s	
1367/4200 (epoch 16.274), train_loss = 1.50617605, grad/param norm = 7.2613e-02, time/batch = 0.0783s	
1368/4200 (epoch 16.286), train_loss = 1.50031205, grad/param norm = 7.0046e-02, time/batch = 0.0776s	
1369/4200 (epoch 16.298), train_loss = 1.47562021, grad/param norm = 7.6530e-02, time/batch = 0.0783s	
1370/4200 (epoch 16.310), train_loss = 1.51292610, grad/param norm = 8.9542e-02, time/batch = 0.0779s	
1371/4200 (epoch 16.321), train_loss = 1.45993994, grad/param norm = 7.7518e-02, time/batch = 0.0799s	
1372/4200 (epoch 16.333), train_loss = 1.49832312, grad/param norm = 6.7710e-02, time/batch = 0.0779s	
1373/4200 (epoch 16.345), train_loss = 1.48304693, grad/param norm = 6.5421e-02, time/batch = 0.0791s	
1374/4200 (epoch 16.357), train_loss = 1.48416517, grad/param norm = 7.4885e-02, time/batch = 0.0784s	
1375/4200 (epoch 16.369), train_loss = 1.50786603, grad/param norm = 8.5900e-02, time/batch = 0.0784s	
1376/4200 (epoch 16.381), train_loss = 1.50482426, grad/param norm = 9.3139e-02, time/batch = 0.0781s	
1377/4200 (epoch 16.393), train_loss = 1.51738636, grad/param norm = 9.7025e-02, time/batch = 0.0783s	
1378/4200 (epoch 16.405), train_loss = 1.50766951, grad/param norm = 9.6042e-02, time/batch = 0.0777s	
1379/4200 (epoch 16.417), train_loss = 1.47153551, grad/param norm = 9.2998e-02, time/batch = 0.0784s	
1380/4200 (epoch 16.429), train_loss = 1.48560285, grad/param norm = 9.7662e-02, time/batch = 0.0780s	
1381/4200 (epoch 16.440), train_loss = 1.50056181, grad/param norm = 9.0740e-02, time/batch = 0.0805s	
1382/4200 (epoch 16.452), train_loss = 1.50751644, grad/param norm = 7.8018e-02, time/batch = 0.0778s	
1383/4200 (epoch 16.464), train_loss = 1.49380834, grad/param norm = 7.0274e-02, time/batch = 0.0782s	
1384/4200 (epoch 16.476), train_loss = 1.51585325, grad/param norm = 7.5535e-02, time/batch = 0.0781s	
1385/4200 (epoch 16.488), train_loss = 1.52002462, grad/param norm = 9.4412e-02, time/batch = 0.0783s	
1386/4200 (epoch 16.500), train_loss = 1.49330353, grad/param norm = 1.0270e-01, time/batch = 0.0809s	
1387/4200 (epoch 16.512), train_loss = 1.49966969, grad/param norm = 1.0236e-01, time/batch = 0.0804s	
1388/4200 (epoch 16.524), train_loss = 1.46416758, grad/param norm = 8.6036e-02, time/batch = 0.0781s	
1389/4200 (epoch 16.536), train_loss = 1.48185980, grad/param norm = 8.0897e-02, time/batch = 0.0783s	
1390/4200 (epoch 16.548), train_loss = 1.47535316, grad/param norm = 9.4305e-02, time/batch = 0.0781s	
1391/4200 (epoch 16.560), train_loss = 1.49799783, grad/param norm = 1.0317e-01, time/batch = 0.0804s	
1392/4200 (epoch 16.571), train_loss = 1.45869343, grad/param norm = 1.0803e-01, time/batch = 0.0779s	
1393/4200 (epoch 16.583), train_loss = 1.49805310, grad/param norm = 1.0939e-01, time/batch = 0.0782s	
1394/4200 (epoch 16.595), train_loss = 1.49690866, grad/param norm = 1.1952e-01, time/batch = 0.0784s	
1395/4200 (epoch 16.607), train_loss = 1.48817229, grad/param norm = 1.2514e-01, time/batch = 0.0785s	
1396/4200 (epoch 16.619), train_loss = 1.47967339, grad/param norm = 9.9070e-02, time/batch = 0.0778s	
1397/4200 (epoch 16.631), train_loss = 1.47337202, grad/param norm = 7.6801e-02, time/batch = 0.0789s	
1398/4200 (epoch 16.643), train_loss = 1.47767153, grad/param norm = 7.4481e-02, time/batch = 0.0780s	
1399/4200 (epoch 16.655), train_loss = 1.47936652, grad/param norm = 6.9381e-02, time/batch = 0.0782s	
1400/4200 (epoch 16.667), train_loss = 1.48974803, grad/param norm = 6.5280e-02, time/batch = 0.0782s	
1401/4200 (epoch 16.679), train_loss = 1.48284201, grad/param norm = 6.6435e-02, time/batch = 0.0801s	
1402/4200 (epoch 16.690), train_loss = 1.47326971, grad/param norm = 7.3792e-02, time/batch = 0.0783s	
1403/4200 (epoch 16.702), train_loss = 1.47550563, grad/param norm = 8.2968e-02, time/batch = 0.0782s	
1404/4200 (epoch 16.714), train_loss = 1.49994812, grad/param norm = 8.9815e-02, time/batch = 0.0782s	
1405/4200 (epoch 16.726), train_loss = 1.49678909, grad/param norm = 8.2367e-02, time/batch = 0.0783s	
1406/4200 (epoch 16.738), train_loss = 1.49138332, grad/param norm = 7.3643e-02, time/batch = 0.0780s	
1407/4200 (epoch 16.750), train_loss = 1.48838947, grad/param norm = 7.2816e-02, time/batch = 0.0788s	
1408/4200 (epoch 16.762), train_loss = 1.48728558, grad/param norm = 8.7001e-02, time/batch = 0.0780s	
1409/4200 (epoch 16.774), train_loss = 1.50594627, grad/param norm = 1.0077e-01, time/batch = 0.0782s	
1410/4200 (epoch 16.786), train_loss = 1.48418465, grad/param norm = 1.0638e-01, time/batch = 0.0782s	
1411/4200 (epoch 16.798), train_loss = 1.50214614, grad/param norm = 8.9505e-02, time/batch = 0.0800s	
1412/4200 (epoch 16.810), train_loss = 1.49000831, grad/param norm = 7.5190e-02, time/batch = 0.0785s	
1413/4200 (epoch 16.821), train_loss = 1.47750440, grad/param norm = 8.9745e-02, time/batch = 0.0781s	
1414/4200 (epoch 16.833), train_loss = 1.50203727, grad/param norm = 1.2450e-01, time/batch = 0.0782s	
1415/4200 (epoch 16.845), train_loss = 1.53329203, grad/param norm = 1.5147e-01, time/batch = 0.0787s	
1416/4200 (epoch 16.857), train_loss = 1.53357424, grad/param norm = 1.5432e-01, time/batch = 0.0778s	
1417/4200 (epoch 16.869), train_loss = 1.53898505, grad/param norm = 1.1402e-01, time/batch = 0.0784s	
1418/4200 (epoch 16.881), train_loss = 1.49458038, grad/param norm = 8.1991e-02, time/batch = 0.0781s	
1419/4200 (epoch 16.893), train_loss = 1.51238862, grad/param norm = 7.4986e-02, time/batch = 0.0783s	
1420/4200 (epoch 16.905), train_loss = 1.48657923, grad/param norm = 8.2724e-02, time/batch = 0.0781s	
1421/4200 (epoch 16.917), train_loss = 1.51169329, grad/param norm = 8.7016e-02, time/batch = 0.0799s	
1422/4200 (epoch 16.929), train_loss = 1.49244155, grad/param norm = 7.4849e-02, time/batch = 0.0780s	
1423/4200 (epoch 16.940), train_loss = 1.49846889, grad/param norm = 7.0226e-02, time/batch = 0.0787s	
1424/4200 (epoch 16.952), train_loss = 1.49651398, grad/param norm = 7.0599e-02, time/batch = 0.0781s	
1425/4200 (epoch 16.964), train_loss = 1.50760322, grad/param norm = 7.1208e-02, time/batch = 0.0784s	
1426/4200 (epoch 16.976), train_loss = 1.49919351, grad/param norm = 7.5182e-02, time/batch = 0.0780s	
1427/4200 (epoch 16.988), train_loss = 1.49342691, grad/param norm = 8.5426e-02, time/batch = 0.0782s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
1428/4200 (epoch 17.000), train_loss = 1.53175868, grad/param norm = 8.6728e-02, time/batch = 0.0784s	
1429/4200 (epoch 17.012), train_loss = 1.64347353, grad/param norm = 1.0832e-01, time/batch = 0.0787s	
1430/4200 (epoch 17.024), train_loss = 1.47875386, grad/param norm = 1.0746e-01, time/batch = 0.0782s	
1431/4200 (epoch 17.036), train_loss = 1.48866791, grad/param norm = 9.7357e-02, time/batch = 0.0799s	
1432/4200 (epoch 17.048), train_loss = 1.45958879, grad/param norm = 9.2376e-02, time/batch = 0.0779s	
1433/4200 (epoch 17.060), train_loss = 1.48314773, grad/param norm = 9.3011e-02, time/batch = 0.0782s	
1434/4200 (epoch 17.071), train_loss = 1.47503696, grad/param norm = 9.0774e-02, time/batch = 0.0783s	
1435/4200 (epoch 17.083), train_loss = 1.47708020, grad/param norm = 9.4974e-02, time/batch = 0.0785s	
1436/4200 (epoch 17.095), train_loss = 1.45365369, grad/param norm = 8.1744e-02, time/batch = 0.0780s	
1437/4200 (epoch 17.107), train_loss = 1.46854911, grad/param norm = 6.9093e-02, time/batch = 0.0783s	
1438/4200 (epoch 17.119), train_loss = 1.46321043, grad/param norm = 6.7133e-02, time/batch = 0.0778s	
1439/4200 (epoch 17.131), train_loss = 1.47321483, grad/param norm = 6.6656e-02, time/batch = 0.0787s	
1440/4200 (epoch 17.143), train_loss = 1.48335351, grad/param norm = 6.8209e-02, time/batch = 0.0783s	
1441/4200 (epoch 17.155), train_loss = 1.45490735, grad/param norm = 6.4646e-02, time/batch = 0.0799s	
1442/4200 (epoch 17.167), train_loss = 1.48177168, grad/param norm = 7.4912e-02, time/batch = 0.0781s	
1443/4200 (epoch 17.179), train_loss = 1.48992861, grad/param norm = 8.3779e-02, time/batch = 0.0783s	
1444/4200 (epoch 17.190), train_loss = 1.46799752, grad/param norm = 8.6404e-02, time/batch = 0.0785s	
1445/4200 (epoch 17.202), train_loss = 1.49836805, grad/param norm = 8.9316e-02, time/batch = 0.0784s	
1446/4200 (epoch 17.214), train_loss = 1.48506804, grad/param norm = 8.5271e-02, time/batch = 0.0780s	
1447/4200 (epoch 17.226), train_loss = 1.48338175, grad/param norm = 8.1247e-02, time/batch = 0.0783s	
1448/4200 (epoch 17.238), train_loss = 1.47701602, grad/param norm = 8.2769e-02, time/batch = 0.0779s	
1449/4200 (epoch 17.250), train_loss = 1.45767791, grad/param norm = 8.7466e-02, time/batch = 0.0783s	
1450/4200 (epoch 17.262), train_loss = 1.43669071, grad/param norm = 8.7957e-02, time/batch = 0.0787s	
1451/4200 (epoch 17.274), train_loss = 1.48984073, grad/param norm = 8.3407e-02, time/batch = 0.0798s	
1452/4200 (epoch 17.286), train_loss = 1.48514066, grad/param norm = 7.2522e-02, time/batch = 0.0779s	
1453/4200 (epoch 17.298), train_loss = 1.45643396, grad/param norm = 6.8989e-02, time/batch = 0.0783s	
1454/4200 (epoch 17.310), train_loss = 1.49524073, grad/param norm = 7.9760e-02, time/batch = 0.0782s	
1455/4200 (epoch 17.321), train_loss = 1.44417171, grad/param norm = 8.8952e-02, time/batch = 0.0789s	
1456/4200 (epoch 17.333), train_loss = 1.48791449, grad/param norm = 1.0334e-01, time/batch = 0.0777s	
1457/4200 (epoch 17.345), train_loss = 1.47921371, grad/param norm = 1.2074e-01, time/batch = 0.0783s	
1458/4200 (epoch 17.357), train_loss = 1.47832779, grad/param norm = 1.1857e-01, time/batch = 0.0778s	
1459/4200 (epoch 17.369), train_loss = 1.49261679, grad/param norm = 1.0535e-01, time/batch = 0.0783s	
1460/4200 (epoch 17.381), train_loss = 1.48806554, grad/param norm = 9.9090e-02, time/batch = 0.0786s	
1461/4200 (epoch 17.393), train_loss = 1.50059586, grad/param norm = 1.0577e-01, time/batch = 0.0801s	
1462/4200 (epoch 17.405), train_loss = 1.49505905, grad/param norm = 1.0506e-01, time/batch = 0.0778s	
1463/4200 (epoch 17.417), train_loss = 1.45898783, grad/param norm = 1.0304e-01, time/batch = 0.0781s	
1464/4200 (epoch 17.429), train_loss = 1.46911205, grad/param norm = 8.5789e-02, time/batch = 0.0781s	
1465/4200 (epoch 17.440), train_loss = 1.47813354, grad/param norm = 6.9751e-02, time/batch = 0.0788s	
1466/4200 (epoch 17.452), train_loss = 1.48918453, grad/param norm = 6.8240e-02, time/batch = 0.0778s	
1467/4200 (epoch 17.464), train_loss = 1.47590906, grad/param norm = 7.1343e-02, time/batch = 0.0785s	
1468/4200 (epoch 17.476), train_loss = 1.49861258, grad/param norm = 7.3803e-02, time/batch = 0.0778s	
1469/4200 (epoch 17.488), train_loss = 1.49986307, grad/param norm = 8.1036e-02, time/batch = 0.0782s	
1470/4200 (epoch 17.500), train_loss = 1.46949930, grad/param norm = 7.9985e-02, time/batch = 0.0781s	
1471/4200 (epoch 17.512), train_loss = 1.47589089, grad/param norm = 7.8154e-02, time/batch = 0.0802s	
1472/4200 (epoch 17.524), train_loss = 1.44405125, grad/param norm = 8.4929e-02, time/batch = 0.0779s	
1473/4200 (epoch 17.536), train_loss = 1.46873131, grad/param norm = 9.4227e-02, time/batch = 0.0783s	
1474/4200 (epoch 17.548), train_loss = 1.46034322, grad/param norm = 9.2528e-02, time/batch = 0.0781s	
1475/4200 (epoch 17.560), train_loss = 1.48369453, grad/param norm = 9.1355e-02, time/batch = 0.0782s	
1476/4200 (epoch 17.571), train_loss = 1.43923167, grad/param norm = 8.6498e-02, time/batch = 0.0784s	
1477/4200 (epoch 17.583), train_loss = 1.47516524, grad/param norm = 7.5778e-02, time/batch = 0.0783s	
1478/4200 (epoch 17.595), train_loss = 1.47246175, grad/param norm = 8.5917e-02, time/batch = 0.0779s	
1479/4200 (epoch 17.607), train_loss = 1.46226039, grad/param norm = 9.6087e-02, time/batch = 0.0791s	
1480/4200 (epoch 17.619), train_loss = 1.45935472, grad/param norm = 8.9329e-02, time/batch = 0.0781s	
1481/4200 (epoch 17.631), train_loss = 1.45604952, grad/param norm = 7.8275e-02, time/batch = 0.0807s	
1482/4200 (epoch 17.643), train_loss = 1.46136145, grad/param norm = 7.6151e-02, time/batch = 0.0783s	
1483/4200 (epoch 17.655), train_loss = 1.46278091, grad/param norm = 6.6810e-02, time/batch = 0.0781s	
1484/4200 (epoch 17.667), train_loss = 1.47270998, grad/param norm = 6.4226e-02, time/batch = 0.0783s	
1485/4200 (epoch 17.679), train_loss = 1.46524758, grad/param norm = 6.4231e-02, time/batch = 0.0784s	
1486/4200 (epoch 17.690), train_loss = 1.45495635, grad/param norm = 7.2453e-02, time/batch = 0.0783s	
1487/4200 (epoch 17.702), train_loss = 1.45729881, grad/param norm = 8.3118e-02, time/batch = 0.0784s	
1488/4200 (epoch 17.714), train_loss = 1.48215670, grad/param norm = 9.3847e-02, time/batch = 0.0777s	
1489/4200 (epoch 17.726), train_loss = 1.48373511, grad/param norm = 9.7215e-02, time/batch = 0.0783s	
1490/4200 (epoch 17.738), train_loss = 1.48152186, grad/param norm = 1.0523e-01, time/batch = 0.0781s	
1491/4200 (epoch 17.750), train_loss = 1.48367948, grad/param norm = 1.1223e-01, time/batch = 0.0798s	
1492/4200 (epoch 17.762), train_loss = 1.48041762, grad/param norm = 1.1817e-01, time/batch = 0.0845s	
1493/4200 (epoch 17.774), train_loss = 1.49580027, grad/param norm = 1.2013e-01, time/batch = 0.0784s	
1494/4200 (epoch 17.786), train_loss = 1.46754216, grad/param norm = 1.0516e-01, time/batch = 0.0784s	
1495/4200 (epoch 17.798), train_loss = 1.48148481, grad/param norm = 8.5162e-02, time/batch = 0.0783s	
1496/4200 (epoch 17.810), train_loss = 1.47381543, grad/param norm = 7.4987e-02, time/batch = 0.0779s	
1497/4200 (epoch 17.821), train_loss = 1.45988524, grad/param norm = 8.5390e-02, time/batch = 0.0790s	
1498/4200 (epoch 17.833), train_loss = 1.47952748, grad/param norm = 9.5864e-02, time/batch = 0.0777s	
1499/4200 (epoch 17.845), train_loss = 1.49737304, grad/param norm = 9.5454e-02, time/batch = 0.0784s	
1500/4200 (epoch 17.857), train_loss = 1.49823494, grad/param norm = 9.8466e-02, time/batch = 0.0782s	
1501/4200 (epoch 17.869), train_loss = 1.51086171, grad/param norm = 8.6755e-02, time/batch = 0.0800s	
1502/4200 (epoch 17.881), train_loss = 1.47627306, grad/param norm = 7.9590e-02, time/batch = 0.0783s	
1503/4200 (epoch 17.893), train_loss = 1.49462965, grad/param norm = 7.5422e-02, time/batch = 0.0783s	
1504/4200 (epoch 17.905), train_loss = 1.47058326, grad/param norm = 7.9051e-02, time/batch = 0.0783s	
1505/4200 (epoch 17.917), train_loss = 1.49437011, grad/param norm = 8.4097e-02, time/batch = 0.0783s	
1506/4200 (epoch 17.929), train_loss = 1.47601045, grad/param norm = 7.8080e-02, time/batch = 0.0777s	
1507/4200 (epoch 17.940), train_loss = 1.48297325, grad/param norm = 7.3368e-02, time/batch = 0.0783s	
1508/4200 (epoch 17.952), train_loss = 1.48097098, grad/param norm = 7.8023e-02, time/batch = 0.0777s	
1509/4200 (epoch 17.964), train_loss = 1.49250898, grad/param norm = 7.4513e-02, time/batch = 0.0783s	
1510/4200 (epoch 17.976), train_loss = 1.48398011, grad/param norm = 7.6529e-02, time/batch = 0.0779s	
1511/4200 (epoch 17.988), train_loss = 1.47853647, grad/param norm = 7.8548e-02, time/batch = 0.0799s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
1512/4200 (epoch 18.000), train_loss = 1.51413110, grad/param norm = 7.7978e-02, time/batch = 0.0777s	
1513/4200 (epoch 18.012), train_loss = 1.62420148, grad/param norm = 9.4765e-02, time/batch = 0.0786s	
1514/4200 (epoch 18.024), train_loss = 1.45822107, grad/param norm = 9.2942e-02, time/batch = 0.0783s	
1515/4200 (epoch 18.036), train_loss = 1.47190072, grad/param norm = 8.2530e-02, time/batch = 0.0781s	
1516/4200 (epoch 18.048), train_loss = 1.43885030, grad/param norm = 7.2713e-02, time/batch = 0.0778s	
1517/4200 (epoch 18.060), train_loss = 1.46253005, grad/param norm = 7.0977e-02, time/batch = 0.0781s	
1518/4200 (epoch 18.071), train_loss = 1.45833032, grad/param norm = 8.0846e-02, time/batch = 0.0781s	
1519/4200 (epoch 18.083), train_loss = 1.46105023, grad/param norm = 9.4647e-02, time/batch = 0.0785s	
1520/4200 (epoch 18.095), train_loss = 1.43990625, grad/param norm = 8.7578e-02, time/batch = 0.0781s	
1521/4200 (epoch 18.107), train_loss = 1.45381309, grad/param norm = 7.8850e-02, time/batch = 0.0800s	
1522/4200 (epoch 18.119), train_loss = 1.44975221, grad/param norm = 8.3814e-02, time/batch = 0.0780s	
1523/4200 (epoch 18.131), train_loss = 1.46227391, grad/param norm = 8.8850e-02, time/batch = 0.0787s	
1524/4200 (epoch 18.143), train_loss = 1.47106826, grad/param norm = 8.7682e-02, time/batch = 0.0784s	
1525/4200 (epoch 18.155), train_loss = 1.44379573, grad/param norm = 8.2588e-02, time/batch = 0.0783s	
1526/4200 (epoch 18.167), train_loss = 1.47271731, grad/param norm = 1.0306e-01, time/batch = 0.0780s	
1527/4200 (epoch 18.179), train_loss = 1.48381290, grad/param norm = 1.1125e-01, time/batch = 0.0782s	
1528/4200 (epoch 18.190), train_loss = 1.46193743, grad/param norm = 1.1286e-01, time/batch = 0.0776s	
1529/4200 (epoch 18.202), train_loss = 1.48964596, grad/param norm = 1.0901e-01, time/batch = 0.0787s	
1530/4200 (epoch 18.214), train_loss = 1.47020895, grad/param norm = 8.9245e-02, time/batch = 0.0782s	
1531/4200 (epoch 18.226), train_loss = 1.46664274, grad/param norm = 7.5233e-02, time/batch = 0.0799s	
1532/4200 (epoch 18.238), train_loss = 1.45823936, grad/param norm = 7.1426e-02, time/batch = 0.0779s	
1533/4200 (epoch 18.250), train_loss = 1.43749543, grad/param norm = 6.6348e-02, time/batch = 0.0782s	
1534/4200 (epoch 18.262), train_loss = 1.41415178, grad/param norm = 6.4877e-02, time/batch = 0.0790s	
1535/4200 (epoch 18.274), train_loss = 1.46924964, grad/param norm = 6.8166e-02, time/batch = 0.0786s	
1536/4200 (epoch 18.286), train_loss = 1.46700172, grad/param norm = 6.6565e-02, time/batch = 0.0779s	
1537/4200 (epoch 18.298), train_loss = 1.43937412, grad/param norm = 6.4848e-02, time/batch = 0.0784s	
1538/4200 (epoch 18.310), train_loss = 1.47819447, grad/param norm = 7.1502e-02, time/batch = 0.0776s	
1539/4200 (epoch 18.321), train_loss = 1.42633296, grad/param norm = 7.1053e-02, time/batch = 0.0788s	
1540/4200 (epoch 18.333), train_loss = 1.46621403, grad/param norm = 7.2994e-02, time/batch = 0.0783s	
1541/4200 (epoch 18.345), train_loss = 1.45410693, grad/param norm = 7.8512e-02, time/batch = 0.0799s	
1542/4200 (epoch 18.357), train_loss = 1.45300777, grad/param norm = 7.9541e-02, time/batch = 0.0782s	
1543/4200 (epoch 18.369), train_loss = 1.47166960, grad/param norm = 7.8629e-02, time/batch = 0.0781s	
1544/4200 (epoch 18.381), train_loss = 1.46672165, grad/param norm = 7.7175e-02, time/batch = 0.0787s	
1545/4200 (epoch 18.393), train_loss = 1.48020682, grad/param norm = 7.1711e-02, time/batch = 0.0784s	
1546/4200 (epoch 18.405), train_loss = 1.47166428, grad/param norm = 7.3310e-02, time/batch = 0.0777s	
1547/4200 (epoch 18.417), train_loss = 1.44020550, grad/param norm = 8.4937e-02, time/batch = 0.0782s	
1548/4200 (epoch 18.429), train_loss = 1.45218783, grad/param norm = 8.5612e-02, time/batch = 0.0778s	
1549/4200 (epoch 18.440), train_loss = 1.46697239, grad/param norm = 9.0977e-02, time/batch = 0.0780s	
1550/4200 (epoch 18.452), train_loss = 1.48331349, grad/param norm = 1.0429e-01, time/batch = 0.0786s	
1551/4200 (epoch 18.464), train_loss = 1.46988974, grad/param norm = 1.0123e-01, time/batch = 0.0798s	
1552/4200 (epoch 18.476), train_loss = 1.48897807, grad/param norm = 8.6743e-02, time/batch = 0.0780s	
1553/4200 (epoch 18.488), train_loss = 1.48938033, grad/param norm = 9.2763e-02, time/batch = 0.0782s	
1554/4200 (epoch 18.500), train_loss = 1.45680992, grad/param norm = 8.7478e-02, time/batch = 0.0780s	
1555/4200 (epoch 18.512), train_loss = 1.46085111, grad/param norm = 7.7078e-02, time/batch = 0.0789s	
1556/4200 (epoch 18.524), train_loss = 1.42496844, grad/param norm = 6.6808e-02, time/batch = 0.0779s	
1557/4200 (epoch 18.536), train_loss = 1.44720135, grad/param norm = 6.4899e-02, time/batch = 0.0784s	
1558/4200 (epoch 18.548), train_loss = 1.43992979, grad/param norm = 7.1643e-02, time/batch = 0.0778s	
1559/4200 (epoch 18.560), train_loss = 1.46569653, grad/param norm = 8.0608e-02, time/batch = 0.0782s	
1560/4200 (epoch 18.571), train_loss = 1.42286796, grad/param norm = 8.4870e-02, time/batch = 0.0785s	
1561/4200 (epoch 18.583), train_loss = 1.46010005, grad/param norm = 8.2919e-02, time/batch = 0.0800s	
1562/4200 (epoch 18.595), train_loss = 1.45923205, grad/param norm = 9.3315e-02, time/batch = 0.0779s	
1563/4200 (epoch 18.607), train_loss = 1.44847035, grad/param norm = 1.0904e-01, time/batch = 0.0784s	
1564/4200 (epoch 18.619), train_loss = 1.44604562, grad/param norm = 9.7350e-02, time/batch = 0.0782s	
1565/4200 (epoch 18.631), train_loss = 1.43999165, grad/param norm = 7.7842e-02, time/batch = 0.0781s	
1566/4200 (epoch 18.643), train_loss = 1.44360315, grad/param norm = 6.8781e-02, time/batch = 0.0778s	
1567/4200 (epoch 18.655), train_loss = 1.44758289, grad/param norm = 6.9645e-02, time/batch = 0.0785s	
1568/4200 (epoch 18.667), train_loss = 1.46132232, grad/param norm = 7.8772e-02, time/batch = 0.0779s	
1569/4200 (epoch 18.679), train_loss = 1.45413100, grad/param norm = 8.2588e-02, time/batch = 0.0783s	
1570/4200 (epoch 18.690), train_loss = 1.44326046, grad/param norm = 7.8192e-02, time/batch = 0.0781s	
1571/4200 (epoch 18.702), train_loss = 1.44230852, grad/param norm = 8.1001e-02, time/batch = 0.0804s	
1572/4200 (epoch 18.714), train_loss = 1.46631365, grad/param norm = 8.4941e-02, time/batch = 0.0778s	
1573/4200 (epoch 18.726), train_loss = 1.46625892, grad/param norm = 8.9065e-02, time/batch = 0.0780s	
1574/4200 (epoch 18.738), train_loss = 1.46219987, grad/param norm = 9.0803e-02, time/batch = 0.0783s	
1575/4200 (epoch 18.750), train_loss = 1.46228716, grad/param norm = 9.3543e-02, time/batch = 0.0783s	
1576/4200 (epoch 18.762), train_loss = 1.45903420, grad/param norm = 8.9096e-02, time/batch = 0.0783s	
1577/4200 (epoch 18.774), train_loss = 1.46765060, grad/param norm = 8.7055e-02, time/batch = 0.0786s	
1578/4200 (epoch 18.786), train_loss = 1.45001081, grad/param norm = 9.6414e-02, time/batch = 0.0777s	
1579/4200 (epoch 18.798), train_loss = 1.46838219, grad/param norm = 8.8149e-02, time/batch = 0.0782s	
1580/4200 (epoch 18.810), train_loss = 1.46217140, grad/param norm = 7.5455e-02, time/batch = 0.0780s	
1581/4200 (epoch 18.821), train_loss = 1.44395476, grad/param norm = 7.5537e-02, time/batch = 0.0801s	
1582/4200 (epoch 18.833), train_loss = 1.46453592, grad/param norm = 8.1732e-02, time/batch = 0.0778s	
1583/4200 (epoch 18.845), train_loss = 1.48057345, grad/param norm = 9.1190e-02, time/batch = 0.0780s	
1584/4200 (epoch 18.857), train_loss = 1.48528914, grad/param norm = 9.5739e-02, time/batch = 0.0790s	
1585/4200 (epoch 18.869), train_loss = 1.49724244, grad/param norm = 9.1262e-02, time/batch = 0.0784s	
1586/4200 (epoch 18.881), train_loss = 1.46566966, grad/param norm = 8.3913e-02, time/batch = 0.0779s	
1587/4200 (epoch 18.893), train_loss = 1.48082160, grad/param norm = 8.1430e-02, time/batch = 0.0791s	
1588/4200 (epoch 18.905), train_loss = 1.45752151, grad/param norm = 8.3204e-02, time/batch = 0.0780s	
1589/4200 (epoch 18.917), train_loss = 1.47649867, grad/param norm = 7.7650e-02, time/batch = 0.0782s	
1590/4200 (epoch 18.929), train_loss = 1.45922575, grad/param norm = 6.7455e-02, time/batch = 0.0781s	
1591/4200 (epoch 18.940), train_loss = 1.46731510, grad/param norm = 7.2725e-02, time/batch = 0.0798s	
1592/4200 (epoch 18.952), train_loss = 1.47073769, grad/param norm = 8.5708e-02, time/batch = 0.0784s	
1593/4200 (epoch 18.964), train_loss = 1.48112315, grad/param norm = 9.9378e-02, time/batch = 0.0781s	
1594/4200 (epoch 18.976), train_loss = 1.47836967, grad/param norm = 1.0852e-01, time/batch = 0.0781s	
1595/4200 (epoch 18.988), train_loss = 1.47114900, grad/param norm = 1.1304e-01, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
1596/4200 (epoch 19.000), train_loss = 1.50828043, grad/param norm = 1.0011e-01, time/batch = 0.0778s	
1597/4200 (epoch 19.012), train_loss = 1.61820594, grad/param norm = 1.0034e-01, time/batch = 0.0789s	
1598/4200 (epoch 19.024), train_loss = 1.44471819, grad/param norm = 9.0725e-02, time/batch = 0.0803s	
1599/4200 (epoch 19.036), train_loss = 1.45719212, grad/param norm = 8.6078e-02, time/batch = 0.0785s	
1600/4200 (epoch 19.048), train_loss = 1.42605127, grad/param norm = 7.4039e-02, time/batch = 0.0780s	
1601/4200 (epoch 19.060), train_loss = 1.44795279, grad/param norm = 6.9803e-02, time/batch = 0.0799s	
1602/4200 (epoch 19.071), train_loss = 1.44158741, grad/param norm = 6.6757e-02, time/batch = 0.0783s	
1603/4200 (epoch 19.083), train_loss = 1.44020047, grad/param norm = 6.6397e-02, time/batch = 0.0782s	
1604/4200 (epoch 19.095), train_loss = 1.41957014, grad/param norm = 5.5395e-02, time/batch = 0.0782s	
1605/4200 (epoch 19.107), train_loss = 1.43532884, grad/param norm = 5.6479e-02, time/batch = 0.0785s	
1606/4200 (epoch 19.119), train_loss = 1.43066991, grad/param norm = 5.7836e-02, time/batch = 0.0777s	
1607/4200 (epoch 19.131), train_loss = 1.44210434, grad/param norm = 5.9654e-02, time/batch = 0.0782s	
1608/4200 (epoch 19.143), train_loss = 1.45070202, grad/param norm = 6.0994e-02, time/batch = 0.0783s	
1609/4200 (epoch 19.155), train_loss = 1.42444650, grad/param norm = 5.8593e-02, time/batch = 0.0783s	
1610/4200 (epoch 19.167), train_loss = 1.45239357, grad/param norm = 7.2380e-02, time/batch = 0.0779s	
1611/4200 (epoch 19.179), train_loss = 1.46010340, grad/param norm = 7.9081e-02, time/batch = 0.0799s	
1612/4200 (epoch 19.190), train_loss = 1.43922058, grad/param norm = 8.3580e-02, time/batch = 0.0778s	
1613/4200 (epoch 19.202), train_loss = 1.47224180, grad/param norm = 9.3974e-02, time/batch = 0.0787s	
1614/4200 (epoch 19.214), train_loss = 1.45689235, grad/param norm = 9.4225e-02, time/batch = 0.0781s	
1615/4200 (epoch 19.226), train_loss = 1.45827939, grad/param norm = 9.0077e-02, time/batch = 0.0782s	
1616/4200 (epoch 19.238), train_loss = 1.44906006, grad/param norm = 8.6933e-02, time/batch = 0.0777s	
1617/4200 (epoch 19.250), train_loss = 1.42806405, grad/param norm = 8.1964e-02, time/batch = 0.0783s	
1618/4200 (epoch 19.262), train_loss = 1.40466846, grad/param norm = 7.7948e-02, time/batch = 0.0780s	
1619/4200 (epoch 19.274), train_loss = 1.45645174, grad/param norm = 7.2435e-02, time/batch = 0.0783s	
1620/4200 (epoch 19.286), train_loss = 1.45298809, grad/param norm = 6.3892e-02, time/batch = 0.0781s	
1621/4200 (epoch 19.298), train_loss = 1.42509613, grad/param norm = 6.5392e-02, time/batch = 0.0800s	
1622/4200 (epoch 19.310), train_loss = 1.46551092, grad/param norm = 7.9552e-02, time/batch = 0.0778s	
1623/4200 (epoch 19.321), train_loss = 1.41307557, grad/param norm = 7.3711e-02, time/batch = 0.0780s	
1624/4200 (epoch 19.333), train_loss = 1.45000317, grad/param norm = 6.7433e-02, time/batch = 0.0781s	
1625/4200 (epoch 19.345), train_loss = 1.43627818, grad/param norm = 6.5381e-02, time/batch = 0.0782s	
1626/4200 (epoch 19.357), train_loss = 1.43740614, grad/param norm = 7.2723e-02, time/batch = 0.0781s	
1627/4200 (epoch 19.369), train_loss = 1.45705471, grad/param norm = 7.8088e-02, time/batch = 0.0785s	
1628/4200 (epoch 19.381), train_loss = 1.45174087, grad/param norm = 7.9450e-02, time/batch = 0.0780s	
1629/4200 (epoch 19.393), train_loss = 1.46678643, grad/param norm = 7.5176e-02, time/batch = 0.0785s	
1630/4200 (epoch 19.405), train_loss = 1.45885929, grad/param norm = 8.4692e-02, time/batch = 0.0783s	
1631/4200 (epoch 19.417), train_loss = 1.42863829, grad/param norm = 9.6470e-02, time/batch = 0.0799s	
1632/4200 (epoch 19.429), train_loss = 1.44190069, grad/param norm = 9.9135e-02, time/batch = 0.0779s	
1633/4200 (epoch 19.440), train_loss = 1.45771075, grad/param norm = 1.0568e-01, time/batch = 0.0782s	
1634/4200 (epoch 19.452), train_loss = 1.46846541, grad/param norm = 1.0226e-01, time/batch = 0.0785s	
1635/4200 (epoch 19.464), train_loss = 1.45458395, grad/param norm = 9.0960e-02, time/batch = 0.0783s	
1636/4200 (epoch 19.476), train_loss = 1.47179047, grad/param norm = 8.1571e-02, time/batch = 0.0777s	
1637/4200 (epoch 19.488), train_loss = 1.47018265, grad/param norm = 7.6399e-02, time/batch = 0.0785s	
1638/4200 (epoch 19.500), train_loss = 1.43768584, grad/param norm = 7.5516e-02, time/batch = 0.0777s	
1639/4200 (epoch 19.512), train_loss = 1.44600303, grad/param norm = 7.4845e-02, time/batch = 0.0782s	
1640/4200 (epoch 19.524), train_loss = 1.41272650, grad/param norm = 8.1979e-02, time/batch = 0.0789s	
1641/4200 (epoch 19.536), train_loss = 1.43895002, grad/param norm = 8.9609e-02, time/batch = 0.0802s	
1642/4200 (epoch 19.548), train_loss = 1.43167762, grad/param norm = 9.2721e-02, time/batch = 0.0780s	
1643/4200 (epoch 19.560), train_loss = 1.45595406, grad/param norm = 8.9405e-02, time/batch = 0.0783s	
1644/4200 (epoch 19.571), train_loss = 1.40978999, grad/param norm = 8.4508e-02, time/batch = 0.0782s	
1645/4200 (epoch 19.583), train_loss = 1.44720993, grad/param norm = 8.0560e-02, time/batch = 0.0787s	
1646/4200 (epoch 19.595), train_loss = 1.44257782, grad/param norm = 8.0286e-02, time/batch = 0.0778s	
1647/4200 (epoch 19.607), train_loss = 1.42756923, grad/param norm = 8.2528e-02, time/batch = 0.0784s	
1648/4200 (epoch 19.619), train_loss = 1.42695595, grad/param norm = 7.7946e-02, time/batch = 0.0779s	
1649/4200 (epoch 19.631), train_loss = 1.42557358, grad/param norm = 7.2773e-02, time/batch = 0.0782s	
1650/4200 (epoch 19.643), train_loss = 1.43137540, grad/param norm = 7.7498e-02, time/batch = 0.0784s	
1651/4200 (epoch 19.655), train_loss = 1.43597917, grad/param norm = 7.4747e-02, time/batch = 0.0799s	
1652/4200 (epoch 19.667), train_loss = 1.44795074, grad/param norm = 7.9869e-02, time/batch = 0.0779s	
1653/4200 (epoch 19.679), train_loss = 1.44186698, grad/param norm = 8.0595e-02, time/batch = 0.0781s	
1654/4200 (epoch 19.690), train_loss = 1.42826732, grad/param norm = 7.5427e-02, time/batch = 0.0782s	
1655/4200 (epoch 19.702), train_loss = 1.42732327, grad/param norm = 7.4101e-02, time/batch = 0.0788s	
1656/4200 (epoch 19.714), train_loss = 1.45042392, grad/param norm = 7.5873e-02, time/batch = 0.0777s	
1657/4200 (epoch 19.726), train_loss = 1.45118182, grad/param norm = 7.2288e-02, time/batch = 0.0784s	
1658/4200 (epoch 19.738), train_loss = 1.44314760, grad/param norm = 7.0288e-02, time/batch = 0.0778s	
1659/4200 (epoch 19.750), train_loss = 1.44801016, grad/param norm = 7.2117e-02, time/batch = 0.0782s	
1660/4200 (epoch 19.762), train_loss = 1.44530518, grad/param norm = 8.8917e-02, time/batch = 0.0779s	
1661/4200 (epoch 19.774), train_loss = 1.46064700, grad/param norm = 9.7712e-02, time/batch = 0.0799s	
1662/4200 (epoch 19.786), train_loss = 1.43640367, grad/param norm = 8.8844e-02, time/batch = 0.0778s	
1663/4200 (epoch 19.798), train_loss = 1.44961104, grad/param norm = 7.0938e-02, time/batch = 0.0783s	
1664/4200 (epoch 19.810), train_loss = 1.44636834, grad/param norm = 6.5483e-02, time/batch = 0.0781s	
1665/4200 (epoch 19.821), train_loss = 1.43045665, grad/param norm = 7.2562e-02, time/batch = 0.0784s	
1666/4200 (epoch 19.833), train_loss = 1.45438819, grad/param norm = 9.2608e-02, time/batch = 0.0783s	
1667/4200 (epoch 19.845), train_loss = 1.47071975, grad/param norm = 1.0259e-01, time/batch = 0.0783s	
1668/4200 (epoch 19.857), train_loss = 1.47566867, grad/param norm = 1.0469e-01, time/batch = 0.0778s	
1669/4200 (epoch 19.869), train_loss = 1.48545748, grad/param norm = 9.0332e-02, time/batch = 0.0784s	
1670/4200 (epoch 19.881), train_loss = 1.45109245, grad/param norm = 8.1614e-02, time/batch = 0.0782s	
1671/4200 (epoch 19.893), train_loss = 1.46772173, grad/param norm = 8.0466e-02, time/batch = 0.0804s	
1672/4200 (epoch 19.905), train_loss = 1.44339372, grad/param norm = 7.8323e-02, time/batch = 0.0779s	
1673/4200 (epoch 19.917), train_loss = 1.46463621, grad/param norm = 7.8029e-02, time/batch = 0.0780s	
1674/4200 (epoch 19.929), train_loss = 1.44616271, grad/param norm = 6.8987e-02, time/batch = 0.0780s	
1675/4200 (epoch 19.940), train_loss = 1.45244676, grad/param norm = 6.2766e-02, time/batch = 0.0783s	
1676/4200 (epoch 19.952), train_loss = 1.45259468, grad/param norm = 7.2367e-02, time/batch = 0.0783s	
1677/4200 (epoch 19.964), train_loss = 1.46379426, grad/param norm = 8.7949e-02, time/batch = 0.0782s	
1678/4200 (epoch 19.976), train_loss = 1.45985365, grad/param norm = 8.9130e-02, time/batch = 0.0777s	
1679/4200 (epoch 19.988), train_loss = 1.45185668, grad/param norm = 7.8869e-02, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
1680/4200 (epoch 20.000), train_loss = 1.48705352, grad/param norm = 6.8285e-02, time/batch = 0.0781s	
1681/4200 (epoch 20.012), train_loss = 1.59997433, grad/param norm = 7.9255e-02, time/batch = 0.0798s	
1682/4200 (epoch 20.024), train_loss = 1.42702424, grad/param norm = 7.0560e-02, time/batch = 0.0781s	
1683/4200 (epoch 20.036), train_loss = 1.43954431, grad/param norm = 6.2039e-02, time/batch = 0.0781s	
1684/4200 (epoch 20.048), train_loss = 1.40950130, grad/param norm = 5.9576e-02, time/batch = 0.0780s	
1685/4200 (epoch 20.060), train_loss = 1.43446790, grad/param norm = 6.5582e-02, time/batch = 0.0783s	
1686/4200 (epoch 20.071), train_loss = 1.43073144, grad/param norm = 7.2440e-02, time/batch = 0.0778s	
1687/4200 (epoch 20.083), train_loss = 1.42952110, grad/param norm = 7.6792e-02, time/batch = 0.0787s	
1688/4200 (epoch 20.095), train_loss = 1.41019979, grad/param norm = 6.5502e-02, time/batch = 0.0777s	
1689/4200 (epoch 20.107), train_loss = 1.42527662, grad/param norm = 6.5666e-02, time/batch = 0.0782s	
1690/4200 (epoch 20.119), train_loss = 1.42204085, grad/param norm = 7.5514e-02, time/batch = 0.0791s	
1691/4200 (epoch 20.131), train_loss = 1.43645656, grad/param norm = 8.4322e-02, time/batch = 0.0799s	
1692/4200 (epoch 20.143), train_loss = 1.44281100, grad/param norm = 8.6171e-02, time/batch = 0.0785s	
1693/4200 (epoch 20.155), train_loss = 1.41748713, grad/param norm = 8.4971e-02, time/batch = 0.0784s	
1694/4200 (epoch 20.167), train_loss = 1.44602574, grad/param norm = 1.0230e-01, time/batch = 0.0781s	
1695/4200 (epoch 20.179), train_loss = 1.45557335, grad/param norm = 1.0785e-01, time/batch = 0.0783s	
1696/4200 (epoch 20.190), train_loss = 1.43572349, grad/param norm = 1.1148e-01, time/batch = 0.0777s	
1697/4200 (epoch 20.202), train_loss = 1.46369395, grad/param norm = 1.0664e-01, time/batch = 0.0783s	
1698/4200 (epoch 20.214), train_loss = 1.44157795, grad/param norm = 8.7187e-02, time/batch = 0.0777s	
1699/4200 (epoch 20.226), train_loss = 1.44176595, grad/param norm = 7.4803e-02, time/batch = 0.0782s	
1700/4200 (epoch 20.238), train_loss = 1.43214563, grad/param norm = 7.1529e-02, time/batch = 0.0780s	
1701/4200 (epoch 20.250), train_loss = 1.41269018, grad/param norm = 6.7785e-02, time/batch = 0.0798s	
1702/4200 (epoch 20.262), train_loss = 1.38828061, grad/param norm = 6.0553e-02, time/batch = 0.0779s	
1703/4200 (epoch 20.274), train_loss = 1.44116012, grad/param norm = 6.2350e-02, time/batch = 0.0810s	
1704/4200 (epoch 20.286), train_loss = 1.43798058, grad/param norm = 5.8835e-02, time/batch = 0.0785s	
1705/4200 (epoch 20.298), train_loss = 1.41097739, grad/param norm = 6.2768e-02, time/batch = 0.0783s	
1706/4200 (epoch 20.310), train_loss = 1.45173869, grad/param norm = 7.3704e-02, time/batch = 0.0778s	
1707/4200 (epoch 20.321), train_loss = 1.39986115, grad/param norm = 6.9460e-02, time/batch = 0.0785s	
1708/4200 (epoch 20.333), train_loss = 1.43726725, grad/param norm = 6.3887e-02, time/batch = 0.0781s	
1709/4200 (epoch 20.345), train_loss = 1.42240364, grad/param norm = 6.0276e-02, time/batch = 0.0781s	
1710/4200 (epoch 20.357), train_loss = 1.42355733, grad/param norm = 6.5832e-02, time/batch = 0.0781s	
1711/4200 (epoch 20.369), train_loss = 1.44226552, grad/param norm = 6.9399e-02, time/batch = 0.0801s	
1712/4200 (epoch 20.381), train_loss = 1.43797581, grad/param norm = 7.2144e-02, time/batch = 0.0778s	
1713/4200 (epoch 20.393), train_loss = 1.45339584, grad/param norm = 7.3218e-02, time/batch = 0.0788s	
1714/4200 (epoch 20.405), train_loss = 1.44501833, grad/param norm = 6.9998e-02, time/batch = 0.0782s	
1715/4200 (epoch 20.417), train_loss = 1.41103549, grad/param norm = 7.4331e-02, time/batch = 0.0782s	
1716/4200 (epoch 20.429), train_loss = 1.42287687, grad/param norm = 7.3697e-02, time/batch = 0.0777s	
1717/4200 (epoch 20.440), train_loss = 1.43519310, grad/param norm = 6.8183e-02, time/batch = 0.0783s	
1718/4200 (epoch 20.452), train_loss = 1.44505313, grad/param norm = 6.4019e-02, time/batch = 0.0777s	
1719/4200 (epoch 20.464), train_loss = 1.43603911, grad/param norm = 7.1493e-02, time/batch = 0.0790s	
1720/4200 (epoch 20.476), train_loss = 1.45933661, grad/param norm = 8.3174e-02, time/batch = 0.0780s	
1721/4200 (epoch 20.488), train_loss = 1.45852607, grad/param norm = 8.1547e-02, time/batch = 0.0799s	
1722/4200 (epoch 20.500), train_loss = 1.42577805, grad/param norm = 6.9177e-02, time/batch = 0.0779s	
1723/4200 (epoch 20.512), train_loss = 1.43103775, grad/param norm = 6.2934e-02, time/batch = 0.0783s	
1724/4200 (epoch 20.524), train_loss = 1.39898497, grad/param norm = 6.2484e-02, time/batch = 0.0789s	
1725/4200 (epoch 20.536), train_loss = 1.42160644, grad/param norm = 7.0157e-02, time/batch = 0.0784s	
1726/4200 (epoch 20.548), train_loss = 1.41743739, grad/param norm = 8.1836e-02, time/batch = 0.0777s	
1727/4200 (epoch 20.560), train_loss = 1.44526170, grad/param norm = 8.9513e-02, time/batch = 0.0784s	
1728/4200 (epoch 20.571), train_loss = 1.40146488, grad/param norm = 9.0775e-02, time/batch = 0.0776s	
1729/4200 (epoch 20.583), train_loss = 1.43689649, grad/param norm = 8.4344e-02, time/batch = 0.0787s	
1730/4200 (epoch 20.595), train_loss = 1.43298293, grad/param norm = 8.9924e-02, time/batch = 0.0782s	
1731/4200 (epoch 20.607), train_loss = 1.41861766, grad/param norm = 9.4567e-02, time/batch = 0.0799s	
1732/4200 (epoch 20.619), train_loss = 1.41747994, grad/param norm = 9.0287e-02, time/batch = 0.0783s	
1733/4200 (epoch 20.631), train_loss = 1.41782560, grad/param norm = 9.1200e-02, time/batch = 0.0782s	
1734/4200 (epoch 20.643), train_loss = 1.42395699, grad/param norm = 9.9288e-02, time/batch = 0.0787s	
1735/4200 (epoch 20.655), train_loss = 1.42908419, grad/param norm = 9.3266e-02, time/batch = 0.0785s	
1736/4200 (epoch 20.667), train_loss = 1.44004615, grad/param norm = 9.3577e-02, time/batch = 0.0777s	
1737/4200 (epoch 20.679), train_loss = 1.43272444, grad/param norm = 8.6840e-02, time/batch = 0.0782s	
1738/4200 (epoch 20.690), train_loss = 1.41656888, grad/param norm = 7.5139e-02, time/batch = 0.0777s	
1739/4200 (epoch 20.702), train_loss = 1.41345566, grad/param norm = 7.0169e-02, time/batch = 0.0782s	
1740/4200 (epoch 20.714), train_loss = 1.43599247, grad/param norm = 7.1799e-02, time/batch = 0.0785s	
1741/4200 (epoch 20.726), train_loss = 1.43890657, grad/param norm = 7.2698e-02, time/batch = 0.0802s	
1742/4200 (epoch 20.738), train_loss = 1.43016211, grad/param norm = 7.5200e-02, time/batch = 0.0779s	
1743/4200 (epoch 20.750), train_loss = 1.43783061, grad/param norm = 7.3613e-02, time/batch = 0.0782s	
1744/4200 (epoch 20.762), train_loss = 1.43136505, grad/param norm = 7.9848e-02, time/batch = 0.0781s	
1745/4200 (epoch 20.774), train_loss = 1.44400597, grad/param norm = 8.3491e-02, time/batch = 0.0792s	
1746/4200 (epoch 20.786), train_loss = 1.42171016, grad/param norm = 7.7454e-02, time/batch = 0.0779s	
1747/4200 (epoch 20.798), train_loss = 1.43526299, grad/param norm = 6.8147e-02, time/batch = 0.0783s	
1748/4200 (epoch 20.810), train_loss = 1.43534945, grad/param norm = 6.9917e-02, time/batch = 0.0776s	
1749/4200 (epoch 20.821), train_loss = 1.42124188, grad/param norm = 8.5956e-02, time/batch = 0.0783s	
1750/4200 (epoch 20.833), train_loss = 1.44584004, grad/param norm = 9.9259e-02, time/batch = 0.0781s	
1751/4200 (epoch 20.845), train_loss = 1.45612205, grad/param norm = 9.3142e-02, time/batch = 0.0800s	
1752/4200 (epoch 20.857), train_loss = 1.45969040, grad/param norm = 9.2851e-02, time/batch = 0.0779s	
1753/4200 (epoch 20.869), train_loss = 1.46965589, grad/param norm = 8.3673e-02, time/batch = 0.0783s	
1754/4200 (epoch 20.881), train_loss = 1.43874569, grad/param norm = 8.4398e-02, time/batch = 0.0783s	
1755/4200 (epoch 20.893), train_loss = 1.45509808, grad/param norm = 8.1834e-02, time/batch = 0.0781s	
1756/4200 (epoch 20.905), train_loss = 1.43107410, grad/param norm = 7.5136e-02, time/batch = 0.0781s	
1757/4200 (epoch 20.917), train_loss = 1.45059680, grad/param norm = 7.2361e-02, time/batch = 0.0784s	
1758/4200 (epoch 20.929), train_loss = 1.43306544, grad/param norm = 6.3811e-02, time/batch = 0.0775s	
1759/4200 (epoch 20.940), train_loss = 1.44149344, grad/param norm = 6.6279e-02, time/batch = 0.0781s	
1760/4200 (epoch 20.952), train_loss = 1.44269472, grad/param norm = 7.6599e-02, time/batch = 0.0780s	
1761/4200 (epoch 20.964), train_loss = 1.45181127, grad/param norm = 8.6938e-02, time/batch = 0.0804s	
1762/4200 (epoch 20.976), train_loss = 1.44728143, grad/param norm = 8.3380e-02, time/batch = 0.0778s	
1763/4200 (epoch 20.988), train_loss = 1.43913757, grad/param norm = 7.2045e-02, time/batch = 0.0782s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
1764/4200 (epoch 21.000), train_loss = 1.47481245, grad/param norm = 6.6342e-02, time/batch = 0.0781s	
1765/4200 (epoch 21.012), train_loss = 1.59089478, grad/param norm = 8.2187e-02, time/batch = 0.0783s	
1766/4200 (epoch 21.024), train_loss = 1.41713851, grad/param norm = 7.4449e-02, time/batch = 0.0784s	
1767/4200 (epoch 21.036), train_loss = 1.42814271, grad/param norm = 6.4494e-02, time/batch = 0.0783s	
1768/4200 (epoch 21.048), train_loss = 1.39690971, grad/param norm = 5.5304e-02, time/batch = 0.0778s	
1769/4200 (epoch 21.060), train_loss = 1.42136536, grad/param norm = 6.0065e-02, time/batch = 0.0782s	
1770/4200 (epoch 21.071), train_loss = 1.41859257, grad/param norm = 6.8784e-02, time/batch = 0.0780s	
1771/4200 (epoch 21.083), train_loss = 1.41684654, grad/param norm = 7.5893e-02, time/batch = 0.0804s	
1772/4200 (epoch 21.095), train_loss = 1.39976547, grad/param norm = 6.6873e-02, time/batch = 0.0778s	
1773/4200 (epoch 21.107), train_loss = 1.41341717, grad/param norm = 6.5097e-02, time/batch = 0.0779s	
1774/4200 (epoch 21.119), train_loss = 1.40972720, grad/param norm = 7.0698e-02, time/batch = 0.0782s	
1775/4200 (epoch 21.131), train_loss = 1.42274979, grad/param norm = 7.6750e-02, time/batch = 0.0783s	
1776/4200 (epoch 21.143), train_loss = 1.42872420, grad/param norm = 7.6048e-02, time/batch = 0.0778s	
1777/4200 (epoch 21.155), train_loss = 1.40371032, grad/param norm = 7.2729e-02, time/batch = 0.0789s	
1778/4200 (epoch 21.167), train_loss = 1.43180689, grad/param norm = 8.9984e-02, time/batch = 0.0779s	
1779/4200 (epoch 21.179), train_loss = 1.44076570, grad/param norm = 9.4902e-02, time/batch = 0.0783s	
1780/4200 (epoch 21.190), train_loss = 1.42059869, grad/param norm = 9.7804e-02, time/batch = 0.0781s	
1781/4200 (epoch 21.202), train_loss = 1.45060149, grad/param norm = 9.6628e-02, time/batch = 0.0800s	
1782/4200 (epoch 21.214), train_loss = 1.42890240, grad/param norm = 8.1721e-02, time/batch = 0.0784s	
1783/4200 (epoch 21.226), train_loss = 1.42962976, grad/param norm = 6.8465e-02, time/batch = 0.0782s	
1784/4200 (epoch 21.238), train_loss = 1.41896603, grad/param norm = 6.1521e-02, time/batch = 0.0781s	
1785/4200 (epoch 21.250), train_loss = 1.39986125, grad/param norm = 5.8923e-02, time/batch = 0.0784s	
1786/4200 (epoch 21.262), train_loss = 1.37582098, grad/param norm = 6.0557e-02, time/batch = 0.0779s	
1787/4200 (epoch 21.274), train_loss = 1.42880676, grad/param norm = 6.5269e-02, time/batch = 0.0789s	
1788/4200 (epoch 21.286), train_loss = 1.42805138, grad/param norm = 6.5100e-02, time/batch = 0.0777s	
1789/4200 (epoch 21.298), train_loss = 1.40296495, grad/param norm = 7.5023e-02, time/batch = 0.0783s	
1790/4200 (epoch 21.310), train_loss = 1.44576770, grad/param norm = 9.0538e-02, time/batch = 0.0782s	
1791/4200 (epoch 21.321), train_loss = 1.39365083, grad/param norm = 8.2689e-02, time/batch = 0.0798s	
1792/4200 (epoch 21.333), train_loss = 1.42791010, grad/param norm = 7.1391e-02, time/batch = 0.0783s	
1793/4200 (epoch 21.345), train_loss = 1.41321877, grad/param norm = 7.2381e-02, time/batch = 0.0781s	
1794/4200 (epoch 21.357), train_loss = 1.41521640, grad/param norm = 7.7252e-02, time/batch = 0.0781s	
1795/4200 (epoch 21.369), train_loss = 1.43132343, grad/param norm = 8.1735e-02, time/batch = 0.0792s	
1796/4200 (epoch 21.381), train_loss = 1.42999152, grad/param norm = 8.3928e-02, time/batch = 0.0779s	
1797/4200 (epoch 21.393), train_loss = 1.44607945, grad/param norm = 8.9293e-02, time/batch = 0.0783s	
1798/4200 (epoch 21.405), train_loss = 1.44048679, grad/param norm = 8.9107e-02, time/batch = 0.0804s	
1799/4200 (epoch 21.417), train_loss = 1.40234663, grad/param norm = 8.4646e-02, time/batch = 0.0790s	
1800/4200 (epoch 21.429), train_loss = 1.41211149, grad/param norm = 7.2299e-02, time/batch = 0.0782s	
1801/4200 (epoch 21.440), train_loss = 1.42303847, grad/param norm = 6.6407e-02, time/batch = 0.0800s	
1802/4200 (epoch 21.452), train_loss = 1.43564686, grad/param norm = 7.4337e-02, time/batch = 0.0779s	
1803/4200 (epoch 21.464), train_loss = 1.42719030, grad/param norm = 7.6082e-02, time/batch = 0.0788s	
1804/4200 (epoch 21.476), train_loss = 1.44626432, grad/param norm = 7.9413e-02, time/batch = 0.0782s	
1805/4200 (epoch 21.488), train_loss = 1.44848333, grad/param norm = 9.4500e-02, time/batch = 0.0784s	
1806/4200 (epoch 21.500), train_loss = 1.41774709, grad/param norm = 8.8670e-02, time/batch = 0.0777s	
1807/4200 (epoch 21.512), train_loss = 1.42251102, grad/param norm = 7.2318e-02, time/batch = 0.0784s	
1808/4200 (epoch 21.524), train_loss = 1.38758139, grad/param norm = 6.4759e-02, time/batch = 0.0778s	
1809/4200 (epoch 21.536), train_loss = 1.40935794, grad/param norm = 6.2254e-02, time/batch = 0.0805s	
1810/4200 (epoch 21.548), train_loss = 1.40273220, grad/param norm = 6.0175e-02, time/batch = 0.0784s	
1811/4200 (epoch 21.560), train_loss = 1.42809808, grad/param norm = 6.5042e-02, time/batch = 0.0800s	
1812/4200 (epoch 21.571), train_loss = 1.38238942, grad/param norm = 6.2143e-02, time/batch = 0.0779s	
1813/4200 (epoch 21.583), train_loss = 1.41690795, grad/param norm = 5.3853e-02, time/batch = 0.0783s	
1814/4200 (epoch 21.595), train_loss = 1.41522483, grad/param norm = 6.1704e-02, time/batch = 0.0782s	
1815/4200 (epoch 21.607), train_loss = 1.40135521, grad/param norm = 7.7084e-02, time/batch = 0.0784s	
1816/4200 (epoch 21.619), train_loss = 1.40359711, grad/param norm = 7.5890e-02, time/batch = 0.0779s	
1817/4200 (epoch 21.631), train_loss = 1.40022035, grad/param norm = 6.6066e-02, time/batch = 0.0784s	
1818/4200 (epoch 21.643), train_loss = 1.40529452, grad/param norm = 6.2489e-02, time/batch = 0.0777s	
1819/4200 (epoch 21.655), train_loss = 1.41135191, grad/param norm = 6.4632e-02, time/batch = 0.0788s	
1820/4200 (epoch 21.667), train_loss = 1.42431292, grad/param norm = 7.1046e-02, time/batch = 0.0783s	
1821/4200 (epoch 21.679), train_loss = 1.41570588, grad/param norm = 6.7207e-02, time/batch = 0.0799s	
1822/4200 (epoch 21.690), train_loss = 1.40291371, grad/param norm = 6.2342e-02, time/batch = 0.0779s	
1823/4200 (epoch 21.702), train_loss = 1.40161540, grad/param norm = 6.6225e-02, time/batch = 0.0782s	
1824/4200 (epoch 21.714), train_loss = 1.42476324, grad/param norm = 6.7950e-02, time/batch = 0.0787s	
1825/4200 (epoch 21.726), train_loss = 1.42695666, grad/param norm = 7.1228e-02, time/batch = 0.0783s	
1826/4200 (epoch 21.738), train_loss = 1.42058183, grad/param norm = 7.8275e-02, time/batch = 0.0779s	
1827/4200 (epoch 21.750), train_loss = 1.42759327, grad/param norm = 8.2925e-02, time/batch = 0.0784s	
1828/4200 (epoch 21.762), train_loss = 1.42274608, grad/param norm = 8.3129e-02, time/batch = 0.0775s	
1829/4200 (epoch 21.774), train_loss = 1.43182425, grad/param norm = 8.8363e-02, time/batch = 0.0782s	
1830/4200 (epoch 21.786), train_loss = 1.41656257, grad/param norm = 1.0230e-01, time/batch = 0.0786s	
1831/4200 (epoch 21.798), train_loss = 1.43333201, grad/param norm = 9.8242e-02, time/batch = 0.0799s	
1832/4200 (epoch 21.810), train_loss = 1.43102971, grad/param norm = 8.4939e-02, time/batch = 0.0777s	
1833/4200 (epoch 21.821), train_loss = 1.41271662, grad/param norm = 8.5663e-02, time/batch = 0.0781s	
1834/4200 (epoch 21.833), train_loss = 1.43225447, grad/param norm = 8.5619e-02, time/batch = 0.0782s	
1835/4200 (epoch 21.845), train_loss = 1.44210652, grad/param norm = 8.0648e-02, time/batch = 0.0788s	
1836/4200 (epoch 21.857), train_loss = 1.44476034, grad/param norm = 7.3523e-02, time/batch = 0.0778s	
1837/4200 (epoch 21.869), train_loss = 1.45356144, grad/param norm = 6.5805e-02, time/batch = 0.0784s	
1838/4200 (epoch 21.881), train_loss = 1.42566415, grad/param norm = 6.5667e-02, time/batch = 0.0779s	
1839/4200 (epoch 21.893), train_loss = 1.44098505, grad/param norm = 6.9726e-02, time/batch = 0.0783s	
1840/4200 (epoch 21.905), train_loss = 1.42097286, grad/param norm = 7.0796e-02, time/batch = 0.0784s	
1841/4200 (epoch 21.917), train_loss = 1.43776476, grad/param norm = 6.9368e-02, time/batch = 0.0801s	
1842/4200 (epoch 21.929), train_loss = 1.42334631, grad/param norm = 6.7708e-02, time/batch = 0.0779s	
1843/4200 (epoch 21.940), train_loss = 1.43291309, grad/param norm = 7.4391e-02, time/batch = 0.0782s	
1844/4200 (epoch 21.952), train_loss = 1.43320233, grad/param norm = 7.5549e-02, time/batch = 0.0781s	
1845/4200 (epoch 21.964), train_loss = 1.44040182, grad/param norm = 7.3504e-02, time/batch = 0.0787s	
1846/4200 (epoch 21.976), train_loss = 1.43712522, grad/param norm = 8.7647e-02, time/batch = 0.0777s	
1847/4200 (epoch 21.988), train_loss = 1.43094287, grad/param norm = 8.4909e-02, time/batch = 0.0782s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
1848/4200 (epoch 22.000), train_loss = 1.46591592, grad/param norm = 7.5670e-02, time/batch = 0.0778s	
1849/4200 (epoch 22.012), train_loss = 1.58054345, grad/param norm = 8.4643e-02, time/batch = 0.0783s	
1850/4200 (epoch 22.024), train_loss = 1.40654117, grad/param norm = 7.1896e-02, time/batch = 0.0779s	
1851/4200 (epoch 22.036), train_loss = 1.41740535, grad/param norm = 6.4637e-02, time/batch = 0.0802s	
1852/4200 (epoch 22.048), train_loss = 1.38767425, grad/param norm = 5.9081e-02, time/batch = 0.0778s	
1853/4200 (epoch 22.060), train_loss = 1.41266512, grad/param norm = 6.9619e-02, time/batch = 0.0780s	
1854/4200 (epoch 22.071), train_loss = 1.41100657, grad/param norm = 7.7711e-02, time/batch = 0.0781s	
1855/4200 (epoch 22.083), train_loss = 1.40776342, grad/param norm = 8.2189e-02, time/batch = 0.0784s	
1856/4200 (epoch 22.095), train_loss = 1.39046174, grad/param norm = 6.4038e-02, time/batch = 0.0783s	
1857/4200 (epoch 22.107), train_loss = 1.40268769, grad/param norm = 5.7476e-02, time/batch = 0.0782s	
1858/4200 (epoch 22.119), train_loss = 1.39870389, grad/param norm = 5.9622e-02, time/batch = 0.0777s	
1859/4200 (epoch 22.131), train_loss = 1.40959644, grad/param norm = 6.2517e-02, time/batch = 0.0786s	
1860/4200 (epoch 22.143), train_loss = 1.41591797, grad/param norm = 6.6529e-02, time/batch = 0.0783s	
1861/4200 (epoch 22.155), train_loss = 1.39176300, grad/param norm = 6.9694e-02, time/batch = 0.0804s	
1862/4200 (epoch 22.167), train_loss = 1.42049516, grad/param norm = 8.2395e-02, time/batch = 0.0780s	
1863/4200 (epoch 22.179), train_loss = 1.42715086, grad/param norm = 8.6905e-02, time/batch = 0.0780s	
1864/4200 (epoch 22.190), train_loss = 1.40548009, grad/param norm = 7.8166e-02, time/batch = 0.0782s	
1865/4200 (epoch 22.202), train_loss = 1.43451591, grad/param norm = 7.6125e-02, time/batch = 0.0783s	
1866/4200 (epoch 22.214), train_loss = 1.41788954, grad/param norm = 7.6761e-02, time/batch = 0.0778s	
1867/4200 (epoch 22.226), train_loss = 1.42153226, grad/param norm = 7.6314e-02, time/batch = 0.0783s	
1868/4200 (epoch 22.238), train_loss = 1.41167218, grad/param norm = 7.5974e-02, time/batch = 0.0776s	
1869/4200 (epoch 22.250), train_loss = 1.39448559, grad/param norm = 8.1552e-02, time/batch = 0.0783s	
1870/4200 (epoch 22.262), train_loss = 1.36990739, grad/param norm = 7.7581e-02, time/batch = 0.0781s	
1871/4200 (epoch 22.274), train_loss = 1.41896462, grad/param norm = 7.1083e-02, time/batch = 0.0800s	
1872/4200 (epoch 22.286), train_loss = 1.41762264, grad/param norm = 6.4862e-02, time/batch = 0.0780s	
1873/4200 (epoch 22.298), train_loss = 1.39188225, grad/param norm = 7.4182e-02, time/batch = 0.0783s	
1874/4200 (epoch 22.310), train_loss = 1.43402581, grad/param norm = 8.5105e-02, time/batch = 0.0782s	
1875/4200 (epoch 22.321), train_loss = 1.38108833, grad/param norm = 7.6562e-02, time/batch = 0.0784s	
1876/4200 (epoch 22.333), train_loss = 1.41641755, grad/param norm = 6.6203e-02, time/batch = 0.0777s	
1877/4200 (epoch 22.345), train_loss = 1.40093895, grad/param norm = 6.7661e-02, time/batch = 0.0787s	
1878/4200 (epoch 22.357), train_loss = 1.40430340, grad/param norm = 7.1826e-02, time/batch = 0.0777s	
1879/4200 (epoch 22.369), train_loss = 1.41943462, grad/param norm = 7.5659e-02, time/batch = 0.0783s	
1880/4200 (epoch 22.381), train_loss = 1.41964828, grad/param norm = 8.0322e-02, time/batch = 0.0782s	
1881/4200 (epoch 22.393), train_loss = 1.43488122, grad/param norm = 8.7412e-02, time/batch = 0.0798s	
1882/4200 (epoch 22.405), train_loss = 1.42965617, grad/param norm = 8.5398e-02, time/batch = 0.0783s	
1883/4200 (epoch 22.417), train_loss = 1.39091440, grad/param norm = 8.0990e-02, time/batch = 0.0782s	
1884/4200 (epoch 22.429), train_loss = 1.40141220, grad/param norm = 7.0894e-02, time/batch = 0.0782s	
1885/4200 (epoch 22.440), train_loss = 1.41139889, grad/param norm = 6.3090e-02, time/batch = 0.0783s	
1886/4200 (epoch 22.452), train_loss = 1.42217940, grad/param norm = 6.3486e-02, time/batch = 0.0776s	
1887/4200 (epoch 22.464), train_loss = 1.41476315, grad/param norm = 6.3886e-02, time/batch = 0.0781s	
1888/4200 (epoch 22.476), train_loss = 1.43307508, grad/param norm = 7.0316e-02, time/batch = 0.0783s	
1889/4200 (epoch 22.488), train_loss = 1.43448997, grad/param norm = 8.3625e-02, time/batch = 0.0781s	
1890/4200 (epoch 22.500), train_loss = 1.40423784, grad/param norm = 7.7801e-02, time/batch = 0.0780s	
1891/4200 (epoch 22.512), train_loss = 1.41059226, grad/param norm = 6.6085e-02, time/batch = 0.0799s	
1892/4200 (epoch 22.524), train_loss = 1.37724718, grad/param norm = 6.2744e-02, time/batch = 0.0779s	
1893/4200 (epoch 22.536), train_loss = 1.39873183, grad/param norm = 6.1665e-02, time/batch = 0.0785s	
1894/4200 (epoch 22.548), train_loss = 1.39299069, grad/param norm = 6.0007e-02, time/batch = 0.0783s	
1895/4200 (epoch 22.560), train_loss = 1.41803896, grad/param norm = 6.3520e-02, time/batch = 0.0783s	
1896/4200 (epoch 22.571), train_loss = 1.37206727, grad/param norm = 5.8509e-02, time/batch = 0.0780s	
1897/4200 (epoch 22.583), train_loss = 1.40595611, grad/param norm = 5.0606e-02, time/batch = 0.0782s	
1898/4200 (epoch 22.595), train_loss = 1.40369793, grad/param norm = 5.6092e-02, time/batch = 0.0780s	
1899/4200 (epoch 22.607), train_loss = 1.38869801, grad/param norm = 6.7516e-02, time/batch = 0.0784s	
1900/4200 (epoch 22.619), train_loss = 1.39140161, grad/param norm = 6.6473e-02, time/batch = 0.0780s	
1901/4200 (epoch 22.631), train_loss = 1.38834997, grad/param norm = 5.9513e-02, time/batch = 0.0807s	
1902/4200 (epoch 22.643), train_loss = 1.39524441, grad/param norm = 6.4152e-02, time/batch = 0.0781s	
1903/4200 (epoch 22.655), train_loss = 1.40302066, grad/param norm = 6.7875e-02, time/batch = 0.0786s	
1904/4200 (epoch 22.667), train_loss = 1.41482930, grad/param norm = 7.2621e-02, time/batch = 0.0787s	
1905/4200 (epoch 22.679), train_loss = 1.40654050, grad/param norm = 6.5894e-02, time/batch = 0.0783s	
1906/4200 (epoch 22.690), train_loss = 1.39220707, grad/param norm = 6.3627e-02, time/batch = 0.0777s	
1907/4200 (epoch 22.702), train_loss = 1.39192942, grad/param norm = 7.4188e-02, time/batch = 0.0784s	
1908/4200 (epoch 22.714), train_loss = 1.41800678, grad/param norm = 8.6515e-02, time/batch = 0.0777s	
1909/4200 (epoch 22.726), train_loss = 1.42229851, grad/param norm = 9.0692e-02, time/batch = 0.0788s	
1910/4200 (epoch 22.738), train_loss = 1.41504552, grad/param norm = 9.8530e-02, time/batch = 0.0782s	
1911/4200 (epoch 22.750), train_loss = 1.42570479, grad/param norm = 1.0342e-01, time/batch = 0.0800s	
1912/4200 (epoch 22.762), train_loss = 1.41780019, grad/param norm = 9.8296e-02, time/batch = 0.0779s	
1913/4200 (epoch 22.774), train_loss = 1.42574361, grad/param norm = 8.8834e-02, time/batch = 0.0780s	
1914/4200 (epoch 22.786), train_loss = 1.40074744, grad/param norm = 7.4091e-02, time/batch = 0.0819s	
1915/4200 (epoch 22.798), train_loss = 1.41240245, grad/param norm = 6.1561e-02, time/batch = 0.0807s	
1916/4200 (epoch 22.810), train_loss = 1.41388818, grad/param norm = 6.1210e-02, time/batch = 0.0782s	
1917/4200 (epoch 22.821), train_loss = 1.40055632, grad/param norm = 7.6362e-02, time/batch = 0.0784s	
1918/4200 (epoch 22.833), train_loss = 1.42202533, grad/param norm = 9.1566e-02, time/batch = 0.0778s	
1919/4200 (epoch 22.845), train_loss = 1.43441493, grad/param norm = 8.9951e-02, time/batch = 0.0789s	
1920/4200 (epoch 22.857), train_loss = 1.43750834, grad/param norm = 8.7536e-02, time/batch = 0.0782s	
1921/4200 (epoch 22.869), train_loss = 1.44549315, grad/param norm = 7.6043e-02, time/batch = 0.0799s	
1922/4200 (epoch 22.881), train_loss = 1.41727607, grad/param norm = 7.9356e-02, time/batch = 0.0782s	
1923/4200 (epoch 22.893), train_loss = 1.43219756, grad/param norm = 7.9450e-02, time/batch = 0.0780s	
1924/4200 (epoch 22.905), train_loss = 1.41091738, grad/param norm = 7.4743e-02, time/batch = 0.0787s	
1925/4200 (epoch 22.917), train_loss = 1.42923564, grad/param norm = 7.1906e-02, time/batch = 0.0785s	
1926/4200 (epoch 22.929), train_loss = 1.41231159, grad/param norm = 6.6555e-02, time/batch = 0.0779s	
1927/4200 (epoch 22.940), train_loss = 1.42176972, grad/param norm = 6.8253e-02, time/batch = 0.0784s	
1928/4200 (epoch 22.952), train_loss = 1.42188156, grad/param norm = 7.5386e-02, time/batch = 0.0777s	
1929/4200 (epoch 22.964), train_loss = 1.42990795, grad/param norm = 8.4226e-02, time/batch = 0.0783s	
1930/4200 (epoch 22.976), train_loss = 1.42585094, grad/param norm = 8.3522e-02, time/batch = 0.0786s	
1931/4200 (epoch 22.988), train_loss = 1.41762762, grad/param norm = 7.0242e-02, time/batch = 0.0800s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
1932/4200 (epoch 23.000), train_loss = 1.45362064, grad/param norm = 6.3012e-02, time/batch = 0.0779s	
1933/4200 (epoch 23.012), train_loss = 1.57336272, grad/param norm = 7.9537e-02, time/batch = 0.0782s	
1934/4200 (epoch 23.024), train_loss = 1.39705719, grad/param norm = 7.0965e-02, time/batch = 0.0782s	
1935/4200 (epoch 23.036), train_loss = 1.40709077, grad/param norm = 6.1883e-02, time/batch = 0.0787s	
1936/4200 (epoch 23.048), train_loss = 1.37716418, grad/param norm = 5.4188e-02, time/batch = 0.0779s	
1937/4200 (epoch 23.060), train_loss = 1.40108577, grad/param norm = 5.9321e-02, time/batch = 0.0783s	
1938/4200 (epoch 23.071), train_loss = 1.39944078, grad/param norm = 6.7746e-02, time/batch = 0.0777s	
1939/4200 (epoch 23.083), train_loss = 1.39576537, grad/param norm = 7.1387e-02, time/batch = 0.0783s	
1940/4200 (epoch 23.095), train_loss = 1.38064051, grad/param norm = 5.9360e-02, time/batch = 0.0780s	
1941/4200 (epoch 23.107), train_loss = 1.39314597, grad/param norm = 6.0049e-02, time/batch = 0.0799s	
1942/4200 (epoch 23.119), train_loss = 1.38979879, grad/param norm = 6.3073e-02, time/batch = 0.0779s	
1943/4200 (epoch 23.131), train_loss = 1.40109781, grad/param norm = 6.5044e-02, time/batch = 0.0783s	
1944/4200 (epoch 23.143), train_loss = 1.40505921, grad/param norm = 6.2483e-02, time/batch = 0.0781s	
1945/4200 (epoch 23.155), train_loss = 1.38037543, grad/param norm = 5.6209e-02, time/batch = 0.0783s	
1946/4200 (epoch 23.167), train_loss = 1.40702334, grad/param norm = 7.0108e-02, time/batch = 0.0783s	
1947/4200 (epoch 23.179), train_loss = 1.41529771, grad/param norm = 7.6605e-02, time/batch = 0.0784s	
1948/4200 (epoch 23.190), train_loss = 1.39707908, grad/param norm = 8.6072e-02, time/batch = 0.0777s	
1949/4200 (epoch 23.202), train_loss = 1.43041604, grad/param norm = 9.4174e-02, time/batch = 0.0784s	
1950/4200 (epoch 23.214), train_loss = 1.40927889, grad/param norm = 8.4359e-02, time/batch = 0.0780s	
1951/4200 (epoch 23.226), train_loss = 1.41124514, grad/param norm = 7.0707e-02, time/batch = 0.0805s	
1952/4200 (epoch 23.238), train_loss = 1.39980428, grad/param norm = 6.5109e-02, time/batch = 0.0780s	
1953/4200 (epoch 23.250), train_loss = 1.38163184, grad/param norm = 6.1491e-02, time/batch = 0.0785s	
1954/4200 (epoch 23.262), train_loss = 1.35541820, grad/param norm = 6.0005e-02, time/batch = 0.0784s	
1955/4200 (epoch 23.274), train_loss = 1.40704235, grad/param norm = 6.2887e-02, time/batch = 0.0783s	
1956/4200 (epoch 23.286), train_loss = 1.40737153, grad/param norm = 5.9261e-02, time/batch = 0.0783s	
1957/4200 (epoch 23.298), train_loss = 1.38070708, grad/param norm = 6.5428e-02, time/batch = 0.0789s	
1958/4200 (epoch 23.310), train_loss = 1.42134580, grad/param norm = 7.2721e-02, time/batch = 0.0777s	
1959/4200 (epoch 23.321), train_loss = 1.36806874, grad/param norm = 6.1553e-02, time/batch = 0.0783s	
1960/4200 (epoch 23.333), train_loss = 1.40303336, grad/param norm = 5.3864e-02, time/batch = 0.0782s	
1961/4200 (epoch 23.345), train_loss = 1.38853336, grad/param norm = 5.2074e-02, time/batch = 0.0802s	
1962/4200 (epoch 23.357), train_loss = 1.39250202, grad/param norm = 5.9197e-02, time/batch = 0.0779s	
1963/4200 (epoch 23.369), train_loss = 1.40814019, grad/param norm = 6.4664e-02, time/batch = 0.0782s	
1964/4200 (epoch 23.381), train_loss = 1.40545458, grad/param norm = 6.6306e-02, time/batch = 0.0785s	
1965/4200 (epoch 23.393), train_loss = 1.42187692, grad/param norm = 6.6237e-02, time/batch = 0.0782s	
1966/4200 (epoch 23.405), train_loss = 1.41543955, grad/param norm = 7.0585e-02, time/batch = 0.0778s	
1967/4200 (epoch 23.417), train_loss = 1.37920066, grad/param norm = 7.1662e-02, time/batch = 0.0789s	
1968/4200 (epoch 23.429), train_loss = 1.39169728, grad/param norm = 7.1213e-02, time/batch = 0.0778s	
1969/4200 (epoch 23.440), train_loss = 1.40576376, grad/param norm = 7.8495e-02, time/batch = 0.0782s	
1970/4200 (epoch 23.452), train_loss = 1.41680336, grad/param norm = 8.2706e-02, time/batch = 0.0781s	
1971/4200 (epoch 23.464), train_loss = 1.41032036, grad/param norm = 8.4112e-02, time/batch = 0.0799s	
1972/4200 (epoch 23.476), train_loss = 1.42671914, grad/param norm = 8.3757e-02, time/batch = 0.0784s	
1973/4200 (epoch 23.488), train_loss = 1.42459253, grad/param norm = 7.6319e-02, time/batch = 0.0779s	
1974/4200 (epoch 23.500), train_loss = 1.39348747, grad/param norm = 7.6288e-02, time/batch = 0.0782s	
1975/4200 (epoch 23.512), train_loss = 1.40250725, grad/param norm = 7.4687e-02, time/batch = 0.0782s	
1976/4200 (epoch 23.524), train_loss = 1.37190570, grad/param norm = 8.4145e-02, time/batch = 0.0776s	
1977/4200 (epoch 23.536), train_loss = 1.39634215, grad/param norm = 8.8820e-02, time/batch = 0.0788s	
1978/4200 (epoch 23.548), train_loss = 1.39058333, grad/param norm = 8.6330e-02, time/batch = 0.0779s	
1979/4200 (epoch 23.560), train_loss = 1.41358184, grad/param norm = 7.6477e-02, time/batch = 0.0783s	
1980/4200 (epoch 23.571), train_loss = 1.36560031, grad/param norm = 6.7078e-02, time/batch = 0.0781s	
1981/4200 (epoch 23.583), train_loss = 1.39894114, grad/param norm = 6.2570e-02, time/batch = 0.0800s	
1982/4200 (epoch 23.595), train_loss = 1.39588079, grad/param norm = 6.2206e-02, time/batch = 0.0782s	
1983/4200 (epoch 23.607), train_loss = 1.37901946, grad/param norm = 6.8974e-02, time/batch = 0.0781s	
1984/4200 (epoch 23.619), train_loss = 1.38117905, grad/param norm = 6.2562e-02, time/batch = 0.0781s	
1985/4200 (epoch 23.631), train_loss = 1.37771364, grad/param norm = 5.4787e-02, time/batch = 0.0785s	
1986/4200 (epoch 23.643), train_loss = 1.38432055, grad/param norm = 5.9967e-02, time/batch = 0.0779s	
1987/4200 (epoch 23.655), train_loss = 1.39179139, grad/param norm = 6.1664e-02, time/batch = 0.0783s	
1988/4200 (epoch 23.667), train_loss = 1.40385627, grad/param norm = 6.6320e-02, time/batch = 0.0784s	
1989/4200 (epoch 23.679), train_loss = 1.39792062, grad/param norm = 6.7125e-02, time/batch = 0.0783s	
1990/4200 (epoch 23.690), train_loss = 1.38443868, grad/param norm = 7.0281e-02, time/batch = 0.0780s	
1991/4200 (epoch 23.702), train_loss = 1.38380090, grad/param norm = 7.9209e-02, time/batch = 0.0799s	
1992/4200 (epoch 23.714), train_loss = 1.40820588, grad/param norm = 7.8756e-02, time/batch = 0.0779s	
1993/4200 (epoch 23.726), train_loss = 1.40792035, grad/param norm = 6.5994e-02, time/batch = 0.0786s	
1994/4200 (epoch 23.738), train_loss = 1.39610502, grad/param norm = 6.0427e-02, time/batch = 0.0782s	
1995/4200 (epoch 23.750), train_loss = 1.40762654, grad/param norm = 6.4196e-02, time/batch = 0.0783s	
1996/4200 (epoch 23.762), train_loss = 1.40299283, grad/param norm = 7.7797e-02, time/batch = 0.0778s	
1997/4200 (epoch 23.774), train_loss = 1.41439612, grad/param norm = 8.2300e-02, time/batch = 0.0781s	
1998/4200 (epoch 23.786), train_loss = 1.39145251, grad/param norm = 7.3051e-02, time/batch = 0.0777s	
1999/4200 (epoch 23.798), train_loss = 1.40309908, grad/param norm = 5.8983e-02, time/batch = 0.0783s	
evaluating loss over split index 2	
1/5...	
2/5...	
3/5...	
4/5...	
5/5...	
saving checkpoint to cv/lm_lstm_epoch23.81_1.4711.t7	
2000/4200 (epoch 23.810), train_loss = 1.40414372, grad/param norm = 5.5336e-02, time/batch = 0.0783s	
2001/4200 (epoch 23.821), train_loss = 1.56297782, grad/param norm = 6.6488e-02, time/batch = 0.1242s	
2002/4200 (epoch 23.833), train_loss = 1.40897409, grad/param norm = 6.6425e-02, time/batch = 0.1192s	
2003/4200 (epoch 23.845), train_loss = 1.42122632, grad/param norm = 6.9090e-02, time/batch = 0.1283s	
2004/4200 (epoch 23.857), train_loss = 1.42793344, grad/param norm = 8.2177e-02, time/batch = 0.1334s	
2005/4200 (epoch 23.869), train_loss = 1.43842185, grad/param norm = 7.9986e-02, time/batch = 0.1348s	
2006/4200 (epoch 23.881), train_loss = 1.40830358, grad/param norm = 7.3360e-02, time/batch = 0.1338s	
2007/4200 (epoch 23.893), train_loss = 1.42130072, grad/param norm = 6.5907e-02, time/batch = 0.1033s	
2008/4200 (epoch 23.905), train_loss = 1.39894194, grad/param norm = 5.7962e-02, time/batch = 0.0948s	
2009/4200 (epoch 23.917), train_loss = 1.41606910, grad/param norm = 5.9431e-02, time/batch = 0.0952s	
2010/4200 (epoch 23.929), train_loss = 1.40211159, grad/param norm = 6.1409e-02, time/batch = 0.0948s	
2011/4200 (epoch 23.940), train_loss = 1.41031689, grad/param norm = 6.5070e-02, time/batch = 0.0967s	
2012/4200 (epoch 23.952), train_loss = 1.41471676, grad/param norm = 7.6171e-02, time/batch = 0.1008s	
2013/4200 (epoch 23.964), train_loss = 1.42263945, grad/param norm = 8.9843e-02, time/batch = 0.0941s	
2014/4200 (epoch 23.976), train_loss = 1.41767878, grad/param norm = 8.2296e-02, time/batch = 0.0939s	
2015/4200 (epoch 23.988), train_loss = 1.40847267, grad/param norm = 7.0602e-02, time/batch = 0.0942s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
2016/4200 (epoch 24.000), train_loss = 1.44642162, grad/param norm = 6.9705e-02, time/batch = 0.0919s	
2017/4200 (epoch 24.012), train_loss = 1.56638412, grad/param norm = 8.3014e-02, time/batch = 0.0794s	
2018/4200 (epoch 24.024), train_loss = 1.38747386, grad/param norm = 6.8132e-02, time/batch = 0.0777s	
2019/4200 (epoch 24.036), train_loss = 1.39915468, grad/param norm = 6.5554e-02, time/batch = 0.0785s	
2020/4200 (epoch 24.048), train_loss = 1.37282040, grad/param norm = 7.0394e-02, time/batch = 0.0782s	
2021/4200 (epoch 24.060), train_loss = 1.39730910, grad/param norm = 7.9010e-02, time/batch = 0.0804s	
2022/4200 (epoch 24.071), train_loss = 1.39204043, grad/param norm = 7.1401e-02, time/batch = 0.0777s	
2023/4200 (epoch 24.083), train_loss = 1.38551683, grad/param norm = 6.4961e-02, time/batch = 0.0781s	
2024/4200 (epoch 24.095), train_loss = 1.37216175, grad/param norm = 5.4786e-02, time/batch = 0.0781s	
2025/4200 (epoch 24.107), train_loss = 1.38493846, grad/param norm = 6.2580e-02, time/batch = 0.0783s	
2026/4200 (epoch 24.119), train_loss = 1.38179905, grad/param norm = 6.3535e-02, time/batch = 0.0777s	
2027/4200 (epoch 24.131), train_loss = 1.39150463, grad/param norm = 6.0920e-02, time/batch = 0.0787s	
2028/4200 (epoch 24.143), train_loss = 1.39600667, grad/param norm = 6.3044e-02, time/batch = 0.0775s	
2029/4200 (epoch 24.155), train_loss = 1.37286521, grad/param norm = 6.6056e-02, time/batch = 0.0782s	
2030/4200 (epoch 24.167), train_loss = 1.40009923, grad/param norm = 7.5805e-02, time/batch = 0.0781s	
2031/4200 (epoch 24.179), train_loss = 1.40640239, grad/param norm = 7.6538e-02, time/batch = 0.0798s	
2032/4200 (epoch 24.190), train_loss = 1.38527730, grad/param norm = 7.0343e-02, time/batch = 0.0783s	
2033/4200 (epoch 24.202), train_loss = 1.41468828, grad/param norm = 6.9061e-02, time/batch = 0.0781s	
2034/4200 (epoch 24.214), train_loss = 1.39627708, grad/param norm = 6.6012e-02, time/batch = 0.0781s	
2035/4200 (epoch 24.226), train_loss = 1.40080191, grad/param norm = 6.2185e-02, time/batch = 0.0783s	
2036/4200 (epoch 24.238), train_loss = 1.39068314, grad/param norm = 6.1620e-02, time/batch = 0.0776s	
2037/4200 (epoch 24.250), train_loss = 1.37403457, grad/param norm = 6.6038e-02, time/batch = 0.0783s	
2038/4200 (epoch 24.262), train_loss = 1.34833475, grad/param norm = 6.3505e-02, time/batch = 0.0777s	
2039/4200 (epoch 24.274), train_loss = 1.39710884, grad/param norm = 6.0619e-02, time/batch = 0.0781s	
2040/4200 (epoch 24.286), train_loss = 1.39775284, grad/param norm = 5.5778e-02, time/batch = 0.0780s	
2041/4200 (epoch 24.298), train_loss = 1.37204058, grad/param norm = 6.7786e-02, time/batch = 0.0798s	
2042/4200 (epoch 24.310), train_loss = 1.41442619, grad/param norm = 8.0054e-02, time/batch = 0.0778s	
2043/4200 (epoch 24.321), train_loss = 1.36284209, grad/param norm = 7.5514e-02, time/batch = 0.0781s	
2044/4200 (epoch 24.333), train_loss = 1.39896855, grad/param norm = 7.3727e-02, time/batch = 0.0782s	
2045/4200 (epoch 24.345), train_loss = 1.38525797, grad/param norm = 8.0933e-02, time/batch = 0.0782s	
2046/4200 (epoch 24.357), train_loss = 1.39007611, grad/param norm = 8.4827e-02, time/batch = 0.0778s	
2047/4200 (epoch 24.369), train_loss = 1.40331470, grad/param norm = 8.5145e-02, time/batch = 0.0781s	
2048/4200 (epoch 24.381), train_loss = 1.40199332, grad/param norm = 8.2436e-02, time/batch = 0.0780s	
2049/4200 (epoch 24.393), train_loss = 1.41659889, grad/param norm = 8.4718e-02, time/batch = 0.0782s	
2050/4200 (epoch 24.405), train_loss = 1.41070219, grad/param norm = 7.7957e-02, time/batch = 0.0779s	
2051/4200 (epoch 24.417), train_loss = 1.36984666, grad/param norm = 7.2170e-02, time/batch = 0.0799s	
2052/4200 (epoch 24.429), train_loss = 1.38029057, grad/param norm = 6.0839e-02, time/batch = 0.0778s	
2053/4200 (epoch 24.440), train_loss = 1.39119428, grad/param norm = 5.1797e-02, time/batch = 0.0784s	
2054/4200 (epoch 24.452), train_loss = 1.40117364, grad/param norm = 5.3747e-02, time/batch = 0.0785s	
2055/4200 (epoch 24.464), train_loss = 1.39562118, grad/param norm = 5.7854e-02, time/batch = 0.0783s	
2056/4200 (epoch 24.476), train_loss = 1.41261228, grad/param norm = 6.1153e-02, time/batch = 0.0776s	
2057/4200 (epoch 24.488), train_loss = 1.41288393, grad/param norm = 6.9817e-02, time/batch = 0.0783s	
2058/4200 (epoch 24.500), train_loss = 1.38405368, grad/param norm = 6.8438e-02, time/batch = 0.0776s	
2059/4200 (epoch 24.512), train_loss = 1.39035241, grad/param norm = 6.0430e-02, time/batch = 0.0787s	
2060/4200 (epoch 24.524), train_loss = 1.35993104, grad/param norm = 6.1214e-02, time/batch = 0.0780s	
2061/4200 (epoch 24.536), train_loss = 1.38181379, grad/param norm = 6.7928e-02, time/batch = 0.0799s	
2062/4200 (epoch 24.548), train_loss = 1.37828143, grad/param norm = 7.2025e-02, time/batch = 0.0780s	
2063/4200 (epoch 24.560), train_loss = 1.40400028, grad/param norm = 7.1273e-02, time/batch = 0.0780s	
2064/4200 (epoch 24.571), train_loss = 1.35677455, grad/param norm = 6.1272e-02, time/batch = 0.0784s	
2065/4200 (epoch 24.583), train_loss = 1.38824323, grad/param norm = 5.0319e-02, time/batch = 0.0783s	
2066/4200 (epoch 24.595), train_loss = 1.38634343, grad/param norm = 5.7262e-02, time/batch = 0.0776s	
2067/4200 (epoch 24.607), train_loss = 1.37082211, grad/param norm = 6.8923e-02, time/batch = 0.0783s	
2068/4200 (epoch 24.619), train_loss = 1.37396049, grad/param norm = 6.7400e-02, time/batch = 0.0775s	
2069/4200 (epoch 24.631), train_loss = 1.36983351, grad/param norm = 6.1172e-02, time/batch = 0.0786s	
2070/4200 (epoch 24.643), train_loss = 1.37665766, grad/param norm = 6.1102e-02, time/batch = 0.0780s	
2071/4200 (epoch 24.655), train_loss = 1.38423391, grad/param norm = 6.2729e-02, time/batch = 0.0799s	
2072/4200 (epoch 24.667), train_loss = 1.39528531, grad/param norm = 6.2861e-02, time/batch = 0.0778s	
2073/4200 (epoch 24.679), train_loss = 1.38844422, grad/param norm = 6.0451e-02, time/batch = 0.0779s	
2074/4200 (epoch 24.690), train_loss = 1.37497732, grad/param norm = 6.2626e-02, time/batch = 0.0784s	
2075/4200 (epoch 24.702), train_loss = 1.37403973, grad/param norm = 7.4979e-02, time/batch = 0.0784s	
2076/4200 (epoch 24.714), train_loss = 1.39923953, grad/param norm = 7.9612e-02, time/batch = 0.0778s	
2077/4200 (epoch 24.726), train_loss = 1.39893321, grad/param norm = 6.8842e-02, time/batch = 0.0781s	
2078/4200 (epoch 24.738), train_loss = 1.38756076, grad/param norm = 6.6302e-02, time/batch = 0.0778s	
2079/4200 (epoch 24.750), train_loss = 1.40110085, grad/param norm = 7.8909e-02, time/batch = 0.0782s	
2080/4200 (epoch 24.762), train_loss = 1.39756625, grad/param norm = 8.2756e-02, time/batch = 0.0784s	
2081/4200 (epoch 24.774), train_loss = 1.40430479, grad/param norm = 7.5360e-02, time/batch = 0.0797s	
2082/4200 (epoch 24.786), train_loss = 1.38193603, grad/param norm = 6.5587e-02, time/batch = 0.0780s	
2083/4200 (epoch 24.798), train_loss = 1.39320395, grad/param norm = 5.7923e-02, time/batch = 0.0780s	
2084/4200 (epoch 24.810), train_loss = 1.39785429, grad/param norm = 6.1309e-02, time/batch = 0.0780s	
2085/4200 (epoch 24.821), train_loss = 1.38530018, grad/param norm = 7.5729e-02, time/batch = 0.0785s	
2086/4200 (epoch 24.833), train_loss = 1.40688569, grad/param norm = 9.3661e-02, time/batch = 0.0778s	
2087/4200 (epoch 24.845), train_loss = 1.41782804, grad/param norm = 9.4037e-02, time/batch = 0.0782s	
2088/4200 (epoch 24.857), train_loss = 1.42226376, grad/param norm = 9.5403e-02, time/batch = 0.0777s	
2089/4200 (epoch 24.869), train_loss = 1.42959789, grad/param norm = 8.0445e-02, time/batch = 0.0782s	
2090/4200 (epoch 24.881), train_loss = 1.39928699, grad/param norm = 7.2391e-02, time/batch = 0.0784s	
2091/4200 (epoch 24.893), train_loss = 1.41199765, grad/param norm = 6.8815e-02, time/batch = 0.0798s	
2092/4200 (epoch 24.905), train_loss = 1.39171499, grad/param norm = 6.4954e-02, time/batch = 0.0777s	
2093/4200 (epoch 24.917), train_loss = 1.41029144, grad/param norm = 7.3952e-02, time/batch = 0.0780s	
2094/4200 (epoch 24.929), train_loss = 1.39564159, grad/param norm = 7.5580e-02, time/batch = 0.0780s	
2095/4200 (epoch 24.940), train_loss = 1.40470628, grad/param norm = 7.1712e-02, time/batch = 0.0782s	
2096/4200 (epoch 24.952), train_loss = 1.40403359, grad/param norm = 7.1647e-02, time/batch = 0.0778s	
2097/4200 (epoch 24.964), train_loss = 1.41075700, grad/param norm = 7.7397e-02, time/batch = 0.0784s	
2098/4200 (epoch 24.976), train_loss = 1.40616105, grad/param norm = 7.9496e-02, time/batch = 0.0776s	
2099/4200 (epoch 24.988), train_loss = 1.39914669, grad/param norm = 7.0247e-02, time/batch = 0.0782s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
2100/4200 (epoch 25.000), train_loss = 1.43607734, grad/param norm = 6.1570e-02, time/batch = 0.0779s	
2101/4200 (epoch 25.012), train_loss = 1.55818375, grad/param norm = 7.2400e-02, time/batch = 0.0803s	
2102/4200 (epoch 25.024), train_loss = 1.37897374, grad/param norm = 6.6630e-02, time/batch = 0.0777s	
2103/4200 (epoch 25.036), train_loss = 1.38958356, grad/param norm = 6.0905e-02, time/batch = 0.0781s	
2104/4200 (epoch 25.048), train_loss = 1.36122917, grad/param norm = 5.5249e-02, time/batch = 0.0784s	
2105/4200 (epoch 25.060), train_loss = 1.38585273, grad/param norm = 6.0737e-02, time/batch = 0.0783s	
2106/4200 (epoch 25.071), train_loss = 1.38212819, grad/param norm = 6.4910e-02, time/batch = 0.0781s	
2107/4200 (epoch 25.083), train_loss = 1.37763571, grad/param norm = 6.8424e-02, time/batch = 0.0788s	
2108/4200 (epoch 25.095), train_loss = 1.36914645, grad/param norm = 6.8788e-02, time/batch = 0.0777s	
2109/4200 (epoch 25.107), train_loss = 1.37719093, grad/param norm = 5.6729e-02, time/batch = 0.0783s	
2110/4200 (epoch 25.119), train_loss = 1.37360820, grad/param norm = 5.8746e-02, time/batch = 0.0780s	
2111/4200 (epoch 25.131), train_loss = 1.38328174, grad/param norm = 5.9528e-02, time/batch = 0.0801s	
2112/4200 (epoch 25.143), train_loss = 1.38642528, grad/param norm = 5.8664e-02, time/batch = 0.0778s	
2113/4200 (epoch 25.155), train_loss = 1.36345514, grad/param norm = 5.4785e-02, time/batch = 0.0781s	
2114/4200 (epoch 25.167), train_loss = 1.38929949, grad/param norm = 6.8600e-02, time/batch = 0.0780s	
2115/4200 (epoch 25.179), train_loss = 1.39797508, grad/param norm = 7.3631e-02, time/batch = 0.0782s	
2116/4200 (epoch 25.190), train_loss = 1.37898277, grad/param norm = 7.9717e-02, time/batch = 0.0779s	
2117/4200 (epoch 25.202), train_loss = 1.41115680, grad/param norm = 8.5650e-02, time/batch = 0.0804s	
2118/4200 (epoch 25.214), train_loss = 1.38957819, grad/param norm = 7.6051e-02, time/batch = 0.0790s	
2119/4200 (epoch 25.226), train_loss = 1.39340063, grad/param norm = 6.5298e-02, time/batch = 0.0784s	
2120/4200 (epoch 25.238), train_loss = 1.38231932, grad/param norm = 6.3376e-02, time/batch = 0.0781s	
2121/4200 (epoch 25.250), train_loss = 1.36540792, grad/param norm = 6.0534e-02, time/batch = 0.0801s	
2122/4200 (epoch 25.262), train_loss = 1.33797709, grad/param norm = 5.8233e-02, time/batch = 0.0784s	
2123/4200 (epoch 25.274), train_loss = 1.38891866, grad/param norm = 6.1847e-02, time/batch = 0.0780s	
2124/4200 (epoch 25.286), train_loss = 1.39051376, grad/param norm = 5.8351e-02, time/batch = 0.0781s	
2125/4200 (epoch 25.298), train_loss = 1.36368786, grad/param norm = 6.5797e-02, time/batch = 0.0785s	
2126/4200 (epoch 25.310), train_loss = 1.40422784, grad/param norm = 7.2040e-02, time/batch = 0.0776s	
2127/4200 (epoch 25.321), train_loss = 1.35161739, grad/param norm = 6.0901e-02, time/batch = 0.0789s	
2128/4200 (epoch 25.333), train_loss = 1.38563432, grad/param norm = 5.5286e-02, time/batch = 0.0778s	
2129/4200 (epoch 25.345), train_loss = 1.37193216, grad/param norm = 5.5809e-02, time/batch = 0.0784s	
2130/4200 (epoch 25.357), train_loss = 1.37751117, grad/param norm = 6.5654e-02, time/batch = 0.0779s	
2131/4200 (epoch 25.369), train_loss = 1.39303927, grad/param norm = 7.7381e-02, time/batch = 0.0798s	
2132/4200 (epoch 25.381), train_loss = 1.39357669, grad/param norm = 8.1693e-02, time/batch = 0.0782s	
2133/4200 (epoch 25.393), train_loss = 1.40784479, grad/param norm = 7.3302e-02, time/batch = 0.0780s	
2134/4200 (epoch 25.405), train_loss = 1.39884619, grad/param norm = 6.4739e-02, time/batch = 0.0778s	
2135/4200 (epoch 25.417), train_loss = 1.35960555, grad/param norm = 6.1034e-02, time/batch = 0.0781s	
2136/4200 (epoch 25.429), train_loss = 1.37172620, grad/param norm = 6.0768e-02, time/batch = 0.0775s	
2137/4200 (epoch 25.440), train_loss = 1.38552298, grad/param norm = 6.4273e-02, time/batch = 0.0782s	
2138/4200 (epoch 25.452), train_loss = 1.39494376, grad/param norm = 6.3959e-02, time/batch = 0.0782s	
2139/4200 (epoch 25.464), train_loss = 1.38970221, grad/param norm = 6.3930e-02, time/batch = 0.0783s	
2140/4200 (epoch 25.476), train_loss = 1.40484889, grad/param norm = 6.3259e-02, time/batch = 0.0780s	
2141/4200 (epoch 25.488), train_loss = 1.40339563, grad/param norm = 6.3235e-02, time/batch = 0.0799s	
2142/4200 (epoch 25.500), train_loss = 1.37480505, grad/param norm = 6.7391e-02, time/batch = 0.0779s	
2143/4200 (epoch 25.512), train_loss = 1.38454908, grad/param norm = 6.7533e-02, time/batch = 0.0786s	
2144/4200 (epoch 25.524), train_loss = 1.35463396, grad/param norm = 7.7338e-02, time/batch = 0.0781s	
2145/4200 (epoch 25.536), train_loss = 1.37886659, grad/param norm = 8.3442e-02, time/batch = 0.0784s	
2146/4200 (epoch 25.548), train_loss = 1.37494842, grad/param norm = 8.5184e-02, time/batch = 0.0780s	
2147/4200 (epoch 25.560), train_loss = 1.39799581, grad/param norm = 7.5714e-02, time/batch = 0.0782s	
2148/4200 (epoch 25.571), train_loss = 1.35014493, grad/param norm = 6.8213e-02, time/batch = 0.0781s	
2149/4200 (epoch 25.583), train_loss = 1.38325286, grad/param norm = 6.9547e-02, time/batch = 0.0783s	
2150/4200 (epoch 25.595), train_loss = 1.38120333, grad/param norm = 7.1172e-02, time/batch = 0.0781s	
2151/4200 (epoch 25.607), train_loss = 1.36362824, grad/param norm = 7.2251e-02, time/batch = 0.0798s	
2152/4200 (epoch 25.619), train_loss = 1.36525359, grad/param norm = 6.0855e-02, time/batch = 0.0777s	
2153/4200 (epoch 25.631), train_loss = 1.36087090, grad/param norm = 5.5684e-02, time/batch = 0.0780s	
2154/4200 (epoch 25.643), train_loss = 1.36872853, grad/param norm = 6.2745e-02, time/batch = 0.0780s	
2155/4200 (epoch 25.655), train_loss = 1.37654843, grad/param norm = 6.2306e-02, time/batch = 0.0782s	
2156/4200 (epoch 25.667), train_loss = 1.38675698, grad/param norm = 5.9510e-02, time/batch = 0.0776s	
2157/4200 (epoch 25.679), train_loss = 1.38019468, grad/param norm = 5.7776e-02, time/batch = 0.0783s	
2158/4200 (epoch 25.690), train_loss = 1.36695745, grad/param norm = 6.3225e-02, time/batch = 0.0775s	
2159/4200 (epoch 25.702), train_loss = 1.36550391, grad/param norm = 7.4806e-02, time/batch = 0.0786s	
2160/4200 (epoch 25.714), train_loss = 1.39005450, grad/param norm = 7.6528e-02, time/batch = 0.0785s	
2161/4200 (epoch 25.726), train_loss = 1.39061134, grad/param norm = 6.4289e-02, time/batch = 0.0799s	
2162/4200 (epoch 25.738), train_loss = 1.37804565, grad/param norm = 5.9269e-02, time/batch = 0.0778s	
2163/4200 (epoch 25.750), train_loss = 1.39086155, grad/param norm = 6.1619e-02, time/batch = 0.0781s	
2164/4200 (epoch 25.762), train_loss = 1.38430656, grad/param norm = 6.6102e-02, time/batch = 0.0785s	
2165/4200 (epoch 25.774), train_loss = 1.39284154, grad/param norm = 6.5866e-02, time/batch = 0.0783s	
2166/4200 (epoch 25.786), train_loss = 1.37204475, grad/param norm = 6.1789e-02, time/batch = 0.0776s	
2167/4200 (epoch 25.798), train_loss = 1.38493001, grad/param norm = 5.7968e-02, time/batch = 0.0783s	
2168/4200 (epoch 25.810), train_loss = 1.39055411, grad/param norm = 6.5245e-02, time/batch = 0.0776s	
2169/4200 (epoch 25.821), train_loss = 1.37870586, grad/param norm = 8.2697e-02, time/batch = 0.0781s	
2170/4200 (epoch 25.833), train_loss = 1.40053278, grad/param norm = 9.6531e-02, time/batch = 0.0781s	
2171/4200 (epoch 25.845), train_loss = 1.40916968, grad/param norm = 9.1918e-02, time/batch = 0.0799s	
2172/4200 (epoch 25.857), train_loss = 1.41222766, grad/param norm = 8.5622e-02, time/batch = 0.0778s	
2173/4200 (epoch 25.869), train_loss = 1.41783853, grad/param norm = 6.7574e-02, time/batch = 0.0781s	
2174/4200 (epoch 25.881), train_loss = 1.38946875, grad/param norm = 5.9232e-02, time/batch = 0.0781s	
2175/4200 (epoch 25.893), train_loss = 1.40246242, grad/param norm = 5.9812e-02, time/batch = 0.0787s	
2176/4200 (epoch 25.905), train_loss = 1.38301533, grad/param norm = 5.8724e-02, time/batch = 0.0777s	
2177/4200 (epoch 25.917), train_loss = 1.39886465, grad/param norm = 6.1194e-02, time/batch = 0.0782s	
2178/4200 (epoch 25.929), train_loss = 1.38459769, grad/param norm = 5.5850e-02, time/batch = 0.0776s	
2179/4200 (epoch 25.940), train_loss = 1.39328206, grad/param norm = 5.5848e-02, time/batch = 0.0782s	
2180/4200 (epoch 25.952), train_loss = 1.39506253, grad/param norm = 5.8683e-02, time/batch = 0.0783s	
2181/4200 (epoch 25.964), train_loss = 1.40016477, grad/param norm = 5.6048e-02, time/batch = 0.0799s	
2182/4200 (epoch 25.976), train_loss = 1.39372896, grad/param norm = 5.8705e-02, time/batch = 0.0778s	
2183/4200 (epoch 25.988), train_loss = 1.38817594, grad/param norm = 5.9320e-02, time/batch = 0.0781s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
2184/4200 (epoch 26.000), train_loss = 1.42650692, grad/param norm = 6.0054e-02, time/batch = 0.0780s	
2185/4200 (epoch 26.012), train_loss = 1.55193079, grad/param norm = 7.1939e-02, time/batch = 0.0785s	
2186/4200 (epoch 26.024), train_loss = 1.37436223, grad/param norm = 7.6604e-02, time/batch = 0.0776s	
2187/4200 (epoch 26.036), train_loss = 1.38516295, grad/param norm = 7.6294e-02, time/batch = 0.0781s	
2188/4200 (epoch 26.048), train_loss = 1.35499414, grad/param norm = 5.9534e-02, time/batch = 0.0778s	
2189/4200 (epoch 26.060), train_loss = 1.37735975, grad/param norm = 5.3724e-02, time/batch = 0.0783s	
2190/4200 (epoch 26.071), train_loss = 1.37344197, grad/param norm = 6.1413e-02, time/batch = 0.0779s	
2191/4200 (epoch 26.083), train_loss = 1.37013979, grad/param norm = 7.2225e-02, time/batch = 0.0799s	
2192/4200 (epoch 26.095), train_loss = 1.35952818, grad/param norm = 6.2321e-02, time/batch = 0.0780s	
2193/4200 (epoch 26.107), train_loss = 1.36967039, grad/param norm = 5.7295e-02, time/batch = 0.0780s	
2194/4200 (epoch 26.119), train_loss = 1.36669239, grad/param norm = 5.9030e-02, time/batch = 0.0782s	
2195/4200 (epoch 26.131), train_loss = 1.37635890, grad/param norm = 6.2912e-02, time/batch = 0.0782s	
2196/4200 (epoch 26.143), train_loss = 1.37921953, grad/param norm = 6.2594e-02, time/batch = 0.0781s	
2197/4200 (epoch 26.155), train_loss = 1.35642605, grad/param norm = 5.3903e-02, time/batch = 0.0784s	
2198/4200 (epoch 26.167), train_loss = 1.38077089, grad/param norm = 6.3247e-02, time/batch = 0.0775s	
2199/4200 (epoch 26.179), train_loss = 1.38924616, grad/param norm = 6.7967e-02, time/batch = 0.0782s	
2200/4200 (epoch 26.190), train_loss = 1.37030191, grad/param norm = 7.7399e-02, time/batch = 0.0780s	
2201/4200 (epoch 26.202), train_loss = 1.40372373, grad/param norm = 8.7848e-02, time/batch = 0.0804s	
2202/4200 (epoch 26.214), train_loss = 1.38320369, grad/param norm = 8.2256e-02, time/batch = 0.0780s	
2203/4200 (epoch 26.226), train_loss = 1.38724065, grad/param norm = 6.9902e-02, time/batch = 0.0782s	
2204/4200 (epoch 26.238), train_loss = 1.37525096, grad/param norm = 6.5246e-02, time/batch = 0.0781s	
2205/4200 (epoch 26.250), train_loss = 1.35818973, grad/param norm = 6.0390e-02, time/batch = 0.0781s	
2206/4200 (epoch 26.262), train_loss = 1.33050952, grad/param norm = 5.8899e-02, time/batch = 0.0776s	
2207/4200 (epoch 26.274), train_loss = 1.38070232, grad/param norm = 6.1308e-02, time/batch = 0.0782s	
2208/4200 (epoch 26.286), train_loss = 1.38333172, grad/param norm = 5.7366e-02, time/batch = 0.0777s	
2209/4200 (epoch 26.298), train_loss = 1.35664697, grad/param norm = 6.6638e-02, time/batch = 0.0791s	
2210/4200 (epoch 26.310), train_loss = 1.39716151, grad/param norm = 7.3970e-02, time/batch = 0.0782s	
2211/4200 (epoch 26.321), train_loss = 1.34475362, grad/param norm = 6.1995e-02, time/batch = 0.0798s	
2212/4200 (epoch 26.333), train_loss = 1.37795879, grad/param norm = 5.5677e-02, time/batch = 0.0782s	
2213/4200 (epoch 26.345), train_loss = 1.36407584, grad/param norm = 5.5067e-02, time/batch = 0.0783s	
2214/4200 (epoch 26.357), train_loss = 1.36965834, grad/param norm = 6.2789e-02, time/batch = 0.0780s	
2215/4200 (epoch 26.369), train_loss = 1.38337955, grad/param norm = 7.1188e-02, time/batch = 0.0782s	
2216/4200 (epoch 26.381), train_loss = 1.38206702, grad/param norm = 6.8737e-02, time/batch = 0.0778s	
2217/4200 (epoch 26.393), train_loss = 1.39832913, grad/param norm = 6.4212e-02, time/batch = 0.0788s	
2218/4200 (epoch 26.405), train_loss = 1.39208884, grad/param norm = 6.3047e-02, time/batch = 0.0778s	
2219/4200 (epoch 26.417), train_loss = 1.35289969, grad/param norm = 6.3726e-02, time/batch = 0.0782s	
2220/4200 (epoch 26.429), train_loss = 1.36492129, grad/param norm = 5.8628e-02, time/batch = 0.0782s	
2221/4200 (epoch 26.440), train_loss = 1.37734410, grad/param norm = 5.7351e-02, time/batch = 0.0798s	
2222/4200 (epoch 26.452), train_loss = 1.38838396, grad/param norm = 6.6806e-02, time/batch = 0.0781s	
2223/4200 (epoch 26.464), train_loss = 1.38350002, grad/param norm = 6.7079e-02, time/batch = 0.0829s	
2224/4200 (epoch 26.476), train_loss = 1.39824578, grad/param norm = 6.4737e-02, time/batch = 0.0786s	
2225/4200 (epoch 26.488), train_loss = 1.40036969, grad/param norm = 8.1975e-02, time/batch = 0.0785s	
2226/4200 (epoch 26.500), train_loss = 1.37306165, grad/param norm = 8.3137e-02, time/batch = 0.0776s	
2227/4200 (epoch 26.512), train_loss = 1.37800963, grad/param norm = 7.0624e-02, time/batch = 0.0782s	
2228/4200 (epoch 26.524), train_loss = 1.34540319, grad/param norm = 6.2008e-02, time/batch = 0.0776s	
2229/4200 (epoch 26.536), train_loss = 1.36583403, grad/param norm = 6.2270e-02, time/batch = 0.0781s	
2230/4200 (epoch 26.548), train_loss = 1.36347350, grad/param norm = 6.6990e-02, time/batch = 0.0782s	
2231/4200 (epoch 26.560), train_loss = 1.38851394, grad/param norm = 6.9783e-02, time/batch = 0.0799s	
2232/4200 (epoch 26.571), train_loss = 1.34227861, grad/param norm = 6.3533e-02, time/batch = 0.0776s	
2233/4200 (epoch 26.583), train_loss = 1.37303593, grad/param norm = 5.6500e-02, time/batch = 0.0792s	
2234/4200 (epoch 26.595), train_loss = 1.37168729, grad/param norm = 6.1016e-02, time/batch = 0.0782s	
2235/4200 (epoch 26.607), train_loss = 1.35575127, grad/param norm = 7.3972e-02, time/batch = 0.0782s	
2236/4200 (epoch 26.619), train_loss = 1.35967690, grad/param norm = 7.0649e-02, time/batch = 0.0777s	
2237/4200 (epoch 26.631), train_loss = 1.35435158, grad/param norm = 6.2370e-02, time/batch = 0.0783s	
2238/4200 (epoch 26.643), train_loss = 1.35999168, grad/param norm = 5.5687e-02, time/batch = 0.0781s	
2239/4200 (epoch 26.655), train_loss = 1.36752170, grad/param norm = 5.8471e-02, time/batch = 0.0781s	
2240/4200 (epoch 26.667), train_loss = 1.38056797, grad/param norm = 6.5523e-02, time/batch = 0.0778s	
2241/4200 (epoch 26.679), train_loss = 1.37384311, grad/param norm = 6.3436e-02, time/batch = 0.0798s	
2242/4200 (epoch 26.690), train_loss = 1.35979684, grad/param norm = 5.8711e-02, time/batch = 0.0777s	
2243/4200 (epoch 26.702), train_loss = 1.35610166, grad/param norm = 6.4904e-02, time/batch = 0.0784s	
2244/4200 (epoch 26.714), train_loss = 1.37965047, grad/param norm = 6.4004e-02, time/batch = 0.0783s	
2245/4200 (epoch 26.726), train_loss = 1.38149742, grad/param norm = 5.7801e-02, time/batch = 0.0782s	
2246/4200 (epoch 26.738), train_loss = 1.36950214, grad/param norm = 5.9408e-02, time/batch = 0.0777s	
2247/4200 (epoch 26.750), train_loss = 1.38358834, grad/param norm = 6.4545e-02, time/batch = 0.0782s	
2248/4200 (epoch 26.762), train_loss = 1.37722414, grad/param norm = 6.6502e-02, time/batch = 0.0777s	
2249/4200 (epoch 26.774), train_loss = 1.38632666, grad/param norm = 7.2545e-02, time/batch = 0.0787s	
2250/4200 (epoch 26.786), train_loss = 1.36879114, grad/param norm = 8.2326e-02, time/batch = 0.0778s	
2251/4200 (epoch 26.798), train_loss = 1.38431813, grad/param norm = 7.9338e-02, time/batch = 0.0800s	
2252/4200 (epoch 26.810), train_loss = 1.38738345, grad/param norm = 7.5551e-02, time/batch = 0.0777s	
2253/4200 (epoch 26.821), train_loss = 1.37036854, grad/param norm = 7.3899e-02, time/batch = 0.0780s	
2254/4200 (epoch 26.833), train_loss = 1.38701791, grad/param norm = 6.9108e-02, time/batch = 0.0787s	
2255/4200 (epoch 26.845), train_loss = 1.39557916, grad/param norm = 6.7839e-02, time/batch = 0.0781s	
2256/4200 (epoch 26.857), train_loss = 1.39988909, grad/param norm = 6.6357e-02, time/batch = 0.0775s	
2257/4200 (epoch 26.869), train_loss = 1.40846793, grad/param norm = 6.6258e-02, time/batch = 0.0784s	
2258/4200 (epoch 26.881), train_loss = 1.38388803, grad/param norm = 6.4674e-02, time/batch = 0.0776s	
2259/4200 (epoch 26.893), train_loss = 1.39785660, grad/param norm = 7.1922e-02, time/batch = 0.0787s	
2260/4200 (epoch 26.905), train_loss = 1.38078974, grad/param norm = 7.4276e-02, time/batch = 0.0779s	
2261/4200 (epoch 26.917), train_loss = 1.39211639, grad/param norm = 6.7494e-02, time/batch = 0.0800s	
2262/4200 (epoch 26.929), train_loss = 1.37907454, grad/param norm = 6.0323e-02, time/batch = 0.0778s	
2263/4200 (epoch 26.940), train_loss = 1.38701620, grad/param norm = 6.5540e-02, time/batch = 0.0780s	
2264/4200 (epoch 26.952), train_loss = 1.39201683, grad/param norm = 7.3710e-02, time/batch = 0.0779s	
2265/4200 (epoch 26.964), train_loss = 1.39786003, grad/param norm = 8.4088e-02, time/batch = 0.0807s	
2266/4200 (epoch 26.976), train_loss = 1.39255388, grad/param norm = 8.3914e-02, time/batch = 0.0781s	
2267/4200 (epoch 26.988), train_loss = 1.38405967, grad/param norm = 7.5270e-02, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
2268/4200 (epoch 27.000), train_loss = 1.42142943, grad/param norm = 6.5644e-02, time/batch = 0.0776s	
2269/4200 (epoch 27.012), train_loss = 1.54702613, grad/param norm = 7.7895e-02, time/batch = 0.0782s	
2270/4200 (epoch 27.024), train_loss = 1.36489737, grad/param norm = 7.1635e-02, time/batch = 0.0785s	
2271/4200 (epoch 27.036), train_loss = 1.37544808, grad/param norm = 6.6437e-02, time/batch = 0.0797s	
2272/4200 (epoch 27.048), train_loss = 1.34755519, grad/param norm = 5.8096e-02, time/batch = 0.0780s	
2273/4200 (epoch 27.060), train_loss = 1.37099672, grad/param norm = 6.1134e-02, time/batch = 0.0782s	
2274/4200 (epoch 27.071), train_loss = 1.36660002, grad/param norm = 6.1792e-02, time/batch = 0.0780s	
2275/4200 (epoch 27.083), train_loss = 1.36140977, grad/param norm = 6.4854e-02, time/batch = 0.0787s	
2276/4200 (epoch 27.095), train_loss = 1.35164965, grad/param norm = 5.4618e-02, time/batch = 0.0787s	
2277/4200 (epoch 27.107), train_loss = 1.36223217, grad/param norm = 5.4719e-02, time/batch = 0.0784s	
2278/4200 (epoch 27.119), train_loss = 1.35862165, grad/param norm = 5.3824e-02, time/batch = 0.0776s	
2279/4200 (epoch 27.131), train_loss = 1.36751252, grad/param norm = 5.4778e-02, time/batch = 0.0783s	
2280/4200 (epoch 27.143), train_loss = 1.37080962, grad/param norm = 5.6416e-02, time/batch = 0.0782s	
2281/4200 (epoch 27.155), train_loss = 1.34963115, grad/param norm = 5.6968e-02, time/batch = 0.0800s	
2282/4200 (epoch 27.167), train_loss = 1.37531035, grad/param norm = 7.1503e-02, time/batch = 0.0778s	
2283/4200 (epoch 27.179), train_loss = 1.38339738, grad/param norm = 7.2946e-02, time/batch = 0.0780s	
2284/4200 (epoch 27.190), train_loss = 1.36269831, grad/param norm = 7.0362e-02, time/batch = 0.0780s	
2285/4200 (epoch 27.202), train_loss = 1.39362864, grad/param norm = 7.3185e-02, time/batch = 0.0780s	
2286/4200 (epoch 27.214), train_loss = 1.37223834, grad/param norm = 6.4195e-02, time/batch = 0.0775s	
2287/4200 (epoch 27.226), train_loss = 1.37741028, grad/param norm = 5.6408e-02, time/batch = 0.0786s	
2288/4200 (epoch 27.238), train_loss = 1.36679428, grad/param norm = 5.7989e-02, time/batch = 0.0777s	
2289/4200 (epoch 27.250), train_loss = 1.35118918, grad/param norm = 5.8520e-02, time/batch = 0.0783s	
2290/4200 (epoch 27.262), train_loss = 1.32320685, grad/param norm = 5.6267e-02, time/batch = 0.0780s	
2291/4200 (epoch 27.274), train_loss = 1.37225496, grad/param norm = 5.5704e-02, time/batch = 0.0804s	
2292/4200 (epoch 27.286), train_loss = 1.37472801, grad/param norm = 5.0833e-02, time/batch = 0.0778s	
2293/4200 (epoch 27.298), train_loss = 1.34819033, grad/param norm = 6.1046e-02, time/batch = 0.0780s	
2294/4200 (epoch 27.310), train_loss = 1.38851772, grad/param norm = 6.5848e-02, time/batch = 0.0781s	
2295/4200 (epoch 27.321), train_loss = 1.33626005, grad/param norm = 5.4551e-02, time/batch = 0.0781s	
2296/4200 (epoch 27.333), train_loss = 1.36949367, grad/param norm = 5.0833e-02, time/batch = 0.0782s	
2297/4200 (epoch 27.345), train_loss = 1.35651018, grad/param norm = 5.4521e-02, time/batch = 0.0784s	
2298/4200 (epoch 27.357), train_loss = 1.36262877, grad/param norm = 6.1623e-02, time/batch = 0.0777s	
2299/4200 (epoch 27.369), train_loss = 1.37544365, grad/param norm = 6.8668e-02, time/batch = 0.0783s	
2300/4200 (epoch 27.381), train_loss = 1.37491248, grad/param norm = 6.6844e-02, time/batch = 0.0778s	
2301/4200 (epoch 27.393), train_loss = 1.39189224, grad/param norm = 6.8178e-02, time/batch = 0.0803s	
2302/4200 (epoch 27.405), train_loss = 1.38750027, grad/param norm = 7.0883e-02, time/batch = 0.0778s	
2303/4200 (epoch 27.417), train_loss = 1.34784120, grad/param norm = 7.5919e-02, time/batch = 0.0779s	
2304/4200 (epoch 27.429), train_loss = 1.35992837, grad/param norm = 6.7699e-02, time/batch = 0.0780s	
2305/4200 (epoch 27.440), train_loss = 1.37088756, grad/param norm = 6.1794e-02, time/batch = 0.0783s	
2306/4200 (epoch 27.452), train_loss = 1.38109221, grad/param norm = 6.8966e-02, time/batch = 0.0776s	
2307/4200 (epoch 27.464), train_loss = 1.37736876, grad/param norm = 6.9196e-02, time/batch = 0.0789s	
2308/4200 (epoch 27.476), train_loss = 1.39260352, grad/param norm = 7.1976e-02, time/batch = 0.0777s	
2309/4200 (epoch 27.488), train_loss = 1.39363842, grad/param norm = 8.7339e-02, time/batch = 0.0784s	
2310/4200 (epoch 27.500), train_loss = 1.36333836, grad/param norm = 7.6427e-02, time/batch = 0.0781s	
2311/4200 (epoch 27.512), train_loss = 1.36911339, grad/param norm = 5.9184e-02, time/batch = 0.0798s	
2312/4200 (epoch 27.524), train_loss = 1.33713938, grad/param norm = 4.9998e-02, time/batch = 0.0783s	
2313/4200 (epoch 27.536), train_loss = 1.35605388, grad/param norm = 4.8624e-02, time/batch = 0.0780s	
2314/4200 (epoch 27.548), train_loss = 1.35328115, grad/param norm = 5.1888e-02, time/batch = 0.0782s	
2315/4200 (epoch 27.560), train_loss = 1.37824628, grad/param norm = 5.5612e-02, time/batch = 0.0792s	
2316/4200 (epoch 27.571), train_loss = 1.33366241, grad/param norm = 5.4530e-02, time/batch = 0.0778s	
2317/4200 (epoch 27.583), train_loss = 1.36521432, grad/param norm = 5.2489e-02, time/batch = 0.0787s	
2318/4200 (epoch 27.595), train_loss = 1.36387440, grad/param norm = 5.5863e-02, time/batch = 0.0780s	
2319/4200 (epoch 27.607), train_loss = 1.34759233, grad/param norm = 6.5797e-02, time/batch = 0.0784s	
2320/4200 (epoch 27.619), train_loss = 1.35094661, grad/param norm = 6.0526e-02, time/batch = 0.0780s	
2321/4200 (epoch 27.631), train_loss = 1.34602527, grad/param norm = 5.2114e-02, time/batch = 0.0798s	
2322/4200 (epoch 27.643), train_loss = 1.35222428, grad/param norm = 5.2902e-02, time/batch = 0.0783s	
2323/4200 (epoch 27.655), train_loss = 1.36218498, grad/param norm = 6.1097e-02, time/batch = 0.0781s	
2324/4200 (epoch 27.667), train_loss = 1.37461256, grad/param norm = 6.8550e-02, time/batch = 0.0781s	
2325/4200 (epoch 27.679), train_loss = 1.36698191, grad/param norm = 5.8447e-02, time/batch = 0.0780s	
2326/4200 (epoch 27.690), train_loss = 1.35120239, grad/param norm = 5.0708e-02, time/batch = 0.0777s	
2327/4200 (epoch 27.702), train_loss = 1.34785604, grad/param norm = 5.9749e-02, time/batch = 0.0784s	
2328/4200 (epoch 27.714), train_loss = 1.37266509, grad/param norm = 6.5424e-02, time/batch = 0.0780s	
2329/4200 (epoch 27.726), train_loss = 1.37648842, grad/param norm = 6.3514e-02, time/batch = 0.0826s	
2330/4200 (epoch 27.738), train_loss = 1.36409111, grad/param norm = 6.9624e-02, time/batch = 0.0783s	
2331/4200 (epoch 27.750), train_loss = 1.38124501, grad/param norm = 7.6081e-02, time/batch = 0.0799s	
2332/4200 (epoch 27.762), train_loss = 1.37628415, grad/param norm = 9.0900e-02, time/batch = 0.0778s	
2333/4200 (epoch 27.774), train_loss = 1.38726603, grad/param norm = 9.2634e-02, time/batch = 0.0786s	
2334/4200 (epoch 27.786), train_loss = 1.36175033, grad/param norm = 7.6512e-02, time/batch = 0.0781s	
2335/4200 (epoch 27.798), train_loss = 1.37142894, grad/param norm = 6.1339e-02, time/batch = 0.0783s	
2336/4200 (epoch 27.810), train_loss = 1.37656402, grad/param norm = 6.2576e-02, time/batch = 0.0778s	
2337/4200 (epoch 27.821), train_loss = 1.36384300, grad/param norm = 7.4691e-02, time/batch = 0.0783s	
2338/4200 (epoch 27.833), train_loss = 1.38347310, grad/param norm = 8.3725e-02, time/batch = 0.0782s	
2339/4200 (epoch 27.845), train_loss = 1.39114086, grad/param norm = 7.7851e-02, time/batch = 0.0783s	
2340/4200 (epoch 27.857), train_loss = 1.39449909, grad/param norm = 7.3143e-02, time/batch = 0.0783s	
2341/4200 (epoch 27.869), train_loss = 1.40066686, grad/param norm = 5.8999e-02, time/batch = 0.0799s	
2342/4200 (epoch 27.881), train_loss = 1.37422163, grad/param norm = 5.3948e-02, time/batch = 0.0778s	
2343/4200 (epoch 27.893), train_loss = 1.38670272, grad/param norm = 5.6612e-02, time/batch = 0.0779s	
2344/4200 (epoch 27.905), train_loss = 1.36860696, grad/param norm = 5.5064e-02, time/batch = 0.0781s	
2345/4200 (epoch 27.917), train_loss = 1.38313057, grad/param norm = 5.8423e-02, time/batch = 0.0782s	
2346/4200 (epoch 27.929), train_loss = 1.36986170, grad/param norm = 5.4126e-02, time/batch = 0.0774s	
2347/4200 (epoch 27.940), train_loss = 1.37860145, grad/param norm = 5.2528e-02, time/batch = 0.0782s	
2348/4200 (epoch 27.952), train_loss = 1.38079847, grad/param norm = 5.5749e-02, time/batch = 0.0774s	
2349/4200 (epoch 27.964), train_loss = 1.38574000, grad/param norm = 5.6333e-02, time/batch = 0.0785s	
2350/4200 (epoch 27.976), train_loss = 1.37901464, grad/param norm = 5.8751e-02, time/batch = 0.0781s	
2351/4200 (epoch 27.988), train_loss = 1.37395199, grad/param norm = 6.0350e-02, time/batch = 0.0798s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
2352/4200 (epoch 28.000), train_loss = 1.41349144, grad/param norm = 6.3998e-02, time/batch = 0.0778s	
2353/4200 (epoch 28.012), train_loss = 1.54057102, grad/param norm = 7.0621e-02, time/batch = 0.0780s	
2354/4200 (epoch 28.024), train_loss = 1.35967610, grad/param norm = 7.2664e-02, time/batch = 0.0785s	
2355/4200 (epoch 28.036), train_loss = 1.36973051, grad/param norm = 6.9413e-02, time/batch = 0.0782s	
2356/4200 (epoch 28.048), train_loss = 1.34147229, grad/param norm = 5.7324e-02, time/batch = 0.0777s	
2357/4200 (epoch 28.060), train_loss = 1.36481578, grad/param norm = 5.8778e-02, time/batch = 0.0785s	
2358/4200 (epoch 28.071), train_loss = 1.36089274, grad/param norm = 6.4752e-02, time/batch = 0.0777s	
2359/4200 (epoch 28.083), train_loss = 1.35598193, grad/param norm = 6.9151e-02, time/batch = 0.0781s	
2360/4200 (epoch 28.095), train_loss = 1.34667471, grad/param norm = 5.7902e-02, time/batch = 0.0780s	
2361/4200 (epoch 28.107), train_loss = 1.35679248, grad/param norm = 5.7295e-02, time/batch = 0.0798s	
2362/4200 (epoch 28.119), train_loss = 1.35359224, grad/param norm = 5.7907e-02, time/batch = 0.0777s	
2363/4200 (epoch 28.131), train_loss = 1.36232717, grad/param norm = 5.8973e-02, time/batch = 0.0782s	
2364/4200 (epoch 28.143), train_loss = 1.36425136, grad/param norm = 5.6996e-02, time/batch = 0.0780s	
2365/4200 (epoch 28.155), train_loss = 1.34277050, grad/param norm = 5.2999e-02, time/batch = 0.0786s	
2366/4200 (epoch 28.167), train_loss = 1.36748351, grad/param norm = 6.7081e-02, time/batch = 0.0776s	
2367/4200 (epoch 28.179), train_loss = 1.37614372, grad/param norm = 6.9919e-02, time/batch = 0.0783s	
2368/4200 (epoch 28.190), train_loss = 1.35609722, grad/param norm = 7.0387e-02, time/batch = 0.0776s	
2369/4200 (epoch 28.202), train_loss = 1.38767476, grad/param norm = 7.5400e-02, time/batch = 0.0781s	
2370/4200 (epoch 28.214), train_loss = 1.36620530, grad/param norm = 6.7805e-02, time/batch = 0.0783s	
2371/4200 (epoch 28.226), train_loss = 1.37173795, grad/param norm = 5.9953e-02, time/batch = 0.0800s	
2372/4200 (epoch 28.238), train_loss = 1.36072306, grad/param norm = 6.0361e-02, time/batch = 0.0777s	
2373/4200 (epoch 28.250), train_loss = 1.34524669, grad/param norm = 5.7496e-02, time/batch = 0.0779s	
2374/4200 (epoch 28.262), train_loss = 1.31591432, grad/param norm = 5.3600e-02, time/batch = 0.0780s	
2375/4200 (epoch 28.274), train_loss = 1.36541823, grad/param norm = 5.5706e-02, time/batch = 0.0787s	
2376/4200 (epoch 28.286), train_loss = 1.36818427, grad/param norm = 5.3594e-02, time/batch = 0.0777s	
2377/4200 (epoch 28.298), train_loss = 1.34218562, grad/param norm = 6.4524e-02, time/batch = 0.0781s	
2378/4200 (epoch 28.310), train_loss = 1.38259563, grad/param norm = 6.9664e-02, time/batch = 0.0777s	
2379/4200 (epoch 28.321), train_loss = 1.33032005, grad/param norm = 5.6850e-02, time/batch = 0.0781s	
2380/4200 (epoch 28.333), train_loss = 1.36255981, grad/param norm = 5.1672e-02, time/batch = 0.0779s	
2381/4200 (epoch 28.345), train_loss = 1.34943227, grad/param norm = 5.1934e-02, time/batch = 0.0800s	
2382/4200 (epoch 28.357), train_loss = 1.35565214, grad/param norm = 5.9088e-02, time/batch = 0.0778s	
2383/4200 (epoch 28.369), train_loss = 1.36830452, grad/param norm = 6.6842e-02, time/batch = 0.0779s	
2384/4200 (epoch 28.381), train_loss = 1.36741856, grad/param norm = 6.4567e-02, time/batch = 0.0781s	
2385/4200 (epoch 28.393), train_loss = 1.38392983, grad/param norm = 5.9322e-02, time/batch = 0.0782s	
2386/4200 (epoch 28.405), train_loss = 1.37753539, grad/param norm = 5.5701e-02, time/batch = 0.0782s	
2387/4200 (epoch 28.417), train_loss = 1.33698995, grad/param norm = 5.6562e-02, time/batch = 0.0782s	
2388/4200 (epoch 28.429), train_loss = 1.35003860, grad/param norm = 5.3229e-02, time/batch = 0.0777s	
2389/4200 (epoch 28.440), train_loss = 1.36301289, grad/param norm = 5.4929e-02, time/batch = 0.0783s	
2390/4200 (epoch 28.452), train_loss = 1.37255358, grad/param norm = 6.0572e-02, time/batch = 0.0779s	
2391/4200 (epoch 28.464), train_loss = 1.36912612, grad/param norm = 6.2152e-02, time/batch = 0.0803s	
2392/4200 (epoch 28.476), train_loss = 1.38383125, grad/param norm = 6.1554e-02, time/batch = 0.0777s	
2393/4200 (epoch 28.488), train_loss = 1.38247080, grad/param norm = 6.4354e-02, time/batch = 0.0779s	
2394/4200 (epoch 28.500), train_loss = 1.35433466, grad/param norm = 6.7699e-02, time/batch = 0.0778s	
2395/4200 (epoch 28.512), train_loss = 1.36420134, grad/param norm = 6.9846e-02, time/batch = 0.0781s	
2396/4200 (epoch 28.524), train_loss = 1.33798763, grad/param norm = 8.5899e-02, time/batch = 0.0777s	
2397/4200 (epoch 28.536), train_loss = 1.36123597, grad/param norm = 9.5178e-02, time/batch = 0.0782s	
2398/4200 (epoch 28.548), train_loss = 1.35677297, grad/param norm = 9.0325e-02, time/batch = 0.0776s	
2399/4200 (epoch 28.560), train_loss = 1.37676175, grad/param norm = 7.2867e-02, time/batch = 0.0785s	
2400/4200 (epoch 28.571), train_loss = 1.32908706, grad/param norm = 6.1540e-02, time/batch = 0.0780s	
2401/4200 (epoch 28.583), train_loss = 1.35981125, grad/param norm = 6.0006e-02, time/batch = 0.0798s	
2402/4200 (epoch 28.595), train_loss = 1.35787465, grad/param norm = 6.0037e-02, time/batch = 0.0777s	
2403/4200 (epoch 28.607), train_loss = 1.34028628, grad/param norm = 6.4012e-02, time/batch = 0.0781s	
2404/4200 (epoch 28.619), train_loss = 1.34369183, grad/param norm = 5.4416e-02, time/batch = 0.0780s	
2405/4200 (epoch 28.631), train_loss = 1.33882908, grad/param norm = 4.9893e-02, time/batch = 0.0782s	
2406/4200 (epoch 28.643), train_loss = 1.34622621, grad/param norm = 5.6905e-02, time/batch = 0.0776s	
2407/4200 (epoch 28.655), train_loss = 1.35576197, grad/param norm = 5.8197e-02, time/batch = 0.0786s	
2408/4200 (epoch 28.667), train_loss = 1.36580808, grad/param norm = 5.5584e-02, time/batch = 0.0777s	
2409/4200 (epoch 28.679), train_loss = 1.36003943, grad/param norm = 5.4653e-02, time/batch = 0.0783s	
2410/4200 (epoch 28.690), train_loss = 1.34637342, grad/param norm = 6.0100e-02, time/batch = 0.0780s	
2411/4200 (epoch 28.702), train_loss = 1.34385783, grad/param norm = 7.2491e-02, time/batch = 0.0798s	
2412/4200 (epoch 28.714), train_loss = 1.36819958, grad/param norm = 7.4060e-02, time/batch = 0.0781s	
2413/4200 (epoch 28.726), train_loss = 1.36991158, grad/param norm = 6.3272e-02, time/batch = 0.0781s	
2414/4200 (epoch 28.738), train_loss = 1.35556438, grad/param norm = 5.8640e-02, time/batch = 0.0781s	
2415/4200 (epoch 28.750), train_loss = 1.37131735, grad/param norm = 6.0041e-02, time/batch = 0.0783s	
2416/4200 (epoch 28.762), train_loss = 1.36401978, grad/param norm = 6.4710e-02, time/batch = 0.0776s	
2417/4200 (epoch 28.774), train_loss = 1.37206270, grad/param norm = 6.3160e-02, time/batch = 0.0782s	
2418/4200 (epoch 28.786), train_loss = 1.35067215, grad/param norm = 5.6780e-02, time/batch = 0.0780s	
2419/4200 (epoch 28.798), train_loss = 1.36220459, grad/param norm = 5.0046e-02, time/batch = 0.0782s	
2420/4200 (epoch 28.810), train_loss = 1.36857634, grad/param norm = 5.3884e-02, time/batch = 0.0781s	
2421/4200 (epoch 28.821), train_loss = 1.35514334, grad/param norm = 6.3439e-02, time/batch = 0.0797s	
2422/4200 (epoch 28.833), train_loss = 1.37479447, grad/param norm = 7.5454e-02, time/batch = 0.0778s	
2423/4200 (epoch 28.845), train_loss = 1.38492474, grad/param norm = 8.2326e-02, time/batch = 0.0787s	
2424/4200 (epoch 28.857), train_loss = 1.39083018, grad/param norm = 8.2274e-02, time/batch = 0.0785s	
2425/4200 (epoch 28.869), train_loss = 1.39596503, grad/param norm = 6.6421e-02, time/batch = 0.0783s	
2426/4200 (epoch 28.881), train_loss = 1.36906632, grad/param norm = 5.5356e-02, time/batch = 0.0777s	
2427/4200 (epoch 28.893), train_loss = 1.38111984, grad/param norm = 5.7010e-02, time/batch = 0.0781s	
2428/4200 (epoch 28.905), train_loss = 1.36297314, grad/param norm = 5.5205e-02, time/batch = 0.0781s	
2429/4200 (epoch 28.917), train_loss = 1.37606284, grad/param norm = 5.6392e-02, time/batch = 0.0781s	
2430/4200 (epoch 28.929), train_loss = 1.36348758, grad/param norm = 5.1020e-02, time/batch = 0.0780s	
2431/4200 (epoch 28.940), train_loss = 1.37164014, grad/param norm = 5.2090e-02, time/batch = 0.0799s	
2432/4200 (epoch 28.952), train_loss = 1.37583133, grad/param norm = 5.9990e-02, time/batch = 0.0778s	
2433/4200 (epoch 28.964), train_loss = 1.38090301, grad/param norm = 7.0991e-02, time/batch = 0.0783s	
2434/4200 (epoch 28.976), train_loss = 1.37570277, grad/param norm = 7.3357e-02, time/batch = 0.0808s	
2435/4200 (epoch 28.988), train_loss = 1.36889309, grad/param norm = 6.4449e-02, time/batch = 0.0797s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
2436/4200 (epoch 29.000), train_loss = 1.40678047, grad/param norm = 5.7051e-02, time/batch = 0.0777s	
2437/4200 (epoch 29.012), train_loss = 1.53481906, grad/param norm = 7.2052e-02, time/batch = 0.0782s	
2438/4200 (epoch 29.024), train_loss = 1.35165330, grad/param norm = 6.7204e-02, time/batch = 0.0778s	
2439/4200 (epoch 29.036), train_loss = 1.36117899, grad/param norm = 6.0416e-02, time/batch = 0.0786s	
2440/4200 (epoch 29.048), train_loss = 1.33475724, grad/param norm = 5.5286e-02, time/batch = 0.0779s	
2441/4200 (epoch 29.060), train_loss = 1.35876076, grad/param norm = 6.1506e-02, time/batch = 0.0800s	
2442/4200 (epoch 29.071), train_loss = 1.35413231, grad/param norm = 6.2035e-02, time/batch = 0.0778s	
2443/4200 (epoch 29.083), train_loss = 1.34828949, grad/param norm = 6.2881e-02, time/batch = 0.0780s	
2444/4200 (epoch 29.095), train_loss = 1.33992354, grad/param norm = 5.2522e-02, time/batch = 0.0786s	
2445/4200 (epoch 29.107), train_loss = 1.35013959, grad/param norm = 5.5553e-02, time/batch = 0.0781s	
2446/4200 (epoch 29.119), train_loss = 1.34725931, grad/param norm = 5.6201e-02, time/batch = 0.0778s	
2447/4200 (epoch 29.131), train_loss = 1.35540681, grad/param norm = 5.6318e-02, time/batch = 0.0785s	
2448/4200 (epoch 29.143), train_loss = 1.35771850, grad/param norm = 5.5772e-02, time/batch = 0.0777s	
2449/4200 (epoch 29.155), train_loss = 1.33720776, grad/param norm = 5.5531e-02, time/batch = 0.0787s	
2450/4200 (epoch 29.167), train_loss = 1.36202405, grad/param norm = 7.0226e-02, time/batch = 0.0779s	
2451/4200 (epoch 29.179), train_loss = 1.37025160, grad/param norm = 7.0269e-02, time/batch = 0.0798s	
2452/4200 (epoch 29.190), train_loss = 1.34922825, grad/param norm = 6.5536e-02, time/batch = 0.0778s	
2453/4200 (epoch 29.202), train_loss = 1.38025918, grad/param norm = 6.9221e-02, time/batch = 0.0781s	
2454/4200 (epoch 29.214), train_loss = 1.35930308, grad/param norm = 6.4026e-02, time/batch = 0.0779s	
2455/4200 (epoch 29.226), train_loss = 1.36545080, grad/param norm = 5.8216e-02, time/batch = 0.0782s	
2456/4200 (epoch 29.238), train_loss = 1.35444262, grad/param norm = 5.8892e-02, time/batch = 0.0778s	
2457/4200 (epoch 29.250), train_loss = 1.33951280, grad/param norm = 5.6804e-02, time/batch = 0.0781s	
2458/4200 (epoch 29.262), train_loss = 1.30985792, grad/param norm = 5.3813e-02, time/batch = 0.0775s	
2459/4200 (epoch 29.274), train_loss = 1.35895113, grad/param norm = 5.5600e-02, time/batch = 0.0781s	
2460/4200 (epoch 29.286), train_loss = 1.36211959, grad/param norm = 5.3531e-02, time/batch = 0.0785s	
2461/4200 (epoch 29.298), train_loss = 1.33657913, grad/param norm = 6.5957e-02, time/batch = 0.0798s	
2462/4200 (epoch 29.310), train_loss = 1.37696198, grad/param norm = 7.1265e-02, time/batch = 0.0778s	
2463/4200 (epoch 29.321), train_loss = 1.32481571, grad/param norm = 5.8804e-02, time/batch = 0.0781s	
2464/4200 (epoch 29.333), train_loss = 1.35640712, grad/param norm = 5.3839e-02, time/batch = 0.0780s	
2465/4200 (epoch 29.345), train_loss = 1.34336290, grad/param norm = 5.4100e-02, time/batch = 0.0786s	
2466/4200 (epoch 29.357), train_loss = 1.35008853, grad/param norm = 6.1188e-02, time/batch = 0.0777s	
2467/4200 (epoch 29.369), train_loss = 1.36193188, grad/param norm = 6.7775e-02, time/batch = 0.0781s	
2468/4200 (epoch 29.381), train_loss = 1.36109182, grad/param norm = 6.3189e-02, time/batch = 0.0776s	
2469/4200 (epoch 29.393), train_loss = 1.37752853, grad/param norm = 5.6840e-02, time/batch = 0.0781s	
2470/4200 (epoch 29.405), train_loss = 1.37129427, grad/param norm = 5.3009e-02, time/batch = 0.0781s	
2471/4200 (epoch 29.417), train_loss = 1.33032577, grad/param norm = 5.5244e-02, time/batch = 0.0799s	
2472/4200 (epoch 29.429), train_loss = 1.34356195, grad/param norm = 5.1782e-02, time/batch = 0.0776s	
2473/4200 (epoch 29.440), train_loss = 1.35649073, grad/param norm = 5.2611e-02, time/batch = 0.0779s	
2474/4200 (epoch 29.452), train_loss = 1.36541714, grad/param norm = 5.7735e-02, time/batch = 0.0779s	
2475/4200 (epoch 29.464), train_loss = 1.36229685, grad/param norm = 5.7815e-02, time/batch = 0.0782s	
2476/4200 (epoch 29.476), train_loss = 1.37640993, grad/param norm = 5.4455e-02, time/batch = 0.0781s	
2477/4200 (epoch 29.488), train_loss = 1.37482878, grad/param norm = 5.9859e-02, time/batch = 0.0786s	
2478/4200 (epoch 29.500), train_loss = 1.34683361, grad/param norm = 5.9924e-02, time/batch = 0.0775s	
2479/4200 (epoch 29.512), train_loss = 1.35524030, grad/param norm = 5.7768e-02, time/batch = 0.0782s	
2480/4200 (epoch 29.524), train_loss = 1.32947768, grad/param norm = 7.2814e-02, time/batch = 0.0779s	
2481/4200 (epoch 29.536), train_loss = 1.35260261, grad/param norm = 8.7483e-02, time/batch = 0.0802s	
2482/4200 (epoch 29.548), train_loss = 1.35108491, grad/param norm = 9.0907e-02, time/batch = 0.0777s	
2483/4200 (epoch 29.560), train_loss = 1.37211741, grad/param norm = 7.7001e-02, time/batch = 0.0781s	
2484/4200 (epoch 29.571), train_loss = 1.32430153, grad/param norm = 6.6109e-02, time/batch = 0.0780s	
2485/4200 (epoch 29.583), train_loss = 1.35500290, grad/param norm = 6.4651e-02, time/batch = 0.0782s	
2486/4200 (epoch 29.595), train_loss = 1.35250558, grad/param norm = 6.2855e-02, time/batch = 0.0780s	
2487/4200 (epoch 29.607), train_loss = 1.33443891, grad/param norm = 6.3668e-02, time/batch = 0.0784s	
2488/4200 (epoch 29.619), train_loss = 1.33767985, grad/param norm = 5.3921e-02, time/batch = 0.0776s	
2489/4200 (epoch 29.631), train_loss = 1.33307512, grad/param norm = 5.0961e-02, time/batch = 0.0783s	
2490/4200 (epoch 29.643), train_loss = 1.34054615, grad/param norm = 5.8768e-02, time/batch = 0.0779s	
2491/4200 (epoch 29.655), train_loss = 1.35053517, grad/param norm = 5.9698e-02, time/batch = 0.0802s	
2492/4200 (epoch 29.667), train_loss = 1.36013598, grad/param norm = 5.7044e-02, time/batch = 0.0779s	
2493/4200 (epoch 29.679), train_loss = 1.35431509, grad/param norm = 5.4389e-02, time/batch = 0.0780s	
2494/4200 (epoch 29.690), train_loss = 1.34043087, grad/param norm = 5.7816e-02, time/batch = 0.0780s	
2495/4200 (epoch 29.702), train_loss = 1.33712944, grad/param norm = 6.8754e-02, time/batch = 0.0781s	
2496/4200 (epoch 29.714), train_loss = 1.36104611, grad/param norm = 6.9715e-02, time/batch = 0.0776s	
2497/4200 (epoch 29.726), train_loss = 1.36332916, grad/param norm = 5.9694e-02, time/batch = 0.0788s	
2498/4200 (epoch 29.738), train_loss = 1.34837491, grad/param norm = 5.5250e-02, time/batch = 0.0777s	
2499/4200 (epoch 29.750), train_loss = 1.36479133, grad/param norm = 5.6063e-02, time/batch = 0.0784s	
2500/4200 (epoch 29.762), train_loss = 1.35732548, grad/param norm = 6.1669e-02, time/batch = 0.0780s	
2501/4200 (epoch 29.774), train_loss = 1.36562222, grad/param norm = 6.1930e-02, time/batch = 0.0799s	
2502/4200 (epoch 29.786), train_loss = 1.34441686, grad/param norm = 5.6508e-02, time/batch = 0.0784s	
2503/4200 (epoch 29.798), train_loss = 1.35590904, grad/param norm = 4.9251e-02, time/batch = 0.0780s	
2504/4200 (epoch 29.810), train_loss = 1.36233449, grad/param norm = 5.2100e-02, time/batch = 0.0782s	
2505/4200 (epoch 29.821), train_loss = 1.34902493, grad/param norm = 6.1582e-02, time/batch = 0.0783s	
2506/4200 (epoch 29.833), train_loss = 1.36837101, grad/param norm = 7.4092e-02, time/batch = 0.0777s	
2507/4200 (epoch 29.845), train_loss = 1.37893910, grad/param norm = 8.3732e-02, time/batch = 0.0786s	
2508/4200 (epoch 29.857), train_loss = 1.38526582, grad/param norm = 8.4380e-02, time/batch = 0.0776s	
2509/4200 (epoch 29.869), train_loss = 1.38978585, grad/param norm = 6.6616e-02, time/batch = 0.0783s	
2510/4200 (epoch 29.881), train_loss = 1.36302830, grad/param norm = 5.4444e-02, time/batch = 0.0780s	
2511/4200 (epoch 29.893), train_loss = 1.37475245, grad/param norm = 5.6151e-02, time/batch = 0.0798s	
2512/4200 (epoch 29.905), train_loss = 1.35702613, grad/param norm = 5.4356e-02, time/batch = 0.0779s	
2513/4200 (epoch 29.917), train_loss = 1.36983310, grad/param norm = 5.6373e-02, time/batch = 0.0782s	
2514/4200 (epoch 29.929), train_loss = 1.35763205, grad/param norm = 5.2085e-02, time/batch = 0.0781s	
2515/4200 (epoch 29.940), train_loss = 1.36579937, grad/param norm = 5.2753e-02, time/batch = 0.0782s	
2516/4200 (epoch 29.952), train_loss = 1.37030731, grad/param norm = 6.0707e-02, time/batch = 0.0776s	
2517/4200 (epoch 29.964), train_loss = 1.37505228, grad/param norm = 7.1797e-02, time/batch = 0.0780s	
2518/4200 (epoch 29.976), train_loss = 1.36932025, grad/param norm = 7.1827e-02, time/batch = 0.0780s	
2519/4200 (epoch 29.988), train_loss = 1.36253754, grad/param norm = 6.1975e-02, time/batch = 0.0782s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
2520/4200 (epoch 30.000), train_loss = 1.40058842, grad/param norm = 5.6219e-02, time/batch = 0.0780s	
2521/4200 (epoch 30.012), train_loss = 1.52963543, grad/param norm = 7.1884e-02, time/batch = 0.0798s	
2522/4200 (epoch 30.024), train_loss = 1.34523446, grad/param norm = 6.5914e-02, time/batch = 0.0778s	
2523/4200 (epoch 30.036), train_loss = 1.35505910, grad/param norm = 5.9172e-02, time/batch = 0.0785s	
2524/4200 (epoch 30.048), train_loss = 1.32908301, grad/param norm = 5.5419e-02, time/batch = 0.0780s	
2525/4200 (epoch 30.060), train_loss = 1.35301628, grad/param norm = 6.0858e-02, time/batch = 0.0781s	
2526/4200 (epoch 30.071), train_loss = 1.34816182, grad/param norm = 6.0802e-02, time/batch = 0.0786s	
2527/4200 (epoch 30.083), train_loss = 1.34194301, grad/param norm = 6.0839e-02, time/batch = 0.0783s	
2528/4200 (epoch 30.095), train_loss = 1.33435789, grad/param norm = 5.2056e-02, time/batch = 0.0775s	
2529/4200 (epoch 30.107), train_loss = 1.34486345, grad/param norm = 5.6195e-02, time/batch = 0.0787s	
2530/4200 (epoch 30.119), train_loss = 1.34146578, grad/param norm = 5.5676e-02, time/batch = 0.0786s	
2531/4200 (epoch 30.131), train_loss = 1.34956505, grad/param norm = 5.6205e-02, time/batch = 0.0798s	
2532/4200 (epoch 30.143), train_loss = 1.35178607, grad/param norm = 5.5735e-02, time/batch = 0.0778s	
2533/4200 (epoch 30.155), train_loss = 1.33186460, grad/param norm = 5.5405e-02, time/batch = 0.0780s	
2534/4200 (epoch 30.167), train_loss = 1.35634256, grad/param norm = 7.1181e-02, time/batch = 0.0786s	
2535/4200 (epoch 30.179), train_loss = 1.36486319, grad/param norm = 7.0761e-02, time/batch = 0.0780s	
2536/4200 (epoch 30.190), train_loss = 1.34381593, grad/param norm = 6.8100e-02, time/batch = 0.0776s	
2537/4200 (epoch 30.202), train_loss = 1.37494756, grad/param norm = 7.2175e-02, time/batch = 0.0782s	
2538/4200 (epoch 30.214), train_loss = 1.35346846, grad/param norm = 6.5451e-02, time/batch = 0.0775s	
2539/4200 (epoch 30.226), train_loss = 1.35992133, grad/param norm = 5.9774e-02, time/batch = 0.0786s	
2540/4200 (epoch 30.238), train_loss = 1.34895485, grad/param norm = 6.0366e-02, time/batch = 0.0817s	
2541/4200 (epoch 30.250), train_loss = 1.33380419, grad/param norm = 5.6032e-02, time/batch = 0.0808s	
2542/4200 (epoch 30.262), train_loss = 1.30378034, grad/param norm = 5.2359e-02, time/batch = 0.0778s	
2543/4200 (epoch 30.274), train_loss = 1.35280625, grad/param norm = 5.4762e-02, time/batch = 0.0781s	
2544/4200 (epoch 30.286), train_loss = 1.35590926, grad/param norm = 5.0014e-02, time/batch = 0.0785s	
2545/4200 (epoch 30.298), train_loss = 1.32965349, grad/param norm = 5.9965e-02, time/batch = 0.0782s	
2546/4200 (epoch 30.310), train_loss = 1.36943133, grad/param norm = 6.1962e-02, time/batch = 0.0776s	
2547/4200 (epoch 30.321), train_loss = 1.31776847, grad/param norm = 5.2965e-02, time/batch = 0.0786s	
2548/4200 (epoch 30.333), train_loss = 1.34988996, grad/param norm = 5.1179e-02, time/batch = 0.0776s	
2549/4200 (epoch 30.345), train_loss = 1.33726784, grad/param norm = 5.4131e-02, time/batch = 0.0781s	
2550/4200 (epoch 30.357), train_loss = 1.34420509, grad/param norm = 5.9738e-02, time/batch = 0.0785s	
2551/4200 (epoch 30.369), train_loss = 1.35527381, grad/param norm = 6.3873e-02, time/batch = 0.0800s	
2552/4200 (epoch 30.381), train_loss = 1.35478384, grad/param norm = 6.0002e-02, time/batch = 0.0777s	
2553/4200 (epoch 30.393), train_loss = 1.37196781, grad/param norm = 5.9247e-02, time/batch = 0.0778s	
2554/4200 (epoch 30.405), train_loss = 1.36683270, grad/param norm = 5.6627e-02, time/batch = 0.0780s	
2555/4200 (epoch 30.417), train_loss = 1.32525225, grad/param norm = 6.0389e-02, time/batch = 0.0789s	
2556/4200 (epoch 30.429), train_loss = 1.33885196, grad/param norm = 5.5780e-02, time/batch = 0.0777s	
2557/4200 (epoch 30.440), train_loss = 1.35095670, grad/param norm = 5.3070e-02, time/batch = 0.0782s	
2558/4200 (epoch 30.452), train_loss = 1.35964052, grad/param norm = 5.9452e-02, time/batch = 0.0777s	
2559/4200 (epoch 30.464), train_loss = 1.35818317, grad/param norm = 6.3303e-02, time/batch = 0.0781s	
2560/4200 (epoch 30.476), train_loss = 1.37376224, grad/param norm = 6.7369e-02, time/batch = 0.0784s	
2561/4200 (epoch 30.488), train_loss = 1.37388338, grad/param norm = 8.4576e-02, time/batch = 0.0799s	
2562/4200 (epoch 30.500), train_loss = 1.34562576, grad/param norm = 7.8478e-02, time/batch = 0.0780s	
2563/4200 (epoch 30.512), train_loss = 1.35085652, grad/param norm = 6.3439e-02, time/batch = 0.0781s	
2564/4200 (epoch 30.524), train_loss = 1.32115445, grad/param norm = 5.4025e-02, time/batch = 0.0781s	
2565/4200 (epoch 30.536), train_loss = 1.33916673, grad/param norm = 5.3440e-02, time/batch = 0.0787s	
2566/4200 (epoch 30.548), train_loss = 1.33743534, grad/param norm = 5.6772e-02, time/batch = 0.0776s	
2567/4200 (epoch 30.560), train_loss = 1.36209264, grad/param norm = 5.9371e-02, time/batch = 0.0782s	
2568/4200 (epoch 30.571), train_loss = 1.31644244, grad/param norm = 5.5287e-02, time/batch = 0.0779s	
2569/4200 (epoch 30.583), train_loss = 1.34715803, grad/param norm = 5.2296e-02, time/batch = 0.0782s	
2570/4200 (epoch 30.595), train_loss = 1.34615041, grad/param norm = 5.6568e-02, time/batch = 0.0781s	
2571/4200 (epoch 30.607), train_loss = 1.32963948, grad/param norm = 6.6011e-02, time/batch = 0.0797s	
2572/4200 (epoch 30.619), train_loss = 1.33316075, grad/param norm = 5.9942e-02, time/batch = 0.0778s	
2573/4200 (epoch 30.631), train_loss = 1.32757983, grad/param norm = 5.2105e-02, time/batch = 0.0779s	
2574/4200 (epoch 30.643), train_loss = 1.33386295, grad/param norm = 5.1922e-02, time/batch = 0.0779s	
2575/4200 (epoch 30.655), train_loss = 1.34458177, grad/param norm = 5.7513e-02, time/batch = 0.0781s	
2576/4200 (epoch 30.667), train_loss = 1.35537686, grad/param norm = 6.0387e-02, time/batch = 0.0781s	
2577/4200 (epoch 30.679), train_loss = 1.34834760, grad/param norm = 5.2971e-02, time/batch = 0.0782s	
2578/4200 (epoch 30.690), train_loss = 1.33385244, grad/param norm = 5.0800e-02, time/batch = 0.0782s	
2579/4200 (epoch 30.702), train_loss = 1.32992089, grad/param norm = 6.1253e-02, time/batch = 0.0786s	
2580/4200 (epoch 30.714), train_loss = 1.35401036, grad/param norm = 6.3445e-02, time/batch = 0.0781s	
2581/4200 (epoch 30.726), train_loss = 1.35643818, grad/param norm = 5.2995e-02, time/batch = 0.0800s	
2582/4200 (epoch 30.738), train_loss = 1.34068377, grad/param norm = 4.7060e-02, time/batch = 0.0783s	
2583/4200 (epoch 30.750), train_loss = 1.35820971, grad/param norm = 5.0858e-02, time/batch = 0.0782s	
2584/4200 (epoch 30.762), train_loss = 1.35238295, grad/param norm = 6.2960e-02, time/batch = 0.0779s	
2585/4200 (epoch 30.774), train_loss = 1.36191221, grad/param norm = 6.8587e-02, time/batch = 0.0783s	
2586/4200 (epoch 30.786), train_loss = 1.34026527, grad/param norm = 6.3747e-02, time/batch = 0.0777s	
2587/4200 (epoch 30.798), train_loss = 1.35151801, grad/param norm = 5.3050e-02, time/batch = 0.0784s	
2588/4200 (epoch 30.810), train_loss = 1.35672068, grad/param norm = 5.1522e-02, time/batch = 0.0776s	
2589/4200 (epoch 30.821), train_loss = 1.34271388, grad/param norm = 5.3902e-02, time/batch = 0.0783s	
2590/4200 (epoch 30.833), train_loss = 1.35991503, grad/param norm = 6.1123e-02, time/batch = 0.0780s	
2591/4200 (epoch 30.845), train_loss = 1.37153385, grad/param norm = 7.5126e-02, time/batch = 0.0799s	
2592/4200 (epoch 30.857), train_loss = 1.37996830, grad/param norm = 8.8783e-02, time/batch = 0.0781s	
2593/4200 (epoch 30.869), train_loss = 1.38651268, grad/param norm = 8.0259e-02, time/batch = 0.0782s	
2594/4200 (epoch 30.881), train_loss = 1.35961760, grad/param norm = 6.5000e-02, time/batch = 0.0781s	
2595/4200 (epoch 30.893), train_loss = 1.37038269, grad/param norm = 6.0702e-02, time/batch = 0.0782s	
2596/4200 (epoch 30.905), train_loss = 1.35246366, grad/param norm = 5.5734e-02, time/batch = 0.0778s	
2597/4200 (epoch 30.917), train_loss = 1.36472413, grad/param norm = 5.8455e-02, time/batch = 0.0787s	
2598/4200 (epoch 30.929), train_loss = 1.35318574, grad/param norm = 5.6631e-02, time/batch = 0.0775s	
2599/4200 (epoch 30.940), train_loss = 1.36061793, grad/param norm = 5.7240e-02, time/batch = 0.0781s	
2600/4200 (epoch 30.952), train_loss = 1.36606039, grad/param norm = 6.6391e-02, time/batch = 0.0780s	
2601/4200 (epoch 30.964), train_loss = 1.37050995, grad/param norm = 7.4708e-02, time/batch = 0.0798s	
2602/4200 (epoch 30.976), train_loss = 1.36292037, grad/param norm = 6.7035e-02, time/batch = 0.0783s	
2603/4200 (epoch 30.988), train_loss = 1.35611988, grad/param norm = 5.6845e-02, time/batch = 0.0780s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
2604/4200 (epoch 31.000), train_loss = 1.39453415, grad/param norm = 5.5829e-02, time/batch = 0.0782s	
2605/4200 (epoch 31.012), train_loss = 1.52458779, grad/param norm = 7.2798e-02, time/batch = 0.0781s	
2606/4200 (epoch 31.024), train_loss = 1.33885885, grad/param norm = 6.3313e-02, time/batch = 0.0776s	
2607/4200 (epoch 31.036), train_loss = 1.34918369, grad/param norm = 5.6663e-02, time/batch = 0.0782s	
2608/4200 (epoch 31.048), train_loss = 1.32341113, grad/param norm = 5.4258e-02, time/batch = 0.0782s	
2609/4200 (epoch 31.060), train_loss = 1.34721251, grad/param norm = 5.8584e-02, time/batch = 0.0781s	
2610/4200 (epoch 31.071), train_loss = 1.34258963, grad/param norm = 5.9093e-02, time/batch = 0.0780s	
2611/4200 (epoch 31.083), train_loss = 1.33612602, grad/param norm = 5.9926e-02, time/batch = 0.0798s	
2612/4200 (epoch 31.095), train_loss = 1.32926362, grad/param norm = 5.2250e-02, time/batch = 0.0778s	
2613/4200 (epoch 31.107), train_loss = 1.33940324, grad/param norm = 5.5563e-02, time/batch = 0.0784s	
2614/4200 (epoch 31.119), train_loss = 1.33564324, grad/param norm = 5.4370e-02, time/batch = 0.0781s	
2615/4200 (epoch 31.131), train_loss = 1.34386196, grad/param norm = 5.5421e-02, time/batch = 0.0781s	
2616/4200 (epoch 31.143), train_loss = 1.34595843, grad/param norm = 5.4452e-02, time/batch = 0.0777s	
2617/4200 (epoch 31.155), train_loss = 1.32609252, grad/param norm = 5.2314e-02, time/batch = 0.0783s	
2618/4200 (epoch 31.167), train_loss = 1.34986917, grad/param norm = 6.6725e-02, time/batch = 0.0782s	
2619/4200 (epoch 31.179), train_loss = 1.35853670, grad/param norm = 6.6535e-02, time/batch = 0.0782s	
2620/4200 (epoch 31.190), train_loss = 1.33745176, grad/param norm = 6.5166e-02, time/batch = 0.0778s	
2621/4200 (epoch 31.202), train_loss = 1.36868713, grad/param norm = 6.9196e-02, time/batch = 0.0797s	
2622/4200 (epoch 31.214), train_loss = 1.34740159, grad/param norm = 6.2544e-02, time/batch = 0.0777s	
2623/4200 (epoch 31.226), train_loss = 1.35424611, grad/param norm = 5.7933e-02, time/batch = 0.0784s	
2624/4200 (epoch 31.238), train_loss = 1.34319607, grad/param norm = 5.8973e-02, time/batch = 0.0781s	
2625/4200 (epoch 31.250), train_loss = 1.32862146, grad/param norm = 5.5125e-02, time/batch = 0.0784s	
2626/4200 (epoch 31.262), train_loss = 1.29827421, grad/param norm = 5.1745e-02, time/batch = 0.0779s	
2627/4200 (epoch 31.274), train_loss = 1.34693554, grad/param norm = 5.3800e-02, time/batch = 0.0782s	
2628/4200 (epoch 31.286), train_loss = 1.35030681, grad/param norm = 4.8527e-02, time/batch = 0.0776s	
2629/4200 (epoch 31.298), train_loss = 1.32398329, grad/param norm = 5.8387e-02, time/batch = 0.0788s	
2630/4200 (epoch 31.310), train_loss = 1.36367870, grad/param norm = 5.9777e-02, time/batch = 0.0780s	
2631/4200 (epoch 31.321), train_loss = 1.31225518, grad/param norm = 5.2134e-02, time/batch = 0.0800s	
2632/4200 (epoch 31.333), train_loss = 1.34440124, grad/param norm = 5.1993e-02, time/batch = 0.0781s	
2633/4200 (epoch 31.345), train_loss = 1.33211030, grad/param norm = 5.6093e-02, time/batch = 0.0779s	
2634/4200 (epoch 31.357), train_loss = 1.33912586, grad/param norm = 6.0499e-02, time/batch = 0.0784s	
2635/4200 (epoch 31.369), train_loss = 1.34966538, grad/param norm = 6.4364e-02, time/batch = 0.0784s	
2636/4200 (epoch 31.381), train_loss = 1.34924075, grad/param norm = 6.0330e-02, time/batch = 0.0779s	
2637/4200 (epoch 31.393), train_loss = 1.36717929, grad/param norm = 6.2381e-02, time/batch = 0.0784s	
2638/4200 (epoch 31.405), train_loss = 1.36296173, grad/param norm = 6.0826e-02, time/batch = 0.0776s	
2639/4200 (epoch 31.417), train_loss = 1.32041911, grad/param norm = 6.3879e-02, time/batch = 0.0781s	
2640/4200 (epoch 31.429), train_loss = 1.33395714, grad/param norm = 5.7536e-02, time/batch = 0.0777s	
2641/4200 (epoch 31.440), train_loss = 1.34584449, grad/param norm = 5.4116e-02, time/batch = 0.0797s	
2642/4200 (epoch 31.452), train_loss = 1.35417461, grad/param norm = 6.0421e-02, time/batch = 0.0777s	
2643/4200 (epoch 31.464), train_loss = 1.35274157, grad/param norm = 6.1869e-02, time/batch = 0.0781s	
2644/4200 (epoch 31.476), train_loss = 1.36687462, grad/param norm = 6.0186e-02, time/batch = 0.0781s	
2645/4200 (epoch 31.488), train_loss = 1.36534477, grad/param norm = 7.2342e-02, time/batch = 0.0782s	
2646/4200 (epoch 31.500), train_loss = 1.33736018, grad/param norm = 6.7185e-02, time/batch = 0.0803s	
2647/4200 (epoch 31.512), train_loss = 1.34371983, grad/param norm = 5.6117e-02, time/batch = 0.0783s	
2648/4200 (epoch 31.524), train_loss = 1.31583972, grad/param norm = 5.2384e-02, time/batch = 0.0777s	
2649/4200 (epoch 31.536), train_loss = 1.33399144, grad/param norm = 5.4706e-02, time/batch = 0.0782s	
2650/4200 (epoch 31.548), train_loss = 1.33255780, grad/param norm = 5.7526e-02, time/batch = 0.0784s	
2651/4200 (epoch 31.560), train_loss = 1.35675261, grad/param norm = 5.7446e-02, time/batch = 0.0799s	
2652/4200 (epoch 31.571), train_loss = 1.31073289, grad/param norm = 5.2390e-02, time/batch = 0.0779s	
2653/4200 (epoch 31.583), train_loss = 1.34146379, grad/param norm = 5.0199e-02, time/batch = 0.0780s	
2654/4200 (epoch 31.595), train_loss = 1.34007146, grad/param norm = 5.3245e-02, time/batch = 0.0778s	
2655/4200 (epoch 31.607), train_loss = 1.32326381, grad/param norm = 6.0902e-02, time/batch = 0.0785s	
2656/4200 (epoch 31.619), train_loss = 1.32709067, grad/param norm = 5.5391e-02, time/batch = 0.0777s	
2657/4200 (epoch 31.631), train_loss = 1.32189902, grad/param norm = 4.9488e-02, time/batch = 0.0783s	
2658/4200 (epoch 31.643), train_loss = 1.32843703, grad/param norm = 5.2283e-02, time/batch = 0.0777s	
2659/4200 (epoch 31.655), train_loss = 1.33991660, grad/param norm = 5.9097e-02, time/batch = 0.0782s	
2660/4200 (epoch 31.667), train_loss = 1.35037527, grad/param norm = 6.1960e-02, time/batch = 0.0780s	
2661/4200 (epoch 31.679), train_loss = 1.34313812, grad/param norm = 5.2504e-02, time/batch = 0.0798s	
2662/4200 (epoch 31.690), train_loss = 1.32892139, grad/param norm = 5.1379e-02, time/batch = 0.0778s	
2663/4200 (epoch 31.702), train_loss = 1.32476685, grad/param norm = 6.2278e-02, time/batch = 0.0780s	
2664/4200 (epoch 31.714), train_loss = 1.34889231, grad/param norm = 6.4126e-02, time/batch = 0.0780s	
2665/4200 (epoch 31.726), train_loss = 1.35184967, grad/param norm = 5.5318e-02, time/batch = 0.0782s	
2666/4200 (epoch 31.738), train_loss = 1.33597797, grad/param norm = 5.4947e-02, time/batch = 0.0779s	
2667/4200 (epoch 31.750), train_loss = 1.35543545, grad/param norm = 6.1010e-02, time/batch = 0.0783s	
2668/4200 (epoch 31.762), train_loss = 1.34950988, grad/param norm = 7.4478e-02, time/batch = 0.0778s	
2669/4200 (epoch 31.774), train_loss = 1.35927710, grad/param norm = 7.7414e-02, time/batch = 0.0782s	
2670/4200 (epoch 31.786), train_loss = 1.33575622, grad/param norm = 6.6885e-02, time/batch = 0.0778s	
2671/4200 (epoch 31.798), train_loss = 1.34630819, grad/param norm = 5.3239e-02, time/batch = 0.0803s	
2672/4200 (epoch 31.810), train_loss = 1.35165149, grad/param norm = 5.3460e-02, time/batch = 0.0776s	
2673/4200 (epoch 31.821), train_loss = 1.33958517, grad/param norm = 6.7375e-02, time/batch = 0.0780s	
2674/4200 (epoch 31.833), train_loss = 1.35903791, grad/param norm = 8.0798e-02, time/batch = 0.0780s	
2675/4200 (epoch 31.845), train_loss = 1.36787170, grad/param norm = 8.2863e-02, time/batch = 0.0782s	
2676/4200 (epoch 31.857), train_loss = 1.37215793, grad/param norm = 7.7480e-02, time/batch = 0.0782s	
2677/4200 (epoch 31.869), train_loss = 1.37651638, grad/param norm = 5.8635e-02, time/batch = 0.0783s	
2678/4200 (epoch 31.881), train_loss = 1.35100188, grad/param norm = 5.1839e-02, time/batch = 0.0778s	
2679/4200 (epoch 31.893), train_loss = 1.36257551, grad/param norm = 5.4809e-02, time/batch = 0.0783s	
2680/4200 (epoch 31.905), train_loss = 1.34602511, grad/param norm = 5.3197e-02, time/batch = 0.0779s	
2681/4200 (epoch 31.917), train_loss = 1.35846601, grad/param norm = 5.6809e-02, time/batch = 0.0803s	
2682/4200 (epoch 31.929), train_loss = 1.34688161, grad/param norm = 5.3657e-02, time/batch = 0.0777s	
2683/4200 (epoch 31.940), train_loss = 1.35509353, grad/param norm = 5.1916e-02, time/batch = 0.0779s	
2684/4200 (epoch 31.952), train_loss = 1.35954129, grad/param norm = 5.7769e-02, time/batch = 0.0781s	
2685/4200 (epoch 31.964), train_loss = 1.36347997, grad/param norm = 6.6722e-02, time/batch = 0.0783s	
2686/4200 (epoch 31.976), train_loss = 1.35652824, grad/param norm = 6.5151e-02, time/batch = 0.0775s	
2687/4200 (epoch 31.988), train_loss = 1.35066914, grad/param norm = 5.8382e-02, time/batch = 0.0786s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
2688/4200 (epoch 32.000), train_loss = 1.38899844, grad/param norm = 5.5424e-02, time/batch = 0.0781s	
2689/4200 (epoch 32.012), train_loss = 1.52025292, grad/param norm = 7.0649e-02, time/batch = 0.0782s	
2690/4200 (epoch 32.024), train_loss = 1.33442005, grad/param norm = 6.6243e-02, time/batch = 0.0782s	
2691/4200 (epoch 32.036), train_loss = 1.34426607, grad/param norm = 5.9086e-02, time/batch = 0.0797s	
2692/4200 (epoch 32.048), train_loss = 1.31829784, grad/param norm = 5.2911e-02, time/batch = 0.0782s	
2693/4200 (epoch 32.060), train_loss = 1.34219298, grad/param norm = 5.8306e-02, time/batch = 0.0779s	
2694/4200 (epoch 32.071), train_loss = 1.33734031, grad/param norm = 5.8956e-02, time/batch = 0.0780s	
2695/4200 (epoch 32.083), train_loss = 1.33067539, grad/param norm = 5.9304e-02, time/batch = 0.0782s	
2696/4200 (epoch 32.095), train_loss = 1.32435865, grad/param norm = 5.0936e-02, time/batch = 0.0776s	
2697/4200 (epoch 32.107), train_loss = 1.33435348, grad/param norm = 5.4519e-02, time/batch = 0.0782s	
2698/4200 (epoch 32.119), train_loss = 1.33041568, grad/param norm = 5.3302e-02, time/batch = 0.0777s	
2699/4200 (epoch 32.131), train_loss = 1.33842742, grad/param norm = 5.4372e-02, time/batch = 0.0783s	
2700/4200 (epoch 32.143), train_loss = 1.34056250, grad/param norm = 5.3323e-02, time/batch = 0.0780s	
2701/4200 (epoch 32.155), train_loss = 1.32115105, grad/param norm = 5.2128e-02, time/batch = 0.0797s	
2702/4200 (epoch 32.167), train_loss = 1.34491433, grad/param norm = 6.7559e-02, time/batch = 0.0777s	
2703/4200 (epoch 32.179), train_loss = 1.35363531, grad/param norm = 6.7582e-02, time/batch = 0.0786s	
2704/4200 (epoch 32.190), train_loss = 1.33191507, grad/param norm = 6.1954e-02, time/batch = 0.0779s	
2705/4200 (epoch 32.202), train_loss = 1.36283744, grad/param norm = 6.4848e-02, time/batch = 0.0782s	
2706/4200 (epoch 32.214), train_loss = 1.34241899, grad/param norm = 6.0958e-02, time/batch = 0.0775s	
2707/4200 (epoch 32.226), train_loss = 1.34900718, grad/param norm = 5.4977e-02, time/batch = 0.0782s	
2708/4200 (epoch 32.238), train_loss = 1.33783580, grad/param norm = 5.6559e-02, time/batch = 0.0779s	
2709/4200 (epoch 32.250), train_loss = 1.32378851, grad/param norm = 5.6094e-02, time/batch = 0.0782s	
2710/4200 (epoch 32.262), train_loss = 1.29407760, grad/param norm = 5.4999e-02, time/batch = 0.0783s	
2711/4200 (epoch 32.274), train_loss = 1.34164665, grad/param norm = 5.5235e-02, time/batch = 0.0798s	
2712/4200 (epoch 32.286), train_loss = 1.34568377, grad/param norm = 4.8999e-02, time/batch = 0.0778s	
2713/4200 (epoch 32.298), train_loss = 1.31930840, grad/param norm = 5.9839e-02, time/batch = 0.0783s	
2714/4200 (epoch 32.310), train_loss = 1.35891602, grad/param norm = 6.0719e-02, time/batch = 0.0780s	
2715/4200 (epoch 32.321), train_loss = 1.30780728, grad/param norm = 5.5236e-02, time/batch = 0.0782s	
2716/4200 (epoch 32.333), train_loss = 1.34013021, grad/param norm = 5.6948e-02, time/batch = 0.0781s	
2717/4200 (epoch 32.345), train_loss = 1.32806132, grad/param norm = 6.2103e-02, time/batch = 0.0782s	
2718/4200 (epoch 32.357), train_loss = 1.33511457, grad/param norm = 6.4658e-02, time/batch = 0.0775s	
2719/4200 (epoch 32.369), train_loss = 1.34484316, grad/param norm = 6.6127e-02, time/batch = 0.0788s	
2720/4200 (epoch 32.381), train_loss = 1.34396068, grad/param norm = 6.1963e-02, time/batch = 0.0782s	
2721/4200 (epoch 32.393), train_loss = 1.36318532, grad/param norm = 6.7346e-02, time/batch = 0.0799s	
2722/4200 (epoch 32.405), train_loss = 1.35900470, grad/param norm = 6.3471e-02, time/batch = 0.0776s	
2723/4200 (epoch 32.417), train_loss = 1.31520127, grad/param norm = 6.2859e-02, time/batch = 0.0780s	
2724/4200 (epoch 32.429), train_loss = 1.32825413, grad/param norm = 5.4336e-02, time/batch = 0.0784s	
2725/4200 (epoch 32.440), train_loss = 1.34053826, grad/param norm = 4.8695e-02, time/batch = 0.0782s	
2726/4200 (epoch 32.452), train_loss = 1.34715836, grad/param norm = 5.2327e-02, time/batch = 0.0776s	
2727/4200 (epoch 32.464), train_loss = 1.34635541, grad/param norm = 5.4195e-02, time/batch = 0.0782s	
2728/4200 (epoch 32.476), train_loss = 1.36022655, grad/param norm = 5.1750e-02, time/batch = 0.0776s	
2729/4200 (epoch 32.488), train_loss = 1.35804784, grad/param norm = 6.2380e-02, time/batch = 0.0785s	
2730/4200 (epoch 32.500), train_loss = 1.33025709, grad/param norm = 5.7058e-02, time/batch = 0.0777s	
2731/4200 (epoch 32.512), train_loss = 1.33689772, grad/param norm = 4.7727e-02, time/batch = 0.0798s	
2732/4200 (epoch 32.524), train_loss = 1.31057235, grad/param norm = 4.7033e-02, time/batch = 0.0776s	
2733/4200 (epoch 32.536), train_loss = 1.32825637, grad/param norm = 5.2984e-02, time/batch = 0.0778s	
2734/4200 (epoch 32.548), train_loss = 1.32770100, grad/param norm = 5.8252e-02, time/batch = 0.0784s	
2735/4200 (epoch 32.560), train_loss = 1.35186985, grad/param norm = 5.8624e-02, time/batch = 0.0782s	
2736/4200 (epoch 32.571), train_loss = 1.30625069, grad/param norm = 5.4557e-02, time/batch = 0.0776s	
2737/4200 (epoch 32.583), train_loss = 1.33704966, grad/param norm = 5.3090e-02, time/batch = 0.0793s	
2738/4200 (epoch 32.595), train_loss = 1.33498406, grad/param norm = 5.3831e-02, time/batch = 0.0778s	
2739/4200 (epoch 32.607), train_loss = 1.31767477, grad/param norm = 5.8485e-02, time/batch = 0.0782s	
2740/4200 (epoch 32.619), train_loss = 1.32159742, grad/param norm = 5.2591e-02, time/batch = 0.0784s	
2741/4200 (epoch 32.631), train_loss = 1.31708453, grad/param norm = 4.8852e-02, time/batch = 0.0813s	
2742/4200 (epoch 32.643), train_loss = 1.32372926, grad/param norm = 5.6444e-02, time/batch = 0.0783s	
2743/4200 (epoch 32.655), train_loss = 1.33595819, grad/param norm = 6.3346e-02, time/batch = 0.0780s	
2744/4200 (epoch 32.667), train_loss = 1.34613917, grad/param norm = 6.6336e-02, time/batch = 0.0781s	
2745/4200 (epoch 32.679), train_loss = 1.33892386, grad/param norm = 5.5574e-02, time/batch = 0.0788s	
2746/4200 (epoch 32.690), train_loss = 1.32556820, grad/param norm = 5.7648e-02, time/batch = 0.0778s	
2747/4200 (epoch 32.702), train_loss = 1.32094910, grad/param norm = 6.8593e-02, time/batch = 0.0784s	
2748/4200 (epoch 32.714), train_loss = 1.34459809, grad/param norm = 6.7879e-02, time/batch = 0.0776s	
2749/4200 (epoch 32.726), train_loss = 1.34771800, grad/param norm = 5.9353e-02, time/batch = 0.0780s	
2750/4200 (epoch 32.738), train_loss = 1.33148495, grad/param norm = 6.0947e-02, time/batch = 0.0784s	
2751/4200 (epoch 32.750), train_loss = 1.35074913, grad/param norm = 6.2581e-02, time/batch = 0.0826s	
2752/4200 (epoch 32.762), train_loss = 1.34253615, grad/param norm = 6.6372e-02, time/batch = 0.0797s	
2753/4200 (epoch 32.774), train_loss = 1.35152533, grad/param norm = 6.6224e-02, time/batch = 0.0782s	
2754/4200 (epoch 32.786), train_loss = 1.32915814, grad/param norm = 5.9851e-02, time/batch = 0.0780s	
2755/4200 (epoch 32.798), train_loss = 1.34026258, grad/param norm = 5.1725e-02, time/batch = 0.0784s	
2756/4200 (epoch 32.810), train_loss = 1.34729945, grad/param norm = 5.6259e-02, time/batch = 0.0775s	
2757/4200 (epoch 32.821), train_loss = 1.33465973, grad/param norm = 6.7501e-02, time/batch = 0.0782s	
2758/4200 (epoch 32.833), train_loss = 1.35289694, grad/param norm = 7.3326e-02, time/batch = 0.0778s	
2759/4200 (epoch 32.845), train_loss = 1.35986788, grad/param norm = 6.9504e-02, time/batch = 0.0782s	
2760/4200 (epoch 32.857), train_loss = 1.36451544, grad/param norm = 6.5779e-02, time/batch = 0.0779s	
2761/4200 (epoch 32.869), train_loss = 1.37031783, grad/param norm = 5.4689e-02, time/batch = 0.0805s	
2762/4200 (epoch 32.881), train_loss = 1.34599541, grad/param norm = 5.2725e-02, time/batch = 0.0778s	
2763/4200 (epoch 32.893), train_loss = 1.35765533, grad/param norm = 5.5958e-02, time/batch = 0.0781s	
2764/4200 (epoch 32.905), train_loss = 1.34138170, grad/param norm = 5.4327e-02, time/batch = 0.0781s	
2765/4200 (epoch 32.917), train_loss = 1.35333775, grad/param norm = 5.6146e-02, time/batch = 0.0781s	
2766/4200 (epoch 32.929), train_loss = 1.34161993, grad/param norm = 5.0299e-02, time/batch = 0.0780s	
2767/4200 (epoch 32.940), train_loss = 1.34962273, grad/param norm = 4.9506e-02, time/batch = 0.0781s	
2768/4200 (epoch 32.952), train_loss = 1.35517592, grad/param norm = 5.9970e-02, time/batch = 0.0775s	
2769/4200 (epoch 32.964), train_loss = 1.35973346, grad/param norm = 7.6303e-02, time/batch = 0.0782s	
2770/4200 (epoch 32.976), train_loss = 1.35316004, grad/param norm = 7.1637e-02, time/batch = 0.0779s	
2771/4200 (epoch 32.988), train_loss = 1.34636166, grad/param norm = 5.9938e-02, time/batch = 0.0800s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
2772/4200 (epoch 33.000), train_loss = 1.38452280, grad/param norm = 5.7120e-02, time/batch = 0.0777s	
2773/4200 (epoch 33.012), train_loss = 1.51626559, grad/param norm = 7.3636e-02, time/batch = 0.0780s	
2774/4200 (epoch 33.024), train_loss = 1.32912254, grad/param norm = 6.4019e-02, time/batch = 0.0783s	
2775/4200 (epoch 33.036), train_loss = 1.33886034, grad/param norm = 5.5931e-02, time/batch = 0.0782s	
2776/4200 (epoch 33.048), train_loss = 1.31392491, grad/param norm = 5.4671e-02, time/batch = 0.0778s	
2777/4200 (epoch 33.060), train_loss = 1.33770038, grad/param norm = 5.9701e-02, time/batch = 0.0787s	
2778/4200 (epoch 33.071), train_loss = 1.33215463, grad/param norm = 5.5769e-02, time/batch = 0.0776s	
2779/4200 (epoch 33.083), train_loss = 1.32517235, grad/param norm = 5.5309e-02, time/batch = 0.0783s	
2780/4200 (epoch 33.095), train_loss = 1.31970238, grad/param norm = 5.0373e-02, time/batch = 0.0781s	
2781/4200 (epoch 33.107), train_loss = 1.32971169, grad/param norm = 5.5545e-02, time/batch = 0.0797s	
2782/4200 (epoch 33.119), train_loss = 1.32539668, grad/param norm = 5.2688e-02, time/batch = 0.0783s	
2783/4200 (epoch 33.131), train_loss = 1.33330591, grad/param norm = 5.2928e-02, time/batch = 0.0780s	
2784/4200 (epoch 33.143), train_loss = 1.33549624, grad/param norm = 5.2392e-02, time/batch = 0.0781s	
2785/4200 (epoch 33.155), train_loss = 1.31697623, grad/param norm = 5.4137e-02, time/batch = 0.0780s	
2786/4200 (epoch 33.167), train_loss = 1.34076582, grad/param norm = 7.0516e-02, time/batch = 0.0776s	
2787/4200 (epoch 33.179), train_loss = 1.34914633, grad/param norm = 6.8051e-02, time/batch = 0.0786s	
2788/4200 (epoch 33.190), train_loss = 1.32701380, grad/param norm = 6.1361e-02, time/batch = 0.0775s	
2789/4200 (epoch 33.202), train_loss = 1.35781215, grad/param norm = 6.4409e-02, time/batch = 0.0781s	
2790/4200 (epoch 33.214), train_loss = 1.33690484, grad/param norm = 5.9417e-02, time/batch = 0.0779s	
2791/4200 (epoch 33.226), train_loss = 1.34411948, grad/param norm = 5.5424e-02, time/batch = 0.0798s	
2792/4200 (epoch 33.238), train_loss = 1.33297299, grad/param norm = 5.6216e-02, time/batch = 0.0781s	
2793/4200 (epoch 33.250), train_loss = 1.31902874, grad/param norm = 5.4781e-02, time/batch = 0.0781s	
2794/4200 (epoch 33.262), train_loss = 1.28898750, grad/param norm = 5.3656e-02, time/batch = 0.0782s	
2795/4200 (epoch 33.274), train_loss = 1.33640898, grad/param norm = 5.3624e-02, time/batch = 0.0783s	
2796/4200 (epoch 33.286), train_loss = 1.34045527, grad/param norm = 4.8043e-02, time/batch = 0.0776s	
2797/4200 (epoch 33.298), train_loss = 1.31440104, grad/param norm = 6.0127e-02, time/batch = 0.0783s	
2798/4200 (epoch 33.310), train_loss = 1.35384149, grad/param norm = 5.9573e-02, time/batch = 0.0781s	
2799/4200 (epoch 33.321), train_loss = 1.30271096, grad/param norm = 5.2982e-02, time/batch = 0.0780s	
2800/4200 (epoch 33.333), train_loss = 1.33431877, grad/param norm = 5.3395e-02, time/batch = 0.0782s	
2801/4200 (epoch 33.345), train_loss = 1.32214547, grad/param norm = 5.6708e-02, time/batch = 0.0797s	
2802/4200 (epoch 33.357), train_loss = 1.32936329, grad/param norm = 5.8920e-02, time/batch = 0.0777s	
2803/4200 (epoch 33.369), train_loss = 1.33891927, grad/param norm = 6.0293e-02, time/batch = 0.0785s	
2804/4200 (epoch 33.381), train_loss = 1.33794079, grad/param norm = 5.7359e-02, time/batch = 0.0781s	
2805/4200 (epoch 33.393), train_loss = 1.35782416, grad/param norm = 6.3446e-02, time/batch = 0.0783s	
2806/4200 (epoch 33.405), train_loss = 1.35366395, grad/param norm = 5.9302e-02, time/batch = 0.0776s	
2807/4200 (epoch 33.417), train_loss = 1.30961798, grad/param norm = 5.9162e-02, time/batch = 0.0781s	
2808/4200 (epoch 33.429), train_loss = 1.32330361, grad/param norm = 5.2045e-02, time/batch = 0.0780s	
2809/4200 (epoch 33.440), train_loss = 1.33563402, grad/param norm = 4.8549e-02, time/batch = 0.0784s	
2810/4200 (epoch 33.452), train_loss = 1.34231666, grad/param norm = 5.4196e-02, time/batch = 0.0779s	
2811/4200 (epoch 33.464), train_loss = 1.34209971, grad/param norm = 5.6649e-02, time/batch = 0.0800s	
2812/4200 (epoch 33.476), train_loss = 1.35598662, grad/param norm = 5.3104e-02, time/batch = 0.0782s	
2813/4200 (epoch 33.488), train_loss = 1.35376380, grad/param norm = 6.5297e-02, time/batch = 0.0780s	
2814/4200 (epoch 33.500), train_loss = 1.32594304, grad/param norm = 5.9272e-02, time/batch = 0.0780s	
2815/4200 (epoch 33.512), train_loss = 1.33221356, grad/param norm = 4.8746e-02, time/batch = 0.0782s	
2816/4200 (epoch 33.524), train_loss = 1.30616758, grad/param norm = 4.5670e-02, time/batch = 0.0776s	
2817/4200 (epoch 33.536), train_loss = 1.32311371, grad/param norm = 5.0395e-02, time/batch = 0.0783s	
2818/4200 (epoch 33.548), train_loss = 1.32270582, grad/param norm = 5.5029e-02, time/batch = 0.0777s	
2819/4200 (epoch 33.560), train_loss = 1.34656420, grad/param norm = 5.5762e-02, time/batch = 0.0786s	
2820/4200 (epoch 33.571), train_loss = 1.30100221, grad/param norm = 5.1673e-02, time/batch = 0.0781s	
2821/4200 (epoch 33.583), train_loss = 1.33185501, grad/param norm = 5.1332e-02, time/batch = 0.0798s	
2822/4200 (epoch 33.595), train_loss = 1.32984445, grad/param norm = 5.2382e-02, time/batch = 0.0781s	
2823/4200 (epoch 33.607), train_loss = 1.31272933, grad/param norm = 5.7615e-02, time/batch = 0.0781s	
2824/4200 (epoch 33.619), train_loss = 1.31688198, grad/param norm = 5.1321e-02, time/batch = 0.0785s	
2825/4200 (epoch 33.631), train_loss = 1.31183108, grad/param norm = 4.6772e-02, time/batch = 0.0781s	
2826/4200 (epoch 33.643), train_loss = 1.31819459, grad/param norm = 5.1865e-02, time/batch = 0.0775s	
2827/4200 (epoch 33.655), train_loss = 1.33055945, grad/param norm = 5.8244e-02, time/batch = 0.0783s	
2828/4200 (epoch 33.667), train_loss = 1.34074725, grad/param norm = 6.2026e-02, time/batch = 0.0777s	
2829/4200 (epoch 33.679), train_loss = 1.33376388, grad/param norm = 5.3190e-02, time/batch = 0.0782s	
2830/4200 (epoch 33.690), train_loss = 1.32030203, grad/param norm = 5.3658e-02, time/batch = 0.0786s	
2831/4200 (epoch 33.702), train_loss = 1.31537919, grad/param norm = 6.3995e-02, time/batch = 0.0797s	
2832/4200 (epoch 33.714), train_loss = 1.33893267, grad/param norm = 6.4092e-02, time/batch = 0.0776s	
2833/4200 (epoch 33.726), train_loss = 1.34238020, grad/param norm = 5.6089e-02, time/batch = 0.0780s	
2834/4200 (epoch 33.738), train_loss = 1.32587946, grad/param norm = 5.7533e-02, time/batch = 0.0778s	
2835/4200 (epoch 33.750), train_loss = 1.34578657, grad/param norm = 6.0653e-02, time/batch = 0.0785s	
2836/4200 (epoch 33.762), train_loss = 1.33818722, grad/param norm = 6.6911e-02, time/batch = 0.0776s	
2837/4200 (epoch 33.774), train_loss = 1.34698398, grad/param norm = 6.7393e-02, time/batch = 0.0782s	
2838/4200 (epoch 33.786), train_loss = 1.32464502, grad/param norm = 6.0681e-02, time/batch = 0.0775s	
2839/4200 (epoch 33.798), train_loss = 1.33543557, grad/param norm = 5.1999e-02, time/batch = 0.0784s	
2840/4200 (epoch 33.810), train_loss = 1.34274541, grad/param norm = 5.6562e-02, time/batch = 0.0783s	
2841/4200 (epoch 33.821), train_loss = 1.33051795, grad/param norm = 6.9529e-02, time/batch = 0.0800s	
2842/4200 (epoch 33.833), train_loss = 1.34897107, grad/param norm = 7.6103e-02, time/batch = 0.0779s	
2843/4200 (epoch 33.845), train_loss = 1.35547935, grad/param norm = 7.1959e-02, time/batch = 0.0790s	
2844/4200 (epoch 33.857), train_loss = 1.36005647, grad/param norm = 6.7043e-02, time/batch = 0.0781s	
2845/4200 (epoch 33.869), train_loss = 1.36549323, grad/param norm = 5.4733e-02, time/batch = 0.0787s	
2846/4200 (epoch 33.881), train_loss = 1.34124857, grad/param norm = 5.2636e-02, time/batch = 0.0779s	
2847/4200 (epoch 33.893), train_loss = 1.35263485, grad/param norm = 5.5302e-02, time/batch = 0.0784s	
2848/4200 (epoch 33.905), train_loss = 1.33662011, grad/param norm = 5.2991e-02, time/batch = 0.0776s	
2849/4200 (epoch 33.917), train_loss = 1.34824064, grad/param norm = 5.4880e-02, time/batch = 0.0781s	
2850/4200 (epoch 33.929), train_loss = 1.33702085, grad/param norm = 5.0291e-02, time/batch = 0.0778s	
2851/4200 (epoch 33.940), train_loss = 1.34494037, grad/param norm = 5.0661e-02, time/batch = 0.0797s	
2852/4200 (epoch 33.952), train_loss = 1.35119402, grad/param norm = 6.2788e-02, time/batch = 0.0776s	
2853/4200 (epoch 33.964), train_loss = 1.35552292, grad/param norm = 7.9300e-02, time/batch = 0.0779s	
2854/4200 (epoch 33.976), train_loss = 1.34826448, grad/param norm = 6.9654e-02, time/batch = 0.0782s	
2855/4200 (epoch 33.988), train_loss = 1.34117280, grad/param norm = 5.7144e-02, time/batch = 0.0782s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
2856/4200 (epoch 34.000), train_loss = 1.37929513, grad/param norm = 5.6152e-02, time/batch = 0.0780s	
2857/4200 (epoch 34.012), train_loss = 1.51203470, grad/param norm = 7.3301e-02, time/batch = 0.0804s	
2858/4200 (epoch 34.024), train_loss = 1.32401026, grad/param norm = 6.1612e-02, time/batch = 0.0779s	
2859/4200 (epoch 34.036), train_loss = 1.33383728, grad/param norm = 5.3918e-02, time/batch = 0.0781s	
2860/4200 (epoch 34.048), train_loss = 1.30911404, grad/param norm = 5.3110e-02, time/batch = 0.0779s	
2861/4200 (epoch 34.060), train_loss = 1.33287735, grad/param norm = 5.7751e-02, time/batch = 0.0803s	
2862/4200 (epoch 34.071), train_loss = 1.32741860, grad/param norm = 5.4523e-02, time/batch = 0.0779s	
2863/4200 (epoch 34.083), train_loss = 1.32051845, grad/param norm = 5.4939e-02, time/batch = 0.0781s	
2864/4200 (epoch 34.095), train_loss = 1.31541173, grad/param norm = 5.0545e-02, time/batch = 0.0781s	
2865/4200 (epoch 34.107), train_loss = 1.32535496, grad/param norm = 5.5099e-02, time/batch = 0.0783s	
2866/4200 (epoch 34.119), train_loss = 1.32067722, grad/param norm = 5.1628e-02, time/batch = 0.0774s	
2867/4200 (epoch 34.131), train_loss = 1.32852062, grad/param norm = 5.2010e-02, time/batch = 0.0783s	
2868/4200 (epoch 34.143), train_loss = 1.33053732, grad/param norm = 5.0966e-02, time/batch = 0.0776s	
2869/4200 (epoch 34.155), train_loss = 1.31232918, grad/param norm = 5.2217e-02, time/batch = 0.0781s	
2870/4200 (epoch 34.167), train_loss = 1.33565459, grad/param norm = 6.7859e-02, time/batch = 0.0778s	
2871/4200 (epoch 34.179), train_loss = 1.34409195, grad/param norm = 6.5015e-02, time/batch = 0.0798s	
2872/4200 (epoch 34.190), train_loss = 1.32176070, grad/param norm = 5.8549e-02, time/batch = 0.0777s	
2873/4200 (epoch 34.202), train_loss = 1.35254430, grad/param norm = 6.2052e-02, time/batch = 0.0778s	
2874/4200 (epoch 34.214), train_loss = 1.33220182, grad/param norm = 5.8169e-02, time/batch = 0.0778s	
2875/4200 (epoch 34.226), train_loss = 1.33960515, grad/param norm = 5.5018e-02, time/batch = 0.0784s	
2876/4200 (epoch 34.238), train_loss = 1.32850860, grad/param norm = 5.5928e-02, time/batch = 0.0774s	
2877/4200 (epoch 34.250), train_loss = 1.31477795, grad/param norm = 5.4946e-02, time/batch = 0.0788s	
2878/4200 (epoch 34.262), train_loss = 1.28465452, grad/param norm = 5.3951e-02, time/batch = 0.0776s	
2879/4200 (epoch 34.274), train_loss = 1.33162709, grad/param norm = 5.3759e-02, time/batch = 0.0782s	
2880/4200 (epoch 34.286), train_loss = 1.33594337, grad/param norm = 4.8317e-02, time/batch = 0.0779s	
2881/4200 (epoch 34.298), train_loss = 1.30996257, grad/param norm = 6.0276e-02, time/batch = 0.0799s	
2882/4200 (epoch 34.310), train_loss = 1.34924890, grad/param norm = 5.9053e-02, time/batch = 0.0781s	
2883/4200 (epoch 34.321), train_loss = 1.29828748, grad/param norm = 5.3526e-02, time/batch = 0.0780s	
2884/4200 (epoch 34.333), train_loss = 1.32968487, grad/param norm = 5.3854e-02, time/batch = 0.0778s	
2885/4200 (epoch 34.345), train_loss = 1.31757668, grad/param norm = 5.6630e-02, time/batch = 0.0783s	
2886/4200 (epoch 34.357), train_loss = 1.32484696, grad/param norm = 5.8263e-02, time/batch = 0.0777s	
2887/4200 (epoch 34.369), train_loss = 1.33410782, grad/param norm = 5.9573e-02, time/batch = 0.0780s	
2888/4200 (epoch 34.381), train_loss = 1.33316450, grad/param norm = 5.7511e-02, time/batch = 0.0781s	
2889/4200 (epoch 34.393), train_loss = 1.35349498, grad/param norm = 6.3584e-02, time/batch = 0.0784s	
2890/4200 (epoch 34.405), train_loss = 1.34922208, grad/param norm = 5.7772e-02, time/batch = 0.0780s	
2891/4200 (epoch 34.417), train_loss = 1.30456479, grad/param norm = 5.6564e-02, time/batch = 0.0798s	
2892/4200 (epoch 34.429), train_loss = 1.31863338, grad/param norm = 5.0011e-02, time/batch = 0.0774s	
2893/4200 (epoch 34.440), train_loss = 1.33104023, grad/param norm = 4.8922e-02, time/batch = 0.0785s	
2894/4200 (epoch 34.452), train_loss = 1.33759515, grad/param norm = 5.5284e-02, time/batch = 0.0780s	
2895/4200 (epoch 34.464), train_loss = 1.33766011, grad/param norm = 5.6194e-02, time/batch = 0.0782s	
2896/4200 (epoch 34.476), train_loss = 1.35134212, grad/param norm = 5.1210e-02, time/batch = 0.0780s	
2897/4200 (epoch 34.488), train_loss = 1.34900259, grad/param norm = 6.5170e-02, time/batch = 0.0782s	
2898/4200 (epoch 34.500), train_loss = 1.32111528, grad/param norm = 5.7436e-02, time/batch = 0.0779s	
2899/4200 (epoch 34.512), train_loss = 1.32733238, grad/param norm = 4.6435e-02, time/batch = 0.0784s	
2900/4200 (epoch 34.524), train_loss = 1.30196147, grad/param norm = 4.4252e-02, time/batch = 0.0782s	
2901/4200 (epoch 34.536), train_loss = 1.31853224, grad/param norm = 4.9933e-02, time/batch = 0.0798s	
2902/4200 (epoch 34.548), train_loss = 1.31853239, grad/param norm = 5.4866e-02, time/batch = 0.0778s	
2903/4200 (epoch 34.560), train_loss = 1.34182601, grad/param norm = 5.4882e-02, time/batch = 0.0785s	
2904/4200 (epoch 34.571), train_loss = 1.29641593, grad/param norm = 5.1342e-02, time/batch = 0.0781s	
2905/4200 (epoch 34.583), train_loss = 1.32746818, grad/param norm = 5.2729e-02, time/batch = 0.0780s	
2906/4200 (epoch 34.595), train_loss = 1.32512829, grad/param norm = 5.2594e-02, time/batch = 0.0778s	
2907/4200 (epoch 34.607), train_loss = 1.30773864, grad/param norm = 5.5929e-02, time/batch = 0.0784s	
2908/4200 (epoch 34.619), train_loss = 1.31208469, grad/param norm = 4.8840e-02, time/batch = 0.0775s	
2909/4200 (epoch 34.631), train_loss = 1.30721294, grad/param norm = 4.5874e-02, time/batch = 0.0786s	
2910/4200 (epoch 34.643), train_loss = 1.31381391, grad/param norm = 5.3026e-02, time/batch = 0.0779s	
2911/4200 (epoch 34.655), train_loss = 1.32644536, grad/param norm = 5.7285e-02, time/batch = 0.0797s	
2912/4200 (epoch 34.667), train_loss = 1.33595596, grad/param norm = 5.8131e-02, time/batch = 0.0777s	
2913/4200 (epoch 34.679), train_loss = 1.32952397, grad/param norm = 5.4042e-02, time/batch = 0.0780s	
2914/4200 (epoch 34.690), train_loss = 1.31656525, grad/param norm = 5.7071e-02, time/batch = 0.0784s	
2915/4200 (epoch 34.702), train_loss = 1.31141675, grad/param norm = 6.7047e-02, time/batch = 0.0782s	
2916/4200 (epoch 34.714), train_loss = 1.33490165, grad/param norm = 6.7090e-02, time/batch = 0.0776s	
2917/4200 (epoch 34.726), train_loss = 1.33822896, grad/param norm = 5.7815e-02, time/batch = 0.0784s	
2918/4200 (epoch 34.738), train_loss = 1.32115610, grad/param norm = 5.5450e-02, time/batch = 0.0777s	
2919/4200 (epoch 34.750), train_loss = 1.34050361, grad/param norm = 5.5534e-02, time/batch = 0.0787s	
2920/4200 (epoch 34.762), train_loss = 1.33272859, grad/param norm = 6.1444e-02, time/batch = 0.0779s	
2921/4200 (epoch 34.774), train_loss = 1.34095014, grad/param norm = 6.1908e-02, time/batch = 0.0798s	
2922/4200 (epoch 34.786), train_loss = 1.31921805, grad/param norm = 5.6264e-02, time/batch = 0.0775s	
2923/4200 (epoch 34.798), train_loss = 1.32978063, grad/param norm = 4.8235e-02, time/batch = 0.0780s	
2924/4200 (epoch 34.810), train_loss = 1.33751748, grad/param norm = 5.2233e-02, time/batch = 0.0779s	
2925/4200 (epoch 34.821), train_loss = 1.32462326, grad/param norm = 6.1785e-02, time/batch = 0.0782s	
2926/4200 (epoch 34.833), train_loss = 1.34250391, grad/param norm = 6.7817e-02, time/batch = 0.0774s	
2927/4200 (epoch 34.845), train_loss = 1.35012305, grad/param norm = 7.0186e-02, time/batch = 0.0783s	
2928/4200 (epoch 34.857), train_loss = 1.35572576, grad/param norm = 6.8093e-02, time/batch = 0.0778s	
2929/4200 (epoch 34.869), train_loss = 1.36119468, grad/param norm = 5.5799e-02, time/batch = 0.0781s	
2930/4200 (epoch 34.881), train_loss = 1.33682675, grad/param norm = 4.9870e-02, time/batch = 0.0785s	
2931/4200 (epoch 34.893), train_loss = 1.34799067, grad/param norm = 5.2863e-02, time/batch = 0.0799s	
2932/4200 (epoch 34.905), train_loss = 1.33220232, grad/param norm = 5.0710e-02, time/batch = 0.0777s	
2933/4200 (epoch 34.917), train_loss = 1.34307149, grad/param norm = 5.2224e-02, time/batch = 0.0779s	
2934/4200 (epoch 34.929), train_loss = 1.33329346, grad/param norm = 5.0869e-02, time/batch = 0.0779s	
2935/4200 (epoch 34.940), train_loss = 1.34086344, grad/param norm = 5.8652e-02, time/batch = 0.0787s	
2936/4200 (epoch 34.952), train_loss = 1.34995427, grad/param norm = 7.3871e-02, time/batch = 0.0776s	
2937/4200 (epoch 34.964), train_loss = 1.35268418, grad/param norm = 8.2695e-02, time/batch = 0.0781s	
2938/4200 (epoch 34.976), train_loss = 1.34332775, grad/param norm = 6.4489e-02, time/batch = 0.0777s	
2939/4200 (epoch 34.988), train_loss = 1.33645599, grad/param norm = 5.7816e-02, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
2940/4200 (epoch 35.000), train_loss = 1.37513320, grad/param norm = 6.1057e-02, time/batch = 0.0778s	
2941/4200 (epoch 35.012), train_loss = 1.50798328, grad/param norm = 7.5083e-02, time/batch = 0.0799s	
2942/4200 (epoch 35.024), train_loss = 1.31925176, grad/param norm = 5.8646e-02, time/batch = 0.0777s	
2943/4200 (epoch 35.036), train_loss = 1.32912608, grad/param norm = 5.3184e-02, time/batch = 0.0781s	
2944/4200 (epoch 35.048), train_loss = 1.30505609, grad/param norm = 5.3455e-02, time/batch = 0.0780s	
2945/4200 (epoch 35.060), train_loss = 1.32843737, grad/param norm = 5.6396e-02, time/batch = 0.0783s	
2946/4200 (epoch 35.071), train_loss = 1.32275043, grad/param norm = 5.2629e-02, time/batch = 0.0781s	
2947/4200 (epoch 35.083), train_loss = 1.31598269, grad/param norm = 5.4209e-02, time/batch = 0.0782s	
2948/4200 (epoch 35.095), train_loss = 1.31124124, grad/param norm = 5.0349e-02, time/batch = 0.0778s	
2949/4200 (epoch 35.107), train_loss = 1.32110337, grad/param norm = 5.4260e-02, time/batch = 0.0792s	
2950/4200 (epoch 35.119), train_loss = 1.31616663, grad/param norm = 5.0175e-02, time/batch = 0.0779s	
2951/4200 (epoch 35.131), train_loss = 1.32383370, grad/param norm = 5.0438e-02, time/batch = 0.0801s	
2952/4200 (epoch 35.143), train_loss = 1.32587427, grad/param norm = 4.9744e-02, time/batch = 0.0780s	
2953/4200 (epoch 35.155), train_loss = 1.30813340, grad/param norm = 5.1703e-02, time/batch = 0.0780s	
2954/4200 (epoch 35.167), train_loss = 1.33104193, grad/param norm = 6.6096e-02, time/batch = 0.0781s	
2955/4200 (epoch 35.179), train_loss = 1.33932833, grad/param norm = 6.1458e-02, time/batch = 0.0781s	
2956/4200 (epoch 35.190), train_loss = 1.31673891, grad/param norm = 5.5728e-02, time/batch = 0.0781s	
2957/4200 (epoch 35.202), train_loss = 1.34758917, grad/param norm = 5.9977e-02, time/batch = 0.0782s	
2958/4200 (epoch 35.214), train_loss = 1.32802416, grad/param norm = 5.9262e-02, time/batch = 0.0775s	
2959/4200 (epoch 35.226), train_loss = 1.33563021, grad/param norm = 5.5532e-02, time/batch = 0.0781s	
2960/4200 (epoch 35.238), train_loss = 1.32414397, grad/param norm = 5.6084e-02, time/batch = 0.0782s	
2961/4200 (epoch 35.250), train_loss = 1.31077328, grad/param norm = 5.4950e-02, time/batch = 0.0802s	
2962/4200 (epoch 35.262), train_loss = 1.28040815, grad/param norm = 5.3901e-02, time/batch = 0.0776s	
2963/4200 (epoch 35.274), train_loss = 1.32707113, grad/param norm = 5.3323e-02, time/batch = 0.0806s	
2964/4200 (epoch 35.286), train_loss = 1.33151932, grad/param norm = 4.8007e-02, time/batch = 0.0780s	
2965/4200 (epoch 35.298), train_loss = 1.30561617, grad/param norm = 6.0273e-02, time/batch = 0.0781s	
2966/4200 (epoch 35.310), train_loss = 1.34487719, grad/param norm = 5.8332e-02, time/batch = 0.0776s	
2967/4200 (epoch 35.321), train_loss = 1.29391932, grad/param norm = 5.3011e-02, time/batch = 0.0788s	
2968/4200 (epoch 35.333), train_loss = 1.32502605, grad/param norm = 5.2813e-02, time/batch = 0.0774s	
2969/4200 (epoch 35.345), train_loss = 1.31302168, grad/param norm = 5.5184e-02, time/batch = 0.0781s	
2970/4200 (epoch 35.357), train_loss = 1.32044023, grad/param norm = 5.6799e-02, time/batch = 0.0780s	
2971/4200 (epoch 35.369), train_loss = 1.32954235, grad/param norm = 5.8358e-02, time/batch = 0.0800s	
2972/4200 (epoch 35.381), train_loss = 1.32861209, grad/param norm = 5.7329e-02, time/batch = 0.0780s	
2973/4200 (epoch 35.393), train_loss = 1.34928277, grad/param norm = 6.3198e-02, time/batch = 0.0780s	
2974/4200 (epoch 35.405), train_loss = 1.34498825, grad/param norm = 5.6132e-02, time/batch = 0.0780s	
2975/4200 (epoch 35.417), train_loss = 1.29977651, grad/param norm = 5.4421e-02, time/batch = 0.0781s	
2976/4200 (epoch 35.429), train_loss = 1.31435846, grad/param norm = 4.9056e-02, time/batch = 0.0776s	
2977/4200 (epoch 35.440), train_loss = 1.32679316, grad/param norm = 5.0160e-02, time/batch = 0.0787s	
2978/4200 (epoch 35.452), train_loss = 1.33317183, grad/param norm = 5.6025e-02, time/batch = 0.0776s	
2979/4200 (epoch 35.464), train_loss = 1.33342725, grad/param norm = 5.4779e-02, time/batch = 0.0780s	
2980/4200 (epoch 35.476), train_loss = 1.34709865, grad/param norm = 5.0774e-02, time/batch = 0.0779s	
2981/4200 (epoch 35.488), train_loss = 1.34474352, grad/param norm = 6.6561e-02, time/batch = 0.0799s	
2982/4200 (epoch 35.500), train_loss = 1.31669958, grad/param norm = 5.5891e-02, time/batch = 0.0778s	
2983/4200 (epoch 35.512), train_loss = 1.32282517, grad/param norm = 4.4908e-02, time/batch = 0.0780s	
2984/4200 (epoch 35.524), train_loss = 1.29807615, grad/param norm = 4.3698e-02, time/batch = 0.0779s	
2985/4200 (epoch 35.536), train_loss = 1.31425488, grad/param norm = 5.0087e-02, time/batch = 0.0781s	
2986/4200 (epoch 35.548), train_loss = 1.31464715, grad/param norm = 5.4659e-02, time/batch = 0.0775s	
2987/4200 (epoch 35.560), train_loss = 1.33729635, grad/param norm = 5.3895e-02, time/batch = 0.0783s	
2988/4200 (epoch 35.571), train_loss = 1.29199976, grad/param norm = 5.0551e-02, time/batch = 0.0780s	
2989/4200 (epoch 35.583), train_loss = 1.32318036, grad/param norm = 5.2687e-02, time/batch = 0.0781s	
2990/4200 (epoch 35.595), train_loss = 1.32065495, grad/param norm = 5.2118e-02, time/batch = 0.0780s	
2991/4200 (epoch 35.607), train_loss = 1.30318232, grad/param norm = 5.5043e-02, time/batch = 0.0799s	
2992/4200 (epoch 35.619), train_loss = 1.30781539, grad/param norm = 4.8156e-02, time/batch = 0.0777s	
2993/4200 (epoch 35.631), train_loss = 1.30306988, grad/param norm = 4.6140e-02, time/batch = 0.0783s	
2994/4200 (epoch 35.643), train_loss = 1.30963122, grad/param norm = 5.3451e-02, time/batch = 0.0780s	
2995/4200 (epoch 35.655), train_loss = 1.32251055, grad/param norm = 5.6619e-02, time/batch = 0.0782s	
2996/4200 (epoch 35.667), train_loss = 1.33161425, grad/param norm = 5.5892e-02, time/batch = 0.0774s	
2997/4200 (epoch 35.679), train_loss = 1.32519133, grad/param norm = 5.3153e-02, time/batch = 0.0782s	
2998/4200 (epoch 35.690), train_loss = 1.31254211, grad/param norm = 5.7257e-02, time/batch = 0.0776s	
2999/4200 (epoch 35.702), train_loss = 1.30695966, grad/param norm = 6.5691e-02, time/batch = 0.0787s	
evaluating loss over split index 2	
1/5...	
2/5...	
3/5...	
4/5...	
5/5...	
saving checkpoint to cv/lm_lstm_epoch35.71_1.4296.t7	
3000/4200 (epoch 35.714), train_loss = 1.33009138, grad/param norm = 6.4278e-02, time/batch = 0.0779s	
3001/4200 (epoch 35.726), train_loss = 1.57118675, grad/param norm = 5.8674e-02, time/batch = 0.0804s	
3002/4200 (epoch 35.738), train_loss = 1.31898322, grad/param norm = 6.4773e-02, time/batch = 0.0782s	
3003/4200 (epoch 35.750), train_loss = 1.33925134, grad/param norm = 6.4339e-02, time/batch = 0.0783s	
3004/4200 (epoch 35.762), train_loss = 1.32917256, grad/param norm = 6.0150e-02, time/batch = 0.0782s	
3005/4200 (epoch 35.774), train_loss = 1.33685321, grad/param norm = 6.0728e-02, time/batch = 0.0791s	
3006/4200 (epoch 35.786), train_loss = 1.31485381, grad/param norm = 5.5983e-02, time/batch = 0.0786s	
3007/4200 (epoch 35.798), train_loss = 1.32568281, grad/param norm = 5.2847e-02, time/batch = 0.0788s	
3008/4200 (epoch 35.810), train_loss = 1.33543424, grad/param norm = 5.9616e-02, time/batch = 0.0784s	
3009/4200 (epoch 35.821), train_loss = 1.31989652, grad/param norm = 5.9424e-02, time/batch = 0.0790s	
3010/4200 (epoch 35.833), train_loss = 1.33616504, grad/param norm = 5.3176e-02, time/batch = 0.0788s	
3011/4200 (epoch 35.845), train_loss = 1.34283674, grad/param norm = 5.0702e-02, time/batch = 0.0798s	
3012/4200 (epoch 35.857), train_loss = 1.34800814, grad/param norm = 4.9192e-02, time/batch = 0.0778s	
3013/4200 (epoch 35.869), train_loss = 1.35572098, grad/param norm = 5.2856e-02, time/batch = 0.0778s	
3014/4200 (epoch 35.881), train_loss = 1.33347811, grad/param norm = 5.9030e-02, time/batch = 0.0780s	
3015/4200 (epoch 35.893), train_loss = 1.34546573, grad/param norm = 6.3565e-02, time/batch = 0.0780s	
3016/4200 (epoch 35.905), train_loss = 1.33020541, grad/param norm = 6.1304e-02, time/batch = 0.0776s	
3017/4200 (epoch 35.917), train_loss = 1.33927968, grad/param norm = 5.5689e-02, time/batch = 0.0787s	
3018/4200 (epoch 35.929), train_loss = 1.32844363, grad/param norm = 4.7614e-02, time/batch = 0.0774s	
3019/4200 (epoch 35.940), train_loss = 1.33645358, grad/param norm = 5.2381e-02, time/batch = 0.0782s	
3020/4200 (epoch 35.952), train_loss = 1.34473200, grad/param norm = 6.7200e-02, time/batch = 0.0779s	
3021/4200 (epoch 35.964), train_loss = 1.34777184, grad/param norm = 7.8218e-02, time/batch = 0.0799s	
3022/4200 (epoch 35.976), train_loss = 1.33890009, grad/param norm = 6.6579e-02, time/batch = 0.0782s	
3023/4200 (epoch 35.988), train_loss = 1.33220439, grad/param norm = 6.1486e-02, time/batch = 0.0781s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
3024/4200 (epoch 36.000), train_loss = 1.37086482, grad/param norm = 6.3438e-02, time/batch = 0.0781s	
3025/4200 (epoch 36.012), train_loss = 1.50410583, grad/param norm = 7.6805e-02, time/batch = 0.0781s	
3026/4200 (epoch 36.024), train_loss = 1.31512402, grad/param norm = 5.8623e-02, time/batch = 0.0776s	
3027/4200 (epoch 36.036), train_loss = 1.32501463, grad/param norm = 5.3078e-02, time/batch = 0.0781s	
3028/4200 (epoch 36.048), train_loss = 1.30068599, grad/param norm = 5.1079e-02, time/batch = 0.0781s	
3029/4200 (epoch 36.060), train_loss = 1.32400839, grad/param norm = 5.4190e-02, time/batch = 0.0781s	
3030/4200 (epoch 36.071), train_loss = 1.31869054, grad/param norm = 5.2639e-02, time/batch = 0.0781s	
3031/4200 (epoch 36.083), train_loss = 1.31205058, grad/param norm = 5.4976e-02, time/batch = 0.0799s	
3032/4200 (epoch 36.095), train_loss = 1.30736832, grad/param norm = 5.0285e-02, time/batch = 0.0778s	
3033/4200 (epoch 36.107), train_loss = 1.31715478, grad/param norm = 5.3533e-02, time/batch = 0.0786s	
3034/4200 (epoch 36.119), train_loss = 1.31208256, grad/param norm = 5.0288e-02, time/batch = 0.0782s	
3035/4200 (epoch 36.131), train_loss = 1.31981210, grad/param norm = 5.1101e-02, time/batch = 0.0782s	
3036/4200 (epoch 36.143), train_loss = 1.32155387, grad/param norm = 4.8967e-02, time/batch = 0.0775s	
3037/4200 (epoch 36.155), train_loss = 1.30392093, grad/param norm = 4.9003e-02, time/batch = 0.0780s	
3038/4200 (epoch 36.167), train_loss = 1.32631631, grad/param norm = 6.3198e-02, time/batch = 0.0779s	
3039/4200 (epoch 36.179), train_loss = 1.33514743, grad/param norm = 6.0049e-02, time/batch = 0.0780s	
3040/4200 (epoch 36.190), train_loss = 1.31236576, grad/param norm = 5.4398e-02, time/batch = 0.0778s	
3041/4200 (epoch 36.202), train_loss = 1.34310311, grad/param norm = 5.7644e-02, time/batch = 0.0798s	
3042/4200 (epoch 36.214), train_loss = 1.32305620, grad/param norm = 5.4185e-02, time/batch = 0.0777s	
3043/4200 (epoch 36.226), train_loss = 1.33087813, grad/param norm = 5.2435e-02, time/batch = 0.0784s	
3044/4200 (epoch 36.238), train_loss = 1.31961308, grad/param norm = 5.4937e-02, time/batch = 0.0780s	
3045/4200 (epoch 36.250), train_loss = 1.30696579, grad/param norm = 5.5707e-02, time/batch = 0.0782s	
3046/4200 (epoch 36.262), train_loss = 1.27680296, grad/param norm = 5.4908e-02, time/batch = 0.0776s	
3047/4200 (epoch 36.274), train_loss = 1.32293975, grad/param norm = 5.3615e-02, time/batch = 0.0783s	
3048/4200 (epoch 36.286), train_loss = 1.32743494, grad/param norm = 4.8478e-02, time/batch = 0.0774s	
3049/4200 (epoch 36.298), train_loss = 1.30174037, grad/param norm = 6.0793e-02, time/batch = 0.0786s	
3050/4200 (epoch 36.310), train_loss = 1.34082823, grad/param norm = 5.8653e-02, time/batch = 0.0780s	
3051/4200 (epoch 36.321), train_loss = 1.28991304, grad/param norm = 5.3447e-02, time/batch = 0.0805s	
3052/4200 (epoch 36.333), train_loss = 1.32084445, grad/param norm = 5.2710e-02, time/batch = 0.0780s	
3053/4200 (epoch 36.345), train_loss = 1.30894107, grad/param norm = 5.4609e-02, time/batch = 0.0780s	
3054/4200 (epoch 36.357), train_loss = 1.31627142, grad/param norm = 5.5919e-02, time/batch = 0.0784s	
3055/4200 (epoch 36.369), train_loss = 1.32531104, grad/param norm = 5.7660e-02, time/batch = 0.0782s	
3056/4200 (epoch 36.381), train_loss = 1.32425988, grad/param norm = 5.7194e-02, time/batch = 0.0777s	
3057/4200 (epoch 36.393), train_loss = 1.34531868, grad/param norm = 6.2656e-02, time/batch = 0.0781s	
3058/4200 (epoch 36.405), train_loss = 1.34102427, grad/param norm = 5.4691e-02, time/batch = 0.0774s	
3059/4200 (epoch 36.417), train_loss = 1.29523720, grad/param norm = 5.2852e-02, time/batch = 0.0785s	
3060/4200 (epoch 36.429), train_loss = 1.31044571, grad/param norm = 4.8435e-02, time/batch = 0.0780s	
3061/4200 (epoch 36.440), train_loss = 1.32273730, grad/param norm = 5.0367e-02, time/batch = 0.0798s	
3062/4200 (epoch 36.452), train_loss = 1.32873531, grad/param norm = 5.5226e-02, time/batch = 0.0777s	
3063/4200 (epoch 36.464), train_loss = 1.32930521, grad/param norm = 5.2928e-02, time/batch = 0.0781s	
3064/4200 (epoch 36.476), train_loss = 1.34295339, grad/param norm = 4.9862e-02, time/batch = 0.0779s	
3065/4200 (epoch 36.488), train_loss = 1.34034971, grad/param norm = 6.5602e-02, time/batch = 0.0781s	
3066/4200 (epoch 36.500), train_loss = 1.31229745, grad/param norm = 5.3438e-02, time/batch = 0.0814s	
3067/4200 (epoch 36.512), train_loss = 1.31855942, grad/param norm = 4.3919e-02, time/batch = 0.0788s	
3068/4200 (epoch 36.524), train_loss = 1.29463003, grad/param norm = 4.4681e-02, time/batch = 0.0776s	
3069/4200 (epoch 36.536), train_loss = 1.31066334, grad/param norm = 5.1950e-02, time/batch = 0.0784s	
3070/4200 (epoch 36.548), train_loss = 1.31125764, grad/param norm = 5.6222e-02, time/batch = 0.0786s	
3071/4200 (epoch 36.560), train_loss = 1.33337210, grad/param norm = 5.4402e-02, time/batch = 0.0798s	
3072/4200 (epoch 36.571), train_loss = 1.28804031, grad/param norm = 5.0432e-02, time/batch = 0.0778s	
3073/4200 (epoch 36.583), train_loss = 1.31924942, grad/param norm = 5.2682e-02, time/batch = 0.0781s	
3074/4200 (epoch 36.595), train_loss = 1.31653605, grad/param norm = 5.2106e-02, time/batch = 0.0781s	
3075/4200 (epoch 36.607), train_loss = 1.29899334, grad/param norm = 5.4688e-02, time/batch = 0.0785s	
3076/4200 (epoch 36.619), train_loss = 1.30381036, grad/param norm = 4.8173e-02, time/batch = 0.0777s	
3077/4200 (epoch 36.631), train_loss = 1.29924710, grad/param norm = 4.7011e-02, time/batch = 0.0783s	
3078/4200 (epoch 36.643), train_loss = 1.30579008, grad/param norm = 5.4137e-02, time/batch = 0.0775s	
3079/4200 (epoch 36.655), train_loss = 1.31874064, grad/param norm = 5.5880e-02, time/batch = 0.0782s	
3080/4200 (epoch 36.667), train_loss = 1.32755840, grad/param norm = 5.3551e-02, time/batch = 0.0779s	
3081/4200 (epoch 36.679), train_loss = 1.32105978, grad/param norm = 5.2172e-02, time/batch = 0.0798s	
3082/4200 (epoch 36.690), train_loss = 1.30883207, grad/param norm = 5.7466e-02, time/batch = 0.0775s	
3083/4200 (epoch 36.702), train_loss = 1.30277632, grad/param norm = 6.4367e-02, time/batch = 0.0781s	
3084/4200 (epoch 36.714), train_loss = 1.32554832, grad/param norm = 6.1423e-02, time/batch = 0.0782s	
3085/4200 (epoch 36.726), train_loss = 1.33011489, grad/param norm = 5.1244e-02, time/batch = 0.0782s	
3086/4200 (epoch 36.738), train_loss = 1.31160039, grad/param norm = 5.1839e-02, time/batch = 0.0781s	
3087/4200 (epoch 36.750), train_loss = 1.33245002, grad/param norm = 5.5700e-02, time/batch = 0.0782s	
3088/4200 (epoch 36.762), train_loss = 1.32458760, grad/param norm = 6.0604e-02, time/batch = 0.0776s	
3089/4200 (epoch 36.774), train_loss = 1.33259599, grad/param norm = 5.9553e-02, time/batch = 0.0782s	
3090/4200 (epoch 36.786), train_loss = 1.31047674, grad/param norm = 5.3493e-02, time/batch = 0.0779s	
3091/4200 (epoch 36.798), train_loss = 1.32093851, grad/param norm = 4.7365e-02, time/batch = 0.0802s	
3092/4200 (epoch 36.810), train_loss = 1.32975978, grad/param norm = 5.3285e-02, time/batch = 0.0777s	
3093/4200 (epoch 36.821), train_loss = 1.31616540, grad/param norm = 6.0398e-02, time/batch = 0.0780s	
3094/4200 (epoch 36.833), train_loss = 1.33372717, grad/param norm = 6.3780e-02, time/batch = 0.0781s	
3095/4200 (epoch 36.845), train_loss = 1.34082128, grad/param norm = 6.5788e-02, time/batch = 0.0783s	
3096/4200 (epoch 36.857), train_loss = 1.34654790, grad/param norm = 6.4772e-02, time/batch = 0.0781s	
3097/4200 (epoch 36.869), train_loss = 1.35238109, grad/param norm = 5.4964e-02, time/batch = 0.0782s	
3098/4200 (epoch 36.881), train_loss = 1.32853725, grad/param norm = 5.1411e-02, time/batch = 0.0775s	
3099/4200 (epoch 36.893), train_loss = 1.33944440, grad/param norm = 5.2859e-02, time/batch = 0.0782s	
3100/4200 (epoch 36.905), train_loss = 1.32407874, grad/param norm = 4.9598e-02, time/batch = 0.0779s	
3101/4200 (epoch 36.917), train_loss = 1.33467847, grad/param norm = 5.3259e-02, time/batch = 0.0803s	
3102/4200 (epoch 36.929), train_loss = 1.32552063, grad/param norm = 5.4032e-02, time/batch = 0.0777s	
3103/4200 (epoch 36.940), train_loss = 1.33322456, grad/param norm = 6.0520e-02, time/batch = 0.0780s	
3104/4200 (epoch 36.952), train_loss = 1.34205853, grad/param norm = 7.3181e-02, time/batch = 0.0778s	
3105/4200 (epoch 36.964), train_loss = 1.34326282, grad/param norm = 7.5351e-02, time/batch = 0.0783s	
3106/4200 (epoch 36.976), train_loss = 1.33304098, grad/param norm = 5.4789e-02, time/batch = 0.0775s	
3107/4200 (epoch 36.988), train_loss = 1.32705392, grad/param norm = 5.2684e-02, time/batch = 0.0788s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
3108/4200 (epoch 37.000), train_loss = 1.36561976, grad/param norm = 5.7927e-02, time/batch = 0.0778s	
3109/4200 (epoch 37.012), train_loss = 1.49991448, grad/param norm = 7.1931e-02, time/batch = 0.0782s	
3110/4200 (epoch 37.024), train_loss = 1.31089394, grad/param norm = 5.6603e-02, time/batch = 0.0780s	
3111/4200 (epoch 37.036), train_loss = 1.32095942, grad/param norm = 5.1778e-02, time/batch = 0.0798s	
3112/4200 (epoch 37.048), train_loss = 1.29684575, grad/param norm = 5.1235e-02, time/batch = 0.0783s	
3113/4200 (epoch 37.060), train_loss = 1.32033293, grad/param norm = 5.3805e-02, time/batch = 0.0778s	
3114/4200 (epoch 37.071), train_loss = 1.31479992, grad/param norm = 5.2362e-02, time/batch = 0.0780s	
3115/4200 (epoch 37.083), train_loss = 1.30817904, grad/param norm = 5.4094e-02, time/batch = 0.0784s	
3116/4200 (epoch 37.095), train_loss = 1.30374569, grad/param norm = 5.0357e-02, time/batch = 0.0778s	
3117/4200 (epoch 37.107), train_loss = 1.31368963, grad/param norm = 5.3916e-02, time/batch = 0.0782s	
3118/4200 (epoch 37.119), train_loss = 1.30812333, grad/param norm = 4.9448e-02, time/batch = 0.0775s	
3119/4200 (epoch 37.131), train_loss = 1.31594122, grad/param norm = 5.0322e-02, time/batch = 0.0780s	
3120/4200 (epoch 37.143), train_loss = 1.31763347, grad/param norm = 4.9289e-02, time/batch = 0.0780s	
3121/4200 (epoch 37.155), train_loss = 1.30074543, grad/param norm = 5.1035e-02, time/batch = 0.0799s	
3122/4200 (epoch 37.167), train_loss = 1.32305857, grad/param norm = 6.5687e-02, time/batch = 0.0776s	
3123/4200 (epoch 37.179), train_loss = 1.33172584, grad/param norm = 6.0664e-02, time/batch = 0.0777s	
3124/4200 (epoch 37.190), train_loss = 1.30858699, grad/param norm = 5.5437e-02, time/batch = 0.0780s	
3125/4200 (epoch 37.202), train_loss = 1.33922944, grad/param norm = 5.9461e-02, time/batch = 0.0782s	
3126/4200 (epoch 37.214), train_loss = 1.31926054, grad/param norm = 5.5878e-02, time/batch = 0.0779s	
3127/4200 (epoch 37.226), train_loss = 1.32721848, grad/param norm = 5.3504e-02, time/batch = 0.0782s	
3128/4200 (epoch 37.238), train_loss = 1.31566750, grad/param norm = 5.4752e-02, time/batch = 0.0780s	
3129/4200 (epoch 37.250), train_loss = 1.30310041, grad/param norm = 5.4076e-02, time/batch = 0.0783s	
3130/4200 (epoch 37.262), train_loss = 1.27255838, grad/param norm = 5.3246e-02, time/batch = 0.0778s	
3131/4200 (epoch 37.274), train_loss = 1.31875757, grad/param norm = 5.2417e-02, time/batch = 0.0797s	
3132/4200 (epoch 37.286), train_loss = 1.32322140, grad/param norm = 4.7838e-02, time/batch = 0.0778s	
3133/4200 (epoch 37.298), train_loss = 1.29761298, grad/param norm = 6.0003e-02, time/batch = 0.0784s	
3134/4200 (epoch 37.310), train_loss = 1.33660384, grad/param norm = 5.6779e-02, time/batch = 0.0779s	
3135/4200 (epoch 37.321), train_loss = 1.28593005, grad/param norm = 5.2531e-02, time/batch = 0.0780s	
3136/4200 (epoch 37.333), train_loss = 1.31665293, grad/param norm = 5.1811e-02, time/batch = 0.0777s	
3137/4200 (epoch 37.345), train_loss = 1.30498864, grad/param norm = 5.4675e-02, time/batch = 0.0784s	
3138/4200 (epoch 37.357), train_loss = 1.31263856, grad/param norm = 5.6321e-02, time/batch = 0.0776s	
3139/4200 (epoch 37.369), train_loss = 1.32143029, grad/param norm = 5.7600e-02, time/batch = 0.0785s	
3140/4200 (epoch 37.381), train_loss = 1.32035979, grad/param norm = 5.7225e-02, time/batch = 0.0778s	
3141/4200 (epoch 37.393), train_loss = 1.34142266, grad/param norm = 6.1920e-02, time/batch = 0.0797s	
3142/4200 (epoch 37.405), train_loss = 1.33716685, grad/param norm = 5.3041e-02, time/batch = 0.0777s	
3143/4200 (epoch 37.417), train_loss = 1.29103584, grad/param norm = 5.1351e-02, time/batch = 0.0780s	
3144/4200 (epoch 37.429), train_loss = 1.30658397, grad/param norm = 4.8143e-02, time/batch = 0.0785s	
3145/4200 (epoch 37.440), train_loss = 1.31885749, grad/param norm = 5.1562e-02, time/batch = 0.0781s	
3146/4200 (epoch 37.452), train_loss = 1.32476208, grad/param norm = 5.5403e-02, time/batch = 0.0776s	
3147/4200 (epoch 37.464), train_loss = 1.32549248, grad/param norm = 5.1624e-02, time/batch = 0.0781s	
3148/4200 (epoch 37.476), train_loss = 1.33912680, grad/param norm = 5.0063e-02, time/batch = 0.0777s	
3149/4200 (epoch 37.488), train_loss = 1.33626514, grad/param norm = 6.5661e-02, time/batch = 0.0786s	
3150/4200 (epoch 37.500), train_loss = 1.30823237, grad/param norm = 5.1406e-02, time/batch = 0.0779s	
3151/4200 (epoch 37.512), train_loss = 1.31450109, grad/param norm = 4.3655e-02, time/batch = 0.0798s	
3152/4200 (epoch 37.524), train_loss = 1.29132282, grad/param norm = 4.5560e-02, time/batch = 0.0778s	
3153/4200 (epoch 37.536), train_loss = 1.30700346, grad/param norm = 5.2766e-02, time/batch = 0.0780s	
3154/4200 (epoch 37.548), train_loss = 1.30784934, grad/param norm = 5.5805e-02, time/batch = 0.0784s	
3155/4200 (epoch 37.560), train_loss = 1.32934254, grad/param norm = 5.3406e-02, time/batch = 0.0781s	
3156/4200 (epoch 37.571), train_loss = 1.28403928, grad/param norm = 4.9344e-02, time/batch = 0.0775s	
3157/4200 (epoch 37.583), train_loss = 1.31532141, grad/param norm = 5.1747e-02, time/batch = 0.0791s	
3158/4200 (epoch 37.595), train_loss = 1.31253463, grad/param norm = 5.1678e-02, time/batch = 0.0779s	
3159/4200 (epoch 37.607), train_loss = 1.29506470, grad/param norm = 5.4800e-02, time/batch = 0.0781s	
3160/4200 (epoch 37.619), train_loss = 1.30020733, grad/param norm = 4.9008e-02, time/batch = 0.0784s	
3161/4200 (epoch 37.631), train_loss = 1.29572522, grad/param norm = 4.7499e-02, time/batch = 0.0800s	
3162/4200 (epoch 37.643), train_loss = 1.30177290, grad/param norm = 5.3040e-02, time/batch = 0.0777s	
3163/4200 (epoch 37.655), train_loss = 1.31482666, grad/param norm = 5.3817e-02, time/batch = 0.0778s	
3164/4200 (epoch 37.667), train_loss = 1.32360528, grad/param norm = 5.1336e-02, time/batch = 0.0779s	
3165/4200 (epoch 37.679), train_loss = 1.31712193, grad/param norm = 5.1383e-02, time/batch = 0.0784s	
3166/4200 (epoch 37.690), train_loss = 1.30509712, grad/param norm = 5.7084e-02, time/batch = 0.0777s	
3167/4200 (epoch 37.702), train_loss = 1.29866462, grad/param norm = 6.2001e-02, time/batch = 0.0780s	
3168/4200 (epoch 37.714), train_loss = 1.32103652, grad/param norm = 5.7268e-02, time/batch = 0.0773s	
3169/4200 (epoch 37.726), train_loss = 1.32576047, grad/param norm = 4.8515e-02, time/batch = 0.0783s	
3170/4200 (epoch 37.738), train_loss = 1.30755558, grad/param norm = 5.6019e-02, time/batch = 0.0783s	
3171/4200 (epoch 37.750), train_loss = 1.32997800, grad/param norm = 6.1276e-02, time/batch = 0.0823s	
3172/4200 (epoch 37.762), train_loss = 1.32087807, grad/param norm = 5.8908e-02, time/batch = 0.0805s	
3173/4200 (epoch 37.774), train_loss = 1.32849413, grad/param norm = 5.6645e-02, time/batch = 0.0778s	
3174/4200 (epoch 37.786), train_loss = 1.30645087, grad/param norm = 5.2620e-02, time/batch = 0.0780s	
3175/4200 (epoch 37.798), train_loss = 1.31684252, grad/param norm = 5.0174e-02, time/batch = 0.0781s	
3176/4200 (epoch 37.810), train_loss = 1.32698730, grad/param norm = 5.7147e-02, time/batch = 0.0777s	
3177/4200 (epoch 37.821), train_loss = 1.31226265, grad/param norm = 6.0039e-02, time/batch = 0.0781s	
3178/4200 (epoch 37.833), train_loss = 1.32933059, grad/param norm = 5.8521e-02, time/batch = 0.0777s	
3179/4200 (epoch 37.845), train_loss = 1.33549093, grad/param norm = 5.6889e-02, time/batch = 0.0783s	
3180/4200 (epoch 37.857), train_loss = 1.34103063, grad/param norm = 5.6704e-02, time/batch = 0.0779s	
3181/4200 (epoch 37.869), train_loss = 1.34791834, grad/param norm = 5.3765e-02, time/batch = 0.0802s	
3182/4200 (epoch 37.881), train_loss = 1.32493777, grad/param norm = 5.5317e-02, time/batch = 0.0777s	
3183/4200 (epoch 37.893), train_loss = 1.33571960, grad/param norm = 5.4927e-02, time/batch = 0.0778s	
3184/4200 (epoch 37.905), train_loss = 1.32043171, grad/param norm = 5.0409e-02, time/batch = 0.0779s	
3185/4200 (epoch 37.917), train_loss = 1.33075357, grad/param norm = 5.2556e-02, time/batch = 0.0780s	
3186/4200 (epoch 37.929), train_loss = 1.32098677, grad/param norm = 5.0774e-02, time/batch = 0.0780s	
3187/4200 (epoch 37.940), train_loss = 1.32887457, grad/param norm = 5.4552e-02, time/batch = 0.0782s	
3188/4200 (epoch 37.952), train_loss = 1.33698864, grad/param norm = 6.7746e-02, time/batch = 0.0776s	
3189/4200 (epoch 37.964), train_loss = 1.33883863, grad/param norm = 7.3346e-02, time/batch = 0.0781s	
3190/4200 (epoch 37.976), train_loss = 1.32882459, grad/param norm = 5.4373e-02, time/batch = 0.0781s	
3191/4200 (epoch 37.988), train_loss = 1.32299119, grad/param norm = 5.0955e-02, time/batch = 0.0801s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
3192/4200 (epoch 38.000), train_loss = 1.36133254, grad/param norm = 5.5662e-02, time/batch = 0.0778s	
3193/4200 (epoch 38.012), train_loss = 1.49709862, grad/param norm = 7.1233e-02, time/batch = 0.0779s	
3194/4200 (epoch 38.024), train_loss = 1.30743291, grad/param norm = 5.7673e-02, time/batch = 0.0779s	
3195/4200 (epoch 38.036), train_loss = 1.31738333, grad/param norm = 5.1831e-02, time/batch = 0.0784s	
3196/4200 (epoch 38.048), train_loss = 1.29316051, grad/param norm = 5.0561e-02, time/batch = 0.0776s	
3197/4200 (epoch 38.060), train_loss = 1.31675140, grad/param norm = 5.3757e-02, time/batch = 0.0786s	
3198/4200 (epoch 38.071), train_loss = 1.31110749, grad/param norm = 5.2423e-02, time/batch = 0.0775s	
3199/4200 (epoch 38.083), train_loss = 1.30457750, grad/param norm = 5.3904e-02, time/batch = 0.0782s	
3200/4200 (epoch 38.095), train_loss = 1.30022069, grad/param norm = 5.0018e-02, time/batch = 0.0780s	
3201/4200 (epoch 38.107), train_loss = 1.31009038, grad/param norm = 5.3514e-02, time/batch = 0.0797s	
3202/4200 (epoch 38.119), train_loss = 1.30443786, grad/param norm = 4.9514e-02, time/batch = 0.0782s	
3203/4200 (epoch 38.131), train_loss = 1.31226129, grad/param norm = 5.0535e-02, time/batch = 0.0781s	
3204/4200 (epoch 38.143), train_loss = 1.31379962, grad/param norm = 4.8977e-02, time/batch = 0.0781s	
3205/4200 (epoch 38.155), train_loss = 1.29718833, grad/param norm = 5.0088e-02, time/batch = 0.0780s	
3206/4200 (epoch 38.167), train_loss = 1.31920514, grad/param norm = 6.4802e-02, time/batch = 0.0776s	
3207/4200 (epoch 38.179), train_loss = 1.32820847, grad/param norm = 6.0516e-02, time/batch = 0.0786s	
3208/4200 (epoch 38.190), train_loss = 1.30486252, grad/param norm = 5.5529e-02, time/batch = 0.0777s	
3209/4200 (epoch 38.202), train_loss = 1.33542743, grad/param norm = 5.9304e-02, time/batch = 0.0782s	
3210/4200 (epoch 38.214), train_loss = 1.31545550, grad/param norm = 5.5169e-02, time/batch = 0.0785s	
3211/4200 (epoch 38.226), train_loss = 1.32344594, grad/param norm = 5.2603e-02, time/batch = 0.0810s	
3212/4200 (epoch 38.238), train_loss = 1.31176733, grad/param norm = 5.4427e-02, time/batch = 0.0787s	
3213/4200 (epoch 38.250), train_loss = 1.29965064, grad/param norm = 5.4284e-02, time/batch = 0.0779s	
3214/4200 (epoch 38.262), train_loss = 1.26910205, grad/param norm = 5.3675e-02, time/batch = 0.0784s	
3215/4200 (epoch 38.274), train_loss = 1.31494339, grad/param norm = 5.2474e-02, time/batch = 0.0782s	
3216/4200 (epoch 38.286), train_loss = 1.31952400, grad/param norm = 4.8054e-02, time/batch = 0.0775s	
3217/4200 (epoch 38.298), train_loss = 1.29396612, grad/param norm = 5.9903e-02, time/batch = 0.0781s	
3218/4200 (epoch 38.310), train_loss = 1.33277574, grad/param norm = 5.6131e-02, time/batch = 0.0780s	
3219/4200 (epoch 38.321), train_loss = 1.28226549, grad/param norm = 5.2495e-02, time/batch = 0.0780s	
3220/4200 (epoch 38.333), train_loss = 1.31275026, grad/param norm = 5.1258e-02, time/batch = 0.0781s	
3221/4200 (epoch 38.345), train_loss = 1.30126052, grad/param norm = 5.4177e-02, time/batch = 0.0799s	
3222/4200 (epoch 38.357), train_loss = 1.30899314, grad/param norm = 5.5960e-02, time/batch = 0.0791s	
3223/4200 (epoch 38.369), train_loss = 1.31770900, grad/param norm = 5.7374e-02, time/batch = 0.0786s	
3224/4200 (epoch 38.381), train_loss = 1.31655511, grad/param norm = 5.7258e-02, time/batch = 0.0780s	
3225/4200 (epoch 38.393), train_loss = 1.33774904, grad/param norm = 6.1215e-02, time/batch = 0.0781s	
3226/4200 (epoch 38.405), train_loss = 1.33354672, grad/param norm = 5.1803e-02, time/batch = 0.0775s	
3227/4200 (epoch 38.417), train_loss = 1.28713013, grad/param norm = 5.0466e-02, time/batch = 0.0781s	
3228/4200 (epoch 38.429), train_loss = 1.30302699, grad/param norm = 4.7949e-02, time/batch = 0.0781s	
3229/4200 (epoch 38.440), train_loss = 1.31511597, grad/param norm = 5.1553e-02, time/batch = 0.0782s	
3230/4200 (epoch 38.452), train_loss = 1.32078105, grad/param norm = 5.4529e-02, time/batch = 0.0779s	
3231/4200 (epoch 38.464), train_loss = 1.32187608, grad/param norm = 5.0508e-02, time/batch = 0.0798s	
3232/4200 (epoch 38.476), train_loss = 1.33545576, grad/param norm = 5.0167e-02, time/batch = 0.0776s	
3233/4200 (epoch 38.488), train_loss = 1.33234296, grad/param norm = 6.5150e-02, time/batch = 0.0779s	
3234/4200 (epoch 38.500), train_loss = 1.30443578, grad/param norm = 5.0056e-02, time/batch = 0.0781s	
3235/4200 (epoch 38.512), train_loss = 1.31074334, grad/param norm = 4.3972e-02, time/batch = 0.0781s	
3236/4200 (epoch 38.524), train_loss = 1.28824716, grad/param norm = 4.6470e-02, time/batch = 0.0775s	
3237/4200 (epoch 38.536), train_loss = 1.30357031, grad/param norm = 5.3322e-02, time/batch = 0.0782s	
3238/4200 (epoch 38.548), train_loss = 1.30454477, grad/param norm = 5.5566e-02, time/batch = 0.0774s	
3239/4200 (epoch 38.560), train_loss = 1.32562742, grad/param norm = 5.3152e-02, time/batch = 0.0784s	
3240/4200 (epoch 38.571), train_loss = 1.28038298, grad/param norm = 4.8627e-02, time/batch = 0.0777s	
3241/4200 (epoch 38.583), train_loss = 1.31163538, grad/param norm = 5.0907e-02, time/batch = 0.0798s	
3242/4200 (epoch 38.595), train_loss = 1.30875011, grad/param norm = 5.1394e-02, time/batch = 0.0777s	
3243/4200 (epoch 38.607), train_loss = 1.29137164, grad/param norm = 5.4844e-02, time/batch = 0.0780s	
3244/4200 (epoch 38.619), train_loss = 1.29672549, grad/param norm = 4.9054e-02, time/batch = 0.0783s	
3245/4200 (epoch 38.631), train_loss = 1.29218178, grad/param norm = 4.6958e-02, time/batch = 0.0780s	
3246/4200 (epoch 38.643), train_loss = 1.29783869, grad/param norm = 5.1239e-02, time/batch = 0.0775s	
3247/4200 (epoch 38.655), train_loss = 1.31104722, grad/param norm = 5.1559e-02, time/batch = 0.0781s	
3248/4200 (epoch 38.667), train_loss = 1.31996029, grad/param norm = 4.9709e-02, time/batch = 0.0775s	
3249/4200 (epoch 38.679), train_loss = 1.31357175, grad/param norm = 5.1719e-02, time/batch = 0.0782s	
3250/4200 (epoch 38.690), train_loss = 1.30173758, grad/param norm = 5.7329e-02, time/batch = 0.0783s	
3251/4200 (epoch 38.702), train_loss = 1.29495148, grad/param norm = 6.0259e-02, time/batch = 0.0798s	
3252/4200 (epoch 38.714), train_loss = 1.31692641, grad/param norm = 5.4247e-02, time/batch = 0.0778s	
3253/4200 (epoch 38.726), train_loss = 1.32203152, grad/param norm = 4.8125e-02, time/batch = 0.0779s	
3254/4200 (epoch 38.738), train_loss = 1.30416362, grad/param norm = 6.2551e-02, time/batch = 0.0782s	
3255/4200 (epoch 38.750), train_loss = 1.32744973, grad/param norm = 6.3814e-02, time/batch = 0.0786s	
3256/4200 (epoch 38.762), train_loss = 1.31702004, grad/param norm = 5.5712e-02, time/batch = 0.0774s	
3257/4200 (epoch 38.774), train_loss = 1.32434612, grad/param norm = 5.5241e-02, time/batch = 0.0782s	
3258/4200 (epoch 38.786), train_loss = 1.30282557, grad/param norm = 5.3094e-02, time/batch = 0.0776s	
3259/4200 (epoch 38.798), train_loss = 1.31296619, grad/param norm = 5.1472e-02, time/batch = 0.0782s	
3260/4200 (epoch 38.810), train_loss = 1.32368052, grad/param norm = 5.7399e-02, time/batch = 0.0783s	
3261/4200 (epoch 38.821), train_loss = 1.30832960, grad/param norm = 5.8237e-02, time/batch = 0.0798s	
3262/4200 (epoch 38.833), train_loss = 1.32494447, grad/param norm = 5.4163e-02, time/batch = 0.0778s	
3263/4200 (epoch 38.845), train_loss = 1.33121132, grad/param norm = 5.2179e-02, time/batch = 0.0791s	
3264/4200 (epoch 38.857), train_loss = 1.33660920, grad/param norm = 5.3170e-02, time/batch = 0.0781s	
3265/4200 (epoch 38.869), train_loss = 1.34407236, grad/param norm = 5.4426e-02, time/batch = 0.0786s	
3266/4200 (epoch 38.881), train_loss = 1.32146077, grad/param norm = 5.6634e-02, time/batch = 0.0775s	
3267/4200 (epoch 38.893), train_loss = 1.33190668, grad/param norm = 5.3889e-02, time/batch = 0.0786s	
3268/4200 (epoch 38.905), train_loss = 1.31666823, grad/param norm = 4.8229e-02, time/batch = 0.0775s	
3269/4200 (epoch 38.917), train_loss = 1.32645700, grad/param norm = 5.0228e-02, time/batch = 0.0782s	
3270/4200 (epoch 38.929), train_loss = 1.31762977, grad/param norm = 5.0952e-02, time/batch = 0.0779s	
3271/4200 (epoch 38.940), train_loss = 1.32533424, grad/param norm = 5.7138e-02, time/batch = 0.0798s	
3272/4200 (epoch 38.952), train_loss = 1.33411819, grad/param norm = 6.8704e-02, time/batch = 0.0777s	
3273/4200 (epoch 38.964), train_loss = 1.33477561, grad/param norm = 6.8257e-02, time/batch = 0.0778s	
3274/4200 (epoch 38.976), train_loss = 1.32432881, grad/param norm = 5.0772e-02, time/batch = 0.0778s	
3275/4200 (epoch 38.988), train_loss = 1.31916855, grad/param norm = 5.2915e-02, time/batch = 0.0783s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
3276/4200 (epoch 39.000), train_loss = 1.35773187, grad/param norm = 5.7853e-02, time/batch = 0.0780s	
3277/4200 (epoch 39.012), train_loss = 1.49379490, grad/param norm = 7.1219e-02, time/batch = 0.0799s	
3278/4200 (epoch 39.024), train_loss = 1.30378985, grad/param norm = 5.6188e-02, time/batch = 0.0801s	
3279/4200 (epoch 39.036), train_loss = 1.31375197, grad/param norm = 5.1655e-02, time/batch = 0.0783s	
3280/4200 (epoch 39.048), train_loss = 1.28984347, grad/param norm = 5.0644e-02, time/batch = 0.0779s	
3281/4200 (epoch 39.060), train_loss = 1.31331237, grad/param norm = 5.3240e-02, time/batch = 0.0803s	
3282/4200 (epoch 39.071), train_loss = 1.30740890, grad/param norm = 5.1440e-02, time/batch = 0.0777s	
3283/4200 (epoch 39.083), train_loss = 1.30109231, grad/param norm = 5.3710e-02, time/batch = 0.0781s	
3284/4200 (epoch 39.095), train_loss = 1.29684496, grad/param norm = 4.9814e-02, time/batch = 0.0782s	
3285/4200 (epoch 39.107), train_loss = 1.30651666, grad/param norm = 5.2891e-02, time/batch = 0.0781s	
3286/4200 (epoch 39.119), train_loss = 1.30086751, grad/param norm = 4.9253e-02, time/batch = 0.0778s	
3287/4200 (epoch 39.131), train_loss = 1.30858212, grad/param norm = 4.9975e-02, time/batch = 0.0781s	
3288/4200 (epoch 39.143), train_loss = 1.31007668, grad/param norm = 4.8166e-02, time/batch = 0.0775s	
3289/4200 (epoch 39.155), train_loss = 1.29378563, grad/param norm = 4.9523e-02, time/batch = 0.0783s	
3290/4200 (epoch 39.167), train_loss = 1.31543802, grad/param norm = 6.3201e-02, time/batch = 0.0778s	
3291/4200 (epoch 39.179), train_loss = 1.32442910, grad/param norm = 5.7880e-02, time/batch = 0.0799s	
3292/4200 (epoch 39.190), train_loss = 1.30092623, grad/param norm = 5.3843e-02, time/batch = 0.0778s	
3293/4200 (epoch 39.202), train_loss = 1.33150504, grad/param norm = 5.8132e-02, time/batch = 0.0778s	
3294/4200 (epoch 39.214), train_loss = 1.31175007, grad/param norm = 5.4243e-02, time/batch = 0.0780s	
3295/4200 (epoch 39.226), train_loss = 1.31988723, grad/param norm = 5.1983e-02, time/batch = 0.0783s	
3296/4200 (epoch 39.238), train_loss = 1.30807713, grad/param norm = 5.4272e-02, time/batch = 0.0776s	
3297/4200 (epoch 39.250), train_loss = 1.29641652, grad/param norm = 5.4458e-02, time/batch = 0.0787s	
3298/4200 (epoch 39.262), train_loss = 1.26579365, grad/param norm = 5.3683e-02, time/batch = 0.0775s	
3299/4200 (epoch 39.274), train_loss = 1.31122131, grad/param norm = 5.1850e-02, time/batch = 0.0780s	
3300/4200 (epoch 39.286), train_loss = 1.31587690, grad/param norm = 4.8155e-02, time/batch = 0.0780s	
3301/4200 (epoch 39.298), train_loss = 1.29048706, grad/param norm = 6.0091e-02, time/batch = 0.0798s	
3302/4200 (epoch 39.310), train_loss = 1.32914222, grad/param norm = 5.5687e-02, time/batch = 0.0781s	
3303/4200 (epoch 39.321), train_loss = 1.27877286, grad/param norm = 5.2322e-02, time/batch = 0.0779s	
3304/4200 (epoch 39.333), train_loss = 1.30904321, grad/param norm = 5.0687e-02, time/batch = 0.0779s	
3305/4200 (epoch 39.345), train_loss = 1.29768878, grad/param norm = 5.3682e-02, time/batch = 0.0784s	
3306/4200 (epoch 39.357), train_loss = 1.30556057, grad/param norm = 5.5831e-02, time/batch = 0.0777s	
3307/4200 (epoch 39.369), train_loss = 1.31427045, grad/param norm = 5.7494e-02, time/batch = 0.0783s	
3308/4200 (epoch 39.381), train_loss = 1.31300291, grad/param norm = 5.7323e-02, time/batch = 0.0781s	
3309/4200 (epoch 39.393), train_loss = 1.33424934, grad/param norm = 6.0456e-02, time/batch = 0.0780s	
3310/4200 (epoch 39.405), train_loss = 1.33014114, grad/param norm = 5.0853e-02, time/batch = 0.0778s	
3311/4200 (epoch 39.417), train_loss = 1.28340315, grad/param norm = 4.9993e-02, time/batch = 0.0797s	
3312/4200 (epoch 39.429), train_loss = 1.29973454, grad/param norm = 4.8031e-02, time/batch = 0.0776s	
3313/4200 (epoch 39.440), train_loss = 1.31156111, grad/param norm = 5.1360e-02, time/batch = 0.0783s	
3314/4200 (epoch 39.452), train_loss = 1.31697212, grad/param norm = 5.3452e-02, time/batch = 0.0780s	
3315/4200 (epoch 39.464), train_loss = 1.31845138, grad/param norm = 4.9632e-02, time/batch = 0.0782s	
3316/4200 (epoch 39.476), train_loss = 1.33204512, grad/param norm = 5.0633e-02, time/batch = 0.0776s	
3317/4200 (epoch 39.488), train_loss = 1.32862752, grad/param norm = 6.4777e-02, time/batch = 0.0782s	
3318/4200 (epoch 39.500), train_loss = 1.30087828, grad/param norm = 4.9142e-02, time/batch = 0.0781s	
3319/4200 (epoch 39.512), train_loss = 1.30717774, grad/param norm = 4.4512e-02, time/batch = 0.0783s	
3320/4200 (epoch 39.524), train_loss = 1.28526732, grad/param norm = 4.6950e-02, time/batch = 0.0785s	
3321/4200 (epoch 39.536), train_loss = 1.30020227, grad/param norm = 5.3081e-02, time/batch = 0.0799s	
3322/4200 (epoch 39.548), train_loss = 1.30124832, grad/param norm = 5.4726e-02, time/batch = 0.0776s	
3323/4200 (epoch 39.560), train_loss = 1.32204569, grad/param norm = 5.2823e-02, time/batch = 0.0784s	
3324/4200 (epoch 39.571), train_loss = 1.27690455, grad/param norm = 4.7902e-02, time/batch = 0.0779s	
3325/4200 (epoch 39.583), train_loss = 1.30813484, grad/param norm = 5.0079e-02, time/batch = 0.0780s	
3326/4200 (epoch 39.595), train_loss = 1.30508938, grad/param norm = 5.0823e-02, time/batch = 0.0777s	
3327/4200 (epoch 39.607), train_loss = 1.28785730, grad/param norm = 5.4569e-02, time/batch = 0.0781s	
3328/4200 (epoch 39.619), train_loss = 1.29337491, grad/param norm = 4.8496e-02, time/batch = 0.0777s	
3329/4200 (epoch 39.631), train_loss = 1.28871662, grad/param norm = 4.5999e-02, time/batch = 0.0785s	
3330/4200 (epoch 39.643), train_loss = 1.29405360, grad/param norm = 4.9512e-02, time/batch = 0.0778s	
3331/4200 (epoch 39.655), train_loss = 1.30754473, grad/param norm = 4.9968e-02, time/batch = 0.0798s	
3332/4200 (epoch 39.667), train_loss = 1.31664773, grad/param norm = 4.9051e-02, time/batch = 0.0778s	
3333/4200 (epoch 39.679), train_loss = 1.31018217, grad/param norm = 5.2098e-02, time/batch = 0.0780s	
3334/4200 (epoch 39.690), train_loss = 1.29848032, grad/param norm = 5.6915e-02, time/batch = 0.0784s	
3335/4200 (epoch 39.702), train_loss = 1.29136220, grad/param norm = 5.8191e-02, time/batch = 0.0780s	
3336/4200 (epoch 39.714), train_loss = 1.31301752, grad/param norm = 5.1802e-02, time/batch = 0.0774s	
3337/4200 (epoch 39.726), train_loss = 1.31874492, grad/param norm = 4.9153e-02, time/batch = 0.0783s	
3338/4200 (epoch 39.738), train_loss = 1.30100649, grad/param norm = 6.7853e-02, time/batch = 0.0774s	
3339/4200 (epoch 39.750), train_loss = 1.32443713, grad/param norm = 6.3945e-02, time/batch = 0.0788s	
3340/4200 (epoch 39.762), train_loss = 1.31334033, grad/param norm = 5.3458e-02, time/batch = 0.0780s	
3341/4200 (epoch 39.774), train_loss = 1.32052248, grad/param norm = 5.4654e-02, time/batch = 0.0798s	
3342/4200 (epoch 39.786), train_loss = 1.29936572, grad/param norm = 5.3058e-02, time/batch = 0.0776s	
3343/4200 (epoch 39.798), train_loss = 1.30924497, grad/param norm = 5.1667e-02, time/batch = 0.0779s	
3344/4200 (epoch 39.810), train_loss = 1.32036467, grad/param norm = 5.7531e-02, time/batch = 0.0779s	
3345/4200 (epoch 39.821), train_loss = 1.30482373, grad/param norm = 5.7975e-02, time/batch = 0.0782s	
3346/4200 (epoch 39.833), train_loss = 1.32118111, grad/param norm = 5.2498e-02, time/batch = 0.0775s	
3347/4200 (epoch 39.845), train_loss = 1.32756358, grad/param norm = 5.0686e-02, time/batch = 0.0783s	
3348/4200 (epoch 39.857), train_loss = 1.33282848, grad/param norm = 5.1911e-02, time/batch = 0.0776s	
3349/4200 (epoch 39.869), train_loss = 1.34041843, grad/param norm = 5.4401e-02, time/batch = 0.0782s	
3350/4200 (epoch 39.881), train_loss = 1.31783585, grad/param norm = 5.5177e-02, time/batch = 0.0785s	
3351/4200 (epoch 39.893), train_loss = 1.32806133, grad/param norm = 5.1705e-02, time/batch = 0.0796s	
3352/4200 (epoch 39.905), train_loss = 1.31318682, grad/param norm = 4.7449e-02, time/batch = 0.0775s	
3353/4200 (epoch 39.917), train_loss = 1.32275292, grad/param norm = 5.1226e-02, time/batch = 0.0779s	
3354/4200 (epoch 39.929), train_loss = 1.31488377, grad/param norm = 5.2813e-02, time/batch = 0.0779s	
3355/4200 (epoch 39.940), train_loss = 1.32183920, grad/param norm = 5.6601e-02, time/batch = 0.0785s	
3356/4200 (epoch 39.952), train_loss = 1.33040092, grad/param norm = 6.4549e-02, time/batch = 0.0775s	
3357/4200 (epoch 39.964), train_loss = 1.33046561, grad/param norm = 6.2707e-02, time/batch = 0.0780s	
3358/4200 (epoch 39.976), train_loss = 1.32030962, grad/param norm = 5.0533e-02, time/batch = 0.0773s	
3359/4200 (epoch 39.988), train_loss = 1.31563011, grad/param norm = 5.5008e-02, time/batch = 0.0779s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
3360/4200 (epoch 40.000), train_loss = 1.35423039, grad/param norm = 5.8798e-02, time/batch = 0.0780s	
3361/4200 (epoch 40.012), train_loss = 1.49092210, grad/param norm = 7.1344e-02, time/batch = 0.0797s	
3362/4200 (epoch 40.024), train_loss = 1.30053429, grad/param norm = 5.6214e-02, time/batch = 0.0774s	
3363/4200 (epoch 40.036), train_loss = 1.31041426, grad/param norm = 5.2003e-02, time/batch = 0.0778s	
3364/4200 (epoch 40.048), train_loss = 1.28662286, grad/param norm = 5.0500e-02, time/batch = 0.0779s	
3365/4200 (epoch 40.060), train_loss = 1.31005514, grad/param norm = 5.2946e-02, time/batch = 0.0781s	
3366/4200 (epoch 40.071), train_loss = 1.30404262, grad/param norm = 5.1275e-02, time/batch = 0.0781s	
3367/4200 (epoch 40.083), train_loss = 1.29784237, grad/param norm = 5.3931e-02, time/batch = 0.0782s	
3368/4200 (epoch 40.095), train_loss = 1.29368054, grad/param norm = 4.9600e-02, time/batch = 0.0777s	
3369/4200 (epoch 40.107), train_loss = 1.30314375, grad/param norm = 5.2369e-02, time/batch = 0.0789s	
3370/4200 (epoch 40.119), train_loss = 1.29747133, grad/param norm = 4.9266e-02, time/batch = 0.0779s	
3371/4200 (epoch 40.131), train_loss = 1.30519094, grad/param norm = 4.9908e-02, time/batch = 0.0802s	
3372/4200 (epoch 40.143), train_loss = 1.30661229, grad/param norm = 4.7759e-02, time/batch = 0.0780s	
3373/4200 (epoch 40.155), train_loss = 1.29058801, grad/param norm = 4.9001e-02, time/batch = 0.0781s	
3374/4200 (epoch 40.167), train_loss = 1.31188147, grad/param norm = 6.1794e-02, time/batch = 0.0780s	
3375/4200 (epoch 40.179), train_loss = 1.32090602, grad/param norm = 5.5815e-02, time/batch = 0.0782s	
3376/4200 (epoch 40.190), train_loss = 1.29725599, grad/param norm = 5.2508e-02, time/batch = 0.0780s	
3377/4200 (epoch 40.202), train_loss = 1.32768854, grad/param norm = 5.6564e-02, time/batch = 0.0781s	
3378/4200 (epoch 40.214), train_loss = 1.30815168, grad/param norm = 5.2743e-02, time/batch = 0.0777s	
3379/4200 (epoch 40.226), train_loss = 1.31642062, grad/param norm = 5.1187e-02, time/batch = 0.0782s	
3380/4200 (epoch 40.238), train_loss = 1.30453838, grad/param norm = 5.4205e-02, time/batch = 0.0778s	
3381/4200 (epoch 40.250), train_loss = 1.29336313, grad/param norm = 5.4859e-02, time/batch = 0.0803s	
3382/4200 (epoch 40.262), train_loss = 1.26268324, grad/param norm = 5.3774e-02, time/batch = 0.0776s	
3383/4200 (epoch 40.274), train_loss = 1.30766583, grad/param norm = 5.1394e-02, time/batch = 0.0839s	
3384/4200 (epoch 40.286), train_loss = 1.31235821, grad/param norm = 4.7980e-02, time/batch = 0.0786s	
3385/4200 (epoch 40.298), train_loss = 1.28708198, grad/param norm = 5.9872e-02, time/batch = 0.0783s	
3386/4200 (epoch 40.310), train_loss = 1.32562748, grad/param norm = 5.5047e-02, time/batch = 0.0776s	
3387/4200 (epoch 40.321), train_loss = 1.27542511, grad/param norm = 5.2100e-02, time/batch = 0.0785s	
3388/4200 (epoch 40.333), train_loss = 1.30551414, grad/param norm = 5.0309e-02, time/batch = 0.0775s	
3389/4200 (epoch 40.345), train_loss = 1.29434205, grad/param norm = 5.3769e-02, time/batch = 0.0784s	
3390/4200 (epoch 40.357), train_loss = 1.30235238, grad/param norm = 5.6193e-02, time/batch = 0.0783s	
3391/4200 (epoch 40.369), train_loss = 1.31101892, grad/param norm = 5.7778e-02, time/batch = 0.0799s	
3392/4200 (epoch 40.381), train_loss = 1.30964866, grad/param norm = 5.7325e-02, time/batch = 0.0781s	
3393/4200 (epoch 40.393), train_loss = 1.33087958, grad/param norm = 5.9549e-02, time/batch = 0.0780s	
3394/4200 (epoch 40.405), train_loss = 1.32686082, grad/param norm = 4.9871e-02, time/batch = 0.0780s	
3395/4200 (epoch 40.417), train_loss = 1.27983850, grad/param norm = 4.9466e-02, time/batch = 0.0780s	
3396/4200 (epoch 40.429), train_loss = 1.29659207, grad/param norm = 4.7924e-02, time/batch = 0.0774s	
3397/4200 (epoch 40.440), train_loss = 1.30818084, grad/param norm = 5.1016e-02, time/batch = 0.0786s	
3398/4200 (epoch 40.452), train_loss = 1.31333102, grad/param norm = 5.2578e-02, time/batch = 0.0776s	
3399/4200 (epoch 40.464), train_loss = 1.31519731, grad/param norm = 4.9020e-02, time/batch = 0.0781s	
3400/4200 (epoch 40.476), train_loss = 1.32876471, grad/param norm = 5.0711e-02, time/batch = 0.0778s	
3401/4200 (epoch 40.488), train_loss = 1.32496842, grad/param norm = 6.3845e-02, time/batch = 0.0799s	
3402/4200 (epoch 40.500), train_loss = 1.29745288, grad/param norm = 4.8266e-02, time/batch = 0.0775s	
3403/4200 (epoch 40.512), train_loss = 1.30377150, grad/param norm = 4.4901e-02, time/batch = 0.0780s	
3404/4200 (epoch 40.524), train_loss = 1.28238963, grad/param norm = 4.7429e-02, time/batch = 0.0780s	
3405/4200 (epoch 40.536), train_loss = 1.29709342, grad/param norm = 5.3091e-02, time/batch = 0.0780s	
3406/4200 (epoch 40.548), train_loss = 1.29819828, grad/param norm = 5.4471e-02, time/batch = 0.0776s	
3407/4200 (epoch 40.560), train_loss = 1.31867573, grad/param norm = 5.2942e-02, time/batch = 0.0780s	
3408/4200 (epoch 40.571), train_loss = 1.27363880, grad/param norm = 4.7524e-02, time/batch = 0.0778s	
3409/4200 (epoch 40.583), train_loss = 1.30482923, grad/param norm = 4.9567e-02, time/batch = 0.0779s	
3410/4200 (epoch 40.595), train_loss = 1.30158880, grad/param norm = 5.0276e-02, time/batch = 0.0780s	
3411/4200 (epoch 40.607), train_loss = 1.28457537, grad/param norm = 5.4274e-02, time/batch = 0.0799s	
3412/4200 (epoch 40.619), train_loss = 1.29010185, grad/param norm = 4.7588e-02, time/batch = 0.0777s	
3413/4200 (epoch 40.631), train_loss = 1.28539840, grad/param norm = 4.5134e-02, time/batch = 0.0783s	
3414/4200 (epoch 40.643), train_loss = 1.29050362, grad/param norm = 4.8458e-02, time/batch = 0.0781s	
3415/4200 (epoch 40.655), train_loss = 1.30428041, grad/param norm = 4.9064e-02, time/batch = 0.0781s	
3416/4200 (epoch 40.667), train_loss = 1.31357236, grad/param norm = 4.8783e-02, time/batch = 0.0776s	
3417/4200 (epoch 40.679), train_loss = 1.30691814, grad/param norm = 5.2163e-02, time/batch = 0.0781s	
3418/4200 (epoch 40.690), train_loss = 1.29533131, grad/param norm = 5.6228e-02, time/batch = 0.0775s	
3419/4200 (epoch 40.702), train_loss = 1.28790608, grad/param norm = 5.6430e-02, time/batch = 0.0787s	
3420/4200 (epoch 40.714), train_loss = 1.30935886, grad/param norm = 5.0205e-02, time/batch = 0.0779s	
3421/4200 (epoch 40.726), train_loss = 1.31576242, grad/param norm = 5.0569e-02, time/batch = 0.0798s	
3422/4200 (epoch 40.738), train_loss = 1.29785177, grad/param norm = 7.0619e-02, time/batch = 0.0778s	
3423/4200 (epoch 40.750), train_loss = 1.32112066, grad/param norm = 6.2871e-02, time/batch = 0.0779s	
3424/4200 (epoch 40.762), train_loss = 1.30979099, grad/param norm = 5.2105e-02, time/batch = 0.0785s	
3425/4200 (epoch 40.774), train_loss = 1.31694783, grad/param norm = 5.4192e-02, time/batch = 0.0783s	
3426/4200 (epoch 40.786), train_loss = 1.29604707, grad/param norm = 5.2782e-02, time/batch = 0.0779s	
3427/4200 (epoch 40.798), train_loss = 1.30570203, grad/param norm = 5.1910e-02, time/batch = 0.0782s	
3428/4200 (epoch 40.810), train_loss = 1.31724014, grad/param norm = 5.7941e-02, time/batch = 0.0774s	
3429/4200 (epoch 40.821), train_loss = 1.30151192, grad/param norm = 5.7979e-02, time/batch = 0.0785s	
3430/4200 (epoch 40.833), train_loss = 1.31773257, grad/param norm = 5.1717e-02, time/batch = 0.0779s	
3431/4200 (epoch 40.845), train_loss = 1.32426295, grad/param norm = 5.0429e-02, time/batch = 0.0799s	
3432/4200 (epoch 40.857), train_loss = 1.32936488, grad/param norm = 5.1477e-02, time/batch = 0.0778s	
3433/4200 (epoch 40.869), train_loss = 1.33688583, grad/param norm = 5.3728e-02, time/batch = 0.0781s	
3434/4200 (epoch 40.881), train_loss = 1.31425482, grad/param norm = 5.3186e-02, time/batch = 0.0784s	
3435/4200 (epoch 40.893), train_loss = 1.32442381, grad/param norm = 5.0331e-02, time/batch = 0.0780s	
3436/4200 (epoch 40.905), train_loss = 1.31000448, grad/param norm = 4.8308e-02, time/batch = 0.0777s	
3437/4200 (epoch 40.917), train_loss = 1.31948632, grad/param norm = 5.3380e-02, time/batch = 0.0782s	
3438/4200 (epoch 40.929), train_loss = 1.31204373, grad/param norm = 5.3548e-02, time/batch = 0.0776s	
3439/4200 (epoch 40.940), train_loss = 1.31833054, grad/param norm = 5.4682e-02, time/batch = 0.0781s	
3440/4200 (epoch 40.952), train_loss = 1.32667591, grad/param norm = 6.1232e-02, time/batch = 0.0785s	
3441/4200 (epoch 40.964), train_loss = 1.32658575, grad/param norm = 5.9852e-02, time/batch = 0.0797s	
3442/4200 (epoch 40.976), train_loss = 1.31669529, grad/param norm = 5.0653e-02, time/batch = 0.0777s	
3443/4200 (epoch 40.988), train_loss = 1.31223182, grad/param norm = 5.5745e-02, time/batch = 0.0780s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
3444/4200 (epoch 41.000), train_loss = 1.35074446, grad/param norm = 5.8438e-02, time/batch = 0.0781s	
3445/4200 (epoch 41.012), train_loss = 1.48801610, grad/param norm = 7.0819e-02, time/batch = 0.0786s	
3446/4200 (epoch 41.024), train_loss = 1.29739551, grad/param norm = 5.6125e-02, time/batch = 0.0775s	
3447/4200 (epoch 41.036), train_loss = 1.30715058, grad/param norm = 5.1804e-02, time/batch = 0.0782s	
3448/4200 (epoch 41.048), train_loss = 1.28347315, grad/param norm = 5.0070e-02, time/batch = 0.0774s	
3449/4200 (epoch 41.060), train_loss = 1.30690623, grad/param norm = 5.2382e-02, time/batch = 0.0780s	
3450/4200 (epoch 41.071), train_loss = 1.30083706, grad/param norm = 5.1080e-02, time/batch = 0.0782s	
3451/4200 (epoch 41.083), train_loss = 1.29472270, grad/param norm = 5.3796e-02, time/batch = 0.0797s	
3452/4200 (epoch 41.095), train_loss = 1.29067009, grad/param norm = 4.9376e-02, time/batch = 0.0777s	
3453/4200 (epoch 41.107), train_loss = 1.29994570, grad/param norm = 5.1884e-02, time/batch = 0.0782s	
3454/4200 (epoch 41.119), train_loss = 1.29416282, grad/param norm = 4.8957e-02, time/batch = 0.0780s	
3455/4200 (epoch 41.131), train_loss = 1.30198042, grad/param norm = 4.9701e-02, time/batch = 0.0782s	
3456/4200 (epoch 41.143), train_loss = 1.30335223, grad/param norm = 4.7521e-02, time/batch = 0.0776s	
3457/4200 (epoch 41.155), train_loss = 1.28765300, grad/param norm = 4.8955e-02, time/batch = 0.0782s	
3458/4200 (epoch 41.167), train_loss = 1.30867153, grad/param norm = 6.1420e-02, time/batch = 0.0775s	
3459/4200 (epoch 41.179), train_loss = 1.31776206, grad/param norm = 5.4904e-02, time/batch = 0.0782s	
3460/4200 (epoch 41.190), train_loss = 1.29399254, grad/param norm = 5.2301e-02, time/batch = 0.0779s	
3461/4200 (epoch 41.202), train_loss = 1.32424489, grad/param norm = 5.6009e-02, time/batch = 0.0802s	
3462/4200 (epoch 41.214), train_loss = 1.30479537, grad/param norm = 5.1848e-02, time/batch = 0.0776s	
3463/4200 (epoch 41.226), train_loss = 1.31313522, grad/param norm = 5.0609e-02, time/batch = 0.0778s	
3464/4200 (epoch 41.238), train_loss = 1.30119044, grad/param norm = 5.4233e-02, time/batch = 0.0779s	
3465/4200 (epoch 41.250), train_loss = 1.29041801, grad/param norm = 5.5042e-02, time/batch = 0.0782s	
3466/4200 (epoch 41.262), train_loss = 1.25966955, grad/param norm = 5.3601e-02, time/batch = 0.0777s	
3467/4200 (epoch 41.274), train_loss = 1.30425914, grad/param norm = 5.0862e-02, time/batch = 0.0782s	
3468/4200 (epoch 41.286), train_loss = 1.30896878, grad/param norm = 4.7869e-02, time/batch = 0.0775s	
3469/4200 (epoch 41.298), train_loss = 1.28380679, grad/param norm = 5.9563e-02, time/batch = 0.0781s	
3470/4200 (epoch 41.310), train_loss = 1.32222740, grad/param norm = 5.4225e-02, time/batch = 0.0778s	
3471/4200 (epoch 41.321), train_loss = 1.27224125, grad/param norm = 5.1954e-02, time/batch = 0.0803s	
3472/4200 (epoch 41.333), train_loss = 1.30210263, grad/param norm = 4.9913e-02, time/batch = 0.0775s	
3473/4200 (epoch 41.345), train_loss = 1.29113720, grad/param norm = 5.3796e-02, time/batch = 0.0779s	
3474/4200 (epoch 41.357), train_loss = 1.29924174, grad/param norm = 5.6280e-02, time/batch = 0.0789s	
3475/4200 (epoch 41.369), train_loss = 1.30786700, grad/param norm = 5.7697e-02, time/batch = 0.0784s	
3476/4200 (epoch 41.381), train_loss = 1.30634303, grad/param norm = 5.6693e-02, time/batch = 0.0775s	
3477/4200 (epoch 41.393), train_loss = 1.32754358, grad/param norm = 5.7867e-02, time/batch = 0.0786s	
3478/4200 (epoch 41.405), train_loss = 1.32366277, grad/param norm = 4.8584e-02, time/batch = 0.0778s	
3479/4200 (epoch 41.417), train_loss = 1.27644396, grad/param norm = 4.8971e-02, time/batch = 0.0783s	
3480/4200 (epoch 41.429), train_loss = 1.29357448, grad/param norm = 4.7791e-02, time/batch = 0.0778s	
3481/4200 (epoch 41.440), train_loss = 1.30497505, grad/param norm = 5.0702e-02, time/batch = 0.0797s	
3482/4200 (epoch 41.452), train_loss = 1.30987277, grad/param norm = 5.1934e-02, time/batch = 0.0780s	
3483/4200 (epoch 41.464), train_loss = 1.31211455, grad/param norm = 4.8550e-02, time/batch = 0.0778s	
3484/4200 (epoch 41.476), train_loss = 1.32563970, grad/param norm = 5.0673e-02, time/batch = 0.0780s	
3485/4200 (epoch 41.488), train_loss = 1.32146720, grad/param norm = 6.2782e-02, time/batch = 0.0780s	
3486/4200 (epoch 41.500), train_loss = 1.29421346, grad/param norm = 4.7516e-02, time/batch = 0.0779s	
3487/4200 (epoch 41.512), train_loss = 1.30053581, grad/param norm = 4.5257e-02, time/batch = 0.0786s	
3488/4200 (epoch 41.524), train_loss = 1.27965497, grad/param norm = 4.7774e-02, time/batch = 0.0775s	
3489/4200 (epoch 41.536), train_loss = 1.29410311, grad/param norm = 5.3050e-02, time/batch = 0.0825s	
3490/4200 (epoch 41.548), train_loss = 1.29532901, grad/param norm = 5.4331e-02, time/batch = 0.0785s	
3491/4200 (epoch 41.560), train_loss = 1.31549179, grad/param norm = 5.3154e-02, time/batch = 0.0799s	
3492/4200 (epoch 41.571), train_loss = 1.27054894, grad/param norm = 4.7218e-02, time/batch = 0.0781s	
3493/4200 (epoch 41.583), train_loss = 1.30169279, grad/param norm = 4.9227e-02, time/batch = 0.0780s	
3494/4200 (epoch 41.595), train_loss = 1.29828057, grad/param norm = 4.9796e-02, time/batch = 0.0778s	
3495/4200 (epoch 41.607), train_loss = 1.28126243, grad/param norm = 5.3756e-02, time/batch = 0.0785s	
3496/4200 (epoch 41.619), train_loss = 1.28704575, grad/param norm = 4.6929e-02, time/batch = 0.0779s	
3497/4200 (epoch 41.631), train_loss = 1.28228193, grad/param norm = 4.4612e-02, time/batch = 0.0781s	
3498/4200 (epoch 41.643), train_loss = 1.28719215, grad/param norm = 4.7813e-02, time/batch = 0.0779s	
3499/4200 (epoch 41.655), train_loss = 1.30119029, grad/param norm = 4.8480e-02, time/batch = 0.0780s	
3500/4200 (epoch 41.667), train_loss = 1.31064159, grad/param norm = 4.8478e-02, time/batch = 0.0778s	
3501/4200 (epoch 41.679), train_loss = 1.30370909, grad/param norm = 5.1674e-02, time/batch = 0.0798s	
3502/4200 (epoch 41.690), train_loss = 1.29221790, grad/param norm = 5.5259e-02, time/batch = 0.0776s	
3503/4200 (epoch 41.702), train_loss = 1.28461602, grad/param norm = 5.4960e-02, time/batch = 0.0786s	
3504/4200 (epoch 41.714), train_loss = 1.30591835, grad/param norm = 4.9183e-02, time/batch = 0.0779s	
3505/4200 (epoch 41.726), train_loss = 1.31298045, grad/param norm = 5.1986e-02, time/batch = 0.0782s	
3506/4200 (epoch 41.738), train_loss = 1.29469018, grad/param norm = 7.1722e-02, time/batch = 0.0775s	
3507/4200 (epoch 41.750), train_loss = 1.31772151, grad/param norm = 6.1355e-02, time/batch = 0.0784s	
3508/4200 (epoch 41.762), train_loss = 1.30647732, grad/param norm = 5.1213e-02, time/batch = 0.0780s	
3509/4200 (epoch 41.774), train_loss = 1.31358250, grad/param norm = 5.3685e-02, time/batch = 0.0780s	
3510/4200 (epoch 41.786), train_loss = 1.29283717, grad/param norm = 5.2319e-02, time/batch = 0.0777s	
3511/4200 (epoch 41.798), train_loss = 1.30227216, grad/param norm = 5.1881e-02, time/batch = 0.0799s	
3512/4200 (epoch 41.810), train_loss = 1.31417006, grad/param norm = 5.7910e-02, time/batch = 0.0776s	
3513/4200 (epoch 41.821), train_loss = 1.29829540, grad/param norm = 5.7610e-02, time/batch = 0.0780s	
3514/4200 (epoch 41.833), train_loss = 1.31450073, grad/param norm = 5.1354e-02, time/batch = 0.0782s	
3515/4200 (epoch 41.845), train_loss = 1.32119624, grad/param norm = 5.0769e-02, time/batch = 0.0780s	
3516/4200 (epoch 41.857), train_loss = 1.32618668, grad/param norm = 5.1680e-02, time/batch = 0.0777s	
3517/4200 (epoch 41.869), train_loss = 1.33356437, grad/param norm = 5.3117e-02, time/batch = 0.0783s	
3518/4200 (epoch 41.881), train_loss = 1.31084516, grad/param norm = 5.1646e-02, time/batch = 0.0774s	
3519/4200 (epoch 41.893), train_loss = 1.32101535, grad/param norm = 4.9564e-02, time/batch = 0.0785s	
3520/4200 (epoch 41.905), train_loss = 1.30699633, grad/param norm = 4.9335e-02, time/batch = 0.0777s	
3521/4200 (epoch 41.917), train_loss = 1.31641331, grad/param norm = 5.5109e-02, time/batch = 0.0799s	
3522/4200 (epoch 41.929), train_loss = 1.30915171, grad/param norm = 5.3704e-02, time/batch = 0.0778s	
3523/4200 (epoch 41.940), train_loss = 1.31500300, grad/param norm = 5.3001e-02, time/batch = 0.0779s	
3524/4200 (epoch 41.952), train_loss = 1.32318510, grad/param norm = 5.8995e-02, time/batch = 0.0784s	
3525/4200 (epoch 41.964), train_loss = 1.32304523, grad/param norm = 5.7855e-02, time/batch = 0.0780s	
3526/4200 (epoch 41.976), train_loss = 1.31332032, grad/param norm = 5.0251e-02, time/batch = 0.0775s	
3527/4200 (epoch 41.988), train_loss = 1.30893256, grad/param norm = 5.5358e-02, time/batch = 0.0781s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
3528/4200 (epoch 42.000), train_loss = 1.34730372, grad/param norm = 5.7155e-02, time/batch = 0.0778s	
3529/4200 (epoch 42.012), train_loss = 1.48516602, grad/param norm = 6.9830e-02, time/batch = 0.0780s	
3530/4200 (epoch 42.024), train_loss = 1.29439109, grad/param norm = 5.5970e-02, time/batch = 0.0777s	
3531/4200 (epoch 42.036), train_loss = 1.30401615, grad/param norm = 5.1313e-02, time/batch = 0.0801s	
3532/4200 (epoch 42.048), train_loss = 1.28045797, grad/param norm = 4.9568e-02, time/batch = 0.0778s	
3533/4200 (epoch 42.060), train_loss = 1.30391611, grad/param norm = 5.1854e-02, time/batch = 0.0781s	
3534/4200 (epoch 42.071), train_loss = 1.29778277, grad/param norm = 5.0938e-02, time/batch = 0.0781s	
3535/4200 (epoch 42.083), train_loss = 1.29174730, grad/param norm = 5.3538e-02, time/batch = 0.0787s	
3536/4200 (epoch 42.095), train_loss = 1.28777960, grad/param norm = 4.9144e-02, time/batch = 0.0777s	
3537/4200 (epoch 42.107), train_loss = 1.29692629, grad/param norm = 5.1505e-02, time/batch = 0.0782s	
3538/4200 (epoch 42.119), train_loss = 1.29101487, grad/param norm = 4.8710e-02, time/batch = 0.0775s	
3539/4200 (epoch 42.131), train_loss = 1.29894496, grad/param norm = 4.9562e-02, time/batch = 0.0782s	
3540/4200 (epoch 42.143), train_loss = 1.30027399, grad/param norm = 4.7389e-02, time/batch = 0.0782s	
3541/4200 (epoch 42.155), train_loss = 1.28487246, grad/param norm = 4.8942e-02, time/batch = 0.0798s	
3542/4200 (epoch 42.167), train_loss = 1.30562274, grad/param norm = 6.1112e-02, time/batch = 0.0776s	
3543/4200 (epoch 42.179), train_loss = 1.31478992, grad/param norm = 5.4164e-02, time/batch = 0.0778s	
3544/4200 (epoch 42.190), train_loss = 1.29091831, grad/param norm = 5.2161e-02, time/batch = 0.0779s	
3545/4200 (epoch 42.202), train_loss = 1.32094687, grad/param norm = 5.5483e-02, time/batch = 0.0787s	
3546/4200 (epoch 42.214), train_loss = 1.30158970, grad/param norm = 5.1037e-02, time/batch = 0.0777s	
3547/4200 (epoch 42.226), train_loss = 1.31000080, grad/param norm = 5.0172e-02, time/batch = 0.0781s	
3548/4200 (epoch 42.238), train_loss = 1.29804908, grad/param norm = 5.4291e-02, time/batch = 0.0776s	
3549/4200 (epoch 42.250), train_loss = 1.28759093, grad/param norm = 5.5056e-02, time/batch = 0.0784s	
3550/4200 (epoch 42.262), train_loss = 1.25674795, grad/param norm = 5.3223e-02, time/batch = 0.0778s	
3551/4200 (epoch 42.274), train_loss = 1.30103026, grad/param norm = 5.0348e-02, time/batch = 0.0798s	
3552/4200 (epoch 42.286), train_loss = 1.30571841, grad/param norm = 4.7784e-02, time/batch = 0.0776s	
3553/4200 (epoch 42.298), train_loss = 1.28069462, grad/param norm = 5.9216e-02, time/batch = 0.0779s	
3554/4200 (epoch 42.310), train_loss = 1.31898750, grad/param norm = 5.3434e-02, time/batch = 0.0780s	
3555/4200 (epoch 42.321), train_loss = 1.26921093, grad/param norm = 5.1877e-02, time/batch = 0.0781s	
3556/4200 (epoch 42.333), train_loss = 1.29886525, grad/param norm = 4.9559e-02, time/batch = 0.0780s	
3557/4200 (epoch 42.345), train_loss = 1.28809748, grad/param norm = 5.3862e-02, time/batch = 0.0783s	
3558/4200 (epoch 42.357), train_loss = 1.29626187, grad/param norm = 5.6308e-02, time/batch = 0.0776s	
3559/4200 (epoch 42.369), train_loss = 1.30485504, grad/param norm = 5.7490e-02, time/batch = 0.0783s	
3560/4200 (epoch 42.381), train_loss = 1.30317292, grad/param norm = 5.5818e-02, time/batch = 0.0780s	
3561/4200 (epoch 42.393), train_loss = 1.32433729, grad/param norm = 5.6228e-02, time/batch = 0.0802s	
3562/4200 (epoch 42.405), train_loss = 1.32066872, grad/param norm = 4.7635e-02, time/batch = 0.0775s	
3563/4200 (epoch 42.417), train_loss = 1.27327028, grad/param norm = 4.8673e-02, time/batch = 0.0779s	
3564/4200 (epoch 42.429), train_loss = 1.29068330, grad/param norm = 4.7617e-02, time/batch = 0.0778s	
3565/4200 (epoch 42.440), train_loss = 1.30191269, grad/param norm = 5.0342e-02, time/batch = 0.0779s	
3566/4200 (epoch 42.452), train_loss = 1.30656387, grad/param norm = 5.1424e-02, time/batch = 0.0776s	
3567/4200 (epoch 42.464), train_loss = 1.30919199, grad/param norm = 4.8220e-02, time/batch = 0.0783s	
3568/4200 (epoch 42.476), train_loss = 1.32269215, grad/param norm = 5.0683e-02, time/batch = 0.0774s	
3569/4200 (epoch 42.488), train_loss = 1.31817940, grad/param norm = 6.1867e-02, time/batch = 0.0781s	
3570/4200 (epoch 42.500), train_loss = 1.29116050, grad/param norm = 4.6999e-02, time/batch = 0.0780s	
3571/4200 (epoch 42.512), train_loss = 1.29745845, grad/param norm = 4.5527e-02, time/batch = 0.0796s	
3572/4200 (epoch 42.524), train_loss = 1.27703808, grad/param norm = 4.7835e-02, time/batch = 0.0777s	
3573/4200 (epoch 42.536), train_loss = 1.29119328, grad/param norm = 5.2727e-02, time/batch = 0.0778s	
3574/4200 (epoch 42.548), train_loss = 1.29256194, grad/param norm = 5.4008e-02, time/batch = 0.0778s	
3575/4200 (epoch 42.560), train_loss = 1.31244516, grad/param norm = 5.3242e-02, time/batch = 0.0781s	
3576/4200 (epoch 42.571), train_loss = 1.26759746, grad/param norm = 4.6814e-02, time/batch = 0.0776s	
3577/4200 (epoch 42.583), train_loss = 1.29869024, grad/param norm = 4.8869e-02, time/batch = 0.0785s	
3578/4200 (epoch 42.595), train_loss = 1.29510586, grad/param norm = 4.9262e-02, time/batch = 0.0775s	
3579/4200 (epoch 42.607), train_loss = 1.27810441, grad/param norm = 5.3302e-02, time/batch = 0.0781s	
3580/4200 (epoch 42.619), train_loss = 1.28417480, grad/param norm = 4.6445e-02, time/batch = 0.0786s	
3581/4200 (epoch 42.631), train_loss = 1.27934950, grad/param norm = 4.4292e-02, time/batch = 0.0798s	
3582/4200 (epoch 42.643), train_loss = 1.28408524, grad/param norm = 4.7343e-02, time/batch = 0.0781s	
3583/4200 (epoch 42.655), train_loss = 1.29827093, grad/param norm = 4.7966e-02, time/batch = 0.0779s	
3584/4200 (epoch 42.667), train_loss = 1.30782981, grad/param norm = 4.7995e-02, time/batch = 0.0785s	
3585/4200 (epoch 42.679), train_loss = 1.30059055, grad/param norm = 5.0887e-02, time/batch = 0.0782s	
3586/4200 (epoch 42.690), train_loss = 1.28916931, grad/param norm = 5.4334e-02, time/batch = 0.0776s	
3587/4200 (epoch 42.702), train_loss = 1.28152713, grad/param norm = 5.3852e-02, time/batch = 0.0779s	
3588/4200 (epoch 42.714), train_loss = 1.30268664, grad/param norm = 4.8543e-02, time/batch = 0.0780s	
3589/4200 (epoch 42.726), train_loss = 1.31030849, grad/param norm = 5.2928e-02, time/batch = 0.0779s	
3590/4200 (epoch 42.738), train_loss = 1.29154350, grad/param norm = 7.1550e-02, time/batch = 0.0779s	
3591/4200 (epoch 42.750), train_loss = 1.31440645, grad/param norm = 5.9866e-02, time/batch = 0.0799s	
3592/4200 (epoch 42.762), train_loss = 1.30333668, grad/param norm = 5.0599e-02, time/batch = 0.0777s	
3593/4200 (epoch 42.774), train_loss = 1.31039521, grad/param norm = 5.3088e-02, time/batch = 0.0783s	
3594/4200 (epoch 42.786), train_loss = 1.28976885, grad/param norm = 5.1811e-02, time/batch = 0.0823s	
3595/4200 (epoch 42.798), train_loss = 1.29898396, grad/param norm = 5.1741e-02, time/batch = 0.0815s	
3596/4200 (epoch 42.810), train_loss = 1.31119159, grad/param norm = 5.7637e-02, time/batch = 0.0776s	
3597/4200 (epoch 42.821), train_loss = 1.29518139, grad/param norm = 5.7013e-02, time/batch = 0.0781s	
3598/4200 (epoch 42.833), train_loss = 1.31144848, grad/param norm = 5.1144e-02, time/batch = 0.0779s	
3599/4200 (epoch 42.845), train_loss = 1.31827709, grad/param norm = 5.1257e-02, time/batch = 0.0782s	
3600/4200 (epoch 42.857), train_loss = 1.32318396, grad/param norm = 5.1938e-02, time/batch = 0.0780s	
3601/4200 (epoch 42.869), train_loss = 1.33041852, grad/param norm = 5.2569e-02, time/batch = 0.0800s	
3602/4200 (epoch 42.881), train_loss = 1.30765396, grad/param norm = 5.0567e-02, time/batch = 0.0780s	
3603/4200 (epoch 42.893), train_loss = 1.31782101, grad/param norm = 4.9218e-02, time/batch = 0.0783s	
3604/4200 (epoch 42.905), train_loss = 1.30412990, grad/param norm = 5.0250e-02, time/batch = 0.0779s	
3605/4200 (epoch 42.917), train_loss = 1.31342185, grad/param norm = 5.6069e-02, time/batch = 0.0781s	
3606/4200 (epoch 42.929), train_loss = 1.30622097, grad/param norm = 5.3267e-02, time/batch = 0.0776s	
3607/4200 (epoch 42.940), train_loss = 1.31184576, grad/param norm = 5.1556e-02, time/batch = 0.0782s	
3608/4200 (epoch 42.952), train_loss = 1.31993093, grad/param norm = 5.7477e-02, time/batch = 0.0775s	
3609/4200 (epoch 42.964), train_loss = 1.31982896, grad/param norm = 5.6687e-02, time/batch = 0.0785s	
3610/4200 (epoch 42.976), train_loss = 1.31020202, grad/param norm = 5.0002e-02, time/batch = 0.0777s	
3611/4200 (epoch 42.988), train_loss = 1.30581095, grad/param norm = 5.4899e-02, time/batch = 0.0799s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
3612/4200 (epoch 43.000), train_loss = 1.34405470, grad/param norm = 5.6062e-02, time/batch = 0.0778s	
3613/4200 (epoch 43.012), train_loss = 1.48256641, grad/param norm = 6.9120e-02, time/batch = 0.0781s	
3614/4200 (epoch 43.024), train_loss = 1.29156216, grad/param norm = 5.5969e-02, time/batch = 0.0784s	
3615/4200 (epoch 43.036), train_loss = 1.30104226, grad/param norm = 5.0947e-02, time/batch = 0.0781s	
3616/4200 (epoch 43.048), train_loss = 1.27760636, grad/param norm = 4.9249e-02, time/batch = 0.0776s	
3617/4200 (epoch 43.060), train_loss = 1.30110097, grad/param norm = 5.1553e-02, time/batch = 0.0782s	
3618/4200 (epoch 43.071), train_loss = 1.29486814, grad/param norm = 5.0879e-02, time/batch = 0.0776s	
3619/4200 (epoch 43.083), train_loss = 1.28891579, grad/param norm = 5.3314e-02, time/batch = 0.0786s	
3620/4200 (epoch 43.095), train_loss = 1.28500978, grad/param norm = 4.8938e-02, time/batch = 0.0779s	
3621/4200 (epoch 43.107), train_loss = 1.29403582, grad/param norm = 5.1196e-02, time/batch = 0.0799s	
3622/4200 (epoch 43.119), train_loss = 1.28803158, grad/param norm = 4.8600e-02, time/batch = 0.0780s	
3623/4200 (epoch 43.131), train_loss = 1.29605986, grad/param norm = 4.9477e-02, time/batch = 0.0782s	
3624/4200 (epoch 43.143), train_loss = 1.29734748, grad/param norm = 4.7242e-02, time/batch = 0.0780s	
3625/4200 (epoch 43.155), train_loss = 1.28219936, grad/param norm = 4.8844e-02, time/batch = 0.0780s	
3626/4200 (epoch 43.167), train_loss = 1.30267350, grad/param norm = 6.0624e-02, time/batch = 0.0776s	
3627/4200 (epoch 43.179), train_loss = 1.31191316, grad/param norm = 5.3241e-02, time/batch = 0.0781s	
3628/4200 (epoch 43.190), train_loss = 1.28796334, grad/param norm = 5.1783e-02, time/batch = 0.0776s	
3629/4200 (epoch 43.202), train_loss = 1.31775442, grad/param norm = 5.4703e-02, time/batch = 0.0782s	
3630/4200 (epoch 43.214), train_loss = 1.29855126, grad/param norm = 5.0256e-02, time/batch = 0.0785s	
3631/4200 (epoch 43.226), train_loss = 1.30703318, grad/param norm = 4.9893e-02, time/batch = 0.0798s	
3632/4200 (epoch 43.238), train_loss = 1.29509167, grad/param norm = 5.4441e-02, time/batch = 0.0778s	
3633/4200 (epoch 43.250), train_loss = 1.28489351, grad/param norm = 5.5051e-02, time/batch = 0.0779s	
3634/4200 (epoch 43.262), train_loss = 1.25395301, grad/param norm = 5.2758e-02, time/batch = 0.0782s	
3635/4200 (epoch 43.274), train_loss = 1.29794352, grad/param norm = 4.9833e-02, time/batch = 0.0785s	
3636/4200 (epoch 43.286), train_loss = 1.30260263, grad/param norm = 4.7708e-02, time/batch = 0.0776s	
3637/4200 (epoch 43.298), train_loss = 1.27771935, grad/param norm = 5.8834e-02, time/batch = 0.0786s	
3638/4200 (epoch 43.310), train_loss = 1.31589412, grad/param norm = 5.2688e-02, time/batch = 0.0776s	
3639/4200 (epoch 43.321), train_loss = 1.26631583, grad/param norm = 5.1856e-02, time/batch = 0.0781s	
3640/4200 (epoch 43.333), train_loss = 1.29579554, grad/param norm = 4.9228e-02, time/batch = 0.0778s	
3641/4200 (epoch 43.345), train_loss = 1.28521502, grad/param norm = 5.3917e-02, time/batch = 0.0795s	
3642/4200 (epoch 43.357), train_loss = 1.29340989, grad/param norm = 5.6340e-02, time/batch = 0.0776s	
3643/4200 (epoch 43.369), train_loss = 1.30198437, grad/param norm = 5.7281e-02, time/batch = 0.0782s	
3644/4200 (epoch 43.381), train_loss = 1.30014956, grad/param norm = 5.4883e-02, time/batch = 0.0781s	
3645/4200 (epoch 43.393), train_loss = 1.32128101, grad/param norm = 5.4762e-02, time/batch = 0.0782s	
3646/4200 (epoch 43.405), train_loss = 1.31787192, grad/param norm = 4.7032e-02, time/batch = 0.0780s	
3647/4200 (epoch 43.417), train_loss = 1.27029444, grad/param norm = 4.8534e-02, time/batch = 0.0780s	
3648/4200 (epoch 43.429), train_loss = 1.28791327, grad/param norm = 4.7449e-02, time/batch = 0.0775s	
3649/4200 (epoch 43.440), train_loss = 1.29899189, grad/param norm = 4.9998e-02, time/batch = 0.0780s	
3650/4200 (epoch 43.452), train_loss = 1.30338816, grad/param norm = 5.0981e-02, time/batch = 0.0777s	
3651/4200 (epoch 43.464), train_loss = 1.30641164, grad/param norm = 4.7961e-02, time/batch = 0.0802s	
3652/4200 (epoch 43.476), train_loss = 1.31991282, grad/param norm = 5.0788e-02, time/batch = 0.0776s	
3653/4200 (epoch 43.488), train_loss = 1.31506046, grad/param norm = 6.1074e-02, time/batch = 0.0779s	
3654/4200 (epoch 43.500), train_loss = 1.28827043, grad/param norm = 4.6618e-02, time/batch = 0.0781s	
3655/4200 (epoch 43.512), train_loss = 1.29453016, grad/param norm = 4.5746e-02, time/batch = 0.0783s	
3656/4200 (epoch 43.524), train_loss = 1.27452852, grad/param norm = 4.7730e-02, time/batch = 0.0782s	
3657/4200 (epoch 43.536), train_loss = 1.28838691, grad/param norm = 5.2296e-02, time/batch = 0.0781s	
3658/4200 (epoch 43.548), train_loss = 1.28992482, grad/param norm = 5.3693e-02, time/batch = 0.0774s	
3659/4200 (epoch 43.560), train_loss = 1.30953286, grad/param norm = 5.3271e-02, time/batch = 0.0781s	
3660/4200 (epoch 43.571), train_loss = 1.26478655, grad/param norm = 4.6340e-02, time/batch = 0.0778s	
3661/4200 (epoch 43.583), train_loss = 1.29582978, grad/param norm = 4.8553e-02, time/batch = 0.0803s	
3662/4200 (epoch 43.595), train_loss = 1.29207599, grad/param norm = 4.8725e-02, time/batch = 0.0778s	
3663/4200 (epoch 43.607), train_loss = 1.27507488, grad/param norm = 5.2891e-02, time/batch = 0.0780s	
3664/4200 (epoch 43.619), train_loss = 1.28146134, grad/param norm = 4.6103e-02, time/batch = 0.0781s	
3665/4200 (epoch 43.631), train_loss = 1.27658824, grad/param norm = 4.4121e-02, time/batch = 0.0783s	
3666/4200 (epoch 43.643), train_loss = 1.28116211, grad/param norm = 4.7027e-02, time/batch = 0.0778s	
3667/4200 (epoch 43.655), train_loss = 1.29551102, grad/param norm = 4.7508e-02, time/batch = 0.0786s	
3668/4200 (epoch 43.667), train_loss = 1.30514577, grad/param norm = 4.7480e-02, time/batch = 0.0776s	
3669/4200 (epoch 43.679), train_loss = 1.29761362, grad/param norm = 5.0143e-02, time/batch = 0.0781s	
3670/4200 (epoch 43.690), train_loss = 1.28624353, grad/param norm = 5.3626e-02, time/batch = 0.0779s	
3671/4200 (epoch 43.702), train_loss = 1.27863142, grad/param norm = 5.2999e-02, time/batch = 0.0799s	
3672/4200 (epoch 43.714), train_loss = 1.29963377, grad/param norm = 4.8107e-02, time/batch = 0.0782s	
3673/4200 (epoch 43.726), train_loss = 1.30772192, grad/param norm = 5.3444e-02, time/batch = 0.0778s	
3674/4200 (epoch 43.738), train_loss = 1.28844150, grad/param norm = 7.0562e-02, time/batch = 0.0778s	
3675/4200 (epoch 43.750), train_loss = 1.31121771, grad/param norm = 5.8440e-02, time/batch = 0.0782s	
3676/4200 (epoch 43.762), train_loss = 1.30032925, grad/param norm = 5.0121e-02, time/batch = 0.0780s	
3677/4200 (epoch 43.774), train_loss = 1.30736298, grad/param norm = 5.2430e-02, time/batch = 0.0780s	
3678/4200 (epoch 43.786), train_loss = 1.28683993, grad/param norm = 5.1308e-02, time/batch = 0.0777s	
3679/4200 (epoch 43.798), train_loss = 1.29581819, grad/param norm = 5.1497e-02, time/batch = 0.0779s	
3680/4200 (epoch 43.810), train_loss = 1.30828683, grad/param norm = 5.7171e-02, time/batch = 0.0777s	
3681/4200 (epoch 43.821), train_loss = 1.29217936, grad/param norm = 5.6283e-02, time/batch = 0.0797s	
3682/4200 (epoch 43.833), train_loss = 1.30856444, grad/param norm = 5.1060e-02, time/batch = 0.0776s	
3683/4200 (epoch 43.845), train_loss = 1.31546101, grad/param norm = 5.1798e-02, time/batch = 0.0778s	
3684/4200 (epoch 43.857), train_loss = 1.32031826, grad/param norm = 5.2146e-02, time/batch = 0.0779s	
3685/4200 (epoch 43.869), train_loss = 1.32741746, grad/param norm = 5.2039e-02, time/batch = 0.0781s	
3686/4200 (epoch 43.881), train_loss = 1.30465474, grad/param norm = 4.9759e-02, time/batch = 0.0778s	
3687/4200 (epoch 43.893), train_loss = 1.31479640, grad/param norm = 4.9058e-02, time/batch = 0.0805s	
3688/4200 (epoch 43.905), train_loss = 1.30137963, grad/param norm = 5.0985e-02, time/batch = 0.0781s	
3689/4200 (epoch 43.917), train_loss = 1.31050968, grad/param norm = 5.6500e-02, time/batch = 0.0781s	
3690/4200 (epoch 43.929), train_loss = 1.30332590, grad/param norm = 5.2558e-02, time/batch = 0.0783s	
3691/4200 (epoch 43.940), train_loss = 1.30885290, grad/param norm = 5.0361e-02, time/batch = 0.0798s	
3692/4200 (epoch 43.952), train_loss = 1.31687200, grad/param norm = 5.6376e-02, time/batch = 0.0778s	
3693/4200 (epoch 43.964), train_loss = 1.31684554, grad/param norm = 5.5936e-02, time/batch = 0.0783s	
3694/4200 (epoch 43.976), train_loss = 1.30727977, grad/param norm = 4.9795e-02, time/batch = 0.0780s	
3695/4200 (epoch 43.988), train_loss = 1.30284551, grad/param norm = 5.4445e-02, time/batch = 0.0781s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
3696/4200 (epoch 44.000), train_loss = 1.34098570, grad/param norm = 5.5176e-02, time/batch = 0.0776s	
3697/4200 (epoch 44.012), train_loss = 1.48014544, grad/param norm = 6.8571e-02, time/batch = 0.0784s	
3698/4200 (epoch 44.024), train_loss = 1.28886786, grad/param norm = 5.6002e-02, time/batch = 0.0785s	
3699/4200 (epoch 44.036), train_loss = 1.29821770, grad/param norm = 5.0614e-02, time/batch = 0.0787s	
3700/4200 (epoch 44.048), train_loss = 1.27491081, grad/param norm = 4.9002e-02, time/batch = 0.0805s	
3701/4200 (epoch 44.060), train_loss = 1.29842896, grad/param norm = 5.1321e-02, time/batch = 0.1976s	
3702/4200 (epoch 44.071), train_loss = 1.29208831, grad/param norm = 5.0836e-02, time/batch = 0.1997s	
3703/4200 (epoch 44.083), train_loss = 1.28621315, grad/param norm = 5.3088e-02, time/batch = 0.2006s	
3704/4200 (epoch 44.095), train_loss = 1.28236400, grad/param norm = 4.8755e-02, time/batch = 0.1896s	
3705/4200 (epoch 44.107), train_loss = 1.29126497, grad/param norm = 5.0944e-02, time/batch = 0.1229s	
3706/4200 (epoch 44.119), train_loss = 1.28519998, grad/param norm = 4.8583e-02, time/batch = 0.1208s	
3707/4200 (epoch 44.131), train_loss = 1.29331671, grad/param norm = 4.9431e-02, time/batch = 0.1213s	
3708/4200 (epoch 44.143), train_loss = 1.29456666, grad/param norm = 4.7112e-02, time/batch = 0.1199s	
3709/4200 (epoch 44.155), train_loss = 1.27964395, grad/param norm = 4.8722e-02, time/batch = 0.1079s	
3710/4200 (epoch 44.167), train_loss = 1.29984795, grad/param norm = 6.0131e-02, time/batch = 0.1072s	
3711/4200 (epoch 44.179), train_loss = 1.30916009, grad/param norm = 5.2339e-02, time/batch = 0.1124s	
3712/4200 (epoch 44.190), train_loss = 1.28515170, grad/param norm = 5.1385e-02, time/batch = 0.1072s	
3713/4200 (epoch 44.202), train_loss = 1.31470709, grad/param norm = 5.3915e-02, time/batch = 0.1082s	
3714/4200 (epoch 44.214), train_loss = 1.29567973, grad/param norm = 4.9607e-02, time/batch = 0.1075s	
3715/4200 (epoch 44.226), train_loss = 1.30422729, grad/param norm = 4.9731e-02, time/batch = 0.1080s	
3716/4200 (epoch 44.238), train_loss = 1.29228571, grad/param norm = 5.4612e-02, time/batch = 0.1072s	
3717/4200 (epoch 44.250), train_loss = 1.28230039, grad/param norm = 5.4957e-02, time/batch = 0.1025s	
3718/4200 (epoch 44.262), train_loss = 1.25127625, grad/param norm = 5.2186e-02, time/batch = 0.0869s	
3719/4200 (epoch 44.274), train_loss = 1.29500079, grad/param norm = 4.9310e-02, time/batch = 0.0863s	
3720/4200 (epoch 44.286), train_loss = 1.29961907, grad/param norm = 4.7669e-02, time/batch = 0.0867s	
3721/4200 (epoch 44.298), train_loss = 1.27487908, grad/param norm = 5.8440e-02, time/batch = 0.0910s	
3722/4200 (epoch 44.310), train_loss = 1.31293681, grad/param norm = 5.1985e-02, time/batch = 0.0863s	
3723/4200 (epoch 44.321), train_loss = 1.26354321, grad/param norm = 5.1896e-02, time/batch = 0.0864s	
3724/4200 (epoch 44.333), train_loss = 1.29287013, grad/param norm = 4.8901e-02, time/batch = 0.0865s	
3725/4200 (epoch 44.345), train_loss = 1.28247629, grad/param norm = 5.3954e-02, time/batch = 0.0866s	
3726/4200 (epoch 44.357), train_loss = 1.29067146, grad/param norm = 5.6364e-02, time/batch = 0.0858s	
3727/4200 (epoch 44.369), train_loss = 1.29924464, grad/param norm = 5.7032e-02, time/batch = 0.0869s	
3728/4200 (epoch 44.381), train_loss = 1.29726464, grad/param norm = 5.3895e-02, time/batch = 0.0856s	
3729/4200 (epoch 44.393), train_loss = 1.31836727, grad/param norm = 5.3503e-02, time/batch = 0.0863s	
3730/4200 (epoch 44.405), train_loss = 1.31525698, grad/param norm = 4.6757e-02, time/batch = 0.0860s	
3731/4200 (epoch 44.417), train_loss = 1.26751231, grad/param norm = 4.8531e-02, time/batch = 0.0909s	
3732/4200 (epoch 44.429), train_loss = 1.28525597, grad/param norm = 4.7270e-02, time/batch = 0.0863s	
3733/4200 (epoch 44.440), train_loss = 1.29619282, grad/param norm = 4.9658e-02, time/batch = 0.0863s	
3734/4200 (epoch 44.452), train_loss = 1.30034130, grad/param norm = 5.0562e-02, time/batch = 0.0864s	
3735/4200 (epoch 44.464), train_loss = 1.30376491, grad/param norm = 4.7730e-02, time/batch = 0.0866s	
3736/4200 (epoch 44.476), train_loss = 1.31728231, grad/param norm = 5.0981e-02, time/batch = 0.0859s	
3737/4200 (epoch 44.488), train_loss = 1.31208857, grad/param norm = 6.0367e-02, time/batch = 0.0863s	
3738/4200 (epoch 44.500), train_loss = 1.28552400, grad/param norm = 4.6341e-02, time/batch = 0.0857s	
3739/4200 (epoch 44.512), train_loss = 1.29174217, grad/param norm = 4.5934e-02, time/batch = 0.0864s	
3740/4200 (epoch 44.524), train_loss = 1.27212845, grad/param norm = 4.7520e-02, time/batch = 0.0865s	
3741/4200 (epoch 44.536), train_loss = 1.28569081, grad/param norm = 5.1849e-02, time/batch = 0.0909s	
3742/4200 (epoch 44.548), train_loss = 1.28744049, grad/param norm = 5.3466e-02, time/batch = 0.0870s	
3743/4200 (epoch 44.560), train_loss = 1.30675147, grad/param norm = 5.3213e-02, time/batch = 0.0866s	
3744/4200 (epoch 44.571), train_loss = 1.26210752, grad/param norm = 4.5791e-02, time/batch = 0.0866s	
3745/4200 (epoch 44.583), train_loss = 1.29310642, grad/param norm = 4.8311e-02, time/batch = 0.0868s	
3746/4200 (epoch 44.595), train_loss = 1.28918924, grad/param norm = 4.8219e-02, time/batch = 0.0861s	
3747/4200 (epoch 44.607), train_loss = 1.27218237, grad/param norm = 5.2525e-02, time/batch = 0.0866s	
3748/4200 (epoch 44.619), train_loss = 1.27888208, grad/param norm = 4.5850e-02, time/batch = 0.0863s	
3749/4200 (epoch 44.631), train_loss = 1.27398049, grad/param norm = 4.4037e-02, time/batch = 0.0866s	
3750/4200 (epoch 44.643), train_loss = 1.27840739, grad/param norm = 4.6832e-02, time/batch = 0.0861s	
3751/4200 (epoch 44.655), train_loss = 1.29289564, grad/param norm = 4.7114e-02, time/batch = 0.0910s	
3752/4200 (epoch 44.667), train_loss = 1.30259370, grad/param norm = 4.7035e-02, time/batch = 0.0866s	
3753/4200 (epoch 44.679), train_loss = 1.29479323, grad/param norm = 4.9571e-02, time/batch = 0.0868s	
3754/4200 (epoch 44.690), train_loss = 1.28346056, grad/param norm = 5.3135e-02, time/batch = 0.0863s	
3755/4200 (epoch 44.702), train_loss = 1.27591535, grad/param norm = 5.2316e-02, time/batch = 0.0869s	
3756/4200 (epoch 44.714), train_loss = 1.29674557, grad/param norm = 4.7773e-02, time/batch = 0.0859s	
3757/4200 (epoch 44.726), train_loss = 1.30521489, grad/param norm = 5.3580e-02, time/batch = 0.0865s	
3758/4200 (epoch 44.738), train_loss = 1.28541274, grad/param norm = 6.8983e-02, time/batch = 0.0861s	
3759/4200 (epoch 44.750), train_loss = 1.30812395, grad/param norm = 5.7079e-02, time/batch = 0.0865s	
3760/4200 (epoch 44.762), train_loss = 1.29745413, grad/param norm = 4.9760e-02, time/batch = 0.0863s	
3761/4200 (epoch 44.774), train_loss = 1.30446904, grad/param norm = 5.1792e-02, time/batch = 0.0907s	
3762/4200 (epoch 44.786), train_loss = 1.28404004, grad/param norm = 5.0847e-02, time/batch = 0.0867s	
3763/4200 (epoch 44.798), train_loss = 1.29278146, grad/param norm = 5.1273e-02, time/batch = 0.0871s	
3764/4200 (epoch 44.810), train_loss = 1.30548121, grad/param norm = 5.6699e-02, time/batch = 0.0866s	
3765/4200 (epoch 44.821), train_loss = 1.28930295, grad/param norm = 5.5544e-02, time/batch = 0.0865s	
3766/4200 (epoch 44.833), train_loss = 1.30582872, grad/param norm = 5.1039e-02, time/batch = 0.0860s	
3767/4200 (epoch 44.845), train_loss = 1.31276865, grad/param norm = 5.2289e-02, time/batch = 0.0868s	
3768/4200 (epoch 44.857), train_loss = 1.31755305, grad/param norm = 5.2168e-02, time/batch = 0.0862s	
3769/4200 (epoch 44.869), train_loss = 1.32453408, grad/param norm = 5.1461e-02, time/batch = 0.0864s	
3770/4200 (epoch 44.881), train_loss = 1.30181656, grad/param norm = 4.9109e-02, time/batch = 0.0860s	
3771/4200 (epoch 44.893), train_loss = 1.31191858, grad/param norm = 4.8973e-02, time/batch = 0.0908s	
3772/4200 (epoch 44.905), train_loss = 1.29872897, grad/param norm = 5.1515e-02, time/batch = 0.0865s	
3773/4200 (epoch 44.917), train_loss = 1.30767758, grad/param norm = 5.6534e-02, time/batch = 0.0872s	
3774/4200 (epoch 44.929), train_loss = 1.30049754, grad/param norm = 5.1718e-02, time/batch = 0.0865s	
3775/4200 (epoch 44.940), train_loss = 1.30601164, grad/param norm = 4.9388e-02, time/batch = 0.0866s	
3776/4200 (epoch 44.952), train_loss = 1.31397894, grad/param norm = 5.5555e-02, time/batch = 0.0857s	
3777/4200 (epoch 44.964), train_loss = 1.31404393, grad/param norm = 5.5415e-02, time/batch = 0.0865s	
3778/4200 (epoch 44.976), train_loss = 1.30451884, grad/param norm = 4.9568e-02, time/batch = 0.0861s	
3779/4200 (epoch 44.988), train_loss = 1.30001840, grad/param norm = 5.3980e-02, time/batch = 0.0865s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
3780/4200 (epoch 45.000), train_loss = 1.33807683, grad/param norm = 5.4424e-02, time/batch = 0.0863s	
3781/4200 (epoch 45.012), train_loss = 1.47786294, grad/param norm = 6.8095e-02, time/batch = 0.0909s	
3782/4200 (epoch 45.024), train_loss = 1.28629454, grad/param norm = 5.6019e-02, time/batch = 0.0866s	
3783/4200 (epoch 45.036), train_loss = 1.29552194, grad/param norm = 5.0305e-02, time/batch = 0.0871s	
3784/4200 (epoch 45.048), train_loss = 1.27234681, grad/param norm = 4.8804e-02, time/batch = 0.0866s	
3785/4200 (epoch 45.060), train_loss = 1.29588617, grad/param norm = 5.1126e-02, time/batch = 0.0867s	
3786/4200 (epoch 45.071), train_loss = 1.28943342, grad/param norm = 5.0802e-02, time/batch = 0.0861s	
3787/4200 (epoch 45.083), train_loss = 1.28363733, grad/param norm = 5.2876e-02, time/batch = 0.0866s	
3788/4200 (epoch 45.095), train_loss = 1.27983489, grad/param norm = 4.8598e-02, time/batch = 0.0863s	
3789/4200 (epoch 45.107), train_loss = 1.28860562, grad/param norm = 5.0745e-02, time/batch = 0.0865s	
3790/4200 (epoch 45.119), train_loss = 1.28251339, grad/param norm = 4.8644e-02, time/batch = 0.0861s	
3791/4200 (epoch 45.131), train_loss = 1.29070851, grad/param norm = 4.9417e-02, time/batch = 0.0909s	
3792/4200 (epoch 45.143), train_loss = 1.29192033, grad/param norm = 4.6988e-02, time/batch = 0.0859s	
3793/4200 (epoch 45.155), train_loss = 1.27720297, grad/param norm = 4.8613e-02, time/batch = 0.0867s	
3794/4200 (epoch 45.167), train_loss = 1.29714888, grad/param norm = 5.9658e-02, time/batch = 0.0863s	
3795/4200 (epoch 45.179), train_loss = 1.30652848, grad/param norm = 5.1491e-02, time/batch = 0.0922s	
3796/4200 (epoch 45.190), train_loss = 1.28247410, grad/param norm = 5.1031e-02, time/batch = 0.0859s	
3797/4200 (epoch 45.202), train_loss = 1.31180226, grad/param norm = 5.3184e-02, time/batch = 0.0865s	
3798/4200 (epoch 45.214), train_loss = 1.29295673, grad/param norm = 4.9057e-02, time/batch = 0.0862s	
3799/4200 (epoch 45.226), train_loss = 1.30155751, grad/param norm = 4.9625e-02, time/batch = 0.0865s	
3800/4200 (epoch 45.238), train_loss = 1.28960972, grad/param norm = 5.4768e-02, time/batch = 0.0860s	
3801/4200 (epoch 45.250), train_loss = 1.27980396, grad/param norm = 5.4741e-02, time/batch = 0.0909s	
3802/4200 (epoch 45.262), train_loss = 1.24871130, grad/param norm = 5.1508e-02, time/batch = 0.0863s	
3803/4200 (epoch 45.274), train_loss = 1.29219866, grad/param norm = 4.8806e-02, time/batch = 0.0871s	
3804/4200 (epoch 45.286), train_loss = 1.29676737, grad/param norm = 4.7645e-02, time/batch = 0.0864s	
3805/4200 (epoch 45.298), train_loss = 1.27215276, grad/param norm = 5.8010e-02, time/batch = 0.0867s	
3806/4200 (epoch 45.310), train_loss = 1.31011622, grad/param norm = 5.1330e-02, time/batch = 0.0861s	
3807/4200 (epoch 45.321), train_loss = 1.26089161, grad/param norm = 5.1987e-02, time/batch = 0.0865s	
3808/4200 (epoch 45.333), train_loss = 1.29007311, grad/param norm = 4.8557e-02, time/batch = 0.0857s	
3809/4200 (epoch 45.345), train_loss = 1.27986841, grad/param norm = 5.3999e-02, time/batch = 0.0864s	
3810/4200 (epoch 45.357), train_loss = 1.28803658, grad/param norm = 5.6372e-02, time/batch = 0.0861s	
3811/4200 (epoch 45.369), train_loss = 1.29662187, grad/param norm = 5.6711e-02, time/batch = 0.0908s	
3812/4200 (epoch 45.381), train_loss = 1.29449793, grad/param norm = 5.2878e-02, time/batch = 0.0865s	
3813/4200 (epoch 45.393), train_loss = 1.31558515, grad/param norm = 5.2501e-02, time/batch = 0.0872s	
3814/4200 (epoch 45.405), train_loss = 1.31280005, grad/param norm = 4.6750e-02, time/batch = 0.0864s	
3815/4200 (epoch 45.417), train_loss = 1.26489799, grad/param norm = 4.8562e-02, time/batch = 0.0865s	
3816/4200 (epoch 45.429), train_loss = 1.28270137, grad/param norm = 4.7033e-02, time/batch = 0.0861s	
3817/4200 (epoch 45.440), train_loss = 1.29349993, grad/param norm = 4.9325e-02, time/batch = 0.0864s	
3818/4200 (epoch 45.452), train_loss = 1.29741647, grad/param norm = 5.0173e-02, time/batch = 0.0857s	
3819/4200 (epoch 45.464), train_loss = 1.30124400, grad/param norm = 4.7533e-02, time/batch = 0.0871s	
3820/4200 (epoch 45.476), train_loss = 1.31477584, grad/param norm = 5.1176e-02, time/batch = 0.0862s	
3821/4200 (epoch 45.488), train_loss = 1.30925728, grad/param norm = 5.9689e-02, time/batch = 0.0910s	
3822/4200 (epoch 45.500), train_loss = 1.28289443, grad/param norm = 4.6155e-02, time/batch = 0.0865s	
3823/4200 (epoch 45.512), train_loss = 1.28907660, grad/param norm = 4.6080e-02, time/batch = 0.0868s	
3824/4200 (epoch 45.524), train_loss = 1.26984168, grad/param norm = 4.7270e-02, time/batch = 0.0864s	
3825/4200 (epoch 45.536), train_loss = 1.28310245, grad/param norm = 5.1491e-02, time/batch = 0.0866s	
3826/4200 (epoch 45.548), train_loss = 1.28514063, grad/param norm = 5.3386e-02, time/batch = 0.0860s	
3827/4200 (epoch 45.560), train_loss = 1.30407580, grad/param norm = 5.2981e-02, time/batch = 0.1585s	
3828/4200 (epoch 45.571), train_loss = 1.25954724, grad/param norm = 4.5169e-02, time/batch = 0.1662s	
3829/4200 (epoch 45.583), train_loss = 1.29052229, grad/param norm = 4.8163e-02, time/batch = 0.1678s	
3830/4200 (epoch 45.595), train_loss = 1.28643422, grad/param norm = 4.7762e-02, time/batch = 0.1671s	
3831/4200 (epoch 45.607), train_loss = 1.26943788, grad/param norm = 5.2205e-02, time/batch = 0.1094s	
3832/4200 (epoch 45.619), train_loss = 1.27642390, grad/param norm = 4.5636e-02, time/batch = 0.1029s	
3833/4200 (epoch 45.631), train_loss = 1.27149799, grad/param norm = 4.3983e-02, time/batch = 0.1031s	
3834/4200 (epoch 45.643), train_loss = 1.27580243, grad/param norm = 4.6729e-02, time/batch = 0.1028s	
3835/4200 (epoch 45.655), train_loss = 1.29041055, grad/param norm = 4.6788e-02, time/batch = 0.1000s	
3836/4200 (epoch 45.667), train_loss = 1.30017467, grad/param norm = 4.6704e-02, time/batch = 0.0927s	
3837/4200 (epoch 45.679), train_loss = 1.29213331, grad/param norm = 4.9187e-02, time/batch = 0.0933s	
3838/4200 (epoch 45.690), train_loss = 1.28081798, grad/param norm = 5.2809e-02, time/batch = 0.0930s	
3839/4200 (epoch 45.702), train_loss = 1.27336189, grad/param norm = 5.1737e-02, time/batch = 0.0936s	
3840/4200 (epoch 45.714), train_loss = 1.29400871, grad/param norm = 4.7483e-02, time/batch = 0.0936s	
3841/4200 (epoch 45.726), train_loss = 1.30277718, grad/param norm = 5.3409e-02, time/batch = 0.0968s	
3842/4200 (epoch 45.738), train_loss = 1.28248794, grad/param norm = 6.7071e-02, time/batch = 0.0927s	
3843/4200 (epoch 45.750), train_loss = 1.30512091, grad/param norm = 5.5799e-02, time/batch = 0.0930s	
3844/4200 (epoch 45.762), train_loss = 1.29468988, grad/param norm = 4.9481e-02, time/batch = 0.0930s	
3845/4200 (epoch 45.774), train_loss = 1.30170824, grad/param norm = 5.1198e-02, time/batch = 0.0841s	
3846/4200 (epoch 45.786), train_loss = 1.28136223, grad/param norm = 5.0437e-02, time/batch = 0.0769s	
3847/4200 (epoch 45.798), train_loss = 1.28988868, grad/param norm = 5.1098e-02, time/batch = 0.0775s	
3848/4200 (epoch 45.810), train_loss = 1.30278266, grad/param norm = 5.6269e-02, time/batch = 0.0768s	
3849/4200 (epoch 45.821), train_loss = 1.28655541, grad/param norm = 5.4827e-02, time/batch = 0.0776s	
3850/4200 (epoch 45.833), train_loss = 1.30323052, grad/param norm = 5.1054e-02, time/batch = 0.0776s	
3851/4200 (epoch 45.845), train_loss = 1.31017988, grad/param norm = 5.2704e-02, time/batch = 0.0808s	
3852/4200 (epoch 45.857), train_loss = 1.31487288, grad/param norm = 5.2000e-02, time/batch = 0.0771s	
3853/4200 (epoch 45.869), train_loss = 1.32176294, grad/param norm = 5.0857e-02, time/batch = 0.0774s	
3854/4200 (epoch 45.881), train_loss = 1.29911076, grad/param norm = 4.8582e-02, time/batch = 0.0772s	
3855/4200 (epoch 45.893), train_loss = 1.30917650, grad/param norm = 4.8921e-02, time/batch = 0.0779s	
3856/4200 (epoch 45.905), train_loss = 1.29617230, grad/param norm = 5.1871e-02, time/batch = 0.0768s	
3857/4200 (epoch 45.917), train_loss = 1.30494030, grad/param norm = 5.6320e-02, time/batch = 0.0776s	
3858/4200 (epoch 45.929), train_loss = 1.29775981, grad/param norm = 5.0868e-02, time/batch = 0.0771s	
3859/4200 (epoch 45.940), train_loss = 1.30330876, grad/param norm = 4.8594e-02, time/batch = 0.0777s	
3860/4200 (epoch 45.952), train_loss = 1.31122361, grad/param norm = 5.4900e-02, time/batch = 0.0772s	
3861/4200 (epoch 45.964), train_loss = 1.31138922, grad/param norm = 5.4992e-02, time/batch = 0.0810s	
3862/4200 (epoch 45.976), train_loss = 1.30189384, grad/param norm = 4.9319e-02, time/batch = 0.0770s	
3863/4200 (epoch 45.988), train_loss = 1.29731897, grad/param norm = 5.3513e-02, time/batch = 0.0773s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
3864/4200 (epoch 46.000), train_loss = 1.33531263, grad/param norm = 5.3751e-02, time/batch = 0.0772s	
3865/4200 (epoch 46.012), train_loss = 1.47569932, grad/param norm = 6.7640e-02, time/batch = 0.0775s	
3866/4200 (epoch 46.024), train_loss = 1.28383963, grad/param norm = 5.6013e-02, time/batch = 0.0772s	
3867/4200 (epoch 46.036), train_loss = 1.29294432, grad/param norm = 5.0011e-02, time/batch = 0.0774s	
3868/4200 (epoch 46.048), train_loss = 1.26991575, grad/param norm = 4.8630e-02, time/batch = 0.0766s	
3869/4200 (epoch 46.060), train_loss = 1.29345447, grad/param norm = 5.0939e-02, time/batch = 0.0773s	
3870/4200 (epoch 46.071), train_loss = 1.28690387, grad/param norm = 5.0777e-02, time/batch = 0.0770s	
3871/4200 (epoch 46.083), train_loss = 1.28118281, grad/param norm = 5.2677e-02, time/batch = 0.0813s	
3872/4200 (epoch 46.095), train_loss = 1.27741908, grad/param norm = 4.8465e-02, time/batch = 0.0773s	
3873/4200 (epoch 46.107), train_loss = 1.28604930, grad/param norm = 5.0588e-02, time/batch = 0.0775s	
3874/4200 (epoch 46.119), train_loss = 1.27995560, grad/param norm = 4.8763e-02, time/batch = 0.0773s	
3875/4200 (epoch 46.131), train_loss = 1.28822709, grad/param norm = 4.9423e-02, time/batch = 0.0774s	
3876/4200 (epoch 46.143), train_loss = 1.28940042, grad/param norm = 4.6888e-02, time/batch = 0.0773s	
3877/4200 (epoch 46.155), train_loss = 1.27487698, grad/param norm = 4.8539e-02, time/batch = 0.0776s	
3878/4200 (epoch 46.167), train_loss = 1.29457981, grad/param norm = 5.9255e-02, time/batch = 0.0770s	
3879/4200 (epoch 46.179), train_loss = 1.30401645, grad/param norm = 5.0734e-02, time/batch = 0.0779s	
3880/4200 (epoch 46.190), train_loss = 1.27991935, grad/param norm = 5.0732e-02, time/batch = 0.0772s	
3881/4200 (epoch 46.202), train_loss = 1.30902832, grad/param norm = 5.2520e-02, time/batch = 0.0812s	
3882/4200 (epoch 46.214), train_loss = 1.29036483, grad/param norm = 4.8586e-02, time/batch = 0.0775s	
3883/4200 (epoch 46.226), train_loss = 1.29902273, grad/param norm = 4.9551e-02, time/batch = 0.0777s	
3884/4200 (epoch 46.238), train_loss = 1.28703923, grad/param norm = 5.4876e-02, time/batch = 0.0773s	
3885/4200 (epoch 46.250), train_loss = 1.27739424, grad/param norm = 5.4400e-02, time/batch = 0.0775s	
3886/4200 (epoch 46.262), train_loss = 1.24625737, grad/param norm = 5.0741e-02, time/batch = 0.0769s	
3887/4200 (epoch 46.274), train_loss = 1.28952874, grad/param norm = 4.8331e-02, time/batch = 0.0780s	
3888/4200 (epoch 46.286), train_loss = 1.29404028, grad/param norm = 4.7631e-02, time/batch = 0.0768s	
3889/4200 (epoch 46.298), train_loss = 1.26952814, grad/param norm = 5.7541e-02, time/batch = 0.0775s	
3890/4200 (epoch 46.310), train_loss = 1.30741682, grad/param norm = 5.0713e-02, time/batch = 0.0772s	
3891/4200 (epoch 46.321), train_loss = 1.25835455, grad/param norm = 5.2104e-02, time/batch = 0.0810s	
3892/4200 (epoch 46.333), train_loss = 1.28739914, grad/param norm = 4.8183e-02, time/batch = 0.0779s	
3893/4200 (epoch 46.345), train_loss = 1.27738805, grad/param norm = 5.4082e-02, time/batch = 0.0774s	
3894/4200 (epoch 46.357), train_loss = 1.28549935, grad/param norm = 5.6371e-02, time/batch = 0.0775s	
3895/4200 (epoch 46.369), train_loss = 1.29410669, grad/param norm = 5.6320e-02, time/batch = 0.0775s	
3896/4200 (epoch 46.381), train_loss = 1.29184651, grad/param norm = 5.1898e-02, time/batch = 0.0767s	
3897/4200 (epoch 46.393), train_loss = 1.31292796, grad/param norm = 5.1762e-02, time/batch = 0.0781s	
3898/4200 (epoch 46.405), train_loss = 1.31050066, grad/param norm = 4.6932e-02, time/batch = 0.0769s	
3899/4200 (epoch 46.417), train_loss = 1.26236753, grad/param norm = 4.8585e-02, time/batch = 0.0774s	
3900/4200 (epoch 46.429), train_loss = 1.28025297, grad/param norm = 4.6825e-02, time/batch = 0.0774s	
3901/4200 (epoch 46.440), train_loss = 1.29092129, grad/param norm = 4.9061e-02, time/batch = 0.0808s	
3902/4200 (epoch 46.452), train_loss = 1.29462901, grad/param norm = 4.9869e-02, time/batch = 0.0775s	
3903/4200 (epoch 46.464), train_loss = 1.29883176, grad/param norm = 4.7358e-02, time/batch = 0.0773s	
3904/4200 (epoch 46.476), train_loss = 1.31236840, grad/param norm = 5.1302e-02, time/batch = 0.0771s	
3905/4200 (epoch 46.488), train_loss = 1.30654680, grad/param norm = 5.8980e-02, time/batch = 0.0775s	
3906/4200 (epoch 46.500), train_loss = 1.28039456, grad/param norm = 4.6028e-02, time/batch = 0.0767s	
3907/4200 (epoch 46.512), train_loss = 1.28652441, grad/param norm = 4.6188e-02, time/batch = 0.0774s	
3908/4200 (epoch 46.524), train_loss = 1.26766846, grad/param norm = 4.7030e-02, time/batch = 0.0770s	
3909/4200 (epoch 46.536), train_loss = 1.28064642, grad/param norm = 5.1266e-02, time/batch = 0.0774s	
3910/4200 (epoch 46.548), train_loss = 1.28295482, grad/param norm = 5.3405e-02, time/batch = 0.0771s	
3911/4200 (epoch 46.560), train_loss = 1.30150139, grad/param norm = 5.2612e-02, time/batch = 0.0806s	
3912/4200 (epoch 46.571), train_loss = 1.25709666, grad/param norm = 4.4524e-02, time/batch = 0.0773s	
3913/4200 (epoch 46.583), train_loss = 1.28804671, grad/param norm = 4.8112e-02, time/batch = 0.0779s	
3914/4200 (epoch 46.595), train_loss = 1.28379727, grad/param norm = 4.7364e-02, time/batch = 0.0774s	
3915/4200 (epoch 46.607), train_loss = 1.26683698, grad/param norm = 5.1950e-02, time/batch = 0.0774s	
3916/4200 (epoch 46.619), train_loss = 1.27407467, grad/param norm = 4.5442e-02, time/batch = 0.0768s	
3917/4200 (epoch 46.631), train_loss = 1.26913411, grad/param norm = 4.3931e-02, time/batch = 0.0775s	
3918/4200 (epoch 46.643), train_loss = 1.27332461, grad/param norm = 4.6675e-02, time/batch = 0.0770s	
3919/4200 (epoch 46.655), train_loss = 1.28804485, grad/param norm = 4.6520e-02, time/batch = 0.0775s	
3920/4200 (epoch 46.667), train_loss = 1.29788287, grad/param norm = 4.6481e-02, time/batch = 0.0769s	
3921/4200 (epoch 46.679), train_loss = 1.28961753, grad/param norm = 4.8937e-02, time/batch = 0.0809s	
3922/4200 (epoch 46.690), train_loss = 1.27830061, grad/param norm = 5.2567e-02, time/batch = 0.0768s	
3923/4200 (epoch 46.702), train_loss = 1.27094777, grad/param norm = 5.1214e-02, time/batch = 0.0779s	
3924/4200 (epoch 46.714), train_loss = 1.29140250, grad/param norm = 4.7219e-02, time/batch = 0.0773s	
3925/4200 (epoch 46.726), train_loss = 1.30041879, grad/param norm = 5.3030e-02, time/batch = 0.0775s	
3926/4200 (epoch 46.738), train_loss = 1.27967731, grad/param norm = 6.4986e-02, time/batch = 0.0765s	
3927/4200 (epoch 46.750), train_loss = 1.30223407, grad/param norm = 5.4593e-02, time/batch = 0.0775s	
3928/4200 (epoch 46.762), train_loss = 1.29203926, grad/param norm = 4.9261e-02, time/batch = 0.0768s	
3929/4200 (epoch 46.774), train_loss = 1.29906611, grad/param norm = 5.0637e-02, time/batch = 0.0781s	
3930/4200 (epoch 46.786), train_loss = 1.27881261, grad/param norm = 5.0082e-02, time/batch = 0.0771s	
3931/4200 (epoch 46.798), train_loss = 1.28712108, grad/param norm = 5.0949e-02, time/batch = 0.0807s	
3932/4200 (epoch 46.810), train_loss = 1.30017714, grad/param norm = 5.5838e-02, time/batch = 0.0773s	
3933/4200 (epoch 46.821), train_loss = 1.28393032, grad/param norm = 5.4135e-02, time/batch = 0.0774s	
3934/4200 (epoch 46.833), train_loss = 1.30076797, grad/param norm = 5.1129e-02, time/batch = 0.0780s	
3935/4200 (epoch 46.845), train_loss = 1.30769534, grad/param norm = 5.3098e-02, time/batch = 0.0775s	
3936/4200 (epoch 46.857), train_loss = 1.31228791, grad/param norm = 5.1720e-02, time/batch = 0.0769s	
3937/4200 (epoch 46.869), train_loss = 1.31910904, grad/param norm = 5.0251e-02, time/batch = 0.0776s	
3938/4200 (epoch 46.881), train_loss = 1.29653100, grad/param norm = 4.8165e-02, time/batch = 0.0768s	
3939/4200 (epoch 46.893), train_loss = 1.30655857, grad/param norm = 4.8889e-02, time/batch = 0.0780s	
3940/4200 (epoch 46.905), train_loss = 1.29370630, grad/param norm = 5.2072e-02, time/batch = 0.0774s	
3941/4200 (epoch 46.917), train_loss = 1.30230288, grad/param norm = 5.5943e-02, time/batch = 0.0808s	
3942/4200 (epoch 46.929), train_loss = 1.29511830, grad/param norm = 5.0066e-02, time/batch = 0.0776s	
3943/4200 (epoch 46.940), train_loss = 1.30073477, grad/param norm = 4.7938e-02, time/batch = 0.0773s	
3944/4200 (epoch 46.952), train_loss = 1.30859183, grad/param norm = 5.4339e-02, time/batch = 0.0781s	
3945/4200 (epoch 46.964), train_loss = 1.30886326, grad/param norm = 5.4591e-02, time/batch = 0.0775s	
3946/4200 (epoch 46.976), train_loss = 1.29938502, grad/param norm = 4.9055e-02, time/batch = 0.0769s	
3947/4200 (epoch 46.988), train_loss = 1.29474424, grad/param norm = 5.3073e-02, time/batch = 0.0778s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
3948/4200 (epoch 47.000), train_loss = 1.33268954, grad/param norm = 5.3160e-02, time/batch = 0.0767s	
3949/4200 (epoch 47.012), train_loss = 1.47364030, grad/param norm = 6.7195e-02, time/batch = 0.0776s	
3950/4200 (epoch 47.024), train_loss = 1.28148557, grad/param norm = 5.5973e-02, time/batch = 0.0777s	
3951/4200 (epoch 47.036), train_loss = 1.29047572, grad/param norm = 4.9732e-02, time/batch = 0.0808s	
3952/4200 (epoch 47.048), train_loss = 1.26761192, grad/param norm = 4.8478e-02, time/batch = 0.0772s	
3953/4200 (epoch 47.060), train_loss = 1.29112642, grad/param norm = 5.0768e-02, time/batch = 0.0774s	
3954/4200 (epoch 47.071), train_loss = 1.28449509, grad/param norm = 5.0741e-02, time/batch = 0.0773s	
3955/4200 (epoch 47.083), train_loss = 1.27883354, grad/param norm = 5.2481e-02, time/batch = 0.0781s	
3956/4200 (epoch 47.095), train_loss = 1.27511138, grad/param norm = 4.8359e-02, time/batch = 0.0768s	
3957/4200 (epoch 47.107), train_loss = 1.28359686, grad/param norm = 5.0473e-02, time/batch = 0.0775s	
3958/4200 (epoch 47.119), train_loss = 1.27751966, grad/param norm = 4.8919e-02, time/batch = 0.0767s	
3959/4200 (epoch 47.131), train_loss = 1.28586333, grad/param norm = 4.9426e-02, time/batch = 0.0775s	
3960/4200 (epoch 47.143), train_loss = 1.28699638, grad/param norm = 4.6790e-02, time/batch = 0.0775s	
3961/4200 (epoch 47.155), train_loss = 1.27265866, grad/param norm = 4.8512e-02, time/batch = 0.0810s	
3962/4200 (epoch 47.167), train_loss = 1.29213248, grad/param norm = 5.8896e-02, time/batch = 0.0772s	
3963/4200 (epoch 47.179), train_loss = 1.30161659, grad/param norm = 5.0041e-02, time/batch = 0.0775s	
3964/4200 (epoch 47.190), train_loss = 1.27748325, grad/param norm = 5.0482e-02, time/batch = 0.0774s	
3965/4200 (epoch 47.202), train_loss = 1.30638269, grad/param norm = 5.1917e-02, time/batch = 0.0777s	
3966/4200 (epoch 47.214), train_loss = 1.28789166, grad/param norm = 4.8187e-02, time/batch = 0.0768s	
3967/4200 (epoch 47.226), train_loss = 1.29661789, grad/param norm = 4.9490e-02, time/batch = 0.0776s	
3968/4200 (epoch 47.238), train_loss = 1.28455892, grad/param norm = 5.4913e-02, time/batch = 0.0766s	
3969/4200 (epoch 47.250), train_loss = 1.27506840, grad/param norm = 5.3971e-02, time/batch = 0.0777s	
3970/4200 (epoch 47.262), train_loss = 1.24391404, grad/param norm = 4.9945e-02, time/batch = 0.0772s	
3971/4200 (epoch 47.274), train_loss = 1.28698148, grad/param norm = 4.7907e-02, time/batch = 0.0808s	
3972/4200 (epoch 47.286), train_loss = 1.29143776, grad/param norm = 4.7615e-02, time/batch = 0.0773s	
3973/4200 (epoch 47.298), train_loss = 1.26700320, grad/param norm = 5.7037e-02, time/batch = 0.0776s	
3974/4200 (epoch 47.310), train_loss = 1.30484108, grad/param norm = 5.0135e-02, time/batch = 0.0773s	
3975/4200 (epoch 47.321), train_loss = 1.25592771, grad/param norm = 5.2257e-02, time/batch = 0.0775s	
3976/4200 (epoch 47.333), train_loss = 1.28484721, grad/param norm = 4.7806e-02, time/batch = 0.0772s	
3977/4200 (epoch 47.345), train_loss = 1.27502217, grad/param norm = 5.4192e-02, time/batch = 0.0776s	
3978/4200 (epoch 47.357), train_loss = 1.28305910, grad/param norm = 5.6333e-02, time/batch = 0.0766s	
3979/4200 (epoch 47.369), train_loss = 1.29168405, grad/param norm = 5.5844e-02, time/batch = 0.0774s	
3980/4200 (epoch 47.381), train_loss = 1.28932174, grad/param norm = 5.0998e-02, time/batch = 0.0773s	
3981/4200 (epoch 47.393), train_loss = 1.31038340, grad/param norm = 5.1259e-02, time/batch = 0.0814s	
3982/4200 (epoch 47.405), train_loss = 1.30834345, grad/param norm = 4.7199e-02, time/batch = 0.0772s	
3983/4200 (epoch 47.417), train_loss = 1.25995225, grad/param norm = 4.8525e-02, time/batch = 0.0773s	
3984/4200 (epoch 47.429), train_loss = 1.27789862, grad/param norm = 4.6593e-02, time/batch = 0.0775s	
3985/4200 (epoch 47.440), train_loss = 1.28844166, grad/param norm = 4.8826e-02, time/batch = 0.0774s	
3986/4200 (epoch 47.452), train_loss = 1.29195420, grad/param norm = 4.9592e-02, time/batch = 0.0772s	
3987/4200 (epoch 47.464), train_loss = 1.29652227, grad/param norm = 4.7198e-02, time/batch = 0.0775s	
3988/4200 (epoch 47.476), train_loss = 1.31006155, grad/param norm = 5.1370e-02, time/batch = 0.0767s	
3989/4200 (epoch 47.488), train_loss = 1.30395274, grad/param norm = 5.8301e-02, time/batch = 0.0777s	
3990/4200 (epoch 47.500), train_loss = 1.27801094, grad/param norm = 4.5963e-02, time/batch = 0.0774s	
3991/4200 (epoch 47.512), train_loss = 1.28407951, grad/param norm = 4.6246e-02, time/batch = 0.0812s	
3992/4200 (epoch 47.524), train_loss = 1.26559202, grad/param norm = 4.6790e-02, time/batch = 0.0771s	
3993/4200 (epoch 47.536), train_loss = 1.27831272, grad/param norm = 5.1146e-02, time/batch = 0.0772s	
3994/4200 (epoch 47.548), train_loss = 1.28083161, grad/param norm = 5.3408e-02, time/batch = 0.0774s	
3995/4200 (epoch 47.560), train_loss = 1.29903371, grad/param norm = 5.2179e-02, time/batch = 0.0772s	
3996/4200 (epoch 47.571), train_loss = 1.25475532, grad/param norm = 4.3932e-02, time/batch = 0.0772s	
3997/4200 (epoch 47.583), train_loss = 1.28567279, grad/param norm = 4.8151e-02, time/batch = 0.0780s	
3998/4200 (epoch 47.595), train_loss = 1.28127516, grad/param norm = 4.7033e-02, time/batch = 0.0767s	
3999/4200 (epoch 47.607), train_loss = 1.26436490, grad/param norm = 5.1757e-02, time/batch = 0.0807s	
evaluating loss over split index 2	
1/5...	
2/5...	
3/5...	
4/5...	
5/5...	
saving checkpoint to cv/lm_lstm_epoch47.62_1.4112.t7	
4000/4200 (epoch 47.619), train_loss = 1.27182921, grad/param norm = 4.5269e-02, time/batch = 0.0774s	
4001/4200 (epoch 47.631), train_loss = 1.52986889, grad/param norm = 6.1464e-02, time/batch = 0.1727s	
4002/4200 (epoch 47.643), train_loss = 1.27347452, grad/param norm = 5.4140e-02, time/batch = 0.1689s	
4003/4200 (epoch 47.655), train_loss = 1.28660152, grad/param norm = 4.9244e-02, time/batch = 0.1687s	
4004/4200 (epoch 47.667), train_loss = 1.29615657, grad/param norm = 4.7913e-02, time/batch = 0.1689s	
4005/4200 (epoch 47.679), train_loss = 1.28748562, grad/param norm = 4.8747e-02, time/batch = 0.1408s	
4006/4200 (epoch 47.690), train_loss = 1.27579131, grad/param norm = 5.2479e-02, time/batch = 0.1050s	
4007/4200 (epoch 47.702), train_loss = 1.26892855, grad/param norm = 5.0144e-02, time/batch = 0.1051s	
4008/4200 (epoch 47.714), train_loss = 1.28905840, grad/param norm = 4.6625e-02, time/batch = 0.1047s	
4009/4200 (epoch 47.726), train_loss = 1.29798009, grad/param norm = 5.0256e-02, time/batch = 0.1053s	
4010/4200 (epoch 47.738), train_loss = 1.27637329, grad/param norm = 5.5009e-02, time/batch = 0.0977s	
4011/4200 (epoch 47.750), train_loss = 1.29828070, grad/param norm = 4.7961e-02, time/batch = 0.0959s	
4012/4200 (epoch 47.762), train_loss = 1.28920936, grad/param norm = 4.9219e-02, time/batch = 0.0935s	
4013/4200 (epoch 47.774), train_loss = 1.29646449, grad/param norm = 4.9930e-02, time/batch = 0.0937s	
4014/4200 (epoch 47.786), train_loss = 1.27641184, grad/param norm = 4.9371e-02, time/batch = 0.0941s	
4015/4200 (epoch 47.798), train_loss = 1.28453899, grad/param norm = 5.0780e-02, time/batch = 0.0939s	
4016/4200 (epoch 47.810), train_loss = 1.29739092, grad/param norm = 5.5245e-02, time/batch = 0.0933s	
4017/4200 (epoch 47.821), train_loss = 1.28133890, grad/param norm = 5.3213e-02, time/batch = 0.0939s	
4018/4200 (epoch 47.833), train_loss = 1.29837898, grad/param norm = 5.1114e-02, time/batch = 0.0932s	
4019/4200 (epoch 47.845), train_loss = 1.30539251, grad/param norm = 5.3973e-02, time/batch = 0.0943s	
4020/4200 (epoch 47.857), train_loss = 1.30977778, grad/param norm = 5.1286e-02, time/batch = 0.0869s	
4021/4200 (epoch 47.869), train_loss = 1.31650466, grad/param norm = 4.8964e-02, time/batch = 0.0795s	
4022/4200 (epoch 47.881), train_loss = 1.29411205, grad/param norm = 4.7673e-02, time/batch = 0.0778s	
4023/4200 (epoch 47.893), train_loss = 1.30408216, grad/param norm = 4.8546e-02, time/batch = 0.0779s	
4024/4200 (epoch 47.905), train_loss = 1.29118180, grad/param norm = 5.0536e-02, time/batch = 0.0780s	
4025/4200 (epoch 47.917), train_loss = 1.29949569, grad/param norm = 5.3796e-02, time/batch = 0.0782s	
4026/4200 (epoch 47.929), train_loss = 1.29230745, grad/param norm = 4.8826e-02, time/batch = 0.0775s	
4027/4200 (epoch 47.940), train_loss = 1.29829161, grad/param norm = 4.7675e-02, time/batch = 0.0779s	
4028/4200 (epoch 47.952), train_loss = 1.30624541, grad/param norm = 5.4341e-02, time/batch = 0.0773s	
4029/4200 (epoch 47.964), train_loss = 1.30649179, grad/param norm = 5.4536e-02, time/batch = 0.0781s	
4030/4200 (epoch 47.976), train_loss = 1.29687479, grad/param norm = 4.8404e-02, time/batch = 0.0782s	
4031/4200 (epoch 47.988), train_loss = 1.29225475, grad/param norm = 5.2725e-02, time/batch = 0.0798s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
4032/4200 (epoch 48.000), train_loss = 1.33022994, grad/param norm = 5.3164e-02, time/batch = 0.0779s	
4033/4200 (epoch 48.012), train_loss = 1.47075614, grad/param norm = 6.6586e-02, time/batch = 0.0780s	
4034/4200 (epoch 48.024), train_loss = 1.27912521, grad/param norm = 5.5179e-02, time/batch = 0.0778s	
4035/4200 (epoch 48.036), train_loss = 1.28811979, grad/param norm = 4.9328e-02, time/batch = 0.0783s	
4036/4200 (epoch 48.048), train_loss = 1.26547684, grad/param norm = 4.8441e-02, time/batch = 0.0775s	
4037/4200 (epoch 48.060), train_loss = 1.28892632, grad/param norm = 5.0732e-02, time/batch = 0.0781s	
4038/4200 (epoch 48.071), train_loss = 1.28218858, grad/param norm = 5.0778e-02, time/batch = 0.0777s	
4039/4200 (epoch 48.083), train_loss = 1.27661255, grad/param norm = 5.2223e-02, time/batch = 0.0782s	
4040/4200 (epoch 48.095), train_loss = 1.27288199, grad/param norm = 4.8154e-02, time/batch = 0.0777s	
4041/4200 (epoch 48.107), train_loss = 1.28130243, grad/param norm = 5.0331e-02, time/batch = 0.0797s	
4042/4200 (epoch 48.119), train_loss = 1.27520940, grad/param norm = 4.9130e-02, time/batch = 0.0776s	
4043/4200 (epoch 48.131), train_loss = 1.28365883, grad/param norm = 4.9584e-02, time/batch = 0.0779s	
4044/4200 (epoch 48.143), train_loss = 1.28472691, grad/param norm = 4.6791e-02, time/batch = 0.0778s	
4045/4200 (epoch 48.155), train_loss = 1.27060596, grad/param norm = 4.8232e-02, time/batch = 0.0780s	
4046/4200 (epoch 48.167), train_loss = 1.28981490, grad/param norm = 5.8366e-02, time/batch = 0.0780s	
4047/4200 (epoch 48.179), train_loss = 1.29934088, grad/param norm = 4.9378e-02, time/batch = 0.0780s	
4048/4200 (epoch 48.190), train_loss = 1.27517715, grad/param norm = 5.0268e-02, time/batch = 0.0774s	
4049/4200 (epoch 48.202), train_loss = 1.30389455, grad/param norm = 5.1394e-02, time/batch = 0.0779s	
4050/4200 (epoch 48.214), train_loss = 1.28554190, grad/param norm = 4.7860e-02, time/batch = 0.0779s	
4051/4200 (epoch 48.226), train_loss = 1.29433118, grad/param norm = 4.9405e-02, time/batch = 0.0801s	
4052/4200 (epoch 48.238), train_loss = 1.28217330, grad/param norm = 5.4936e-02, time/batch = 0.0776s	
4053/4200 (epoch 48.250), train_loss = 1.27281170, grad/param norm = 5.3602e-02, time/batch = 0.0777s	
4054/4200 (epoch 48.262), train_loss = 1.24166242, grad/param norm = 4.9229e-02, time/batch = 0.0779s	
4055/4200 (epoch 48.274), train_loss = 1.28460162, grad/param norm = 4.7607e-02, time/batch = 0.0781s	
4056/4200 (epoch 48.286), train_loss = 1.28893844, grad/param norm = 4.7460e-02, time/batch = 0.0779s	
4057/4200 (epoch 48.298), train_loss = 1.26461504, grad/param norm = 5.6393e-02, time/batch = 0.0780s	
4058/4200 (epoch 48.310), train_loss = 1.30236884, grad/param norm = 4.9637e-02, time/batch = 0.0775s	
4059/4200 (epoch 48.321), train_loss = 1.25363316, grad/param norm = 5.2326e-02, time/batch = 0.0783s	
4060/4200 (epoch 48.333), train_loss = 1.28240980, grad/param norm = 4.7391e-02, time/batch = 0.0777s	
4061/4200 (epoch 48.345), train_loss = 1.27273387, grad/param norm = 5.4267e-02, time/batch = 0.0802s	
4062/4200 (epoch 48.357), train_loss = 1.28074038, grad/param norm = 5.6147e-02, time/batch = 0.0776s	
4063/4200 (epoch 48.369), train_loss = 1.28936625, grad/param norm = 5.5115e-02, time/batch = 0.0779s	
4064/4200 (epoch 48.381), train_loss = 1.28693415, grad/param norm = 5.0113e-02, time/batch = 0.0778s	
4065/4200 (epoch 48.393), train_loss = 1.30797797, grad/param norm = 5.0860e-02, time/batch = 0.0780s	
4066/4200 (epoch 48.405), train_loss = 1.30630040, grad/param norm = 4.7396e-02, time/batch = 0.0775s	
4067/4200 (epoch 48.417), train_loss = 1.25761336, grad/param norm = 4.8296e-02, time/batch = 0.0784s	
4068/4200 (epoch 48.429), train_loss = 1.27564497, grad/param norm = 4.6361e-02, time/batch = 0.0775s	
4069/4200 (epoch 48.440), train_loss = 1.28608066, grad/param norm = 4.8636e-02, time/batch = 0.0781s	
4070/4200 (epoch 48.452), train_loss = 1.28944420, grad/param norm = 4.9295e-02, time/batch = 0.0776s	
4071/4200 (epoch 48.464), train_loss = 1.29432251, grad/param norm = 4.7022e-02, time/batch = 0.0798s	
4072/4200 (epoch 48.476), train_loss = 1.30789065, grad/param norm = 5.1379e-02, time/batch = 0.0782s	
4073/4200 (epoch 48.488), train_loss = 1.30147719, grad/param norm = 5.7605e-02, time/batch = 0.0779s	
4074/4200 (epoch 48.500), train_loss = 1.27574376, grad/param norm = 4.5934e-02, time/batch = 0.0779s	
4075/4200 (epoch 48.512), train_loss = 1.28177463, grad/param norm = 4.6321e-02, time/batch = 0.0780s	
4076/4200 (epoch 48.524), train_loss = 1.26361922, grad/param norm = 4.6614e-02, time/batch = 0.0776s	
4077/4200 (epoch 48.536), train_loss = 1.27611263, grad/param norm = 5.1019e-02, time/batch = 0.0782s	
4078/4200 (epoch 48.548), train_loss = 1.27873347, grad/param norm = 5.3298e-02, time/batch = 0.0776s	
4079/4200 (epoch 48.560), train_loss = 1.29671294, grad/param norm = 5.1849e-02, time/batch = 0.0782s	
4080/4200 (epoch 48.571), train_loss = 1.25254474, grad/param norm = 4.3521e-02, time/batch = 0.0788s	
4081/4200 (epoch 48.583), train_loss = 1.28341124, grad/param norm = 4.8167e-02, time/batch = 0.0798s	
4082/4200 (epoch 48.595), train_loss = 1.27886875, grad/param norm = 4.6760e-02, time/batch = 0.0777s	
4083/4200 (epoch 48.607), train_loss = 1.26206011, grad/param norm = 5.1654e-02, time/batch = 0.0778s	
4084/4200 (epoch 48.619), train_loss = 1.26968834, grad/param norm = 4.5144e-02, time/batch = 0.0778s	
4085/4200 (epoch 48.631), train_loss = 1.26554059, grad/param norm = 4.3821e-02, time/batch = 0.0785s	
4086/4200 (epoch 48.643), train_loss = 1.26887070, grad/param norm = 4.6757e-02, time/batch = 0.0775s	
4087/4200 (epoch 48.655), train_loss = 1.28384984, grad/param norm = 4.6384e-02, time/batch = 0.0780s	
4088/4200 (epoch 48.667), train_loss = 1.29380211, grad/param norm = 4.6404e-02, time/batch = 0.0776s	
4089/4200 (epoch 48.679), train_loss = 1.28513632, grad/param norm = 4.8690e-02, time/batch = 0.0781s	
4090/4200 (epoch 48.690), train_loss = 1.27371968, grad/param norm = 5.2160e-02, time/batch = 0.0777s	
4091/4200 (epoch 48.702), train_loss = 1.26658750, grad/param norm = 5.0317e-02, time/batch = 0.0796s	
4092/4200 (epoch 48.714), train_loss = 1.28664105, grad/param norm = 4.6939e-02, time/batch = 0.0779s	
4093/4200 (epoch 48.726), train_loss = 1.29613475, grad/param norm = 5.2509e-02, time/batch = 0.0783s	
4094/4200 (epoch 48.738), train_loss = 1.27449925, grad/param norm = 6.1188e-02, time/batch = 0.0780s	
4095/4200 (epoch 48.750), train_loss = 1.29694911, grad/param norm = 5.2296e-02, time/batch = 0.0804s	
4096/4200 (epoch 48.762), train_loss = 1.28712504, grad/param norm = 4.8832e-02, time/batch = 0.0802s	
4097/4200 (epoch 48.774), train_loss = 1.29415575, grad/param norm = 4.9457e-02, time/batch = 0.0783s	
4098/4200 (epoch 48.786), train_loss = 1.27412606, grad/param norm = 4.9402e-02, time/batch = 0.0776s	
4099/4200 (epoch 48.798), train_loss = 1.28197164, grad/param norm = 5.0432e-02, time/batch = 0.0785s	
4100/4200 (epoch 48.810), train_loss = 1.29522691, grad/param norm = 5.4675e-02, time/batch = 0.0777s	
4101/4200 (epoch 48.821), train_loss = 1.27903729, grad/param norm = 5.2865e-02, time/batch = 0.0800s	
4102/4200 (epoch 48.833), train_loss = 1.29628163, grad/param norm = 5.1610e-02, time/batch = 0.0778s	
4103/4200 (epoch 48.845), train_loss = 1.30305211, grad/param norm = 5.3915e-02, time/batch = 0.0781s	
4104/4200 (epoch 48.857), train_loss = 1.30741845, grad/param norm = 5.1080e-02, time/batch = 0.0784s	
4105/4200 (epoch 48.869), train_loss = 1.31414687, grad/param norm = 4.9295e-02, time/batch = 0.0781s	
4106/4200 (epoch 48.881), train_loss = 1.29178289, grad/param norm = 4.7745e-02, time/batch = 0.0777s	
4107/4200 (epoch 48.893), train_loss = 1.30171638, grad/param norm = 4.8728e-02, time/batch = 0.0782s	
4108/4200 (epoch 48.905), train_loss = 1.28905181, grad/param norm = 5.1890e-02, time/batch = 0.0774s	
4109/4200 (epoch 48.917), train_loss = 1.29734577, grad/param norm = 5.4819e-02, time/batch = 0.0785s	
4110/4200 (epoch 48.929), train_loss = 1.29013343, grad/param norm = 4.8669e-02, time/batch = 0.0775s	
4111/4200 (epoch 48.940), train_loss = 1.29598515, grad/param norm = 4.6873e-02, time/batch = 0.0799s	
4112/4200 (epoch 48.952), train_loss = 1.30367483, grad/param norm = 5.3248e-02, time/batch = 0.0775s	
4113/4200 (epoch 48.964), train_loss = 1.30417859, grad/param norm = 5.3657e-02, time/batch = 0.0781s	
4114/4200 (epoch 48.976), train_loss = 1.29465863, grad/param norm = 4.8681e-02, time/batch = 0.0785s	
4115/4200 (epoch 48.988), train_loss = 1.28995367, grad/param norm = 5.2505e-02, time/batch = 0.0781s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
4116/4200 (epoch 49.000), train_loss = 1.32786504, grad/param norm = 5.2177e-02, time/batch = 0.0775s	
4117/4200 (epoch 49.012), train_loss = 1.46935562, grad/param norm = 6.6071e-02, time/batch = 0.0780s	
4118/4200 (epoch 49.024), train_loss = 1.27702346, grad/param norm = 5.5631e-02, time/batch = 0.0774s	
4119/4200 (epoch 49.036), train_loss = 1.28584021, grad/param norm = 4.9188e-02, time/batch = 0.0780s	
4120/4200 (epoch 49.048), train_loss = 1.26337167, grad/param norm = 4.8250e-02, time/batch = 0.0783s	
4121/4200 (epoch 49.060), train_loss = 1.28681191, grad/param norm = 5.0454e-02, time/batch = 0.0797s	
4122/4200 (epoch 49.071), train_loss = 1.27997959, grad/param norm = 5.0600e-02, time/batch = 0.0779s	
4123/4200 (epoch 49.083), train_loss = 1.27444649, grad/param norm = 5.2062e-02, time/batch = 0.0778s	
4124/4200 (epoch 49.095), train_loss = 1.27080882, grad/param norm = 4.8202e-02, time/batch = 0.0781s	
4125/4200 (epoch 49.107), train_loss = 1.27904601, grad/param norm = 5.0320e-02, time/batch = 0.0790s	
4126/4200 (epoch 49.119), train_loss = 1.27298625, grad/param norm = 4.9210e-02, time/batch = 0.0776s	
4127/4200 (epoch 49.131), train_loss = 1.28147170, grad/param norm = 4.9308e-02, time/batch = 0.0779s	
4128/4200 (epoch 49.143), train_loss = 1.28252057, grad/param norm = 4.6608e-02, time/batch = 0.0785s	
4129/4200 (epoch 49.155), train_loss = 1.26855152, grad/param norm = 4.8543e-02, time/batch = 0.0786s	
4130/4200 (epoch 49.167), train_loss = 1.28759376, grad/param norm = 5.8227e-02, time/batch = 0.0781s	
4131/4200 (epoch 49.179), train_loss = 1.29714897, grad/param norm = 4.8726e-02, time/batch = 0.0798s	
4132/4200 (epoch 49.190), train_loss = 1.27294359, grad/param norm = 5.0167e-02, time/batch = 0.0777s	
4133/4200 (epoch 49.202), train_loss = 1.30146508, grad/param norm = 5.0901e-02, time/batch = 0.0781s	
4134/4200 (epoch 49.214), train_loss = 1.28329026, grad/param norm = 4.7576e-02, time/batch = 0.0796s	
4135/4200 (epoch 49.226), train_loss = 1.29214545, grad/param norm = 4.9354e-02, time/batch = 0.0791s	
4136/4200 (epoch 49.238), train_loss = 1.27988420, grad/param norm = 5.4884e-02, time/batch = 0.0777s	
4137/4200 (epoch 49.250), train_loss = 1.27066948, grad/param norm = 5.2963e-02, time/batch = 0.0782s	
4138/4200 (epoch 49.262), train_loss = 1.23951777, grad/param norm = 4.8265e-02, time/batch = 0.0779s	
4139/4200 (epoch 49.274), train_loss = 1.28224686, grad/param norm = 4.7152e-02, time/batch = 0.0781s	
4140/4200 (epoch 49.286), train_loss = 1.28655317, grad/param norm = 4.7572e-02, time/batch = 0.0778s	
4141/4200 (epoch 49.298), train_loss = 1.26227270, grad/param norm = 5.5964e-02, time/batch = 0.0802s	
4142/4200 (epoch 49.310), train_loss = 1.30002319, grad/param norm = 4.9165e-02, time/batch = 0.0777s	
4143/4200 (epoch 49.321), train_loss = 1.25140747, grad/param norm = 5.2579e-02, time/batch = 0.0780s	
4144/4200 (epoch 49.333), train_loss = 1.28011276, grad/param norm = 4.7026e-02, time/batch = 0.0790s	
4145/4200 (epoch 49.345), train_loss = 1.27057335, grad/param norm = 5.4458e-02, time/batch = 0.0797s	
4146/4200 (epoch 49.357), train_loss = 1.27847728, grad/param norm = 5.6027e-02, time/batch = 0.0784s	
4147/4200 (epoch 49.369), train_loss = 1.28707582, grad/param norm = 5.4559e-02, time/batch = 0.0781s	
4148/4200 (epoch 49.381), train_loss = 1.28465992, grad/param norm = 4.9515e-02, time/batch = 0.0774s	
4149/4200 (epoch 49.393), train_loss = 1.30561812, grad/param norm = 5.0726e-02, time/batch = 0.0780s	
4150/4200 (epoch 49.405), train_loss = 1.30437388, grad/param norm = 4.7565e-02, time/batch = 0.0778s	
4151/4200 (epoch 49.417), train_loss = 1.25539721, grad/param norm = 4.8022e-02, time/batch = 0.0801s	
4152/4200 (epoch 49.429), train_loss = 1.27343783, grad/param norm = 4.6169e-02, time/batch = 0.0775s	
4153/4200 (epoch 49.440), train_loss = 1.28379322, grad/param norm = 4.8449e-02, time/batch = 0.0780s	
4154/4200 (epoch 49.452), train_loss = 1.28693513, grad/param norm = 4.9045e-02, time/batch = 0.0779s	
4155/4200 (epoch 49.464), train_loss = 1.29221218, grad/param norm = 4.6899e-02, time/batch = 0.0779s	
4156/4200 (epoch 49.476), train_loss = 1.30573398, grad/param norm = 5.1364e-02, time/batch = 0.0775s	
4157/4200 (epoch 49.488), train_loss = 1.29908605, grad/param norm = 5.7039e-02, time/batch = 0.0787s	
4158/4200 (epoch 49.500), train_loss = 1.27357358, grad/param norm = 4.5943e-02, time/batch = 0.0775s	
4159/4200 (epoch 49.512), train_loss = 1.27951586, grad/param norm = 4.6263e-02, time/batch = 0.0782s	
4160/4200 (epoch 49.524), train_loss = 1.26171974, grad/param norm = 4.6413e-02, time/batch = 0.0777s	
4161/4200 (epoch 49.536), train_loss = 1.27400712, grad/param norm = 5.1074e-02, time/batch = 0.0798s	
4162/4200 (epoch 49.548), train_loss = 1.27670762, grad/param norm = 5.3138e-02, time/batch = 0.0781s	
4163/4200 (epoch 49.560), train_loss = 1.29442461, grad/param norm = 5.1292e-02, time/batch = 0.0778s	
4164/4200 (epoch 49.571), train_loss = 1.25039063, grad/param norm = 4.3057e-02, time/batch = 0.0781s	
4165/4200 (epoch 49.583), train_loss = 1.28122308, grad/param norm = 4.8357e-02, time/batch = 0.0782s	
4166/4200 (epoch 49.595), train_loss = 1.27656919, grad/param norm = 4.6512e-02, time/batch = 0.0775s	
4167/4200 (epoch 49.607), train_loss = 1.25978503, grad/param norm = 5.1511e-02, time/batch = 0.0785s	
4168/4200 (epoch 49.619), train_loss = 1.26761976, grad/param norm = 4.4978e-02, time/batch = 0.0775s	
4169/4200 (epoch 49.631), train_loss = 1.26332193, grad/param norm = 4.3799e-02, time/batch = 0.0780s	
4170/4200 (epoch 49.643), train_loss = 1.26665887, grad/param norm = 4.6744e-02, time/batch = 0.0777s	
4171/4200 (epoch 49.655), train_loss = 1.28172921, grad/param norm = 4.6103e-02, time/batch = 0.0798s	
4172/4200 (epoch 49.667), train_loss = 1.29177898, grad/param norm = 4.6222e-02, time/batch = 0.0779s	
4173/4200 (epoch 49.679), train_loss = 1.28288106, grad/param norm = 4.8537e-02, time/batch = 0.0778s	
4174/4200 (epoch 49.690), train_loss = 1.27147720, grad/param norm = 5.1972e-02, time/batch = 0.0778s	
4175/4200 (epoch 49.702), train_loss = 1.26447419, grad/param norm = 4.9880e-02, time/batch = 0.0780s	
4176/4200 (epoch 49.714), train_loss = 1.28434209, grad/param norm = 4.6673e-02, time/batch = 0.0773s	
4177/4200 (epoch 49.726), train_loss = 1.29397572, grad/param norm = 5.1723e-02, time/batch = 0.0782s	
4178/4200 (epoch 49.738), train_loss = 1.27200635, grad/param norm = 5.9061e-02, time/batch = 0.0781s	
4179/4200 (epoch 49.750), train_loss = 1.29446373, grad/param norm = 5.1399e-02, time/batch = 0.0779s	
4180/4200 (epoch 49.762), train_loss = 1.28479885, grad/param norm = 4.8657e-02, time/batch = 0.0778s	
4181/4200 (epoch 49.774), train_loss = 1.29182968, grad/param norm = 4.9074e-02, time/batch = 0.0798s	
4182/4200 (epoch 49.786), train_loss = 1.27189888, grad/param norm = 4.9258e-02, time/batch = 0.0774s	
4183/4200 (epoch 49.798), train_loss = 1.27954170, grad/param norm = 5.0306e-02, time/batch = 0.0783s	
4184/4200 (epoch 49.810), train_loss = 1.29288645, grad/param norm = 5.4263e-02, time/batch = 0.0780s	
4185/4200 (epoch 49.821), train_loss = 1.27675922, grad/param norm = 5.2305e-02, time/batch = 0.0781s	
4186/4200 (epoch 49.833), train_loss = 1.29414875, grad/param norm = 5.1769e-02, time/batch = 0.0786s	
4187/4200 (epoch 49.845), train_loss = 1.30084558, grad/param norm = 5.4224e-02, time/batch = 0.0781s	
4188/4200 (epoch 49.857), train_loss = 1.30510303, grad/param norm = 5.0646e-02, time/batch = 0.0781s	
4189/4200 (epoch 49.869), train_loss = 1.31185165, grad/param norm = 4.8754e-02, time/batch = 0.0780s	
4190/4200 (epoch 49.881), train_loss = 1.28951144, grad/param norm = 4.7543e-02, time/batch = 0.0777s	
4191/4200 (epoch 49.893), train_loss = 1.29940846, grad/param norm = 4.8752e-02, time/batch = 0.0797s	
4192/4200 (epoch 49.905), train_loss = 1.28686760, grad/param norm = 5.1859e-02, time/batch = 0.0777s	
4193/4200 (epoch 49.917), train_loss = 1.29500309, grad/param norm = 5.4249e-02, time/batch = 0.0777s	
4194/4200 (epoch 49.929), train_loss = 1.28778621, grad/param norm = 4.8064e-02, time/batch = 0.0777s	
4195/4200 (epoch 49.940), train_loss = 1.29372524, grad/param norm = 4.6481e-02, time/batch = 0.0781s	
4196/4200 (epoch 49.952), train_loss = 1.30133518, grad/param norm = 5.2874e-02, time/batch = 0.0775s	
4197/4200 (epoch 49.964), train_loss = 1.30200325, grad/param norm = 5.3326e-02, time/batch = 0.0780s	
4198/4200 (epoch 49.976), train_loss = 1.29244100, grad/param norm = 4.8382e-02, time/batch = 0.0776s	
4199/4200 (epoch 49.988), train_loss = 1.28768714, grad/param norm = 5.2085e-02, time/batch = 0.0785s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/5...	
2/5...	
3/5...	
4/5...	
5/5...	
saving checkpoint to cv/lm_lstm_epoch50.00_1.4099.t7	
4200/4200 (epoch 50.000), train_loss = 1.32560816, grad/param norm = 5.1709e-02, time/batch = 0.0777s	
