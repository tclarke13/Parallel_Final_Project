using CUDA on GPU 0...	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 423, val: 23, test: 0	
vocab size: 65	
creating an lstm with 2 layers	
